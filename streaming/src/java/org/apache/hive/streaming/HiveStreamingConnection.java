begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|streaming
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|UnknownHostException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ScheduledExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|JavaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|IMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|LockComponentBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|LockRequestBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|AlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|DataOperationType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|HeartbeatTxnRangeResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchTxnException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|TxnAbortedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|TxnToWriteId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|DbTxnManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|LockException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Hive
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AddPartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_comment
comment|/**  * Streaming connection implementation for hive. To create a streaming connection, use the builder API  * to create record writer first followed by the connection itself. Once connection is created, clients can  * begin a transaction, keep writing using the connection, commit the transaction and close connection when done.  * To bind to the correct metastore, HiveConf object has to be created from hive-site.xml or HIVE_CONF_DIR.  * If hive conf is manually created, metastore uri has to be set correctly. If hive conf object is not specified,  * "thrift://localhost:9083" will be used as default.  *<br/><br/>  * NOTE: The streaming connection APIs and record writer APIs are not thread-safe. Streaming connection creation,  * begin/commit/abort transactions, write and close has to be called in the same thread. If close() or  * abortTransaction() has to be triggered from a separate thread it has to be co-ordinated via external variables or  * synchronization mechanism  *<br/><br/>  * Example usage:  *<pre>{@code  * // create delimited record writer whose schema exactly matches table schema  * StrictDelimitedInputWriter writer = StrictDelimitedInputWriter.newBuilder()  *                                      .withFieldDelimiter(',')  *                                      .build();  * // create and open streaming connection (default.src table has to exist already)  * StreamingConnection connection = HiveStreamingConnection.newBuilder()  *                                    .withDatabase("default")  *                                    .withTable("src")  *                                    .withAgentInfo("nifi-agent")  *                                    .withRecordWriter(writer)  *                                    .withHiveConf(hiveConf)  *                                    .connect();  * // begin a transaction, write records and commit 1st transaction  * connection.beginTransaction();  * connection.write("key1,val1".getBytes());  * connection.write("key2,val2".getBytes());  * connection.commitTransaction();  * // begin another transaction, write more records and commit 2nd transaction  * connection.beginTransaction();  * connection.write("key3,val3".getBytes());  * connection.write("key4,val4".getBytes());  * connection.commitTransaction();  * // close the streaming connection  * connection.close();  * }  *</pre>  */
end_comment

begin_class
specifier|public
class|class
name|HiveStreamingConnection
implements|implements
name|StreamingConnection
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HiveStreamingConnection
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DEFAULT_METASTORE_URI
init|=
literal|"thrift://localhost:9083"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_TRANSACTION_BATCH_SIZE
init|=
literal|1
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_HEARTBEAT_INTERVAL
init|=
literal|60
operator|*
literal|1000
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_STREAMING_OPTIMIZATIONS_ENABLED
init|=
literal|true
decl_stmt|;
specifier|public
enum|enum
name|TxnState
block|{
name|INACTIVE
argument_list|(
literal|"I"
argument_list|)
block|,
name|OPEN
argument_list|(
literal|"O"
argument_list|)
block|,
name|COMMITTED
argument_list|(
literal|"C"
argument_list|)
block|,
name|ABORTED
argument_list|(
literal|"A"
argument_list|)
block|;
specifier|private
specifier|final
name|String
name|code
decl_stmt|;
name|TxnState
parameter_list|(
name|String
name|code
parameter_list|)
block|{
name|this
operator|.
name|code
operator|=
name|code
expr_stmt|;
block|}
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|code
return|;
block|}
block|}
comment|// fields populated from builder
specifier|private
name|String
name|database
decl_stmt|;
specifier|private
name|String
name|table
decl_stmt|;
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|staticPartitionValues
decl_stmt|;
specifier|private
name|String
name|agentInfo
decl_stmt|;
specifier|private
name|int
name|transactionBatchSize
decl_stmt|;
specifier|private
name|RecordWriter
name|recordWriter
decl_stmt|;
specifier|private
name|TransactionBatch
name|currentTransactionBatch
decl_stmt|;
specifier|private
name|HiveConf
name|conf
decl_stmt|;
specifier|private
name|boolean
name|streamingOptimizations
decl_stmt|;
specifier|private
name|AtomicBoolean
name|isConnectionClosed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// internal fields
specifier|private
name|boolean
name|isPartitionedTable
decl_stmt|;
specifier|private
name|IMetaStoreClient
name|msClient
decl_stmt|;
specifier|private
name|IMetaStoreClient
name|heartbeatMSClient
decl_stmt|;
specifier|private
specifier|final
name|String
name|username
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|secureMode
decl_stmt|;
specifier|private
name|Table
name|tableObject
init|=
literal|null
decl_stmt|;
specifier|private
name|String
name|metastoreUri
decl_stmt|;
specifier|private
name|ConnectionStats
name|connectionStats
decl_stmt|;
specifier|private
name|HiveStreamingConnection
parameter_list|(
name|Builder
name|builder
parameter_list|)
throws|throws
name|StreamingException
block|{
name|this
operator|.
name|database
operator|=
name|builder
operator|.
name|database
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
name|this
operator|.
name|table
operator|=
name|builder
operator|.
name|table
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
name|this
operator|.
name|staticPartitionValues
operator|=
name|builder
operator|.
name|staticPartitionValues
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|builder
operator|.
name|hiveConf
expr_stmt|;
name|this
operator|.
name|agentInfo
operator|=
name|builder
operator|.
name|agentInfo
expr_stmt|;
name|this
operator|.
name|streamingOptimizations
operator|=
name|builder
operator|.
name|streamingOptimizations
expr_stmt|;
name|UserGroupInformation
name|loggedInUser
init|=
literal|null
decl_stmt|;
try|try
block|{
name|loggedInUser
operator|=
name|UserGroupInformation
operator|.
name|getLoginUser
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to get logged in user via UGI. err: {}"
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|loggedInUser
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|username
operator|=
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
expr_stmt|;
name|this
operator|.
name|secureMode
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|username
operator|=
name|loggedInUser
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
name|this
operator|.
name|secureMode
operator|=
name|loggedInUser
operator|.
name|hasKerberosCredentials
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|transactionBatchSize
operator|=
name|builder
operator|.
name|transactionBatchSize
expr_stmt|;
name|this
operator|.
name|recordWriter
operator|=
name|builder
operator|.
name|recordWriter
expr_stmt|;
name|this
operator|.
name|connectionStats
operator|=
operator|new
name|ConnectionStats
argument_list|()
expr_stmt|;
if|if
condition|(
name|agentInfo
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|agentInfo
operator|=
name|username
operator|+
literal|":"
operator|+
name|InetAddress
operator|.
name|getLocalHost
argument_list|()
operator|.
name|getHostName
argument_list|()
operator|+
literal|":"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnknownHostException
name|e
parameter_list|)
block|{
comment|// ignore and use UUID instead
name|this
operator|.
name|agentInfo
operator|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
name|conf
operator|=
name|createHiveConf
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|,
name|DEFAULT_METASTORE_URI
argument_list|)
expr_stmt|;
block|}
name|overrideConfSettings
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|metastoreUri
operator|=
name|conf
operator|.
name|get
argument_list|(
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|THRIFT_URIS
operator|.
name|getHiveName
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|msClient
operator|=
name|getMetaStoreClient
argument_list|(
name|conf
argument_list|,
name|metastoreUri
argument_list|,
name|secureMode
argument_list|,
literal|"streaming-connection"
argument_list|)
expr_stmt|;
comment|// We use a separate metastore client for heartbeat calls to ensure heartbeat RPC calls are
comment|// isolated from the other transaction related RPC calls.
name|this
operator|.
name|heartbeatMSClient
operator|=
name|getMetaStoreClient
argument_list|(
name|conf
argument_list|,
name|metastoreUri
argument_list|,
name|secureMode
argument_list|,
literal|"streaming-connection-heartbeat"
argument_list|)
expr_stmt|;
name|validateTable
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"STREAMING CONNECTION INFO: {}"
argument_list|,
name|toConnectionInfoString
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|Builder
name|newBuilder
parameter_list|()
block|{
return|return
operator|new
name|Builder
argument_list|()
return|;
block|}
specifier|public
specifier|static
class|class
name|Builder
block|{
specifier|private
name|String
name|database
decl_stmt|;
specifier|private
name|String
name|table
decl_stmt|;
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|staticPartitionValues
decl_stmt|;
specifier|private
name|String
name|agentInfo
decl_stmt|;
specifier|private
name|HiveConf
name|hiveConf
decl_stmt|;
specifier|private
name|int
name|transactionBatchSize
init|=
name|DEFAULT_TRANSACTION_BATCH_SIZE
decl_stmt|;
specifier|private
name|boolean
name|streamingOptimizations
init|=
name|DEFAULT_STREAMING_OPTIMIZATIONS_ENABLED
decl_stmt|;
specifier|private
name|RecordWriter
name|recordWriter
decl_stmt|;
comment|/**      * Specify database to use for streaming connection.      *      * @param database - db name      * @return - builder      */
specifier|public
name|Builder
name|withDatabase
parameter_list|(
specifier|final
name|String
name|database
parameter_list|)
block|{
name|this
operator|.
name|database
operator|=
name|database
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Specify table to use for streaming connection.      *      * @param table - table name      * @return - builder      */
specifier|public
name|Builder
name|withTable
parameter_list|(
specifier|final
name|String
name|table
parameter_list|)
block|{
name|this
operator|.
name|table
operator|=
name|table
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Specify the name of partition to use for streaming connection.      *      * @param staticPartitionValues - static partition values      * @return - builder      */
specifier|public
name|Builder
name|withStaticPartitionValues
parameter_list|(
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|staticPartitionValues
parameter_list|)
block|{
name|this
operator|.
name|staticPartitionValues
operator|=
name|staticPartitionValues
operator|==
literal|null
condition|?
literal|null
else|:
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|staticPartitionValues
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Specify agent info to use for streaming connection.      *      * @param agentInfo - agent info      * @return - builder      */
specifier|public
name|Builder
name|withAgentInfo
parameter_list|(
specifier|final
name|String
name|agentInfo
parameter_list|)
block|{
name|this
operator|.
name|agentInfo
operator|=
name|agentInfo
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Specify hive configuration object to use for streaming connection.      * Generate this object by point to already existing hive-site.xml or HIVE_CONF_DIR.      * Make sure if metastore URI has been set correctly else thrift://localhost:9083 will be      * used as default.      *      * @param hiveConf - hive conf object      * @return - builder      */
specifier|public
name|Builder
name|withHiveConf
parameter_list|(
specifier|final
name|HiveConf
name|hiveConf
parameter_list|)
block|{
name|this
operator|.
name|hiveConf
operator|=
name|hiveConf
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Transaction batch size to use (default value is 10). This is expert level configuration.      * For every transaction batch a delta directory will be created which will impact      * when compaction will trigger.      * NOTE: This is evolving API and is subject to change/might not be honored in future releases.      *      * @param transactionBatchSize - transaction batch size      * @return - builder      */
annotation|@
name|InterfaceStability
operator|.
name|Evolving
specifier|public
name|Builder
name|withTransactionBatchSize
parameter_list|(
specifier|final
name|int
name|transactionBatchSize
parameter_list|)
block|{
name|this
operator|.
name|transactionBatchSize
operator|=
name|transactionBatchSize
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Whether to enable streaming optimizations. This is expert level configurations.      * Disabling streaming optimizations will have significant impact to performance and memory consumption.      *      * @param enable - flag to enable or not      * @return - builder      */
specifier|public
name|Builder
name|withStreamingOptimizations
parameter_list|(
specifier|final
name|boolean
name|enable
parameter_list|)
block|{
name|this
operator|.
name|streamingOptimizations
operator|=
name|enable
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Record writer to use for writing records to destination table.      *      * @param recordWriter - record writer      * @return - builder      */
specifier|public
name|Builder
name|withRecordWriter
parameter_list|(
specifier|final
name|RecordWriter
name|recordWriter
parameter_list|)
block|{
name|this
operator|.
name|recordWriter
operator|=
name|recordWriter
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Returning a streaming connection to hive.      *      * @return - hive streaming connection      */
specifier|public
name|HiveStreamingConnection
name|connect
parameter_list|()
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|database
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Database cannot be null for streaming connection"
argument_list|)
throw|;
block|}
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Table cannot be null for streaming connection"
argument_list|)
throw|;
block|}
if|if
condition|(
name|recordWriter
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Record writer cannot be null for streaming connection"
argument_list|)
throw|;
block|}
return|return
operator|new
name|HiveStreamingConnection
argument_list|(
name|this
argument_list|)
return|;
block|}
block|}
specifier|private
name|void
name|setPartitionedTable
parameter_list|(
name|boolean
name|isPartitionedTable
parameter_list|)
block|{
name|this
operator|.
name|isPartitionedTable
operator|=
name|isPartitionedTable
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"{ metaStoreUri: "
operator|+
name|metastoreUri
operator|+
literal|", database: "
operator|+
name|database
operator|+
literal|", table: "
operator|+
name|table
operator|+
literal|" }"
return|;
block|}
specifier|private
name|String
name|toConnectionInfoString
parameter_list|()
block|{
return|return
literal|"{ metastore-uri: "
operator|+
name|metastoreUri
operator|+
literal|", "
operator|+
literal|"database: "
operator|+
name|database
operator|+
literal|", "
operator|+
literal|"table: "
operator|+
name|table
operator|+
literal|", "
operator|+
literal|"partitioned-table: "
operator|+
name|isPartitionedTable
argument_list|()
operator|+
literal|", "
operator|+
literal|"dynamic-partitioning: "
operator|+
name|isDynamicPartitioning
argument_list|()
operator|+
literal|", "
operator|+
literal|"username: "
operator|+
name|username
operator|+
literal|", "
operator|+
literal|"secure-mode: "
operator|+
name|secureMode
operator|+
literal|", "
operator|+
literal|"record-writer: "
operator|+
name|recordWriter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|", "
operator|+
literal|"agent-info: "
operator|+
name|agentInfo
operator|+
literal|" }"
return|;
block|}
annotation|@
name|VisibleForTesting
name|String
name|toTransactionString
parameter_list|()
block|{
return|return
name|currentTransactionBatch
operator|==
literal|null
condition|?
literal|""
else|:
name|currentTransactionBatch
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|PartitionInfo
name|createPartitionIfNotExists
parameter_list|(
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|partitionValues
parameter_list|)
throws|throws
name|StreamingException
block|{
name|String
name|partLocation
init|=
literal|null
decl_stmt|;
name|String
name|partName
init|=
literal|null
decl_stmt|;
name|boolean
name|exists
init|=
literal|false
decl_stmt|;
try|try
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|Warehouse
operator|.
name|makeSpecFromValues
argument_list|(
name|tableObject
operator|.
name|getPartitionKeys
argument_list|()
argument_list|,
name|partitionValues
argument_list|)
decl_stmt|;
name|AddPartitionDesc
name|addPartitionDesc
init|=
operator|new
name|AddPartitionDesc
argument_list|(
name|database
argument_list|,
name|table
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|partName
operator|=
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|tableObject
operator|.
name|getPartitionKeys
argument_list|()
argument_list|,
name|partitionValues
argument_list|)
expr_stmt|;
name|partLocation
operator|=
operator|new
name|Path
argument_list|(
name|tableObject
operator|.
name|getDataLocation
argument_list|()
argument_list|,
name|Warehouse
operator|.
name|makePartPath
argument_list|(
name|partSpec
argument_list|)
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
name|addPartitionDesc
operator|.
name|addPartition
argument_list|(
name|partSpec
argument_list|,
name|partLocation
argument_list|)
expr_stmt|;
name|Partition
name|partition
init|=
name|Hive
operator|.
name|convertAddSpecToMetaPartition
argument_list|(
name|tableObject
argument_list|,
name|addPartitionDesc
operator|.
name|getPartition
argument_list|(
literal|0
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|getMSC
argument_list|()
operator|.
name|add_partition
argument_list|(
name|partition
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|e
parameter_list|)
block|{
name|exists
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|HiveException
decl||
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Unable to creation partition for values: "
operator|+
name|partitionValues
operator|+
literal|" connection: "
operator|+
name|toConnectionInfoString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
return|return
operator|new
name|PartitionInfo
argument_list|(
name|partName
argument_list|,
name|partLocation
argument_list|,
name|exists
argument_list|)
return|;
block|}
name|IMetaStoreClient
name|getMSC
parameter_list|()
block|{
name|connectionStats
operator|.
name|incrementMetastoreCalls
argument_list|()
expr_stmt|;
return|return
name|msClient
return|;
block|}
name|IMetaStoreClient
name|getHeatbeatMSC
parameter_list|()
block|{
name|connectionStats
operator|.
name|incrementMetastoreCalls
argument_list|()
expr_stmt|;
return|return
name|heartbeatMSClient
return|;
block|}
specifier|private
name|void
name|validateTable
parameter_list|()
throws|throws
name|InvalidTable
throws|,
name|ConnectionError
block|{
try|try
block|{
name|tableObject
operator|=
operator|new
name|Table
argument_list|(
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|database
argument_list|,
name|table
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to validate the table for connection: "
operator|+
name|toConnectionInfoString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTable
argument_list|(
name|database
argument_list|,
name|table
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// 1 - check that the table is Acid
if|if
condition|(
operator|!
name|AcidUtils
operator|.
name|isFullAcidTable
argument_list|(
name|tableObject
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"HiveEndPoint "
operator|+
name|this
operator|+
literal|" must use an acid table"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTable
argument_list|(
name|database
argument_list|,
name|table
argument_list|,
literal|"is not an Acid table"
argument_list|)
throw|;
block|}
if|if
condition|(
name|tableObject
operator|.
name|getPartitionKeys
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|tableObject
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|setPartitionedTable
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|setPartitionedTable
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// partition values are specified on non-partitioned table
if|if
condition|(
operator|!
name|isPartitionedTable
argument_list|()
operator|&&
operator|(
name|staticPartitionValues
operator|!=
literal|null
operator|&&
operator|!
name|staticPartitionValues
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
comment|// Invalid if table is not partitioned, but endPoint's partitionVals is not empty
name|String
name|errMsg
init|=
name|this
operator|.
name|toString
argument_list|()
operator|+
literal|" specifies partitions for un-partitioned table"
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|errMsg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|ConnectionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
class|class
name|HeartbeatRunnable
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|HiveStreamingConnection
name|conn
decl_stmt|;
specifier|private
specifier|final
name|AtomicLong
name|minTxnId
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxTxnId
decl_stmt|;
specifier|private
specifier|final
name|ReentrantLock
name|transactionLock
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|isTxnClosed
decl_stmt|;
name|HeartbeatRunnable
parameter_list|(
specifier|final
name|HiveStreamingConnection
name|conn
parameter_list|,
specifier|final
name|AtomicLong
name|minTxnId
parameter_list|,
specifier|final
name|long
name|maxTxnId
parameter_list|,
specifier|final
name|ReentrantLock
name|transactionLock
parameter_list|,
specifier|final
name|AtomicBoolean
name|isTxnClosed
parameter_list|)
block|{
name|this
operator|.
name|conn
operator|=
name|conn
expr_stmt|;
name|this
operator|.
name|minTxnId
operator|=
name|minTxnId
expr_stmt|;
name|this
operator|.
name|maxTxnId
operator|=
name|maxTxnId
expr_stmt|;
name|this
operator|.
name|transactionLock
operator|=
name|transactionLock
expr_stmt|;
name|this
operator|.
name|isTxnClosed
operator|=
name|isTxnClosed
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|transactionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|minTxnId
operator|.
name|get
argument_list|()
operator|>
literal|0
condition|)
block|{
name|HeartbeatTxnRangeResponse
name|resp
init|=
name|conn
operator|.
name|getHeatbeatMSC
argument_list|()
operator|.
name|heartbeatTxnRange
argument_list|(
name|minTxnId
operator|.
name|get
argument_list|()
argument_list|,
name|maxTxnId
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|resp
operator|.
name|getAborted
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|||
operator|!
name|resp
operator|.
name|getNosuch
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Heartbeat failure: {}"
argument_list|,
name|resp
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|isTxnClosed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Heartbeat sent for range: [{}-{}]"
argument_list|,
name|minTxnId
operator|.
name|get
argument_list|()
argument_list|,
name|maxTxnId
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failure to heartbeat for transaction range: ["
operator|+
name|minTxnId
operator|.
name|get
argument_list|()
operator|+
literal|"-"
operator|+
name|maxTxnId
operator|+
literal|"]"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|transactionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|beginNextTransaction
parameter_list|()
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|currentTransactionBatch
operator|==
literal|null
condition|)
block|{
name|currentTransactionBatch
operator|=
name|createNewTransactionBatch
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Opened new transaction batch {}"
argument_list|,
name|currentTransactionBatch
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|currentTransactionBatch
operator|.
name|isClosed
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Cannot begin next transaction on a closed streaming connection"
argument_list|)
throw|;
block|}
if|if
condition|(
name|currentTransactionBatch
operator|.
name|remainingTransactions
argument_list|()
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Transaction batch {} is done. Rolling over to next transaction batch."
argument_list|,
name|currentTransactionBatch
argument_list|)
expr_stmt|;
name|currentTransactionBatch
operator|.
name|close
argument_list|()
expr_stmt|;
name|currentTransactionBatch
operator|=
name|createNewTransactionBatch
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolled over to new transaction batch {}"
argument_list|,
name|currentTransactionBatch
argument_list|)
expr_stmt|;
block|}
name|currentTransactionBatch
operator|.
name|beginNextTransaction
argument_list|()
expr_stmt|;
block|}
specifier|private
name|TransactionBatch
name|createNewTransactionBatch
parameter_list|()
throws|throws
name|StreamingException
block|{
return|return
operator|new
name|TransactionBatch
argument_list|(
name|this
argument_list|)
return|;
block|}
specifier|private
name|void
name|checkClosedState
parameter_list|()
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|isConnectionClosed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Streaming connection is closed already."
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|checkState
parameter_list|()
throws|throws
name|StreamingException
block|{
name|checkClosedState
argument_list|()
expr_stmt|;
if|if
condition|(
name|currentTransactionBatch
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Transaction batch is null. Missing beginTransaction?"
argument_list|)
throw|;
block|}
if|if
condition|(
name|currentTransactionBatch
operator|.
name|state
operator|!=
name|TxnState
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Transaction state is not OPEN. Missing beginTransaction?"
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|beginTransaction
parameter_list|()
throws|throws
name|StreamingException
block|{
name|checkClosedState
argument_list|()
expr_stmt|;
name|beginNextTransaction
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|commitTransaction
parameter_list|()
throws|throws
name|StreamingException
block|{
name|checkState
argument_list|()
expr_stmt|;
name|currentTransactionBatch
operator|.
name|commit
argument_list|()
expr_stmt|;
name|connectionStats
operator|.
name|incrementCommittedTransactions
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|abortTransaction
parameter_list|()
throws|throws
name|StreamingException
block|{
name|checkState
argument_list|()
expr_stmt|;
name|currentTransactionBatch
operator|.
name|abort
argument_list|()
expr_stmt|;
name|connectionStats
operator|.
name|incrementAbortedTransactions
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|byte
index|[]
name|record
parameter_list|)
throws|throws
name|StreamingException
block|{
name|checkState
argument_list|()
expr_stmt|;
name|currentTransactionBatch
operator|.
name|write
argument_list|(
name|record
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|InputStream
name|inputStream
parameter_list|)
throws|throws
name|StreamingException
block|{
name|checkState
argument_list|()
expr_stmt|;
name|currentTransactionBatch
operator|.
name|write
argument_list|(
name|inputStream
argument_list|)
expr_stmt|;
block|}
comment|/**    * Close connection    */
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
name|isConnectionClosed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|isConnectionClosed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|currentTransactionBatch
operator|!=
literal|null
condition|)
block|{
name|currentTransactionBatch
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|StreamingException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to close current transaction batch: "
operator|+
name|currentTransactionBatch
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|getMSC
argument_list|()
operator|.
name|close
argument_list|()
expr_stmt|;
name|getHeatbeatMSC
argument_list|()
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed streaming connection. Agent: {} Stats: {}"
argument_list|,
name|getAgentInfo
argument_list|()
argument_list|,
name|getConnectionStats
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|ConnectionStats
name|getConnectionStats
parameter_list|()
block|{
return|return
name|connectionStats
return|;
block|}
specifier|private
specifier|static
name|IMetaStoreClient
name|getMetaStoreClient
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|String
name|metastoreUri
parameter_list|,
name|boolean
name|secureMode
parameter_list|,
name|String
name|owner
parameter_list|)
throws|throws
name|ConnectionError
block|{
if|if
condition|(
name|metastoreUri
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|THRIFT_URIS
operator|.
name|getHiveName
argument_list|()
argument_list|,
name|metastoreUri
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|secureMode
condition|)
block|{
name|conf
operator|.
name|setBoolean
argument_list|(
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|USE_THRIFT_SASL
operator|.
name|getHiveName
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating metastore client for {}"
argument_list|,
name|owner
argument_list|)
expr_stmt|;
return|return
name|HiveMetaStoreUtils
operator|.
name|getHiveMetastoreClient
argument_list|(
name|conf
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|MetaException
decl||
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ConnectionError
argument_list|(
literal|"Error connecting to Hive Metastore URI: "
operator|+
name|metastoreUri
operator|+
literal|". "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|VisibleForTesting
name|TxnState
name|getCurrentTransactionState
parameter_list|()
block|{
return|return
name|currentTransactionBatch
operator|.
name|getCurrentTransactionState
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
name|int
name|remainingTransactions
parameter_list|()
block|{
return|return
name|currentTransactionBatch
operator|.
name|remainingTransactions
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
name|Long
name|getCurrentTxnId
parameter_list|()
block|{
return|return
name|currentTransactionBatch
operator|.
name|getCurrentTxnId
argument_list|()
return|;
block|}
specifier|private
specifier|static
class|class
name|TransactionBatch
block|{
specifier|private
name|String
name|username
decl_stmt|;
specifier|private
name|HiveStreamingConnection
name|conn
decl_stmt|;
specifier|private
name|ScheduledExecutorService
name|scheduledExecutorService
decl_stmt|;
specifier|private
name|RecordWriter
name|recordWriter
decl_stmt|;
specifier|private
name|String
name|partNameForLock
init|=
literal|null
decl_stmt|;
specifier|private
name|List
argument_list|<
name|TxnToWriteId
argument_list|>
name|txnToWriteIds
decl_stmt|;
specifier|private
name|int
name|currentTxnIndex
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|TxnState
name|state
decl_stmt|;
specifier|private
name|LockRequest
name|lockRequest
init|=
literal|null
decl_stmt|;
comment|// heartbeats can only be sent for open transactions.
comment|// there is a race between committing/aborting a transaction and heartbeat.
comment|// Example: If a heartbeat is sent for committed txn, exception will be thrown.
comment|// Similarly if we don't send a heartbeat, metastore server might abort a txn
comment|// for missed heartbeat right before commit txn call.
comment|// This lock is used to mutex commit/abort and heartbeat calls
specifier|private
specifier|final
name|ReentrantLock
name|transactionLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
comment|// min txn id is incremented linearly within a transaction batch.
comment|// keeping minTxnId atomic as it is shared with heartbeat thread
specifier|private
specifier|final
name|AtomicLong
name|minTxnId
decl_stmt|;
comment|// max txn id does not change for a transaction batch
specifier|private
specifier|final
name|long
name|maxTxnId
decl_stmt|;
comment|/**      * once any operation on this batch encounters a system exception      * (e.g. IOException on write) it's safest to assume that we can't write to the      * file backing this batch any more.  This guards important public methods      */
specifier|private
specifier|final
name|AtomicBoolean
name|isTxnClosed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
specifier|private
name|String
name|agentInfo
decl_stmt|;
specifier|private
name|int
name|numTxns
decl_stmt|;
comment|/**      * Tracks the state of each transaction      */
specifier|private
name|TxnState
index|[]
name|txnStatus
decl_stmt|;
comment|/**      * ID of the last txn used by {@link #beginNextTransactionImpl()}      */
specifier|private
name|long
name|lastTxnUsed
decl_stmt|;
comment|/**      * Represents a batch of transactions acquired from MetaStore      *      * @param conn - hive streaming connection      * @throws StreamingException if failed to create new RecordUpdater for batch      */
specifier|private
name|TransactionBatch
parameter_list|(
name|HiveStreamingConnection
name|conn
parameter_list|)
throws|throws
name|StreamingException
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|conn
operator|.
name|isPartitionedTable
argument_list|()
operator|&&
operator|!
name|conn
operator|.
name|isDynamicPartitioning
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partKeys
init|=
name|conn
operator|.
name|tableObject
operator|.
name|getPartitionKeys
argument_list|()
decl_stmt|;
name|partNameForLock
operator|=
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|partKeys
argument_list|,
name|conn
operator|.
name|staticPartitionValues
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|conn
operator|=
name|conn
expr_stmt|;
name|this
operator|.
name|username
operator|=
name|conn
operator|.
name|username
expr_stmt|;
name|this
operator|.
name|recordWriter
operator|=
name|conn
operator|.
name|recordWriter
expr_stmt|;
name|this
operator|.
name|agentInfo
operator|=
name|conn
operator|.
name|agentInfo
expr_stmt|;
name|this
operator|.
name|numTxns
operator|=
name|conn
operator|.
name|transactionBatchSize
expr_stmt|;
name|setupHeartBeatThread
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|txnIds
init|=
name|openTxnImpl
argument_list|(
name|username
argument_list|,
name|numTxns
argument_list|)
decl_stmt|;
name|txnToWriteIds
operator|=
name|allocateWriteIdsImpl
argument_list|(
name|txnIds
argument_list|)
expr_stmt|;
assert|assert
operator|(
name|txnToWriteIds
operator|.
name|size
argument_list|()
operator|==
name|numTxns
operator|)
assert|;
name|txnStatus
operator|=
operator|new
name|TxnState
index|[
name|numTxns
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|txnStatus
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
assert|assert
operator|(
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getTxnId
argument_list|()
operator|==
name|txnIds
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|)
assert|;
name|txnStatus
index|[
name|i
index|]
operator|=
name|TxnState
operator|.
name|OPEN
expr_stmt|;
comment|//Open matches Metastore state
block|}
name|this
operator|.
name|state
operator|=
name|TxnState
operator|.
name|INACTIVE
expr_stmt|;
comment|// initialize record writer with connection and write id info
name|recordWriter
operator|.
name|init
argument_list|(
name|conn
argument_list|,
name|txnToWriteIds
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getWriteId
argument_list|()
argument_list|,
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|numTxns
operator|-
literal|1
argument_list|)
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|minTxnId
operator|=
operator|new
name|AtomicLong
argument_list|(
name|txnIds
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxTxnId
operator|=
name|txnIds
operator|.
name|get
argument_list|(
name|txnIds
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
name|conn
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
comment|//clean up if above throws
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|setupHeartBeatThread
parameter_list|()
block|{
comment|// start heartbeat thread
name|ThreadFactory
name|threadFactory
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"HiveStreamingConnection-Heartbeat-Thread"
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|this
operator|.
name|scheduledExecutorService
operator|=
name|Executors
operator|.
name|newSingleThreadScheduledExecutor
argument_list|(
name|threadFactory
argument_list|)
expr_stmt|;
name|long
name|heartBeatInterval
decl_stmt|;
name|long
name|initialDelay
decl_stmt|;
try|try
block|{
comment|// if HIVE_TXN_TIMEOUT is defined, heartbeat interval will be HIVE_TXN_TIMEOUT/2
name|heartBeatInterval
operator|=
name|DbTxnManager
operator|.
name|getHeartbeatInterval
argument_list|(
name|conn
operator|.
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|heartBeatInterval
operator|=
name|DEFAULT_HEARTBEAT_INTERVAL
expr_stmt|;
block|}
comment|// to introduce some randomness and to avoid hammering the metastore at the same time (same logic as DbTxnManager)
name|initialDelay
operator|=
call|(
name|long
call|)
argument_list|(
name|heartBeatInterval
operator|*
literal|0.75
operator|*
name|Math
operator|.
name|random
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting heartbeat thread with interval: {} ms initialDelay: {} ms for agentInfo: {}"
argument_list|,
name|heartBeatInterval
argument_list|,
name|initialDelay
argument_list|,
name|conn
operator|.
name|agentInfo
argument_list|)
expr_stmt|;
name|Runnable
name|runnable
init|=
operator|new
name|HeartbeatRunnable
argument_list|(
name|conn
argument_list|,
name|minTxnId
argument_list|,
name|maxTxnId
argument_list|,
name|transactionLock
argument_list|,
name|isTxnClosed
argument_list|)
decl_stmt|;
name|this
operator|.
name|scheduledExecutorService
operator|.
name|scheduleWithFixedDelay
argument_list|(
name|runnable
argument_list|,
name|initialDelay
argument_list|,
name|heartBeatInterval
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
specifier|private
name|List
argument_list|<
name|Long
argument_list|>
name|openTxnImpl
parameter_list|(
specifier|final
name|String
name|user
parameter_list|,
specifier|final
name|int
name|numTxns
parameter_list|)
throws|throws
name|TException
block|{
return|return
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|openTxns
argument_list|(
name|user
argument_list|,
name|numTxns
argument_list|)
operator|.
name|getTxn_ids
argument_list|()
return|;
block|}
specifier|private
name|List
argument_list|<
name|TxnToWriteId
argument_list|>
name|allocateWriteIdsImpl
parameter_list|(
specifier|final
name|List
argument_list|<
name|Long
argument_list|>
name|txnIds
parameter_list|)
throws|throws
name|TException
block|{
return|return
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|allocateTableWriteIdsBatch
argument_list|(
name|txnIds
argument_list|,
name|conn
operator|.
name|database
argument_list|,
name|conn
operator|.
name|table
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
if|if
condition|(
name|txnToWriteIds
operator|==
literal|null
operator|||
name|txnToWriteIds
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|"{}"
return|;
block|}
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|" TxnStatus["
argument_list|)
decl_stmt|;
for|for
control|(
name|TxnState
name|state
range|:
name|txnStatus
control|)
block|{
comment|//'state' should not be null - future proofing
name|sb
operator|.
name|append
argument_list|(
name|state
operator|==
literal|null
condition|?
literal|"N"
else|:
name|state
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"] LastUsed "
argument_list|)
operator|.
name|append
argument_list|(
name|JavaUtils
operator|.
name|txnIdToString
argument_list|(
name|lastTxnUsed
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|"TxnId/WriteIds=["
operator|+
name|txnToWriteIds
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getTxnId
argument_list|()
operator|+
literal|"/"
operator|+
name|txnToWriteIds
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getWriteId
argument_list|()
operator|+
literal|"..."
operator|+
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|txnToWriteIds
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|.
name|getTxnId
argument_list|()
operator|+
literal|"/"
operator|+
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|txnToWriteIds
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|.
name|getWriteId
argument_list|()
operator|+
literal|"] on connection = "
operator|+
name|conn
operator|+
literal|"; "
operator|+
name|sb
return|;
block|}
specifier|private
name|void
name|beginNextTransaction
parameter_list|()
throws|throws
name|StreamingException
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
name|beginNextTransactionImpl
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|beginNextTransactionImpl
parameter_list|()
throws|throws
name|TransactionError
block|{
name|state
operator|=
name|TxnState
operator|.
name|INACTIVE
expr_stmt|;
comment|//clear state from previous txn
if|if
condition|(
operator|(
name|currentTxnIndex
operator|+
literal|1
operator|)
operator|>=
name|txnToWriteIds
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|InvalidTransactionState
argument_list|(
literal|"No more transactions available in"
operator|+
literal|" next batch for connection: "
operator|+
name|conn
operator|+
literal|" user: "
operator|+
name|username
argument_list|)
throw|;
block|}
name|currentTxnIndex
operator|++
expr_stmt|;
name|state
operator|=
name|TxnState
operator|.
name|OPEN
expr_stmt|;
name|lastTxnUsed
operator|=
name|getCurrentTxnId
argument_list|()
expr_stmt|;
name|lockRequest
operator|=
name|createLockRequest
argument_list|(
name|conn
argument_list|,
name|partNameForLock
argument_list|,
name|username
argument_list|,
name|getCurrentTxnId
argument_list|()
argument_list|,
name|agentInfo
argument_list|)
expr_stmt|;
try|try
block|{
name|LockResponse
name|res
init|=
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|lock
argument_list|(
name|lockRequest
argument_list|)
decl_stmt|;
if|if
condition|(
name|res
operator|.
name|getState
argument_list|()
operator|!=
name|LockState
operator|.
name|ACQUIRED
condition|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to acquire lock on "
operator|+
name|conn
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to acquire lock on "
operator|+
name|conn
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|long
name|getCurrentTxnId
parameter_list|()
block|{
if|if
condition|(
name|currentTxnIndex
operator|>=
literal|0
condition|)
block|{
return|return
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
operator|.
name|getTxnId
argument_list|()
return|;
block|}
return|return
operator|-
literal|1L
return|;
block|}
name|long
name|getCurrentWriteId
parameter_list|()
block|{
if|if
condition|(
name|currentTxnIndex
operator|>=
literal|0
condition|)
block|{
return|return
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
operator|.
name|getWriteId
argument_list|()
return|;
block|}
return|return
operator|-
literal|1L
return|;
block|}
name|TxnState
name|getCurrentTransactionState
parameter_list|()
block|{
return|return
name|state
return|;
block|}
name|int
name|remainingTransactions
parameter_list|()
block|{
if|if
condition|(
name|currentTxnIndex
operator|>=
literal|0
condition|)
block|{
return|return
name|txnToWriteIds
operator|.
name|size
argument_list|()
operator|-
name|currentTxnIndex
operator|-
literal|1
return|;
block|}
return|return
name|txnToWriteIds
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|byte
index|[]
name|record
parameter_list|)
throws|throws
name|StreamingException
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|recordWriter
operator|.
name|write
argument_list|(
name|getCurrentWriteId
argument_list|()
argument_list|,
name|record
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SerializationError
name|ex
parameter_list|)
block|{
comment|//this exception indicates that a {@code record} could not be parsed and the
comment|//caller can decide whether to drop it or send it to dead letter queue.
comment|//rolling back the txn and retrying won't help since the tuple will be exactly the same
comment|//when it's replayed.
name|success
operator|=
literal|true
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
finally|finally
block|{
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|InputStream
name|inputStream
parameter_list|)
throws|throws
name|StreamingException
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|recordWriter
operator|.
name|write
argument_list|(
name|getCurrentWriteId
argument_list|()
argument_list|,
name|inputStream
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SerializationError
name|ex
parameter_list|)
block|{
comment|//this exception indicates that a {@code record} could not be parsed and the
comment|//caller can decide whether to drop it or send it to dead letter queue.
comment|//rolling back the txn and retrying won'table help since the tuple will be exactly the same
comment|//when it's replayed.
name|success
operator|=
literal|true
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
finally|finally
block|{
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|checkIsClosed
parameter_list|()
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|isTxnClosed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Transaction"
operator|+
name|toString
argument_list|()
operator|+
literal|" is closed()"
argument_list|)
throw|;
block|}
block|}
comment|/**      * A transaction batch opens a single HDFS file and writes multiple transaction to it.  If there is any issue      * with the write, we can't continue to write to the same file any as it may be corrupted now (at the tail).      * This ensures that a client can't ignore these failures and continue to write.      */
specifier|private
name|void
name|markDead
parameter_list|(
name|boolean
name|success
parameter_list|)
block|{
if|if
condition|(
name|success
condition|)
block|{
return|return;
block|}
name|isTxnClosed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|//also ensures that heartbeat() is no-op since client is likely doing it async
try|try
block|{
name|abort
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|//abort all remaining txns
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Fatal error on "
operator|+
name|toString
argument_list|()
operator|+
literal|"; cause "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|closeImpl
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Fatal error on "
operator|+
name|toString
argument_list|()
operator|+
literal|"; cause "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|commit
parameter_list|()
throws|throws
name|StreamingException
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|commitImpl
argument_list|()
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|commitImpl
parameter_list|()
throws|throws
name|StreamingException
block|{
try|try
block|{
name|recordWriter
operator|.
name|flush
argument_list|()
expr_stmt|;
name|TxnToWriteId
name|txnToWriteId
init|=
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
decl_stmt|;
if|if
condition|(
name|conn
operator|.
name|isDynamicPartitioning
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|partNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|recordWriter
operator|.
name|getPartitions
argument_list|()
argument_list|)
decl_stmt|;
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|addDynamicPartitions
argument_list|(
name|txnToWriteId
operator|.
name|getTxnId
argument_list|()
argument_list|,
name|txnToWriteId
operator|.
name|getWriteId
argument_list|()
argument_list|,
name|conn
operator|.
name|database
argument_list|,
name|conn
operator|.
name|table
argument_list|,
name|partNames
argument_list|,
name|DataOperationType
operator|.
name|INSERT
argument_list|)
expr_stmt|;
block|}
name|transactionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|commitTxn
argument_list|(
name|txnToWriteId
operator|.
name|getTxnId
argument_list|()
argument_list|)
expr_stmt|;
comment|// increment the min txn id so that heartbeat thread will heartbeat only from the next open transaction.
comment|// the current transaction is going to committed or fail, so don't need heartbeat for current transaction.
if|if
condition|(
name|currentTxnIndex
operator|+
literal|1
operator|<
name|txnToWriteIds
operator|.
name|size
argument_list|()
condition|)
block|{
name|minTxnId
operator|.
name|set
argument_list|(
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
operator|+
literal|1
argument_list|)
operator|.
name|getTxnId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// exhausted the batch, no longer have to heartbeat for current txn batch
name|minTxnId
operator|.
name|set
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|transactionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|state
operator|=
name|TxnState
operator|.
name|COMMITTED
expr_stmt|;
name|txnStatus
index|[
name|currentTxnIndex
index|]
operator|=
name|TxnState
operator|.
name|COMMITTED
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchTxnException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Invalid transaction id : "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TxnAbortedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Aborted transaction cannot be committed"
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to commitTransaction transaction"
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|void
name|abort
parameter_list|()
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|isTxnClosed
operator|.
name|get
argument_list|()
condition|)
block|{
comment|/*          * isDead is only set internally by this class.  {@link #markDead(boolean)} will abort all          * remaining txns, so make this no-op to make sure that a well-behaved client that calls abortTransaction()          * error doesn't get misleading errors          */
return|return;
block|}
name|abort
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|abort
parameter_list|(
specifier|final
name|boolean
name|abortAllRemaining
parameter_list|)
throws|throws
name|StreamingException
block|{
name|abortImpl
argument_list|(
name|abortAllRemaining
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|abortImpl
parameter_list|(
name|boolean
name|abortAllRemaining
parameter_list|)
throws|throws
name|StreamingException
block|{
name|transactionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|abortAllRemaining
condition|)
block|{
comment|// we are aborting all txns in the current batch, so no need to heartbeat
name|minTxnId
operator|.
name|set
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
comment|//when last txn finished (abortTransaction/commitTransaction) the currentTxnIndex is pointing at that txn
comment|//so we need to start from next one, if any.  Also if batch was created but
comment|//fetchTransactionBatch() was never called, we want to start with first txn
name|int
name|minOpenTxnIndex
init|=
name|Math
operator|.
name|max
argument_list|(
name|currentTxnIndex
operator|+
operator|(
name|state
operator|==
name|TxnState
operator|.
name|ABORTED
operator|||
name|state
operator|==
name|TxnState
operator|.
name|COMMITTED
condition|?
literal|1
else|:
literal|0
operator|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|currentTxnIndex
operator|=
name|minOpenTxnIndex
init|;
name|currentTxnIndex
operator|<
name|txnToWriteIds
operator|.
name|size
argument_list|()
condition|;
name|currentTxnIndex
operator|++
control|)
block|{
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|rollbackTxn
argument_list|(
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
operator|.
name|getTxnId
argument_list|()
argument_list|)
expr_stmt|;
name|txnStatus
index|[
name|currentTxnIndex
index|]
operator|=
name|TxnState
operator|.
name|ABORTED
expr_stmt|;
block|}
name|currentTxnIndex
operator|--
expr_stmt|;
comment|//since the loop left it == txnToWriteIds.size()
block|}
else|else
block|{
comment|// we are aborting only the current transaction, so move the min range for heartbeat or disable heartbeat
comment|// if the current txn is last in the batch.
if|if
condition|(
name|currentTxnIndex
operator|+
literal|1
operator|<
name|txnToWriteIds
operator|.
name|size
argument_list|()
condition|)
block|{
name|minTxnId
operator|.
name|set
argument_list|(
name|txnToWriteIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
operator|+
literal|1
argument_list|)
operator|.
name|getTxnId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// exhausted the batch, no longer have to heartbeat
name|minTxnId
operator|.
name|set
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|long
name|currTxnId
init|=
name|getCurrentTxnId
argument_list|()
decl_stmt|;
if|if
condition|(
name|currTxnId
operator|>
literal|0
condition|)
block|{
name|conn
operator|.
name|getMSC
argument_list|()
operator|.
name|rollbackTxn
argument_list|(
name|currTxnId
argument_list|)
expr_stmt|;
name|txnStatus
index|[
name|currentTxnIndex
index|]
operator|=
name|TxnState
operator|.
name|ABORTED
expr_stmt|;
block|}
block|}
name|state
operator|=
name|TxnState
operator|.
name|ABORTED
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchTxnException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to abort invalid transaction id : "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to abort transaction id : "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|transactionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|isTxnClosed
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**      * Close the TransactionBatch.  This will abort any still open txns in this batch.      *      * @throws StreamingException - failure when closing transaction batch      */
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|isTxnClosed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|isTxnClosed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|abortImpl
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|closeImpl
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|closeImpl
parameter_list|()
throws|throws
name|StreamingException
block|{
name|state
operator|=
name|TxnState
operator|.
name|INACTIVE
expr_stmt|;
name|recordWriter
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|scheduledExecutorService
operator|!=
literal|null
condition|)
block|{
name|scheduledExecutorService
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
block|}
specifier|static
name|LockRequest
name|createLockRequest
parameter_list|(
specifier|final
name|HiveStreamingConnection
name|connection
parameter_list|,
name|String
name|partNameForLock
parameter_list|,
name|String
name|user
parameter_list|,
name|long
name|txnId
parameter_list|,
name|String
name|agentInfo
parameter_list|)
block|{
name|LockRequestBuilder
name|requestBuilder
init|=
operator|new
name|LockRequestBuilder
argument_list|(
name|agentInfo
argument_list|)
decl_stmt|;
name|requestBuilder
operator|.
name|setUser
argument_list|(
name|user
argument_list|)
expr_stmt|;
name|requestBuilder
operator|.
name|setTransactionId
argument_list|(
name|txnId
argument_list|)
expr_stmt|;
name|LockComponentBuilder
name|lockCompBuilder
init|=
operator|new
name|LockComponentBuilder
argument_list|()
operator|.
name|setDbName
argument_list|(
name|connection
operator|.
name|database
argument_list|)
operator|.
name|setTableName
argument_list|(
name|connection
operator|.
name|table
argument_list|)
operator|.
name|setShared
argument_list|()
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|INSERT
argument_list|)
decl_stmt|;
if|if
condition|(
name|connection
operator|.
name|isDynamicPartitioning
argument_list|()
condition|)
block|{
name|lockCompBuilder
operator|.
name|setIsDynamicPartitionWrite
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|partNameForLock
operator|!=
literal|null
operator|&&
operator|!
name|partNameForLock
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|lockCompBuilder
operator|.
name|setPartitionName
argument_list|(
name|partNameForLock
argument_list|)
expr_stmt|;
block|}
name|requestBuilder
operator|.
name|addLockComponent
argument_list|(
name|lockCompBuilder
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|requestBuilder
operator|.
name|build
argument_list|()
return|;
block|}
block|}
specifier|private
name|HiveConf
name|createHiveConf
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
parameter_list|,
name|String
name|metaStoreUri
parameter_list|)
block|{
name|HiveConf
name|conf
init|=
operator|new
name|HiveConf
argument_list|(
name|clazz
argument_list|)
decl_stmt|;
if|if
condition|(
name|metaStoreUri
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|THRIFT_URIS
operator|.
name|getHiveName
argument_list|()
argument_list|,
name|metaStoreUri
argument_list|)
expr_stmt|;
block|}
return|return
name|conf
return|;
block|}
specifier|private
name|void
name|overrideConfSettings
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_TXN_MANAGER
argument_list|,
name|DbTxnManager
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SUPPORT_CONCURRENCY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|EXECUTE_SET_UGI
operator|.
name|getHiveName
argument_list|()
argument_list|)
expr_stmt|;
comment|// Avoids creating Tez Client sessions internally as it takes much longer currently
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|,
literal|"mr"
argument_list|)
expr_stmt|;
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONINGMODE
argument_list|,
literal|"nonstrict"
argument_list|)
expr_stmt|;
if|if
condition|(
name|streamingOptimizations
condition|)
block|{
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_ORC_DELTA_STREAMING_OPTIMIZATIONS_ENABLED
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// since same thread creates metastore client for streaming connection thread and heartbeat thread we explicitly
comment|// disable metastore client cache
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CLIENT_CACHE_ENABLED
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|setHiveConf
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|HiveConf
operator|.
name|ConfVars
name|var
parameter_list|,
name|String
name|value
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overriding HiveConf setting : "
operator|+
name|var
operator|+
literal|" = "
operator|+
name|value
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setVar
argument_list|(
name|var
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|setHiveConf
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|HiveConf
operator|.
name|ConfVars
name|var
parameter_list|,
name|boolean
name|value
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overriding HiveConf setting : "
operator|+
name|var
operator|+
literal|" = "
operator|+
name|value
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setBoolVar
argument_list|(
name|var
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|setHiveConf
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|String
name|var
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overriding HiveConf setting : "
operator|+
name|var
operator|+
literal|" = "
operator|+
literal|true
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setBoolean
argument_list|(
name|var
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|HiveConf
name|getHiveConf
parameter_list|()
block|{
return|return
name|conf
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getMetastoreUri
parameter_list|()
block|{
return|return
name|metastoreUri
return|;
block|}
annotation|@
name|Override
specifier|public
name|Table
name|getTable
parameter_list|()
block|{
return|return
name|tableObject
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getStaticPartitionValues
parameter_list|()
block|{
return|return
name|staticPartitionValues
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getAgentInfo
parameter_list|()
block|{
return|return
name|agentInfo
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isPartitionedTable
parameter_list|()
block|{
return|return
name|isPartitionedTable
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isDynamicPartitioning
parameter_list|()
block|{
return|return
name|isPartitionedTable
argument_list|()
operator|&&
operator|(
name|staticPartitionValues
operator|==
literal|null
operator|||
name|staticPartitionValues
operator|.
name|isEmpty
argument_list|()
operator|)
return|;
block|}
block|}
end_class

end_unit

