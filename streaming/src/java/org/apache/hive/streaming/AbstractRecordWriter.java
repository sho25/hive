begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|streaming
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|management
operator|.
name|ManagementFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|management
operator|.
name|MemoryMXBean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|management
operator|.
name|MemoryUsage
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Scanner
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|HeapMemoryMonitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|JavaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|LlapUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|RecordUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|AbstractSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructField
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|SubStructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_class
specifier|public
specifier|abstract
class|class
name|AbstractRecordWriter
implements|implements
name|RecordWriter
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AbstractRecordWriter
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DEFAULT_LINE_DELIMITER_PATTERN
init|=
literal|"[\r\n]"
decl_stmt|;
specifier|private
name|Integer
name|statementId
decl_stmt|;
specifier|protected
name|HiveConf
name|conf
decl_stmt|;
specifier|protected
name|StreamingConnection
name|conn
decl_stmt|;
specifier|protected
name|Table
name|table
decl_stmt|;
specifier|protected
name|List
argument_list|<
name|String
argument_list|>
name|inputColumns
decl_stmt|;
specifier|protected
name|List
argument_list|<
name|String
argument_list|>
name|inputTypes
decl_stmt|;
specifier|protected
name|String
name|fullyQualifiedTableName
decl_stmt|;
specifier|protected
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|RecordUpdater
argument_list|>
argument_list|>
name|updaters
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|protected
name|Map
argument_list|<
name|String
argument_list|,
name|Path
argument_list|>
name|partitionPaths
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|protected
name|Set
argument_list|<
name|String
argument_list|>
name|addedPartitions
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
comment|// input OI includes table columns + partition columns
specifier|protected
name|StructObjectInspector
name|inputRowObjectInspector
decl_stmt|;
comment|// output OI strips off the partition columns and retains other columns
specifier|protected
name|ObjectInspector
name|outputRowObjectInspector
decl_stmt|;
specifier|protected
name|List
argument_list|<
name|String
argument_list|>
name|partitionColumns
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|protected
name|ObjectInspector
index|[]
name|partitionObjInspectors
init|=
literal|null
decl_stmt|;
specifier|protected
name|StructField
index|[]
name|partitionStructFields
init|=
literal|null
decl_stmt|;
specifier|protected
name|Object
index|[]
name|partitionFieldData
decl_stmt|;
specifier|protected
name|ObjectInspector
index|[]
name|bucketObjInspectors
init|=
literal|null
decl_stmt|;
specifier|protected
name|StructField
index|[]
name|bucketStructFields
init|=
literal|null
decl_stmt|;
specifier|protected
name|Object
index|[]
name|bucketFieldData
decl_stmt|;
specifier|protected
name|List
argument_list|<
name|Integer
argument_list|>
name|bucketIds
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|protected
name|int
name|totalBuckets
decl_stmt|;
specifier|protected
name|String
name|defaultPartitionName
decl_stmt|;
specifier|protected
name|boolean
name|isBucketed
decl_stmt|;
specifier|protected
name|AcidOutputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|acidOutputFormat
decl_stmt|;
specifier|protected
name|Long
name|curBatchMinWriteId
decl_stmt|;
specifier|protected
name|Long
name|curBatchMaxWriteId
decl_stmt|;
specifier|protected
specifier|final
name|String
name|lineDelimiter
decl_stmt|;
specifier|protected
name|HeapMemoryMonitor
name|heapMemoryMonitor
decl_stmt|;
comment|// if low memory canary is set and if records after set canary exceeds threshold, trigger a flush.
comment|// This is to avoid getting notified of low memory too often and flushing too often.
specifier|protected
name|AtomicBoolean
name|lowMemoryCanary
decl_stmt|;
specifier|protected
name|long
name|ingestSizeBytes
init|=
literal|0
decl_stmt|;
specifier|protected
name|boolean
name|autoFlush
decl_stmt|;
specifier|protected
name|float
name|memoryUsageThreshold
decl_stmt|;
specifier|protected
name|long
name|ingestSizeThreshold
decl_stmt|;
specifier|protected
name|FileSystem
name|fs
decl_stmt|;
specifier|public
name|AbstractRecordWriter
parameter_list|(
specifier|final
name|String
name|lineDelimiter
parameter_list|)
block|{
name|this
operator|.
name|lineDelimiter
operator|=
name|lineDelimiter
operator|==
literal|null
operator|||
name|lineDelimiter
operator|.
name|isEmpty
argument_list|()
condition|?
name|DEFAULT_LINE_DELIMITER_PATTERN
else|:
name|lineDelimiter
expr_stmt|;
block|}
specifier|protected
specifier|static
class|class
name|OrcMemoryPressureMonitor
implements|implements
name|HeapMemoryMonitor
operator|.
name|Listener
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|OrcMemoryPressureMonitor
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|lowMemoryCanary
decl_stmt|;
name|OrcMemoryPressureMonitor
parameter_list|(
specifier|final
name|AtomicBoolean
name|lowMemoryCanary
parameter_list|)
block|{
name|this
operator|.
name|lowMemoryCanary
operator|=
name|lowMemoryCanary
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|memoryUsageAboveThreshold
parameter_list|(
specifier|final
name|long
name|usedMemory
parameter_list|,
specifier|final
name|long
name|maxMemory
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Orc memory pressure notified! usedMemory: {} maxMemory: {}."
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|usedMemory
argument_list|)
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|maxMemory
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|lowMemoryCanary
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|init
parameter_list|(
name|StreamingConnection
name|conn
parameter_list|,
name|long
name|minWriteId
parameter_list|,
name|long
name|maxWriteId
parameter_list|)
throws|throws
name|StreamingException
block|{
name|init
argument_list|(
name|conn
argument_list|,
name|minWriteId
argument_list|,
name|maxWriteId
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|init
parameter_list|(
name|StreamingConnection
name|conn
parameter_list|,
name|long
name|minWriteId
parameter_list|,
name|long
name|maxWriteId
parameter_list|,
name|int
name|statementId
parameter_list|)
throws|throws
name|StreamingException
block|{
if|if
condition|(
name|conn
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Streaming connection cannot be null during record writer initialization"
argument_list|)
throw|;
block|}
name|this
operator|.
name|conn
operator|=
name|conn
expr_stmt|;
name|this
operator|.
name|curBatchMinWriteId
operator|=
name|minWriteId
expr_stmt|;
name|this
operator|.
name|curBatchMaxWriteId
operator|=
name|maxWriteId
expr_stmt|;
name|this
operator|.
name|statementId
operator|=
name|statementId
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conn
operator|.
name|getHiveConf
argument_list|()
expr_stmt|;
name|this
operator|.
name|defaultPartitionName
operator|=
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DEFAULTPARTITIONNAME
argument_list|)
expr_stmt|;
name|this
operator|.
name|table
operator|=
name|conn
operator|.
name|getTable
argument_list|()
expr_stmt|;
name|String
name|location
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
decl_stmt|;
try|try
block|{
name|URI
name|uri
init|=
operator|new
name|URI
argument_list|(
name|location
argument_list|)
decl_stmt|;
name|this
operator|.
name|fs
operator|=
name|FileSystem
operator|.
name|newInstance
argument_list|(
name|uri
argument_list|,
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Created new filesystem instance: {}"
argument_list|,
name|System
operator|.
name|identityHashCode
argument_list|(
name|this
operator|.
name|fs
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Unable to create URI from location: "
operator|+
name|location
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Unable to get filesystem for location: "
operator|+
name|location
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|this
operator|.
name|inputColumns
operator|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|FieldSchema
operator|::
name|getName
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputTypes
operator|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|FieldSchema
operator|::
name|getType
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|conn
operator|.
name|isPartitionedTable
argument_list|()
operator|&&
name|conn
operator|.
name|isDynamicPartitioning
argument_list|()
condition|)
block|{
name|this
operator|.
name|partitionColumns
operator|=
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|FieldSchema
operator|::
name|getName
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputColumns
operator|.
name|addAll
argument_list|(
name|partitionColumns
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputTypes
operator|.
name|addAll
argument_list|(
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|FieldSchema
operator|::
name|getType
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|fullyQualifiedTableName
operator|=
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|outFormatName
init|=
name|this
operator|.
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
try|try
block|{
name|this
operator|.
name|acidOutputFormat
operator|=
operator|(
name|AcidOutputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
operator|)
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|JavaUtils
operator|.
name|loadClass
argument_list|(
name|outFormatName
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|shadePrefix
init|=
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_CLASSLOADER_SHADE_PREFIX
argument_list|)
decl_stmt|;
if|if
condition|(
name|shadePrefix
operator|!=
literal|null
operator|&&
operator|!
name|shadePrefix
operator|.
name|trim
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Shade prefix: {} specified. Using as fallback to load {}.."
argument_list|,
name|shadePrefix
argument_list|,
name|outFormatName
argument_list|)
expr_stmt|;
name|this
operator|.
name|acidOutputFormat
operator|=
operator|(
name|AcidOutputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
operator|)
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|JavaUtils
operator|.
name|loadClass
argument_list|(
name|shadePrefix
argument_list|,
name|outFormatName
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e1
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|setupMemoryMonitoring
argument_list|()
expr_stmt|;
try|try
block|{
specifier|final
name|AbstractSerDe
name|serDe
init|=
name|createSerde
argument_list|()
decl_stmt|;
name|this
operator|.
name|inputRowObjectInspector
operator|=
operator|(
name|StructObjectInspector
operator|)
name|serDe
operator|.
name|getObjectInspector
argument_list|()
expr_stmt|;
if|if
condition|(
name|conn
operator|.
name|isPartitionedTable
argument_list|()
operator|&&
name|conn
operator|.
name|isDynamicPartitioning
argument_list|()
condition|)
block|{
name|preparePartitioningFields
argument_list|()
expr_stmt|;
name|int
name|dpStartCol
init|=
name|inputRowObjectInspector
operator|.
name|getAllStructFieldRefs
argument_list|()
operator|.
name|size
argument_list|()
operator|-
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|this
operator|.
name|outputRowObjectInspector
operator|=
operator|new
name|SubStructObjectInspector
argument_list|(
name|inputRowObjectInspector
argument_list|,
literal|0
argument_list|,
name|dpStartCol
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|outputRowObjectInspector
operator|=
name|inputRowObjectInspector
expr_stmt|;
block|}
name|prepareBucketingFields
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Unable to create SerDe"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|protected
name|void
name|setupMemoryMonitoring
parameter_list|()
block|{
name|this
operator|.
name|autoFlush
operator|=
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_STREAMING_AUTO_FLUSH_ENABLED
argument_list|)
expr_stmt|;
name|this
operator|.
name|memoryUsageThreshold
operator|=
name|conf
operator|.
name|getFloatVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_HEAP_MEMORY_MONITOR_USAGE_THRESHOLD
argument_list|)
expr_stmt|;
name|this
operator|.
name|ingestSizeThreshold
operator|=
name|conf
operator|.
name|getSizeVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_STREAMING_AUTO_FLUSH_CHECK_INTERVAL_SIZE
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Memory monitoring settings - autoFlush: {} memoryUsageThreshold: {} ingestSizeThreshold: {}"
argument_list|,
name|autoFlush
argument_list|,
name|memoryUsageThreshold
argument_list|,
name|ingestSizeBytes
argument_list|)
expr_stmt|;
name|this
operator|.
name|heapMemoryMonitor
operator|=
operator|new
name|HeapMemoryMonitor
argument_list|(
name|memoryUsageThreshold
argument_list|)
expr_stmt|;
name|MemoryUsage
name|tenuredMemUsage
init|=
name|heapMemoryMonitor
operator|.
name|getTenuredGenMemoryUsage
argument_list|()
decl_stmt|;
if|if
condition|(
name|tenuredMemUsage
operator|!=
literal|null
condition|)
block|{
name|lowMemoryCanary
operator|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|heapMemoryMonitor
operator|.
name|registerListener
argument_list|(
operator|new
name|OrcMemoryPressureMonitor
argument_list|(
name|lowMemoryCanary
argument_list|)
argument_list|)
expr_stmt|;
name|heapMemoryMonitor
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// alert if we already running low on memory (starting with low memory will lead to frequent auto flush)
name|float
name|currentUsage
init|=
operator|(
name|float
operator|)
name|tenuredMemUsage
operator|.
name|getUsed
argument_list|()
operator|/
operator|(
name|float
operator|)
name|tenuredMemUsage
operator|.
name|getMax
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentUsage
operator|>
name|memoryUsageThreshold
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"LOW MEMORY ALERT! Tenured gen memory is already low. Increase memory to improve performance."
operator|+
literal|" Used: {} Max: {}"
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|tenuredMemUsage
operator|.
name|getUsed
argument_list|()
argument_list|)
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|tenuredMemUsage
operator|.
name|getMax
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|protected
name|void
name|prepareBucketingFields
parameter_list|()
block|{
name|this
operator|.
name|isBucketed
operator|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
operator|>
literal|0
expr_stmt|;
comment|// For unbucketed tables we have exactly 1 RecordUpdater (until HIVE-19208) for each AbstractRecordWriter which
comment|// ends up writing to a file bucket_000000.
comment|// See also {@link #getBucket(Object)}
name|this
operator|.
name|totalBuckets
operator|=
name|isBucketed
condition|?
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
else|:
literal|1
expr_stmt|;
if|if
condition|(
name|isBucketed
condition|)
block|{
name|this
operator|.
name|bucketIds
operator|=
name|getBucketColIDs
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getBucketCols
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|bucketFieldData
operator|=
operator|new
name|Object
index|[
name|bucketIds
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|this
operator|.
name|bucketObjInspectors
operator|=
name|getObjectInspectorsForBucketedCols
argument_list|(
name|bucketIds
argument_list|,
name|inputRowObjectInspector
argument_list|)
expr_stmt|;
name|this
operator|.
name|bucketStructFields
operator|=
operator|new
name|StructField
index|[
name|bucketIds
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|List
argument_list|<
name|?
extends|extends
name|StructField
argument_list|>
name|allFields
init|=
name|inputRowObjectInspector
operator|.
name|getAllStructFieldRefs
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bucketIds
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|bucketStructFields
index|[
name|i
index|]
operator|=
name|allFields
operator|.
name|get
argument_list|(
name|bucketIds
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|protected
name|void
name|preparePartitioningFields
parameter_list|()
block|{
specifier|final
name|int
name|numPartitions
init|=
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|this
operator|.
name|partitionFieldData
operator|=
operator|new
name|Object
index|[
name|numPartitions
index|]
expr_stmt|;
name|this
operator|.
name|partitionObjInspectors
operator|=
operator|new
name|ObjectInspector
index|[
name|numPartitions
index|]
expr_stmt|;
name|int
name|startIdx
init|=
name|inputRowObjectInspector
operator|.
name|getAllStructFieldRefs
argument_list|()
operator|.
name|size
argument_list|()
operator|-
name|numPartitions
decl_stmt|;
name|int
name|endIdx
init|=
name|inputRowObjectInspector
operator|.
name|getAllStructFieldRefs
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|j
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|startIdx
init|;
name|i
operator|<
name|endIdx
condition|;
name|i
operator|++
control|)
block|{
name|StructField
name|structField
init|=
name|inputRowObjectInspector
operator|.
name|getAllStructFieldRefs
argument_list|()
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|partitionObjInspectors
index|[
name|j
operator|++
index|]
operator|=
name|structField
operator|.
name|getFieldObjectInspector
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|partitionStructFields
operator|=
operator|new
name|StructField
index|[
name|partitionColumns
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partitionColumns
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|partCol
init|=
name|partitionColumns
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|partitionStructFields
index|[
name|i
index|]
operator|=
name|inputRowObjectInspector
operator|.
name|getStructFieldRef
argument_list|(
name|partCol
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * used to tag error msgs to provided some breadcrumbs    */
specifier|protected
name|String
name|getWatermark
parameter_list|(
name|String
name|partition
parameter_list|)
block|{
return|return
name|partition
operator|+
literal|" writeIds["
operator|+
name|curBatchMinWriteId
operator|+
literal|","
operator|+
name|curBatchMaxWriteId
operator|+
literal|"]"
return|;
block|}
comment|// return the column numbers of the bucketed columns
specifier|protected
name|List
argument_list|<
name|Integer
argument_list|>
name|getBucketColIDs
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
name|ArrayList
argument_list|<
name|Integer
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|bucketCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|HashSet
argument_list|<
name|String
argument_list|>
name|bucketSet
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|bucketCols
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|cols
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|bucketSet
operator|.
name|contains
argument_list|(
name|cols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Create SerDe for the record writer.    *    * @return - serde    * @throws SerializationError - if serde cannot be created.    */
specifier|public
specifier|abstract
name|AbstractSerDe
name|createSerde
parameter_list|()
throws|throws
name|SerializationError
function_decl|;
comment|/**    * Encode a record as an Object that Hive can read with the ObjectInspector associated with the    * serde returned by {@link #createSerde}.  This is public so that test frameworks can use it.    *    * @param record record to be deserialized    * @return deserialized record as an Object    * @throws SerializationError - any error during serialization or deserialization of record    */
specifier|public
specifier|abstract
name|Object
name|encode
parameter_list|(
name|byte
index|[]
name|record
parameter_list|)
throws|throws
name|SerializationError
function_decl|;
comment|// returns the bucket number to which the record belongs to
specifier|protected
name|int
name|getBucket
parameter_list|(
name|Object
name|row
parameter_list|)
block|{
if|if
condition|(
operator|!
name|isBucketed
condition|)
block|{
return|return
literal|0
return|;
block|}
name|Object
index|[]
name|bucketFields
init|=
name|getBucketFields
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|int
name|bucketingVersion
init|=
name|Utilities
operator|.
name|getBucketingVersion
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_BUCKETING_VERSION
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|bucketingVersion
operator|==
literal|2
condition|?
name|ObjectInspectorUtils
operator|.
name|getBucketNumber
argument_list|(
name|bucketFields
argument_list|,
name|bucketObjInspectors
argument_list|,
name|totalBuckets
argument_list|)
else|:
name|ObjectInspectorUtils
operator|.
name|getBucketNumberOld
argument_list|(
name|bucketFields
argument_list|,
name|bucketObjInspectors
argument_list|,
name|totalBuckets
argument_list|)
return|;
block|}
specifier|protected
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionValues
parameter_list|(
specifier|final
name|Object
name|row
parameter_list|)
block|{
if|if
condition|(
operator|!
name|conn
operator|.
name|isPartitionedTable
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|partitionValues
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|conn
operator|.
name|isPartitionedTable
argument_list|()
operator|&&
name|conn
operator|.
name|isDynamicPartitioning
argument_list|()
condition|)
block|{
name|Object
index|[]
name|partitionFields
init|=
name|getPartitionFields
argument_list|(
name|row
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partitionObjInspectors
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|ObjectInspector
name|oi
init|=
name|partitionObjInspectors
index|[
name|i
index|]
decl_stmt|;
name|Object
name|field
init|=
name|partitionFields
index|[
name|i
index|]
decl_stmt|;
name|Object
name|partitionValue
init|=
name|ObjectInspectorUtils
operator|.
name|copyToStandardObject
argument_list|(
name|field
argument_list|,
name|oi
argument_list|,
name|ObjectInspectorUtils
operator|.
name|ObjectInspectorCopyOption
operator|.
name|WRITABLE
argument_list|)
decl_stmt|;
if|if
condition|(
name|partitionValue
operator|==
literal|null
operator|||
name|partitionValue
operator|.
name|toString
argument_list|()
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|partitionValues
operator|.
name|add
argument_list|(
name|defaultPartitionName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partitionValues
operator|.
name|add
argument_list|(
name|partitionValue
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|partitionValues
operator|=
name|conn
operator|.
name|getStaticPartitionValues
argument_list|()
expr_stmt|;
block|}
return|return
name|partitionValues
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|flush
parameter_list|()
throws|throws
name|StreamingIOFailure
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logStats
argument_list|(
literal|"Stats before flush:"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|RecordUpdater
argument_list|>
argument_list|>
name|entry
range|:
name|updaters
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flushing record updater for partitions: {}"
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|RecordUpdater
name|updater
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
if|if
condition|(
name|updater
operator|!=
literal|null
condition|)
block|{
name|updater
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|ingestSizeBytes
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logStats
argument_list|(
literal|"Stats after flush:"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingIOFailure
argument_list|(
literal|"Unable to flush recordUpdater"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|StreamingIOFailure
block|{
name|heapMemoryMonitor
operator|.
name|close
argument_list|()
expr_stmt|;
name|boolean
name|haveError
init|=
literal|false
decl_stmt|;
name|String
name|partition
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logStats
argument_list|(
literal|"Stats before close:"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|RecordUpdater
argument_list|>
argument_list|>
name|entry
range|:
name|updaters
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|partition
operator|=
name|entry
operator|.
name|getKey
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing updater for partitions: {}"
argument_list|,
name|partition
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|RecordUpdater
name|updater
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
if|if
condition|(
name|updater
operator|!=
literal|null
condition|)
block|{
try|try
block|{
comment|//try not to leave any files open
name|updater
operator|.
name|close
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|haveError
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to close "
operator|+
name|updater
operator|+
literal|" due to: "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|updaters
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logStats
argument_list|(
literal|"Stats after close:"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|haveError
condition|)
block|{
throw|throw
operator|new
name|StreamingIOFailure
argument_list|(
literal|"Encountered errors while closing (see logs) "
operator|+
name|getWatermark
argument_list|(
name|partition
argument_list|)
argument_list|)
throw|;
block|}
block|}
specifier|protected
specifier|static
name|ObjectInspector
index|[]
name|getObjectInspectorsForBucketedCols
parameter_list|(
name|List
argument_list|<
name|Integer
argument_list|>
name|bucketIds
parameter_list|,
name|StructObjectInspector
name|recordObjInspector
parameter_list|)
block|{
name|ObjectInspector
index|[]
name|result
init|=
operator|new
name|ObjectInspector
index|[
name|bucketIds
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bucketIds
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|int
name|bucketId
init|=
name|bucketIds
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|result
index|[
name|i
index|]
operator|=
name|recordObjInspector
operator|.
name|getAllStructFieldRefs
argument_list|()
operator|.
name|get
argument_list|(
name|bucketId
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
specifier|protected
name|Object
index|[]
name|getBucketFields
parameter_list|(
name|Object
name|row
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bucketIds
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|bucketFieldData
index|[
name|i
index|]
operator|=
name|inputRowObjectInspector
operator|.
name|getStructFieldData
argument_list|(
name|row
argument_list|,
name|bucketStructFields
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|bucketFieldData
return|;
block|}
specifier|protected
name|Object
index|[]
name|getPartitionFields
parameter_list|(
name|Object
name|row
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partitionFieldData
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|partitionFieldData
index|[
name|i
index|]
operator|=
name|inputRowObjectInspector
operator|.
name|getStructFieldData
argument_list|(
name|row
argument_list|,
name|partitionStructFields
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|partitionFieldData
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|long
name|writeId
parameter_list|,
specifier|final
name|InputStream
name|inputStream
parameter_list|)
throws|throws
name|StreamingException
block|{
try|try
init|(
name|Scanner
name|scanner
init|=
operator|new
name|Scanner
argument_list|(
name|inputStream
argument_list|)
operator|.
name|useDelimiter
argument_list|(
name|lineDelimiter
argument_list|)
init|)
block|{
while|while
condition|(
name|scanner
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|write
argument_list|(
name|writeId
argument_list|,
name|scanner
operator|.
name|next
argument_list|()
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|long
name|writeId
parameter_list|,
specifier|final
name|byte
index|[]
name|record
parameter_list|)
throws|throws
name|StreamingException
block|{
name|checkAutoFlush
argument_list|()
expr_stmt|;
name|ingestSizeBytes
operator|+=
name|record
operator|.
name|length
expr_stmt|;
try|try
block|{
name|Object
name|encodedRow
init|=
name|encode
argument_list|(
name|record
argument_list|)
decl_stmt|;
name|int
name|bucket
init|=
name|getBucket
argument_list|(
name|encodedRow
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|partitionValues
init|=
name|getPartitionValues
argument_list|(
name|encodedRow
argument_list|)
decl_stmt|;
name|getRecordUpdater
argument_list|(
name|partitionValues
argument_list|,
name|bucket
argument_list|)
operator|.
name|insert
argument_list|(
name|writeId
argument_list|,
name|encodedRow
argument_list|)
expr_stmt|;
comment|// ingest size bytes gets resetted on flush() whereas connection stats is not
name|conn
operator|.
name|getConnectionStats
argument_list|()
operator|.
name|incrementRecordsWritten
argument_list|()
expr_stmt|;
name|conn
operator|.
name|getConnectionStats
argument_list|()
operator|.
name|incrementRecordsSize
argument_list|(
name|record
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingIOFailure
argument_list|(
literal|"Error writing record in transaction write id ("
operator|+
name|writeId
operator|+
literal|")"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|protected
name|void
name|checkAutoFlush
parameter_list|()
throws|throws
name|StreamingIOFailure
block|{
if|if
condition|(
operator|!
name|autoFlush
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|lowMemoryCanary
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|lowMemoryCanary
operator|.
name|get
argument_list|()
operator|&&
name|ingestSizeBytes
operator|>
name|ingestSizeThreshold
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Low memory canary is set and ingestion size (buffered) threshold '{}' exceeded. "
operator|+
literal|"Flushing all record updaters.."
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|ingestSizeThreshold
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|flush
argument_list|()
expr_stmt|;
name|conn
operator|.
name|getConnectionStats
argument_list|()
operator|.
name|incrementAutoFlushCount
argument_list|()
expr_stmt|;
name|lowMemoryCanary
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|ingestSizeBytes
operator|>
name|ingestSizeThreshold
condition|)
block|{
name|MemoryMXBean
name|mxBean
init|=
name|ManagementFactory
operator|.
name|getMemoryMXBean
argument_list|()
decl_stmt|;
name|MemoryUsage
name|heapUsage
init|=
name|mxBean
operator|.
name|getHeapMemoryUsage
argument_list|()
decl_stmt|;
name|float
name|memUsedFraction
init|=
operator|(
operator|(
name|float
operator|)
name|heapUsage
operator|.
name|getUsed
argument_list|()
operator|/
operator|(
name|float
operator|)
name|heapUsage
operator|.
name|getMax
argument_list|()
operator|)
decl_stmt|;
if|if
condition|(
name|memUsedFraction
operator|>
name|memoryUsageThreshold
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Memory usage threshold '{}' and ingestion size (buffered) threshold '{}' exceeded. "
operator|+
literal|"Flushing all record updaters.."
argument_list|,
name|memUsedFraction
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|ingestSizeThreshold
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|flush
argument_list|()
expr_stmt|;
name|conn
operator|.
name|getConnectionStats
argument_list|()
operator|.
name|incrementAutoFlushCount
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|String
argument_list|>
name|getPartitions
parameter_list|()
block|{
return|return
name|addedPartitions
return|;
block|}
specifier|protected
name|RecordUpdater
name|createRecordUpdater
parameter_list|(
specifier|final
name|Path
name|partitionPath
parameter_list|,
name|int
name|bucketId
parameter_list|,
name|Long
name|minWriteId
parameter_list|,
name|Long
name|maxWriteID
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Initialize table properties from the table parameters. This is required because the table
comment|// may define certain table parameters that may be required while writing. The table parameter
comment|// 'transactional_properties' is one such example.
name|Properties
name|tblProperties
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|tblProperties
operator|.
name|putAll
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|acidOutputFormat
operator|.
name|getRecordUpdater
argument_list|(
name|partitionPath
argument_list|,
operator|new
name|AcidOutputFormat
operator|.
name|Options
argument_list|(
name|conf
argument_list|)
operator|.
name|filesystem
argument_list|(
name|fs
argument_list|)
operator|.
name|inspector
argument_list|(
name|outputRowObjectInspector
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucketId
argument_list|)
operator|.
name|tableProperties
argument_list|(
name|tblProperties
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
name|minWriteId
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
name|maxWriteID
argument_list|)
operator|.
name|statementId
argument_list|(
name|statementId
argument_list|)
operator|.
name|finalDestination
argument_list|(
name|partitionPath
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns the file that would be used to store rows under this.    * parameters    * @param partitionValues partition values    * @param bucketId bucket id    * @param minWriteId min write Id    * @param maxWriteId max write Id    * @param statementId statement Id    * @param table table    * @return the location of the file.    * @throws StreamingException when the path is not found    */
annotation|@
name|Override
specifier|public
name|Path
name|getDeltaFileLocation
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partitionValues
parameter_list|,
name|Integer
name|bucketId
parameter_list|,
name|Long
name|minWriteId
parameter_list|,
name|Long
name|maxWriteId
parameter_list|,
name|Integer
name|statementId
parameter_list|,
name|Table
name|table
parameter_list|)
throws|throws
name|StreamingException
block|{
name|Path
name|destLocation
decl_stmt|;
if|if
condition|(
name|partitionValues
operator|==
literal|null
condition|)
block|{
name|destLocation
operator|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|Warehouse
operator|.
name|makeSpecFromValues
argument_list|(
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|,
name|partitionValues
argument_list|)
decl_stmt|;
try|try
block|{
name|destLocation
operator|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getDataLocation
argument_list|()
argument_list|,
name|Warehouse
operator|.
name|makePartPath
argument_list|(
name|partSpec
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Unable to retrieve the delta file location"
operator|+
literal|" for values: "
operator|+
name|partitionValues
operator|+
literal|", minWriteId: "
operator|+
name|minWriteId
operator|+
literal|", maxWriteId: "
operator|+
name|maxWriteId
operator|+
literal|", statementId: "
operator|+
name|statementId
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|AcidOutputFormat
operator|.
name|Options
name|options
init|=
operator|new
name|AcidOutputFormat
operator|.
name|Options
argument_list|(
name|conf
argument_list|)
operator|.
name|filesystem
argument_list|(
name|fs
argument_list|)
operator|.
name|inspector
argument_list|(
name|outputRowObjectInspector
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucketId
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
name|minWriteId
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
name|maxWriteId
argument_list|)
operator|.
name|statementId
argument_list|(
name|statementId
argument_list|)
operator|.
name|finalDestination
argument_list|(
name|destLocation
argument_list|)
decl_stmt|;
return|return
name|AcidUtils
operator|.
name|createFilename
argument_list|(
name|destLocation
argument_list|,
name|options
argument_list|)
return|;
block|}
specifier|protected
name|RecordUpdater
name|getRecordUpdater
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partitionValues
parameter_list|,
name|int
name|bucketId
parameter_list|)
throws|throws
name|StreamingIOFailure
block|{
name|RecordUpdater
name|recordUpdater
decl_stmt|;
name|String
name|key
decl_stmt|;
name|Path
name|destLocation
decl_stmt|;
try|try
block|{
name|key
operator|=
name|partitionValues
operator|==
literal|null
condition|?
name|fullyQualifiedTableName
else|:
name|partitionValues
operator|.
name|toString
argument_list|()
expr_stmt|;
comment|// add partition in metastore for dynamic partition. We make a metastore call for every new partition value that
comment|// we encounter even if partition already exists (exists check require a metastore call anyways).
if|if
condition|(
name|partitionPaths
operator|.
name|containsKey
argument_list|(
name|key
argument_list|)
condition|)
block|{
name|destLocation
operator|=
name|partitionPaths
operator|.
name|get
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// un-partitioned table
if|if
condition|(
name|partitionValues
operator|==
literal|null
condition|)
block|{
name|destLocation
operator|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|PartitionInfo
name|partitionInfo
init|=
name|conn
operator|.
name|createPartitionIfNotExists
argument_list|(
name|partitionValues
argument_list|)
decl_stmt|;
comment|// collect the newly added partitions. connection.commitTransaction() will report the dynamically added
comment|// partitions to TxnHandler
if|if
condition|(
operator|!
name|partitionInfo
operator|.
name|isExists
argument_list|()
condition|)
block|{
name|addedPartitions
operator|.
name|add
argument_list|(
name|partitionInfo
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Partition {} already exists for table {}"
argument_list|,
name|partitionInfo
operator|.
name|getName
argument_list|()
argument_list|,
name|fullyQualifiedTableName
argument_list|)
expr_stmt|;
block|}
block|}
name|destLocation
operator|=
operator|new
name|Path
argument_list|(
name|partitionInfo
operator|.
name|getPartitionLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|partitionPaths
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|destLocation
argument_list|)
expr_stmt|;
block|}
name|updaters
operator|.
name|computeIfAbsent
argument_list|(
name|key
argument_list|,
name|k
lambda|->
name|initializeBuckets
argument_list|()
argument_list|)
expr_stmt|;
name|recordUpdater
operator|=
name|updaters
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|.
name|get
argument_list|(
name|bucketId
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StreamingException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingIOFailure
argument_list|(
literal|"Unable to create partition: "
operator|+
name|partitionValues
operator|+
literal|"for "
operator|+
name|conn
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|recordUpdater
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|recordUpdater
operator|=
name|createRecordUpdater
argument_list|(
name|destLocation
argument_list|,
name|bucketId
argument_list|,
name|curBatchMinWriteId
argument_list|,
name|curBatchMaxWriteId
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|errMsg
init|=
literal|"Failed creating RecordUpdater for "
operator|+
name|getWatermark
argument_list|(
name|destLocation
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|errMsg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|StreamingIOFailure
argument_list|(
name|errMsg
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|RecordUpdater
argument_list|>
name|partitionUpdaters
init|=
name|updaters
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|partitionUpdaters
operator|.
name|set
argument_list|(
name|bucketId
argument_list|,
name|recordUpdater
argument_list|)
expr_stmt|;
block|}
return|return
name|recordUpdater
return|;
block|}
specifier|protected
name|List
argument_list|<
name|RecordUpdater
argument_list|>
name|initializeBuckets
parameter_list|()
block|{
name|List
argument_list|<
name|RecordUpdater
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|totalBuckets
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|bucket
init|=
literal|0
init|;
name|bucket
operator|<
name|totalBuckets
condition|;
name|bucket
operator|++
control|)
block|{
name|result
operator|.
name|add
argument_list|(
name|bucket
argument_list|,
literal|null
argument_list|)
expr_stmt|;
comment|//so that get(i) returns null rather than ArrayOutOfBounds
block|}
return|return
name|result
return|;
block|}
specifier|protected
name|void
name|logStats
parameter_list|(
specifier|final
name|String
name|prefix
parameter_list|)
block|{
name|int
name|openRecordUpdaters
init|=
name|updaters
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|mapToInt
argument_list|(
name|List
operator|::
name|size
argument_list|)
operator|.
name|sum
argument_list|()
decl_stmt|;
name|long
name|bufferedRecords
init|=
name|updaters
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|flatMap
argument_list|(
name|List
operator|::
name|stream
argument_list|)
operator|.
name|filter
argument_list|(
name|Objects
operator|::
name|nonNull
argument_list|)
operator|.
name|mapToLong
argument_list|(
name|RecordUpdater
operator|::
name|getBufferedRowCount
argument_list|)
operator|.
name|sum
argument_list|()
decl_stmt|;
name|MemoryUsage
name|memoryUsage
init|=
name|heapMemoryMonitor
operator|.
name|getTenuredGenMemoryUsage
argument_list|()
decl_stmt|;
name|String
name|oldGenUsage
init|=
literal|"NA"
decl_stmt|;
if|if
condition|(
name|memoryUsage
operator|!=
literal|null
condition|)
block|{
name|oldGenUsage
operator|=
literal|"used/max => "
operator|+
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|memoryUsage
operator|.
name|getUsed
argument_list|()
argument_list|)
operator|+
literal|"/"
operator|+
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|memoryUsage
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} [record-updaters: {}, partitions: {}, buffered-records: {} total-records: {} "
operator|+
literal|"buffered-ingest-size: {}, total-ingest-size: {} tenured-memory-usage: {}]"
argument_list|,
name|prefix
argument_list|,
name|openRecordUpdaters
argument_list|,
name|partitionPaths
operator|.
name|size
argument_list|()
argument_list|,
name|bufferedRecords
argument_list|,
name|conn
operator|.
name|getConnectionStats
argument_list|()
operator|.
name|getRecordsWritten
argument_list|()
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|ingestSizeBytes
argument_list|)
argument_list|,
name|LlapUtil
operator|.
name|humanReadableByteCount
argument_list|(
name|conn
operator|.
name|getConnectionStats
argument_list|()
operator|.
name|getRecordsSize
argument_list|()
argument_list|)
argument_list|,
name|oldGenUsage
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

