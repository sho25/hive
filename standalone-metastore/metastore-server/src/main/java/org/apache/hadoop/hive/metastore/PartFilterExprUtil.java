begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
package|;
end_package

begin_import
import|import
name|org
operator|.
name|antlr
operator|.
name|runtime
operator|.
name|CommonTokenStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|antlr
operator|.
name|runtime
operator|.
name|RecognitionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|JavaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|FilterLexer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|FilterParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|ANTLRNoCaseStringStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|LeafNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|Operator
import|;
end_import

begin_comment
comment|/**  * Utility functions for working with partition filter expressions  */
end_comment

begin_class
specifier|public
class|class
name|PartFilterExprUtil
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|PartFilterExprUtil
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|public
specifier|static
name|ExpressionTree
name|makeExpressionTree
parameter_list|(
name|PartitionExpressionProxy
name|expressionProxy
parameter_list|,
name|byte
index|[]
name|expr
parameter_list|,
name|String
name|defaultPartitionName
parameter_list|)
throws|throws
name|MetaException
block|{
comment|// We will try pushdown first, so make the filter. This will also validate the expression,
comment|// if serialization fails we will throw incompatible metastore error to the client.
name|String
name|filter
init|=
literal|null
decl_stmt|;
try|try
block|{
name|filter
operator|=
name|expressionProxy
operator|.
name|convertExprToFilter
argument_list|(
name|expr
argument_list|,
name|defaultPartitionName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|ex
parameter_list|)
block|{
comment|// TODO MS-SPLIT - for now we have construct this by reflection because IMetaStoreClient
comment|// can't be
comment|// moved until after HiveMetaStore is moved, which can't be moved until this is moved.
name|Class
argument_list|<
name|?
extends|extends
name|MetaException
argument_list|>
name|exClass
init|=
name|JavaUtils
operator|.
name|getClass
argument_list|(
literal|"org.apache.hadoop.hive.metastore.IMetaStoreClient$IncompatibleMetastoreException"
argument_list|,
name|MetaException
operator|.
name|class
argument_list|)
decl_stmt|;
throw|throw
name|JavaUtils
operator|.
name|newInstance
argument_list|(
name|exClass
argument_list|,
operator|new
name|Class
argument_list|<
name|?
argument_list|>
index|[]
block|{
name|String
operator|.
name|class
block|}
operator|,
operator|new
name|Object
index|[]
block|{
name|ex
operator|.
name|getMessage
argument_list|()
block|}
block|)
empty_stmt|;
block|}
comment|// Make a tree out of the filter.
comment|// TODO: this is all pretty ugly. The only reason we need all these transformations
comment|//       is to maintain support for simple filters for HCat users that query metastore.
comment|//       If forcing everyone to use thick client is out of the question, maybe we could
comment|//       parse the filter into standard hive expressions and not all this separate tree
comment|//       Filter.g stuff. That way this method and ...ByFilter would just be merged.
return|return
name|PartFilterExprUtil
operator|.
name|makeExpressionTree
argument_list|(
name|filter
argument_list|)
return|;
block|}
end_class

begin_comment
comment|/**    * Creates the proxy used to evaluate expressions. This is here to prevent circular    * dependency - ql -&gt; metastore client&lt;-&gt; metastore server -&gt; ql. If server and    * client are split, this can be removed.    * @param conf Configuration.    * @return The partition expression proxy.    */
end_comment

begin_function
specifier|public
specifier|static
name|PartitionExpressionProxy
name|createExpressionProxy
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|className
init|=
name|MetastoreConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|EXPRESSION_PROXY_CLASS
argument_list|)
decl_stmt|;
try|try
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|Class
argument_list|<
name|?
extends|extends
name|PartitionExpressionProxy
argument_list|>
name|clazz
init|=
name|JavaUtils
operator|.
name|getClass
argument_list|(
name|className
argument_list|,
name|PartitionExpressionProxy
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
name|JavaUtils
operator|.
name|newInstance
argument_list|(
name|clazz
argument_list|,
operator|new
name|Class
argument_list|<
name|?
argument_list|>
index|[
literal|0
index|]
operator|,
operator|new
name|Object
index|[
literal|0
index|]
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getMessage
argument_list|()
operator|.
name|matches
argument_list|(
literal|".* class not found"
argument_list|)
condition|)
block|{
comment|// TODO MS-SPLIT For now if we cannot load the default PartitionExpressionForMetastore
comment|// class (since it's from ql) load the DefaultPartitionExpressionProxy, which just throws
comment|// UnsupportedOperationExceptions.  This allows existing Hive instances to work but also
comment|// allows us to instantiate the metastore stand alone for testing.  Not sure if this is
comment|// the best long term solution.
return|return
operator|new
name|DefaultPartitionExpressionProxy
argument_list|()
return|;
block|}
name|LOG
operator|.
name|error
argument_list|(
literal|"Error loading PartitionExpressionProxy"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Error loading PartitionExpressionProxy: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
end_function

begin_comment
comment|/**    * Makes expression tree out of expr.    * @param filter Filter.    * @return Expression tree. Null if there was an error.    */
end_comment

begin_function
specifier|private
specifier|static
name|ExpressionTree
name|makeExpressionTree
parameter_list|(
name|String
name|filter
parameter_list|)
throws|throws
name|MetaException
block|{
comment|// TODO: ExprNodeDesc is an expression tree, we could just use that and be rid of Filter.g.
if|if
condition|(
name|filter
operator|==
literal|null
operator|||
name|filter
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|ExpressionTree
operator|.
name|EMPTY_TREE
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Filter specified is "
operator|+
name|filter
argument_list|)
expr_stmt|;
name|ExpressionTree
name|tree
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tree
operator|=
name|getFilterParser
argument_list|(
name|filter
argument_list|)
operator|.
name|tree
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unable to make the expression tree from expression string ["
operator|+
name|filter
operator|+
literal|"]"
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
comment|// Don't log the stack, this is normal.
block|}
if|if
condition|(
name|tree
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// We suspect that LIKE pushdown into JDO is invalid; see HIVE-5134. Check for like here.
name|LikeChecker
name|lc
init|=
operator|new
name|LikeChecker
argument_list|()
decl_stmt|;
name|tree
operator|.
name|accept
argument_list|(
name|lc
argument_list|)
expr_stmt|;
return|return
name|lc
operator|.
name|hasLike
argument_list|()
condition|?
literal|null
else|:
name|tree
return|;
block|}
end_function

begin_class
specifier|private
specifier|static
class|class
name|LikeChecker
extends|extends
name|ExpressionTree
operator|.
name|TreeVisitor
block|{
specifier|private
name|boolean
name|hasLike
decl_stmt|;
specifier|public
name|boolean
name|hasLike
parameter_list|()
block|{
return|return
name|hasLike
return|;
block|}
annotation|@
name|Override
specifier|protected
name|boolean
name|shouldStop
parameter_list|()
block|{
return|return
name|hasLike
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|visit
parameter_list|(
name|LeafNode
name|node
parameter_list|)
throws|throws
name|MetaException
block|{
name|hasLike
operator|=
name|hasLike
operator|||
operator|(
name|node
operator|.
name|operator
operator|==
name|Operator
operator|.
name|LIKE
operator|)
expr_stmt|;
block|}
block|}
end_class

begin_function
specifier|public
specifier|static
name|FilterParser
name|getFilterParser
parameter_list|(
name|String
name|filter
parameter_list|)
throws|throws
name|MetaException
block|{
name|FilterLexer
name|lexer
init|=
operator|new
name|FilterLexer
argument_list|(
operator|new
name|ANTLRNoCaseStringStream
argument_list|(
name|filter
argument_list|)
argument_list|)
decl_stmt|;
name|CommonTokenStream
name|tokens
init|=
operator|new
name|CommonTokenStream
argument_list|(
name|lexer
argument_list|)
decl_stmt|;
name|FilterParser
name|parser
init|=
operator|new
name|FilterParser
argument_list|(
name|tokens
argument_list|)
decl_stmt|;
try|try
block|{
name|parser
operator|.
name|filter
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RecognitionException
name|re
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Error parsing partition filter; lexer error: "
operator|+
name|lexer
operator|.
name|errorMsg
operator|+
literal|"; exception "
operator|+
name|re
argument_list|)
throw|;
block|}
if|if
condition|(
name|lexer
operator|.
name|errorMsg
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Error parsing partition filter : "
operator|+
name|lexer
operator|.
name|errorMsg
argument_list|)
throw|;
block|}
return|return
name|parser
return|;
block|}
end_function

unit|}
end_unit

