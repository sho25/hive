begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *<p>  * http://www.apache.org/licenses/LICENSE-2.0  *<p>  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMPoolSchedulingPolicy
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Predicates
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|ListUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|CollectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeysPublic
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|StatsSetupConst
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ColumnType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ColumnStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ColumnStatisticsObj
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Decimal
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|EnvironmentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Order
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SerDeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SkewedInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|aggr
operator|.
name|ColumnStatsAggregator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|aggr
operator|.
name|ColumnStatsAggregatorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|merge
operator|.
name|ColumnStatsMerger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|merge
operator|.
name|ColumnStatsMergerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|partition
operator|.
name|spec
operator|.
name|PartitionSpecProxy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|security
operator|.
name|HadoopThriftAuthBridge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SaslRpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|authorize
operator|.
name|DefaultImpersonationProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|authorize
operator|.
name|ProxyUsers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|MachineList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|math
operator|.
name|BigDecimal
import|;
end_import

begin_import
import|import
name|java
operator|.
name|math
operator|.
name|BigInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|ServerSocket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLClassLoader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|Charset
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|MessageDigest
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|DateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|SimpleDateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|StringJoiner
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_class
specifier|public
class|class
name|MetaStoreUtils
block|{
comment|/** A fixed date format to be used for hive partition column values. */
specifier|public
specifier|static
specifier|final
name|ThreadLocal
argument_list|<
name|DateFormat
argument_list|>
name|PARTITION_DATE_FORMAT
init|=
operator|new
name|ThreadLocal
argument_list|<
name|DateFormat
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|DateFormat
name|initialValue
parameter_list|()
block|{
name|DateFormat
name|val
init|=
operator|new
name|SimpleDateFormat
argument_list|(
literal|"yyyy-MM-dd"
argument_list|)
decl_stmt|;
name|val
operator|.
name|setLenient
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// Without this, 2020-20-20 becomes 2021-08-20.
return|return
name|val
return|;
block|}
block|}
decl_stmt|;
comment|// Indicates a type was derived from the deserializer rather than Hive's metadata.
specifier|public
specifier|static
specifier|final
name|String
name|TYPE_FROM_DESERIALIZER
init|=
literal|"<derived from deserializer>"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Charset
name|ENCODING
init|=
name|StandardCharsets
operator|.
name|UTF_8
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MetaStoreUtils
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// The following two are public for any external users who wish to use them.
comment|/**    * This character is used to mark a database name as having a catalog name prepended.  This    * marker should be placed first in the String to make it easy to determine that this has both    * a catalog and a database name.  @ is chosen as it is not used in regular expressions.  This    * is only intended for use when making old Thrift calls that do not support catalog names.    */
specifier|public
specifier|static
specifier|final
name|char
name|CATALOG_DB_THRIFT_NAME_MARKER
init|=
literal|'@'
decl_stmt|;
comment|/**    * This String is used to seaprate the catalog name from the database name.  This should only    * be used in Strings that are prepended with {@link #CATALOG_DB_THRIFT_NAME_MARKER}.  # is    * chosen because it is not used in regular expressions.  this is only intended for use when    * making old Thrift calls that do not support catalog names.    */
specifier|public
specifier|static
specifier|final
name|String
name|CATALOG_DB_SEPARATOR
init|=
literal|"#"
decl_stmt|;
comment|/**    * Mark a database as being empty (as distinct from null).    */
specifier|public
specifier|static
specifier|final
name|String
name|DB_EMPTY_MARKER
init|=
literal|"!"
decl_stmt|;
comment|// Right now we only support one special character '/'.
comment|// More special characters can be added accordingly in the future.
comment|// NOTE:
comment|// If the following array is updated, please also be sure to update the
comment|// configuration parameter documentation
comment|// HIVE_SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES in HiveConf as well.
specifier|private
specifier|static
specifier|final
name|char
index|[]
name|specialCharactersInTableNames
init|=
operator|new
name|char
index|[]
block|{
literal|'/'
block|}
decl_stmt|;
comment|/**    * Catches exceptions that can't be handled and bundles them to MetaException    *    * @param e exception to wrap.    * @throws MetaException wrapper for the exception    */
specifier|public
specifier|static
name|void
name|logAndThrowMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|exInfo
init|=
literal|"Got exception: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|exInfo
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Converting exception to MetaException"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|exInfo
argument_list|)
throw|;
block|}
specifier|public
specifier|static
name|String
name|encodeTableName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
comment|// The encoding method is simple, e.g., replace
comment|// all the special characters with the corresponding number in ASCII.
comment|// Note that unicode is not supported in table names. And we have explicit
comment|// checks for it.
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|char
name|ch
range|:
name|name
operator|.
name|toCharArray
argument_list|()
control|)
block|{
if|if
condition|(
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|ch
argument_list|)
operator|||
name|ch
operator|==
literal|'_'
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|ch
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|'-'
argument_list|)
operator|.
name|append
argument_list|(
operator|(
name|int
operator|)
name|ch
argument_list|)
operator|.
name|append
argument_list|(
literal|'-'
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * convert Exception to MetaException, which sets the cause to such exception    * @param e cause of the exception    * @return  the MetaException with the specified exception as the cause    */
specifier|public
specifier|static
name|MetaException
name|newMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
return|return
name|newMetaException
argument_list|(
name|e
operator|!=
literal|null
condition|?
name|e
operator|.
name|getMessage
argument_list|()
else|:
literal|null
argument_list|,
name|e
argument_list|)
return|;
block|}
comment|/**    * convert Exception to MetaException, which sets the cause to such exception    * @param errorMessage  the error message for this MetaException    * @param e             cause of the exception    * @return  the MetaException with the specified exception as the cause    */
specifier|public
specifier|static
name|MetaException
name|newMetaException
parameter_list|(
name|String
name|errorMessage
parameter_list|,
name|Exception
name|e
parameter_list|)
block|{
name|MetaException
name|metaException
init|=
operator|new
name|MetaException
argument_list|(
name|errorMessage
argument_list|)
decl_stmt|;
if|if
condition|(
name|e
operator|!=
literal|null
condition|)
block|{
name|metaException
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|metaException
return|;
block|}
comment|/**    * Helper function to transform Nulls to empty strings.    */
specifier|private
specifier|static
specifier|final
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|transFormNullsToEmptyString
init|=
operator|new
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|java
operator|.
name|lang
operator|.
name|String
name|apply
parameter_list|(
annotation|@
name|Nullable
name|java
operator|.
name|lang
operator|.
name|String
name|string
parameter_list|)
block|{
return|return
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|defaultString
argument_list|(
name|string
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * We have a need to sanity-check the map before conversion from persisted objects to    * metadata thrift objects because null values in maps will cause a NPE if we send    * across thrift. Pruning is appropriate for most cases except for databases such as    * Oracle where Empty strings are stored as nulls, in which case we need to handle that.    * See HIVE-8485 for motivations for this.    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|trimMapNulls
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|dnMap
parameter_list|,
name|boolean
name|retrieveMapNullsAsEmptyStrings
parameter_list|)
block|{
if|if
condition|(
name|dnMap
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Must be deterministic order map - see HIVE-8707
comment|//   => we use Maps.newLinkedHashMap instead of Maps.newHashMap
if|if
condition|(
name|retrieveMapNullsAsEmptyStrings
condition|)
block|{
comment|// convert any nulls present in map values to empty strings - this is done in the case
comment|// of backing dbs like oracle which persist empty strings as nulls.
return|return
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|Maps
operator|.
name|transformValues
argument_list|(
name|dnMap
argument_list|,
name|transFormNullsToEmptyString
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// prune any nulls present in map values - this is the typical case.
return|return
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|Maps
operator|.
name|filterValues
argument_list|(
name|dnMap
argument_list|,
name|Predicates
operator|.
name|notNull
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|// Given a list of partStats, this function will give you an aggr stats
specifier|public
specifier|static
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|aggrPartitionStats
parameter_list|(
name|List
argument_list|<
name|ColumnStatistics
argument_list|>
name|partStats
parameter_list|,
name|String
name|catName
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|colNames
parameter_list|,
name|boolean
name|areAllPartsFound
parameter_list|,
name|boolean
name|useDensityFunctionForNDVEstimation
parameter_list|,
name|double
name|ndvTuner
parameter_list|)
throws|throws
name|MetaException
block|{
name|Map
argument_list|<
name|ColumnStatsAggregator
argument_list|,
name|List
argument_list|<
name|ColStatsObjWithSourceInfo
argument_list|>
argument_list|>
name|colStatsMap
init|=
operator|new
name|HashMap
argument_list|<
name|ColumnStatsAggregator
argument_list|,
name|List
argument_list|<
name|ColStatsObjWithSourceInfo
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
comment|// Group stats by colName for each partition
name|Map
argument_list|<
name|String
argument_list|,
name|ColumnStatsAggregator
argument_list|>
name|aliasToAggregator
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|ColumnStatsAggregator
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|ColumnStatistics
name|css
range|:
name|partStats
control|)
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|objs
init|=
name|css
operator|.
name|getStatsObj
argument_list|()
decl_stmt|;
for|for
control|(
name|ColumnStatisticsObj
name|obj
range|:
name|objs
control|)
block|{
name|String
name|partName
init|=
name|css
operator|.
name|getStatsDesc
argument_list|()
operator|.
name|getPartName
argument_list|()
decl_stmt|;
if|if
condition|(
name|aliasToAggregator
operator|.
name|get
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|)
operator|==
literal|null
condition|)
block|{
name|aliasToAggregator
operator|.
name|put
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|,
name|ColumnStatsAggregatorFactory
operator|.
name|getColumnStatsAggregator
argument_list|(
name|obj
operator|.
name|getStatsData
argument_list|()
operator|.
name|getSetField
argument_list|()
argument_list|,
name|useDensityFunctionForNDVEstimation
argument_list|,
name|ndvTuner
argument_list|)
argument_list|)
expr_stmt|;
name|colStatsMap
operator|.
name|put
argument_list|(
name|aliasToAggregator
operator|.
name|get
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|)
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|ColStatsObjWithSourceInfo
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|colStatsMap
operator|.
name|get
argument_list|(
name|aliasToAggregator
operator|.
name|get
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|)
argument_list|)
operator|.
name|add
argument_list|(
operator|new
name|ColStatsObjWithSourceInfo
argument_list|(
name|obj
argument_list|,
name|catName
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partName
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|colStatsMap
operator|.
name|size
argument_list|()
operator|<
literal|1
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No stats data found for: tblName= {}, partNames= {}, colNames= {}"
argument_list|,
name|Warehouse
operator|.
name|getCatalogQualifiedTableName
argument_list|(
name|catName
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|)
argument_list|,
name|partNames
argument_list|,
name|colNames
argument_list|)
expr_stmt|;
return|return
operator|new
name|ArrayList
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|()
return|;
block|}
return|return
name|aggrPartitionStats
argument_list|(
name|colStatsMap
argument_list|,
name|partNames
argument_list|,
name|areAllPartsFound
argument_list|,
name|useDensityFunctionForNDVEstimation
argument_list|,
name|ndvTuner
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|aggrPartitionStats
parameter_list|(
name|Map
argument_list|<
name|ColumnStatsAggregator
argument_list|,
name|List
argument_list|<
name|ColStatsObjWithSourceInfo
argument_list|>
argument_list|>
name|colStatsMap
parameter_list|,
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|,
specifier|final
name|boolean
name|areAllPartsFound
parameter_list|,
specifier|final
name|boolean
name|useDensityFunctionForNDVEstimation
parameter_list|,
specifier|final
name|double
name|ndvTuner
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|aggrColStatObjs
init|=
operator|new
name|ArrayList
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|()
decl_stmt|;
name|int
name|numProcessors
init|=
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|availableProcessors
argument_list|()
decl_stmt|;
specifier|final
name|ExecutorService
name|pool
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|colStatsMap
operator|.
name|size
argument_list|()
argument_list|,
name|numProcessors
argument_list|)
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"aggr-col-stats-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|>
name|futures
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Aggregating column stats. Threads used: {}"
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|colStatsMap
operator|.
name|size
argument_list|()
argument_list|,
name|numProcessors
argument_list|)
argument_list|)
expr_stmt|;
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
for|for
control|(
specifier|final
name|Entry
argument_list|<
name|ColumnStatsAggregator
argument_list|,
name|List
argument_list|<
name|ColStatsObjWithSourceInfo
argument_list|>
argument_list|>
name|entry
range|:
name|colStatsMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|futures
operator|.
name|add
argument_list|(
name|pool
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|ColumnStatisticsObj
name|call
parameter_list|()
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|ColStatsObjWithSourceInfo
argument_list|>
name|colStatWithSourceInfo
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|ColumnStatsAggregator
name|aggregator
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
try|try
block|{
name|ColumnStatisticsObj
name|statsObj
init|=
name|aggregator
operator|.
name|aggregate
argument_list|(
name|colStatWithSourceInfo
argument_list|,
name|partNames
argument_list|,
name|areAllPartsFound
argument_list|)
decl_stmt|;
return|return
name|statsObj
return|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|futures
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|Future
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
if|if
condition|(
name|future
operator|.
name|get
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|aggrColStatObjs
operator|.
name|add
argument_list|(
name|future
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|pool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Time for aggr col stats in seconds: {} Threads used: {}"
argument_list|,
operator|(
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
operator|(
name|double
operator|)
name|start
operator|)
operator|)
operator|/
literal|1000
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|colStatsMap
operator|.
name|size
argument_list|()
argument_list|,
name|numProcessors
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|aggrColStatObjs
return|;
block|}
specifier|public
specifier|static
name|double
name|decimalToDouble
parameter_list|(
name|Decimal
name|decimal
parameter_list|)
block|{
return|return
operator|new
name|BigDecimal
argument_list|(
operator|new
name|BigInteger
argument_list|(
name|decimal
operator|.
name|getUnscaled
argument_list|()
argument_list|)
argument_list|,
name|decimal
operator|.
name|getScale
argument_list|()
argument_list|)
operator|.
name|doubleValue
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|void
name|validatePartitionNameCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|invalidPartitionVal
init|=
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
decl_stmt|;
if|if
condition|(
name|invalidPartitionVal
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Partition value '"
operator|+
name|invalidPartitionVal
operator|+
literal|"' contains a character "
operator|+
literal|"not matched by whitelist pattern '"
operator|+
name|partitionValidationPattern
operator|.
name|toString
argument_list|()
operator|+
literal|"'.  "
operator|+
literal|"(configure with "
operator|+
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|PARTITION_NAME_WHITELIST_PATTERN
operator|.
name|getVarname
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|String
name|getPartitionValWithInvalidCharacter
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
if|if
condition|(
name|partitionValidationPattern
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|partVal
range|:
name|partVals
control|)
block|{
if|if
condition|(
operator|!
name|partitionValidationPattern
operator|.
name|matcher
argument_list|(
name|partVal
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
name|partVal
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Produce a hash for the storage descriptor    * @param sd storage descriptor to hash    * @param md message descriptor to use to generate the hash    * @return the hash as a byte array    */
specifier|public
specifier|static
specifier|synchronized
name|byte
index|[]
name|hashStorageDescriptor
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|MessageDigest
name|md
parameter_list|)
block|{
comment|// Note all maps and lists have to be absolutely sorted.  Otherwise we'll produce different
comment|// results for hashes based on the OS or JVM being used.
name|md
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// In case cols are null
if|if
condition|(
name|sd
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FieldSchema
name|fs
range|:
name|sd
operator|.
name|getCols
argument_list|()
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|fs
operator|.
name|getType
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|getComment
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|fs
operator|.
name|getComment
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|isCompressed
argument_list|()
condition|?
literal|"true"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
else|:
literal|"false"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SerDeInfo
name|serde
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|serde
operator|.
name|getName
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|serde
operator|.
name|getName
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serde
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|serde
operator|.
name|getSerializationLib
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serde
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|serde
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|params
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|param
operator|.
name|getKey
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|param
operator|.
name|getValue
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|sd
operator|.
name|getBucketCols
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|bucket
range|:
name|bucketCols
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|bucket
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getSortCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedSet
argument_list|<
name|Order
argument_list|>
name|orders
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|sd
operator|.
name|getSortCols
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Order
name|order
range|:
name|orders
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|order
operator|.
name|getCol
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|Integer
operator|.
name|toString
argument_list|(
name|order
operator|.
name|getOrder
argument_list|()
argument_list|)
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getSkewedInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SkewedInfo
name|skewed
init|=
name|sd
operator|.
name|getSkewedInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|skewed
operator|.
name|getSkewedColNames
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|colnames
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|skewed
operator|.
name|getSkewedColNames
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|colname
range|:
name|colnames
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|colname
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|skewed
operator|.
name|getSkewedColValues
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|sortedOuterList
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|String
argument_list|>
name|innerList
range|:
name|skewed
operator|.
name|getSkewedColValues
argument_list|()
control|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|sortedInnerList
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|innerList
argument_list|)
decl_stmt|;
name|sortedOuterList
operator|.
name|add
argument_list|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|join
argument_list|(
name|sortedInnerList
argument_list|,
literal|"."
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|colval
range|:
name|sortedOuterList
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|colval
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|skewed
operator|.
name|getSkewedColValueLocationMaps
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|sortedMap
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|smap
range|:
name|skewed
operator|.
name|getSkewedColValueLocationMaps
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|sortedKey
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|smap
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|sortedMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|join
argument_list|(
name|sortedKey
argument_list|,
literal|"."
argument_list|)
argument_list|,
name|smap
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|sortedMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|isStoredAsSubDirectories
argument_list|()
condition|?
literal|"true"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
else|:
literal|"false"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|md
operator|.
name|digest
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getColumnNamesForTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|colsIterator
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getColsIterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|colsIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|colsIterator
operator|.
name|next
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|colNames
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getColumnNamesForPartition
parameter_list|(
name|Partition
name|partition
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|colsIterator
init|=
name|partition
operator|.
name|getSd
argument_list|()
operator|.
name|getColsIterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|colsIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|colsIterator
operator|.
name|next
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|colNames
return|;
block|}
comment|/**    * validateName    *    * Checks the name conforms to our standars which are: "[a-zA-z_0-9]+". checks    * this is just characters and numbers and _    *    * @param name    *          the name to validate    * @param conf    *          hive configuration    * @return true or false depending on conformance    *              if it doesn't match the pattern.    */
specifier|public
specifier|static
name|boolean
name|validateName
parameter_list|(
name|String
name|name
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|Pattern
name|tpat
decl_stmt|;
name|String
name|allowedCharacters
init|=
literal|"\\w_"
decl_stmt|;
if|if
condition|(
name|conf
operator|!=
literal|null
operator|&&
name|MetastoreConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES
argument_list|)
condition|)
block|{
for|for
control|(
name|Character
name|c
range|:
name|specialCharactersInTableNames
control|)
block|{
name|allowedCharacters
operator|+=
name|c
expr_stmt|;
block|}
block|}
name|tpat
operator|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"["
operator|+
name|allowedCharacters
operator|+
literal|"]+"
argument_list|)
expr_stmt|;
name|Matcher
name|m
init|=
name|tpat
operator|.
name|matcher
argument_list|(
name|name
argument_list|)
decl_stmt|;
return|return
name|m
operator|.
name|matches
argument_list|()
return|;
block|}
comment|/*    * At the Metadata level there are no restrictions on Column Names.    */
specifier|public
specifier|static
name|boolean
name|validateColumnName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
specifier|static
specifier|public
name|String
name|validateTblColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
comment|// skip this, as validateColumnName always returns true
comment|/*       if (!validateColumnName(fieldSchema.getName())) {         return "name: " + fieldSchema.getName();       }       */
name|String
name|typeError
init|=
name|validateColumnType
argument_list|(
name|fieldSchema
operator|.
name|getType
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeError
operator|!=
literal|null
condition|)
block|{
return|return
name|typeError
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|private
specifier|static
name|String
name|validateColumnType
parameter_list|(
name|String
name|type
parameter_list|)
block|{
if|if
condition|(
name|type
operator|.
name|equals
argument_list|(
name|TYPE_FROM_DESERIALIZER
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|int
name|last
init|=
literal|0
decl_stmt|;
name|boolean
name|lastAlphaDigit
init|=
name|isValidTypeChar
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|last
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|type
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|type
operator|.
name|length
argument_list|()
operator|||
name|isValidTypeChar
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|!=
name|lastAlphaDigit
condition|)
block|{
name|String
name|token
init|=
name|type
operator|.
name|substring
argument_list|(
name|last
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|last
operator|=
name|i
expr_stmt|;
if|if
condition|(
operator|!
name|ColumnType
operator|.
name|AllTypes
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
return|return
literal|"type: "
operator|+
name|type
return|;
block|}
break|break;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isValidTypeChar
parameter_list|(
name|char
name|c
parameter_list|)
block|{
return|return
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|c
argument_list|)
operator|||
name|c
operator|==
literal|'_'
return|;
block|}
comment|/**    * Determines whether a table is an external table.    *    * @param table table of interest    *    * @return true if external    */
specifier|public
specifier|static
name|boolean
name|isExternalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|isExternal
argument_list|(
name|params
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isExternal
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tableParams
parameter_list|)
block|{
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|tableParams
operator|.
name|get
argument_list|(
literal|"EXTERNAL"
argument_list|)
argument_list|)
return|;
block|}
comment|// check if stats need to be (re)calculated
specifier|public
specifier|static
name|boolean
name|requireCalStats
parameter_list|(
name|Partition
name|oldPart
parameter_list|,
name|Partition
name|newPart
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
block|{
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TRUE
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|isView
argument_list|(
name|tbl
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|oldPart
operator|==
literal|null
operator|&&
name|newPart
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// requires to calculate stats if new partition doesn't have it
if|if
condition|(
operator|(
name|newPart
operator|==
literal|null
operator|)
operator|||
operator|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|==
literal|null
operator|)
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|newPart
operator|.
name|getParameters
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
condition|)
block|{
name|String
name|statsType
init|=
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
decl_stmt|;
comment|// no matter STATS_GENERATED is USER or TASK, all need to re-calculate the stats:
comment|// USER: alter table .. update statistics
comment|// TASK: from some sql operation which could collect and compute stats
if|if
condition|(
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|statsType
argument_list|)
operator|||
name|StatsSetupConst
operator|.
name|USER
operator|.
name|equals
argument_list|(
name|statsType
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
comment|// requires to calculate stats if new and old have different fast stats
return|return
operator|!
name|isFastStatsSame
argument_list|(
name|oldPart
argument_list|,
name|newPart
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isView
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param partParams    * @return True if the passed Parameters Map contains values for all "Fast Stats".    */
specifier|private
specifier|static
name|boolean
name|containsAllFastStats
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partParams
parameter_list|)
block|{
for|for
control|(
name|String
name|stat
range|:
name|StatsSetupConst
operator|.
name|fastStats
control|)
block|{
if|if
condition|(
operator|!
name|partParams
operator|.
name|containsKey
argument_list|(
name|stat
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isFastStatsSame
parameter_list|(
name|Partition
name|oldPart
parameter_list|,
name|Partition
name|newPart
parameter_list|)
block|{
comment|// requires to calculate stats if new and old have different fast stats
if|if
condition|(
operator|(
name|oldPart
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
operator|)
condition|)
block|{
for|for
control|(
name|String
name|stat
range|:
name|StatsSetupConst
operator|.
name|fastStats
control|)
block|{
if|if
condition|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|.
name|containsKey
argument_list|(
name|stat
argument_list|)
condition|)
block|{
name|Long
name|oldStat
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|stat
argument_list|)
argument_list|)
decl_stmt|;
name|Long
name|newStat
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|stat
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|oldStat
operator|.
name|equals
argument_list|(
name|newStat
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Table by querying    * the warehouse if the passed Table does not already have values for these parameters.    * NOTE: This function is rather expensive since it needs to traverse the file system to get all    * the information.    *    * @param newDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Table already has    * these parameters set    */
specifier|public
specifier|static
name|void
name|updateTableStatsSlow
parameter_list|(
name|Database
name|db
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|newDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
comment|// DO_NOT_UPDATE_STATS is supposed to be a transient parameter that is only passed via RPC
comment|// We want to avoid this property from being persistent.
comment|//
comment|// NOTE: If this property *is* set as table property we will remove it which is incorrect but
comment|// we can't distinguish between these two cases
comment|//
comment|// This problem was introduced by HIVE-10228. A better approach would be to pass the property
comment|// via the environment context.
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|tbl
operator|.
name|getParameters
argument_list|()
decl_stmt|;
name|boolean
name|updateStats
init|=
literal|true
decl_stmt|;
if|if
condition|(
operator|(
name|params
operator|!=
literal|null
operator|)
operator|&&
name|params
operator|.
name|containsKey
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
condition|)
block|{
name|updateStats
operator|=
operator|!
name|Boolean
operator|.
name|valueOf
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
argument_list|)
expr_stmt|;
name|params
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|updateStats
operator|||
name|newDir
operator|||
name|tbl
operator|.
name|getPartitionKeysSize
argument_list|()
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
comment|// If stats are already present and forceRecompute isn't set, nothing to do
if|if
condition|(
operator|!
name|forceRecompute
operator|&&
name|params
operator|!=
literal|null
operator|&&
name|containsAllFastStats
argument_list|(
name|params
argument_list|)
condition|)
block|{
return|return;
block|}
comment|// NOTE: wh.getFileStatusesForUnpartitionedTable() can be REALLY slow
name|List
argument_list|<
name|FileStatus
argument_list|>
name|fileStatus
init|=
name|wh
operator|.
name|getFileStatusesForUnpartitionedTable
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
name|params
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|tbl
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
block|}
comment|// The table location already exists and may contain data.
comment|// Let's try to populate those stats that don't require full scan.
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating table stats for {}"
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|populateQuickStats
argument_list|(
name|fileStatus
argument_list|,
name|params
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated size of table {} to {}"
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** This method is invalid for MM and ACID tables unless fileStatus comes from AcidUtils. */
specifier|public
specifier|static
name|void
name|populateQuickStats
parameter_list|(
name|List
argument_list|<
name|FileStatus
argument_list|>
name|fileStatus
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
comment|// Why is this even in metastore?
name|LOG
operator|.
name|trace
argument_list|(
literal|"Populating quick stats based on {} files"
argument_list|,
name|fileStatus
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|numFiles
init|=
literal|0
decl_stmt|;
name|long
name|tableSize
init|=
literal|0L
decl_stmt|;
for|for
control|(
name|FileStatus
name|status
range|:
name|fileStatus
control|)
block|{
comment|// don't take directories into account for quick stats TODO: wtf?
if|if
condition|(
operator|!
name|status
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|tableSize
operator|+=
name|status
operator|.
name|getLen
argument_list|()
expr_stmt|;
name|numFiles
operator|+=
literal|1
expr_stmt|;
block|}
block|}
name|params
operator|.
name|put
argument_list|(
name|StatsSetupConst
operator|.
name|NUM_FILES
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|numFiles
argument_list|)
argument_list|)
expr_stmt|;
name|params
operator|.
name|put
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|tableSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|clearQuickStats
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|params
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|NUM_FILES
argument_list|)
expr_stmt|;
name|params
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|boolean
name|areSameColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
block|{
return|return
name|ListUtils
operator|.
name|isEqualList
argument_list|(
name|oldCols
argument_list|,
name|newCols
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|updateBasicState
parameter_list|(
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Partition by querying    *  the warehouse if the passed Partition does not already have values for these parameters.    * @param part    * @param wh    * @param madeDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Partition already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|isCreate
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
operator|new
name|PartitionSpecProxy
operator|.
name|SimplePartitionWrapperIterator
argument_list|(
name|part
argument_list|)
argument_list|,
name|tbl
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
name|forceRecompute
argument_list|,
name|environmentContext
argument_list|,
name|isCreate
argument_list|)
return|;
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Partition by querying    *  the warehouse if the passed Partition does not already have values for these parameters.    * @param part    * @param wh    * @param madeDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Partition already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|PartitionSpecProxy
operator|.
name|PartitionIterator
name|part
parameter_list|,
name|Table
name|table
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|isCreate
parameter_list|)
throws|throws
name|MetaException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|forceRecompute
operator|&&
name|params
operator|!=
literal|null
operator|&&
name|containsAllFastStats
argument_list|(
name|params
argument_list|)
condition|)
return|return
literal|false
return|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
name|params
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|isCreate
operator|&&
name|MetaStoreUtils
operator|.
name|isTransactionalTable
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
condition|)
block|{
comment|// TODO: implement?
name|LOG
operator|.
name|warn
argument_list|(
literal|"Not updating fast stats for a transactional table "
operator|+
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|part
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
if|if
condition|(
operator|!
name|madeDir
condition|)
block|{
comment|// The partition location already existed and may contain data. Lets try to
comment|// populate those statistics that don't require a full scan of the data.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Updating partition stats fast for: "
operator|+
name|part
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|fileStatus
init|=
name|wh
operator|.
name|getFileStatusesForLocation
argument_list|(
name|part
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
comment|// TODO: this is invalid for ACID tables, and we cannot access AcidUtils here.
name|populateQuickStats
argument_list|(
name|fileStatus
argument_list|,
name|params
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Updated size to "
operator|+
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|updateBasicState
argument_list|(
name|environmentContext
argument_list|,
name|params
argument_list|)
expr_stmt|;
block|}
name|part
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/*      * This method is to check if the new column list includes all the old columns with same name and      * type. The column comment does not count.      */
specifier|public
specifier|static
name|boolean
name|columnsIncludedByNameType
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
block|{
if|if
condition|(
name|oldCols
operator|.
name|size
argument_list|()
operator|>
name|newCols
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|columnNameTypePairMap
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|newCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|newCol
range|:
name|newCols
control|)
block|{
name|columnNameTypePairMap
operator|.
name|put
argument_list|(
name|newCol
operator|.
name|getName
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|newCol
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
specifier|final
name|FieldSchema
name|oldCol
range|:
name|oldCols
control|)
block|{
if|if
condition|(
operator|!
name|columnNameTypePairMap
operator|.
name|containsKey
argument_list|(
name|oldCol
operator|.
name|getName
argument_list|()
argument_list|)
operator|||
operator|!
name|columnNameTypePairMap
operator|.
name|get
argument_list|(
name|oldCol
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|equalsIgnoreCase
argument_list|(
name|oldCol
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/** Duplicates AcidUtils; used in a couple places in metastore. */
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
comment|/** Duplicates AcidUtils; used in a couple places in metastore. */
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTableParam
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
comment|/**    * create listener instances as per the configuration.    *    * @param clazz Class of the listener    * @param conf configuration object    * @param listenerImplList Implementation class name    * @return instance of the listener    * @throws MetaException if there is any failure instantiating the class    */
specifier|public
specifier|static
parameter_list|<
name|T
parameter_list|>
name|List
argument_list|<
name|T
argument_list|>
name|getMetaStoreListeners
parameter_list|(
name|Class
argument_list|<
name|T
argument_list|>
name|clazz
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|String
name|listenerImplList
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|T
argument_list|>
name|listeners
init|=
operator|new
name|ArrayList
argument_list|<
name|T
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isBlank
argument_list|(
name|listenerImplList
argument_list|)
condition|)
block|{
return|return
name|listeners
return|;
block|}
name|String
index|[]
name|listenerImpls
init|=
name|listenerImplList
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|listenerImpl
range|:
name|listenerImpls
control|)
block|{
try|try
block|{
name|T
name|listener
init|=
operator|(
name|T
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|listenerImpl
operator|.
name|trim
argument_list|()
argument_list|,
literal|true
argument_list|,
name|JavaUtils
operator|.
name|getClassLoader
argument_list|()
argument_list|)
operator|.
name|getConstructor
argument_list|(
name|Configuration
operator|.
name|class
argument_list|)
operator|.
name|newInstance
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvocationTargetException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Got InvocationTargetException"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|ie
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Got Exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|listeners
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNames
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|cols
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|validateColumnName
argument_list|(
name|col
argument_list|)
condition|)
block|{
return|return
name|col
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNamesSubsetCol
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|skewedColNames
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|skewedColNames
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|cols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|fieldSchema
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// make a copy
name|List
argument_list|<
name|String
argument_list|>
name|copySkewedColNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|skewedColNames
argument_list|)
decl_stmt|;
comment|// remove valid columns
name|copySkewedColNames
operator|.
name|removeAll
argument_list|(
name|colNames
argument_list|)
expr_stmt|;
if|if
condition|(
name|copySkewedColNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|copySkewedColNames
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isNonNativeTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
operator|||
name|table
operator|.
name|getParameters
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|(
name|table
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|META_TABLE_STORAGE
argument_list|)
operator|!=
literal|null
operator|)
return|;
block|}
comment|/**    * Given a list of partition columns and a partial mapping from    * some partition columns to values the function returns the values    * for the column.    * @param partCols the list of table partition columns    * @param partSpec the partial mapping from partition column to values    * @return list of values of for given partition columns, any missing    *         values in partSpec is replaced by an empty string    */
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPvals
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|partCols
control|)
block|{
name|String
name|val
init|=
name|StringUtils
operator|.
name|defaultString
argument_list|(
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
return|return
name|pvals
return|;
block|}
specifier|public
specifier|static
name|String
name|makePartNameMatcher
parameter_list|(
name|Table
name|table
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
init|=
name|table
operator|.
name|getPartitionKeys
argument_list|()
decl_stmt|;
name|int
name|numPartKeys
init|=
name|partCols
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|partVals
operator|.
name|size
argument_list|()
operator|>
name|numPartKeys
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Incorrect number of partition values."
operator|+
literal|" numPartKeys="
operator|+
name|numPartKeys
operator|+
literal|", part_val="
operator|+
name|partVals
argument_list|)
throw|;
block|}
name|partCols
operator|=
name|partCols
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|partVals
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// Construct a pattern of the form: partKey=partVal/partKey2=partVal2/...
comment|// where partVal is either the escaped partition value given as input,
comment|// or a regex of the form ".*"
comment|// This works because the "=" and "/" separating key names and partition key/values
comment|// are not escaped.
name|String
name|partNameMatcher
init|=
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|partCols
argument_list|,
name|partVals
argument_list|,
literal|".*"
argument_list|)
decl_stmt|;
comment|// add ".*" to the regex to match anything else afterwards the partial spec.
if|if
condition|(
name|partVals
operator|.
name|size
argument_list|()
operator|<
name|numPartKeys
condition|)
block|{
name|partNameMatcher
operator|+=
literal|".*"
expr_stmt|;
block|}
return|return
name|partNameMatcher
return|;
block|}
comment|/**    * @param schema1: The first schema to be compared    * @param schema2: The second schema to be compared    * @return true if the two schemas are the same else false    *         for comparing a field we ignore the comment it has    */
specifier|public
specifier|static
name|boolean
name|compareFieldColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema1
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema2
parameter_list|)
block|{
if|if
condition|(
name|schema1
operator|.
name|size
argument_list|()
operator|!=
name|schema2
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|its1
init|=
name|schema1
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|its2
init|=
name|schema2
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|its1
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FieldSchema
name|f1
init|=
name|its1
operator|.
name|next
argument_list|()
decl_stmt|;
name|FieldSchema
name|f2
init|=
name|its2
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// The default equals provided by thrift compares the comments too for
comment|// equality, thus we need to compare the relevant fields here.
if|if
condition|(
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|f1
operator|.
name|getName
argument_list|()
argument_list|,
name|f2
operator|.
name|getName
argument_list|()
argument_list|)
operator|||
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|f1
operator|.
name|getType
argument_list|()
argument_list|,
name|f2
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isArchived
parameter_list|(
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|)
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Path
name|getOriginalLocation
parameter_list|(
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
assert|assert
operator|(
name|isArchived
argument_list|(
name|part
argument_list|)
operator|)
assert|;
name|String
name|originalLocation
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|originalLocation
operator|!=
literal|null
operator|)
assert|;
return|return
operator|new
name|Path
argument_list|(
name|originalLocation
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
name|ARCHIVING_LEVEL
init|=
literal|"archiving_level"
decl_stmt|;
specifier|public
specifier|static
name|int
name|getArchivingLevel
parameter_list|(
name|Partition
name|part
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
operator|!
name|isArchived
argument_list|(
name|part
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Getting level of unarchived partition"
argument_list|)
throw|;
block|}
name|String
name|lv
init|=
name|part
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|ARCHIVING_LEVEL
argument_list|)
decl_stmt|;
if|if
condition|(
name|lv
operator|!=
literal|null
condition|)
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|lv
argument_list|)
return|;
block|}
comment|// partitions archived before introducing multiple archiving
return|return
name|part
operator|.
name|getValues
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|boolean
name|partitionNameHasValidCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
return|return
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
operator|==
literal|null
return|;
block|}
specifier|public
specifier|static
name|void
name|getMergableCols
parameter_list|(
name|ColumnStatistics
name|csNew
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|index
init|=
literal|0
init|;
name|index
operator|<
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|index
operator|++
control|)
block|{
name|ColumnStatisticsObj
name|statsObjNew
init|=
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|get
argument_list|(
name|index
argument_list|)
decl_stmt|;
comment|// canColumnStatsMerge guarantees that it is accurate before we do merge
if|if
condition|(
name|StatsSetupConst
operator|.
name|canColumnStatsMerge
argument_list|(
name|parameters
argument_list|,
name|statsObjNew
operator|.
name|getColName
argument_list|()
argument_list|)
condition|)
block|{
name|list
operator|.
name|add
argument_list|(
name|statsObjNew
argument_list|)
expr_stmt|;
block|}
comment|// in all the other cases, we can not merge
block|}
name|csNew
operator|.
name|setStatsObj
argument_list|(
name|list
argument_list|)
expr_stmt|;
block|}
comment|// this function will merge csOld into csNew.
specifier|public
specifier|static
name|void
name|mergeColStats
parameter_list|(
name|ColumnStatistics
name|csNew
parameter_list|,
name|ColumnStatistics
name|csOld
parameter_list|)
throws|throws
name|InvalidObjectException
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|csOld
operator|.
name|getStatsObjSize
argument_list|()
condition|)
block|{
comment|// Some of the columns' stats are missing
comment|// This implies partition schema has changed. We will merge columns
comment|// present in both, overwrite stats for columns absent in metastore and
comment|// leave alone columns stats missing from stats task. This last case may
comment|// leave stats in stale state. This will be addressed later.
name|LOG
operator|.
name|debug
argument_list|(
literal|"New ColumnStats size is {}, but old ColumnStats size is {}"
argument_list|,
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|csOld
operator|.
name|getStatsObjSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// In this case, we have to find out which columns can be merged.
name|Map
argument_list|<
name|String
argument_list|,
name|ColumnStatisticsObj
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|// We build a hash map from colName to object for old ColumnStats.
for|for
control|(
name|ColumnStatisticsObj
name|obj
range|:
name|csOld
operator|.
name|getStatsObj
argument_list|()
control|)
block|{
name|map
operator|.
name|put
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|,
name|obj
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|index
init|=
literal|0
init|;
name|index
operator|<
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|index
operator|++
control|)
block|{
name|ColumnStatisticsObj
name|statsObjNew
init|=
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|get
argument_list|(
name|index
argument_list|)
decl_stmt|;
name|ColumnStatisticsObj
name|statsObjOld
init|=
name|map
operator|.
name|get
argument_list|(
name|statsObjNew
operator|.
name|getColName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|statsObjOld
operator|!=
literal|null
condition|)
block|{
comment|// because we already confirm that the stats is accurate
comment|// it is impossible that the column types have been changed while the
comment|// column stats is still accurate.
assert|assert
operator|(
name|statsObjNew
operator|.
name|getStatsData
argument_list|()
operator|.
name|getSetField
argument_list|()
operator|==
name|statsObjOld
operator|.
name|getStatsData
argument_list|()
operator|.
name|getSetField
argument_list|()
operator|)
assert|;
comment|// If statsObjOld is found, we can merge.
name|ColumnStatsMerger
name|merger
init|=
name|ColumnStatsMergerFactory
operator|.
name|getColumnStatsMerger
argument_list|(
name|statsObjNew
argument_list|,
name|statsObjOld
argument_list|)
decl_stmt|;
name|merger
operator|.
name|merge
argument_list|(
name|statsObjNew
argument_list|,
name|statsObjOld
argument_list|)
expr_stmt|;
block|}
comment|// If statsObjOld is not found, we just use statsObjNew as it is accurate.
name|list
operator|.
name|add
argument_list|(
name|statsObjNew
argument_list|)
expr_stmt|;
block|}
comment|// in all the other cases, we can not merge
name|csNew
operator|.
name|setStatsObj
argument_list|(
name|list
argument_list|)
expr_stmt|;
block|}
comment|/**    * Read and return the meta store Sasl configuration. Currently it uses the default    * Hadoop SASL configuration and can be configured using "hadoop.rpc.protection"    * HADOOP-10211, made a backward incompatible change due to which this call doesn't    * work with Hadoop 2.4.0 and later.    * @param conf    * @return The SASL configuration    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getMetaStoreSaslProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|useSSL
parameter_list|)
block|{
comment|// As of now Hive Meta Store uses the same configuration as Hadoop SASL configuration
comment|// If SSL is enabled, override the given value of "hadoop.rpc.protection" and set it to "authentication"
comment|// This disables any encryption provided by SASL, since SSL already provides it
name|String
name|hadoopRpcProtectionVal
init|=
name|conf
operator|.
name|get
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
argument_list|)
decl_stmt|;
name|String
name|hadoopRpcProtectionAuth
init|=
name|SaslRpcServer
operator|.
name|QualityOfProtection
operator|.
name|AUTHENTICATION
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|useSSL
operator|&&
name|hadoopRpcProtectionVal
operator|!=
literal|null
operator|&&
operator|!
name|hadoopRpcProtectionVal
operator|.
name|equals
argument_list|(
name|hadoopRpcProtectionAuth
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Overriding value of "
operator|+
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
operator|+
literal|" setting it from "
operator|+
name|hadoopRpcProtectionVal
operator|+
literal|" to "
operator|+
name|hadoopRpcProtectionAuth
operator|+
literal|" because SSL is enabled"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
argument_list|,
name|hadoopRpcProtectionAuth
argument_list|)
expr_stmt|;
block|}
return|return
name|HadoopThriftAuthBridge
operator|.
name|getBridge
argument_list|()
operator|.
name|getHadoopSaslProperties
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Add new elements to the classpath.    *    * @param newPaths    *          Array of classpath elements    */
specifier|public
specifier|static
name|ClassLoader
name|addToClassPath
parameter_list|(
name|ClassLoader
name|cloader
parameter_list|,
name|String
index|[]
name|newPaths
parameter_list|)
throws|throws
name|Exception
block|{
name|URLClassLoader
name|loader
init|=
operator|(
name|URLClassLoader
operator|)
name|cloader
decl_stmt|;
name|List
argument_list|<
name|URL
argument_list|>
name|curPath
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|loader
operator|.
name|getURLs
argument_list|()
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|URL
argument_list|>
name|newPath
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|curPath
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// get a list with the current classpath components
for|for
control|(
name|URL
name|onePath
range|:
name|curPath
control|)
block|{
name|newPath
operator|.
name|add
argument_list|(
name|onePath
argument_list|)
expr_stmt|;
block|}
name|curPath
operator|=
name|newPath
expr_stmt|;
for|for
control|(
name|String
name|onestr
range|:
name|newPaths
control|)
block|{
name|URL
name|oneurl
init|=
name|urlFromPathString
argument_list|(
name|onestr
argument_list|)
decl_stmt|;
if|if
condition|(
name|oneurl
operator|!=
literal|null
operator|&&
operator|!
name|curPath
operator|.
name|contains
argument_list|(
name|oneurl
argument_list|)
condition|)
block|{
name|curPath
operator|.
name|add
argument_list|(
name|oneurl
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|URLClassLoader
argument_list|(
name|curPath
operator|.
name|toArray
argument_list|(
operator|new
name|URL
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|loader
argument_list|)
return|;
block|}
comment|/**    * Create a URL from a string representing a path to a local file.    * The path string can be just a path, or can start with file:/, file:///    * @param onestr  path string    * @return    */
specifier|private
specifier|static
name|URL
name|urlFromPathString
parameter_list|(
name|String
name|onestr
parameter_list|)
block|{
name|URL
name|oneurl
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|onestr
operator|.
name|startsWith
argument_list|(
literal|"file:/"
argument_list|)
condition|)
block|{
name|oneurl
operator|=
operator|new
name|URL
argument_list|(
name|onestr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|oneurl
operator|=
operator|new
name|File
argument_list|(
name|onestr
argument_list|)
operator|.
name|toURL
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|err
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad URL "
operator|+
name|onestr
operator|+
literal|", ignoring path"
argument_list|)
expr_stmt|;
block|}
return|return
name|oneurl
return|;
block|}
comment|/**    * Verify if the user is allowed to make DB notification related calls.    * Only the superusers defined in the Hadoop proxy user settings have the permission.    *    * @param user the short user name    * @param conf that contains the proxy user settings    * @return if the user has the permission    */
specifier|public
specifier|static
name|boolean
name|checkUserHasHostProxyPrivileges
parameter_list|(
name|String
name|user
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|String
name|ipAddress
parameter_list|)
block|{
name|DefaultImpersonationProvider
name|sip
init|=
name|ProxyUsers
operator|.
name|getDefaultImpersonationProvider
argument_list|()
decl_stmt|;
comment|// Just need to initialize the ProxyUsers for the first time, given that the conf will not change on the fly
if|if
condition|(
name|sip
operator|==
literal|null
condition|)
block|{
name|ProxyUsers
operator|.
name|refreshSuperUserGroupsConfiguration
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|sip
operator|=
name|ProxyUsers
operator|.
name|getDefaultImpersonationProvider
argument_list|()
expr_stmt|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|Collection
argument_list|<
name|String
argument_list|>
argument_list|>
name|proxyHosts
init|=
name|sip
operator|.
name|getProxyHosts
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|hostEntries
init|=
name|proxyHosts
operator|.
name|get
argument_list|(
name|sip
operator|.
name|getProxySuperuserIpConfKey
argument_list|(
name|user
argument_list|)
argument_list|)
decl_stmt|;
name|MachineList
name|machineList
init|=
operator|new
name|MachineList
argument_list|(
name|hostEntries
argument_list|)
decl_stmt|;
name|ipAddress
operator|=
operator|(
name|ipAddress
operator|==
literal|null
operator|)
condition|?
name|StringUtils
operator|.
name|EMPTY
else|:
name|ipAddress
expr_stmt|;
return|return
name|machineList
operator|.
name|includes
argument_list|(
name|ipAddress
argument_list|)
return|;
block|}
comment|/**    * Convert FieldSchemas to Thrift DDL.    */
specifier|public
specifier|static
name|String
name|getDDLFromFieldSchema
parameter_list|(
name|String
name|structName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|ddl
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|"struct "
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|structName
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|" { "
argument_list|)
expr_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|fieldSchemas
control|)
block|{
if|if
condition|(
name|first
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|ddl
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
name|ColumnType
operator|.
name|typeToThriftType
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|' '
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"DDL: {}"
argument_list|,
name|ddl
argument_list|)
expr_stmt|;
return|return
name|ddl
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getTableMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getPartitionMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|partition
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|part
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get partition level schema from table level schema.    * This function will use the same column names, column types and partition keys for    * each partition Properties. Their values are copied from the table Properties. This    * is mainly to save CPU and memory. CPU is saved because the first time the    * StorageDescriptor column names are accessed, JDO needs to execute a SQL query to    * retrieve the data. If we know the data will be the same as the table level schema    * and they are immutable, we should just reuse the table level schema objects.    *    * @param sd The Partition level Storage Descriptor.    * @param parameters partition level parameters    * @param tblSchema The table level schema from which this partition should be copied.    * @return the properties    */
specifier|public
specifier|static
name|Properties
name|getPartSchemaFromTableSchema
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|Properties
name|tblSchema
parameter_list|)
block|{
comment|// Inherent most properties from table level schema and overwrite some properties
comment|// in the following code.
comment|// This is mainly for saving CPU and memory to reuse the column names, types and
comment|// partition columns in the table level schema.
name|Properties
name|schema
init|=
operator|(
name|Properties
operator|)
name|tblSchema
operator|.
name|clone
argument_list|()
decl_stmt|;
comment|// InputFormat
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblInput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblInput
operator|==
literal|null
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|inputFormat
operator|=
name|tblInput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
comment|// OutputFormat
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblOutput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblOutput
operator|==
literal|null
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|outputFormat
operator|=
name|tblOutput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
comment|// Location
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Bucket count
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|sd
operator|.
name|getBucketCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// SerdeInfo
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// We should not update the following 3 values if SerDeInfo contains these.
comment|// This is to keep backward compatible with getSchema(), where these 3 keys
comment|// are updated after SerDeInfo properties got copied.
name|String
name|cols
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
decl_stmt|;
name|String
name|colTypes
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
decl_stmt|;
name|String
name|parts
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|key
init|=
name|param
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|schema
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|!=
literal|null
operator|&&
operator|(
name|key
operator|.
name|equals
argument_list|(
name|cols
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|colTypes
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|parts
argument_list|)
operator|||
comment|// skip Druid properties which are used in DruidSerde, since they are also updated
comment|// after SerDeInfo properties are copied.
name|key
operator|.
name|startsWith
argument_list|(
literal|"druid."
argument_list|)
operator|)
condition|)
block|{
continue|continue;
block|}
name|schema
operator|.
name|put
argument_list|(
name|key
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
name|StringUtils
operator|.
name|EMPTY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// skipping columns since partition level field schemas are the same as table level's
comment|// skipping partition keys since it is the same as table level partition keys
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|private
specifier|static
name|Properties
name|addCols
parameter_list|(
name|Properties
name|schema
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
name|StringBuilder
name|colNameBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colTypeBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colComment
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|String
name|columnNameDelimiter
init|=
name|getColumnNameDelimiter
argument_list|(
name|cols
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|colNameBuf
operator|.
name|append
argument_list|(
name|columnNameDelimiter
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
expr_stmt|;
name|colComment
operator|.
name|append
argument_list|(
literal|'\0'
argument_list|)
expr_stmt|;
block|}
name|colNameBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
name|colComment
operator|.
name|append
argument_list|(
operator|(
literal|null
operator|!=
name|col
operator|.
name|getComment
argument_list|()
operator|)
condition|?
name|col
operator|.
name|getComment
argument_list|()
else|:
name|StringUtils
operator|.
name|EMPTY
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
argument_list|,
name|colNameBuf
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|COLUMN_NAME_DELIMITER
argument_list|,
name|columnNameDelimiter
argument_list|)
expr_stmt|;
name|String
name|colTypes
init|=
name|colTypeBuf
operator|.
name|toString
argument_list|()
decl_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
argument_list|,
name|colTypes
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
literal|"columns.comments"
argument_list|,
name|colComment
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchemaWithoutCols
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
name|Properties
name|schema
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_NAME
argument_list|,
name|databaseName
operator|+
literal|"."
operator|+
name|tableName
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|sd
operator|.
name|getBucketCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|put
argument_list|(
name|param
operator|.
name|getKey
argument_list|()
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
name|StringUtils
operator|.
name|EMPTY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|SERIALIZATION_DDL
argument_list|,
name|getDDLFromFieldSchema
argument_list|(
name|tableName
argument_list|,
name|sd
operator|.
name|getCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|partString
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
name|String
name|partStringSep
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
name|String
name|partTypesString
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
name|String
name|partTypesStringSep
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
for|for
control|(
name|FieldSchema
name|partKey
range|:
name|partitionKeys
control|)
block|{
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partStringSep
argument_list|)
expr_stmt|;
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|partTypesString
operator|=
name|partTypesString
operator|.
name|concat
argument_list|(
name|partTypesStringSep
argument_list|)
expr_stmt|;
name|partTypesString
operator|=
name|partTypesString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|partStringSep
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|partStringSep
operator|=
literal|"/"
expr_stmt|;
name|partTypesStringSep
operator|=
literal|":"
expr_stmt|;
block|}
block|}
if|if
condition|(
name|partString
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|,
name|partString
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMN_TYPES
argument_list|,
name|partTypesString
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// add non-null parameters to the schema
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
return|return
name|addCols
argument_list|(
name|getSchemaWithoutCols
argument_list|(
name|sd
argument_list|,
name|parameters
argument_list|,
name|databaseName
argument_list|,
name|tableName
argument_list|,
name|partitionKeys
argument_list|)
argument_list|,
name|tblsd
operator|.
name|getCols
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|getColumnNameDelimiter
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
comment|// we first take a look if any fieldSchemas contain COMMA
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
operator|.
name|contains
argument_list|(
literal|","
argument_list|)
condition|)
block|{
return|return
name|String
operator|.
name|valueOf
argument_list|(
name|ColumnType
operator|.
name|COLUMN_COMMENTS_DELIMITER
argument_list|)
return|;
block|}
block|}
return|return
name|String
operator|.
name|valueOf
argument_list|(
literal|','
argument_list|)
return|;
block|}
comment|/**    * Convert FieldSchemas to columnNames.    */
specifier|public
specifier|static
name|String
name|getColumnNamesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|String
name|delimiter
init|=
name|getColumnNameDelimiter
argument_list|(
name|fieldSchemas
argument_list|)
decl_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to columnTypes.    */
specifier|public
specifier|static
name|String
name|getColumnTypesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|String
name|getColumnCommentsFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|ColumnType
operator|.
name|COLUMN_COMMENTS_DELIMITER
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getComment
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|int
name|startMetaStore
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|startMetaStore
argument_list|(
name|HadoopThriftAuthBridge
operator|.
name|getBridge
argument_list|()
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|int
name|startMetaStore
parameter_list|(
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|port
init|=
name|findFreePort
argument_list|()
decl_stmt|;
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|,
name|conf
argument_list|)
expr_stmt|;
return|return
name|port
return|;
block|}
specifier|public
specifier|static
name|int
name|startMetaStore
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|startMetaStore
argument_list|(
name|HadoopThriftAuthBridge
operator|.
name|getBridge
argument_list|()
argument_list|,
name|conf
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|startMetaStore
parameter_list|(
specifier|final
name|int
name|port
parameter_list|,
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|)
throws|throws
name|Exception
block|{
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|startMetaStore
parameter_list|(
specifier|final
name|int
name|port
parameter_list|,
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|,
name|Configuration
name|hiveConf
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
name|hiveConf
operator|==
literal|null
condition|)
block|{
name|hiveConf
operator|=
name|MetastoreConf
operator|.
name|newMetastoreConf
argument_list|()
expr_stmt|;
block|}
specifier|final
name|Configuration
name|finalHiveConf
init|=
name|hiveConf
decl_stmt|;
name|Thread
name|thread
init|=
operator|new
name|Thread
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|HiveMetaStore
operator|.
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|,
name|finalHiveConf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Metastore Thrift Server threw an exception..."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|thread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|thread
operator|.
name|start
argument_list|()
expr_stmt|;
name|loopUntilHMSReady
argument_list|(
name|port
argument_list|)
expr_stmt|;
block|}
comment|/**    * A simple connect test to make sure that the metastore is up    * @throws Exception    */
specifier|private
specifier|static
name|void
name|loopUntilHMSReady
parameter_list|(
name|int
name|port
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|retries
init|=
literal|0
decl_stmt|;
name|Exception
name|exc
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
name|Socket
name|socket
init|=
operator|new
name|Socket
argument_list|()
decl_stmt|;
name|socket
operator|.
name|connect
argument_list|(
operator|new
name|InetSocketAddress
argument_list|(
name|port
argument_list|)
argument_list|,
literal|5000
argument_list|)
expr_stmt|;
name|socket
operator|.
name|close
argument_list|()
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|retries
operator|++
operator|>
literal|60
condition|)
block|{
comment|//give up
name|exc
operator|=
name|e
expr_stmt|;
break|break;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
block|}
comment|// something is preventing metastore from starting
comment|// print the stack from all threads for debugging purposes
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to connect to metastore server: "
operator|+
name|exc
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Printing all thread stack traces for debugging before throwing exception."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|getAllThreadStacksAsString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|exc
throw|;
block|}
specifier|private
specifier|static
name|String
name|getAllThreadStacksAsString
parameter_list|()
block|{
name|Map
argument_list|<
name|Thread
argument_list|,
name|StackTraceElement
index|[]
argument_list|>
name|threadStacks
init|=
name|Thread
operator|.
name|getAllStackTraces
argument_list|()
decl_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Thread
argument_list|,
name|StackTraceElement
index|[]
argument_list|>
name|entry
range|:
name|threadStacks
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Thread
name|t
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|System
operator|.
name|lineSeparator
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"Name: "
argument_list|)
operator|.
name|append
argument_list|(
name|t
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|" State: "
argument_list|)
operator|.
name|append
argument_list|(
name|t
operator|.
name|getState
argument_list|()
argument_list|)
expr_stmt|;
name|addStackString
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|sb
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
specifier|static
name|void
name|addStackString
parameter_list|(
name|StackTraceElement
index|[]
name|stackElems
parameter_list|,
name|StringBuilder
name|sb
parameter_list|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|System
operator|.
name|lineSeparator
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|StackTraceElement
name|stackElem
range|:
name|stackElems
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|stackElem
argument_list|)
operator|.
name|append
argument_list|(
name|System
operator|.
name|lineSeparator
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Finds a free port on the machine.    *    * @return    * @throws IOException    */
specifier|public
specifier|static
name|int
name|findFreePort
parameter_list|()
throws|throws
name|IOException
block|{
name|ServerSocket
name|socket
init|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|int
name|port
init|=
name|socket
operator|.
name|getLocalPort
argument_list|()
decl_stmt|;
name|socket
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|port
return|;
block|}
comment|/**    * Finds a free port on the machine, but allow the    * ability to specify a port number to not use, no matter what.    */
specifier|public
specifier|static
name|int
name|findFreePortExcepting
parameter_list|(
name|int
name|portToExclude
parameter_list|)
throws|throws
name|IOException
block|{
name|ServerSocket
name|socket1
init|=
literal|null
decl_stmt|;
name|ServerSocket
name|socket2
init|=
literal|null
decl_stmt|;
try|try
block|{
name|socket1
operator|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|socket2
operator|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|socket1
operator|.
name|getLocalPort
argument_list|()
operator|!=
name|portToExclude
condition|)
block|{
return|return
name|socket1
operator|.
name|getLocalPort
argument_list|()
return|;
block|}
comment|// If we're here, then socket1.getLocalPort was the port to exclude
comment|// Since both sockets were open together at a point in time, we're
comment|// guaranteed that socket2.getLocalPort() is not the same.
return|return
name|socket2
operator|.
name|getLocalPort
argument_list|()
return|;
block|}
finally|finally
block|{
if|if
condition|(
name|socket1
operator|!=
literal|null
condition|)
block|{
name|socket1
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|socket2
operator|!=
literal|null
condition|)
block|{
name|socket2
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|public
specifier|static
name|String
name|getIndexTableName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|baseTblName
parameter_list|,
name|String
name|indexName
parameter_list|)
block|{
return|return
name|dbName
operator|+
literal|"__"
operator|+
name|baseTblName
operator|+
literal|"_"
operator|+
name|indexName
operator|+
literal|"__"
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isMaterializedViewTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|MATERIALIZED_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getColumnNames
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|cols
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|schema
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fs
range|:
name|schema
control|)
block|{
name|cols
operator|.
name|add
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|cols
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isValidSchedulingPolicy
parameter_list|(
name|String
name|str
parameter_list|)
block|{
try|try
block|{
name|parseSchedulingPolicy
argument_list|(
name|str
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|ex
parameter_list|)
block|{     }
return|return
literal|false
return|;
block|}
specifier|public
specifier|static
name|WMPoolSchedulingPolicy
name|parseSchedulingPolicy
parameter_list|(
name|String
name|schedulingPolicy
parameter_list|)
block|{
if|if
condition|(
name|schedulingPolicy
operator|==
literal|null
condition|)
block|{
return|return
name|WMPoolSchedulingPolicy
operator|.
name|FAIR
return|;
block|}
name|schedulingPolicy
operator|=
name|schedulingPolicy
operator|.
name|trim
argument_list|()
operator|.
name|toUpperCase
argument_list|()
expr_stmt|;
if|if
condition|(
literal|"DEFAULT"
operator|.
name|equals
argument_list|(
name|schedulingPolicy
argument_list|)
condition|)
block|{
return|return
name|WMPoolSchedulingPolicy
operator|.
name|FAIR
return|;
block|}
return|return
name|Enum
operator|.
name|valueOf
argument_list|(
name|WMPoolSchedulingPolicy
operator|.
name|class
argument_list|,
name|schedulingPolicy
argument_list|)
return|;
block|}
comment|// ColumnStatisticsObj with info about its db, table, partition (if table is partitioned)
specifier|public
specifier|static
class|class
name|ColStatsObjWithSourceInfo
block|{
specifier|private
specifier|final
name|ColumnStatisticsObj
name|colStatsObj
decl_stmt|;
specifier|private
specifier|final
name|String
name|catName
decl_stmt|;
specifier|private
specifier|final
name|String
name|dbName
decl_stmt|;
specifier|private
specifier|final
name|String
name|tblName
decl_stmt|;
specifier|private
specifier|final
name|String
name|partName
decl_stmt|;
specifier|public
name|ColStatsObjWithSourceInfo
parameter_list|(
name|ColumnStatisticsObj
name|colStatsObj
parameter_list|,
name|String
name|catName
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|partName
parameter_list|)
block|{
name|this
operator|.
name|colStatsObj
operator|=
name|colStatsObj
expr_stmt|;
name|this
operator|.
name|catName
operator|=
name|catName
expr_stmt|;
name|this
operator|.
name|dbName
operator|=
name|dbName
expr_stmt|;
name|this
operator|.
name|tblName
operator|=
name|tblName
expr_stmt|;
name|this
operator|.
name|partName
operator|=
name|partName
expr_stmt|;
block|}
specifier|public
name|ColumnStatisticsObj
name|getColStatsObj
parameter_list|()
block|{
return|return
name|colStatsObj
return|;
block|}
specifier|public
name|String
name|getCatName
parameter_list|()
block|{
return|return
name|catName
return|;
block|}
specifier|public
name|String
name|getDbName
parameter_list|()
block|{
return|return
name|dbName
return|;
block|}
specifier|public
name|String
name|getTblName
parameter_list|()
block|{
return|return
name|tblName
return|;
block|}
specifier|public
name|String
name|getPartName
parameter_list|()
block|{
return|return
name|partName
return|;
block|}
block|}
specifier|private
specifier|static
name|boolean
name|hasCatalogName
parameter_list|(
name|String
name|dbName
parameter_list|)
block|{
return|return
name|dbName
operator|!=
literal|null
operator|&&
name|dbName
operator|.
name|length
argument_list|()
operator|>
literal|0
operator|&&
name|dbName
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
operator|==
name|CATALOG_DB_THRIFT_NAME_MARKER
return|;
block|}
comment|/**    * Given a catalog name and database name cram them together into one string.  This method can    * be used if you do not know the catalog name, in which case the default catalog will be    * retrieved from the conf object.  The resulting string can be parsed apart again via    * {@link #parseDbName(String, Configuration)}.    * @param catalogName catalog name, can be null if no known.    * @param dbName database name, can be null or empty.    * @param conf configuration object, used to determine default catalog if catalogName is null    * @return one string that contains both.    */
specifier|public
specifier|static
name|String
name|prependCatalogToDbName
parameter_list|(
annotation|@
name|Nullable
name|String
name|catalogName
parameter_list|,
annotation|@
name|Nullable
name|String
name|dbName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|catalogName
operator|==
literal|null
condition|)
name|catalogName
operator|=
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|StringBuilder
name|buf
init|=
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
name|CATALOG_DB_THRIFT_NAME_MARKER
argument_list|)
operator|.
name|append
argument_list|(
name|catalogName
argument_list|)
operator|.
name|append
argument_list|(
name|CATALOG_DB_SEPARATOR
argument_list|)
decl_stmt|;
if|if
condition|(
name|dbName
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|dbName
operator|.
name|isEmpty
argument_list|()
condition|)
name|buf
operator|.
name|append
argument_list|(
name|DB_EMPTY_MARKER
argument_list|)
expr_stmt|;
else|else
name|buf
operator|.
name|append
argument_list|(
name|dbName
argument_list|)
expr_stmt|;
block|}
return|return
name|buf
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Given a catalog name and database name, cram them together into one string.  These can be    * parsed apart again via {@link #parseDbName(String, Configuration)}.    * @param catalogName catalog name.  This cannot be null.  If this might be null use    *                    {@link #prependCatalogToDbName(String, String, Configuration)} instead.    * @param dbName database name.    * @return one string that contains both.    */
specifier|public
specifier|static
name|String
name|prependNotNullCatToDbName
parameter_list|(
name|String
name|catalogName
parameter_list|,
name|String
name|dbName
parameter_list|)
block|{
assert|assert
name|catalogName
operator|!=
literal|null
assert|;
return|return
name|prependCatalogToDbName
argument_list|(
name|catalogName
argument_list|,
name|dbName
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Prepend the default 'hive' catalog onto the database name.    * @param dbName database name    * @param conf configuration object, used to determine default catalog    * @return one string with the 'hive' catalog name prepended.    */
specifier|public
specifier|static
name|String
name|prependCatalogToDbName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|prependCatalogToDbName
argument_list|(
literal|null
argument_list|,
name|dbName
argument_list|,
name|conf
argument_list|)
return|;
block|}
specifier|private
specifier|final
specifier|static
name|String
index|[]
name|nullCatalogAndDatabase
init|=
block|{
literal|null
block|,
literal|null
block|}
decl_stmt|;
comment|/**    * Parse the catalog name out of the database name.  If no catalog name is present then the    * default catalog (as set in configuration file) will be assumed.    * @param dbName name of the database.  This may or may not contain the catalog name.    * @param conf configuration object, used to determine the default catalog if it is not present    *            in the database name.    * @return an array of two elements, the first being the catalog name, the second the database    * name.    * @throws MetaException if the name is not either just a database name or a catalog plus    * database name with the proper delimiters.    */
specifier|public
specifier|static
name|String
index|[]
name|parseDbName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|dbName
operator|==
literal|null
condition|)
return|return
name|nullCatalogAndDatabase
return|;
if|if
condition|(
name|hasCatalogName
argument_list|(
name|dbName
argument_list|)
condition|)
block|{
if|if
condition|(
name|dbName
operator|.
name|endsWith
argument_list|(
name|CATALOG_DB_SEPARATOR
argument_list|)
condition|)
block|{
comment|// This means the DB name is null
return|return
operator|new
name|String
index|[]
block|{
name|dbName
operator|.
name|substring
argument_list|(
literal|1
argument_list|,
name|dbName
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
block|,
literal|null
block|}
return|;
block|}
elseif|else
if|if
condition|(
name|dbName
operator|.
name|endsWith
argument_list|(
name|DB_EMPTY_MARKER
argument_list|)
condition|)
block|{
comment|// This means the DB name is empty
return|return
operator|new
name|String
index|[]
block|{
name|dbName
operator|.
name|substring
argument_list|(
literal|1
argument_list|,
name|dbName
operator|.
name|length
argument_list|()
operator|-
name|DB_EMPTY_MARKER
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
block|,
literal|""
block|}
return|;
block|}
name|String
index|[]
name|names
init|=
name|dbName
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
operator|.
name|split
argument_list|(
name|CATALOG_DB_SEPARATOR
argument_list|,
literal|2
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
name|dbName
operator|+
literal|" is prepended with the catalog marker but does not "
operator|+
literal|"appear to have a catalog name in it"
argument_list|)
throw|;
block|}
return|return
name|names
return|;
block|}
else|else
block|{
return|return
operator|new
name|String
index|[]
block|{
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
block|,
name|dbName
block|}
return|;
block|}
block|}
comment|/**    * Position in the array returned by {@link #parseDbName} that has the catalog name.    */
specifier|public
specifier|static
specifier|final
name|int
name|CAT_NAME
init|=
literal|0
decl_stmt|;
comment|/**    * Position in the array returned by {@link #parseDbName} that has the database name.    */
specifier|public
specifier|static
specifier|final
name|int
name|DB_NAME
init|=
literal|1
decl_stmt|;
specifier|public
specifier|static
name|String
name|getDefaultCatalog
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Configuration is null, so going with default catalog."
argument_list|)
expr_stmt|;
return|return
name|Warehouse
operator|.
name|DEFAULT_CATALOG_NAME
return|;
block|}
name|String
name|catName
init|=
name|MetastoreConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|CATALOG_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
name|catName
operator|==
literal|null
operator|||
literal|""
operator|.
name|equals
argument_list|(
name|catName
argument_list|)
condition|)
name|catName
operator|=
name|Warehouse
operator|.
name|DEFAULT_CATALOG_NAME
expr_stmt|;
return|return
name|catName
return|;
block|}
specifier|public
specifier|static
class|class
name|FullTableName
block|{
specifier|public
specifier|final
name|String
name|catalog
decl_stmt|,
name|db
decl_stmt|,
name|table
decl_stmt|;
specifier|public
name|FullTableName
parameter_list|(
name|String
name|catalog
parameter_list|,
name|String
name|db
parameter_list|,
name|String
name|table
parameter_list|)
block|{
assert|assert
name|catalog
operator|!=
literal|null
operator|&&
name|db
operator|!=
literal|null
operator|&&
name|table
operator|!=
literal|null
operator|:
name|catalog
operator|+
literal|", "
operator|+
name|db
operator|+
literal|", "
operator|+
name|table
assert|;
name|this
operator|.
name|catalog
operator|=
name|catalog
expr_stmt|;
name|this
operator|.
name|db
operator|=
name|db
expr_stmt|;
name|this
operator|.
name|table
operator|=
name|table
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|catalog
operator|+
name|MetaStoreUtils
operator|.
name|CATALOG_DB_SEPARATOR
operator|+
name|db
operator|+
literal|"."
operator|+
name|table
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
specifier|final
name|int
name|prime
init|=
literal|31
decl_stmt|;
return|return
name|prime
operator|*
operator|(
name|prime
operator|*
operator|(
name|prime
operator|+
name|catalog
operator|.
name|hashCode
argument_list|()
operator|)
operator|+
name|db
operator|.
name|hashCode
argument_list|()
operator|)
operator|+
name|table
operator|.
name|hashCode
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|obj
parameter_list|)
block|{
if|if
condition|(
name|this
operator|==
name|obj
condition|)
return|return
literal|true
return|;
if|if
condition|(
name|obj
operator|==
literal|null
operator|||
name|getClass
argument_list|()
operator|!=
name|obj
operator|.
name|getClass
argument_list|()
condition|)
return|return
literal|false
return|;
name|FullTableName
name|other
init|=
operator|(
name|FullTableName
operator|)
name|obj
decl_stmt|;
return|return
name|catalog
operator|.
name|equals
argument_list|(
name|other
operator|.
name|catalog
argument_list|)
operator|&&
name|db
operator|.
name|equals
argument_list|(
name|other
operator|.
name|db
argument_list|)
operator|&&
name|table
operator|.
name|equals
argument_list|(
name|other
operator|.
name|table
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

