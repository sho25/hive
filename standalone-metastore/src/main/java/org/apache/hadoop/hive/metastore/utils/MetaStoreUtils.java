begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *<p>  * http://www.apache.org/licenses/LICENSE-2.0  *<p>  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Predicates
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|ListUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|CollectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeysPublic
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|StatsSetupConst
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ColumnType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ColumnStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ColumnStatisticsObj
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Decimal
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|EnvironmentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Order
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SerDeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SkewedInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|aggr
operator|.
name|ColumnStatsAggregator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|aggr
operator|.
name|ColumnStatsAggregatorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|merge
operator|.
name|ColumnStatsMerger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|columnstats
operator|.
name|merge
operator|.
name|ColumnStatsMergerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|events
operator|.
name|EventCleanerTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|partition
operator|.
name|spec
operator|.
name|PartitionSpecProxy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|security
operator|.
name|HadoopThriftAuthBridge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SaslRpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|authorize
operator|.
name|DefaultImpersonationProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|authorize
operator|.
name|ProxyUsers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|MachineList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|math
operator|.
name|BigDecimal
import|;
end_import

begin_import
import|import
name|java
operator|.
name|math
operator|.
name|BigInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLClassLoader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|Charset
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|MessageDigest
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|DateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|SimpleDateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_class
specifier|public
class|class
name|MetaStoreUtils
block|{
comment|/** A fixed date format to be used for hive partition column values. */
specifier|public
specifier|static
specifier|final
name|ThreadLocal
argument_list|<
name|DateFormat
argument_list|>
name|PARTITION_DATE_FORMAT
init|=
operator|new
name|ThreadLocal
argument_list|<
name|DateFormat
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|DateFormat
name|initialValue
parameter_list|()
block|{
name|DateFormat
name|val
init|=
operator|new
name|SimpleDateFormat
argument_list|(
literal|"yyyy-MM-dd"
argument_list|)
decl_stmt|;
name|val
operator|.
name|setLenient
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// Without this, 2020-20-20 becomes 2021-08-20.
return|return
name|val
return|;
block|}
block|}
decl_stmt|;
comment|// Indicates a type was derived from the deserializer rather than Hive's metadata.
specifier|public
specifier|static
specifier|final
name|String
name|TYPE_FROM_DESERIALIZER
init|=
literal|"<derived from deserializer>"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Charset
name|ENCODING
init|=
name|StandardCharsets
operator|.
name|UTF_8
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MetaStoreUtils
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// Right now we only support one special character '/'.
comment|// More special characters can be added accordingly in the future.
comment|// NOTE:
comment|// If the following array is updated, please also be sure to update the
comment|// configuration parameter documentation
comment|// HIVE_SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES in HiveConf as well.
specifier|private
specifier|static
specifier|final
name|char
index|[]
name|specialCharactersInTableNames
init|=
operator|new
name|char
index|[]
block|{
literal|'/'
block|}
decl_stmt|;
comment|/**    * Catches exceptions that can't be handled and bundles them to MetaException    *    * @param e exception to wrap.    * @throws MetaException wrapper for the exception    */
specifier|public
specifier|static
name|void
name|logAndThrowMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|exInfo
init|=
literal|"Got exception: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|exInfo
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Converting exception to MetaException"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|exInfo
argument_list|)
throw|;
block|}
specifier|public
specifier|static
name|String
name|encodeTableName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
comment|// The encoding method is simple, e.g., replace
comment|// all the special characters with the corresponding number in ASCII.
comment|// Note that unicode is not supported in table names. And we have explicit
comment|// checks for it.
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|char
name|ch
range|:
name|name
operator|.
name|toCharArray
argument_list|()
control|)
block|{
if|if
condition|(
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|ch
argument_list|)
operator|||
name|ch
operator|==
literal|'_'
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|ch
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|'-'
argument_list|)
operator|.
name|append
argument_list|(
operator|(
name|int
operator|)
name|ch
argument_list|)
operator|.
name|append
argument_list|(
literal|'-'
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * convert Exception to MetaException, which sets the cause to such exception    * @param e cause of the exception    * @return  the MetaException with the specified exception as the cause    */
specifier|public
specifier|static
name|MetaException
name|newMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
return|return
name|newMetaException
argument_list|(
name|e
operator|!=
literal|null
condition|?
name|e
operator|.
name|getMessage
argument_list|()
else|:
literal|null
argument_list|,
name|e
argument_list|)
return|;
block|}
comment|/**    * convert Exception to MetaException, which sets the cause to such exception    * @param errorMessage  the error message for this MetaException    * @param e             cause of the exception    * @return  the MetaException with the specified exception as the cause    */
specifier|public
specifier|static
name|MetaException
name|newMetaException
parameter_list|(
name|String
name|errorMessage
parameter_list|,
name|Exception
name|e
parameter_list|)
block|{
name|MetaException
name|metaException
init|=
operator|new
name|MetaException
argument_list|(
name|errorMessage
argument_list|)
decl_stmt|;
if|if
condition|(
name|e
operator|!=
literal|null
condition|)
block|{
name|metaException
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|metaException
return|;
block|}
comment|/**    * Helper function to transform Nulls to empty strings.    */
specifier|private
specifier|static
specifier|final
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|transFormNullsToEmptyString
init|=
operator|new
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|java
operator|.
name|lang
operator|.
name|String
name|apply
parameter_list|(
annotation|@
name|Nullable
name|java
operator|.
name|lang
operator|.
name|String
name|string
parameter_list|)
block|{
return|return
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|defaultString
argument_list|(
name|string
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * We have a need to sanity-check the map before conversion from persisted objects to    * metadata thrift objects because null values in maps will cause a NPE if we send    * across thrift. Pruning is appropriate for most cases except for databases such as    * Oracle where Empty strings are stored as nulls, in which case we need to handle that.    * See HIVE-8485 for motivations for this.    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|trimMapNulls
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|dnMap
parameter_list|,
name|boolean
name|retrieveMapNullsAsEmptyStrings
parameter_list|)
block|{
if|if
condition|(
name|dnMap
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Must be deterministic order map - see HIVE-8707
comment|//   => we use Maps.newLinkedHashMap instead of Maps.newHashMap
if|if
condition|(
name|retrieveMapNullsAsEmptyStrings
condition|)
block|{
comment|// convert any nulls present in map values to empty strings - this is done in the case
comment|// of backing dbs like oracle which persist empty strings as nulls.
return|return
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|Maps
operator|.
name|transformValues
argument_list|(
name|dnMap
argument_list|,
name|transFormNullsToEmptyString
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// prune any nulls present in map values - this is the typical case.
return|return
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|Maps
operator|.
name|filterValues
argument_list|(
name|dnMap
argument_list|,
name|Predicates
operator|.
name|notNull
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|// given a list of partStats, this function will give you an aggr stats
specifier|public
specifier|static
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|aggrPartitionStats
parameter_list|(
name|List
argument_list|<
name|ColumnStatistics
argument_list|>
name|partStats
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|colNames
parameter_list|,
name|boolean
name|useDensityFunctionForNDVEstimation
parameter_list|,
name|double
name|ndvTuner
parameter_list|)
throws|throws
name|MetaException
block|{
comment|// 1. group by the stats by colNames
comment|// map the colName to List<ColumnStatistics>
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|ColumnStatistics
argument_list|>
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|ColumnStatistics
name|css
range|:
name|partStats
control|)
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|objs
init|=
name|css
operator|.
name|getStatsObj
argument_list|()
decl_stmt|;
for|for
control|(
name|ColumnStatisticsObj
name|obj
range|:
name|objs
control|)
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|singleObj
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|singleObj
operator|.
name|add
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|ColumnStatistics
name|singleCS
init|=
operator|new
name|ColumnStatistics
argument_list|(
name|css
operator|.
name|getStatsDesc
argument_list|()
argument_list|,
name|singleObj
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|map
operator|.
name|containsKey
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|)
condition|)
block|{
name|map
operator|.
name|put
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|map
operator|.
name|get
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|)
operator|.
name|add
argument_list|(
name|singleCS
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|aggrPartitionStats
argument_list|(
name|map
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partNames
argument_list|,
name|colNames
argument_list|,
name|useDensityFunctionForNDVEstimation
argument_list|,
name|ndvTuner
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|aggrPartitionStats
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|ColumnStatistics
argument_list|>
argument_list|>
name|map
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|colNames
parameter_list|,
specifier|final
name|boolean
name|useDensityFunctionForNDVEstimation
parameter_list|,
specifier|final
name|double
name|ndvTuner
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|colStats
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// 2. Aggregate stats for each column in a separate thread
if|if
condition|(
name|map
operator|.
name|size
argument_list|()
operator|<
literal|1
condition|)
block|{
comment|//stats are absent in RDBMS
name|LOG
operator|.
name|debug
argument_list|(
literal|"No stats data found for: dbName="
operator|+
name|dbName
operator|+
literal|" tblName="
operator|+
name|tableName
operator|+
literal|" partNames= "
operator|+
name|partNames
operator|+
literal|" colNames="
operator|+
name|colNames
argument_list|)
expr_stmt|;
return|return
name|colStats
return|;
block|}
specifier|final
name|ExecutorService
name|pool
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|map
operator|.
name|size
argument_list|()
argument_list|,
literal|16
argument_list|)
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"aggr-col-stats-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|>
name|futures
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
for|for
control|(
specifier|final
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|ColumnStatistics
argument_list|>
argument_list|>
name|entry
range|:
name|map
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|futures
operator|.
name|add
argument_list|(
name|pool
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|ColumnStatisticsObj
name|call
parameter_list|()
throws|throws
name|Exception
block|{
name|List
argument_list|<
name|ColumnStatistics
argument_list|>
name|css
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|ColumnStatsAggregator
name|aggregator
init|=
name|ColumnStatsAggregatorFactory
operator|.
name|getColumnStatsAggregator
argument_list|(
name|css
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
operator|.
name|getStatsObj
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
operator|.
name|getStatsData
argument_list|()
operator|.
name|getSetField
argument_list|()
argument_list|,
name|useDensityFunctionForNDVEstimation
argument_list|,
name|ndvTuner
argument_list|)
decl_stmt|;
name|ColumnStatisticsObj
name|statsObj
init|=
name|aggregator
operator|.
name|aggregate
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|partNames
argument_list|,
name|css
argument_list|)
decl_stmt|;
return|return
name|statsObj
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|Future
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
name|colStats
operator|.
name|add
argument_list|(
name|future
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|ExecutionException
name|e
parameter_list|)
block|{
name|pool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Time for aggr col stats in seconds: {} Threads used: {}"
argument_list|,
operator|(
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
operator|(
name|double
operator|)
name|start
operator|)
operator|)
operator|/
literal|1000
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|map
operator|.
name|size
argument_list|()
argument_list|,
literal|16
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|colStats
return|;
block|}
specifier|public
specifier|static
name|double
name|decimalToDouble
parameter_list|(
name|Decimal
name|decimal
parameter_list|)
block|{
return|return
operator|new
name|BigDecimal
argument_list|(
operator|new
name|BigInteger
argument_list|(
name|decimal
operator|.
name|getUnscaled
argument_list|()
argument_list|)
argument_list|,
name|decimal
operator|.
name|getScale
argument_list|()
argument_list|)
operator|.
name|doubleValue
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|String
index|[]
name|getQualifiedName
parameter_list|(
name|String
name|defaultDbName
parameter_list|,
name|String
name|tableName
parameter_list|)
block|{
name|String
index|[]
name|names
init|=
name|tableName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|length
operator|==
literal|1
condition|)
block|{
return|return
operator|new
name|String
index|[]
block|{
name|defaultDbName
block|,
name|tableName
block|}
return|;
block|}
return|return
name|names
return|;
block|}
specifier|public
specifier|static
name|void
name|validatePartitionNameCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|invalidPartitionVal
init|=
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
decl_stmt|;
if|if
condition|(
name|invalidPartitionVal
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Partition value '"
operator|+
name|invalidPartitionVal
operator|+
literal|"' contains a character "
operator|+
literal|"not matched by whitelist pattern '"
operator|+
name|partitionValidationPattern
operator|.
name|toString
argument_list|()
operator|+
literal|"'.  "
operator|+
literal|"(configure with "
operator|+
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|PARTITION_NAME_WHITELIST_PATTERN
operator|.
name|getVarname
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|String
name|getPartitionValWithInvalidCharacter
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
if|if
condition|(
name|partitionValidationPattern
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|partVal
range|:
name|partVals
control|)
block|{
if|if
condition|(
operator|!
name|partitionValidationPattern
operator|.
name|matcher
argument_list|(
name|partVal
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
name|partVal
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Produce a hash for the storage descriptor    * @param sd storage descriptor to hash    * @param md message descriptor to use to generate the hash    * @return the hash as a byte array    */
specifier|public
specifier|static
name|byte
index|[]
name|hashStorageDescriptor
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|MessageDigest
name|md
parameter_list|)
block|{
comment|// Note all maps and lists have to be absolutely sorted.  Otherwise we'll produce different
comment|// results for hashes based on the OS or JVM being used.
name|md
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// In case cols are null
if|if
condition|(
name|sd
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FieldSchema
name|fs
range|:
name|sd
operator|.
name|getCols
argument_list|()
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|fs
operator|.
name|getType
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|getComment
argument_list|()
operator|!=
literal|null
condition|)
name|md
operator|.
name|update
argument_list|(
name|fs
operator|.
name|getComment
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|isCompressed
argument_list|()
condition|?
literal|"true"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
else|:
literal|"false"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SerDeInfo
name|serde
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|serde
operator|.
name|getName
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|serde
operator|.
name|getName
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serde
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|md
operator|.
name|update
argument_list|(
name|serde
operator|.
name|getSerializationLib
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serde
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|serde
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|params
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|param
operator|.
name|getKey
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|param
operator|.
name|getValue
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|sd
operator|.
name|getBucketCols
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|bucket
range|:
name|bucketCols
control|)
name|md
operator|.
name|update
argument_list|(
name|bucket
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSortCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedSet
argument_list|<
name|Order
argument_list|>
name|orders
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|sd
operator|.
name|getSortCols
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Order
name|order
range|:
name|orders
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|order
operator|.
name|getCol
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|Integer
operator|.
name|toString
argument_list|(
name|order
operator|.
name|getOrder
argument_list|()
argument_list|)
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getSkewedInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SkewedInfo
name|skewed
init|=
name|sd
operator|.
name|getSkewedInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|skewed
operator|.
name|getSkewedColNames
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|colnames
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|skewed
operator|.
name|getSkewedColNames
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|colname
range|:
name|colnames
control|)
name|md
operator|.
name|update
argument_list|(
name|colname
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|skewed
operator|.
name|getSkewedColValues
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|sortedOuterList
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|String
argument_list|>
name|innerList
range|:
name|skewed
operator|.
name|getSkewedColValues
argument_list|()
control|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|sortedInnerList
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|innerList
argument_list|)
decl_stmt|;
name|sortedOuterList
operator|.
name|add
argument_list|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|join
argument_list|(
name|sortedInnerList
argument_list|,
literal|"."
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|colval
range|:
name|sortedOuterList
control|)
name|md
operator|.
name|update
argument_list|(
name|colval
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|skewed
operator|.
name|getSkewedColValueLocationMaps
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SortedMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|sortedMap
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|smap
range|:
name|skewed
operator|.
name|getSkewedColValueLocationMaps
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|sortedKey
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|smap
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|sortedMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|join
argument_list|(
name|sortedKey
argument_list|,
literal|"."
argument_list|)
argument_list|,
name|smap
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|sortedMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|md
operator|.
name|update
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
name|md
operator|.
name|update
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|md
operator|.
name|update
argument_list|(
name|sd
operator|.
name|isStoredAsSubDirectories
argument_list|()
condition|?
literal|"true"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
else|:
literal|"false"
operator|.
name|getBytes
argument_list|(
name|ENCODING
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|md
operator|.
name|digest
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getColumnNamesForTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|colsIterator
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getColsIterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|colsIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|colsIterator
operator|.
name|next
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|colNames
return|;
block|}
comment|/**    * validateName    *    * Checks the name conforms to our standars which are: "[a-zA-z_0-9]+". checks    * this is just characters and numbers and _    *    * @param name    *          the name to validate    * @param conf    *          hive configuration    * @return true or false depending on conformance    *              if it doesn't match the pattern.    */
specifier|public
specifier|static
name|boolean
name|validateName
parameter_list|(
name|String
name|name
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|Pattern
name|tpat
decl_stmt|;
name|String
name|allowedCharacters
init|=
literal|"\\w_"
decl_stmt|;
if|if
condition|(
name|conf
operator|!=
literal|null
operator|&&
name|MetastoreConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES
argument_list|)
condition|)
block|{
for|for
control|(
name|Character
name|c
range|:
name|specialCharactersInTableNames
control|)
block|{
name|allowedCharacters
operator|+=
name|c
expr_stmt|;
block|}
block|}
name|tpat
operator|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"["
operator|+
name|allowedCharacters
operator|+
literal|"]+"
argument_list|)
expr_stmt|;
name|Matcher
name|m
init|=
name|tpat
operator|.
name|matcher
argument_list|(
name|name
argument_list|)
decl_stmt|;
return|return
name|m
operator|.
name|matches
argument_list|()
return|;
block|}
comment|/*    * At the Metadata level there are no restrictions on Column Names.    */
specifier|public
specifier|static
name|boolean
name|validateColumnName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
specifier|static
specifier|public
name|String
name|validateTblColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
comment|// skip this, as validateColumnName always returns true
comment|/*       if (!validateColumnName(fieldSchema.getName())) {         return "name: " + fieldSchema.getName();       }       */
name|String
name|typeError
init|=
name|validateColumnType
argument_list|(
name|fieldSchema
operator|.
name|getType
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeError
operator|!=
literal|null
condition|)
block|{
return|return
name|typeError
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|private
specifier|static
name|String
name|validateColumnType
parameter_list|(
name|String
name|type
parameter_list|)
block|{
if|if
condition|(
name|type
operator|.
name|equals
argument_list|(
name|TYPE_FROM_DESERIALIZER
argument_list|)
condition|)
return|return
literal|null
return|;
name|int
name|last
init|=
literal|0
decl_stmt|;
name|boolean
name|lastAlphaDigit
init|=
name|isValidTypeChar
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|last
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|type
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|type
operator|.
name|length
argument_list|()
operator|||
name|isValidTypeChar
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|!=
name|lastAlphaDigit
condition|)
block|{
name|String
name|token
init|=
name|type
operator|.
name|substring
argument_list|(
name|last
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|last
operator|=
name|i
expr_stmt|;
if|if
condition|(
operator|!
name|ColumnType
operator|.
name|AllTypes
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
return|return
literal|"type: "
operator|+
name|type
return|;
block|}
break|break;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isValidTypeChar
parameter_list|(
name|char
name|c
parameter_list|)
block|{
return|return
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|c
argument_list|)
operator|||
name|c
operator|==
literal|'_'
return|;
block|}
comment|/**    * Determines whether a table is an external table.    *    * @param table table of interest    *    * @return true if external    */
specifier|public
specifier|static
name|boolean
name|isExternalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
literal|"EXTERNAL"
argument_list|)
argument_list|)
return|;
block|}
comment|// check if stats need to be (re)calculated
specifier|public
specifier|static
name|boolean
name|requireCalStats
parameter_list|(
name|Configuration
name|hiveConf
parameter_list|,
name|Partition
name|oldPart
parameter_list|,
name|Partition
name|newPart
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
block|{
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TRUE
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|isView
argument_list|(
name|tbl
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|oldPart
operator|==
literal|null
operator|&&
name|newPart
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// requires to calculate stats if new partition doesn't have it
if|if
condition|(
operator|(
name|newPart
operator|==
literal|null
operator|)
operator|||
operator|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|==
literal|null
operator|)
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|newPart
operator|.
name|getParameters
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
condition|)
block|{
name|String
name|statsType
init|=
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
decl_stmt|;
comment|// no matter STATS_GENERATED is USER or TASK, all need to re-calculate the stats:
comment|// USER: alter table .. update statistics
comment|// TASK: from some sql operation which could collect and compute stats
if|if
condition|(
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|statsType
argument_list|)
operator|||
name|StatsSetupConst
operator|.
name|USER
operator|.
name|equals
argument_list|(
name|statsType
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
comment|// requires to calculate stats if new and old have different fast stats
return|return
operator|!
name|isFastStatsSame
argument_list|(
name|oldPart
argument_list|,
name|newPart
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isView
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param partParams    * @return True if the passed Parameters Map contains values for all "Fast Stats".    */
specifier|private
specifier|static
name|boolean
name|containsAllFastStats
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partParams
parameter_list|)
block|{
for|for
control|(
name|String
name|stat
range|:
name|StatsSetupConst
operator|.
name|fastStats
control|)
block|{
if|if
condition|(
operator|!
name|partParams
operator|.
name|containsKey
argument_list|(
name|stat
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isFastStatsSame
parameter_list|(
name|Partition
name|oldPart
parameter_list|,
name|Partition
name|newPart
parameter_list|)
block|{
comment|// requires to calculate stats if new and old have different fast stats
if|if
condition|(
operator|(
name|oldPart
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
operator|)
condition|)
block|{
for|for
control|(
name|String
name|stat
range|:
name|StatsSetupConst
operator|.
name|fastStats
control|)
block|{
if|if
condition|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|.
name|containsKey
argument_list|(
name|stat
argument_list|)
condition|)
block|{
name|Long
name|oldStat
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|stat
argument_list|)
argument_list|)
decl_stmt|;
name|Long
name|newStat
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|stat
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|oldStat
operator|.
name|equals
argument_list|(
name|newStat
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updateTableStatsFast
parameter_list|(
name|Database
name|db
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updateTableStatsFast
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updateTableStatsFast
parameter_list|(
name|Database
name|db
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|tbl
operator|.
name|getPartitionKeysSize
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// Update stats only when unpartitioned
name|FileStatus
index|[]
name|fileStatuses
init|=
name|wh
operator|.
name|getFileStatusesForUnpartitionedTable
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
return|return
name|updateTableStatsFast
argument_list|(
name|tbl
argument_list|,
name|fileStatuses
argument_list|,
name|madeDir
argument_list|,
name|forceRecompute
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Table by querying    * the warehouse if the passed Table does not already have values for these parameters.    * @param tbl    * @param fileStatus    * @param newDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Table already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updateTableStatsFast
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|FileStatus
index|[]
name|fileStatus
parameter_list|,
name|boolean
name|newDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|tbl
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|params
operator|!=
literal|null
operator|)
operator|&&
name|params
operator|.
name|containsKey
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
condition|)
block|{
name|boolean
name|doNotUpdateStats
init|=
name|Boolean
operator|.
name|valueOf
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
argument_list|)
decl_stmt|;
name|params
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
comment|// to make sure we remove this marker property
if|if
condition|(
name|doNotUpdateStats
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
name|boolean
name|updated
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|forceRecompute
operator|||
name|params
operator|==
literal|null
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|params
argument_list|)
condition|)
block|{
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
name|params
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|newDir
condition|)
block|{
comment|// The table location already exists and may contain data.
comment|// Let's try to populate those stats that don't require full scan.
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating table stats fast for "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|populateQuickStats
argument_list|(
name|fileStatus
argument_list|,
name|params
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated size of table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" to "
operator|+
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
block|}
name|tbl
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
name|updated
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|updated
return|;
block|}
specifier|public
specifier|static
name|void
name|populateQuickStats
parameter_list|(
name|FileStatus
index|[]
name|fileStatus
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|int
name|numFiles
init|=
literal|0
decl_stmt|;
name|long
name|tableSize
init|=
literal|0L
decl_stmt|;
for|for
control|(
name|FileStatus
name|status
range|:
name|fileStatus
control|)
block|{
comment|// don't take directories into account for quick stats
if|if
condition|(
operator|!
name|status
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|tableSize
operator|+=
name|status
operator|.
name|getLen
argument_list|()
expr_stmt|;
name|numFiles
operator|+=
literal|1
expr_stmt|;
block|}
block|}
name|params
operator|.
name|put
argument_list|(
name|StatsSetupConst
operator|.
name|NUM_FILES
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|numFiles
argument_list|)
argument_list|)
expr_stmt|;
name|params
operator|.
name|put
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|tableSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|boolean
name|areSameColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
block|{
return|return
name|ListUtils
operator|.
name|isEqualList
argument_list|(
name|oldCols
argument_list|,
name|newCols
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|updateBasicState
parameter_list|(
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
name|part
argument_list|,
name|wh
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
name|part
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Partition by querying    *  the warehouse if the passed Partition does not already have values for these parameters.    * @param part    * @param wh    * @param madeDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Partition already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
operator|new
name|PartitionSpecProxy
operator|.
name|SimplePartitionWrapperIterator
argument_list|(
name|part
argument_list|)
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
name|forceRecompute
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Partition by querying    *  the warehouse if the passed Partition does not already have values for these parameters.    * @param part    * @param wh    * @param madeDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Partition already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|PartitionSpecProxy
operator|.
name|PartitionIterator
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
name|boolean
name|updated
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|forceRecompute
operator|||
name|params
operator|==
literal|null
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|params
argument_list|)
condition|)
block|{
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
name|params
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|madeDir
condition|)
block|{
comment|// The partition location already existed and may contain data. Lets try to
comment|// populate those statistics that don't require a full scan of the data.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Updating partition stats fast for: "
operator|+
name|part
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|fileStatus
init|=
name|wh
operator|.
name|getFileStatusesForLocation
argument_list|(
name|part
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
name|populateQuickStats
argument_list|(
name|fileStatus
argument_list|,
name|params
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Updated size to "
operator|+
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|updateBasicState
argument_list|(
name|environmentContext
argument_list|,
name|params
argument_list|)
expr_stmt|;
block|}
name|part
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
name|updated
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|updated
return|;
block|}
comment|/*      * This method is to check if the new column list includes all the old columns with same name and      * type. The column comment does not count.      */
specifier|public
specifier|static
name|boolean
name|columnsIncludedByNameType
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
block|{
if|if
condition|(
name|oldCols
operator|.
name|size
argument_list|()
operator|>
name|newCols
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|columnNameTypePairMap
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|newCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|newCol
range|:
name|newCols
control|)
block|{
name|columnNameTypePairMap
operator|.
name|put
argument_list|(
name|newCol
operator|.
name|getName
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|newCol
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
specifier|final
name|FieldSchema
name|oldCol
range|:
name|oldCols
control|)
block|{
if|if
condition|(
operator|!
name|columnNameTypePairMap
operator|.
name|containsKey
argument_list|(
name|oldCol
operator|.
name|getName
argument_list|()
argument_list|)
operator|||
operator|!
name|columnNameTypePairMap
operator|.
name|get
argument_list|(
name|oldCol
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|equalsIgnoreCase
argument_list|(
name|oldCol
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/** Duplicates AcidUtils; used in a couple places in metastore. */
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTableParam
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
comment|/**    * create listener instances as per the configuration.    *    * @param clazz Class of the listener    * @param conf configuration object    * @param listenerImplList Implementation class name    * @return instance of the listener    * @throws MetaException if there is any failure instantiating the class    */
specifier|public
specifier|static
parameter_list|<
name|T
parameter_list|>
name|List
argument_list|<
name|T
argument_list|>
name|getMetaStoreListeners
parameter_list|(
name|Class
argument_list|<
name|T
argument_list|>
name|clazz
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|String
name|listenerImplList
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|T
argument_list|>
name|listeners
init|=
operator|new
name|ArrayList
argument_list|<
name|T
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isBlank
argument_list|(
name|listenerImplList
argument_list|)
condition|)
block|{
return|return
name|listeners
return|;
block|}
name|String
index|[]
name|listenerImpls
init|=
name|listenerImplList
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|listenerImpl
range|:
name|listenerImpls
control|)
block|{
try|try
block|{
name|T
name|listener
init|=
operator|(
name|T
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|listenerImpl
operator|.
name|trim
argument_list|()
argument_list|,
literal|true
argument_list|,
name|JavaUtils
operator|.
name|getClassLoader
argument_list|()
argument_list|)
operator|.
name|getConstructor
argument_list|(
name|Configuration
operator|.
name|class
argument_list|)
operator|.
name|newInstance
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvocationTargetException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|ie
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|listeners
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNames
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|cols
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|validateColumnName
argument_list|(
name|col
argument_list|)
condition|)
block|{
return|return
name|col
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNamesSubsetCol
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|skewedColNames
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|skewedColNames
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|cols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|fieldSchema
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// make a copy
name|List
argument_list|<
name|String
argument_list|>
name|copySkewedColNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|skewedColNames
argument_list|)
decl_stmt|;
comment|// remove valid columns
name|copySkewedColNames
operator|.
name|removeAll
argument_list|(
name|colNames
argument_list|)
expr_stmt|;
if|if
condition|(
name|copySkewedColNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|copySkewedColNames
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isNonNativeTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
operator|||
name|table
operator|.
name|getParameters
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|(
name|table
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|META_TABLE_STORAGE
argument_list|)
operator|!=
literal|null
operator|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isIndexTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|INDEX_TABLE
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Given a list of partition columns and a partial mapping from    * some partition columns to values the function returns the values    * for the column.    * @param partCols the list of table partition columns    * @param partSpec the partial mapping from partition column to values    * @return list of values of for given partition columns, any missing    *         values in partSpec is replaced by an empty string    */
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPvals
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|partCols
control|)
block|{
name|String
name|val
init|=
name|StringUtils
operator|.
name|defaultString
argument_list|(
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
return|return
name|pvals
return|;
block|}
comment|/**    * @param schema1: The first schema to be compared    * @param schema2: The second schema to be compared    * @return true if the two schemas are the same else false    *         for comparing a field we ignore the comment it has    */
specifier|public
specifier|static
name|boolean
name|compareFieldColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema1
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema2
parameter_list|)
block|{
if|if
condition|(
name|schema1
operator|.
name|size
argument_list|()
operator|!=
name|schema2
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|its1
init|=
name|schema1
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|its2
init|=
name|schema2
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|its1
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FieldSchema
name|f1
init|=
name|its1
operator|.
name|next
argument_list|()
decl_stmt|;
name|FieldSchema
name|f2
init|=
name|its2
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// The default equals provided by thrift compares the comments too for
comment|// equality, thus we need to compare the relevant fields here.
if|if
condition|(
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|f1
operator|.
name|getName
argument_list|()
argument_list|,
name|f2
operator|.
name|getName
argument_list|()
argument_list|)
operator|||
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|f1
operator|.
name|getType
argument_list|()
argument_list|,
name|f2
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isArchived
parameter_list|(
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|)
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Path
name|getOriginalLocation
parameter_list|(
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
assert|assert
operator|(
name|isArchived
argument_list|(
name|part
argument_list|)
operator|)
assert|;
name|String
name|originalLocation
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|originalLocation
operator|!=
literal|null
operator|)
assert|;
return|return
operator|new
name|Path
argument_list|(
name|originalLocation
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
name|ARCHIVING_LEVEL
init|=
literal|"archiving_level"
decl_stmt|;
specifier|public
specifier|static
name|int
name|getArchivingLevel
parameter_list|(
name|Partition
name|part
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
operator|!
name|isArchived
argument_list|(
name|part
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Getting level of unarchived partition"
argument_list|)
throw|;
block|}
name|String
name|lv
init|=
name|part
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|ARCHIVING_LEVEL
argument_list|)
decl_stmt|;
if|if
condition|(
name|lv
operator|!=
literal|null
condition|)
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|lv
argument_list|)
return|;
block|}
comment|// partitions archived before introducing multiple archiving
return|return
name|part
operator|.
name|getValues
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|boolean
name|partitionNameHasValidCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
return|return
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
operator|==
literal|null
return|;
block|}
specifier|public
specifier|static
name|void
name|getMergableCols
parameter_list|(
name|ColumnStatistics
name|csNew
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|index
init|=
literal|0
init|;
name|index
operator|<
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|index
operator|++
control|)
block|{
name|ColumnStatisticsObj
name|statsObjNew
init|=
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|get
argument_list|(
name|index
argument_list|)
decl_stmt|;
comment|// canColumnStatsMerge guarantees that it is accurate before we do merge
if|if
condition|(
name|StatsSetupConst
operator|.
name|canColumnStatsMerge
argument_list|(
name|parameters
argument_list|,
name|statsObjNew
operator|.
name|getColName
argument_list|()
argument_list|)
condition|)
block|{
name|list
operator|.
name|add
argument_list|(
name|statsObjNew
argument_list|)
expr_stmt|;
block|}
comment|// in all the other cases, we can not merge
block|}
name|csNew
operator|.
name|setStatsObj
argument_list|(
name|list
argument_list|)
expr_stmt|;
block|}
comment|// this function will merge csOld into csNew.
specifier|public
specifier|static
name|void
name|mergeColStats
parameter_list|(
name|ColumnStatistics
name|csNew
parameter_list|,
name|ColumnStatistics
name|csOld
parameter_list|)
throws|throws
name|InvalidObjectException
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|csOld
operator|.
name|getStatsObjSize
argument_list|()
condition|)
block|{
comment|// Some of the columns' stats are missing
comment|// This implies partition schema has changed. We will merge columns
comment|// present in both, overwrite stats for columns absent in metastore and
comment|// leave alone columns stats missing from stats task. This last case may
comment|// leave stats in stale state. This will be addressed later.
name|LOG
operator|.
name|debug
argument_list|(
literal|"New ColumnStats size is {}, but old ColumnStats size is {}"
argument_list|,
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|csOld
operator|.
name|getStatsObjSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// In this case, we have to find out which columns can be merged.
name|Map
argument_list|<
name|String
argument_list|,
name|ColumnStatisticsObj
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|// We build a hash map from colName to object for old ColumnStats.
for|for
control|(
name|ColumnStatisticsObj
name|obj
range|:
name|csOld
operator|.
name|getStatsObj
argument_list|()
control|)
block|{
name|map
operator|.
name|put
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|,
name|obj
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|index
init|=
literal|0
init|;
name|index
operator|<
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|index
operator|++
control|)
block|{
name|ColumnStatisticsObj
name|statsObjNew
init|=
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|get
argument_list|(
name|index
argument_list|)
decl_stmt|;
name|ColumnStatisticsObj
name|statsObjOld
init|=
name|map
operator|.
name|get
argument_list|(
name|statsObjNew
operator|.
name|getColName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|statsObjOld
operator|!=
literal|null
condition|)
block|{
comment|// If statsObjOld is found, we can merge.
name|ColumnStatsMerger
name|merger
init|=
name|ColumnStatsMergerFactory
operator|.
name|getColumnStatsMerger
argument_list|(
name|statsObjNew
argument_list|,
name|statsObjOld
argument_list|)
decl_stmt|;
name|merger
operator|.
name|merge
argument_list|(
name|statsObjNew
argument_list|,
name|statsObjOld
argument_list|)
expr_stmt|;
block|}
name|list
operator|.
name|add
argument_list|(
name|statsObjNew
argument_list|)
expr_stmt|;
block|}
name|csNew
operator|.
name|setStatsObj
argument_list|(
name|list
argument_list|)
expr_stmt|;
block|}
comment|/**    * Read and return the meta store Sasl configuration. Currently it uses the default    * Hadoop SASL configuration and can be configured using "hadoop.rpc.protection"    * HADOOP-10211, made a backward incompatible change due to which this call doesn't    * work with Hadoop 2.4.0 and later.    * @param conf    * @return The SASL configuration    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getMetaStoreSaslProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|useSSL
parameter_list|)
block|{
comment|// As of now Hive Meta Store uses the same configuration as Hadoop SASL configuration
comment|// If SSL is enabled, override the given value of "hadoop.rpc.protection" and set it to "authentication"
comment|// This disables any encryption provided by SASL, since SSL already provides it
name|String
name|hadoopRpcProtectionVal
init|=
name|conf
operator|.
name|get
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
argument_list|)
decl_stmt|;
name|String
name|hadoopRpcProtectionAuth
init|=
name|SaslRpcServer
operator|.
name|QualityOfProtection
operator|.
name|AUTHENTICATION
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|useSSL
operator|&&
name|hadoopRpcProtectionVal
operator|!=
literal|null
operator|&&
operator|!
name|hadoopRpcProtectionVal
operator|.
name|equals
argument_list|(
name|hadoopRpcProtectionAuth
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Overriding value of "
operator|+
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
operator|+
literal|" setting it from "
operator|+
name|hadoopRpcProtectionVal
operator|+
literal|" to "
operator|+
name|hadoopRpcProtectionAuth
operator|+
literal|" because SSL is enabled"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
argument_list|,
name|hadoopRpcProtectionAuth
argument_list|)
expr_stmt|;
block|}
return|return
name|HadoopThriftAuthBridge
operator|.
name|getBridge
argument_list|()
operator|.
name|getHadoopSaslProperties
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Add new elements to the classpath.    *    * @param newPaths    *          Array of classpath elements    */
specifier|public
specifier|static
name|ClassLoader
name|addToClassPath
parameter_list|(
name|ClassLoader
name|cloader
parameter_list|,
name|String
index|[]
name|newPaths
parameter_list|)
throws|throws
name|Exception
block|{
name|URLClassLoader
name|loader
init|=
operator|(
name|URLClassLoader
operator|)
name|cloader
decl_stmt|;
name|List
argument_list|<
name|URL
argument_list|>
name|curPath
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|loader
operator|.
name|getURLs
argument_list|()
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|URL
argument_list|>
name|newPath
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|curPath
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// get a list with the current classpath components
for|for
control|(
name|URL
name|onePath
range|:
name|curPath
control|)
block|{
name|newPath
operator|.
name|add
argument_list|(
name|onePath
argument_list|)
expr_stmt|;
block|}
name|curPath
operator|=
name|newPath
expr_stmt|;
for|for
control|(
name|String
name|onestr
range|:
name|newPaths
control|)
block|{
name|URL
name|oneurl
init|=
name|urlFromPathString
argument_list|(
name|onestr
argument_list|)
decl_stmt|;
if|if
condition|(
name|oneurl
operator|!=
literal|null
operator|&&
operator|!
name|curPath
operator|.
name|contains
argument_list|(
name|oneurl
argument_list|)
condition|)
block|{
name|curPath
operator|.
name|add
argument_list|(
name|oneurl
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|URLClassLoader
argument_list|(
name|curPath
operator|.
name|toArray
argument_list|(
operator|new
name|URL
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|loader
argument_list|)
return|;
block|}
comment|/**    * Create a URL from a string representing a path to a local file.    * The path string can be just a path, or can start with file:/, file:///    * @param onestr  path string    * @return    */
specifier|private
specifier|static
name|URL
name|urlFromPathString
parameter_list|(
name|String
name|onestr
parameter_list|)
block|{
name|URL
name|oneurl
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|onestr
operator|.
name|startsWith
argument_list|(
literal|"file:/"
argument_list|)
condition|)
block|{
name|oneurl
operator|=
operator|new
name|URL
argument_list|(
name|onestr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|oneurl
operator|=
operator|new
name|File
argument_list|(
name|onestr
argument_list|)
operator|.
name|toURL
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|err
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad URL "
operator|+
name|onestr
operator|+
literal|", ignoring path"
argument_list|)
expr_stmt|;
block|}
return|return
name|oneurl
return|;
block|}
comment|/**    * Verify if the user is allowed to make DB notification related calls.    * Only the superusers defined in the Hadoop proxy user settings have the permission.    *    * @param user the short user name    * @param conf that contains the proxy user settings    * @return if the user has the permission    */
specifier|public
specifier|static
name|boolean
name|checkUserHasHostProxyPrivileges
parameter_list|(
name|String
name|user
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|String
name|ipAddress
parameter_list|)
block|{
name|DefaultImpersonationProvider
name|sip
init|=
name|ProxyUsers
operator|.
name|getDefaultImpersonationProvider
argument_list|()
decl_stmt|;
comment|// Just need to initialize the ProxyUsers for the first time, given that the conf will not change on the fly
if|if
condition|(
name|sip
operator|==
literal|null
condition|)
block|{
name|ProxyUsers
operator|.
name|refreshSuperUserGroupsConfiguration
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|sip
operator|=
name|ProxyUsers
operator|.
name|getDefaultImpersonationProvider
argument_list|()
expr_stmt|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|Collection
argument_list|<
name|String
argument_list|>
argument_list|>
name|proxyHosts
init|=
name|sip
operator|.
name|getProxyHosts
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|hostEntries
init|=
name|proxyHosts
operator|.
name|get
argument_list|(
name|sip
operator|.
name|getProxySuperuserIpConfKey
argument_list|(
name|user
argument_list|)
argument_list|)
decl_stmt|;
name|MachineList
name|machineList
init|=
operator|new
name|MachineList
argument_list|(
name|hostEntries
argument_list|)
decl_stmt|;
name|ipAddress
operator|=
operator|(
name|ipAddress
operator|==
literal|null
operator|)
condition|?
name|StringUtils
operator|.
name|EMPTY
else|:
name|ipAddress
expr_stmt|;
return|return
name|machineList
operator|.
name|includes
argument_list|(
name|ipAddress
argument_list|)
return|;
block|}
comment|// TODO This should be moved to MetaStoreTestUtils once it is moved into standalone-metastore.
comment|/**    * Setup a configuration file for standalone mode.  There are a few config variables that have    * defaults that require parts of Hive that aren't present in standalone mode.  This method    * sets them to something that will work without the rest of Hive.    * @param conf Configuration object    */
specifier|public
specifier|static
name|void
name|setConfForStandloneMode
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|MetastoreConf
operator|.
name|setVar
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|TASK_THREADS_ALWAYS
argument_list|,
name|EventCleanerTask
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

