begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *<p>  * http://www.apache.org/licenses/LICENSE-2.0  *<p>  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|DefaultStorageSchemaReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveAlterHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MaterializationsCacheCleanerTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MaterializationsRebuildLockCleanerTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MetastoreTaskThread
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|RuntimeStatsCleanerTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|events
operator|.
name|EventCleanerTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|security
operator|.
name|MetastoreDelegationTokenManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|AcidCompactionHistoryService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|AcidHouseKeeperService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|AcidOpenTxnsCounterService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|AcidWriteSetService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_comment
comment|/**  * A set of definitions of config values used by the Metastore.  One of the key aims of this  * class is to provide backwards compatibility with existing Hive configuration keys while  * allowing the metastore to have its own, Hive independent keys.   For this reason access to the  * underlying Configuration object should always be done via the static methods provided here  * rather than directly via {@link Configuration#get(String)} and  * {@link Configuration#set(String, String)}.  All the methods of this class will handle checking  * both the MetastoreConf key and the Hive key.  The algorithm is, on reads, to check first the  * MetastoreConf key, then the Hive key, then return the default if neither are set.  On write  * the Metastore key only is set.  *  * This class does not extend Configuration.  Rather it provides static methods for operating on  * a Configuration object.  This allows it to work on HiveConf objects, which otherwise would not  * be the case.  */
end_comment

begin_class
specifier|public
class|class
name|MetastoreConf
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MetastoreConf
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Pattern
name|TIME_UNIT_SUFFIX
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"([0-9]+)([a-zA-Z]+)"
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|ConfVars
argument_list|>
name|metaConfs
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|static
name|URL
name|hiveDefaultURL
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|URL
name|hiveSiteURL
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|URL
name|hiveMetastoreSiteURL
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|URL
name|metastoreSiteURL
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|AtomicBoolean
name|beenDumped
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
specifier|private
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|ConfVars
argument_list|>
name|keyToVars
decl_stmt|;
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
name|String
name|TEST_ENV_WORKAROUND
init|=
literal|"metastore.testing.env.workaround.dont.ever.set.this."
decl_stmt|;
specifier|public
specifier|static
enum|enum
name|StatsUpdateMode
block|{
name|NONE
block|,
name|EXISTING
block|,
name|ALL
block|}
specifier|private
specifier|static
class|class
name|TimeValue
block|{
specifier|final
name|long
name|val
decl_stmt|;
specifier|final
name|TimeUnit
name|unit
decl_stmt|;
specifier|private
name|TimeValue
parameter_list|(
name|long
name|val
parameter_list|,
name|TimeUnit
name|unit
parameter_list|)
block|{
name|this
operator|.
name|val
operator|=
name|val
expr_stmt|;
name|this
operator|.
name|unit
operator|=
name|unit
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
switch|switch
condition|(
name|unit
condition|)
block|{
case|case
name|NANOSECONDS
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"ns"
return|;
case|case
name|MICROSECONDS
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"us"
return|;
case|case
name|MILLISECONDS
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"ms"
return|;
case|case
name|SECONDS
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"s"
return|;
case|case
name|MINUTES
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"m"
return|;
case|case
name|HOURS
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"h"
return|;
case|case
name|DAYS
case|:
return|return
name|Long
operator|.
name|toString
argument_list|(
name|val
argument_list|)
operator|+
literal|"d"
return|;
block|}
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown time unit "
operator|+
name|unit
argument_list|)
throw|;
block|}
block|}
comment|/**    * Metastore related options that the db is initialized against. When a conf    * var in this is list is changed, the metastore instance for the CLI will    * be recreated so that the change will take effect.    * TODO - I suspect the vast majority of these don't need to be here.  But it requires testing    * before just pulling them out.    */
specifier|public
specifier|static
specifier|final
name|MetastoreConf
operator|.
name|ConfVars
index|[]
name|metaVars
init|=
block|{
name|ConfVars
operator|.
name|WAREHOUSE
block|,
name|ConfVars
operator|.
name|REPLDIR
block|,
name|ConfVars
operator|.
name|THRIFT_URIS
block|,
name|ConfVars
operator|.
name|SERVER_PORT
block|,
name|ConfVars
operator|.
name|THRIFT_CONNECTION_RETRIES
block|,
name|ConfVars
operator|.
name|THRIFT_FAILURE_RETRIES
block|,
name|ConfVars
operator|.
name|CLIENT_CONNECT_RETRY_DELAY
block|,
name|ConfVars
operator|.
name|CLIENT_SOCKET_TIMEOUT
block|,
name|ConfVars
operator|.
name|CLIENT_SOCKET_LIFETIME
block|,
name|ConfVars
operator|.
name|PWD
block|,
name|ConfVars
operator|.
name|CONNECT_URL_HOOK
block|,
name|ConfVars
operator|.
name|CONNECT_URL_KEY
block|,
name|ConfVars
operator|.
name|SERVER_MIN_THREADS
block|,
name|ConfVars
operator|.
name|SERVER_MAX_THREADS
block|,
name|ConfVars
operator|.
name|TCP_KEEP_ALIVE
block|,
name|ConfVars
operator|.
name|KERBEROS_KEYTAB_FILE
block|,
name|ConfVars
operator|.
name|KERBEROS_PRINCIPAL
block|,
name|ConfVars
operator|.
name|USE_THRIFT_SASL
block|,
name|ConfVars
operator|.
name|TOKEN_SIGNATURE
block|,
name|ConfVars
operator|.
name|CACHE_PINOBJTYPES
block|,
name|ConfVars
operator|.
name|CONNECTION_POOLING_TYPE
block|,
name|ConfVars
operator|.
name|VALIDATE_TABLES
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_INIT_COL_INFO
block|,
name|ConfVars
operator|.
name|VALIDATE_COLUMNS
block|,
name|ConfVars
operator|.
name|VALIDATE_CONSTRAINTS
block|,
name|ConfVars
operator|.
name|STORE_MANAGER_TYPE
block|,
name|ConfVars
operator|.
name|AUTO_CREATE_ALL
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_TRANSACTION_ISOLATION
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_CACHE_LEVEL2
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_CACHE_LEVEL2_TYPE
block|,
name|ConfVars
operator|.
name|IDENTIFIER_FACTORY
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_PLUGIN_REGISTRY_BUNDLE_CHECK
block|,
name|ConfVars
operator|.
name|AUTHORIZATION_STORAGE_AUTH_CHECKS
block|,
name|ConfVars
operator|.
name|BATCH_RETRIEVE_MAX
block|,
name|ConfVars
operator|.
name|EVENT_LISTENERS
block|,
name|ConfVars
operator|.
name|TRANSACTIONAL_EVENT_LISTENERS
block|,
name|ConfVars
operator|.
name|EVENT_CLEAN_FREQ
block|,
name|ConfVars
operator|.
name|EVENT_EXPIRY_DURATION
block|,
name|ConfVars
operator|.
name|EVENT_MESSAGE_FACTORY
block|,
name|ConfVars
operator|.
name|FILTER_HOOK
block|,
name|ConfVars
operator|.
name|RAW_STORE_IMPL
block|,
name|ConfVars
operator|.
name|END_FUNCTION_LISTENERS
block|,
name|ConfVars
operator|.
name|PART_INHERIT_TBL_PROPS
block|,
name|ConfVars
operator|.
name|BATCH_RETRIEVE_OBJECTS_MAX
block|,
name|ConfVars
operator|.
name|INIT_HOOKS
block|,
name|ConfVars
operator|.
name|PRE_EVENT_LISTENERS
block|,
name|ConfVars
operator|.
name|HMS_HANDLER_ATTEMPTS
block|,
name|ConfVars
operator|.
name|HMS_HANDLER_INTERVAL
block|,
name|ConfVars
operator|.
name|HMS_HANDLER_FORCE_RELOAD_CONF
block|,
name|ConfVars
operator|.
name|PARTITION_NAME_WHITELIST_PATTERN
block|,
name|ConfVars
operator|.
name|ORM_RETRIEVE_MAPNULLS_AS_EMPTY_STRINGS
block|,
name|ConfVars
operator|.
name|USERS_IN_ADMIN_ROLE
block|,
name|ConfVars
operator|.
name|HIVE_TXN_MANAGER
block|,
name|ConfVars
operator|.
name|TXN_TIMEOUT
block|,
name|ConfVars
operator|.
name|TXN_MAX_OPEN_BATCH
block|,
name|ConfVars
operator|.
name|TXN_RETRYABLE_SQLEX_REGEX
block|,
name|ConfVars
operator|.
name|STATS_NDV_TUNER
block|,
name|ConfVars
operator|.
name|STATS_NDV_DENSITY_FUNCTION
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_ENABLED
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_SIZE
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_MAX_PARTITIONS
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_FPP
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_MAX_VARIANCE
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_TTL
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_MAX_WRITER_WAIT
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_MAX_READER_WAIT
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_MAX_FULL
block|,
name|ConfVars
operator|.
name|AGGREGATE_STATS_CACHE_CLEAN_UNTIL
block|,
name|ConfVars
operator|.
name|DISALLOW_INCOMPATIBLE_COL_TYPE_CHANGES
block|,
name|ConfVars
operator|.
name|FILE_METADATA_THREADS
block|}
decl_stmt|;
comment|/**    * User configurable Metastore vars    */
specifier|private
specifier|static
specifier|final
name|MetastoreConf
operator|.
name|ConfVars
index|[]
name|metaConfVars
init|=
block|{
name|ConfVars
operator|.
name|TRY_DIRECT_SQL
block|,
name|ConfVars
operator|.
name|TRY_DIRECT_SQL_DDL
block|,
name|ConfVars
operator|.
name|CLIENT_SOCKET_TIMEOUT
block|,
name|ConfVars
operator|.
name|PARTITION_NAME_WHITELIST_PATTERN
block|,
name|ConfVars
operator|.
name|CAPABILITY_CHECK
block|,
name|ConfVars
operator|.
name|DISALLOW_INCOMPATIBLE_COL_TYPE_CHANGES
block|}
decl_stmt|;
static|static
block|{
for|for
control|(
name|ConfVars
name|confVar
range|:
name|metaConfVars
control|)
block|{
name|metaConfs
operator|.
name|put
argument_list|(
name|confVar
operator|.
name|varname
argument_list|,
name|confVar
argument_list|)
expr_stmt|;
name|metaConfs
operator|.
name|put
argument_list|(
name|confVar
operator|.
name|hiveName
argument_list|,
name|confVar
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Variables that we should never print the value of for security reasons.    */
specifier|private
specifier|static
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|unprintables
init|=
name|StringUtils
operator|.
name|asSet
argument_list|(
name|ConfVars
operator|.
name|PWD
operator|.
name|varname
argument_list|,
name|ConfVars
operator|.
name|PWD
operator|.
name|hiveName
argument_list|,
name|ConfVars
operator|.
name|SSL_KEYSTORE_PASSWORD
operator|.
name|varname
argument_list|,
name|ConfVars
operator|.
name|SSL_KEYSTORE_PASSWORD
operator|.
name|hiveName
argument_list|,
name|ConfVars
operator|.
name|SSL_TRUSTSTORE_PASSWORD
operator|.
name|varname
argument_list|,
name|ConfVars
operator|.
name|SSL_TRUSTSTORE_PASSWORD
operator|.
name|hiveName
argument_list|)
decl_stmt|;
specifier|public
specifier|static
name|ConfVars
name|getMetaConf
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|metaConfs
operator|.
name|get
argument_list|(
name|name
argument_list|)
return|;
block|}
specifier|public
enum|enum
name|ConfVars
block|{
comment|// alpha order, PLEASE!
name|ADDED_JARS
argument_list|(
literal|"metastore.added.jars.path"
argument_list|,
literal|"hive.added.jars.path"
argument_list|,
literal|""
argument_list|,
literal|"This an internal parameter."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_CLEAN_UNTIL
argument_list|(
literal|"metastore.aggregate.stats.cache.clean.until"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.clean.until"
argument_list|,
literal|0.8
argument_list|,
literal|"The cleaner thread cleans until cache reaches this % full size."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_ENABLED
argument_list|(
literal|"metastore.aggregate.stats.cache.enabled"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.enabled"
argument_list|,
literal|true
argument_list|,
literal|"Whether aggregate stats caching is enabled or not."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_FPP
argument_list|(
literal|"metastore.aggregate.stats.cache.fpp"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.fpp"
argument_list|,
literal|0.01
argument_list|,
literal|"Maximum false positive probability for the Bloom Filter used in each aggregate stats cache node (default 1%)."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_MAX_FULL
argument_list|(
literal|"metastore.aggregate.stats.cache.max.full"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.max.full"
argument_list|,
literal|0.9
argument_list|,
literal|"Maximum cache full % after which the cache cleaner thread kicks in."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_MAX_PARTITIONS
argument_list|(
literal|"metastore.aggregate.stats.cache.max.partitions"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.max.partitions"
argument_list|,
literal|10000
argument_list|,
literal|"Maximum number of partitions that are aggregated per cache node."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_MAX_READER_WAIT
argument_list|(
literal|"metastore.aggregate.stats.cache.max.reader.wait"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.max.reader.wait"
argument_list|,
literal|1000
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
literal|"Number of milliseconds a reader will wait to acquire the readlock before giving up."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_MAX_VARIANCE
argument_list|(
literal|"metastore.aggregate.stats.cache.max.variance"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.max.variance"
argument_list|,
literal|0.01
argument_list|,
literal|"Maximum tolerable variance in number of partitions between a cached node and our request (default 1%)."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_MAX_WRITER_WAIT
argument_list|(
literal|"metastore.aggregate.stats.cache.max.writer.wait"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.max.writer.wait"
argument_list|,
literal|5000
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
literal|"Number of milliseconds a writer will wait to acquire the writelock before giving up."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_SIZE
argument_list|(
literal|"metastore.aggregate.stats.cache.size"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.size"
argument_list|,
literal|10000
argument_list|,
literal|"Maximum number of aggregate stats nodes that we will place in the metastore aggregate stats cache."
argument_list|)
block|,
name|AGGREGATE_STATS_CACHE_TTL
argument_list|(
literal|"metastore.aggregate.stats.cache.ttl"
argument_list|,
literal|"hive.metastore.aggregate.stats.cache.ttl"
argument_list|,
literal|600
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Number of seconds for a cached node to be active in the cache before they become stale."
argument_list|)
block|,
name|ALTER_HANDLER
argument_list|(
literal|"metastore.alter.handler"
argument_list|,
literal|"hive.metastore.alter.impl"
argument_list|,
name|HiveAlterHandler
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|"Alter handler.  For now defaults to the Hive one.  Really need a better default option"
argument_list|)
block|,
name|ASYNC_LOG_ENABLED
argument_list|(
literal|"metastore.async.log.enabled"
argument_list|,
literal|"hive.async.log.enabled"
argument_list|,
literal|true
argument_list|,
literal|"Whether to enable Log4j2's asynchronous logging. Asynchronous logging can give\n"
operator|+
literal|" significant performance improvement as logging will be handled in separate thread\n"
operator|+
literal|" that uses LMAX disruptor queue for buffering log messages.\n"
operator|+
literal|" Refer https://logging.apache.org/log4j/2.x/manual/async.html for benefits and\n"
operator|+
literal|" drawbacks."
argument_list|)
block|,
name|AUTHORIZATION_STORAGE_AUTH_CHECKS
argument_list|(
literal|"metastore.authorization.storage.checks"
argument_list|,
literal|"hive.metastore.authorization.storage.checks"
argument_list|,
literal|false
argument_list|,
literal|"Should the metastore do authorization checks against the underlying storage (usually hdfs) \n"
operator|+
literal|"for operations like drop-partition (disallow the drop-partition if the user in\n"
operator|+
literal|"question doesn't have permissions to delete the corresponding directory\n"
operator|+
literal|"on the storage)."
argument_list|)
block|,
name|AUTO_CREATE_ALL
argument_list|(
literal|"datanucleus.schema.autoCreateAll"
argument_list|,
literal|"datanucleus.schema.autoCreateAll"
argument_list|,
literal|false
argument_list|,
literal|"Auto creates necessary schema on a startup if one doesn't exist. Set this to false, after creating it once."
operator|+
literal|"To enable auto create also set hive.metastore.schema.verification=false. Auto creation is not "
operator|+
literal|"recommended for production use cases, run schematool command instead."
argument_list|)
block|,
name|BATCH_RETRIEVE_MAX
argument_list|(
literal|"metastore.batch.retrieve.max"
argument_list|,
literal|"hive.metastore.batch.retrieve.max"
argument_list|,
literal|300
argument_list|,
literal|"Maximum number of objects (tables/partitions) can be retrieved from metastore in one batch. \n"
operator|+
literal|"The higher the number, the less the number of round trips is needed to the Hive metastore server, \n"
operator|+
literal|"but it may also cause higher memory requirement at the client side."
argument_list|)
block|,
name|BATCH_RETRIEVE_OBJECTS_MAX
argument_list|(
literal|"metastore.batch.retrieve.table.partition.max"
argument_list|,
literal|"hive.metastore.batch.retrieve.table.partition.max"
argument_list|,
literal|1000
argument_list|,
literal|"Maximum number of objects that metastore internally retrieves in one batch."
argument_list|)
block|,
name|CACHE_PINOBJTYPES
argument_list|(
literal|"metastore.cache.pinobjtypes"
argument_list|,
literal|"hive.metastore.cache.pinobjtypes"
argument_list|,
literal|"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
argument_list|,
literal|"List of comma separated metastore object types that should be pinned in the cache"
argument_list|)
block|,
name|CACHED_RAW_STORE_IMPL
argument_list|(
literal|"metastore.cached.rawstore.impl"
argument_list|,
literal|"hive.metastore.cached.rawstore.impl"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.ObjectStore"
argument_list|,
literal|"Name of the wrapped RawStore class"
argument_list|)
block|,
name|CACHED_RAW_STORE_CACHE_UPDATE_FREQUENCY
argument_list|(
literal|"metastore.cached.rawstore.cache.update.frequency"
argument_list|,
literal|"hive.metastore.cached.rawstore.cache.update.frequency"
argument_list|,
literal|60
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"The time after which metastore cache is updated from metastore DB."
argument_list|)
block|,
name|CACHED_RAW_STORE_CACHED_OBJECTS_WHITELIST
argument_list|(
literal|"metastore.cached.rawstore.cached.object.whitelist"
argument_list|,
literal|"hive.metastore.cached.rawstore.cached.object.whitelist"
argument_list|,
literal|".*"
argument_list|,
literal|"Comma separated list of regular expressions \n "
operator|+
literal|"to select the tables (and its partitions, stats etc) that will be cached by CachedStore. \n"
operator|+
literal|"This can be used in conjunction with hive.metastore.cached.rawstore.cached.object.blacklist. \n"
operator|+
literal|"Example: .*, db1.*, db2\\.tbl.*. The last item can potentially override patterns specified before."
argument_list|)
block|,
name|CACHED_RAW_STORE_CACHED_OBJECTS_BLACKLIST
argument_list|(
literal|"metastore.cached.rawstore.cached.object.blacklist"
argument_list|,
literal|"hive.metastore.cached.rawstore.cached.object.blacklist"
argument_list|,
literal|""
argument_list|,
literal|"Comma separated list of regular expressions \n "
operator|+
literal|"to filter out the tables (and its partitions, stats etc) that will be cached by CachedStore. \n"
operator|+
literal|"This can be used in conjunction with hive.metastore.cached.rawstore.cached.object.whitelist. \n"
operator|+
literal|"Example: db2.*, db3\\.tbl1, db3\\..*. The last item can potentially override patterns specified before. \n"
operator|+
literal|"The blacklist also overrides the whitelist."
argument_list|)
block|,
name|CACHED_RAW_STORE_MAX_CACHE_MEMORY
argument_list|(
literal|"metastore.cached.rawstore.max.cache.memory"
argument_list|,
literal|"hive.metastore.cached.rawstore.max.cache.memory"
argument_list|,
literal|"1Gb"
argument_list|,
operator|new
name|SizeValidator
argument_list|()
argument_list|,
literal|"The maximum memory in bytes that the cached objects can use. "
operator|+
literal|"Memory used is calculated based on estimated size of tables and partitions in the cache. "
operator|+
literal|"Setting it to a negative value disables memory estimation."
argument_list|)
block|,
name|CAPABILITY_CHECK
argument_list|(
literal|"metastore.client.capability.check"
argument_list|,
literal|"hive.metastore.client.capability.check"
argument_list|,
literal|true
argument_list|,
literal|"Whether to check client capabilities for potentially breaking API usage."
argument_list|)
block|,
name|CATALOG_DEFAULT
argument_list|(
literal|"metastore.catalog.default"
argument_list|,
literal|"metastore.catalog.default"
argument_list|,
literal|"hive"
argument_list|,
literal|"The default catalog to use when a catalog is not specified.  Default is 'hive' (the "
operator|+
literal|"default catalog)."
argument_list|)
block|,
name|CATALOGS_TO_CACHE
argument_list|(
literal|"metastore.cached.rawstore.catalogs"
argument_list|,
literal|"metastore.cached.rawstore.catalogs"
argument_list|,
literal|"hive"
argument_list|,
literal|"Comma separated list of catalogs to cache in the CachedStore. Default is 'hive' "
operator|+
literal|"(the default catalog).  Empty string means all catalogs will be cached."
argument_list|)
block|,
name|CLIENT_CONNECT_RETRY_DELAY
argument_list|(
literal|"metastore.client.connect.retry.delay"
argument_list|,
literal|"hive.metastore.client.connect.retry.delay"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Number of seconds for the client to wait between consecutive connection attempts"
argument_list|)
block|,
name|CLIENT_KERBEROS_PRINCIPAL
argument_list|(
literal|"metastore.client.kerberos.principal"
argument_list|,
literal|"hive.metastore.client.kerberos.principal"
argument_list|,
literal|""
argument_list|,
comment|// E.g. "hive-metastore/_HOST@EXAMPLE.COM".
literal|"The Kerberos principal associated with the HA cluster of hcat_servers."
argument_list|)
block|,
name|CLIENT_SOCKET_LIFETIME
argument_list|(
literal|"metastore.client.socket.lifetime"
argument_list|,
literal|"hive.metastore.client.socket.lifetime"
argument_list|,
literal|0
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"MetaStore Client socket lifetime in seconds. After this time is exceeded, client\n"
operator|+
literal|"reconnects on the next MetaStore operation. A value of 0s means the connection\n"
operator|+
literal|"has an infinite lifetime."
argument_list|)
block|,
name|CLIENT_SOCKET_TIMEOUT
argument_list|(
literal|"metastore.client.socket.timeout"
argument_list|,
literal|"hive.metastore.client.socket.timeout"
argument_list|,
literal|600
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"MetaStore Client socket timeout in seconds"
argument_list|)
block|,
name|COMPACTOR_HISTORY_REAPER_INTERVAL
argument_list|(
literal|"metastore.compactor.history.reaper.interval"
argument_list|,
literal|"hive.compactor.history.reaper.interval"
argument_list|,
literal|2
argument_list|,
name|TimeUnit
operator|.
name|MINUTES
argument_list|,
literal|"Determines how often compaction history reaper runs"
argument_list|)
block|,
name|COMPACTOR_HISTORY_RETENTION_ATTEMPTED
argument_list|(
literal|"metastore.compactor.history.retention.attempted"
argument_list|,
literal|"hive.compactor.history.retention.attempted"
argument_list|,
literal|2
argument_list|,
operator|new
name|RangeValidator
argument_list|(
literal|0
argument_list|,
literal|100
argument_list|)
argument_list|,
literal|"Determines how many attempted compaction records will be "
operator|+
literal|"retained in compaction history for a given table/partition."
argument_list|)
block|,
name|COMPACTOR_HISTORY_RETENTION_FAILED
argument_list|(
literal|"metastore.compactor.history.retention.failed"
argument_list|,
literal|"hive.compactor.history.retention.failed"
argument_list|,
literal|3
argument_list|,
operator|new
name|RangeValidator
argument_list|(
literal|0
argument_list|,
literal|100
argument_list|)
argument_list|,
literal|"Determines how many failed compaction records will be "
operator|+
literal|"retained in compaction history for a given table/partition."
argument_list|)
block|,
name|COMPACTOR_HISTORY_RETENTION_SUCCEEDED
argument_list|(
literal|"metastore.compactor.history.retention.succeeded"
argument_list|,
literal|"hive.compactor.history.retention.succeeded"
argument_list|,
literal|3
argument_list|,
operator|new
name|RangeValidator
argument_list|(
literal|0
argument_list|,
literal|100
argument_list|)
argument_list|,
literal|"Determines how many successful compaction records will be "
operator|+
literal|"retained in compaction history for a given table/partition."
argument_list|)
block|,
name|COMPACTOR_INITIATOR_FAILED_THRESHOLD
argument_list|(
literal|"metastore.compactor.initiator.failed.compacts.threshold"
argument_list|,
literal|"hive.compactor.initiator.failed.compacts.threshold"
argument_list|,
literal|2
argument_list|,
operator|new
name|RangeValidator
argument_list|(
literal|1
argument_list|,
literal|20
argument_list|)
argument_list|,
literal|"Number of consecutive compaction failures (per table/partition) "
operator|+
literal|"after which automatic compactions will not be scheduled any more.  Note that this must be less "
operator|+
literal|"than hive.compactor.history.retention.failed."
argument_list|)
block|,
name|COMPACTOR_INITIATOR_ON
argument_list|(
literal|"metastore.compactor.initiator.on"
argument_list|,
literal|"hive.compactor.initiator.on"
argument_list|,
literal|false
argument_list|,
literal|"Whether to run the initiator and cleaner threads on this metastore instance or not.\n"
operator|+
literal|"Set this to true on one instance of the Thrift metastore service as part of turning\n"
operator|+
literal|"on Hive transactions. For a complete list of parameters required for turning on\n"
operator|+
literal|"transactions, see hive.txn.manager."
argument_list|)
block|,
name|COMPACTOR_WORKER_THREADS
argument_list|(
literal|"metastore.compactor.worker.threads"
argument_list|,
literal|"hive.compactor.worker.threads"
argument_list|,
literal|0
argument_list|,
literal|"How many compactor worker threads to run on this metastore instance. Set this to a\n"
operator|+
literal|"positive number on one or more instances of the Thrift metastore service as part of\n"
operator|+
literal|"turning on Hive transactions. For a complete list of parameters required for turning\n"
operator|+
literal|"on transactions, see hive.txn.manager.\n"
operator|+
literal|"Worker threads spawn MapReduce jobs to do compactions. They do not do the compactions\n"
operator|+
literal|"themselves. Increasing the number of worker threads will decrease the time it takes\n"
operator|+
literal|"tables or partitions to be compacted once they are determined to need compaction.\n"
operator|+
literal|"It will also increase the background load on the Hadoop cluster as more MapReduce jobs\n"
operator|+
literal|"will be running in the background."
argument_list|)
block|,
name|CONNECTION_DRIVER
argument_list|(
literal|"javax.jdo.option.ConnectionDriverName"
argument_list|,
literal|"javax.jdo.option.ConnectionDriverName"
argument_list|,
literal|"org.apache.derby.jdbc.EmbeddedDriver"
argument_list|,
literal|"Driver class name for a JDBC metastore"
argument_list|)
block|,
name|CONNECTION_POOLING_MAX_CONNECTIONS
argument_list|(
literal|"datanucleus.connectionPool.maxPoolSize"
argument_list|,
literal|"datanucleus.connectionPool.maxPoolSize"
argument_list|,
literal|10
argument_list|,
literal|"Specify the maximum number of connections in the connection pool. Note: The configured size will be used by\n"
operator|+
literal|"2 connection pools (TxnHandler and ObjectStore). When configuring the max connection pool size, it is\n"
operator|+
literal|"recommended to take into account the number of metastore instances and the number of HiveServer2 instances\n"
operator|+
literal|"configured with embedded metastore. To get optimal performance, set config to meet the following condition\n"
operator|+
literal|"(2 * pool_size * metastore_instances + 2 * pool_size * HS2_instances_with_embedded_metastore) = \n"
operator|+
literal|"(2 * physical_core_count + hard_disk_count)."
argument_list|)
block|,
name|CONNECT_URL_HOOK
argument_list|(
literal|"metastore.ds.connection.url.hook"
argument_list|,
literal|"hive.metastore.ds.connection.url.hook"
argument_list|,
literal|""
argument_list|,
literal|"Name of the hook to use for retrieving the JDO connection URL. If empty, the value in javax.jdo.option.ConnectionURL is used"
argument_list|)
block|,
name|CONNECT_URL_KEY
argument_list|(
literal|"javax.jdo.option.ConnectionURL"
argument_list|,
literal|"javax.jdo.option.ConnectionURL"
argument_list|,
literal|"jdbc:derby:;databaseName=metastore_db;create=true"
argument_list|,
literal|"JDBC connect string for a JDBC metastore.\n"
operator|+
literal|"To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.\n"
operator|+
literal|"For example, jdbc:postgresql://myhost/db?ssl=true for postgres database."
argument_list|)
block|,
name|CONNECTION_POOLING_TYPE
argument_list|(
literal|"datanucleus.connectionPoolingType"
argument_list|,
literal|"datanucleus.connectionPoolingType"
argument_list|,
literal|"HikariCP"
argument_list|,
operator|new
name|StringSetValidator
argument_list|(
literal|"BONECP"
argument_list|,
literal|"DBCP"
argument_list|,
literal|"HikariCP"
argument_list|,
literal|"NONE"
argument_list|)
argument_list|,
literal|"Specify connection pool library for datanucleus"
argument_list|)
block|,
name|CONNECTION_USER_NAME
argument_list|(
literal|"javax.jdo.option.ConnectionUserName"
argument_list|,
literal|"javax.jdo.option.ConnectionUserName"
argument_list|,
literal|"APP"
argument_list|,
literal|"Username to use against metastore database"
argument_list|)
block|,
name|CREATE_TABLES_AS_ACID
argument_list|(
literal|"metastore.create.as.acid"
argument_list|,
literal|"hive.create.as.acid"
argument_list|,
literal|false
argument_list|,
literal|"Whether the eligible tables should be created as full ACID by default. Does \n"
operator|+
literal|"not apply to external tables, the ones using storage handlers, etc."
argument_list|)
block|,
name|COUNT_OPEN_TXNS_INTERVAL
argument_list|(
literal|"metastore.count.open.txns.interval"
argument_list|,
literal|"hive.count.open.txns.interval"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Time in seconds between checks to count open transactions."
argument_list|)
block|,
name|DATANUCLEUS_AUTOSTART
argument_list|(
literal|"datanucleus.autoStartMechanismMode"
argument_list|,
literal|"datanucleus.autoStartMechanismMode"
argument_list|,
literal|"ignored"
argument_list|,
operator|new
name|StringSetValidator
argument_list|(
literal|"ignored"
argument_list|)
argument_list|,
literal|"Autostart mechanism for datanucleus.  Currently ignored is the only option supported."
argument_list|)
block|,
name|DATANUCLEUS_CACHE_LEVEL2
argument_list|(
literal|"datanucleus.cache.level2"
argument_list|,
literal|"datanucleus.cache.level2"
argument_list|,
literal|false
argument_list|,
literal|"Use a level 2 cache. Turn this off if metadata is changed independently of Hive metastore server"
argument_list|)
block|,
name|DATANUCLEUS_CACHE_LEVEL2_TYPE
argument_list|(
literal|"datanucleus.cache.level2.type"
argument_list|,
literal|"datanucleus.cache.level2.type"
argument_list|,
literal|"none"
argument_list|,
literal|""
argument_list|)
block|,
name|DATANUCLEUS_INIT_COL_INFO
argument_list|(
literal|"datanucleus.rdbms.initializeColumnInfo"
argument_list|,
literal|"datanucleus.rdbms.initializeColumnInfo"
argument_list|,
literal|"NONE"
argument_list|,
literal|"initializeColumnInfo setting for DataNucleus; set to NONE at least on Postgres."
argument_list|)
block|,
name|DATANUCLEUS_PLUGIN_REGISTRY_BUNDLE_CHECK
argument_list|(
literal|"datanucleus.plugin.pluginRegistryBundleCheck"
argument_list|,
literal|"datanucleus.plugin.pluginRegistryBundleCheck"
argument_list|,
literal|"LOG"
argument_list|,
literal|"Defines what happens when plugin bundles are found and are duplicated [EXCEPTION|LOG|NONE]"
argument_list|)
block|,
name|DATANUCLEUS_TRANSACTION_ISOLATION
argument_list|(
literal|"datanucleus.transactionIsolation"
argument_list|,
literal|"datanucleus.transactionIsolation"
argument_list|,
literal|"read-committed"
argument_list|,
literal|"Default transaction isolation level for identity generation."
argument_list|)
block|,
name|DATANUCLEUS_USE_LEGACY_VALUE_STRATEGY
argument_list|(
literal|"datanucleus.rdbms.useLegacyNativeValueStrategy"
argument_list|,
literal|"datanucleus.rdbms.useLegacyNativeValueStrategy"
argument_list|,
literal|true
argument_list|,
literal|""
argument_list|)
block|,
name|DBACCESS_SSL_PROPS
argument_list|(
literal|"metastore.dbaccess.ssl.properties"
argument_list|,
literal|"hive.metastore.dbaccess.ssl.properties"
argument_list|,
literal|""
argument_list|,
literal|"Comma-separated SSL properties for metastore to access database when JDO connection URL\n"
operator|+
literal|"enables SSL access. e.g. javax.net.ssl.trustStore=/tmp/truststore,javax.net.ssl.trustStorePassword=pwd."
argument_list|)
block|,
name|DEFAULTPARTITIONNAME
argument_list|(
literal|"metastore.default.partition.name"
argument_list|,
literal|"hive.exec.default.partition.name"
argument_list|,
literal|"__HIVE_DEFAULT_PARTITION__"
argument_list|,
literal|"The default partition name in case the dynamic partition column value is null/empty string or any other values that cannot be escaped. \n"
operator|+
literal|"This value must not contain any special character used in HDFS URI (e.g., ':', '%', '/' etc). \n"
operator|+
literal|"The user has to be aware that the dynamic partition value should not contain this value to avoid confusions."
argument_list|)
block|,
name|DELEGATION_KEY_UPDATE_INTERVAL
argument_list|(
literal|"metastore.cluster.delegation.key.update-interval"
argument_list|,
literal|"hive.cluster.delegation.key.update-interval"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|DAYS
argument_list|,
literal|""
argument_list|)
block|,
name|DELEGATION_TOKEN_GC_INTERVAL
argument_list|(
literal|"metastore.cluster.delegation.token.gc-interval"
argument_list|,
literal|"hive.cluster.delegation.token.gc-interval"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|HOURS
argument_list|,
literal|""
argument_list|)
block|,
name|DELEGATION_TOKEN_MAX_LIFETIME
argument_list|(
literal|"metastore.cluster.delegation.token.max-lifetime"
argument_list|,
literal|"hive.cluster.delegation.token.max-lifetime"
argument_list|,
literal|7
argument_list|,
name|TimeUnit
operator|.
name|DAYS
argument_list|,
literal|""
argument_list|)
block|,
name|DELEGATION_TOKEN_RENEW_INTERVAL
argument_list|(
literal|"metastore.cluster.delegation.token.renew-interval"
argument_list|,
literal|"hive.cluster.delegation.token.renew-interval"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|DAYS
argument_list|,
literal|""
argument_list|)
block|,
name|DELEGATION_TOKEN_STORE_CLS
argument_list|(
literal|"metastore.cluster.delegation.token.store.class"
argument_list|,
literal|"hive.cluster.delegation.token.store.class"
argument_list|,
name|MetastoreDelegationTokenManager
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|"Class to store delegation tokens"
argument_list|)
block|,
name|DETACH_ALL_ON_COMMIT
argument_list|(
literal|"javax.jdo.option.DetachAllOnCommit"
argument_list|,
literal|"javax.jdo.option.DetachAllOnCommit"
argument_list|,
literal|true
argument_list|,
literal|"Detaches all objects from session so that they can be used after transaction is committed"
argument_list|)
block|,
name|DIRECT_SQL_MAX_ELEMENTS_IN_CLAUSE
argument_list|(
literal|"metastore.direct.sql.max.elements.in.clause"
argument_list|,
literal|"hive.direct.sql.max.elements.in.clause"
argument_list|,
literal|1000
argument_list|,
literal|"The maximum number of values in a IN clause. Once exceeded, it will be broken into\n"
operator|+
literal|" multiple OR separated IN clauses."
argument_list|)
block|,
name|DIRECT_SQL_MAX_ELEMENTS_VALUES_CLAUSE
argument_list|(
literal|"metastore.direct.sql.max.elements.values.clause"
argument_list|,
literal|"hive.direct.sql.max.elements.values.clause"
argument_list|,
literal|1000
argument_list|,
literal|"The maximum number of values in a VALUES clause for INSERT statement."
argument_list|)
block|,
name|DIRECT_SQL_MAX_QUERY_LENGTH
argument_list|(
literal|"metastore.direct.sql.max.query.length"
argument_list|,
literal|"hive.direct.sql.max.query.length"
argument_list|,
literal|100
argument_list|,
literal|"The maximum\n"
operator|+
literal|" size of a query string (in KB)."
argument_list|)
block|,
name|DIRECT_SQL_PARTITION_BATCH_SIZE
argument_list|(
literal|"metastore.direct.sql.batch.size"
argument_list|,
literal|"hive.metastore.direct.sql.batch.size"
argument_list|,
literal|0
argument_list|,
literal|"Batch size for partition and other object retrieval from the underlying DB in direct\n"
operator|+
literal|"SQL. For some DBs like Oracle and MSSQL, there are hardcoded or perf-based limitations\n"
operator|+
literal|"that necessitate this. For DBs that can handle the queries, this isn't necessary and\n"
operator|+
literal|"may impede performance. -1 means no batching, 0 means automatic batching."
argument_list|)
block|,
name|DISALLOW_INCOMPATIBLE_COL_TYPE_CHANGES
argument_list|(
literal|"metastore.disallow.incompatible.col.type.changes"
argument_list|,
literal|"hive.metastore.disallow.incompatible.col.type.changes"
argument_list|,
literal|true
argument_list|,
literal|"If true, ALTER TABLE operations which change the type of a\n"
operator|+
literal|"column (say STRING) to an incompatible type (say MAP) are disallowed.\n"
operator|+
literal|"RCFile default SerDe (ColumnarSerDe) serializes the values in such a way that the\n"
operator|+
literal|"datatypes can be converted from string to any type. The map is also serialized as\n"
operator|+
literal|"a string, which can be read as a string as well. However, with any binary\n"
operator|+
literal|"serialization, this is not true. Blocking the ALTER TABLE prevents ClassCastExceptions\n"
operator|+
literal|"when subsequently trying to access old partitions.\n"
operator|+
literal|"\n"
operator|+
literal|"Primitive types like INT, STRING, BIGINT, etc., are compatible with each other and are\n"
operator|+
literal|"not blocked.\n"
operator|+
literal|"\n"
operator|+
literal|"See HIVE-4409 for more details."
argument_list|)
block|,
name|DUMP_CONFIG_ON_CREATION
argument_list|(
literal|"metastore.dump.config.on.creation"
argument_list|,
literal|"metastore.dump.config.on.creation"
argument_list|,
literal|true
argument_list|,
literal|"If true, a printout of the config file (minus sensitive values) will be dumped to the "
operator|+
literal|"log whenever newMetastoreConf() is called.  Can produce a lot of logs"
argument_list|)
block|,
name|END_FUNCTION_LISTENERS
argument_list|(
literal|"metastore.end.function.listeners"
argument_list|,
literal|"hive.metastore.end.function.listeners"
argument_list|,
literal|""
argument_list|,
literal|"List of comma separated listeners for the end of metastore functions."
argument_list|)
block|,
name|EVENT_CLEAN_FREQ
argument_list|(
literal|"metastore.event.clean.freq"
argument_list|,
literal|"hive.metastore.event.clean.freq"
argument_list|,
literal|0
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Frequency at which timer task runs to purge expired events in metastore."
argument_list|)
block|,
name|EVENT_EXPIRY_DURATION
argument_list|(
literal|"metastore.event.expiry.duration"
argument_list|,
literal|"hive.metastore.event.expiry.duration"
argument_list|,
literal|0
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Duration after which events expire from events table"
argument_list|)
block|,
name|EVENT_LISTENERS
argument_list|(
literal|"metastore.event.listeners"
argument_list|,
literal|"hive.metastore.event.listeners"
argument_list|,
literal|""
argument_list|,
literal|"A comma separated list of Java classes that implement the org.apache.riven.MetaStoreEventListener"
operator|+
literal|" interface. The metastore event and corresponding listener method will be invoked in separate JDO transactions. "
operator|+
literal|"Alternatively, configure hive.metastore.transactional.event.listeners to ensure both are invoked in same JDO transaction."
argument_list|)
block|,
name|EVENT_MESSAGE_FACTORY
argument_list|(
literal|"metastore.event.message.factory"
argument_list|,
literal|"hive.metastore.event.message.factory"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory"
argument_list|,
literal|"Factory class for making encoding and decoding messages in the events generated."
argument_list|)
block|,
name|EVENT_DB_LISTENER_TTL
argument_list|(
literal|"metastore.event.db.listener.timetolive"
argument_list|,
literal|"hive.metastore.event.db.listener.timetolive"
argument_list|,
literal|86400
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"time after which events will be removed from the database listener queue"
argument_list|)
block|,
name|EVENT_DB_NOTIFICATION_API_AUTH
argument_list|(
literal|"metastore.metastore.event.db.notification.api.auth"
argument_list|,
literal|"hive.metastore.event.db.notification.api.auth"
argument_list|,
literal|true
argument_list|,
literal|"Should metastore do authorization against database notification related APIs such as get_next_notification.\n"
operator|+
literal|"If set to true, then only the superusers in proxy settings have the permission"
argument_list|)
block|,
name|EXECUTE_SET_UGI
argument_list|(
literal|"metastore.execute.setugi"
argument_list|,
literal|"hive.metastore.execute.setugi"
argument_list|,
literal|true
argument_list|,
literal|"In unsecure mode, setting this property to true will cause the metastore to execute DFS operations using \n"
operator|+
literal|"the client's reported user and group permissions. Note that this property must be set on \n"
operator|+
literal|"both the client and server sides. Further note that its best effort. \n"
operator|+
literal|"If client sets its to true and server sets it to false, client setting will be ignored."
argument_list|)
block|,
name|EXPRESSION_PROXY_CLASS
argument_list|(
literal|"metastore.expression.proxy"
argument_list|,
literal|"hive.metastore.expression.proxy"
argument_list|,
literal|"org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore"
argument_list|,
literal|"Class to use to process expressions in partition pruning."
argument_list|)
block|,
name|FILE_METADATA_THREADS
argument_list|(
literal|"metastore.file.metadata.threads"
argument_list|,
literal|"hive.metastore.hbase.file.metadata.threads"
argument_list|,
literal|1
argument_list|,
literal|"Number of threads to use to read file metadata in background to cache it."
argument_list|)
block|,
name|FILTER_HOOK
argument_list|(
literal|"metastore.filter.hook"
argument_list|,
literal|"hive.metastore.filter.hook"
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|DefaultMetaStoreFilterHookImpl
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|"Metastore hook class for filtering the metadata read results. If hive.security.authorization.manager"
operator|+
literal|"is set to instance of HiveAuthorizerFactory, then this value is ignored."
argument_list|)
block|,
name|FS_HANDLER_CLS
argument_list|(
literal|"metastore.fs.handler.class"
argument_list|,
literal|"hive.metastore.fs.handler.class"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl"
argument_list|,
literal|""
argument_list|)
block|,
name|FS_HANDLER_THREADS_COUNT
argument_list|(
literal|"metastore.fshandler.threads"
argument_list|,
literal|"hive.metastore.fshandler.threads"
argument_list|,
literal|15
argument_list|,
literal|"Number of threads to be allocated for metastore handler for fs operations."
argument_list|)
block|,
name|HMS_HANDLER_ATTEMPTS
argument_list|(
literal|"metastore.hmshandler.retry.attempts"
argument_list|,
literal|"hive.hmshandler.retry.attempts"
argument_list|,
literal|10
argument_list|,
literal|"The number of times to retry a HMSHandler call if there were a connection error."
argument_list|)
block|,
name|HMS_HANDLER_FORCE_RELOAD_CONF
argument_list|(
literal|"metastore.hmshandler.force.reload.conf"
argument_list|,
literal|"hive.hmshandler.force.reload.conf"
argument_list|,
literal|false
argument_list|,
literal|"Whether to force reloading of the HMSHandler configuration (including\n"
operator|+
literal|"the connection URL, before the next metastore query that accesses the\n"
operator|+
literal|"datastore. Once reloaded, this value is reset to false. Used for\n"
operator|+
literal|"testing only."
argument_list|)
block|,
name|HMS_HANDLER_INTERVAL
argument_list|(
literal|"metastore.hmshandler.retry.interval"
argument_list|,
literal|"hive.hmshandler.retry.interval"
argument_list|,
literal|2000
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
literal|"The time between HMSHandler retry attempts on failure."
argument_list|)
block|,
name|IDENTIFIER_FACTORY
argument_list|(
literal|"datanucleus.identifierFactory"
argument_list|,
literal|"datanucleus.identifierFactory"
argument_list|,
literal|"datanucleus1"
argument_list|,
literal|"Name of the identifier factory to use when generating table/column names etc. \n"
operator|+
literal|"'datanucleus1' is used for backward compatibility with DataNucleus v1"
argument_list|)
block|,
name|INIT_HOOKS
argument_list|(
literal|"metastore.init.hooks"
argument_list|,
literal|"hive.metastore.init.hooks"
argument_list|,
literal|""
argument_list|,
literal|"A comma separated list of hooks to be invoked at the beginning of HMSHandler initialization. \n"
operator|+
literal|"An init hook is specified as the name of Java class which extends org.apache.riven.MetaStoreInitListener."
argument_list|)
block|,
name|INIT_METADATA_COUNT_ENABLED
argument_list|(
literal|"metastore.initial.metadata.count.enabled"
argument_list|,
literal|"hive.metastore.initial.metadata.count.enabled"
argument_list|,
literal|true
argument_list|,
literal|"Enable a metadata count at metastore startup for metrics."
argument_list|)
block|,
name|INTEGER_JDO_PUSHDOWN
argument_list|(
literal|"metastore.integral.jdo.pushdown"
argument_list|,
literal|"hive.metastore.integral.jdo.pushdown"
argument_list|,
literal|false
argument_list|,
literal|"Allow JDO query pushdown for integral partition columns in metastore. Off by default. This\n"
operator|+
literal|"improves metastore perf for integral columns, especially if there's a large number of partitions.\n"
operator|+
literal|"However, it doesn't work correctly with integral values that are not normalized (e.g. have\n"
operator|+
literal|"leading zeroes, like 0012). If metastore direct SQL is enabled and works, this optimization\n"
operator|+
literal|"is also irrelevant."
argument_list|)
block|,
name|KERBEROS_KEYTAB_FILE
argument_list|(
literal|"metastore.kerberos.keytab.file"
argument_list|,
literal|"hive.metastore.kerberos.keytab.file"
argument_list|,
literal|""
argument_list|,
literal|"The path to the Kerberos Keytab file containing the metastore Thrift server's service principal."
argument_list|)
block|,
name|KERBEROS_PRINCIPAL
argument_list|(
literal|"metastore.kerberos.principal"
argument_list|,
literal|"hive.metastore.kerberos.principal"
argument_list|,
literal|"hive-metastore/_HOST@EXAMPLE.COM"
argument_list|,
literal|"The service principal for the metastore Thrift server. \n"
operator|+
literal|"The special string _HOST will be replaced automatically with the correct host name."
argument_list|)
block|,
name|LIMIT_PARTITION_REQUEST
argument_list|(
literal|"metastore.limit.partition.request"
argument_list|,
literal|"hive.metastore.limit.partition.request"
argument_list|,
operator|-
literal|1
argument_list|,
literal|"This limits the number of partitions (whole partition objects) that can be requested "
operator|+
literal|"from the metastore for a give table. MetaStore API methods using this are: \n"
operator|+
literal|"get_partitions, \n"
operator|+
literal|"get_partitions_with_auth, \n"
operator|+
literal|"get_partitions_by_filter, \n"
operator|+
literal|"get_partitions_by_expr.\n"
operator|+
literal|"The default value \"-1\" means no limit."
argument_list|)
block|,
name|LOG4J_FILE
argument_list|(
literal|"metastore.log4j.file"
argument_list|,
literal|"hive.log4j.file"
argument_list|,
literal|""
argument_list|,
literal|"Hive log4j configuration file.\n"
operator|+
literal|"If the property is not set, then logging will be initialized using metastore-log4j2.properties found on the classpath.\n"
operator|+
literal|"If the property is set, the value must be a valid URI (java.net.URI, e.g. \"file:///tmp/my-logging.xml\"), \n"
operator|+
literal|"which you can then extract a URL from and pass to PropertyConfigurator.configure(URL)."
argument_list|)
block|,
name|MANAGER_FACTORY_CLASS
argument_list|(
literal|"javax.jdo.PersistenceManagerFactoryClass"
argument_list|,
literal|"javax.jdo.PersistenceManagerFactoryClass"
argument_list|,
literal|"org.datanucleus.api.jdo.JDOPersistenceManagerFactory"
argument_list|,
literal|"class implementing the jdo persistence"
argument_list|)
block|,
name|MATERIALIZATIONS_INVALIDATION_CACHE_IMPL
argument_list|(
literal|"metastore.materializations.invalidation.impl"
argument_list|,
literal|"hive.metastore.materializations.invalidation.impl"
argument_list|,
literal|"DEFAULT"
argument_list|,
operator|new
name|StringSetValidator
argument_list|(
literal|"DEFAULT"
argument_list|,
literal|"DISABLE"
argument_list|)
argument_list|,
literal|"The implementation that we should use for the materializations invalidation cache. \n"
operator|+
literal|"  DEFAULT: Default implementation for invalidation cache\n"
operator|+
literal|"  DISABLE: Disable invalidation cache (debugging purposes)"
argument_list|)
block|,
name|MATERIALIZATIONS_INVALIDATION_CACHE_CLEAN_FREQUENCY
argument_list|(
literal|"metastore.materializations.invalidation.clean.frequency"
argument_list|,
literal|"hive.metastore.materializations.invalidation.clean.frequency"
argument_list|,
literal|3600
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Frequency at which timer task runs to remove unnecessary transaction entries from"
operator|+
literal|"materializations invalidation cache."
argument_list|)
block|,
name|MATERIALIZATIONS_INVALIDATION_CACHE_EXPIRY_DURATION
argument_list|(
literal|"metastore.materializations.invalidation.max.duration"
argument_list|,
literal|"hive.metastore.materializations.invalidation.max.duration"
argument_list|,
literal|86400
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Maximum duration for query producing a materialization. After this time, transaction"
operator|+
literal|"entries that are not relevant for materializations can be removed from invalidation cache."
argument_list|)
block|,
name|RUNTIME_STATS_CLEAN_FREQUENCY
argument_list|(
literal|"runtime.stats.clean.frequency"
argument_list|,
literal|"hive.metastore.runtime.stats.clean.frequency"
argument_list|,
literal|3600
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Frequency at which timer task runs to remove outdated runtime stat entries."
argument_list|)
block|,
name|RUNTIME_STATS_MAX_AGE
argument_list|(
literal|"runtime.stats.max.age"
argument_list|,
literal|"hive.metastore.runtime.stats.max.age"
argument_list|,
literal|86400
operator|*
literal|3
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Stat entries which are older than this are removed."
argument_list|)
block|,
comment|// Parameters for exporting metadata on table drop (requires the use of the)
comment|// org.apache.hadoop.hive.ql.parse.MetaDataExportListener preevent listener
name|METADATA_EXPORT_LOCATION
argument_list|(
literal|"metastore.metadata.export.location"
argument_list|,
literal|"hive.metadata.export.location"
argument_list|,
literal|""
argument_list|,
literal|"When used in conjunction with the org.apache.hadoop.hive.ql.parse.MetaDataExportListener pre event listener, \n"
operator|+
literal|"it is the location to which the metadata will be exported. The default is an empty string, which results in the \n"
operator|+
literal|"metadata being exported to the current user's home directory on HDFS."
argument_list|)
block|,
name|MOVE_EXPORTED_METADATA_TO_TRASH
argument_list|(
literal|"metastore.metadata.move.exported.metadata.to.trash"
argument_list|,
literal|"hive.metadata.move.exported.metadata.to.trash"
argument_list|,
literal|true
argument_list|,
literal|"When used in conjunction with the org.apache.hadoop.hive.ql.parse.MetaDataExportListener pre event listener, \n"
operator|+
literal|"this setting determines if the metadata that is exported will subsequently be moved to the user's trash directory \n"
operator|+
literal|"alongside the dropped table data. This ensures that the metadata will be cleaned up along with the dropped table data."
argument_list|)
block|,
name|METRICS_ENABLED
argument_list|(
literal|"metastore.metrics.enabled"
argument_list|,
literal|"hive.metastore.metrics.enabled"
argument_list|,
literal|false
argument_list|,
literal|"Enable metrics on the metastore."
argument_list|)
block|,
name|METRICS_JSON_FILE_INTERVAL
argument_list|(
literal|"metastore.metrics.file.frequency"
argument_list|,
literal|"hive.service.metrics.file.frequency"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|MINUTES
argument_list|,
literal|"For json metric reporter, the frequency of updating JSON metrics file."
argument_list|)
block|,
name|METRICS_JSON_FILE_LOCATION
argument_list|(
literal|"metastore.metrics.file.location"
argument_list|,
literal|"hive.service.metrics.file.location"
argument_list|,
literal|"/tmp/report.json"
argument_list|,
literal|"For metric class json metric reporter, the location of local JSON metrics file.  "
operator|+
literal|"This file will get overwritten at every interval."
argument_list|)
block|,
name|METRICS_REPORTERS
argument_list|(
literal|"metastore.metrics.reporters"
argument_list|,
literal|"metastore.metrics.reporters"
argument_list|,
literal|"json,jmx"
argument_list|,
operator|new
name|StringSetValidator
argument_list|(
literal|"json"
argument_list|,
literal|"jmx"
argument_list|,
literal|"console"
argument_list|,
literal|"hadoop"
argument_list|)
argument_list|,
literal|"A comma separated list of metrics reporters to start"
argument_list|)
block|,
name|MULTITHREADED
argument_list|(
literal|"javax.jdo.option.Multithreaded"
argument_list|,
literal|"javax.jdo.option.Multithreaded"
argument_list|,
literal|true
argument_list|,
literal|"Set this to true if multiple threads access metastore through JDO concurrently."
argument_list|)
block|,
name|MAX_OPEN_TXNS
argument_list|(
literal|"metastore.max.open.txns"
argument_list|,
literal|"hive.max.open.txns"
argument_list|,
literal|100000
argument_list|,
literal|"Maximum number of open transactions. If \n"
operator|+
literal|"current open transactions reach this limit, future open transaction requests will be \n"
operator|+
literal|"rejected, until this number goes below the limit."
argument_list|)
block|,
name|NON_TRANSACTIONAL_READ
argument_list|(
literal|"javax.jdo.option.NonTransactionalRead"
argument_list|,
literal|"javax.jdo.option.NonTransactionalRead"
argument_list|,
literal|true
argument_list|,
literal|"Reads outside of transactions"
argument_list|)
block|,
name|NOTIFICATION_SEQUENCE_LOCK_MAX_RETRIES
argument_list|(
literal|"metastore.notification.sequence.lock.max.retries"
argument_list|,
literal|"hive.notification.sequence.lock.max.retries"
argument_list|,
literal|5
argument_list|,
literal|"Number of retries required to acquire a lock when getting the next notification sequential ID for entries "
operator|+
literal|"in the NOTIFICATION_LOG table."
argument_list|)
block|,
name|NOTIFICATION_SEQUENCE_LOCK_RETRY_SLEEP_INTERVAL
argument_list|(
literal|"metastore.notification.sequence.lock.retry.sleep.interval"
argument_list|,
literal|"hive.notification.sequence.lock.retry.sleep.interval"
argument_list|,
literal|500
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
literal|"Sleep interval between retries to acquire a notification lock as described part of property "
operator|+
name|NOTIFICATION_SEQUENCE_LOCK_MAX_RETRIES
operator|.
name|name
argument_list|()
argument_list|)
block|,
name|ORM_RETRIEVE_MAPNULLS_AS_EMPTY_STRINGS
argument_list|(
literal|"metastore.orm.retrieveMapNullsAsEmptyStrings"
argument_list|,
literal|"hive.metastore.orm.retrieveMapNullsAsEmptyStrings"
argument_list|,
literal|false
argument_list|,
literal|"Thrift does not support nulls in maps, so any nulls present in maps retrieved from ORM must "
operator|+
literal|"either be pruned or converted to empty strings. Some backing dbs such as Oracle persist empty strings "
operator|+
literal|"as nulls, so we should set this parameter if we wish to reverse that behaviour. For others, "
operator|+
literal|"pruning is the correct behaviour"
argument_list|)
block|,
name|PARTITION_NAME_WHITELIST_PATTERN
argument_list|(
literal|"metastore.partition.name.whitelist.pattern"
argument_list|,
literal|"hive.metastore.partition.name.whitelist.pattern"
argument_list|,
literal|""
argument_list|,
literal|"Partition names will be checked against this regex pattern and rejected if not matched."
argument_list|)
block|,
name|PART_INHERIT_TBL_PROPS
argument_list|(
literal|"metastore.partition.inherit.table.properties"
argument_list|,
literal|"hive.metastore.partition.inherit.table.properties"
argument_list|,
literal|""
argument_list|,
literal|"List of comma separated keys occurring in table properties which will get inherited to newly created partitions. \n"
operator|+
literal|"* implies all the keys will get inherited."
argument_list|)
block|,
name|PRE_EVENT_LISTENERS
argument_list|(
literal|"metastore.pre.event.listeners"
argument_list|,
literal|"hive.metastore.pre.event.listeners"
argument_list|,
literal|""
argument_list|,
literal|"List of comma separated listeners for metastore events."
argument_list|)
block|,
name|PWD
argument_list|(
literal|"javax.jdo.option.ConnectionPassword"
argument_list|,
literal|"javax.jdo.option.ConnectionPassword"
argument_list|,
literal|"mine"
argument_list|,
literal|"password to use against metastore database"
argument_list|)
block|,
name|RAW_STORE_IMPL
argument_list|(
literal|"metastore.rawstore.impl"
argument_list|,
literal|"hive.metastore.rawstore.impl"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.ObjectStore"
argument_list|,
literal|"Name of the class that implements org.apache.riven.rawstore interface. \n"
operator|+
literal|"This class is used to store and retrieval of raw metadata objects such as table, database"
argument_list|)
block|,
name|REPLCMDIR
argument_list|(
literal|"metastore.repl.cmrootdir"
argument_list|,
literal|"hive.repl.cmrootdir"
argument_list|,
literal|"/user/hive/cmroot/"
argument_list|,
literal|"Root dir for ChangeManager, used for deleted files."
argument_list|)
block|,
name|REPLCMRETIAN
argument_list|(
literal|"metastore.repl.cm.retain"
argument_list|,
literal|"hive.repl.cm.retain"
argument_list|,
literal|24
argument_list|,
name|TimeUnit
operator|.
name|HOURS
argument_list|,
literal|"Time to retain removed files in cmrootdir."
argument_list|)
block|,
name|REPLCMINTERVAL
argument_list|(
literal|"metastore.repl.cm.interval"
argument_list|,
literal|"hive.repl.cm.interval"
argument_list|,
literal|3600
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Inteval for cmroot cleanup thread."
argument_list|)
block|,
name|REPLCMENABLED
argument_list|(
literal|"metastore.repl.cm.enabled"
argument_list|,
literal|"hive.repl.cm.enabled"
argument_list|,
literal|false
argument_list|,
literal|"Turn on ChangeManager, so delete files will go to cmrootdir."
argument_list|)
block|,
name|REPLDIR
argument_list|(
literal|"metastore.repl.rootdir"
argument_list|,
literal|"hive.repl.rootdir"
argument_list|,
literal|"/user/hive/repl/"
argument_list|,
literal|"HDFS root dir for all replication dumps."
argument_list|)
block|,
name|REPL_COPYFILE_MAXNUMFILES
argument_list|(
literal|"metastore.repl.copyfile.maxnumfiles"
argument_list|,
literal|"hive.exec.copyfile.maxnumfiles"
argument_list|,
literal|1L
argument_list|,
literal|"Maximum number of files Hive uses to do sequential HDFS copies between directories."
operator|+
literal|"Distributed copies (distcp) will be used instead for larger numbers of files so that copies can be done faster."
argument_list|)
block|,
name|REPL_COPYFILE_MAXSIZE
argument_list|(
literal|"metastore.repl.copyfile.maxsize"
argument_list|,
literal|"hive.exec.copyfile.maxsize"
argument_list|,
literal|32L
operator|*
literal|1024
operator|*
literal|1024
comment|/*32M*/
argument_list|,
literal|"Maximum file size (in bytes) that Hive uses to do single HDFS copies between directories."
operator|+
literal|"Distributed copies (distcp) will be used instead for bigger files so that copies can be done faster."
argument_list|)
block|,
name|SCHEMA_INFO_CLASS
argument_list|(
literal|"metastore.schema.info.class"
argument_list|,
literal|"hive.metastore.schema.info.class"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo"
argument_list|,
literal|"Fully qualified class name for the metastore schema information class \n"
operator|+
literal|"which is used by schematool to fetch the schema information.\n"
operator|+
literal|" This class should implement the IMetaStoreSchemaInfo interface"
argument_list|)
block|,
name|SCHEMA_VERIFICATION
argument_list|(
literal|"metastore.schema.verification"
argument_list|,
literal|"hive.metastore.schema.verification"
argument_list|,
literal|true
argument_list|,
literal|"Enforce metastore schema version consistency.\n"
operator|+
literal|"True: Verify that version information stored in is compatible with one from Hive jars.  Also disable automatic\n"
operator|+
literal|"      schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures\n"
operator|+
literal|"      proper metastore schema migration. (Default)\n"
operator|+
literal|"False: Warn if the version information stored in metastore doesn't match with one from in Hive jars."
argument_list|)
block|,
name|SCHEMA_VERIFICATION_RECORD_VERSION
argument_list|(
literal|"metastore.schema.verification.record.version"
argument_list|,
literal|"hive.metastore.schema.verification.record.version"
argument_list|,
literal|false
argument_list|,
literal|"When true the current MS version is recorded in the VERSION table. If this is disabled and verification is\n"
operator|+
literal|" enabled the MS will be unusable."
argument_list|)
block|,
name|SERDES_USING_METASTORE_FOR_SCHEMA
argument_list|(
literal|"metastore.serdes.using.metastore.for.schema"
argument_list|,
literal|"hive.serdes.using.metastore.for.schema"
argument_list|,
literal|"org.apache.hadoop.hive.ql.io.orc.OrcSerde,"
operator|+
literal|"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,"
operator|+
literal|"org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,"
operator|+
literal|"org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,"
operator|+
literal|"org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,"
operator|+
literal|"org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,"
operator|+
literal|"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,"
operator|+
literal|"org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe"
argument_list|,
literal|"SerDes retrieving schema from metastore. This is an internal parameter."
argument_list|)
block|,
name|SERVER_MAX_MESSAGE_SIZE
argument_list|(
literal|"metastore.server.max.message.size"
argument_list|,
literal|"hive.metastore.server.max.message.size"
argument_list|,
literal|100
operator|*
literal|1024
operator|*
literal|1024L
argument_list|,
literal|"Maximum message size in bytes a HMS will accept."
argument_list|)
block|,
name|SERVER_MAX_THREADS
argument_list|(
literal|"metastore.server.max.threads"
argument_list|,
literal|"hive.metastore.server.max.threads"
argument_list|,
literal|1000
argument_list|,
literal|"Maximum number of worker threads in the Thrift server's pool."
argument_list|)
block|,
name|SERVER_MIN_THREADS
argument_list|(
literal|"metastore.server.min.threads"
argument_list|,
literal|"hive.metastore.server.min.threads"
argument_list|,
literal|200
argument_list|,
literal|"Minimum number of worker threads in the Thrift server's pool."
argument_list|)
block|,
name|SERVER_PORT
argument_list|(
literal|"metastore.thrift.port"
argument_list|,
literal|"hive.metastore.port"
argument_list|,
literal|9083
argument_list|,
literal|"Hive metastore listener port"
argument_list|)
block|,
name|SSL_KEYSTORE_PASSWORD
argument_list|(
literal|"metastore.keystore.password"
argument_list|,
literal|"hive.metastore.keystore.password"
argument_list|,
literal|""
argument_list|,
literal|"Metastore SSL certificate keystore password."
argument_list|)
block|,
name|SSL_KEYSTORE_PATH
argument_list|(
literal|"metastore.keystore.path"
argument_list|,
literal|"hive.metastore.keystore.path"
argument_list|,
literal|""
argument_list|,
literal|"Metastore SSL certificate keystore location."
argument_list|)
block|,
name|SSL_PROTOCOL_BLACKLIST
argument_list|(
literal|"metastore.ssl.protocol.blacklist"
argument_list|,
literal|"hive.ssl.protocol.blacklist"
argument_list|,
literal|"SSLv2,SSLv3"
argument_list|,
literal|"SSL Versions to disable for all Hive Servers"
argument_list|)
block|,
name|SSL_TRUSTSTORE_PATH
argument_list|(
literal|"metastore.truststore.path"
argument_list|,
literal|"hive.metastore.truststore.path"
argument_list|,
literal|""
argument_list|,
literal|"Metastore SSL certificate truststore location."
argument_list|)
block|,
name|SSL_TRUSTSTORE_PASSWORD
argument_list|(
literal|"metastore.truststore.password"
argument_list|,
literal|"hive.metastore.truststore.password"
argument_list|,
literal|""
argument_list|,
literal|"Metastore SSL certificate truststore password."
argument_list|)
block|,
name|STATS_AUTO_GATHER
argument_list|(
literal|"metastore.stats.autogather"
argument_list|,
literal|"hive.stats.autogather"
argument_list|,
literal|true
argument_list|,
literal|"A flag to gather statistics (only basic) automatically during the INSERT OVERWRITE command."
argument_list|)
block|,
name|STATS_FETCH_BITVECTOR
argument_list|(
literal|"metastore.stats.fetch.bitvector"
argument_list|,
literal|"hive.stats.fetch.bitvector"
argument_list|,
literal|false
argument_list|,
literal|"Whether we fetch bitvector when we compute ndv. Users can turn it off if they want to use old schema"
argument_list|)
block|,
name|STATS_NDV_TUNER
argument_list|(
literal|"metastore.stats.ndv.tuner"
argument_list|,
literal|"hive.metastore.stats.ndv.tuner"
argument_list|,
literal|0.0
argument_list|,
literal|"Provides a tunable parameter between the lower bound and the higher bound of ndv for aggregate ndv across all the partitions. \n"
operator|+
literal|"The lower bound is equal to the maximum of ndv of all the partitions. The higher bound is equal to the sum of ndv of all the partitions.\n"
operator|+
literal|"Its value should be between 0.0 (i.e., choose lower bound) and 1.0 (i.e., choose higher bound)"
argument_list|)
block|,
name|STATS_NDV_DENSITY_FUNCTION
argument_list|(
literal|"metastore.stats.ndv.densityfunction"
argument_list|,
literal|"hive.metastore.stats.ndv.densityfunction"
argument_list|,
literal|false
argument_list|,
literal|"Whether to use density function to estimate the NDV for the whole table based on the NDV of partitions"
argument_list|)
block|,
name|STATS_DEFAULT_AGGREGATOR
argument_list|(
literal|"metastore.stats.default.aggregator"
argument_list|,
literal|"hive.stats.default.aggregator"
argument_list|,
literal|""
argument_list|,
literal|"The Java class (implementing the StatsAggregator interface) that is used by default if hive.stats.dbclass is custom type."
argument_list|)
block|,
name|STATS_DEFAULT_PUBLISHER
argument_list|(
literal|"metastore.stats.default.publisher"
argument_list|,
literal|"hive.stats.default.publisher"
argument_list|,
literal|""
argument_list|,
literal|"The Java class (implementing the StatsPublisher interface) that is used by default if hive.stats.dbclass is custom type."
argument_list|)
block|,
name|STATS_AUTO_UPDATE
argument_list|(
literal|"metastore.stats.auto.analyze"
argument_list|,
literal|"hive.metastore.stats.auto.analyze"
argument_list|,
literal|"none"
argument_list|,
operator|new
name|EnumValidator
argument_list|(
name|StatsUpdateMode
operator|.
name|values
argument_list|()
argument_list|)
argument_list|,
literal|"Whether to update stats in the background; none - no, all - for all tables, existing - only existing, out of date, stats."
argument_list|)
block|,
name|STATS_AUTO_UPDATE_NOOP_WAIT
argument_list|(
literal|"metastore.stats.auto.analyze.noop.wait"
argument_list|,
literal|"hive.metastore.stats.auto.analyze.noop.wait"
argument_list|,
literal|5L
argument_list|,
name|TimeUnit
operator|.
name|MINUTES
argument_list|,
operator|new
name|TimeValidator
argument_list|(
name|TimeUnit
operator|.
name|MINUTES
argument_list|)
argument_list|,
literal|"How long to sleep if there were no stats needing update during an update iteration.\n"
operator|+
literal|"This is a setting to throttle table/partition checks when nothing is being changed; not\n"
operator|+
literal|"the analyze queries themselves."
argument_list|)
block|,
name|STATS_AUTO_UPDATE_WORKER_COUNT
argument_list|(
literal|"metastore.stats.auto.analyze.worker.count"
argument_list|,
literal|"hive.metastore.stats.auto.analyze.worker.count"
argument_list|,
literal|1
argument_list|,
literal|"Number of parallel analyze commands to run for background stats update."
argument_list|)
block|,
name|STORAGE_SCHEMA_READER_IMPL
argument_list|(
literal|"metastore.storage.schema.reader.impl"
argument_list|,
literal|"metastore.storage.schema.reader.impl"
argument_list|,
name|DefaultStorageSchemaReader
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|"The class to use to read schemas from storage.  It must implement "
operator|+
literal|"org.apache.hadoop.hive.metastore.StorageSchemaReader"
argument_list|)
block|,
name|STORE_MANAGER_TYPE
argument_list|(
literal|"datanucleus.storeManagerType"
argument_list|,
literal|"datanucleus.storeManagerType"
argument_list|,
literal|"rdbms"
argument_list|,
literal|"metadata store type"
argument_list|)
block|,
name|STRICT_MANAGED_TABLES
argument_list|(
literal|"metastore.strict.managed.tables"
argument_list|,
literal|"hive.strict.managed.tables"
argument_list|,
literal|false
argument_list|,
literal|"Whether strict managed tables mode is enabled. With this mode enabled, "
operator|+
literal|"only transactional tables (both full and insert-only) are allowed to be created as managed tables"
argument_list|)
block|,
name|SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES
argument_list|(
literal|"metastore.support.special.characters.tablename"
argument_list|,
literal|"hive.support.special.characters.tablename"
argument_list|,
literal|true
argument_list|,
literal|"This flag should be set to true to enable support for special characters in table names.\n"
operator|+
literal|"When it is set to false, only [a-zA-Z_0-9]+ are supported.\n"
operator|+
literal|"The only supported special character right now is '/'. This flag applies only to quoted table names.\n"
operator|+
literal|"The default value is true."
argument_list|)
block|,
name|TASK_THREADS_ALWAYS
argument_list|(
literal|"metastore.task.threads.always"
argument_list|,
literal|"metastore.task.threads.always"
argument_list|,
name|EventCleanerTask
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
name|RuntimeStatsCleanerTask
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
literal|"org.apache.hadoop.hive.metastore.repl.DumpDirCleanerTask"
operator|+
literal|","
operator|+
name|MaterializationsCacheCleanerTask
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
name|MaterializationsRebuildLockCleanerTask
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
name|RuntimeStatsCleanerTask
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|"Comma separated list of tasks that will be started in separate threads.  These will "
operator|+
literal|"always be started, regardless of whether the metastore is running in embedded mode "
operator|+
literal|"or in server mode.  They must implement "
operator|+
name|MetastoreTaskThread
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
block|,
name|TASK_THREADS_REMOTE_ONLY
argument_list|(
literal|"metastore.task.threads.remote"
argument_list|,
literal|"metastore.task.threads.remote"
argument_list|,
name|AcidHouseKeeperService
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
name|AcidOpenTxnsCounterService
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
name|AcidCompactionHistoryService
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|","
operator|+
name|AcidWriteSetService
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|"Command separated list of tasks that will be started in separate threads.  These will be"
operator|+
literal|" started only when the metastore is running as a separate service.  They must "
operator|+
literal|"implement "
operator|+
name|MetastoreTaskThread
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
block|,
name|TCP_KEEP_ALIVE
argument_list|(
literal|"metastore.server.tcp.keepalive"
argument_list|,
literal|"hive.metastore.server.tcp.keepalive"
argument_list|,
literal|true
argument_list|,
literal|"Whether to enable TCP keepalive for the metastore server. Keepalive will prevent accumulation of half-open connections."
argument_list|)
block|,
name|THREAD_POOL_SIZE
argument_list|(
literal|"metastore.thread.pool.size"
argument_list|,
literal|"no.such"
argument_list|,
literal|10
argument_list|,
literal|"Number of threads in the thread pool.  These will be used to execute all background "
operator|+
literal|"processes."
argument_list|)
block|,
name|THRIFT_CONNECTION_RETRIES
argument_list|(
literal|"metastore.connect.retries"
argument_list|,
literal|"hive.metastore.connect.retries"
argument_list|,
literal|3
argument_list|,
literal|"Number of retries while opening a connection to metastore"
argument_list|)
block|,
name|THRIFT_FAILURE_RETRIES
argument_list|(
literal|"metastore.failure.retries"
argument_list|,
literal|"hive.metastore.failure.retries"
argument_list|,
literal|1
argument_list|,
literal|"Number of retries upon failure of Thrift metastore calls"
argument_list|)
block|,
name|THRIFT_URIS
argument_list|(
literal|"metastore.thrift.uris"
argument_list|,
literal|"hive.metastore.uris"
argument_list|,
literal|""
argument_list|,
literal|"Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore."
argument_list|)
block|,
name|THRIFT_URI_SELECTION
argument_list|(
literal|"metastore.thrift.uri.selection"
argument_list|,
literal|"hive.metastore.uri.selection"
argument_list|,
literal|"RANDOM"
argument_list|,
operator|new
name|StringSetValidator
argument_list|(
literal|"RANDOM"
argument_list|,
literal|"SEQUENTIAL"
argument_list|)
argument_list|,
literal|"Determines the selection mechanism used by metastore client to connect to remote "
operator|+
literal|"metastore.  SEQUENTIAL implies that the first valid metastore from the URIs specified "
operator|+
literal|"as part of hive.metastore.uris will be picked.  RANDOM implies that the metastore "
operator|+
literal|"will be picked randomly"
argument_list|)
block|,
name|TIMEDOUT_TXN_REAPER_START
argument_list|(
literal|"metastore.timedout.txn.reaper.start"
argument_list|,
literal|"hive.timedout.txn.reaper.start"
argument_list|,
literal|100
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Time delay of 1st reaper run after metastore start"
argument_list|)
block|,
name|TIMEDOUT_TXN_REAPER_INTERVAL
argument_list|(
literal|"metastore.timedout.txn.reaper.interval"
argument_list|,
literal|"hive.timedout.txn.reaper.interval"
argument_list|,
literal|180
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Time interval describing how often the reaper runs"
argument_list|)
block|,
name|TOKEN_SIGNATURE
argument_list|(
literal|"metastore.token.signature"
argument_list|,
literal|"hive.metastore.token.signature"
argument_list|,
literal|""
argument_list|,
literal|"The delegation token service name to match when selecting a token from the current user's tokens."
argument_list|)
block|,
name|TRANSACTIONAL_EVENT_LISTENERS
argument_list|(
literal|"metastore.transactional.event.listeners"
argument_list|,
literal|"hive.metastore.transactional.event.listeners"
argument_list|,
literal|""
argument_list|,
literal|"A comma separated list of Java classes that implement the org.apache.riven.MetaStoreEventListener"
operator|+
literal|" interface. Both the metastore event and corresponding listener method will be invoked in the same JDO transaction."
argument_list|)
block|,
name|TRY_DIRECT_SQL
argument_list|(
literal|"metastore.try.direct.sql"
argument_list|,
literal|"hive.metastore.try.direct.sql"
argument_list|,
literal|true
argument_list|,
literal|"Whether the metastore should try to use direct SQL queries instead of the\n"
operator|+
literal|"DataNucleus for certain read paths. This can improve metastore performance when\n"
operator|+
literal|"fetching many partitions or column statistics by orders of magnitude; however, it\n"
operator|+
literal|"is not guaranteed to work on all RDBMS-es and all versions. In case of SQL failures,\n"
operator|+
literal|"the metastore will fall back to the DataNucleus, so it's safe even if SQL doesn't\n"
operator|+
literal|"work for all queries on your datastore. If all SQL queries fail (for example, your\n"
operator|+
literal|"metastore is backed by MongoDB), you might want to disable this to save the\n"
operator|+
literal|"try-and-fall-back cost."
argument_list|)
block|,
name|TRY_DIRECT_SQL_DDL
argument_list|(
literal|"metastore.try.direct.sql.ddl"
argument_list|,
literal|"hive.metastore.try.direct.sql.ddl"
argument_list|,
literal|true
argument_list|,
literal|"Same as hive.metastore.try.direct.sql, for read statements within a transaction that\n"
operator|+
literal|"modifies metastore data. Due to non-standard behavior in Postgres, if a direct SQL\n"
operator|+
literal|"select query has incorrect syntax or something similar inside a transaction, the\n"
operator|+
literal|"entire transaction will fail and fall-back to DataNucleus will not be possible. You\n"
operator|+
literal|"should disable the usage of direct SQL inside transactions if that happens in your case."
argument_list|)
block|,
name|TXN_MAX_OPEN_BATCH
argument_list|(
literal|"metastore.txn.max.open.batch"
argument_list|,
literal|"hive.txn.max.open.batch"
argument_list|,
literal|1000
argument_list|,
literal|"Maximum number of transactions that can be fetched in one call to open_txns().\n"
operator|+
literal|"This controls how many transactions streaming agents such as Flume or Storm open\n"
operator|+
literal|"simultaneously. The streaming agent then writes that number of entries into a single\n"
operator|+
literal|"file (per Flume agent or Storm bolt). Thus increasing this value decreases the number\n"
operator|+
literal|"of delta files created by streaming agents. But it also increases the number of open\n"
operator|+
literal|"transactions that Hive has to track at any given time, which may negatively affect\n"
operator|+
literal|"read performance."
argument_list|)
block|,
name|TXN_RETRYABLE_SQLEX_REGEX
argument_list|(
literal|"metastore.txn.retryable.sqlex.regex"
argument_list|,
literal|"hive.txn.retryable.sqlex.regex"
argument_list|,
literal|""
argument_list|,
literal|"Comma separated list\n"
operator|+
literal|"of regular expression patterns for SQL state, error code, and error message of\n"
operator|+
literal|"retryable SQLExceptions, that's suitable for the metastore DB.\n"
operator|+
literal|"For example: Can't serialize.*,40001$,^Deadlock,.*ORA-08176.*\n"
operator|+
literal|"The string that the regex will be matched against is of the following form, where ex is a SQLException:\n"
operator|+
literal|"ex.getMessage() + \" (SQLState=\" + ex.getSQLState() + \", ErrorCode=\" + ex.getErrorCode() + \")\""
argument_list|)
block|,
name|TXN_STORE_IMPL
argument_list|(
literal|"metastore.txn.store.impl"
argument_list|,
literal|"hive.metastore.txn.store.impl"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler"
argument_list|,
literal|"Name of class that implements org.apache.riven.txn.TxnStore.  This "
operator|+
literal|"class is used to store and retrieve transactions and locks"
argument_list|)
block|,
name|TXN_TIMEOUT
argument_list|(
literal|"metastore.txn.timeout"
argument_list|,
literal|"hive.txn.timeout"
argument_list|,
literal|300
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"time after which transactions are declared aborted if the client has not sent a heartbeat."
argument_list|)
block|,
name|URI_RESOLVER
argument_list|(
literal|"metastore.uri.resolver"
argument_list|,
literal|"hive.metastore.uri.resolver"
argument_list|,
literal|""
argument_list|,
literal|"If set, fully qualified class name of resolver for hive metastore uri's"
argument_list|)
block|,
name|USERS_IN_ADMIN_ROLE
argument_list|(
literal|"metastore.users.in.admin.role"
argument_list|,
literal|"hive.users.in.admin.role"
argument_list|,
literal|""
argument_list|,
literal|false
argument_list|,
literal|"Comma separated list of users who are in admin role for bootstrapping.\n"
operator|+
literal|"More users can be added in ADMIN role later."
argument_list|)
block|,
name|USE_SSL
argument_list|(
literal|"metastore.use.SSL"
argument_list|,
literal|"hive.metastore.use.SSL"
argument_list|,
literal|false
argument_list|,
literal|"Set this to true for using SSL encryption in HMS server."
argument_list|)
block|,
name|USE_THRIFT_SASL
argument_list|(
literal|"metastore.sasl.enabled"
argument_list|,
literal|"hive.metastore.sasl.enabled"
argument_list|,
literal|false
argument_list|,
literal|"If true, the metastore Thrift interface will be secured with SASL. Clients must authenticate with Kerberos."
argument_list|)
block|,
name|USE_THRIFT_FRAMED_TRANSPORT
argument_list|(
literal|"metastore.thrift.framed.transport.enabled"
argument_list|,
literal|"hive.metastore.thrift.framed.transport.enabled"
argument_list|,
literal|false
argument_list|,
literal|"If true, the metastore Thrift interface will use TFramedTransport. When false (default) a standard TTransport is used."
argument_list|)
block|,
name|USE_THRIFT_COMPACT_PROTOCOL
argument_list|(
literal|"metastore.thrift.compact.protocol.enabled"
argument_list|,
literal|"hive.metastore.thrift.compact.protocol.enabled"
argument_list|,
literal|false
argument_list|,
literal|"If true, the metastore Thrift interface will use TCompactProtocol. When false (default) TBinaryProtocol will be used.\n"
operator|+
literal|"Setting it to true will break compatibility with older clients running TBinaryProtocol."
argument_list|)
block|,
name|VALIDATE_COLUMNS
argument_list|(
literal|"datanucleus.schema.validateColumns"
argument_list|,
literal|"datanucleus.schema.validateColumns"
argument_list|,
literal|false
argument_list|,
literal|"validates existing schema against code. turn this on if you want to verify existing schema"
argument_list|)
block|,
name|VALIDATE_CONSTRAINTS
argument_list|(
literal|"datanucleus.schema.validateConstraints"
argument_list|,
literal|"datanucleus.schema.validateConstraints"
argument_list|,
literal|false
argument_list|,
literal|"validates existing schema against code. turn this on if you want to verify existing schema"
argument_list|)
block|,
name|VALIDATE_TABLES
argument_list|(
literal|"datanucleus.schema.validateTables"
argument_list|,
literal|"datanucleus.schema.validateTables"
argument_list|,
literal|false
argument_list|,
literal|"validates existing schema against code. turn this on if you want to verify existing schema"
argument_list|)
block|,
name|WAREHOUSE
argument_list|(
literal|"metastore.warehouse.dir"
argument_list|,
literal|"hive.metastore.warehouse.dir"
argument_list|,
literal|"/user/hive/warehouse"
argument_list|,
literal|"location of default database for the warehouse"
argument_list|)
block|,
name|WAREHOUSE_EXTERNAL
argument_list|(
literal|"metastore.warehouse.external.dir"
argument_list|,
literal|"hive.metastore.warehouse.external.dir"
argument_list|,
literal|""
argument_list|,
literal|"Default location for external tables created in the warehouse. "
operator|+
literal|"If not set or null, then the normal warehouse location will be used as the default location."
argument_list|)
block|,
name|WRITE_SET_REAPER_INTERVAL
argument_list|(
literal|"metastore.writeset.reaper.interval"
argument_list|,
literal|"hive.writeset.reaper.interval"
argument_list|,
literal|60
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"Frequency of WriteSet reaper runs"
argument_list|)
block|,
name|WM_DEFAULT_POOL_SIZE
argument_list|(
literal|"metastore.wm.default.pool.size"
argument_list|,
literal|"hive.metastore.wm.default.pool.size"
argument_list|,
literal|4
argument_list|,
literal|"The size of a default pool to create when creating an empty resource plan;\n"
operator|+
literal|"If not positive, no default pool will be created."
argument_list|)
block|,
name|RAWSTORE_PARTITION_BATCH_SIZE
argument_list|(
literal|"metastore.rawstore.batch.size"
argument_list|,
literal|"metastore.rawstore.batch.size"
argument_list|,
operator|-
literal|1
argument_list|,
literal|"Batch size for partition and other object retrieval from the underlying DB in JDO.\n"
operator|+
literal|"The JDO implementation such as DataNucleus may run into issues when the generated queries are\n"
operator|+
literal|"too large. Use this parameter to break the query into multiple batches. -1 means no batching."
argument_list|)
block|,
comment|// Hive values we have copied and use as is
comment|// These two are used to indicate that we are running tests
name|HIVE_IN_TEST
argument_list|(
literal|"hive.in.test"
argument_list|,
literal|"hive.in.test"
argument_list|,
literal|false
argument_list|,
literal|"internal usage only, true in test mode"
argument_list|)
block|,
name|HIVE_IN_TEZ_TEST
argument_list|(
literal|"hive.in.tez.test"
argument_list|,
literal|"hive.in.tez.test"
argument_list|,
literal|false
argument_list|,
literal|"internal use only, true when in testing tez"
argument_list|)
block|,
comment|// We need to track this as some listeners pass it through our config and we need to honor
comment|// the system properties.
name|HIVE_AUTHORIZATION_MANAGER
argument_list|(
literal|"hive.security.authorization.manager"
argument_list|,
literal|"hive.security.authorization.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory"
argument_list|,
literal|"The Hive client authorization manager class name. The user defined authorization class should implement \n"
operator|+
literal|"interface org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider."
argument_list|)
block|,
name|HIVE_METASTORE_AUTHENTICATOR_MANAGER
argument_list|(
literal|"hive.security.metastore.authenticator.manager"
argument_list|,
literal|"hive.security.metastore.authenticator.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator"
argument_list|,
literal|"authenticator manager class name to be used in the metastore for authentication. \n"
operator|+
literal|"The user defined authenticator should implement interface org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider."
argument_list|)
block|,
name|HIVE_METASTORE_AUTHORIZATION_AUTH_READS
argument_list|(
literal|"hive.security.metastore.authorization.auth.reads"
argument_list|,
literal|"hive.security.metastore.authorization.auth.reads"
argument_list|,
literal|true
argument_list|,
literal|"If this is true, metastore authorizer authorizes read actions on database, table"
argument_list|)
block|,
comment|// The metastore shouldn't care what txn manager Hive is running, but in various tests it
comment|// needs to set these values.  We should do the work to detangle this.
name|HIVE_TXN_MANAGER
argument_list|(
literal|"hive.txn.manager"
argument_list|,
literal|"hive.txn.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager"
argument_list|,
literal|"Set to org.apache.hadoop.hive.ql.lockmgr.DbTxnManager as part of turning on Hive\n"
operator|+
literal|"transactions, which also requires appropriate settings for hive.compactor.initiator.on,\n"
operator|+
literal|"hive.compactor.worker.threads, hive.support.concurrency (true),\n"
operator|+
literal|"and hive.exec.dynamic.partition.mode (nonstrict).\n"
operator|+
literal|"The default DummyTxnManager replicates pre-Hive-0.13 behavior and provides\n"
operator|+
literal|"no transactions."
argument_list|)
block|,
comment|// Metastore always support concurrency, but certain ACID tests depend on this being set.  We
comment|// need to do the work to detangle this
name|HIVE_SUPPORT_CONCURRENCY
argument_list|(
literal|"hive.support.concurrency"
argument_list|,
literal|"hive.support.concurrency"
argument_list|,
literal|false
argument_list|,
literal|"Whether Hive supports concurrency control or not. \n"
operator|+
literal|"A ZooKeeper instance must be up and running when using zookeeper Hive lock manager "
argument_list|)
block|,
comment|// Deprecated Hive values that we are keeping for backwards compatibility.
annotation|@
name|Deprecated
name|HIVE_CODAHALE_METRICS_REPORTER_CLASSES
argument_list|(
literal|"hive.service.metrics.codahale.reporter.classes"
argument_list|,
literal|"hive.service.metrics.codahale.reporter.classes"
argument_list|,
literal|""
argument_list|,
literal|"Use METRICS_REPORTERS instead.  Comma separated list of reporter implementation classes "
operator|+
literal|"for metric class org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics. Overrides "
operator|+
literal|"HIVE_METRICS_REPORTER conf if present.  This will be overridden by "
operator|+
literal|"METRICS_REPORTERS if it is present"
argument_list|)
block|,
annotation|@
name|Deprecated
name|HIVE_METRICS_REPORTER
argument_list|(
literal|"hive.service.metrics.reporter"
argument_list|,
literal|"hive.service.metrics.reporter"
argument_list|,
literal|""
argument_list|,
literal|"Reporter implementations for metric class "
operator|+
literal|"org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics;"
operator|+
literal|"Deprecated, use METRICS_REPORTERS instead. This configuraiton will be"
operator|+
literal|" overridden by HIVE_CODAHALE_METRICS_REPORTER_CLASSES and METRICS_REPORTERS if "
operator|+
literal|"present. Comma separated list of JMX, CONSOLE, JSON_FILE, HADOOP2"
argument_list|)
block|,
comment|// These are all values that we put here just for testing
name|STR_TEST_ENTRY
argument_list|(
literal|"test.str"
argument_list|,
literal|"hive.test.str"
argument_list|,
literal|"defaultval"
argument_list|,
literal|"comment"
argument_list|)
block|,
name|STR_SET_ENTRY
argument_list|(
literal|"test.str.set"
argument_list|,
literal|"hive.test.str.set"
argument_list|,
literal|"a"
argument_list|,
operator|new
name|StringSetValidator
argument_list|(
literal|"a"
argument_list|,
literal|"b"
argument_list|,
literal|"c"
argument_list|)
argument_list|,
literal|""
argument_list|)
block|,
name|STR_LIST_ENTRY
argument_list|(
literal|"test.str.list"
argument_list|,
literal|"hive.test.str.list"
argument_list|,
literal|"a,b,c"
argument_list|,
literal|"no comment"
argument_list|)
block|,
name|LONG_TEST_ENTRY
argument_list|(
literal|"test.long"
argument_list|,
literal|"hive.test.long"
argument_list|,
literal|42
argument_list|,
literal|"comment"
argument_list|)
block|,
name|DOUBLE_TEST_ENTRY
argument_list|(
literal|"test.double"
argument_list|,
literal|"hive.test.double"
argument_list|,
literal|3.141592654
argument_list|,
literal|"comment"
argument_list|)
block|,
name|TIME_TEST_ENTRY
argument_list|(
literal|"test.time"
argument_list|,
literal|"hive.test.time"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"comment"
argument_list|)
block|,
name|TIME_VALIDATOR_ENTRY_INCLUSIVE
argument_list|(
literal|"test.time.validator.inclusive"
argument_list|,
literal|"hive.test.time.validator.inclusive"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|TimeValidator
argument_list|(
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
literal|500L
argument_list|,
literal|true
argument_list|,
literal|1500L
argument_list|,
literal|true
argument_list|)
argument_list|,
literal|"comment"
argument_list|)
block|,
name|TIME_VALIDATOR_ENTRY_EXCLUSIVE
argument_list|(
literal|"test.time.validator.exclusive"
argument_list|,
literal|"hive.test.time.validator.exclusive"
argument_list|,
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|TimeValidator
argument_list|(
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
literal|500L
argument_list|,
literal|false
argument_list|,
literal|1500L
argument_list|,
literal|false
argument_list|)
argument_list|,
literal|"comment"
argument_list|)
block|,
name|BOOLEAN_TEST_ENTRY
argument_list|(
literal|"test.bool"
argument_list|,
literal|"hive.test.bool"
argument_list|,
literal|true
argument_list|,
literal|"comment"
argument_list|)
block|,
name|CLASS_TEST_ENTRY
argument_list|(
literal|"test.class"
argument_list|,
literal|"hive.test.class"
argument_list|,
literal|""
argument_list|,
literal|"comment"
argument_list|)
block|;
specifier|private
specifier|final
name|String
name|varname
decl_stmt|;
specifier|private
specifier|final
name|String
name|hiveName
decl_stmt|;
specifier|private
specifier|final
name|Object
name|defaultVal
decl_stmt|;
specifier|private
specifier|final
name|Validator
name|validator
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|caseSensitive
decl_stmt|;
specifier|private
specifier|final
name|String
name|description
decl_stmt|;
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|String
name|defaultVal
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|validator
operator|=
literal|null
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|String
name|defaultVal
parameter_list|,
name|Validator
name|validator
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|this
operator|.
name|validator
operator|=
name|validator
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|String
name|defaultVal
parameter_list|,
name|boolean
name|caseSensitive
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|validator
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|caseSensitive
operator|=
name|caseSensitive
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|long
name|defaultVal
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|validator
operator|=
literal|null
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|long
name|defaultVal
parameter_list|,
name|Validator
name|validator
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|this
operator|.
name|validator
operator|=
name|validator
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|boolean
name|defaultVal
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|validator
operator|=
literal|null
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|double
name|defaultVal
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|validator
operator|=
literal|null
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|long
name|defaultVal
parameter_list|,
name|TimeUnit
name|unit
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
operator|new
name|TimeValue
argument_list|(
name|defaultVal
argument_list|,
name|unit
argument_list|)
expr_stmt|;
name|validator
operator|=
operator|new
name|TimeValidator
argument_list|(
name|unit
argument_list|)
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|hiveName
parameter_list|,
name|long
name|defaultVal
parameter_list|,
name|TimeUnit
name|unit
parameter_list|,
name|Validator
name|validator
parameter_list|,
name|String
name|description
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|hiveName
operator|=
name|hiveName
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
operator|new
name|TimeValue
argument_list|(
name|defaultVal
argument_list|,
name|unit
argument_list|)
expr_stmt|;
name|this
operator|.
name|validator
operator|=
name|validator
expr_stmt|;
name|caseSensitive
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|description
operator|=
name|description
expr_stmt|;
block|}
specifier|public
name|void
name|validate
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|IllegalArgumentException
block|{
if|if
condition|(
name|validator
operator|!=
literal|null
condition|)
block|{
name|validator
operator|.
name|validate
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|boolean
name|isCaseSensitive
parameter_list|()
block|{
return|return
name|caseSensitive
return|;
block|}
comment|/**      * If you are calling this, you're probably doing it wrong.  You shouldn't need to use the      * underlying variable name.  Use one of the getVar methods instead.  Only use this if you      * are 100% sure you know you're doing.  The reason for this is that MetastoreConf goes to a      * lot of trouble to make sure it checks both Hive and Metastore values for config keys.  If      * you call {@link Configuration#get(String)} you are undermining that.      * @return variable name      */
specifier|public
name|String
name|getVarname
parameter_list|()
block|{
return|return
name|varname
return|;
block|}
comment|/**      * Use this method if you need to set a system property and are going to instantiate the      * configuration file via HiveConf.  This is because HiveConf only looks for values it knows,      * so it will miss all of the metastore.* ones.  Do not use this to explicitly set or get the      * underlying config value unless you are 100% sure you know what you're doing.      * The reason for this is that MetastoreConf goes to a      * lot of trouble to make sure it checks both Hive and Metastore values for config keys.  If      * you call {@link Configuration#get(String)} you are undermining that.      * @return hive.* configuration key      */
specifier|public
name|String
name|getHiveName
parameter_list|()
block|{
return|return
name|hiveName
return|;
block|}
specifier|public
name|Object
name|getDefaultVal
parameter_list|()
block|{
return|return
name|defaultVal
return|;
block|}
specifier|public
name|String
name|getDescription
parameter_list|()
block|{
return|return
name|description
return|;
block|}
comment|/**      * This is useful if you need the variable name for a LOG message or      * {@link System#setProperty(String, String)}, beware however that you should only use this      * with setProperty if you're going to create a configuration via      * {@link MetastoreConf#newMetastoreConf()}.  If you are going to create it with HiveConf,      * then use {@link #getHiveName()}.      * @return metastore.* configuration key      */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|varname
return|;
block|}
block|}
specifier|public
specifier|static
specifier|final
name|ConfVars
index|[]
name|dataNucleusAndJdoConfs
init|=
block|{
name|ConfVars
operator|.
name|AUTO_CREATE_ALL
block|,
name|ConfVars
operator|.
name|CONNECTION_DRIVER
block|,
name|ConfVars
operator|.
name|CONNECTION_POOLING_MAX_CONNECTIONS
block|,
name|ConfVars
operator|.
name|CONNECTION_POOLING_TYPE
block|,
name|ConfVars
operator|.
name|CONNECT_URL_KEY
block|,
name|ConfVars
operator|.
name|CONNECTION_USER_NAME
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_AUTOSTART
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_CACHE_LEVEL2
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_CACHE_LEVEL2_TYPE
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_INIT_COL_INFO
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_PLUGIN_REGISTRY_BUNDLE_CHECK
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_TRANSACTION_ISOLATION
block|,
name|ConfVars
operator|.
name|DATANUCLEUS_USE_LEGACY_VALUE_STRATEGY
block|,
name|ConfVars
operator|.
name|DETACH_ALL_ON_COMMIT
block|,
name|ConfVars
operator|.
name|IDENTIFIER_FACTORY
block|,
name|ConfVars
operator|.
name|MANAGER_FACTORY_CLASS
block|,
name|ConfVars
operator|.
name|MULTITHREADED
block|,
name|ConfVars
operator|.
name|NON_TRANSACTIONAL_READ
block|,
name|ConfVars
operator|.
name|PWD
block|,
name|ConfVars
operator|.
name|STORE_MANAGER_TYPE
block|,
name|ConfVars
operator|.
name|VALIDATE_COLUMNS
block|,
name|ConfVars
operator|.
name|VALIDATE_CONSTRAINTS
block|,
name|ConfVars
operator|.
name|VALIDATE_TABLES
block|}
decl_stmt|;
comment|// Make sure no one calls this
specifier|private
name|MetastoreConf
parameter_list|()
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"You should never be creating one of these!"
argument_list|)
throw|;
block|}
specifier|public
specifier|static
name|void
name|setHiveSiteLocation
parameter_list|(
name|URL
name|location
parameter_list|)
block|{
name|hiveSiteURL
operator|=
name|location
expr_stmt|;
block|}
specifier|public
specifier|static
name|Configuration
name|newMetastoreConf
parameter_list|()
block|{
return|return
name|newMetastoreConf
argument_list|(
operator|new
name|Configuration
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Configuration
name|newMetastoreConf
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|ClassLoader
name|classLoader
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getContextClassLoader
argument_list|()
decl_stmt|;
if|if
condition|(
name|classLoader
operator|==
literal|null
condition|)
block|{
name|classLoader
operator|=
name|MetastoreConf
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
expr_stmt|;
block|}
comment|// We don't add this to the resources because we don't want to read config values from it.
comment|// But we do find it because we want to remember where it is for later in case anyone calls
comment|// getHiveDefaultLocation().
name|hiveDefaultURL
operator|=
name|classLoader
operator|.
name|getResource
argument_list|(
literal|"hive-default.xml"
argument_list|)
expr_stmt|;
comment|// Add in hive-site.xml.  We add this first so that it gets overridden by the new metastore
comment|// specific files if they exist.
if|if
condition|(
name|hiveSiteURL
operator|==
literal|null
condition|)
block|{
comment|/*        * this 'if' is pretty lame - QTestUtil.QTestUtil() uses hiveSiteURL to load a specific        * hive-site.xml from data/conf/<subdir> so this makes it follow the same logic - otherwise        * HiveConf and MetastoreConf may load different hive-site.xml  ( For example,        * HiveConf uses data/conf/spark/hive-site.xml and MetastoreConf data/conf/hive-site.xml)        */
name|hiveSiteURL
operator|=
name|findConfigFile
argument_list|(
name|classLoader
argument_list|,
literal|"hive-site.xml"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hiveSiteURL
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|addResource
argument_list|(
name|hiveSiteURL
argument_list|)
expr_stmt|;
block|}
comment|// Now add hivemetastore-site.xml.  Again we add this before our own config files so that the
comment|// newer overrides the older.
name|hiveMetastoreSiteURL
operator|=
name|findConfigFile
argument_list|(
name|classLoader
argument_list|,
literal|"hivemetastore-site.xml"
argument_list|)
expr_stmt|;
if|if
condition|(
name|hiveMetastoreSiteURL
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|addResource
argument_list|(
name|hiveMetastoreSiteURL
argument_list|)
expr_stmt|;
block|}
comment|// Add in our conf file
name|metastoreSiteURL
operator|=
name|findConfigFile
argument_list|(
name|classLoader
argument_list|,
literal|"metastore-site.xml"
argument_list|)
expr_stmt|;
if|if
condition|(
name|metastoreSiteURL
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|addResource
argument_list|(
name|metastoreSiteURL
argument_list|)
expr_stmt|;
block|}
comment|// If a system property that matches one of our conf value names is set then use the value
comment|// it's set to to set our own conf value.
for|for
control|(
name|ConfVars
name|var
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|System
operator|.
name|getProperty
argument_list|(
name|var
operator|.
name|varname
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting conf value "
operator|+
name|var
operator|.
name|varname
operator|+
literal|" using value "
operator|+
name|System
operator|.
name|getProperty
argument_list|(
name|var
operator|.
name|varname
argument_list|)
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|System
operator|.
name|getProperty
argument_list|(
name|var
operator|.
name|varname
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Pick up any system properties that start with "hive." and set them in our config.  This
comment|// way we can properly pull any Hive values from the environment without needing to know all
comment|// of the Hive config values.
name|System
operator|.
name|getProperties
argument_list|()
operator|.
name|stringPropertyNames
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|s
lambda|->
name|s
operator|.
name|startsWith
argument_list|(
literal|"hive."
argument_list|)
argument_list|)
operator|.
name|forEach
argument_list|(
name|s
lambda|->
block|{
name|String
name|v
operator|=
name|System
operator|.
name|getProperty
argument_list|(
name|s
argument_list|)
argument_list|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Picking up system property "
operator|+
name|s
operator|+
literal|" with value "
operator|+
name|v
argument_list|)
argument_list|;
name|conf
operator|.
name|set
argument_list|(
name|s
argument_list|,
name|v
argument_list|)
argument_list|;
block|}
block|)
class|;
end_class

begin_comment
comment|// If we are going to validate the schema, make sure we don't create it
end_comment

begin_if
if|if
condition|(
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|SCHEMA_VERIFICATION
argument_list|)
condition|)
block|{
name|setBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|AUTO_CREATE_ALL
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
end_if

begin_if
if|if
condition|(
operator|!
name|beenDumped
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
operator|&&
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|DUMP_CONFIG_ON_CREATION
argument_list|)
operator|&&
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|dumpConfig
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_if

begin_return
return|return
name|conf
return|;
end_return

begin_function
unit|}    private
specifier|static
name|URL
name|findConfigFile
parameter_list|(
name|ClassLoader
name|classLoader
parameter_list|,
name|String
name|name
parameter_list|)
block|{
comment|// First, look in the classpath
name|URL
name|result
init|=
name|classLoader
operator|.
name|getResource
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
comment|// Nope, so look to see if our conf dir has been explicitly set
name|result
operator|=
name|seeIfConfAtThisLocation
argument_list|(
literal|"METASTORE_CONF_DIR"
argument_list|,
name|name
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
comment|// Nope, so look to see if our home dir has been explicitly set
name|result
operator|=
name|seeIfConfAtThisLocation
argument_list|(
literal|"METASTORE_HOME"
argument_list|,
name|name
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
comment|// Nope, so look to see if Hive's conf dir has been explicitly set
name|result
operator|=
name|seeIfConfAtThisLocation
argument_list|(
literal|"HIVE_CONF_DIR"
argument_list|,
name|name
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
comment|// Nope, so look to see if Hive's home dir has been explicitly set
name|result
operator|=
name|seeIfConfAtThisLocation
argument_list|(
literal|"HIVE_HOME"
argument_list|,
name|name
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
comment|// Nope, so look to see if we can find a conf file by finding our jar, going up one
comment|// directory, and looking for a conf directory.
name|URI
name|jarUri
init|=
literal|null
decl_stmt|;
try|try
block|{
name|jarUri
operator|=
name|MetastoreConf
operator|.
name|class
operator|.
name|getProtectionDomain
argument_list|()
operator|.
name|getCodeSource
argument_list|()
operator|.
name|getLocation
argument_list|()
operator|.
name|toURI
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot get jar URI"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|result
operator|=
name|seeIfConfAtThisLocation
argument_list|(
operator|new
name|File
argument_list|(
name|jarUri
argument_list|)
operator|.
name|getParent
argument_list|()
argument_list|,
name|name
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// At this point if we haven't found it, screw it, we don't know where it is
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unable to find config file "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Found configuration file "
operator|+
name|result
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
end_function

begin_function
specifier|private
specifier|static
name|URL
name|seeIfConfAtThisLocation
parameter_list|(
name|String
name|envVar
parameter_list|,
name|String
name|name
parameter_list|,
name|boolean
name|inConfDir
parameter_list|)
block|{
name|String
name|path
init|=
name|System
operator|.
name|getenv
argument_list|(
name|envVar
argument_list|)
decl_stmt|;
if|if
condition|(
name|path
operator|==
literal|null
condition|)
block|{
comment|// Workaround for testing since tests can't set the env vars.
name|path
operator|=
name|System
operator|.
name|getProperty
argument_list|(
name|TEST_ENV_WORKAROUND
operator|+
name|envVar
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|path
operator|!=
literal|null
condition|)
block|{
name|String
name|suffix
init|=
name|inConfDir
condition|?
literal|"conf"
operator|+
name|File
operator|.
name|separatorChar
operator|+
name|name
else|:
name|name
decl_stmt|;
return|return
name|checkConfigFile
argument_list|(
operator|new
name|File
argument_list|(
name|path
argument_list|,
name|suffix
argument_list|)
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
end_function

begin_function
specifier|private
specifier|static
name|URL
name|checkConfigFile
parameter_list|(
name|File
name|f
parameter_list|)
block|{
try|try
block|{
return|return
operator|(
name|f
operator|.
name|exists
argument_list|()
operator|&&
name|f
operator|.
name|isFile
argument_list|()
operator|)
condition|?
name|f
operator|.
name|toURI
argument_list|()
operator|.
name|toURL
argument_list|()
else|:
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error looking for config "
operator|+
name|f
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
end_function

begin_comment
comment|// In all of the getters, we try the metastore value name first.  If it is not set we try the
end_comment

begin_comment
comment|// Hive value name.
end_comment

begin_comment
comment|/**    * Get the variable as a string    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @return value, or default value if value not in config file    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
operator|(
name|String
operator|)
name|var
operator|.
name|defaultVal
argument_list|)
else|:
name|val
return|;
block|}
end_function

begin_comment
comment|/**    * Get the variable as a string    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @param defaultVal default to return if the variable is unset    * @return value, or default value passed in if the value is not in the config file    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|String
name|defaultVal
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
name|defaultVal
argument_list|)
else|:
name|val
return|;
block|}
end_function

begin_comment
comment|/**    * Treat a configuration value as a comma separated list.    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @return collection of strings.  If the value is unset it will return an empty collection.    */
end_comment

begin_function
specifier|public
specifier|static
name|Collection
argument_list|<
name|String
argument_list|>
name|getStringCollection
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
operator|(
name|String
operator|)
name|var
operator|.
name|defaultVal
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
return|return
name|Collections
operator|.
name|emptySet
argument_list|()
return|;
block|}
return|return
name|StringUtils
operator|.
name|asSet
argument_list|(
name|val
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Set the variable as a string    * @param conf configuration file to set it in    * @param var variable to set    * @param val value to set it to    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|setVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|String
name|val
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|conf
operator|.
name|set
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Get the variable as a int.  Note that all integer valued variables are stored as longs, thus    * this downcasts from a long to an in.    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @return value, or default value if value not in config file    */
end_comment

begin_function
specifier|public
specifier|static
name|int
name|getIntVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
name|long
name|val
init|=
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
decl_stmt|;
assert|assert
name|val
operator|<=
name|Integer
operator|.
name|MAX_VALUE
assert|;
return|return
operator|(
name|int
operator|)
name|val
return|;
block|}
end_function

begin_comment
comment|/**    * Get the variable as a long    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @return value, or default value if value not in config file    */
end_comment

begin_function
specifier|public
specifier|static
name|long
name|getLongVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Long
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|getLong
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
operator|(
name|Long
operator|)
name|var
operator|.
name|defaultVal
argument_list|)
else|:
name|Long
operator|.
name|valueOf
argument_list|(
name|val
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Set the variable as a long    * @param conf configuration file to set it in    * @param var variable to set    * @param val value to set it to    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|setLongVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|long
name|val
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Long
operator|.
name|class
assert|;
name|conf
operator|.
name|setLong
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Get the variable as a boolean    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @return value, or default value if value not in config file    */
end_comment

begin_function
specifier|public
specifier|static
name|boolean
name|getBoolVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Boolean
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|getBoolean
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
operator|(
name|Boolean
operator|)
name|var
operator|.
name|defaultVal
argument_list|)
else|:
name|Boolean
operator|.
name|valueOf
argument_list|(
name|val
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Set the variable as a boolean    * @param conf configuration file to set it in    * @param var variable to set    * @param val value to set it to    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|setBoolVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|boolean
name|val
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Boolean
operator|.
name|class
assert|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Get the variable as a double    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @return value, or default value if value not in config file    */
end_comment

begin_function
specifier|public
specifier|static
name|double
name|getDoubleVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Double
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|getDouble
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
operator|(
name|Double
operator|)
name|var
operator|.
name|defaultVal
argument_list|)
else|:
name|Double
operator|.
name|valueOf
argument_list|(
name|val
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Set the variable as a double    * @param conf configuration file to set it in    * @param var variable to set    * @param val value to set it to    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|setDoubleVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|double
name|val
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Double
operator|.
name|class
assert|;
name|conf
operator|.
name|setDouble
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|long
name|getSizeVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
return|return
name|SizeValidator
operator|.
name|toSizeBytes
argument_list|(
name|getVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Get a class instance based on a configuration value    * @param conf configuration file to retrieve it from    * @param var variable to retrieve    * @param defaultValue default class to return if the value isn't set    * @param xface interface that class must implement    * @param<I> interface that class implements    * @return instance of the class    */
end_comment

begin_function
specifier|public
specifier|static
parameter_list|<
name|I
parameter_list|>
name|Class
argument_list|<
name|?
extends|extends
name|I
argument_list|>
name|getClass
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|I
argument_list|>
name|defaultValue
parameter_list|,
name|Class
argument_list|<
name|I
argument_list|>
name|xface
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|getClass
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
name|defaultValue
argument_list|,
name|xface
argument_list|)
else|:
name|conf
operator|.
name|getClass
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|defaultValue
argument_list|,
name|xface
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Set the class name in the configuration file    * @param conf configuration file to set it in    * @param var variable to set    * @param theClass the class to set it to    * @param xface interface that the class implements.  I don't know why this is required, but    *              the underlying {@link Configuration#setClass(String, Class, Class)} requires it.    * @param<I> interface the class implements.    */
end_comment

begin_function
specifier|public
specifier|static
parameter_list|<
name|I
parameter_list|>
name|void
name|setClass
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|I
argument_list|>
name|theClass
parameter_list|,
name|Class
argument_list|<
name|I
argument_list|>
name|xface
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|conf
operator|.
name|setClass
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|theClass
argument_list|,
name|xface
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Get the variable as a long indicating a period of time    * @param conf configuration to retrieve it from    * @param var variable to retrieve    * @param outUnit Timeout to return value in    * @return value, or default value if value not in config file    */
end_comment

begin_function
specifier|public
specifier|static
name|long
name|getTimeVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|TimeUnit
name|outUnit
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|TimeValue
operator|.
name|class
assert|;
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
comment|// Look for it under the old Hive name
name|val
operator|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|hiveName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
return|return
name|convertTimeStr
argument_list|(
name|val
argument_list|,
operator|(
operator|(
name|TimeValue
operator|)
name|var
operator|.
name|defaultVal
operator|)
operator|.
name|unit
argument_list|,
name|outUnit
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
operator|(
operator|(
name|TimeValue
operator|)
name|var
operator|.
name|defaultVal
operator|)
operator|.
name|val
argument_list|,
operator|(
operator|(
name|TimeValue
operator|)
name|var
operator|.
name|defaultVal
operator|)
operator|.
name|unit
argument_list|)
return|;
block|}
block|}
end_function

begin_comment
comment|/**    * Set the variable as a string    * @param conf configuration file to set it in    * @param var variable to set    * @param duration value to set it to    * @param unit time unit that duration is expressed in    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|setTimeVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|long
name|duration
parameter_list|,
name|TimeUnit
name|unit
parameter_list|)
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|TimeValue
operator|.
name|class
assert|;
name|conf
operator|.
name|setTimeDuration
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|duration
argument_list|,
name|unit
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|long
name|convertTimeStr
parameter_list|(
name|String
name|val
parameter_list|,
name|TimeUnit
name|defaultUnit
parameter_list|,
name|TimeUnit
name|outUnit
parameter_list|)
block|{
if|if
condition|(
name|val
operator|.
name|charAt
argument_list|(
name|val
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
operator|>=
literal|'A'
condition|)
block|{
comment|// It ends in a character, this means they appended a time indicator (e.g. 600s)
name|Matcher
name|m
init|=
name|TIME_UNIT_SUFFIX
operator|.
name|matcher
argument_list|(
name|val
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
name|long
name|duration
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|m
operator|.
name|group
argument_list|(
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|unit
init|=
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
operator|.
name|toLowerCase
argument_list|()
decl_stmt|;
comment|// If/else chain arranged in likely order of frequency for performance
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"s"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"sec"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"ms"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"msec"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"m"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"min"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|MINUTES
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"us"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"usec"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|MICROSECONDS
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"ns"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"nsec"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|NANOSECONDS
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"h"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"hour"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|HOURS
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|unit
operator|.
name|equals
argument_list|(
literal|"d"
argument_list|)
operator|||
name|unit
operator|.
name|startsWith
argument_list|(
literal|"day"
argument_list|)
condition|)
block|{
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|duration
argument_list|,
name|TimeUnit
operator|.
name|DAYS
argument_list|)
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid time unit "
operator|+
name|unit
argument_list|)
throw|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid time unit "
operator|+
name|val
argument_list|)
throw|;
block|}
block|}
comment|// If they gave a value but not a time unit assume the default time unit.
return|return
name|outUnit
operator|.
name|convert
argument_list|(
name|Long
operator|.
name|parseLong
argument_list|(
name|val
argument_list|)
argument_list|,
name|defaultUnit
argument_list|)
return|;
block|}
end_function

begin_function
specifier|static
name|String
name|timeAbbreviationFor
parameter_list|(
name|TimeUnit
name|timeunit
parameter_list|)
block|{
switch|switch
condition|(
name|timeunit
condition|)
block|{
case|case
name|DAYS
case|:
return|return
literal|"d"
return|;
case|case
name|HOURS
case|:
return|return
literal|"h"
return|;
case|case
name|MINUTES
case|:
return|return
literal|"m"
return|;
case|case
name|SECONDS
case|:
return|return
literal|"s"
return|;
case|case
name|MILLISECONDS
case|:
return|return
literal|"ms"
return|;
case|case
name|MICROSECONDS
case|:
return|return
literal|"us"
return|;
case|case
name|NANOSECONDS
case|:
return|return
literal|"ns"
return|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid timeunit "
operator|+
name|timeunit
argument_list|)
throw|;
block|}
end_function

begin_comment
comment|/**    * Get a password from the configuration file.  This uses Hadoop's    * {@link Configuration#getPassword(String)} to handle getting secure passwords.    * @param conf configuration file to read from    * @param var configuration value to read    * @return the password as a string, or the default value.    * @throws IOException if thrown by Configuration.getPassword    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getPassword
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
assert|;
name|char
index|[]
name|pw
init|=
name|conf
operator|.
name|getPassword
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
if|if
condition|(
name|pw
operator|==
literal|null
condition|)
block|{
comment|// Might be under the hive name
name|pw
operator|=
name|conf
operator|.
name|getPassword
argument_list|(
name|var
operator|.
name|hiveName
argument_list|)
expr_stmt|;
block|}
return|return
name|pw
operator|==
literal|null
condition|?
name|var
operator|.
name|defaultVal
operator|.
name|toString
argument_list|()
else|:
operator|new
name|String
argument_list|(
name|pw
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Get the configuration value based on a string rather than a ConfVar.  This will do the    * mapping between metastore keys and Hive keys.  That is, if there's a ConfVar with a    * metastore key of "metastore.a" and a hive key of "hive.a", the value for that variable will    * be returned if either of those keys is present in the config.  If neither are present than    * the default value will be returned.    * @param conf configuration to read.    * @param key metastore or hive key to read.    * @return the value set    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|get
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|String
name|key
parameter_list|)
block|{
comment|// Map this key back to the ConfVars it is associated with.
if|if
condition|(
name|keyToVars
operator|==
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|MetastoreConf
operator|.
name|class
init|)
block|{
if|if
condition|(
name|keyToVars
operator|==
literal|null
condition|)
block|{
name|keyToVars
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|ConfVars
operator|.
name|values
argument_list|()
operator|.
name|length
operator|*
literal|2
argument_list|)
expr_stmt|;
for|for
control|(
name|ConfVars
name|var
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
name|keyToVars
operator|.
name|put
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
argument_list|)
expr_stmt|;
name|keyToVars
operator|.
name|put
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
name|var
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|ConfVars
name|var
init|=
name|keyToVars
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|var
operator|==
literal|null
condition|)
block|{
comment|// Ok, this isn't one we track.  Just return whatever matches the string
return|return
name|conf
operator|.
name|get
argument_list|(
name|key
argument_list|)
return|;
block|}
comment|// Check if the metastore key is set first
name|String
name|val
init|=
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
decl_stmt|;
return|return
name|val
operator|==
literal|null
condition|?
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|hiveName
argument_list|,
name|var
operator|.
name|defaultVal
operator|.
name|toString
argument_list|()
argument_list|)
else|:
name|val
return|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|boolean
name|isPrintable
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
operator|!
name|unprintables
operator|.
name|contains
argument_list|(
name|key
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Return the configuration value as a String.  For time based values it will be returned in    * the default time unit appended with an appropriate abbreviation (eg s for seconds, ...)    * @param conf configuration to read    * @param var variable to read    * @return value as a String    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getAsString
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
if|if
condition|(
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|String
operator|.
name|class
condition|)
block|{
return|return
name|getVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Boolean
operator|.
name|class
condition|)
block|{
return|return
name|Boolean
operator|.
name|toString
argument_list|(
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Long
operator|.
name|class
condition|)
block|{
return|return
name|Long
operator|.
name|toString
argument_list|(
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|Double
operator|.
name|class
condition|)
block|{
return|return
name|Double
operator|.
name|toString
argument_list|(
name|getDoubleVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|TimeValue
operator|.
name|class
condition|)
block|{
name|TimeUnit
name|timeUnit
init|=
operator|(
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|==
name|TimeValue
operator|.
name|class
operator|)
condition|?
operator|(
operator|(
name|TimeValue
operator|)
name|var
operator|.
name|defaultVal
operator|)
operator|.
name|unit
else|:
literal|null
decl_stmt|;
return|return
name|Long
operator|.
name|toString
argument_list|(
name|getTimeVar
argument_list|(
name|conf
argument_list|,
name|var
argument_list|,
name|timeUnit
argument_list|)
argument_list|)
operator|+
name|timeAbbreviationFor
argument_list|(
name|timeUnit
argument_list|)
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown type for getObject "
operator|+
name|var
operator|.
name|defaultVal
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
block|}
end_function

begin_function
specifier|public
specifier|static
name|URL
name|getHiveDefaultLocation
parameter_list|()
block|{
return|return
name|hiveDefaultURL
return|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|URL
name|getHiveSiteLocation
parameter_list|()
block|{
return|return
name|hiveSiteURL
return|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|URL
name|getHiveMetastoreSiteURL
parameter_list|()
block|{
return|return
name|hiveMetastoreSiteURL
return|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|URL
name|getMetastoreSiteURL
parameter_list|()
block|{
return|return
name|metastoreSiteURL
return|;
block|}
end_function

begin_function
specifier|public
name|List
argument_list|<
name|URL
argument_list|>
name|getResourceFileLocations
parameter_list|()
block|{
return|return
name|Arrays
operator|.
name|asList
argument_list|(
name|hiveSiteURL
argument_list|,
name|hiveMetastoreSiteURL
argument_list|,
name|metastoreSiteURL
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Check if metastore is being used in embedded mode.    * This utility function exists so that the logic for determining the mode is same    * in HiveConf and HiveMetaStoreClient    * @param msUri - metastore server uri    * @return true if the metastore is embedded    */
end_comment

begin_function
specifier|public
specifier|static
name|boolean
name|isEmbeddedMetaStore
parameter_list|(
name|String
name|msUri
parameter_list|)
block|{
return|return
operator|(
name|msUri
operator|==
literal|null
operator|)
operator|||
name|msUri
operator|.
name|trim
argument_list|()
operator|.
name|isEmpty
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Dump the configuration file to the log.  It will be dumped at an INFO level.  This can    * potentially produce a lot of logs, so you might want to be careful when and where you do it.    * It takes care not to dump hidden keys.    * @param conf Configuration file to dump    * @return String containing dumped config file.    */
end_comment

begin_function
specifier|static
name|String
name|dumpConfig
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|StringBuilder
name|buf
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"MetastoreConf object:\n"
argument_list|)
decl_stmt|;
if|if
condition|(
name|hiveSiteURL
operator|!=
literal|null
condition|)
block|{
name|buf
operator|.
name|append
argument_list|(
literal|"Used hive-site file: "
argument_list|)
operator|.
name|append
argument_list|(
name|hiveSiteURL
argument_list|)
operator|.
name|append
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hiveMetastoreSiteURL
operator|!=
literal|null
condition|)
block|{
name|buf
operator|.
name|append
argument_list|(
literal|"Used hivemetastore-site file: "
argument_list|)
operator|.
name|append
argument_list|(
name|hiveMetastoreSiteURL
argument_list|)
operator|.
name|append
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|metastoreSiteURL
operator|!=
literal|null
condition|)
block|{
name|buf
operator|.
name|append
argument_list|(
literal|"Used metastore-site file: "
argument_list|)
operator|.
name|append
argument_list|(
name|metastoreSiteURL
argument_list|)
operator|.
name|append
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ConfVars
name|var
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|unprintables
operator|.
name|contains
argument_list|(
name|var
operator|.
name|varname
argument_list|)
condition|)
block|{
name|buf
operator|.
name|append
argument_list|(
literal|"Key:<"
argument_list|)
operator|.
name|append
argument_list|(
name|var
operator|.
name|varname
argument_list|)
operator|.
name|append
argument_list|(
literal|"> old hive key:<"
argument_list|)
operator|.
name|append
argument_list|(
name|var
operator|.
name|hiveName
argument_list|)
operator|.
name|append
argument_list|(
literal|">  value:<"
argument_list|)
operator|.
name|append
argument_list|(
name|getAsString
argument_list|(
name|conf
argument_list|,
name|var
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|">\n"
argument_list|)
expr_stmt|;
block|}
block|}
name|buf
operator|.
name|append
argument_list|(
literal|"Finished MetastoreConf object.\n"
argument_list|)
expr_stmt|;
return|return
name|buf
operator|.
name|toString
argument_list|()
return|;
block|}
end_function

unit|}
end_unit

