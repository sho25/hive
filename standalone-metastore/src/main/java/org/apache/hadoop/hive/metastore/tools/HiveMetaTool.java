begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|tools
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|CommandLine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|CommandLineParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|GnuParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|HelpFormatter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|Option
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|OptionBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|Options
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|ParseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|ContentSummary
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|AcidStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OrcAcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ObjectStore
import|;
end_import

begin_comment
comment|/**  * This class provides Hive admins a tool to  * - execute JDOQL against the metastore using DataNucleus  * - perform HA name node upgrade  */
end_comment

begin_class
specifier|public
class|class
name|HiveMetaTool
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HiveMetaTool
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Options
name|cmdLineOptions
init|=
operator|new
name|Options
argument_list|()
decl_stmt|;
specifier|private
name|ObjectStore
name|objStore
decl_stmt|;
specifier|private
name|boolean
name|isObjStoreInitialized
decl_stmt|;
specifier|public
name|HiveMetaTool
parameter_list|()
block|{
name|this
operator|.
name|isObjStoreInitialized
operator|=
literal|false
expr_stmt|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"static-access"
argument_list|)
specifier|private
name|void
name|init
parameter_list|()
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Initializing HiveMetaTool.."
argument_list|)
expr_stmt|;
name|Option
name|help
init|=
operator|new
name|Option
argument_list|(
literal|"help"
argument_list|,
literal|"print this message"
argument_list|)
decl_stmt|;
name|Option
name|listFSRoot
init|=
operator|new
name|Option
argument_list|(
literal|"listFSRoot"
argument_list|,
literal|"print the current FS root locations"
argument_list|)
decl_stmt|;
name|Option
name|executeJDOQL
init|=
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"query-string"
argument_list|)
operator|.
name|hasArgs
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"execute the given JDOQL query"
argument_list|)
operator|.
name|create
argument_list|(
literal|"executeJDOQL"
argument_list|)
decl_stmt|;
comment|/* Ideally we want to specify the different arguments to updateLocation as separate argNames.      * However if we did that, HelpFormatter swallows all but the last argument. Note that this is      * a know issue with the HelpFormatter class that has not been fixed. We specify all arguments      * with a single argName to workaround this HelpFormatter bug.      */
name|Option
name|updateFSRootLoc
init|=
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"new-loc> "
operator|+
literal|"<old-loc"
argument_list|)
operator|.
name|hasArgs
argument_list|(
literal|2
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Update FS root location in the metastore to new location.Both new-loc and "
operator|+
literal|"old-loc should be valid URIs with valid host names and schemes."
operator|+
literal|"When run with the dryRun option changes are displayed but are not "
operator|+
literal|"persisted. When run with the serdepropKey/tablePropKey option "
operator|+
literal|"updateLocation looks for the serde-prop-key/table-prop-key that is "
operator|+
literal|"specified and updates its value if found."
argument_list|)
operator|.
name|create
argument_list|(
literal|"updateLocation"
argument_list|)
decl_stmt|;
name|Option
name|dryRun
init|=
operator|new
name|Option
argument_list|(
literal|"dryRun"
argument_list|,
literal|"Perform a dry run of updateLocation changes.When "
operator|+
literal|"run with the dryRun option updateLocation changes are displayed but not persisted. "
operator|+
literal|"dryRun is valid only with the updateLocation option."
argument_list|)
decl_stmt|;
name|Option
name|serdePropKey
init|=
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"serde-prop-key"
argument_list|)
operator|.
name|hasArgs
argument_list|()
operator|.
name|withValueSeparator
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"Specify the key for serde property to be updated. serdePropKey option "
operator|+
literal|"is valid only with updateLocation option."
argument_list|)
operator|.
name|create
argument_list|(
literal|"serdePropKey"
argument_list|)
decl_stmt|;
name|Option
name|tablePropKey
init|=
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"table-prop-key"
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|withValueSeparator
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"Specify the key for table property to be updated. tablePropKey option "
operator|+
literal|"is valid only with updateLocation option."
argument_list|)
operator|.
name|create
argument_list|(
literal|"tablePropKey"
argument_list|)
decl_stmt|;
name|Option
name|prepareAcidUpgrade
init|=
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"find-compactions"
argument_list|)
operator|.
name|hasOptionalArg
argument_list|()
comment|//directory to output results to
operator|.
name|withDescription
argument_list|(
literal|"Generates a set Compaction commands to run to prepare for Hive 2.x"
operator|+
literal|" to 3.0 upgrade"
argument_list|)
operator|.
name|create
argument_list|(
literal|"prepareAcidUpgrade"
argument_list|)
decl_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|help
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|listFSRoot
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|executeJDOQL
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|updateFSRootLoc
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|dryRun
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|serdePropKey
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|tablePropKey
argument_list|)
expr_stmt|;
name|cmdLineOptions
operator|.
name|addOption
argument_list|(
name|prepareAcidUpgrade
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|initObjectStore
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|isObjStoreInitialized
condition|)
block|{
name|objStore
operator|=
operator|new
name|ObjectStore
argument_list|()
expr_stmt|;
name|objStore
operator|.
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|isObjStoreInitialized
operator|=
literal|true
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|shutdownObjectStore
parameter_list|()
block|{
if|if
condition|(
name|isObjStoreInitialized
condition|)
block|{
name|objStore
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|isObjStoreInitialized
operator|=
literal|false
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|listFSRoot
parameter_list|()
block|{
name|Configuration
name|conf
init|=
name|MetastoreConf
operator|.
name|newMetastoreConf
argument_list|()
decl_stmt|;
name|initObjectStore
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|hdfsRoots
init|=
name|objStore
operator|.
name|listFSRoots
argument_list|()
decl_stmt|;
if|if
condition|(
name|hdfsRoots
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Listing FS Roots.."
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|hdfsRoots
control|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error during listFSRoot - "
operator|+
literal|"commit of JDO transaction failed"
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|executeJDOQLSelect
parameter_list|(
name|String
name|query
parameter_list|)
block|{
name|Configuration
name|conf
init|=
name|MetastoreConf
operator|.
name|newMetastoreConf
argument_list|()
decl_stmt|;
name|initObjectStore
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Executing query: "
operator|+
name|query
argument_list|)
expr_stmt|;
try|try
init|(
name|ObjectStore
operator|.
name|QueryWrapper
name|queryWrapper
init|=
operator|new
name|ObjectStore
operator|.
name|QueryWrapper
argument_list|()
init|)
block|{
name|Collection
argument_list|<
name|?
argument_list|>
name|result
init|=
name|objStore
operator|.
name|executeJDOQLSelect
argument_list|(
name|query
argument_list|,
name|queryWrapper
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|!=
literal|null
condition|)
block|{
name|Iterator
argument_list|<
name|?
argument_list|>
name|iter
init|=
name|result
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Object
name|o
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|o
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error during executeJDOQLSelect -"
operator|+
literal|"commit of JDO transaction failed."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|executeJDOQLUpdate
parameter_list|(
name|String
name|query
parameter_list|)
block|{
name|Configuration
name|conf
init|=
name|MetastoreConf
operator|.
name|newMetastoreConf
argument_list|()
decl_stmt|;
name|initObjectStore
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Executing query: "
operator|+
name|query
argument_list|)
expr_stmt|;
name|long
name|numUpdated
init|=
name|objStore
operator|.
name|executeJDOQLUpdate
argument_list|(
name|query
argument_list|)
decl_stmt|;
if|if
condition|(
name|numUpdated
operator|>=
literal|0
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Number of records updated: "
operator|+
name|numUpdated
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error during executeJDOQL -"
operator|+
literal|"commit of JDO transaction failed."
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|int
name|printUpdateLocations
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|updateLocations
parameter_list|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|String
name|key
range|:
name|updateLocations
operator|.
name|keySet
argument_list|()
control|)
block|{
name|String
name|value
init|=
name|updateLocations
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"old location: "
operator|+
name|key
operator|+
literal|" new location: "
operator|+
name|value
argument_list|)
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
return|return
name|count
return|;
block|}
specifier|private
name|void
name|printTblURIUpdateSummary
parameter_list|(
name|ObjectStore
operator|.
name|UpdateMStorageDescriptorTblURIRetVal
name|retVal
parameter_list|,
name|boolean
name|isDryRun
parameter_list|)
block|{
name|String
name|tblName
init|=
literal|"SDS"
decl_stmt|;
name|String
name|fieldName
init|=
literal|"LOCATION"
decl_stmt|;
if|if
condition|(
name|retVal
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error while executing updateMStorageDescriptorTblURI - "
operator|+
literal|"commit of JDO transaction failed. Failed to update FSRoot locations in "
operator|+
name|fieldName
operator|+
literal|"field in "
operator|+
name|tblName
operator|+
literal|" table."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|updateLocations
init|=
name|retVal
operator|.
name|getUpdateLocations
argument_list|()
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Dry Run of updateLocation on table "
operator|+
name|tblName
operator|+
literal|".."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Successfully updated the following locations.."
argument_list|)
expr_stmt|;
block|}
name|int
name|count
init|=
name|printUpdateLocations
argument_list|(
name|updateLocations
argument_list|)
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Found "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table to update"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Updated "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table"
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|badRecords
init|=
name|retVal
operator|.
name|getBadRecords
argument_list|()
decl_stmt|;
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Warning: Found records with bad "
operator|+
name|fieldName
operator|+
literal|" in "
operator|+
name|tblName
operator|+
literal|" table.. "
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|badRecord
range|:
name|badRecords
control|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"bad location URI: "
operator|+
name|badRecord
argument_list|)
expr_stmt|;
block|}
block|}
name|int
name|numNullRecords
init|=
name|retVal
operator|.
name|getNumNullRecords
argument_list|()
decl_stmt|;
if|if
condition|(
name|numNullRecords
operator|!=
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Number of NULL location URI: "
operator|+
name|numNullRecords
operator|+
literal|". This can happen for View or Index."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|printDatabaseURIUpdateSummary
parameter_list|(
name|ObjectStore
operator|.
name|UpdateMDatabaseURIRetVal
name|retVal
parameter_list|,
name|boolean
name|isDryRun
parameter_list|)
block|{
name|String
name|tblName
init|=
literal|"DBS"
decl_stmt|;
name|String
name|fieldName
init|=
literal|"LOCATION_URI"
decl_stmt|;
if|if
condition|(
name|retVal
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error while executing updateMDatabaseURI - "
operator|+
literal|"commit of JDO transaction failed. Failed to update FSRoot locations in "
operator|+
name|fieldName
operator|+
literal|"field in "
operator|+
name|tblName
operator|+
literal|" table."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|updateLocations
init|=
name|retVal
operator|.
name|getUpdateLocations
argument_list|()
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Dry Run of updateLocation on table "
operator|+
name|tblName
operator|+
literal|".."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Successfully updated the following locations.."
argument_list|)
expr_stmt|;
block|}
name|int
name|count
init|=
name|printUpdateLocations
argument_list|(
name|updateLocations
argument_list|)
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Found "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table to update"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Updated "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table"
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|badRecords
init|=
name|retVal
operator|.
name|getBadRecords
argument_list|()
decl_stmt|;
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Warning: Found records with bad "
operator|+
name|fieldName
operator|+
literal|" in "
operator|+
name|tblName
operator|+
literal|" table.. "
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|badRecord
range|:
name|badRecords
control|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"bad location URI: "
operator|+
name|badRecord
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|void
name|printPropURIUpdateSummary
parameter_list|(
name|ObjectStore
operator|.
name|UpdatePropURIRetVal
name|retVal
parameter_list|,
name|String
name|tablePropKey
parameter_list|,
name|boolean
name|isDryRun
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|methodName
parameter_list|)
block|{
if|if
condition|(
name|retVal
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error while executing "
operator|+
name|methodName
operator|+
literal|" - "
operator|+
literal|"commit of JDO transaction failed. Failed to update FSRoot locations in "
operator|+
literal|"value field corresponding to"
operator|+
name|tablePropKey
operator|+
literal|" in "
operator|+
name|tblName
operator|+
literal|" table."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|updateLocations
init|=
name|retVal
operator|.
name|getUpdateLocations
argument_list|()
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Dry Run of updateLocation on table "
operator|+
name|tblName
operator|+
literal|".."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Successfully updated the following locations.."
argument_list|)
expr_stmt|;
block|}
name|int
name|count
init|=
name|printUpdateLocations
argument_list|(
name|updateLocations
argument_list|)
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Found "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table to update"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Updated "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table"
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|badRecords
init|=
name|retVal
operator|.
name|getBadRecords
argument_list|()
decl_stmt|;
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Warning: Found records with bad "
operator|+
name|tablePropKey
operator|+
literal|" key in "
operator|+
name|tblName
operator|+
literal|" table.. "
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|badRecord
range|:
name|badRecords
control|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"bad location URI: "
operator|+
name|badRecord
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|void
name|printSerdePropURIUpdateSummary
parameter_list|(
name|ObjectStore
operator|.
name|UpdateSerdeURIRetVal
name|retVal
parameter_list|,
name|String
name|serdePropKey
parameter_list|,
name|boolean
name|isDryRun
parameter_list|)
block|{
name|String
name|tblName
init|=
literal|"SERDE_PARAMS"
decl_stmt|;
if|if
condition|(
name|retVal
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Encountered error while executing updateSerdeURI - "
operator|+
literal|"commit of JDO transaction failed. Failed to update FSRoot locations in "
operator|+
literal|"value field corresponding to "
operator|+
name|serdePropKey
operator|+
literal|" in "
operator|+
name|tblName
operator|+
literal|" table."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|updateLocations
init|=
name|retVal
operator|.
name|getUpdateLocations
argument_list|()
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Dry Run of updateLocation on table "
operator|+
name|tblName
operator|+
literal|".."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Successfully updated the following locations.."
argument_list|)
expr_stmt|;
block|}
name|int
name|count
init|=
name|printUpdateLocations
argument_list|(
name|updateLocations
argument_list|)
decl_stmt|;
if|if
condition|(
name|isDryRun
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Found "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table to update"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Updated "
operator|+
name|count
operator|+
literal|" records in "
operator|+
name|tblName
operator|+
literal|" table"
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|badRecords
init|=
name|retVal
operator|.
name|getBadRecords
argument_list|()
decl_stmt|;
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Warning: Found records with bad "
operator|+
name|serdePropKey
operator|+
literal|" key in "
operator|+
name|tblName
operator|+
literal|" table.. "
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|badRecord
range|:
name|badRecords
control|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"bad location URI: "
operator|+
name|badRecord
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|public
name|void
name|updateFSRootLocation
parameter_list|(
name|URI
name|oldURI
parameter_list|,
name|URI
name|newURI
parameter_list|,
name|String
name|serdePropKey
parameter_list|,
name|String
name|tablePropKey
parameter_list|,
name|boolean
name|isDryRun
parameter_list|)
block|{
name|Configuration
name|conf
init|=
name|MetastoreConf
operator|.
name|newMetastoreConf
argument_list|()
decl_stmt|;
name|initObjectStore
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Looking for LOCATION_URI field in DBS table to update.."
argument_list|)
expr_stmt|;
name|ObjectStore
operator|.
name|UpdateMDatabaseURIRetVal
name|updateMDBURIRetVal
init|=
name|objStore
operator|.
name|updateMDatabaseURI
argument_list|(
name|oldURI
argument_list|,
name|newURI
argument_list|,
name|isDryRun
argument_list|)
decl_stmt|;
name|printDatabaseURIUpdateSummary
argument_list|(
name|updateMDBURIRetVal
argument_list|,
name|isDryRun
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Looking for LOCATION field in SDS table to update.."
argument_list|)
expr_stmt|;
name|ObjectStore
operator|.
name|UpdateMStorageDescriptorTblURIRetVal
name|updateTblURIRetVal
init|=
name|objStore
operator|.
name|updateMStorageDescriptorTblURI
argument_list|(
name|oldURI
argument_list|,
name|newURI
argument_list|,
name|isDryRun
argument_list|)
decl_stmt|;
name|printTblURIUpdateSummary
argument_list|(
name|updateTblURIRetVal
argument_list|,
name|isDryRun
argument_list|)
expr_stmt|;
if|if
condition|(
name|tablePropKey
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Looking for value of "
operator|+
name|tablePropKey
operator|+
literal|" key in TABLE_PARAMS table "
operator|+
literal|"to update.."
argument_list|)
expr_stmt|;
name|ObjectStore
operator|.
name|UpdatePropURIRetVal
name|updateTblPropURIRetVal
init|=
name|objStore
operator|.
name|updateTblPropURI
argument_list|(
name|oldURI
argument_list|,
name|newURI
argument_list|,
name|tablePropKey
argument_list|,
name|isDryRun
argument_list|)
decl_stmt|;
name|printPropURIUpdateSummary
argument_list|(
name|updateTblPropURIRetVal
argument_list|,
name|tablePropKey
argument_list|,
name|isDryRun
argument_list|,
literal|"TABLE_PARAMS"
argument_list|,
literal|"updateTblPropURI"
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Looking for value of "
operator|+
name|tablePropKey
operator|+
literal|" key in SD_PARAMS table "
operator|+
literal|"to update.."
argument_list|)
expr_stmt|;
name|ObjectStore
operator|.
name|UpdatePropURIRetVal
name|updatePropURIRetVal
init|=
name|objStore
operator|.
name|updateMStorageDescriptorTblPropURI
argument_list|(
name|oldURI
argument_list|,
name|newURI
argument_list|,
name|tablePropKey
argument_list|,
name|isDryRun
argument_list|)
decl_stmt|;
name|printPropURIUpdateSummary
argument_list|(
name|updatePropURIRetVal
argument_list|,
name|tablePropKey
argument_list|,
name|isDryRun
argument_list|,
literal|"SD_PARAMS"
argument_list|,
literal|"updateMStorageDescriptorTblPropURI"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serdePropKey
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Looking for value of "
operator|+
name|serdePropKey
operator|+
literal|" key in SERDE_PARAMS table "
operator|+
literal|"to update.."
argument_list|)
expr_stmt|;
name|ObjectStore
operator|.
name|UpdateSerdeURIRetVal
name|updateSerdeURIretVal
init|=
name|objStore
operator|.
name|updateSerdeURI
argument_list|(
name|oldURI
argument_list|,
name|newURI
argument_list|,
name|serdePropKey
argument_list|,
name|isDryRun
argument_list|)
decl_stmt|;
name|printSerdePropURIUpdateSummary
argument_list|(
name|updateSerdeURIretVal
argument_list|,
name|serdePropKey
argument_list|,
name|isDryRun
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|prepareAcidUpgrade
parameter_list|(
name|String
name|scriptLocation
parameter_list|)
block|{
try|try
block|{
name|prepareAcidUpgradeInternal
argument_list|(
name|scriptLocation
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
decl||
name|IOException
name|ex
parameter_list|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ex
argument_list|)
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
class|class
name|CompactionMetaInfo
block|{
comment|/**      * total number of bytes to be compacted across all compaction commands      */
name|long
name|numberOfBytes
decl_stmt|;
block|}
comment|/**    * todo: make sure compaction queue is configured and has ample capacity    * todo: what to do on failure?  Suppose some table/part is not readable.  should it produce    * todo: should probably suppor dryRun mode where we output scripts but instead of renaming files    *  we generate a renaming script.  Alternatively, always generate a renaming script and have    *  user execute it - this is probably a better option.  If script is not empty on rerun someone    *  added files to table to be made Acid.    * commands for all other tables?    * todo: how do we test this?  even if we had 2.x data it won't be readable in 3.0.  even w/o any    * updates, txnids in the data won't make sense in 3.0 w/o actually performing equivalent of    * metastore upgrade to init writeid table.  Also, can we even create a new table and set location    * to existing files to simulate a 2.x table?    * todo: generate some instructions in compaction script to include tottal compactions to perform,    * total data volume to handle and anything else that may help users guess at how long it will    * take.  Also, highlight tuning options to speed this up.    * todo: can we make the script blocking so that it waits for cleaner to delete files?    * need to poll SHOW COMPACTIONS and make sure that all partitions are in "finished" state    * todo: this should accept a file of table names to exclude from non-acid to acid conversion    * todo: change script comments to a preamble instead of a footer    *    * @throws MetaException    * @throws TException    */
specifier|private
name|void
name|prepareAcidUpgradeInternal
parameter_list|(
name|String
name|scriptLocation
parameter_list|)
throws|throws
name|MetaException
throws|,
name|TException
throws|,
name|IOException
block|{
name|Configuration
name|conf
init|=
name|MetastoreConf
operator|.
name|newMetastoreConf
argument_list|()
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Looking for Acid tables that need to be compacted"
argument_list|)
expr_stmt|;
comment|//todo: check if acid is enabled and bail if not
comment|//todo: check that running on 2.x?
name|HiveMetaStoreClient
name|hms
init|=
operator|new
name|HiveMetaStoreClient
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|//MetaException
name|List
argument_list|<
name|String
argument_list|>
name|databases
init|=
name|hms
operator|.
name|getAllDatabases
argument_list|()
decl_stmt|;
comment|//TException
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Found "
operator|+
name|databases
operator|.
name|size
argument_list|()
operator|+
literal|" databases to process"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|compactions
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|convertToAcid
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|convertToMM
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|CompactionMetaInfo
name|compactionMetaInfo
init|=
operator|new
name|CompactionMetaInfo
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|dbName
range|:
name|databases
control|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tables
init|=
name|hms
operator|.
name|getAllTables
argument_list|(
name|dbName
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"found "
operator|+
name|tables
operator|.
name|size
argument_list|()
operator|+
literal|" tables in "
operator|+
name|dbName
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|tableName
range|:
name|tables
control|)
block|{
name|Table
name|t
init|=
name|hms
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
comment|//ql depends on metastore and is not accessible here...  and if it was, I would not be using
comment|//2.6 exec jar, but 3.0.... which is not what we want
name|List
argument_list|<
name|String
argument_list|>
name|compactionCommands
init|=
name|getCompactionCommands
argument_list|(
name|t
argument_list|,
name|conf
argument_list|,
name|hms
argument_list|,
name|compactionMetaInfo
argument_list|)
decl_stmt|;
name|compactions
operator|.
name|addAll
argument_list|(
name|compactionCommands
argument_list|)
expr_stmt|;
name|processConversion
argument_list|(
name|t
argument_list|,
name|convertToAcid
argument_list|,
name|convertToMM
argument_list|,
name|hms
argument_list|)
expr_stmt|;
comment|/*todo: handle renaming files somewhere            * */
block|}
block|}
name|makeCompactionScript
argument_list|(
name|compactions
argument_list|,
name|scriptLocation
argument_list|,
name|compactionMetaInfo
argument_list|)
expr_stmt|;
name|makeConvertTableScript
argument_list|(
name|convertToAcid
argument_list|,
name|convertToMM
argument_list|,
name|scriptLocation
argument_list|)
expr_stmt|;
name|makeRenameFileScript
argument_list|(
name|scriptLocation
argument_list|)
expr_stmt|;
block|}
comment|//todo: handle exclusion list
specifier|private
specifier|static
name|void
name|processConversion
parameter_list|(
name|Table
name|t
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|convertToAcid
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|convertToMM
parameter_list|,
name|HiveMetaStoreClient
name|hms
parameter_list|)
throws|throws
name|TException
block|{
if|if
condition|(
name|isFullAcidTable
argument_list|(
name|t
argument_list|)
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|TableType
operator|.
name|MANAGED_TABLE
operator|.
name|name
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|t
operator|.
name|getTableType
argument_list|()
argument_list|)
condition|)
block|{
return|return;
block|}
name|String
name|fullTableName
init|=
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|.
name|getPartitionKeysSize
argument_list|()
operator|<=
literal|0
condition|)
block|{
if|if
condition|(
name|canBeMadeAcid
argument_list|(
name|fullTableName
argument_list|,
name|t
operator|.
name|getSd
argument_list|()
argument_list|)
condition|)
block|{
name|convertToAcid
operator|.
name|add
argument_list|(
literal|"ALTER TABLE "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
operator|+
literal|" SET TBLPROPERTIES ("
operator|+
literal|"'transactional'='true')"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|convertToMM
operator|.
name|add
argument_list|(
literal|"ALTER TABLE "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
operator|+
literal|" SET TBLPROPERTIES ("
operator|+
literal|"'transactional'='true', 'transactional_properties'='insert_only')"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|String
argument_list|>
name|partNames
init|=
name|hms
operator|.
name|listPartitionNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
name|int
name|batchSize
init|=
literal|10000
decl_stmt|;
comment|//todo: right size?
name|int
name|numWholeBatches
init|=
name|partNames
operator|.
name|size
argument_list|()
operator|/
name|batchSize
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numWholeBatches
condition|;
name|i
operator|++
control|)
block|{
name|List
argument_list|<
name|Partition
argument_list|>
name|partitionList
init|=
name|hms
operator|.
name|getPartitionsByNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|i
operator|*
name|batchSize
argument_list|,
operator|(
name|i
operator|+
literal|1
operator|)
operator|*
name|batchSize
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|p
range|:
name|partitionList
control|)
block|{
if|if
condition|(
operator|!
name|canBeMadeAcid
argument_list|(
name|fullTableName
argument_list|,
name|p
operator|.
name|getSd
argument_list|()
argument_list|)
condition|)
block|{
name|convertToMM
operator|.
name|add
argument_list|(
literal|"ALTER TABLE "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
operator|+
literal|" SET TBLPROPERTIES ("
operator|+
literal|"'transactional'='true', 'transactional_properties'='insert_only')"
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
block|}
if|if
condition|(
name|numWholeBatches
operator|*
name|batchSize
operator|<
name|partNames
operator|.
name|size
argument_list|()
condition|)
block|{
comment|//last partial batch
name|List
argument_list|<
name|Partition
argument_list|>
name|partitionList
init|=
name|hms
operator|.
name|getPartitionsByNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|numWholeBatches
operator|*
name|batchSize
argument_list|,
name|partNames
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|p
range|:
name|partitionList
control|)
block|{
if|if
condition|(
operator|!
name|canBeMadeAcid
argument_list|(
name|fullTableName
argument_list|,
name|p
operator|.
name|getSd
argument_list|()
argument_list|)
condition|)
block|{
name|convertToMM
operator|.
name|add
argument_list|(
literal|"ALTER TABLE "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
operator|+
literal|" SET TBLPROPERTIES ("
operator|+
literal|"'transactional'='true', 'transactional_properties'='insert_only')"
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
block|}
comment|//if here checked all parts and they are Acid compatible - make it acid
name|convertToAcid
operator|.
name|add
argument_list|(
literal|"ALTER TABLE "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
operator|+
literal|" SET TBLPROPERTIES ("
operator|+
literal|"'transactional'='true')"
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|boolean
name|canBeMadeAcid
parameter_list|(
name|String
name|fullTableName
parameter_list|,
name|StorageDescriptor
name|sd
parameter_list|)
block|{
return|return
name|isAcidInputOutputFormat
argument_list|(
name|fullTableName
argument_list|,
name|sd
argument_list|)
operator|&&
name|sd
operator|.
name|getSortColsSize
argument_list|()
operator|<=
literal|0
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isAcidInputOutputFormat
parameter_list|(
name|String
name|fullTableName
parameter_list|,
name|StorageDescriptor
name|sd
parameter_list|)
block|{
try|try
block|{
name|Class
name|inputFormatClass
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|==
literal|null
condition|?
literal|null
else|:
name|Class
operator|.
name|forName
argument_list|(
name|sd
operator|.
name|getInputFormat
argument_list|()
argument_list|)
decl_stmt|;
name|Class
name|outputFormatClass
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|==
literal|null
condition|?
literal|null
else|:
name|Class
operator|.
name|forName
argument_list|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|inputFormatClass
operator|!=
literal|null
operator|&&
name|outputFormatClass
operator|!=
literal|null
operator|&&
name|Class
operator|.
name|forName
argument_list|(
literal|"org.apache.hadoop.hive.ql.io.AcidInputFormat"
argument_list|)
operator|.
name|isAssignableFrom
argument_list|(
name|inputFormatClass
argument_list|)
operator|&&
name|Class
operator|.
name|forName
argument_list|(
literal|"org.apache.hadoop.hive.ql.io.AcidOutputFormat"
argument_list|)
operator|.
name|isAssignableFrom
argument_list|(
name|outputFormatClass
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
comment|//if a table is using some custom I/O format and it's not in the classpath, we won't mark
comment|//the table for Acid, but today (Hive 3.1 and earlier) OrcInput/OutputFormat is the only
comment|//Acid format
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Could not determine if "
operator|+
name|fullTableName
operator|+
literal|" can be made Acid due to: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * currently writes to current dir (whatever that is).    * If there is nothing to compact, outputs empty file so as not to confuse the output with a    * failed run.    * todo: add some config to tell it where to put the script    */
specifier|private
specifier|static
name|void
name|makeCompactionScript
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|commands
parameter_list|,
name|String
name|scriptLocation
parameter_list|,
name|CompactionMetaInfo
name|compactionMetaInfo
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|commands
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"No compaction is necessary"
argument_list|)
expr_stmt|;
return|return;
block|}
name|String
name|fileName
init|=
literal|"compacts_"
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|+
literal|".sql"
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Writing compaction commands to "
operator|+
name|fileName
argument_list|)
expr_stmt|;
try|try
init|(
name|PrintWriter
name|pw
init|=
name|createScript
argument_list|(
name|commands
argument_list|,
name|fileName
argument_list|,
name|scriptLocation
argument_list|)
init|)
block|{
comment|//add post script
name|pw
operator|.
name|println
argument_list|(
literal|"-- Generated total of "
operator|+
name|commands
operator|.
name|size
argument_list|()
operator|+
literal|" compaction commands"
argument_list|)
expr_stmt|;
if|if
condition|(
name|compactionMetaInfo
operator|.
name|numberOfBytes
operator|<
name|Math
operator|.
name|pow
argument_list|(
literal|2
argument_list|,
literal|20
argument_list|)
condition|)
block|{
comment|//to see it working in UTs
name|pw
operator|.
name|println
argument_list|(
literal|"-- The total volume of data to be compacted is "
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%.6fMB"
argument_list|,
name|compactionMetaInfo
operator|.
name|numberOfBytes
operator|/
name|Math
operator|.
name|pow
argument_list|(
literal|2
argument_list|,
literal|20
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pw
operator|.
name|println
argument_list|(
literal|"-- The total volume of data to be compacted is "
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%.3fGB"
argument_list|,
name|compactionMetaInfo
operator|.
name|numberOfBytes
operator|/
name|Math
operator|.
name|pow
argument_list|(
literal|2
argument_list|,
literal|30
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pw
operator|.
name|println
argument_list|()
expr_stmt|;
name|pw
operator|.
name|println
argument_list|(
literal|"-- Please note that compaction may be a heavyweight and time consuming process.\n"
operator|+
literal|"-- Submitting all of these commands will enqueue them to a scheduling queue from\n"
operator|+
literal|"-- which they will be picked up by compactor Workers.  The max number of\n"
operator|+
literal|"-- concurrent Workers is controlled by hive.compactor.worker.threads configured\n"
operator|+
literal|"-- for the standalone metastore process.  Compaction itself is a Map-Reduce job\n"
operator|+
literal|"-- which is submitted to the YARN queue identified by hive.compactor.job.queue\n"
operator|+
literal|"-- property if defined or 'default' if not defined.  It's advisable to set the\n"
operator|+
literal|"-- capacity of this queue appropriately"
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|void
name|makeConvertTableScript
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|alterTableAcid
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|alterTableMm
parameter_list|,
name|String
name|scriptLocation
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|alterTableAcid
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"No acid conversion is necessary"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|fileName
init|=
literal|"convertToAcid_"
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|+
literal|".sql"
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Writing acid conversion commands to "
operator|+
name|fileName
argument_list|)
expr_stmt|;
try|try
init|(
name|PrintWriter
name|pw
init|=
name|createScript
argument_list|(
name|alterTableAcid
argument_list|,
name|fileName
argument_list|,
name|scriptLocation
argument_list|)
init|)
block|{
name|pw
operator|.
name|println
argument_list|(
literal|"-- These commands may be executed by Hive 1.x later"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|alterTableMm
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"No managed table conversion is necessary"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|fileName
init|=
literal|"convertToMM_"
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|+
literal|".sql"
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Writing managed table conversion commands to "
operator|+
name|fileName
argument_list|)
expr_stmt|;
try|try
init|(
name|PrintWriter
name|pw
init|=
name|createScript
argument_list|(
name|alterTableMm
argument_list|,
name|fileName
argument_list|,
name|scriptLocation
argument_list|)
init|)
block|{
name|pw
operator|.
name|println
argument_list|(
literal|"-- These commands must be executed by Hive 3.0 or later"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|PrintWriter
name|createScript
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|commands
parameter_list|,
name|String
name|fileName
parameter_list|,
name|String
name|scriptLocation
parameter_list|)
throws|throws
name|IOException
block|{
comment|//todo: make sure to create the file in 'scriptLocation' dir
name|FileWriter
name|fw
init|=
operator|new
name|FileWriter
argument_list|(
name|scriptLocation
operator|+
literal|"/"
operator|+
name|fileName
argument_list|)
decl_stmt|;
name|PrintWriter
name|pw
init|=
operator|new
name|PrintWriter
argument_list|(
name|fw
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|cmd
range|:
name|commands
control|)
block|{
name|pw
operator|.
name|println
argument_list|(
name|cmd
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
return|return
name|pw
return|;
block|}
specifier|private
specifier|static
name|void
name|makeRenameFileScript
parameter_list|(
name|String
name|scriptLocation
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|commands
init|=
name|Collections
operator|.
name|emptyList
argument_list|()
decl_stmt|;
if|if
condition|(
name|commands
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"No file renaming is necessary"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|fileName
init|=
literal|"normalizeFileNames_"
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|+
literal|".sh"
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Writing file renaming commands to "
operator|+
name|fileName
argument_list|)
expr_stmt|;
name|PrintWriter
name|pw
init|=
name|createScript
argument_list|(
name|commands
argument_list|,
name|fileName
argument_list|,
name|scriptLocation
argument_list|)
decl_stmt|;
name|pw
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return any compaction commands to run for {@code Table t}    */
specifier|private
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getCompactionCommands
parameter_list|(
name|Table
name|t
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|HiveMetaStoreClient
name|hms
parameter_list|,
name|CompactionMetaInfo
name|compactionMetaInfo
parameter_list|)
throws|throws
name|IOException
throws|,
name|TException
block|{
if|if
condition|(
operator|!
name|isFullAcidTable
argument_list|(
name|t
argument_list|)
condition|)
block|{
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
if|if
condition|(
name|t
operator|.
name|getPartitionKeysSize
argument_list|()
operator|<=
literal|0
condition|)
block|{
comment|//not partitioned
if|if
condition|(
operator|!
name|needsCompaction
argument_list|(
operator|new
name|Path
argument_list|(
name|t
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|,
name|compactionMetaInfo
argument_list|)
condition|)
block|{
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|cmds
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|cmds
operator|.
name|add
argument_list|(
name|getCompactionCommand
argument_list|(
name|t
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|cmds
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|partNames
init|=
name|hms
operator|.
name|listPartitionNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
name|int
name|batchSize
init|=
literal|10000
decl_stmt|;
comment|//todo: right size?
name|int
name|numWholeBatches
init|=
name|partNames
operator|.
name|size
argument_list|()
operator|/
name|batchSize
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|compactionCommands
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numWholeBatches
condition|;
name|i
operator|++
control|)
block|{
name|List
argument_list|<
name|Partition
argument_list|>
name|partitionList
init|=
name|hms
operator|.
name|getPartitionsByNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|i
operator|*
name|batchSize
argument_list|,
operator|(
name|i
operator|+
literal|1
operator|)
operator|*
name|batchSize
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|p
range|:
name|partitionList
control|)
block|{
if|if
condition|(
name|needsCompaction
argument_list|(
operator|new
name|Path
argument_list|(
name|p
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|,
name|compactionMetaInfo
argument_list|)
condition|)
block|{
name|compactionCommands
operator|.
name|add
argument_list|(
name|getCompactionCommand
argument_list|(
name|t
argument_list|,
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|numWholeBatches
operator|*
name|batchSize
operator|<
name|partNames
operator|.
name|size
argument_list|()
condition|)
block|{
comment|//last partial batch
name|List
argument_list|<
name|Partition
argument_list|>
name|partitionList
init|=
name|hms
operator|.
name|getPartitionsByNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|numWholeBatches
operator|*
name|batchSize
argument_list|,
name|partNames
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|p
range|:
name|partitionList
control|)
block|{
if|if
condition|(
name|needsCompaction
argument_list|(
operator|new
name|Path
argument_list|(
name|p
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|,
name|compactionMetaInfo
argument_list|)
condition|)
block|{
name|compactionCommands
operator|.
name|add
argument_list|(
name|getCompactionCommand
argument_list|(
name|t
argument_list|,
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|compactionCommands
return|;
block|}
comment|/**    *    * @param location - path to a partition (or table if not partitioned) dir    */
specifier|private
specifier|static
name|boolean
name|needsCompaction
parameter_list|(
name|Path
name|location
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|CompactionMetaInfo
name|compactionMetaInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|location
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|deltas
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|location
argument_list|,
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
comment|//checking for delete_delta is only so that this functionality can be exercised by code 3.0
comment|//which cannot produce any deltas with mix of update/insert events
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"delta_"
argument_list|)
operator|||
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"delete_delta_"
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
if|if
condition|(
name|deltas
operator|==
literal|null
operator|||
name|deltas
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|//base_n cannot contain update/delete.  Original files are all 'insert' and we need to compact
comment|//only if there are update/delete events.
return|return
literal|false
return|;
block|}
name|deltaLoop
label|:
for|for
control|(
name|FileStatus
name|delta
range|:
name|deltas
control|)
block|{
if|if
condition|(
operator|!
name|delta
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
comment|//should never happen - just in case
continue|continue;
block|}
name|FileStatus
index|[]
name|buckets
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|delta
operator|.
name|getPath
argument_list|()
argument_list|,
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
comment|//since this is inside a delta dir created by Hive 2.x or earlier it can only contain
comment|//bucket_x or bucket_x__flush_length
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"bucket_"
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|bucket
range|:
name|buckets
control|)
block|{
if|if
condition|(
name|bucket
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|endsWith
argument_list|(
literal|"_flush_length"
argument_list|)
condition|)
block|{
comment|//streaming ingest dir - cannot have update/delete events
continue|continue
name|deltaLoop
continue|;
block|}
if|if
condition|(
name|needsCompaction
argument_list|(
name|bucket
argument_list|,
name|fs
argument_list|)
condition|)
block|{
comment|//found delete events - this 'location' needs compacting
name|compactionMetaInfo
operator|.
name|numberOfBytes
operator|+=
name|getDataSize
argument_list|(
name|location
argument_list|,
name|conf
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * @param location - path to a partition (or table if not partitioned) dir    * @throws IOException    */
specifier|private
specifier|static
name|long
name|getDataSize
parameter_list|(
name|Path
name|location
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|/*      * todo: Figure out the size of the partition.  The      * best way is to getAcidState() and look at each file - this way it takes care of      * original files vs base and any other obsolete files.  For now just brute force it,       * it's likely close enough for a rough estimate.*/
name|FileSystem
name|fs
init|=
name|location
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|ContentSummary
name|cs
init|=
name|fs
operator|.
name|getContentSummary
argument_list|(
name|location
argument_list|)
decl_stmt|;
return|return
name|cs
operator|.
name|getLength
argument_list|()
return|;
block|}
specifier|private
specifier|static
name|boolean
name|needsCompaction
parameter_list|(
name|FileStatus
name|bucket
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
comment|//create reader, look at footer
comment|//no need to check side file since it can only be in a streaming ingest delta
name|Reader
name|orcReader
init|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|bucket
operator|.
name|getPath
argument_list|()
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|)
operator|.
name|filesystem
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
name|AcidStats
name|as
init|=
name|OrcAcidUtils
operator|.
name|parseAcidStats
argument_list|(
name|orcReader
argument_list|)
decl_stmt|;
if|if
condition|(
name|as
operator|==
literal|null
condition|)
block|{
comment|//should never happen since we are reading bucket_x written by acid write
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"AcidStats missing in "
operator|+
name|bucket
operator|.
name|getPath
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|as
operator|.
name|deletes
operator|>
literal|0
operator|||
name|as
operator|.
name|updates
operator|>
literal|0
return|;
block|}
specifier|private
specifier|static
name|String
name|getCompactionCommand
parameter_list|(
name|Table
name|t
parameter_list|,
name|Partition
name|p
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"ALTER TABLE "
argument_list|)
operator|.
name|append
argument_list|(
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|.
name|getPartitionKeysSize
argument_list|()
operator|>
literal|0
condition|)
block|{
assert|assert
name|p
operator|!=
literal|null
operator|:
literal|"must supply partition for partitioned table "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
assert|;
name|sb
operator|.
name|append
argument_list|(
literal|" PARTITION("
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|t
operator|.
name|getPartitionKeysSize
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
comment|//todo: should these be quoted?  HiveUtils.unparseIdentifier() - if value is String should definitely quote
name|sb
operator|.
name|append
argument_list|(
name|t
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|'='
argument_list|)
operator|.
name|append
argument_list|(
name|p
operator|.
name|getValues
argument_list|()
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|setCharAt
argument_list|(
name|sb
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|,
literal|')'
argument_list|)
expr_stmt|;
comment|//replace trailing ','
block|}
return|return
name|sb
operator|.
name|append
argument_list|(
literal|" COMPACT 'major'"
argument_list|)
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isFullAcidTable
parameter_list|(
name|Table
name|t
parameter_list|)
block|{
if|if
condition|(
name|t
operator|.
name|getParametersSize
argument_list|()
operator|<=
literal|0
condition|)
block|{
comment|//cannot be acid
return|return
literal|false
return|;
block|}
name|String
name|transacationalValue
init|=
name|t
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|transacationalValue
operator|!=
literal|null
operator|&&
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transacationalValue
argument_list|)
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Found Acid table: "
operator|+
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|t
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
specifier|static
name|void
name|printAndExit
parameter_list|(
name|HiveMetaTool
name|metaTool
parameter_list|)
block|{
name|HelpFormatter
name|formatter
init|=
operator|new
name|HelpFormatter
argument_list|()
decl_stmt|;
name|formatter
operator|.
name|printHelp
argument_list|(
literal|"metatool"
argument_list|,
name|metaTool
operator|.
name|cmdLineOptions
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
block|{
name|HiveMetaTool
name|metaTool
init|=
operator|new
name|HiveMetaTool
argument_list|()
decl_stmt|;
name|metaTool
operator|.
name|init
argument_list|()
expr_stmt|;
name|CommandLineParser
name|parser
init|=
operator|new
name|GnuParser
argument_list|()
decl_stmt|;
name|CommandLine
name|line
init|=
literal|null
decl_stmt|;
try|try
block|{
try|try
block|{
name|line
operator|=
name|parser
operator|.
name|parse
argument_list|(
name|metaTool
operator|.
name|cmdLineOptions
argument_list|,
name|args
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ParseException
name|e
parameter_list|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool:Parsing failed.  Reason: "
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"help"
argument_list|)
condition|)
block|{
name|HelpFormatter
name|formatter
init|=
operator|new
name|HelpFormatter
argument_list|()
decl_stmt|;
name|formatter
operator|.
name|printHelp
argument_list|(
literal|"metatool"
argument_list|,
name|metaTool
operator|.
name|cmdLineOptions
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"listFSRoot"
argument_list|)
condition|)
block|{
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"dryRun"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: dryRun is not valid with listFSRoot"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"serdePropKey"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: serdePropKey is not valid with listFSRoot"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"tablePropKey"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: tablePropKey is not valid with listFSRoot"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
name|metaTool
operator|.
name|listFSRoot
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"executeJDOQL"
argument_list|)
condition|)
block|{
name|String
name|query
init|=
name|line
operator|.
name|getOptionValue
argument_list|(
literal|"executeJDOQL"
argument_list|)
decl_stmt|;
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"dryRun"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: dryRun is not valid with executeJDOQL"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"serdePropKey"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: serdePropKey is not valid with executeJDOQL"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"tablePropKey"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: tablePropKey is not valid with executeJDOQL"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|query
operator|.
name|toLowerCase
argument_list|()
operator|.
name|trim
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"select"
argument_list|)
condition|)
block|{
name|metaTool
operator|.
name|executeJDOQLSelect
argument_list|(
name|query
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|query
operator|.
name|toLowerCase
argument_list|()
operator|.
name|trim
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"update"
argument_list|)
condition|)
block|{
name|metaTool
operator|.
name|executeJDOQLUpdate
argument_list|(
name|query
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool:Unsupported statement type"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"updateLocation"
argument_list|)
condition|)
block|{
name|String
index|[]
name|loc
init|=
name|line
operator|.
name|getOptionValues
argument_list|(
literal|"updateLocation"
argument_list|)
decl_stmt|;
name|boolean
name|isDryRun
init|=
literal|false
decl_stmt|;
name|String
name|serdepropKey
init|=
literal|null
decl_stmt|;
name|String
name|tablePropKey
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|loc
operator|.
name|length
operator|!=
literal|2
operator|&&
name|loc
operator|.
name|length
operator|!=
literal|3
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool:updateLocation takes in 2 required and 1 "
operator|+
literal|"optional arguments but "
operator|+
literal|"was passed "
operator|+
name|loc
operator|.
name|length
operator|+
literal|" arguments"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
name|Path
name|newPath
init|=
operator|new
name|Path
argument_list|(
name|loc
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|Path
name|oldPath
init|=
operator|new
name|Path
argument_list|(
name|loc
index|[
literal|1
index|]
argument_list|)
decl_stmt|;
name|URI
name|oldURI
init|=
name|oldPath
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|URI
name|newURI
init|=
name|newPath
operator|.
name|toUri
argument_list|()
decl_stmt|;
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"dryRun"
argument_list|)
condition|)
block|{
name|isDryRun
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"serdePropKey"
argument_list|)
condition|)
block|{
name|serdepropKey
operator|=
name|line
operator|.
name|getOptionValue
argument_list|(
literal|"serdePropKey"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"tablePropKey"
argument_list|)
condition|)
block|{
name|tablePropKey
operator|=
name|line
operator|.
name|getOptionValue
argument_list|(
literal|"tablePropKey"
argument_list|)
expr_stmt|;
block|}
comment|/*          * validate input - Both new and old URI should contain valid host names and valid schemes.          * port is optional in both the URIs since HDFS HA NN URI doesn't have a port.          */
if|if
condition|(
name|oldURI
operator|.
name|getHost
argument_list|()
operator|==
literal|null
operator|||
name|newURI
operator|.
name|getHost
argument_list|()
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool:A valid host is required in both old-loc and new-loc"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oldURI
operator|.
name|getScheme
argument_list|()
operator|==
literal|null
operator|||
name|newURI
operator|.
name|getScheme
argument_list|()
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool:A valid scheme is required in both old-loc and new-loc"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|metaTool
operator|.
name|updateFSRootLocation
argument_list|(
name|oldURI
argument_list|,
name|newURI
argument_list|,
name|serdepropKey
argument_list|,
name|tablePropKey
argument_list|,
name|isDryRun
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"prepareAcidUpgrade"
argument_list|)
condition|)
block|{
name|String
index|[]
name|values
init|=
name|line
operator|.
name|getOptionValues
argument_list|(
literal|"prepareAcidUpgrade"
argument_list|)
decl_stmt|;
name|String
name|targetDir
init|=
literal|"."
decl_stmt|;
if|if
condition|(
name|values
operator|!=
literal|null
operator|&&
name|values
operator|.
name|length
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|values
operator|.
name|length
operator|>
literal|1
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: prepareAcidUpgrade"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|targetDir
operator|=
name|values
index|[
literal|0
index|]
expr_stmt|;
block|}
block|}
name|metaTool
operator|.
name|prepareAcidUpgrade
argument_list|(
name|targetDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"dryRun"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: dryRun is not a valid standalone option"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"serdePropKey"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: serdePropKey is not a valid standalone option"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|line
operator|.
name|hasOption
argument_list|(
literal|"tablePropKey"
argument_list|)
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HiveMetaTool: tablePropKey is not a valid standalone option"
argument_list|)
expr_stmt|;
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|print
argument_list|(
literal|"HiveMetaTool:Parsing failed.  Reason: Invalid arguments: "
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|line
operator|.
name|getArgs
argument_list|()
control|)
block|{
name|System
operator|.
name|err
operator|.
name|print
argument_list|(
name|s
operator|+
literal|" "
argument_list|)
expr_stmt|;
block|}
name|System
operator|.
name|err
operator|.
name|println
argument_list|()
expr_stmt|;
block|}
name|printAndExit
argument_list|(
name|metaTool
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|metaTool
operator|.
name|shutdownObjectStore
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

