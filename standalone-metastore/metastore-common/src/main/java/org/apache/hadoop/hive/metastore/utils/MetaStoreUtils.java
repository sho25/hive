begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *<p>  * http://www.apache.org/licenses/LICENSE-2.0  *<p>  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
package|;
end_package

begin_import
import|import
name|java
operator|.
name|beans
operator|.
name|PropertyDescriptor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLClassLoader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|DateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|SimpleDateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TimeZone
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Predicate
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|PatternSyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
operator|.
name|compile
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeysPublic
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ColumnType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMPoolSchedulingPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|security
operator|.
name|HadoopThriftAuthBridge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SaslRpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_class
specifier|public
class|class
name|MetaStoreUtils
block|{
comment|/** A fixed date format to be used for hive partition column values. */
specifier|public
specifier|static
specifier|final
name|ThreadLocal
argument_list|<
name|DateFormat
argument_list|>
name|PARTITION_DATE_FORMAT
init|=
operator|new
name|ThreadLocal
argument_list|<
name|DateFormat
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|DateFormat
name|initialValue
parameter_list|()
block|{
name|DateFormat
name|val
init|=
operator|new
name|SimpleDateFormat
argument_list|(
literal|"yyyy-MM-dd"
argument_list|)
decl_stmt|;
name|val
operator|.
name|setLenient
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// Without this, 2020-20-20 becomes 2021-08-20.
name|val
operator|.
name|setTimeZone
argument_list|(
name|TimeZone
operator|.
name|getTimeZone
argument_list|(
literal|"UTC"
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|val
return|;
block|}
block|}
decl_stmt|;
comment|// Indicates a type was derived from the deserializer rather than Hive's metadata.
specifier|public
specifier|static
specifier|final
name|String
name|TYPE_FROM_DESERIALIZER
init|=
literal|"<derived from deserializer>"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MetaStoreUtils
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// The following two are public for any external users who wish to use them.
comment|/**    * This character is used to mark a database name as having a catalog name prepended.  This    * marker should be placed first in the String to make it easy to determine that this has both    * a catalog and a database name.  @ is chosen as it is not used in regular expressions.  This    * is only intended for use when making old Thrift calls that do not support catalog names.    */
specifier|public
specifier|static
specifier|final
name|char
name|CATALOG_DB_THRIFT_NAME_MARKER
init|=
literal|'@'
decl_stmt|;
comment|/**    * This String is used to seaprate the catalog name from the database name.  This should only    * be used in Strings that are prepended with {@link #CATALOG_DB_THRIFT_NAME_MARKER}.  # is    * chosen because it is not used in regular expressions.  this is only intended for use when    * making old Thrift calls that do not support catalog names.    */
specifier|public
specifier|static
specifier|final
name|String
name|CATALOG_DB_SEPARATOR
init|=
literal|"#"
decl_stmt|;
comment|/**    * Mark a database as being empty (as distinct from null).    */
specifier|public
specifier|static
specifier|final
name|String
name|DB_EMPTY_MARKER
init|=
literal|"!"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|EXTERNAL_TABLE_PURGE
init|=
literal|"external.table.purge"
decl_stmt|;
comment|// Right now we only support one special character '/'.
comment|// More special characters can be added accordingly in the future.
comment|// NOTE:
comment|// If the following array is updated, please also be sure to update the
comment|// configuration parameter documentation
comment|// HIVE_SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES in HiveConf as well.
specifier|private
specifier|static
specifier|final
name|char
index|[]
name|specialCharactersInTableNames
init|=
operator|new
name|char
index|[]
block|{
literal|'/'
block|}
decl_stmt|;
comment|/**    * Catches exceptions that can't be handled and bundles them to MetaException    *    * @param e exception to wrap.    * @throws MetaException wrapper for the exception    */
specifier|public
specifier|static
name|void
name|logAndThrowMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|exInfo
init|=
literal|"Got exception: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|exInfo
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Converting exception to MetaException"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|exInfo
argument_list|)
throw|;
block|}
specifier|public
specifier|static
name|String
name|encodeTableName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
comment|// The encoding method is simple, e.g., replace
comment|// all the special characters with the corresponding number in ASCII.
comment|// Note that unicode is not supported in table names. And we have explicit
comment|// checks for it.
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|char
name|ch
range|:
name|name
operator|.
name|toCharArray
argument_list|()
control|)
block|{
if|if
condition|(
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|ch
argument_list|)
operator|||
name|ch
operator|==
literal|'_'
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|ch
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|'-'
argument_list|)
operator|.
name|append
argument_list|(
operator|(
name|int
operator|)
name|ch
argument_list|)
operator|.
name|append
argument_list|(
literal|'-'
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * convert Exception to MetaException, which sets the cause to such exception    * @param e cause of the exception    * @return  the MetaException with the specified exception as the cause    */
specifier|public
specifier|static
name|MetaException
name|newMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
return|return
name|newMetaException
argument_list|(
name|e
operator|!=
literal|null
condition|?
name|e
operator|.
name|getMessage
argument_list|()
else|:
literal|null
argument_list|,
name|e
argument_list|)
return|;
block|}
comment|/**    * convert Exception to MetaException, which sets the cause to such exception    * @param errorMessage  the error message for this MetaException    * @param e             cause of the exception    * @return  the MetaException with the specified exception as the cause    */
specifier|public
specifier|static
name|MetaException
name|newMetaException
parameter_list|(
name|String
name|errorMessage
parameter_list|,
name|Exception
name|e
parameter_list|)
block|{
name|MetaException
name|metaException
init|=
operator|new
name|MetaException
argument_list|(
name|errorMessage
argument_list|)
decl_stmt|;
if|if
condition|(
name|e
operator|!=
literal|null
condition|)
block|{
name|metaException
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|metaException
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getColumnNamesForTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|colsIterator
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getColsIterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|colsIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|colsIterator
operator|.
name|next
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|colNames
return|;
block|}
comment|/**    * validateName    *    * Checks the name conforms to our standars which are: "[a-zA-z_0-9]+". checks    * this is just characters and numbers and _    *    * @param name    *          the name to validate    * @param conf    *          hive configuration    * @return true or false depending on conformance    *              if it doesn't match the pattern.    */
specifier|public
specifier|static
name|boolean
name|validateName
parameter_list|(
name|String
name|name
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|Pattern
name|tpat
decl_stmt|;
name|String
name|allowedCharacters
init|=
literal|"\\w_"
decl_stmt|;
if|if
condition|(
name|conf
operator|!=
literal|null
operator|&&
name|MetastoreConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES
argument_list|)
condition|)
block|{
for|for
control|(
name|Character
name|c
range|:
name|specialCharactersInTableNames
control|)
block|{
name|allowedCharacters
operator|+=
name|c
expr_stmt|;
block|}
block|}
name|tpat
operator|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"["
operator|+
name|allowedCharacters
operator|+
literal|"]+"
argument_list|)
expr_stmt|;
name|Matcher
name|m
init|=
name|tpat
operator|.
name|matcher
argument_list|(
name|name
argument_list|)
decl_stmt|;
return|return
name|m
operator|.
name|matches
argument_list|()
return|;
block|}
comment|/**    * Determines whether a table is an external table.    *    * @param table table of interest    *    * @return true if external    */
specifier|public
specifier|static
name|boolean
name|isExternalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|isExternal
argument_list|(
name|params
argument_list|)
return|;
block|}
comment|/**    * Determines whether an table needs to be purged or not.    *    * @param table table of interest    *    * @return true if external table needs to be purged    */
specifier|public
specifier|static
name|boolean
name|isExternalTablePurge
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|isPropertyTrue
argument_list|(
name|params
argument_list|,
name|EXTERNAL_TABLE_PURGE
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isExternal
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tableParams
parameter_list|)
block|{
return|return
name|isPropertyTrue
argument_list|(
name|tableParams
argument_list|,
literal|"EXTERNAL"
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isPropertyTrue
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tableParams
parameter_list|,
name|String
name|prop
parameter_list|)
block|{
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|tableParams
operator|.
name|get
argument_list|(
name|prop
argument_list|)
argument_list|)
return|;
block|}
comment|/** Duplicates AcidUtils; used in a couple places in metastore. */
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTableParam
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isNonNativeTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
operator|||
name|table
operator|.
name|getParameters
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|(
name|table
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|META_TABLE_STORAGE
argument_list|)
operator|!=
literal|null
operator|)
return|;
block|}
comment|/**    * Given a list of partition columns and a partial mapping from    * some partition columns to values the function returns the values    * for the column.    * @param partCols the list of table partition columns    * @param partSpec the partial mapping from partition column to values    * @return list of values of for given partition columns, any missing    *         values in partSpec is replaced by an empty string    */
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPvals
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|partCols
control|)
block|{
name|String
name|val
init|=
name|StringUtils
operator|.
name|defaultString
argument_list|(
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
return|return
name|pvals
return|;
block|}
specifier|public
specifier|static
name|String
name|makePartNameMatcher
parameter_list|(
name|Table
name|table
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|String
name|defaultStr
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
init|=
name|table
operator|.
name|getPartitionKeys
argument_list|()
decl_stmt|;
name|int
name|numPartKeys
init|=
name|partCols
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|partVals
operator|.
name|size
argument_list|()
operator|>
name|numPartKeys
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Incorrect number of partition values."
operator|+
literal|" numPartKeys="
operator|+
name|numPartKeys
operator|+
literal|", part_val="
operator|+
name|partVals
argument_list|)
throw|;
block|}
name|partCols
operator|=
name|partCols
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|partVals
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// Construct a pattern of the form: partKey=partVal/partKey2=partVal2/...
comment|// where partVal is either the escaped partition value given as input,
comment|// or a regex of the form ".*"
comment|// This works because the "=" and "/" separating key names and partition key/values
comment|// are not escaped.
name|String
name|partNameMatcher
init|=
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|partCols
argument_list|,
name|partVals
argument_list|,
name|defaultStr
argument_list|)
decl_stmt|;
comment|// add ".*" to the regex to match anything else afterwards the partial spec.
if|if
condition|(
name|partVals
operator|.
name|size
argument_list|()
operator|<
name|numPartKeys
condition|)
block|{
name|partNameMatcher
operator|+=
name|defaultStr
expr_stmt|;
block|}
return|return
name|partNameMatcher
return|;
block|}
comment|/**    * @param schema1: The first schema to be compared    * @param schema2: The second schema to be compared    * @return true if the two schemas are the same else false    *         for comparing a field we ignore the comment it has    */
specifier|public
specifier|static
name|boolean
name|compareFieldColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema1
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema2
parameter_list|)
block|{
if|if
condition|(
name|schema1
operator|.
name|size
argument_list|()
operator|!=
name|schema2
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|its1
init|=
name|schema1
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|its2
init|=
name|schema2
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|its1
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FieldSchema
name|f1
init|=
name|its1
operator|.
name|next
argument_list|()
decl_stmt|;
name|FieldSchema
name|f2
init|=
name|its2
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// The default equals provided by thrift compares the comments too for
comment|// equality, thus we need to compare the relevant fields here.
if|if
condition|(
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|f1
operator|.
name|getName
argument_list|()
argument_list|,
name|f2
operator|.
name|getName
argument_list|()
argument_list|)
operator|||
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|f1
operator|.
name|getType
argument_list|()
argument_list|,
name|f2
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isArchived
parameter_list|(
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
return|return
operator|(
name|params
operator|!=
literal|null
operator|&&
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|)
argument_list|)
operator|)
return|;
block|}
specifier|public
specifier|static
name|Path
name|getOriginalLocation
parameter_list|(
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
assert|assert
operator|(
name|isArchived
argument_list|(
name|part
argument_list|)
operator|)
assert|;
name|String
name|originalLocation
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|originalLocation
operator|!=
literal|null
operator|)
assert|;
return|return
operator|new
name|Path
argument_list|(
name|originalLocation
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
name|ARCHIVING_LEVEL
init|=
literal|"archiving_level"
decl_stmt|;
specifier|public
specifier|static
name|int
name|getArchivingLevel
parameter_list|(
name|Partition
name|part
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
operator|!
name|isArchived
argument_list|(
name|part
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Getting level of unarchived partition"
argument_list|)
throw|;
block|}
name|String
name|lv
init|=
name|part
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|ARCHIVING_LEVEL
argument_list|)
decl_stmt|;
if|if
condition|(
name|lv
operator|!=
literal|null
condition|)
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|lv
argument_list|)
return|;
block|}
comment|// partitions archived before introducing multiple archiving
return|return
name|part
operator|.
name|getValues
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**    * Read and return the meta store Sasl configuration. Currently it uses the default    * Hadoop SASL configuration and can be configured using "hadoop.rpc.protection"    * HADOOP-10211, made a backward incompatible change due to which this call doesn't    * work with Hadoop 2.4.0 and later.    * @param conf    * @return The SASL configuration    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getMetaStoreSaslProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|useSSL
parameter_list|)
block|{
comment|// As of now Hive Meta Store uses the same configuration as Hadoop SASL configuration
comment|// If SSL is enabled, override the given value of "hadoop.rpc.protection" and set it to "authentication"
comment|// This disables any encryption provided by SASL, since SSL already provides it
name|String
name|hadoopRpcProtectionVal
init|=
name|conf
operator|.
name|get
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
argument_list|)
decl_stmt|;
name|String
name|hadoopRpcProtectionAuth
init|=
name|SaslRpcServer
operator|.
name|QualityOfProtection
operator|.
name|AUTHENTICATION
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|useSSL
operator|&&
name|hadoopRpcProtectionVal
operator|!=
literal|null
operator|&&
operator|!
name|hadoopRpcProtectionVal
operator|.
name|equals
argument_list|(
name|hadoopRpcProtectionAuth
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Overriding value of "
operator|+
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
operator|+
literal|" setting it from "
operator|+
name|hadoopRpcProtectionVal
operator|+
literal|" to "
operator|+
name|hadoopRpcProtectionAuth
operator|+
literal|" because SSL is enabled"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_RPC_PROTECTION
argument_list|,
name|hadoopRpcProtectionAuth
argument_list|)
expr_stmt|;
block|}
return|return
name|HadoopThriftAuthBridge
operator|.
name|getBridge
argument_list|()
operator|.
name|getHadoopSaslProperties
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Add new elements to the classpath.    *    * @param newPaths    *          Array of classpath elements    */
specifier|public
specifier|static
name|ClassLoader
name|addToClassPath
parameter_list|(
name|ClassLoader
name|cloader
parameter_list|,
name|String
index|[]
name|newPaths
parameter_list|)
throws|throws
name|Exception
block|{
name|URLClassLoader
name|loader
init|=
operator|(
name|URLClassLoader
operator|)
name|cloader
decl_stmt|;
name|List
argument_list|<
name|URL
argument_list|>
name|curPath
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|loader
operator|.
name|getURLs
argument_list|()
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|URL
argument_list|>
name|newPath
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|curPath
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// get a list with the current classpath components
for|for
control|(
name|URL
name|onePath
range|:
name|curPath
control|)
block|{
name|newPath
operator|.
name|add
argument_list|(
name|onePath
argument_list|)
expr_stmt|;
block|}
name|curPath
operator|=
name|newPath
expr_stmt|;
for|for
control|(
name|String
name|onestr
range|:
name|newPaths
control|)
block|{
name|URL
name|oneurl
init|=
name|urlFromPathString
argument_list|(
name|onestr
argument_list|)
decl_stmt|;
if|if
condition|(
name|oneurl
operator|!=
literal|null
operator|&&
operator|!
name|curPath
operator|.
name|contains
argument_list|(
name|oneurl
argument_list|)
condition|)
block|{
name|curPath
operator|.
name|add
argument_list|(
name|oneurl
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|URLClassLoader
argument_list|(
name|curPath
operator|.
name|toArray
argument_list|(
operator|new
name|URL
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|loader
argument_list|)
return|;
block|}
comment|/**    * Create a URL from a string representing a path to a local file.    * The path string can be just a path, or can start with file:/, file:///    * @param onestr  path string    * @return    */
specifier|private
specifier|static
name|URL
name|urlFromPathString
parameter_list|(
name|String
name|onestr
parameter_list|)
block|{
name|URL
name|oneurl
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|onestr
operator|.
name|startsWith
argument_list|(
literal|"file:/"
argument_list|)
condition|)
block|{
name|oneurl
operator|=
operator|new
name|URL
argument_list|(
name|onestr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|oneurl
operator|=
operator|new
name|File
argument_list|(
name|onestr
argument_list|)
operator|.
name|toURL
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|err
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad URL "
operator|+
name|onestr
operator|+
literal|", ignoring path"
argument_list|)
expr_stmt|;
block|}
return|return
name|oneurl
return|;
block|}
comment|/**    * Convert FieldSchemas to Thrift DDL.    */
specifier|public
specifier|static
name|String
name|getDDLFromFieldSchema
parameter_list|(
name|String
name|structName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|ddl
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|"struct "
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|structName
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|" { "
argument_list|)
expr_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|fieldSchemas
control|)
block|{
if|if
condition|(
name|first
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|ddl
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
name|ColumnType
operator|.
name|typeToThriftType
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|' '
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"DDL: {}"
argument_list|,
name|ddl
argument_list|)
expr_stmt|;
return|return
name|ddl
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getTableMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getPartitionMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|partition
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|part
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get partition level schema from table level schema.    * This function will use the same column names, column types and partition keys for    * each partition Properties. Their values are copied from the table Properties. This    * is mainly to save CPU and memory. CPU is saved because the first time the    * StorageDescriptor column names are accessed, JDO needs to execute a SQL query to    * retrieve the data. If we know the data will be the same as the table level schema    * and they are immutable, we should just reuse the table level schema objects.    *    * @param sd The Partition level Storage Descriptor.    * @param parameters partition level parameters    * @param tblSchema The table level schema from which this partition should be copied.    * @return the properties    */
specifier|public
specifier|static
name|Properties
name|getPartSchemaFromTableSchema
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|Properties
name|tblSchema
parameter_list|)
block|{
comment|// Inherent most properties from table level schema and overwrite some properties
comment|// in the following code.
comment|// This is mainly for saving CPU and memory to reuse the column names, types and
comment|// partition columns in the table level schema.
name|Properties
name|schema
init|=
operator|(
name|Properties
operator|)
name|tblSchema
operator|.
name|clone
argument_list|()
decl_stmt|;
comment|// InputFormat
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblInput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblInput
operator|==
literal|null
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|inputFormat
operator|=
name|tblInput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
comment|// OutputFormat
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblOutput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblOutput
operator|==
literal|null
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|outputFormat
operator|=
name|tblOutput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
comment|// Location
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Bucket count
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|sd
operator|.
name|getBucketCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// SerdeInfo
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// We should not update the following 3 values if SerDeInfo contains these.
comment|// This is to keep backward compatible with getSchema(), where these 3 keys
comment|// are updated after SerDeInfo properties got copied.
name|String
name|cols
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
decl_stmt|;
name|String
name|colTypes
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
decl_stmt|;
name|String
name|parts
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|key
init|=
name|param
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|schema
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|!=
literal|null
operator|&&
operator|(
operator|(
name|key
operator|.
name|equals
argument_list|(
name|cols
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|colTypes
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|parts
argument_list|)
operator|||
comment|// Skip Druid and JDBC properties which are used in respective SerDes,
comment|// since they are also updated after SerDeInfo properties are copied.
name|key
operator|.
name|startsWith
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|DRUID_CONFIG_PREFIX
argument_list|)
operator|||
name|key
operator|.
name|startsWith
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|JDBC_CONFIG_PREFIX
argument_list|)
operator|)
operator|)
condition|)
block|{
continue|continue;
block|}
name|schema
operator|.
name|put
argument_list|(
name|key
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
name|StringUtils
operator|.
name|EMPTY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// skipping columns since partition level field schemas are the same as table level's
comment|// skipping partition keys since it is the same as table level partition keys
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|private
specifier|static
name|Properties
name|addCols
parameter_list|(
name|Properties
name|schema
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
name|StringBuilder
name|colNameBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colTypeBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colComment
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|String
name|columnNameDelimiter
init|=
name|getColumnNameDelimiter
argument_list|(
name|cols
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|colNameBuf
operator|.
name|append
argument_list|(
name|columnNameDelimiter
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
expr_stmt|;
name|colComment
operator|.
name|append
argument_list|(
literal|'\0'
argument_list|)
expr_stmt|;
block|}
name|colNameBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
name|colComment
operator|.
name|append
argument_list|(
operator|(
literal|null
operator|!=
name|col
operator|.
name|getComment
argument_list|()
operator|)
condition|?
name|col
operator|.
name|getComment
argument_list|()
else|:
name|StringUtils
operator|.
name|EMPTY
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
argument_list|,
name|colNameBuf
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|COLUMN_NAME_DELIMITER
argument_list|,
name|columnNameDelimiter
argument_list|)
expr_stmt|;
name|String
name|colTypes
init|=
name|colTypeBuf
operator|.
name|toString
argument_list|()
decl_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
argument_list|,
name|colTypes
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
literal|"columns.comments"
argument_list|,
name|colComment
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchemaWithoutCols
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
name|Properties
name|schema
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_NAME
argument_list|,
name|databaseName
operator|+
literal|"."
operator|+
name|tableName
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|sd
operator|.
name|getBucketCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|put
argument_list|(
name|param
operator|.
name|getKey
argument_list|()
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
name|StringUtils
operator|.
name|EMPTY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|ColumnType
operator|.
name|SERIALIZATION_DDL
argument_list|,
name|getDDLFromFieldSchema
argument_list|(
name|tableName
argument_list|,
name|sd
operator|.
name|getCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|partString
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
name|String
name|partStringSep
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
name|String
name|partTypesString
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
name|String
name|partTypesStringSep
init|=
name|StringUtils
operator|.
name|EMPTY
decl_stmt|;
for|for
control|(
name|FieldSchema
name|partKey
range|:
name|partitionKeys
control|)
block|{
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partStringSep
argument_list|)
expr_stmt|;
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|partTypesString
operator|=
name|partTypesString
operator|.
name|concat
argument_list|(
name|partTypesStringSep
argument_list|)
expr_stmt|;
name|partTypesString
operator|=
name|partTypesString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|partStringSep
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|partStringSep
operator|=
literal|"/"
expr_stmt|;
name|partTypesStringSep
operator|=
literal|":"
expr_stmt|;
block|}
block|}
if|if
condition|(
name|partString
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|,
name|partString
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMN_TYPES
argument_list|,
name|partTypesString
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// add non-null parameters to the schema
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
return|return
name|addCols
argument_list|(
name|getSchemaWithoutCols
argument_list|(
name|sd
argument_list|,
name|parameters
argument_list|,
name|databaseName
argument_list|,
name|tableName
argument_list|,
name|partitionKeys
argument_list|)
argument_list|,
name|tblsd
operator|.
name|getCols
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|getColumnNameDelimiter
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
comment|// we first take a look if any fieldSchemas contain COMMA
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
operator|.
name|contains
argument_list|(
literal|","
argument_list|)
condition|)
block|{
return|return
name|String
operator|.
name|valueOf
argument_list|(
name|ColumnType
operator|.
name|COLUMN_COMMENTS_DELIMITER
argument_list|)
return|;
block|}
block|}
return|return
name|String
operator|.
name|valueOf
argument_list|(
literal|','
argument_list|)
return|;
block|}
comment|/**    * Convert FieldSchemas to columnNames.    */
specifier|public
specifier|static
name|String
name|getColumnNamesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|String
name|delimiter
init|=
name|getColumnNameDelimiter
argument_list|(
name|fieldSchemas
argument_list|)
decl_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to columnTypes.    */
specifier|public
specifier|static
name|String
name|getColumnTypesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|String
name|getColumnCommentsFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|ColumnType
operator|.
name|COLUMN_COMMENTS_DELIMITER
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getComment
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isMaterializedViewTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|MATERIALIZED_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getColumnNames
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|cols
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|schema
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fs
range|:
name|schema
control|)
block|{
name|cols
operator|.
name|add
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|cols
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isValidSchedulingPolicy
parameter_list|(
name|String
name|str
parameter_list|)
block|{
try|try
block|{
name|parseSchedulingPolicy
argument_list|(
name|str
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|ex
parameter_list|)
block|{     }
return|return
literal|false
return|;
block|}
specifier|public
specifier|static
name|WMPoolSchedulingPolicy
name|parseSchedulingPolicy
parameter_list|(
name|String
name|schedulingPolicy
parameter_list|)
block|{
if|if
condition|(
name|schedulingPolicy
operator|==
literal|null
condition|)
block|{
return|return
name|WMPoolSchedulingPolicy
operator|.
name|FAIR
return|;
block|}
name|schedulingPolicy
operator|=
name|schedulingPolicy
operator|.
name|trim
argument_list|()
operator|.
name|toUpperCase
argument_list|()
expr_stmt|;
if|if
condition|(
literal|"DEFAULT"
operator|.
name|equals
argument_list|(
name|schedulingPolicy
argument_list|)
condition|)
block|{
return|return
name|WMPoolSchedulingPolicy
operator|.
name|FAIR
return|;
block|}
return|return
name|Enum
operator|.
name|valueOf
argument_list|(
name|WMPoolSchedulingPolicy
operator|.
name|class
argument_list|,
name|schedulingPolicy
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|boolean
name|hasCatalogName
parameter_list|(
name|String
name|dbName
parameter_list|)
block|{
return|return
name|dbName
operator|!=
literal|null
operator|&&
name|dbName
operator|.
name|length
argument_list|()
operator|>
literal|0
operator|&&
name|dbName
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
operator|==
name|CATALOG_DB_THRIFT_NAME_MARKER
return|;
block|}
comment|/**    * Given a catalog name and database name cram them together into one string.  This method can    * be used if you do not know the catalog name, in which case the default catalog will be    * retrieved from the conf object.  The resulting string can be parsed apart again via    * {@link #parseDbName(String, Configuration)}.    * @param catalogName catalog name, can be null if no known.    * @param dbName database name, can be null or empty.    * @param conf configuration object, used to determine default catalog if catalogName is null    * @return one string that contains both.    */
specifier|public
specifier|static
name|String
name|prependCatalogToDbName
parameter_list|(
annotation|@
name|Nullable
name|String
name|catalogName
parameter_list|,
annotation|@
name|Nullable
name|String
name|dbName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|catalogName
operator|==
literal|null
condition|)
name|catalogName
operator|=
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|StringBuilder
name|buf
init|=
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
name|CATALOG_DB_THRIFT_NAME_MARKER
argument_list|)
operator|.
name|append
argument_list|(
name|catalogName
argument_list|)
operator|.
name|append
argument_list|(
name|CATALOG_DB_SEPARATOR
argument_list|)
decl_stmt|;
if|if
condition|(
name|dbName
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|dbName
operator|.
name|isEmpty
argument_list|()
condition|)
name|buf
operator|.
name|append
argument_list|(
name|DB_EMPTY_MARKER
argument_list|)
expr_stmt|;
else|else
name|buf
operator|.
name|append
argument_list|(
name|dbName
argument_list|)
expr_stmt|;
block|}
return|return
name|buf
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Given a catalog name and database name, cram them together into one string.  These can be    * parsed apart again via {@link #parseDbName(String, Configuration)}.    * @param catalogName catalog name.  This cannot be null.  If this might be null use    *                    {@link #prependCatalogToDbName(String, String, Configuration)} instead.    * @param dbName database name.    * @return one string that contains both.    */
specifier|public
specifier|static
name|String
name|prependNotNullCatToDbName
parameter_list|(
name|String
name|catalogName
parameter_list|,
name|String
name|dbName
parameter_list|)
block|{
assert|assert
name|catalogName
operator|!=
literal|null
assert|;
return|return
name|prependCatalogToDbName
argument_list|(
name|catalogName
argument_list|,
name|dbName
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Prepend the default 'hive' catalog onto the database name.    * @param dbName database name    * @param conf configuration object, used to determine default catalog    * @return one string with the 'hive' catalog name prepended.    */
specifier|public
specifier|static
name|String
name|prependCatalogToDbName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|prependCatalogToDbName
argument_list|(
literal|null
argument_list|,
name|dbName
argument_list|,
name|conf
argument_list|)
return|;
block|}
specifier|private
specifier|final
specifier|static
name|String
index|[]
name|nullCatalogAndDatabase
init|=
block|{
literal|null
block|,
literal|null
block|}
decl_stmt|;
comment|/**    * Parse the catalog name out of the database name.  If no catalog name is present then the    * default catalog (as set in configuration file) will be assumed.    * @param dbName name of the database.  This may or may not contain the catalog name.    * @param conf configuration object, used to determine the default catalog if it is not present    *            in the database name.    * @return an array of two elements, the first being the catalog name, the second the database    * name.    * @throws MetaException if the name is not either just a database name or a catalog plus    * database name with the proper delimiters.    */
specifier|public
specifier|static
name|String
index|[]
name|parseDbName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|dbName
operator|==
literal|null
condition|)
return|return
name|nullCatalogAndDatabase
return|;
if|if
condition|(
name|hasCatalogName
argument_list|(
name|dbName
argument_list|)
condition|)
block|{
if|if
condition|(
name|dbName
operator|.
name|endsWith
argument_list|(
name|CATALOG_DB_SEPARATOR
argument_list|)
condition|)
block|{
comment|// This means the DB name is null
return|return
operator|new
name|String
index|[]
block|{
name|dbName
operator|.
name|substring
argument_list|(
literal|1
argument_list|,
name|dbName
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
block|,
literal|null
block|}
return|;
block|}
elseif|else
if|if
condition|(
name|dbName
operator|.
name|endsWith
argument_list|(
name|DB_EMPTY_MARKER
argument_list|)
condition|)
block|{
comment|// This means the DB name is empty
return|return
operator|new
name|String
index|[]
block|{
name|dbName
operator|.
name|substring
argument_list|(
literal|1
argument_list|,
name|dbName
operator|.
name|length
argument_list|()
operator|-
name|DB_EMPTY_MARKER
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
block|,
literal|""
block|}
return|;
block|}
name|String
index|[]
name|names
init|=
name|dbName
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
operator|.
name|split
argument_list|(
name|CATALOG_DB_SEPARATOR
argument_list|,
literal|2
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
name|dbName
operator|+
literal|" is prepended with the catalog marker but does not "
operator|+
literal|"appear to have a catalog name in it"
argument_list|)
throw|;
block|}
return|return
name|names
return|;
block|}
else|else
block|{
return|return
operator|new
name|String
index|[]
block|{
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
block|,
name|dbName
block|}
return|;
block|}
block|}
comment|/**    * Position in the array returned by {@link #parseDbName} that has the catalog name.    */
specifier|public
specifier|static
specifier|final
name|int
name|CAT_NAME
init|=
literal|0
decl_stmt|;
comment|/**    * Position in the array returned by {@link #parseDbName} that has the database name.    */
specifier|public
specifier|static
specifier|final
name|int
name|DB_NAME
init|=
literal|1
decl_stmt|;
specifier|public
specifier|static
name|String
name|getDefaultCatalog
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Configuration is null, so going with default catalog."
argument_list|)
expr_stmt|;
return|return
name|Warehouse
operator|.
name|DEFAULT_CATALOG_NAME
return|;
block|}
name|String
name|catName
init|=
name|MetastoreConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|CATALOG_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
name|catName
operator|==
literal|null
operator|||
literal|""
operator|.
name|equals
argument_list|(
name|catName
argument_list|)
condition|)
name|catName
operator|=
name|Warehouse
operator|.
name|DEFAULT_CATALOG_NAME
expr_stmt|;
return|return
name|catName
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isView
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * filters a given map with predicate provided. All entries of map whose key matches with    * predicate will be removed. Expects map to be modifiable and does the operation on actual map,    * so does not return a copy of filtered map.    * @param map A map of String key-value pairs    * @param predicate Predicate with pattern to filter the map    */
specifier|public
specifier|static
parameter_list|<
name|T
parameter_list|>
name|void
name|filterMapKeys
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|T
argument_list|>
name|map
parameter_list|,
name|Predicate
argument_list|<
name|String
argument_list|>
name|predicate
parameter_list|)
block|{
if|if
condition|(
name|map
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|map
operator|.
name|entrySet
argument_list|()
operator|.
name|removeIf
argument_list|(
name|entry
lambda|->
name|predicate
operator|.
name|test
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * filters a given map with list of predicates. All entries of map whose key matches with any    * predicate will be removed. Expects map to be modifiable and does the operation on actual map,    * so does not return a copy of filtered map.    * @param map A map of String key-value pairs    * @param predicates List of predicates with patterns to filter the map    */
specifier|public
specifier|static
parameter_list|<
name|T
parameter_list|>
name|void
name|filterMapkeys
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|T
argument_list|>
name|map
parameter_list|,
name|List
argument_list|<
name|Predicate
argument_list|<
name|String
argument_list|>
argument_list|>
name|predicates
parameter_list|)
block|{
if|if
condition|(
name|map
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|filterMapKeys
argument_list|(
name|map
argument_list|,
name|predicates
operator|.
name|stream
argument_list|()
operator|.
name|reduce
argument_list|(
name|Predicate
operator|::
name|or
argument_list|)
operator|.
name|orElse
argument_list|(
name|x
lambda|->
literal|false
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Compile a list of regex patterns and collect them as Predicates.    * @param patterns List of regex patterns to be compiled    * @return a List of Predicate created by compiling the regex patterns    */
specifier|public
specifier|static
name|List
argument_list|<
name|Predicate
argument_list|<
name|String
argument_list|>
argument_list|>
name|compilePatternsToPredicates
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|patterns
parameter_list|)
block|{
return|return
name|patterns
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|pattern
lambda|->
name|compile
argument_list|(
name|pattern
argument_list|)
operator|.
name|asPredicate
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
return|;
block|}
block|}
end_class

end_unit

