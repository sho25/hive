begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|security
operator|.
name|auth
operator|.
name|login
operator|.
name|LoginException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Shell
import|;
end_import

begin_comment
comment|/**  * Hive Configuration.  */
end_comment

begin_class
specifier|public
class|class
name|HiveConf
extends|extends
name|Configuration
block|{
specifier|protected
name|String
name|hiveJar
decl_stmt|;
specifier|protected
name|Properties
name|origProp
decl_stmt|;
specifier|protected
name|String
name|auxJars
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Log
name|l4j
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HiveConf
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
name|URL
name|hiveDefaultURL
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|URL
name|hiveSiteURL
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|byte
index|[]
name|confVarByteArray
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|ConfVars
argument_list|>
name|vars
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|ConfVars
argument_list|>
argument_list|()
decl_stmt|;
static|static
block|{
name|ClassLoader
name|classLoader
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getContextClassLoader
argument_list|()
decl_stmt|;
if|if
condition|(
name|classLoader
operator|==
literal|null
condition|)
block|{
name|classLoader
operator|=
name|HiveConf
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
expr_stmt|;
block|}
name|hiveDefaultURL
operator|=
name|classLoader
operator|.
name|getResource
argument_list|(
literal|"hive-default.xml"
argument_list|)
expr_stmt|;
comment|// Look for hive-site.xml on the CLASSPATH and log its location if found.
name|hiveSiteURL
operator|=
name|classLoader
operator|.
name|getResource
argument_list|(
literal|"hive-site.xml"
argument_list|)
expr_stmt|;
for|for
control|(
name|ConfVars
name|confVar
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
name|vars
operator|.
name|put
argument_list|(
name|confVar
operator|.
name|varname
argument_list|,
name|confVar
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Metastore related options that the db is initialized against. When a conf    * var in this is list is changed, the metastore instance for the CLI will    * be recreated so that the change will take effect.    */
specifier|public
specifier|static
specifier|final
name|HiveConf
operator|.
name|ConfVars
index|[]
name|metaVars
init|=
block|{
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREDIRECTORY
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREWAREHOUSE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREURIS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORETHRIFTCONNECTIONRETRIES
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORETHRIFTFAILURERETRIES
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CLIENT_CONNECT_RETRY_DELAY
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CLIENT_SOCKET_TIMEOUT
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREPWD
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORECONNECTURLHOOK
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORECONNECTURLKEY
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREATTEMPTS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREINTERVAL
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREFORCERELOADCONF
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORESERVERMINTHREADS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORESERVERMAXTHREADS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_TCP_KEEP_ALIVE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_INT_ORIGINAL
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_INT_ARCHIVED
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_INT_EXTRACTED
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_KERBEROS_KEYTAB_FILE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_KERBEROS_PRINCIPAL
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_USE_THRIFT_SASL
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CACHE_PINOBJTYPES
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CONNECTION_POOLING_TYPE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_VALIDATE_TABLES
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_VALIDATE_COLUMNS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_VALIDATE_CONSTRAINTS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_STORE_MANAGER_TYPE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_AUTO_CREATE_SCHEMA
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_AUTO_START_MECHANISM_MODE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_TRANSACTION_ISOLATION
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CACHE_LEVEL2
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_CACHE_LEVEL2_TYPE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_IDENTIFIER_FACTORY
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_PLUGIN_REGISTRY_BUNDLE_CHECK
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_AUTHORIZATION_STORAGE_AUTH_CHECKS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_BATCH_RETRIEVE_MAX
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_EVENT_LISTENERS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_EVENT_CLEAN_FREQ
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_EVENT_EXPIRY_DURATION
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_RAW_STORE_IMPL
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_END_FUNCTION_LISTENERS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_PART_INHERIT_TBL_PROPS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_BATCH_RETRIEVE_TABLE_PARTITION_MAX
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_INIT_HOOKS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_PRE_EVENT_LISTENERS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HMSHANDLERATTEMPTS
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HMSHANDLERINTERVAL
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HMSHANDLERFORCERELOADCONF
block|,       }
decl_stmt|;
comment|/**    * dbVars are the parameters can be set per database. If these    * parameters are set as a database property, when switching to that    * database, the HiveConf variable will be changed. The change of these    * parameters will effectively change the DFS and MapReduce clusters    * for different databases.    */
specifier|public
specifier|static
specifier|final
name|HiveConf
operator|.
name|ConfVars
index|[]
name|dbVars
init|=
block|{
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPBIN
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPJT
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREWAREHOUSE
block|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|SCRATCHDIR
block|}
decl_stmt|;
comment|/**    * ConfVars.    *    * These are the default configuration properties for Hive. Each HiveConf    * object is initialized as follows:    *    * 1) Hadoop configuration properties are applied.    * 2) ConfVar properties with non-null values are overlayed.    * 3) hive-site.xml properties are overlayed.    *    * WARNING: think twice before adding any Hadoop configuration properties    * with non-null values to this list as they will override any values defined    * in the underlying Hadoop configuration.    */
specifier|public
specifier|static
enum|enum
name|ConfVars
block|{
comment|// QL execution stuff
name|SCRIPTWRAPPER
argument_list|(
literal|"hive.exec.script.wrapper"
argument_list|,
literal|null
argument_list|)
block|,
name|PLAN
argument_list|(
literal|"hive.exec.plan"
argument_list|,
literal|""
argument_list|)
block|,
name|SCRATCHDIR
argument_list|(
literal|"hive.exec.scratchdir"
argument_list|,
literal|"/tmp/hive-"
operator|+
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|)
block|,
name|LOCALSCRATCHDIR
argument_list|(
literal|"hive.exec.local.scratchdir"
argument_list|,
literal|"/tmp/"
operator|+
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|)
block|,
name|SUBMITVIACHILD
argument_list|(
literal|"hive.exec.submitviachild"
argument_list|,
literal|false
argument_list|)
block|,
name|SCRIPTERRORLIMIT
argument_list|(
literal|"hive.exec.script.maxerrsize"
argument_list|,
literal|100000
argument_list|)
block|,
name|ALLOWPARTIALCONSUMP
argument_list|(
literal|"hive.exec.script.allow.partial.consumption"
argument_list|,
literal|false
argument_list|)
block|,
name|COMPRESSRESULT
argument_list|(
literal|"hive.exec.compress.output"
argument_list|,
literal|false
argument_list|)
block|,
name|COMPRESSINTERMEDIATE
argument_list|(
literal|"hive.exec.compress.intermediate"
argument_list|,
literal|false
argument_list|)
block|,
name|COMPRESSINTERMEDIATECODEC
argument_list|(
literal|"hive.intermediate.compression.codec"
argument_list|,
literal|""
argument_list|)
block|,
name|COMPRESSINTERMEDIATETYPE
argument_list|(
literal|"hive.intermediate.compression.type"
argument_list|,
literal|""
argument_list|)
block|,
name|BYTESPERREDUCER
argument_list|(
literal|"hive.exec.reducers.bytes.per.reducer"
argument_list|,
call|(
name|long
call|)
argument_list|(
literal|1000
operator|*
literal|1000
operator|*
literal|1000
argument_list|)
argument_list|)
block|,
name|MAXREDUCERS
argument_list|(
literal|"hive.exec.reducers.max"
argument_list|,
literal|999
argument_list|)
block|,
name|PREEXECHOOKS
argument_list|(
literal|"hive.exec.pre.hooks"
argument_list|,
literal|""
argument_list|)
block|,
name|POSTEXECHOOKS
argument_list|(
literal|"hive.exec.post.hooks"
argument_list|,
literal|""
argument_list|)
block|,
name|ONFAILUREHOOKS
argument_list|(
literal|"hive.exec.failure.hooks"
argument_list|,
literal|""
argument_list|)
block|,
name|OPERATORHOOKS
argument_list|(
literal|"hive.exec.operator.hooks"
argument_list|,
literal|""
argument_list|)
block|,
name|CLIENTSTATSPUBLISHERS
argument_list|(
literal|"hive.client.stats.publishers"
argument_list|,
literal|""
argument_list|)
block|,
name|EXECPARALLEL
argument_list|(
literal|"hive.exec.parallel"
argument_list|,
literal|false
argument_list|)
block|,
comment|// parallel query launching
name|EXECPARALLETHREADNUMBER
argument_list|(
literal|"hive.exec.parallel.thread.number"
argument_list|,
literal|8
argument_list|)
block|,
name|HIVESPECULATIVEEXECREDUCERS
argument_list|(
literal|"hive.mapred.reduce.tasks.speculative.execution"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVECOUNTERSPULLINTERVAL
argument_list|(
literal|"hive.exec.counters.pull.interval"
argument_list|,
literal|1000L
argument_list|)
block|,
name|DYNAMICPARTITIONING
argument_list|(
literal|"hive.exec.dynamic.partition"
argument_list|,
literal|true
argument_list|)
block|,
name|DYNAMICPARTITIONINGMODE
argument_list|(
literal|"hive.exec.dynamic.partition.mode"
argument_list|,
literal|"strict"
argument_list|)
block|,
name|DYNAMICPARTITIONMAXPARTS
argument_list|(
literal|"hive.exec.max.dynamic.partitions"
argument_list|,
literal|1000
argument_list|)
block|,
name|DYNAMICPARTITIONMAXPARTSPERNODE
argument_list|(
literal|"hive.exec.max.dynamic.partitions.pernode"
argument_list|,
literal|100
argument_list|)
block|,
name|MAXCREATEDFILES
argument_list|(
literal|"hive.exec.max.created.files"
argument_list|,
literal|100000L
argument_list|)
block|,
name|DOWNLOADED_RESOURCES_DIR
argument_list|(
literal|"hive.downloaded.resources.dir"
argument_list|,
literal|"/tmp/"
operator|+
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
operator|+
literal|"/hive_resources"
argument_list|)
block|,
name|DEFAULTPARTITIONNAME
argument_list|(
literal|"hive.exec.default.partition.name"
argument_list|,
literal|"__HIVE_DEFAULT_PARTITION__"
argument_list|)
block|,
name|DEFAULT_ZOOKEEPER_PARTITION_NAME
argument_list|(
literal|"hive.lockmgr.zookeeper.default.partition.name"
argument_list|,
literal|"__HIVE_DEFAULT_ZOOKEEPER_PARTITION__"
argument_list|)
block|,
comment|// Whether to show a link to the most failed task + debugging tips
name|SHOW_JOB_FAIL_DEBUG_INFO
argument_list|(
literal|"hive.exec.show.job.failure.debug.info"
argument_list|,
literal|true
argument_list|)
block|,
name|JOB_DEBUG_CAPTURE_STACKTRACES
argument_list|(
literal|"hive.exec.job.debug.capture.stacktraces"
argument_list|,
literal|true
argument_list|)
block|,
name|JOB_DEBUG_TIMEOUT
argument_list|(
literal|"hive.exec.job.debug.timeout"
argument_list|,
literal|30000
argument_list|)
block|,
name|TASKLOG_DEBUG_TIMEOUT
argument_list|(
literal|"hive.exec.tasklog.debug.timeout"
argument_list|,
literal|20000
argument_list|)
block|,
name|OUTPUT_FILE_EXTENSION
argument_list|(
literal|"hive.output.file.extension"
argument_list|,
literal|null
argument_list|)
block|,
comment|// should hive determine whether to run in local mode automatically ?
name|LOCALMODEAUTO
argument_list|(
literal|"hive.exec.mode.local.auto"
argument_list|,
literal|false
argument_list|)
block|,
comment|// if yes:
comment|// run in local mode only if input bytes is less than this. 128MB by default
name|LOCALMODEMAXBYTES
argument_list|(
literal|"hive.exec.mode.local.auto.inputbytes.max"
argument_list|,
literal|134217728L
argument_list|)
block|,
comment|// run in local mode only if number of tasks (for map and reduce each) is
comment|// less than this
name|LOCALMODEMAXINPUTFILES
argument_list|(
literal|"hive.exec.mode.local.auto.input.files.max"
argument_list|,
literal|4
argument_list|)
block|,
comment|// if true, DROP TABLE/VIEW does not fail if table/view doesn't exist and IF EXISTS is
comment|// not specified
name|DROPIGNORESNONEXISTENT
argument_list|(
literal|"hive.exec.drop.ignorenonexistent"
argument_list|,
literal|true
argument_list|)
block|,
comment|// Hadoop Configuration Properties
comment|// Properties with null values are ignored and exist only for the purpose of giving us
comment|// a symbolic name to reference in the Hive source code. Properties with non-null
comment|// values will override any values set in the underlying Hadoop configuration.
name|HADOOPBIN
argument_list|(
literal|"hadoop.bin.path"
argument_list|,
name|findHadoopBinary
argument_list|()
argument_list|)
block|,
name|HADOOPFS
argument_list|(
literal|"fs.default.name"
argument_list|,
literal|null
argument_list|)
block|,
name|HIVE_FS_HAR_IMPL
argument_list|(
literal|"fs.har.impl"
argument_list|,
literal|"org.apache.hadoop.hive.shims.HiveHarFileSystem"
argument_list|)
block|,
name|HADOOPMAPFILENAME
argument_list|(
literal|"map.input.file"
argument_list|,
literal|null
argument_list|)
block|,
name|HADOOPMAPREDINPUTDIR
argument_list|(
literal|"mapred.input.dir"
argument_list|,
literal|null
argument_list|)
block|,
name|HADOOPMAPREDINPUTDIRRECURSIVE
argument_list|(
literal|"mapred.input.dir.recursive"
argument_list|,
literal|false
argument_list|)
block|,
name|HADOOPJT
argument_list|(
literal|"mapred.job.tracker"
argument_list|,
literal|null
argument_list|)
block|,
name|MAPREDMAXSPLITSIZE
argument_list|(
literal|"mapred.max.split.size"
argument_list|,
literal|256000000L
argument_list|)
block|,
name|MAPREDMINSPLITSIZE
argument_list|(
literal|"mapred.min.split.size"
argument_list|,
literal|1L
argument_list|)
block|,
name|MAPREDMINSPLITSIZEPERNODE
argument_list|(
literal|"mapred.min.split.size.per.rack"
argument_list|,
literal|1L
argument_list|)
block|,
name|MAPREDMINSPLITSIZEPERRACK
argument_list|(
literal|"mapred.min.split.size.per.node"
argument_list|,
literal|1L
argument_list|)
block|,
comment|// The number of reduce tasks per job. Hadoop sets this value to 1 by default
comment|// By setting this property to -1, Hive will automatically determine the correct
comment|// number of reducers.
name|HADOOPNUMREDUCERS
argument_list|(
literal|"mapred.reduce.tasks"
argument_list|,
operator|-
literal|1
argument_list|)
block|,
name|HADOOPJOBNAME
argument_list|(
literal|"mapred.job.name"
argument_list|,
literal|null
argument_list|)
block|,
name|HADOOPSPECULATIVEEXECREDUCERS
argument_list|(
literal|"mapred.reduce.tasks.speculative.execution"
argument_list|,
literal|true
argument_list|)
block|,
comment|// Metastore stuff. Be sure to update HiveConf.metaVars when you add
comment|// something here!
name|METASTOREDIRECTORY
argument_list|(
literal|"hive.metastore.metadb.dir"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTOREWAREHOUSE
argument_list|(
literal|"hive.metastore.warehouse.dir"
argument_list|,
literal|"/user/hive/warehouse"
argument_list|)
block|,
name|METASTOREURIS
argument_list|(
literal|"hive.metastore.uris"
argument_list|,
literal|""
argument_list|)
block|,
comment|// Number of times to retry a connection to a Thrift metastore server
name|METASTORETHRIFTCONNECTIONRETRIES
argument_list|(
literal|"hive.metastore.connect.retries"
argument_list|,
literal|3
argument_list|)
block|,
comment|// Number of times to retry a Thrift metastore call upon failure
name|METASTORETHRIFTFAILURERETRIES
argument_list|(
literal|"hive.metastore.failure.retries"
argument_list|,
literal|1
argument_list|)
block|,
comment|// Number of seconds the client should wait between connection attempts
name|METASTORE_CLIENT_CONNECT_RETRY_DELAY
argument_list|(
literal|"hive.metastore.client.connect.retry.delay"
argument_list|,
literal|1
argument_list|)
block|,
comment|// Socket timeout for the client connection (in seconds)
name|METASTORE_CLIENT_SOCKET_TIMEOUT
argument_list|(
literal|"hive.metastore.client.socket.timeout"
argument_list|,
literal|20
argument_list|)
block|,
name|METASTOREPWD
argument_list|(
literal|"javax.jdo.option.ConnectionPassword"
argument_list|,
literal|"mine"
argument_list|)
block|,
comment|// Class name of JDO connection url hook
name|METASTORECONNECTURLHOOK
argument_list|(
literal|"hive.metastore.ds.connection.url.hook"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTOREMULTITHREADED
argument_list|(
literal|"javax.jdo.option.Multithreaded"
argument_list|,
literal|true
argument_list|)
block|,
comment|// Name of the connection url in the configuration
name|METASTORECONNECTURLKEY
argument_list|(
literal|"javax.jdo.option.ConnectionURL"
argument_list|,
literal|"jdbc:derby:;databaseName=metastore_db;create=true"
argument_list|)
block|,
comment|// Number of attempts to retry connecting after there is a JDO datastore err
name|METASTOREATTEMPTS
argument_list|(
literal|"hive.metastore.ds.retry.attempts"
argument_list|,
literal|1
argument_list|)
block|,
comment|// Number of miliseconds to wait between attepting
name|METASTOREINTERVAL
argument_list|(
literal|"hive.metastore.ds.retry.interval"
argument_list|,
literal|1000
argument_list|)
block|,
comment|// Whether to force reloading of the metastore configuration (including
comment|// the connection URL, before the next metastore query that accesses the
comment|// datastore. Once reloaded, this value is reset to false. Used for
comment|// testing only.
name|METASTOREFORCERELOADCONF
argument_list|(
literal|"hive.metastore.force.reload.conf"
argument_list|,
literal|false
argument_list|)
block|,
comment|// Number of attempts to retry connecting after there is a JDO datastore err
name|HMSHANDLERATTEMPTS
argument_list|(
literal|"hive.hmshandler.retry.attempts"
argument_list|,
literal|1
argument_list|)
block|,
comment|// Number of miliseconds to wait between attepting
name|HMSHANDLERINTERVAL
argument_list|(
literal|"hive.hmshandler.retry.interval"
argument_list|,
literal|1000
argument_list|)
block|,
comment|// Whether to force reloading of the HMSHandler configuration (including
comment|// the connection URL, before the next metastore query that accesses the
comment|// datastore. Once reloaded, this value is reset to false. Used for
comment|// testing only.
name|HMSHANDLERFORCERELOADCONF
argument_list|(
literal|"hive.hmshandler.force.reload.conf"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORESERVERMINTHREADS
argument_list|(
literal|"hive.metastore.server.min.threads"
argument_list|,
literal|200
argument_list|)
block|,
name|METASTORESERVERMAXTHREADS
argument_list|(
literal|"hive.metastore.server.max.threads"
argument_list|,
literal|100000
argument_list|)
block|,
name|METASTORE_TCP_KEEP_ALIVE
argument_list|(
literal|"hive.metastore.server.tcp.keepalive"
argument_list|,
literal|true
argument_list|)
block|,
comment|// Intermediate dir suffixes used for archiving. Not important what they
comment|// are, as long as collisions are avoided
name|METASTORE_INT_ORIGINAL
argument_list|(
literal|"hive.metastore.archive.intermediate.original"
argument_list|,
literal|"_INTERMEDIATE_ORIGINAL"
argument_list|)
block|,
name|METASTORE_INT_ARCHIVED
argument_list|(
literal|"hive.metastore.archive.intermediate.archived"
argument_list|,
literal|"_INTERMEDIATE_ARCHIVED"
argument_list|)
block|,
name|METASTORE_INT_EXTRACTED
argument_list|(
literal|"hive.metastore.archive.intermediate.extracted"
argument_list|,
literal|"_INTERMEDIATE_EXTRACTED"
argument_list|)
block|,
name|METASTORE_KERBEROS_KEYTAB_FILE
argument_list|(
literal|"hive.metastore.kerberos.keytab.file"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_KERBEROS_PRINCIPAL
argument_list|(
literal|"hive.metastore.kerberos.principal"
argument_list|,
literal|"hive-metastore/_HOST@EXAMPLE.COM"
argument_list|)
block|,
name|METASTORE_USE_THRIFT_SASL
argument_list|(
literal|"hive.metastore.sasl.enabled"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_USE_THRIFT_FRAMED_TRANSPORT
argument_list|(
literal|"hive.metastore.thrift.framed.transport.enabled"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_CLS
argument_list|(
literal|"hive.cluster.delegation.token.store.class"
argument_list|,
literal|"org.apache.hadoop.hive.thrift.MemoryTokenStore"
argument_list|)
block|,
name|METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_CONNECTSTR
argument_list|(
literal|"hive.cluster.delegation.token.store.zookeeper.connectString"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_ZNODE
argument_list|(
literal|"hive.cluster.delegation.token.store.zookeeper.znode"
argument_list|,
literal|"/hive/cluster/delegation"
argument_list|)
block|,
name|METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_ACL
argument_list|(
literal|"hive.cluster.delegation.token.store.zookeeper.acl"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_CACHE_PINOBJTYPES
argument_list|(
literal|"hive.metastore.cache.pinobjtypes"
argument_list|,
literal|"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
argument_list|)
block|,
name|METASTORE_CONNECTION_POOLING_TYPE
argument_list|(
literal|"datanucleus.connectionPoolingType"
argument_list|,
literal|"DBCP"
argument_list|)
block|,
name|METASTORE_VALIDATE_TABLES
argument_list|(
literal|"datanucleus.validateTables"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_VALIDATE_COLUMNS
argument_list|(
literal|"datanucleus.validateColumns"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_VALIDATE_CONSTRAINTS
argument_list|(
literal|"datanucleus.validateConstraints"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_STORE_MANAGER_TYPE
argument_list|(
literal|"datanucleus.storeManagerType"
argument_list|,
literal|"rdbms"
argument_list|)
block|,
name|METASTORE_AUTO_CREATE_SCHEMA
argument_list|(
literal|"datanucleus.autoCreateSchema"
argument_list|,
literal|true
argument_list|)
block|,
name|METASTORE_AUTO_START_MECHANISM_MODE
argument_list|(
literal|"datanucleus.autoStartMechanismMode"
argument_list|,
literal|"checked"
argument_list|)
block|,
name|METASTORE_TRANSACTION_ISOLATION
argument_list|(
literal|"datanucleus.transactionIsolation"
argument_list|,
literal|"read-committed"
argument_list|)
block|,
name|METASTORE_CACHE_LEVEL2
argument_list|(
literal|"datanucleus.cache.level2"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_CACHE_LEVEL2_TYPE
argument_list|(
literal|"datanucleus.cache.level2.type"
argument_list|,
literal|"none"
argument_list|)
block|,
name|METASTORE_IDENTIFIER_FACTORY
argument_list|(
literal|"datanucleus.identifierFactory"
argument_list|,
literal|"datanucleus"
argument_list|)
block|,
name|METASTORE_PLUGIN_REGISTRY_BUNDLE_CHECK
argument_list|(
literal|"datanucleus.plugin.pluginRegistryBundleCheck"
argument_list|,
literal|"LOG"
argument_list|)
block|,
name|METASTORE_BATCH_RETRIEVE_MAX
argument_list|(
literal|"hive.metastore.batch.retrieve.max"
argument_list|,
literal|300
argument_list|)
block|,
name|METASTORE_BATCH_RETRIEVE_TABLE_PARTITION_MAX
argument_list|(
literal|"hive.metastore.batch.retrieve.table.partition.max"
argument_list|,
literal|1000
argument_list|)
block|,
comment|// A comma separated list of hooks which implement MetaStoreInitListener and will be run at
comment|// the beginning of HMSHandler initialization
name|METASTORE_INIT_HOOKS
argument_list|(
literal|"hive.metastore.init.hooks"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_PRE_EVENT_LISTENERS
argument_list|(
literal|"hive.metastore.pre.event.listeners"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_EVENT_LISTENERS
argument_list|(
literal|"hive.metastore.event.listeners"
argument_list|,
literal|""
argument_list|)
block|,
comment|// should we do checks against the storage (usually hdfs) for operations like drop_partition
name|METASTORE_AUTHORIZATION_STORAGE_AUTH_CHECKS
argument_list|(
literal|"hive.metastore.authorization.storage.checks"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_EVENT_CLEAN_FREQ
argument_list|(
literal|"hive.metastore.event.clean.freq"
argument_list|,
literal|0L
argument_list|)
block|,
name|METASTORE_EVENT_EXPIRY_DURATION
argument_list|(
literal|"hive.metastore.event.expiry.duration"
argument_list|,
literal|0L
argument_list|)
block|,
name|METASTORE_EXECUTE_SET_UGI
argument_list|(
literal|"hive.metastore.execute.setugi"
argument_list|,
literal|false
argument_list|)
block|,
name|METASTORE_PARTITION_NAME_WHITELIST_PATTERN
argument_list|(
literal|"hive.metastore.partition.name.whitelist.pattern"
argument_list|,
literal|""
argument_list|)
block|,
comment|// Default parameters for creating tables
name|NEWTABLEDEFAULTPARA
argument_list|(
literal|"hive.table.parameters.default"
argument_list|,
literal|""
argument_list|)
block|,
comment|// Parameters to copy over when creating a table with Create Table Like.
name|DDL_CTL_PARAMETERS_WHITELIST
argument_list|(
literal|"hive.ddl.createtablelike.properties.whitelist"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_RAW_STORE_IMPL
argument_list|(
literal|"hive.metastore.rawstore.impl"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.ObjectStore"
argument_list|)
block|,
name|METASTORE_CONNECTION_DRIVER
argument_list|(
literal|"javax.jdo.option.ConnectionDriverName"
argument_list|,
literal|"org.apache.derby.jdbc.EmbeddedDriver"
argument_list|)
block|,
name|METASTORE_MANAGER_FACTORY_CLASS
argument_list|(
literal|"javax.jdo.PersistenceManagerFactoryClass"
argument_list|,
literal|"org.datanucleus.jdo.JDOPersistenceManagerFactory"
argument_list|)
block|,
name|METASTORE_DETACH_ALL_ON_COMMIT
argument_list|(
literal|"javax.jdo.option.DetachAllOnCommit"
argument_list|,
literal|true
argument_list|)
block|,
name|METASTORE_NON_TRANSACTIONAL_READ
argument_list|(
literal|"javax.jdo.option.NonTransactionalRead"
argument_list|,
literal|true
argument_list|)
block|,
name|METASTORE_CONNECTION_USER_NAME
argument_list|(
literal|"javax.jdo.option.ConnectionUserName"
argument_list|,
literal|"APP"
argument_list|)
block|,
name|METASTORE_END_FUNCTION_LISTENERS
argument_list|(
literal|"hive.metastore.end.function.listeners"
argument_list|,
literal|""
argument_list|)
block|,
name|METASTORE_PART_INHERIT_TBL_PROPS
argument_list|(
literal|"hive.metastore.partition.inherit.table.properties"
argument_list|,
literal|""
argument_list|)
block|,
comment|// Parameters for exporting metadata on table drop (requires the use of the)
comment|// org.apache.hadoop.hive.ql.parse.MetaDataExportListener preevent listener
name|METADATA_EXPORT_LOCATION
argument_list|(
literal|"hive.metadata.export.location"
argument_list|,
literal|""
argument_list|)
block|,
name|MOVE_EXPORTED_METADATA_TO_TRASH
argument_list|(
literal|"hive.metadata.move.exported.metadata.to.trash"
argument_list|,
literal|true
argument_list|)
block|,
comment|// CLI
name|CLIIGNOREERRORS
argument_list|(
literal|"hive.cli.errors.ignore"
argument_list|,
literal|false
argument_list|)
block|,
name|CLIPRINTCURRENTDB
argument_list|(
literal|"hive.cli.print.current.db"
argument_list|,
literal|false
argument_list|)
block|,
name|CLIPROMPT
argument_list|(
literal|"hive.cli.prompt"
argument_list|,
literal|"hive"
argument_list|)
block|,
name|CLIPRETTYOUTPUTNUMCOLS
argument_list|(
literal|"hive.cli.pretty.output.num.cols"
argument_list|,
operator|-
literal|1
argument_list|)
block|,
name|HIVE_METASTORE_FS_HANDLER_CLS
argument_list|(
literal|"hive.metastore.fs.handler.class"
argument_list|,
literal|"org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl"
argument_list|)
block|,
comment|// Things we log in the jobconf
comment|// session identifier
name|HIVESESSIONID
argument_list|(
literal|"hive.session.id"
argument_list|,
literal|""
argument_list|)
block|,
comment|// whether session is running in silent mode or not
name|HIVESESSIONSILENT
argument_list|(
literal|"hive.session.silent"
argument_list|,
literal|false
argument_list|)
block|,
comment|// query being executed (multiple per session)
name|HIVEQUERYSTRING
argument_list|(
literal|"hive.query.string"
argument_list|,
literal|""
argument_list|)
block|,
comment|// id of query being executed (multiple per session)
name|HIVEQUERYID
argument_list|(
literal|"hive.query.id"
argument_list|,
literal|""
argument_list|)
block|,
comment|// id of the mapred plan being executed (multiple per query)
name|HIVEPLANID
argument_list|(
literal|"hive.query.planid"
argument_list|,
literal|""
argument_list|)
block|,
comment|// max jobname length
name|HIVEJOBNAMELENGTH
argument_list|(
literal|"hive.jobname.length"
argument_list|,
literal|50
argument_list|)
block|,
comment|// hive jar
name|HIVEJAR
argument_list|(
literal|"hive.jar.path"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVEAUXJARS
argument_list|(
literal|"hive.aux.jars.path"
argument_list|,
literal|""
argument_list|)
block|,
comment|// hive added files and jars
name|HIVEADDEDFILES
argument_list|(
literal|"hive.added.files.path"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVEADDEDJARS
argument_list|(
literal|"hive.added.jars.path"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVEADDEDARCHIVES
argument_list|(
literal|"hive.added.archives.path"
argument_list|,
literal|""
argument_list|)
block|,
comment|// for hive script operator
name|HIVES_AUTO_PROGRESS_TIMEOUT
argument_list|(
literal|"hive.auto.progress.timeout"
argument_list|,
literal|0
argument_list|)
block|,
name|HIVETABLENAME
argument_list|(
literal|"hive.table.name"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVEPARTITIONNAME
argument_list|(
literal|"hive.partition.name"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVESCRIPTAUTOPROGRESS
argument_list|(
literal|"hive.script.auto.progress"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVESCRIPTIDENVVAR
argument_list|(
literal|"hive.script.operator.id.env.var"
argument_list|,
literal|"HIVE_SCRIPT_OPERATOR_ID"
argument_list|)
block|,
name|HIVESCRIPTTRUNCATEENV
argument_list|(
literal|"hive.script.operator.truncate.env"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEMAPREDMODE
argument_list|(
literal|"hive.mapred.mode"
argument_list|,
literal|"nonstrict"
argument_list|)
block|,
name|HIVEALIAS
argument_list|(
literal|"hive.alias"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVEMAPSIDEAGGREGATE
argument_list|(
literal|"hive.map.aggr"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEGROUPBYSKEW
argument_list|(
literal|"hive.groupby.skewindata"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_OPTIMIZE_MULTI_GROUPBY_COMMON_DISTINCTS
argument_list|(
literal|"hive.optimize.multigroupby.common.distincts"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEJOINEMITINTERVAL
argument_list|(
literal|"hive.join.emit.interval"
argument_list|,
literal|1000
argument_list|)
block|,
name|HIVEJOINCACHESIZE
argument_list|(
literal|"hive.join.cache.size"
argument_list|,
literal|25000
argument_list|)
block|,
name|HIVEMAPJOINBUCKETCACHESIZE
argument_list|(
literal|"hive.mapjoin.bucket.cache.size"
argument_list|,
literal|100
argument_list|)
block|,
name|HIVEMAPJOINROWSIZE
argument_list|(
literal|"hive.mapjoin.size.key"
argument_list|,
literal|10000
argument_list|)
block|,
name|HIVEMAPJOINCACHEROWS
argument_list|(
literal|"hive.mapjoin.cache.numrows"
argument_list|,
literal|25000
argument_list|)
block|,
name|HIVEGROUPBYMAPINTERVAL
argument_list|(
literal|"hive.groupby.mapaggr.checkinterval"
argument_list|,
literal|100000
argument_list|)
block|,
name|HIVEMAPAGGRHASHMEMORY
argument_list|(
literal|"hive.map.aggr.hash.percentmemory"
argument_list|,
operator|(
name|float
operator|)
literal|0.5
argument_list|)
block|,
name|HIVEMAPJOINFOLLOWEDBYMAPAGGRHASHMEMORY
argument_list|(
literal|"hive.mapjoin.followby.map.aggr.hash.percentmemory"
argument_list|,
operator|(
name|float
operator|)
literal|0.3
argument_list|)
block|,
name|HIVEMAPAGGRMEMORYTHRESHOLD
argument_list|(
literal|"hive.map.aggr.hash.force.flush.memory.threshold"
argument_list|,
operator|(
name|float
operator|)
literal|0.9
argument_list|)
block|,
name|HIVEMAPAGGRHASHMINREDUCTION
argument_list|(
literal|"hive.map.aggr.hash.min.reduction"
argument_list|,
operator|(
name|float
operator|)
literal|0.5
argument_list|)
block|,
name|HIVEMULTIGROUPBYSINGLEREDUCER
argument_list|(
literal|"hive.multigroupby.singlereducer"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVE_MAP_GROUPBY_SORT
argument_list|(
literal|"hive.map.groupby.sorted"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_GROUPBY_ORDERBY_POSITION_ALIAS
argument_list|(
literal|"hive.groupby.orderby.position.alias"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_NEW_JOB_GROUPING_SET_CARDINALITY
argument_list|(
literal|"hive.new.job.grouping.set.cardinality"
argument_list|,
literal|30
argument_list|)
block|,
comment|// for hive udtf operator
name|HIVEUDTFAUTOPROGRESS
argument_list|(
literal|"hive.udtf.auto.progress"
argument_list|,
literal|false
argument_list|)
block|,
comment|// Default file format for CREATE TABLE statement
comment|// Options: TextFile, SequenceFile
name|HIVEDEFAULTFILEFORMAT
argument_list|(
literal|"hive.default.fileformat"
argument_list|,
literal|"TextFile"
argument_list|)
block|,
name|HIVEQUERYRESULTFILEFORMAT
argument_list|(
literal|"hive.query.result.fileformat"
argument_list|,
literal|"TextFile"
argument_list|)
block|,
name|HIVECHECKFILEFORMAT
argument_list|(
literal|"hive.fileformat.check"
argument_list|,
literal|true
argument_list|)
block|,
comment|//Location of Hive run time structured log file
name|HIVEHISTORYFILELOC
argument_list|(
literal|"hive.querylog.location"
argument_list|,
literal|"/tmp/"
operator|+
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|)
block|,
comment|// Whether to log the plan's progress every time a job's progress is checked
name|HIVE_LOG_INCREMENTAL_PLAN_PROGRESS
argument_list|(
literal|"hive.querylog.enable.plan.progress"
argument_list|,
literal|true
argument_list|)
block|,
comment|// The interval between logging the plan's progress in milliseconds
name|HIVE_LOG_INCREMENTAL_PLAN_PROGRESS_INTERVAL
argument_list|(
literal|"hive.querylog.plan.progress.interval"
argument_list|,
literal|60000L
argument_list|)
block|,
comment|// Default serde and record reader for user scripts
name|HIVESCRIPTSERDE
argument_list|(
literal|"hive.script.serde"
argument_list|,
literal|"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"
argument_list|)
block|,
name|HIVESCRIPTRECORDREADER
argument_list|(
literal|"hive.script.recordreader"
argument_list|,
literal|"org.apache.hadoop.hive.ql.exec.TextRecordReader"
argument_list|)
block|,
name|HIVESCRIPTRECORDWRITER
argument_list|(
literal|"hive.script.recordwriter"
argument_list|,
literal|"org.apache.hadoop.hive.ql.exec.TextRecordWriter"
argument_list|)
block|,
name|HIVESCRIPTESCAPE
argument_list|(
literal|"hive.transform.escape.input"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEBINARYRECORDMAX
argument_list|(
literal|"hive.binary.record.max.length"
argument_list|,
literal|1000
argument_list|)
block|,
comment|// HWI
name|HIVEHWILISTENHOST
argument_list|(
literal|"hive.hwi.listen.host"
argument_list|,
literal|"0.0.0.0"
argument_list|)
block|,
name|HIVEHWILISTENPORT
argument_list|(
literal|"hive.hwi.listen.port"
argument_list|,
literal|"9999"
argument_list|)
block|,
name|HIVEHWIWARFILE
argument_list|(
literal|"hive.hwi.war.file"
argument_list|,
name|System
operator|.
name|getenv
argument_list|(
literal|"HWI_WAR_FILE"
argument_list|)
argument_list|)
block|,
comment|// mapper/reducer memory in local mode
name|HIVEHADOOPMAXMEM
argument_list|(
literal|"hive.mapred.local.mem"
argument_list|,
literal|0
argument_list|)
block|,
comment|//small table file size
name|HIVESMALLTABLESFILESIZE
argument_list|(
literal|"hive.mapjoin.smalltable.filesize"
argument_list|,
literal|25000000L
argument_list|)
block|,
comment|//25M
comment|// random number for split sampling
name|HIVESAMPLERANDOMNUM
argument_list|(
literal|"hive.sample.seednumber"
argument_list|,
literal|0
argument_list|)
block|,
comment|// test mode in hive mode
name|HIVETESTMODE
argument_list|(
literal|"hive.test.mode"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVETESTMODEPREFIX
argument_list|(
literal|"hive.test.mode.prefix"
argument_list|,
literal|"test_"
argument_list|)
block|,
name|HIVETESTMODESAMPLEFREQ
argument_list|(
literal|"hive.test.mode.samplefreq"
argument_list|,
literal|32
argument_list|)
block|,
name|HIVETESTMODENOSAMPLE
argument_list|(
literal|"hive.test.mode.nosamplelist"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVEMERGEMAPFILES
argument_list|(
literal|"hive.merge.mapfiles"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEMERGEMAPREDFILES
argument_list|(
literal|"hive.merge.mapredfiles"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEMERGEMAPFILESSIZE
argument_list|(
literal|"hive.merge.size.per.task"
argument_list|,
call|(
name|long
call|)
argument_list|(
literal|256
operator|*
literal|1000
operator|*
literal|1000
argument_list|)
argument_list|)
block|,
name|HIVEMERGEMAPFILESAVGSIZE
argument_list|(
literal|"hive.merge.smallfiles.avgsize"
argument_list|,
call|(
name|long
call|)
argument_list|(
literal|16
operator|*
literal|1000
operator|*
literal|1000
argument_list|)
argument_list|)
block|,
name|HIVEMERGERCFILEBLOCKLEVEL
argument_list|(
literal|"hive.merge.rcfile.block.level"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEMERGEINPUTFORMATBLOCKLEVEL
argument_list|(
literal|"hive.merge.input.format.block.level"
argument_list|,
literal|"org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeInputFormat"
argument_list|)
block|,
name|HIVEMERGECURRENTJOBHASDYNAMICPARTITIONS
argument_list|(
literal|"hive.merge.current.job.has.dynamic.partitions"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEUSEEXPLICITRCFILEHEADER
argument_list|(
literal|"hive.exec.rcfile.use.explicit.header"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVESKEWJOIN
argument_list|(
literal|"hive.optimize.skewjoin"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVECONVERTJOIN
argument_list|(
literal|"hive.auto.convert.join"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVECONVERTJOINNOCONDITIONALTASK
argument_list|(
literal|"hive.auto.convert.join.noconditionaltask"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD
argument_list|(
literal|"hive.auto.convert.join.noconditionaltask.size"
argument_list|,
literal|10000000L
argument_list|)
block|,
name|HIVESKEWJOINKEY
argument_list|(
literal|"hive.skewjoin.key"
argument_list|,
literal|100000
argument_list|)
block|,
name|HIVESKEWJOINMAPJOINNUMMAPTASK
argument_list|(
literal|"hive.skewjoin.mapjoin.map.tasks"
argument_list|,
literal|10000
argument_list|)
block|,
name|HIVESKEWJOINMAPJOINMINSPLIT
argument_list|(
literal|"hive.skewjoin.mapjoin.min.split"
argument_list|,
literal|33554432L
argument_list|)
block|,
comment|//32M
name|HIVESENDHEARTBEAT
argument_list|(
literal|"hive.heartbeat.interval"
argument_list|,
literal|1000
argument_list|)
block|,
name|HIVELIMITMAXROWSIZE
argument_list|(
literal|"hive.limit.row.max.size"
argument_list|,
literal|100000L
argument_list|)
block|,
name|HIVELIMITOPTLIMITFILE
argument_list|(
literal|"hive.limit.optimize.limit.file"
argument_list|,
literal|10
argument_list|)
block|,
name|HIVELIMITOPTENABLE
argument_list|(
literal|"hive.limit.optimize.enable"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVELIMITOPTMAXFETCH
argument_list|(
literal|"hive.limit.optimize.fetch.max"
argument_list|,
literal|50000
argument_list|)
block|,
name|HIVEHASHTABLETHRESHOLD
argument_list|(
literal|"hive.hashtable.initialCapacity"
argument_list|,
literal|100000
argument_list|)
block|,
name|HIVEHASHTABLELOADFACTOR
argument_list|(
literal|"hive.hashtable.loadfactor"
argument_list|,
operator|(
name|float
operator|)
literal|0.75
argument_list|)
block|,
name|HIVEHASHTABLEFOLLOWBYGBYMAXMEMORYUSAGE
argument_list|(
literal|"hive.mapjoin.followby.gby.localtask.max.memory.usage"
argument_list|,
operator|(
name|float
operator|)
literal|0.55
argument_list|)
block|,
name|HIVEHASHTABLEMAXMEMORYUSAGE
argument_list|(
literal|"hive.mapjoin.localtask.max.memory.usage"
argument_list|,
operator|(
name|float
operator|)
literal|0.90
argument_list|)
block|,
name|HIVEHASHTABLESCALE
argument_list|(
literal|"hive.mapjoin.check.memory.rows"
argument_list|,
operator|(
name|long
operator|)
literal|100000
argument_list|)
block|,
name|HIVEDEBUGLOCALTASK
argument_list|(
literal|"hive.debug.localtask"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEJOBPROGRESS
argument_list|(
literal|"hive.task.progress"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEINPUTFORMAT
argument_list|(
literal|"hive.input.format"
argument_list|,
literal|"org.apache.hadoop.hive.ql.io.CombineHiveInputFormat"
argument_list|)
block|,
name|HIVEENFORCEBUCKETING
argument_list|(
literal|"hive.enforce.bucketing"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEENFORCESORTING
argument_list|(
literal|"hive.enforce.sorting"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEPARTITIONER
argument_list|(
literal|"hive.mapred.partitioner"
argument_list|,
literal|"org.apache.hadoop.hive.ql.io.DefaultHivePartitioner"
argument_list|)
block|,
name|HIVEENFORCESORTMERGEBUCKETMAPJOIN
argument_list|(
literal|"hive.enforce.sortmergebucketmapjoin"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEENFORCEBUCKETMAPJOIN
argument_list|(
literal|"hive.enforce.bucketmapjoin"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVESCRIPTOPERATORTRUST
argument_list|(
literal|"hive.exec.script.trust"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEROWOFFSET
argument_list|(
literal|"hive.exec.rowoffset"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_COMBINE_INPUT_FORMAT_SUPPORTS_SPLITTABLE
argument_list|(
literal|"hive.hadoop.supports.splittable.combineinputformat"
argument_list|,
literal|false
argument_list|)
block|,
comment|// Optimizer
name|HIVEOPTCP
argument_list|(
literal|"hive.optimize.cp"
argument_list|,
literal|true
argument_list|)
block|,
comment|// column pruner
name|HIVEOPTINDEXFILTER
argument_list|(
literal|"hive.optimize.index.filter"
argument_list|,
literal|false
argument_list|)
block|,
comment|// automatically use indexes
name|HIVEINDEXAUTOUPDATE
argument_list|(
literal|"hive.optimize.index.autoupdate"
argument_list|,
literal|false
argument_list|)
block|,
comment|//automatically update stale indexes
name|HIVEOPTPPD
argument_list|(
literal|"hive.optimize.ppd"
argument_list|,
literal|true
argument_list|)
block|,
comment|// predicate pushdown
name|HIVEPPDRECOGNIZETRANSITIVITY
argument_list|(
literal|"hive.ppd.recognizetransivity"
argument_list|,
literal|true
argument_list|)
block|,
comment|// predicate pushdown
name|HIVEPPDREMOVEDUPLICATEFILTERS
argument_list|(
literal|"hive.ppd.remove.duplicatefilters"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEMETADATAONLYQUERIES
argument_list|(
literal|"hive.optimize.metadataonly"
argument_list|,
literal|true
argument_list|)
block|,
comment|// push predicates down to storage handlers
name|HIVEOPTPPD_STORAGE
argument_list|(
literal|"hive.optimize.ppd.storage"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEOPTGROUPBY
argument_list|(
literal|"hive.optimize.groupby"
argument_list|,
literal|true
argument_list|)
block|,
comment|// optimize group by
name|HIVEOPTBUCKETMAPJOIN
argument_list|(
literal|"hive.optimize.bucketmapjoin"
argument_list|,
literal|false
argument_list|)
block|,
comment|// optimize bucket map join
name|HIVEOPTSORTMERGEBUCKETMAPJOIN
argument_list|(
literal|"hive.optimize.bucketmapjoin.sortedmerge"
argument_list|,
literal|false
argument_list|)
block|,
comment|// try to use sorted merge bucket map join
name|HIVEOPTREDUCEDEDUPLICATION
argument_list|(
literal|"hive.optimize.reducededuplication"
argument_list|,
literal|true
argument_list|)
block|,
comment|// whether to optimize union followed by select followed by filesink
comment|// It creates sub-directories in the final output, so should not be turned on in systems
comment|// where MAPREDUCE-1501 is not present
name|HIVE_OPTIMIZE_UNION_REMOVE
argument_list|(
literal|"hive.optimize.union.remove"
argument_list|,
literal|false
argument_list|)
block|,
comment|// whether hadoop map-reduce supports sub-directories. It was added by MAPREDUCE-1501.
comment|// Some optimizations can only be performed if the version of hadoop being used supports
comment|// sub-directories
name|HIVE_HADOOP_SUPPORTS_SUBDIRECTORIES
argument_list|(
literal|"hive.mapred.supports.subdirectories"
argument_list|,
literal|false
argument_list|)
block|,
comment|// optimize skewed join by changing the query plan at compile time
name|HIVE_OPTIMIZE_SKEWJOIN_COMPILETIME
argument_list|(
literal|"hive.optimize.skewjoin.compiletime"
argument_list|,
literal|false
argument_list|)
block|,
comment|// Indexes
name|HIVEOPTINDEXFILTER_COMPACT_MINSIZE
argument_list|(
literal|"hive.optimize.index.filter.compact.minsize"
argument_list|,
operator|(
name|long
operator|)
literal|5
operator|*
literal|1024
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
block|,
comment|// 5G
name|HIVEOPTINDEXFILTER_COMPACT_MAXSIZE
argument_list|(
literal|"hive.optimize.index.filter.compact.maxsize"
argument_list|,
operator|(
name|long
operator|)
operator|-
literal|1
argument_list|)
block|,
comment|// infinity
name|HIVE_INDEX_COMPACT_QUERY_MAX_ENTRIES
argument_list|(
literal|"hive.index.compact.query.max.entries"
argument_list|,
operator|(
name|long
operator|)
literal|10000000
argument_list|)
block|,
comment|// 10M
name|HIVE_INDEX_COMPACT_QUERY_MAX_SIZE
argument_list|(
literal|"hive.index.compact.query.max.size"
argument_list|,
operator|(
name|long
operator|)
literal|10
operator|*
literal|1024
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
block|,
comment|// 10G
name|HIVE_INDEX_COMPACT_BINARY_SEARCH
argument_list|(
literal|"hive.index.compact.binary.search"
argument_list|,
literal|true
argument_list|)
block|,
comment|// Statistics
name|HIVESTATSAUTOGATHER
argument_list|(
literal|"hive.stats.autogather"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVESTATSDBCLASS
argument_list|(
literal|"hive.stats.dbclass"
argument_list|,
literal|"jdbc:derby"
argument_list|)
block|,
comment|// other options are jdbc:mysql and hbase as defined in StatsSetupConst.java
name|HIVESTATSJDBCDRIVER
argument_list|(
literal|"hive.stats.jdbcdriver"
argument_list|,
literal|"org.apache.derby.jdbc.EmbeddedDriver"
argument_list|)
block|,
comment|// JDBC driver specific to the dbclass
name|HIVESTATSDBCONNECTIONSTRING
argument_list|(
literal|"hive.stats.dbconnectionstring"
argument_list|,
literal|"jdbc:derby:;databaseName=TempStatsStore;create=true"
argument_list|)
block|,
comment|// automatically create database
name|HIVE_STATS_DEFAULT_PUBLISHER
argument_list|(
literal|"hive.stats.default.publisher"
argument_list|,
literal|""
argument_list|)
block|,
comment|// default stats publisher if none of JDBC/HBase is specified
name|HIVE_STATS_DEFAULT_AGGREGATOR
argument_list|(
literal|"hive.stats.default.aggregator"
argument_list|,
literal|""
argument_list|)
block|,
comment|// default stats aggregator if none of JDBC/HBase is specified
name|HIVE_STATS_JDBC_TIMEOUT
argument_list|(
literal|"hive.stats.jdbc.timeout"
argument_list|,
literal|30
argument_list|)
block|,
comment|// default timeout in sec for JDBC connection& SQL statements
name|HIVE_STATS_ATOMIC
argument_list|(
literal|"hive.stats.atomic"
argument_list|,
literal|false
argument_list|)
block|,
comment|// whether to update metastore stats only if all stats are available
name|HIVE_STATS_RETRIES_MAX
argument_list|(
literal|"hive.stats.retries.max"
argument_list|,
literal|0
argument_list|)
block|,
comment|// maximum # of retries to insert/select/delete the stats DB
name|HIVE_STATS_RETRIES_WAIT
argument_list|(
literal|"hive.stats.retries.wait"
argument_list|,
literal|3000
argument_list|)
block|,
comment|// # milliseconds to wait before the next retry
name|HIVE_STATS_COLLECT_RAWDATASIZE
argument_list|(
literal|"hive.stats.collect.rawdatasize"
argument_list|,
literal|true
argument_list|)
block|,
comment|// should the raw data size be collected when analyzing tables
name|CLIENT_STATS_COUNTERS
argument_list|(
literal|"hive.client.stats.counters"
argument_list|,
literal|""
argument_list|)
block|,
comment|//Subset of counters that should be of interest for hive.client.stats.publishers (when one wants to limit their publishing). Non-display names should be used".
name|HIVE_STATS_RELIABLE
argument_list|(
literal|"hive.stats.reliable"
argument_list|,
literal|false
argument_list|)
block|,
comment|// Collect table access keys information for operators that can benefit from bucketing
name|HIVE_STATS_COLLECT_TABLEKEYS
argument_list|(
literal|"hive.stats.collect.tablekeys"
argument_list|,
literal|false
argument_list|)
block|,
comment|// standard error allowed for ndv estimates. A lower value indicates higher accuracy and a
comment|// higher compute cost.
name|HIVE_STATS_NDV_ERROR
argument_list|(
literal|"hive.stats.ndv.error"
argument_list|,
operator|(
name|float
operator|)
literal|20.0
argument_list|)
block|,
name|HIVE_STATS_KEY_PREFIX_MAX_LENGTH
argument_list|(
literal|"hive.stats.key.prefix.max.length"
argument_list|,
literal|200
argument_list|)
block|,
comment|// Concurrency
name|HIVE_SUPPORT_CONCURRENCY
argument_list|(
literal|"hive.support.concurrency"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_LOCK_MANAGER
argument_list|(
literal|"hive.lock.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager"
argument_list|)
block|,
name|HIVE_LOCK_NUMRETRIES
argument_list|(
literal|"hive.lock.numretries"
argument_list|,
literal|100
argument_list|)
block|,
name|HIVE_UNLOCK_NUMRETRIES
argument_list|(
literal|"hive.unlock.numretries"
argument_list|,
literal|10
argument_list|)
block|,
name|HIVE_LOCK_SLEEP_BETWEEN_RETRIES
argument_list|(
literal|"hive.lock.sleep.between.retries"
argument_list|,
literal|60
argument_list|)
block|,
name|HIVE_LOCK_MAPRED_ONLY
argument_list|(
literal|"hive.lock.mapred.only.operation"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_ZOOKEEPER_QUORUM
argument_list|(
literal|"hive.zookeeper.quorum"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_ZOOKEEPER_CLIENT_PORT
argument_list|(
literal|"hive.zookeeper.client.port"
argument_list|,
literal|"2181"
argument_list|)
block|,
name|HIVE_ZOOKEEPER_SESSION_TIMEOUT
argument_list|(
literal|"hive.zookeeper.session.timeout"
argument_list|,
literal|600
operator|*
literal|1000
argument_list|)
block|,
name|HIVE_ZOOKEEPER_NAMESPACE
argument_list|(
literal|"hive.zookeeper.namespace"
argument_list|,
literal|"hive_zookeeper_namespace"
argument_list|)
block|,
name|HIVE_ZOOKEEPER_CLEAN_EXTRA_NODES
argument_list|(
literal|"hive.zookeeper.clean.extra.nodes"
argument_list|,
literal|false
argument_list|)
block|,
comment|// For HBase storage handler
name|HIVE_HBASE_WAL_ENABLED
argument_list|(
literal|"hive.hbase.wal.enabled"
argument_list|,
literal|true
argument_list|)
block|,
comment|// For har files
name|HIVEARCHIVEENABLED
argument_list|(
literal|"hive.archive.enabled"
argument_list|,
literal|false
argument_list|)
block|,
comment|//Enable/Disable gbToIdx rewrite rule
name|HIVEOPTGBYUSINGINDEX
argument_list|(
literal|"hive.optimize.index.groupby"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVEOUTERJOINSUPPORTSFILTERS
argument_list|(
literal|"hive.outerjoin.supports.filters"
argument_list|,
literal|true
argument_list|)
block|,
comment|// 'minimal', 'more' (and 'all' later)
name|HIVEFETCHTASKCONVERSION
argument_list|(
literal|"hive.fetch.task.conversion"
argument_list|,
literal|"minimal"
argument_list|)
block|,
comment|// Serde for FetchTask
name|HIVEFETCHOUTPUTSERDE
argument_list|(
literal|"hive.fetch.output.serde"
argument_list|,
literal|"org.apache.hadoop.hive.serde2.DelimitedJSONSerDe"
argument_list|)
block|,
comment|// Hive Variables
name|HIVEVARIABLESUBSTITUTE
argument_list|(
literal|"hive.variable.substitute"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVEVARIABLESUBSTITUTEDEPTH
argument_list|(
literal|"hive.variable.substitute.depth"
argument_list|,
literal|40
argument_list|)
block|,
name|HIVECONFVALIDATION
argument_list|(
literal|"hive.conf.validation"
argument_list|,
literal|true
argument_list|)
block|,
name|SEMANTIC_ANALYZER_HOOK
argument_list|(
literal|"hive.semantic.analyzer.hook"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_AUTHORIZATION_ENABLED
argument_list|(
literal|"hive.security.authorization.enabled"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_AUTHORIZATION_MANAGER
argument_list|(
literal|"hive.security.authorization.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider"
argument_list|)
block|,
name|HIVE_AUTHENTICATOR_MANAGER
argument_list|(
literal|"hive.security.authenticator.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator"
argument_list|)
block|,
name|HIVE_METASTORE_AUTHORIZATION_MANAGER
argument_list|(
literal|"hive.security.metastore.authorization.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.authorization."
operator|+
literal|"DefaultHiveMetastoreAuthorizationProvider"
argument_list|)
block|,
name|HIVE_METASTORE_AUTHENTICATOR_MANAGER
argument_list|(
literal|"hive.security.metastore.authenticator.manager"
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator"
argument_list|)
block|,
name|HIVE_AUTHORIZATION_TABLE_USER_GRANTS
argument_list|(
literal|"hive.security.authorization.createtable.user.grants"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_AUTHORIZATION_TABLE_GROUP_GRANTS
argument_list|(
literal|"hive.security.authorization.createtable.group.grants"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_AUTHORIZATION_TABLE_ROLE_GRANTS
argument_list|(
literal|"hive.security.authorization.createtable.role.grants"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_AUTHORIZATION_TABLE_OWNER_GRANTS
argument_list|(
literal|"hive.security.authorization.createtable.owner.grants"
argument_list|,
literal|""
argument_list|)
block|,
comment|// Print column names in output
name|HIVE_CLI_PRINT_HEADER
argument_list|(
literal|"hive.cli.print.header"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_ERROR_ON_EMPTY_PARTITION
argument_list|(
literal|"hive.error.on.empty.partition"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_INDEX_IGNORE_HDFS_LOC
argument_list|(
literal|"hive.index.compact.file.ignore.hdfs"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_EXIM_URI_SCHEME_WL
argument_list|(
literal|"hive.exim.uri.scheme.whitelist"
argument_list|,
literal|"hdfs,pfile"
argument_list|)
block|,
comment|// temporary variable for testing. This is added just to turn off this feature in case of a bug in
comment|// deployment. It has not been documented in hive-default.xml intentionally, this should be removed
comment|// once the feature is stable
name|HIVE_MAPPER_CANNOT_SPAN_MULTIPLE_PARTITIONS
argument_list|(
literal|"hive.mapper.cannot.span.multiple.partitions"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_REWORK_MAPREDWORK
argument_list|(
literal|"hive.rework.mapredwork"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_CONCATENATE_CHECK_INDEX
argument_list|(
literal|"hive.exec.concatenate.check.index"
argument_list|,
literal|true
argument_list|)
block|,
name|HIVE_IO_EXCEPTION_HANDLERS
argument_list|(
literal|"hive.io.exception.handlers"
argument_list|,
literal|""
argument_list|)
block|,
comment|// logging configuration
name|HIVE_LOG4J_FILE
argument_list|(
literal|"hive.log4j.file"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_EXEC_LOG4J_FILE
argument_list|(
literal|"hive.exec.log4j.file"
argument_list|,
literal|""
argument_list|)
block|,
comment|// prefix used to auto generated column aliases (this should be started with '_')
name|HIVE_AUTOGEN_COLUMNALIAS_PREFIX_LABEL
argument_list|(
literal|"hive.autogen.columnalias.prefix.label"
argument_list|,
literal|"_c"
argument_list|)
block|,
name|HIVE_AUTOGEN_COLUMNALIAS_PREFIX_INCLUDEFUNCNAME
argument_list|(
literal|"hive.autogen.columnalias.prefix.includefuncname"
argument_list|,
literal|false
argument_list|)
block|,
comment|// The class responsible for logging client side performance metrics
comment|// Must be a subclass of org.apache.hadoop.hive.ql.log.PerfLogger
name|HIVE_PERF_LOGGER
argument_list|(
literal|"hive.exec.perf.logger"
argument_list|,
literal|"org.apache.hadoop.hive.ql.log.PerfLogger"
argument_list|)
block|,
comment|// Whether to delete the scratchdir while startup
name|HIVE_START_CLEANUP_SCRATCHDIR
argument_list|(
literal|"hive.start.cleanup.scratchdir"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_INSERT_INTO_MULTILEVEL_DIRS
argument_list|(
literal|"hive.insert.into.multilevel.dirs"
argument_list|,
literal|false
argument_list|)
block|,
name|HIVE_WAREHOUSE_SUBDIR_INHERIT_PERMS
argument_list|(
literal|"hive.warehouse.subdir.inherit.perms"
argument_list|,
literal|false
argument_list|)
block|,
comment|// whether insert into external tables is allowed
name|HIVE_INSERT_INTO_EXTERNAL_TABLES
argument_list|(
literal|"hive.insert.into.external.tables"
argument_list|,
literal|true
argument_list|)
block|,
comment|// A comma separated list of hooks which implement HiveDriverRunHook and will be run at the
comment|// beginning and end of Driver.run, these will be run in the order specified
name|HIVE_DRIVER_RUN_HOOKS
argument_list|(
literal|"hive.exec.driver.run.hooks"
argument_list|,
literal|""
argument_list|)
block|,
name|HIVE_DDL_OUTPUT_FORMAT
argument_list|(
literal|"hive.ddl.output.format"
argument_list|,
literal|null
argument_list|)
block|,
name|HIVE_ENTITY_SEPARATOR
argument_list|(
literal|"hive.entity.separator"
argument_list|,
literal|"@"
argument_list|)
block|,
comment|// If this is set all move tasks at the end of a multi-insert query will only begin once all
comment|// outputs are ready
name|HIVE_MULTI_INSERT_MOVE_TASKS_SHARE_DEPENDENCIES
argument_list|(
literal|"hive.multi.insert.move.tasks.share.dependencies"
argument_list|,
literal|false
argument_list|)
block|,
comment|// If this is set, when writing partitions, the metadata will include the bucketing/sorting
comment|// properties with which the data was written if any (this will not overwrite the metadata
comment|// inherited from the table if the table is bucketed/sorted)
name|HIVE_INFER_BUCKET_SORT
argument_list|(
literal|"hive.exec.infer.bucket.sort"
argument_list|,
literal|false
argument_list|)
block|,
comment|// If this is set, when setting the number of reducers for the map reduce task which writes the
comment|// final output files, it will choose a number which is a power of two.  The number of reducers
comment|// may be set to a power of two, only to be followed by a merge task meaning preventing
comment|// anything from being inferred.
name|HIVE_INFER_BUCKET_SORT_NUM_BUCKETS_POWER_TWO
argument_list|(
literal|"hive.exec.infer.bucket.sort.num.buckets.power.two"
argument_list|,
literal|false
argument_list|)
block|,
comment|/* The following section contains all configurations used for list bucketing feature.*/
comment|/* This is not for clients. but only for block merge task. */
comment|/* This is used by BlockMergeTask to send out flag to RCFileMergeMapper */
comment|/* about alter table...concatenate and list bucketing case. */
name|HIVEMERGECURRENTJOBCONCATENATELISTBUCKETING
argument_list|(
literal|"hive.merge.current.job.concatenate.list.bucketing"
argument_list|,
literal|true
argument_list|)
block|,
comment|/* This is not for clients. but only for block merge task. */
comment|/* This is used by BlockMergeTask to send out flag to RCFileMergeMapper */
comment|/* about depth of list bucketing. */
name|HIVEMERGECURRENTJOBCONCATENATELISTBUCKETINGDEPTH
argument_list|(
literal|"hive.merge.current.job.concatenate.list.bucketing.depth"
argument_list|,
literal|0
argument_list|)
block|,
comment|// Enable list bucketing optimizer. Default value is false so that we disable it by default.
name|HIVEOPTLISTBUCKETING
argument_list|(
literal|"hive.optimize.listbucketing"
argument_list|,
literal|false
argument_list|)
block|,
comment|// Allow TCP Keep alive socket option for for HiveServer or a maximum timeout for the socket.
name|SERVER_READ_SOCKET_TIMEOUT
argument_list|(
literal|"hive.server.read.socket.timeout"
argument_list|,
literal|10
argument_list|)
block|,
name|SERVER_TCP_KEEP_ALIVE
argument_list|(
literal|"hive.server.tcp.keepalive"
argument_list|,
literal|true
argument_list|)
block|,
comment|// Whether to show the unquoted partition names in query results.
name|HIVE_DECODE_PARTITION_NAME
argument_list|(
literal|"hive.decode.partition.name"
argument_list|,
literal|false
argument_list|)
block|,     ;
specifier|public
specifier|final
name|String
name|varname
decl_stmt|;
specifier|public
specifier|final
name|String
name|defaultVal
decl_stmt|;
specifier|public
specifier|final
name|int
name|defaultIntVal
decl_stmt|;
specifier|public
specifier|final
name|long
name|defaultLongVal
decl_stmt|;
specifier|public
specifier|final
name|float
name|defaultFloatVal
decl_stmt|;
specifier|public
specifier|final
name|Class
argument_list|<
name|?
argument_list|>
name|valClass
decl_stmt|;
specifier|public
specifier|final
name|boolean
name|defaultBoolVal
decl_stmt|;
specifier|private
specifier|final
name|VarType
name|type
decl_stmt|;
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|String
name|defaultVal
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|valClass
operator|=
name|String
operator|.
name|class
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|defaultVal
expr_stmt|;
name|this
operator|.
name|defaultIntVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultLongVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultFloatVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultBoolVal
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|type
operator|=
name|VarType
operator|.
name|STRING
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|int
name|defaultIntVal
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|valClass
operator|=
name|Integer
operator|.
name|class
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|Integer
operator|.
name|toString
argument_list|(
name|defaultIntVal
argument_list|)
expr_stmt|;
name|this
operator|.
name|defaultIntVal
operator|=
name|defaultIntVal
expr_stmt|;
name|this
operator|.
name|defaultLongVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultFloatVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultBoolVal
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|type
operator|=
name|VarType
operator|.
name|INT
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|long
name|defaultLongVal
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|valClass
operator|=
name|Long
operator|.
name|class
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|Long
operator|.
name|toString
argument_list|(
name|defaultLongVal
argument_list|)
expr_stmt|;
name|this
operator|.
name|defaultIntVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultLongVal
operator|=
name|defaultLongVal
expr_stmt|;
name|this
operator|.
name|defaultFloatVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultBoolVal
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|type
operator|=
name|VarType
operator|.
name|LONG
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|float
name|defaultFloatVal
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|valClass
operator|=
name|Float
operator|.
name|class
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|Float
operator|.
name|toString
argument_list|(
name|defaultFloatVal
argument_list|)
expr_stmt|;
name|this
operator|.
name|defaultIntVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultLongVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultFloatVal
operator|=
name|defaultFloatVal
expr_stmt|;
name|this
operator|.
name|defaultBoolVal
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|type
operator|=
name|VarType
operator|.
name|FLOAT
expr_stmt|;
block|}
name|ConfVars
parameter_list|(
name|String
name|varname
parameter_list|,
name|boolean
name|defaultBoolVal
parameter_list|)
block|{
name|this
operator|.
name|varname
operator|=
name|varname
expr_stmt|;
name|this
operator|.
name|valClass
operator|=
name|Boolean
operator|.
name|class
expr_stmt|;
name|this
operator|.
name|defaultVal
operator|=
name|Boolean
operator|.
name|toString
argument_list|(
name|defaultBoolVal
argument_list|)
expr_stmt|;
name|this
operator|.
name|defaultIntVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultLongVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultFloatVal
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|defaultBoolVal
operator|=
name|defaultBoolVal
expr_stmt|;
name|this
operator|.
name|type
operator|=
name|VarType
operator|.
name|BOOLEAN
expr_stmt|;
block|}
specifier|public
name|boolean
name|isType
parameter_list|(
name|String
name|value
parameter_list|)
block|{
return|return
name|type
operator|.
name|isType
argument_list|(
name|value
argument_list|)
return|;
block|}
specifier|public
name|String
name|typeString
parameter_list|()
block|{
return|return
name|type
operator|.
name|typeString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|varname
return|;
block|}
specifier|private
specifier|static
name|String
name|findHadoopBinary
parameter_list|()
block|{
name|String
name|val
init|=
name|System
operator|.
name|getenv
argument_list|(
literal|"HADOOP_HOME"
argument_list|)
decl_stmt|;
comment|// In Hadoop 1.X and Hadoop 2.X HADOOP_HOME is gone and replaced with HADOOP_PREFIX
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
name|System
operator|.
name|getenv
argument_list|(
literal|"HADOOP_PREFIX"
argument_list|)
expr_stmt|;
block|}
comment|// and if all else fails we can at least try /usr/bin/hadoop
name|val
operator|=
operator|(
name|val
operator|==
literal|null
condition|?
name|File
operator|.
name|separator
operator|+
literal|"usr"
else|:
name|val
operator|)
operator|+
name|File
operator|.
name|separator
operator|+
literal|"bin"
operator|+
name|File
operator|.
name|separator
operator|+
literal|"hadoop"
expr_stmt|;
comment|// Launch hadoop command file on windows.
return|return
name|val
operator|+
operator|(
name|Shell
operator|.
name|WINDOWS
condition|?
literal|".cmd"
else|:
literal|""
operator|)
return|;
block|}
enum|enum
name|VarType
block|{
name|STRING
block|{
annotation|@
name|Override
name|void
name|checkType
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|Exception
block|{ }
block|}
block|,
name|INT
block|{
annotation|@
name|Override
name|void
name|checkType
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|Exception
block|{
name|Integer
operator|.
name|valueOf
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
block|,
name|LONG
block|{
annotation|@
name|Override
name|void
name|checkType
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|Exception
block|{
name|Long
operator|.
name|valueOf
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
block|,
name|FLOAT
block|{
annotation|@
name|Override
name|void
name|checkType
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|Exception
block|{
name|Float
operator|.
name|valueOf
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
block|,
name|BOOLEAN
block|{
annotation|@
name|Override
name|void
name|checkType
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|Exception
block|{
name|Boolean
operator|.
name|valueOf
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
block|;
name|boolean
name|isType
parameter_list|(
name|String
name|value
parameter_list|)
block|{
try|try
block|{
name|checkType
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
name|String
name|typeString
parameter_list|()
block|{
return|return
name|name
argument_list|()
operator|.
name|toUpperCase
argument_list|()
return|;
block|}
specifier|abstract
name|void
name|checkType
parameter_list|(
name|String
name|value
parameter_list|)
throws|throws
name|Exception
function_decl|;
block|}
block|}
comment|/**    * Writes the default ConfVars out to a byte array and returns an input    * stream wrapping that byte array.    *    * We need this in order to initialize the ConfVar properties    * in the underling Configuration object using the addResource(InputStream)    * method.    *    * It is important to use a LoopingByteArrayInputStream because it turns out    * addResource(InputStream) is broken since Configuration tries to read the    * entire contents of the same InputStream repeatedly without resetting it.    * LoopingByteArrayInputStream has special logic to handle this.    */
specifier|private
specifier|static
specifier|synchronized
name|InputStream
name|getConfVarInputStream
parameter_list|()
block|{
if|if
condition|(
name|confVarByteArray
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
name|applyDefaultNonNullConfVars
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|ByteArrayOutputStream
name|confVarBaos
init|=
operator|new
name|ByteArrayOutputStream
argument_list|()
decl_stmt|;
name|conf
operator|.
name|writeXml
argument_list|(
name|confVarBaos
argument_list|)
expr_stmt|;
name|confVarByteArray
operator|=
name|confVarBaos
operator|.
name|toByteArray
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// We're pretty screwed if we can't load the default conf vars
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed to initialize default Hive configuration variables!"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
return|return
operator|new
name|LoopingByteArrayInputStream
argument_list|(
name|confVarByteArray
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|int
name|getIntVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Integer
operator|.
name|class
operator|)
assert|;
return|return
name|conf
operator|.
name|getInt
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
operator|.
name|defaultIntVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|setIntVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|int
name|val
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Integer
operator|.
name|class
operator|)
assert|;
name|conf
operator|.
name|setInt
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
name|int
name|getIntVar
parameter_list|(
name|ConfVars
name|var
parameter_list|)
block|{
return|return
name|getIntVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|)
return|;
block|}
specifier|public
name|void
name|setIntVar
parameter_list|(
name|ConfVars
name|var
parameter_list|,
name|int
name|val
parameter_list|)
block|{
name|setIntVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|long
name|getLongVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Long
operator|.
name|class
operator|)
assert|;
return|return
name|conf
operator|.
name|getLong
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
operator|.
name|defaultLongVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|long
name|getLongVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|long
name|defaultVal
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getLong
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|defaultVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|setLongVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|long
name|val
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Long
operator|.
name|class
operator|)
assert|;
name|conf
operator|.
name|setLong
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
name|long
name|getLongVar
parameter_list|(
name|ConfVars
name|var
parameter_list|)
block|{
return|return
name|getLongVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|)
return|;
block|}
specifier|public
name|void
name|setLongVar
parameter_list|(
name|ConfVars
name|var
parameter_list|,
name|long
name|val
parameter_list|)
block|{
name|setLongVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|float
name|getFloatVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Float
operator|.
name|class
operator|)
assert|;
return|return
name|conf
operator|.
name|getFloat
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
operator|.
name|defaultFloatVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|float
name|getFloatVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|float
name|defaultVal
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getFloat
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|defaultVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|setFloatVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|float
name|val
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Float
operator|.
name|class
operator|)
assert|;
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|setFloatConf
argument_list|(
name|conf
argument_list|,
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
name|float
name|getFloatVar
parameter_list|(
name|ConfVars
name|var
parameter_list|)
block|{
return|return
name|getFloatVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|)
return|;
block|}
specifier|public
name|void
name|setFloatVar
parameter_list|(
name|ConfVars
name|var
parameter_list|,
name|float
name|val
parameter_list|)
block|{
name|setFloatVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|boolean
name|getBoolVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Boolean
operator|.
name|class
operator|)
assert|;
return|return
name|conf
operator|.
name|getBoolean
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
operator|.
name|defaultBoolVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|getBoolVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|boolean
name|defaultVal
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getBoolean
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|defaultVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|setBoolVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|boolean
name|val
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|Boolean
operator|.
name|class
operator|)
assert|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
name|boolean
name|getBoolVar
parameter_list|(
name|ConfVars
name|var
parameter_list|)
block|{
return|return
name|getBoolVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|)
return|;
block|}
specifier|public
name|void
name|setBoolVar
parameter_list|(
name|ConfVars
name|var
parameter_list|,
name|boolean
name|val
parameter_list|)
block|{
name|setBoolVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|String
name|getVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|String
operator|.
name|class
operator|)
assert|;
return|return
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
operator|.
name|defaultVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|getVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|String
name|defaultVal
parameter_list|)
block|{
return|return
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|defaultVal
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|setVar
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ConfVars
name|var
parameter_list|,
name|String
name|val
parameter_list|)
block|{
assert|assert
operator|(
name|var
operator|.
name|valClass
operator|==
name|String
operator|.
name|class
operator|)
assert|;
name|conf
operator|.
name|set
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|ConfVars
name|getConfVars
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|vars
operator|.
name|get
argument_list|(
name|name
argument_list|)
return|;
block|}
specifier|public
name|String
name|getVar
parameter_list|(
name|ConfVars
name|var
parameter_list|)
block|{
return|return
name|getVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|)
return|;
block|}
specifier|public
name|void
name|setVar
parameter_list|(
name|ConfVars
name|var
parameter_list|,
name|String
name|val
parameter_list|)
block|{
name|setVar
argument_list|(
name|this
argument_list|,
name|var
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|logVars
parameter_list|(
name|PrintStream
name|ps
parameter_list|)
block|{
for|for
control|(
name|ConfVars
name|one
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
name|ps
operator|.
name|println
argument_list|(
name|one
operator|.
name|varname
operator|+
literal|"="
operator|+
operator|(
operator|(
name|get
argument_list|(
name|one
operator|.
name|varname
argument_list|)
operator|!=
literal|null
operator|)
condition|?
name|get
argument_list|(
name|one
operator|.
name|varname
argument_list|)
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|HiveConf
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
name|initialize
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|HiveConf
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|cls
parameter_list|)
block|{
name|super
argument_list|()
expr_stmt|;
name|initialize
argument_list|(
name|cls
argument_list|)
expr_stmt|;
block|}
specifier|public
name|HiveConf
parameter_list|(
name|Configuration
name|other
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|cls
parameter_list|)
block|{
name|super
argument_list|(
name|other
argument_list|)
expr_stmt|;
name|initialize
argument_list|(
name|cls
argument_list|)
expr_stmt|;
block|}
comment|/**    * Copy constructor    */
specifier|public
name|HiveConf
parameter_list|(
name|HiveConf
name|other
parameter_list|)
block|{
name|super
argument_list|(
name|other
argument_list|)
expr_stmt|;
name|hiveJar
operator|=
name|other
operator|.
name|hiveJar
expr_stmt|;
name|auxJars
operator|=
name|other
operator|.
name|auxJars
expr_stmt|;
name|origProp
operator|=
operator|(
name|Properties
operator|)
name|other
operator|.
name|origProp
operator|.
name|clone
argument_list|()
expr_stmt|;
block|}
specifier|public
name|Properties
name|getAllProperties
parameter_list|()
block|{
return|return
name|getProperties
argument_list|(
name|this
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|Properties
name|getProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|Iterator
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|iter
init|=
name|conf
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Properties
name|p
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|p
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|p
return|;
block|}
specifier|private
name|void
name|initialize
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|cls
parameter_list|)
block|{
name|hiveJar
operator|=
operator|(
operator|new
name|JobConf
argument_list|(
name|cls
argument_list|)
operator|)
operator|.
name|getJar
argument_list|()
expr_stmt|;
comment|// preserve the original configuration
name|origProp
operator|=
name|getAllProperties
argument_list|()
expr_stmt|;
comment|// Overlay the ConfVars. Note that this ignores ConfVars with null values
name|addResource
argument_list|(
name|getConfVarInputStream
argument_list|()
argument_list|)
expr_stmt|;
comment|// Overlay hive-site.xml if it exists
if|if
condition|(
name|hiveSiteURL
operator|!=
literal|null
condition|)
block|{
name|addResource
argument_list|(
name|hiveSiteURL
argument_list|)
expr_stmt|;
block|}
comment|// Overlay the values of any system properties whose names appear in the list of ConfVars
name|applySystemProperties
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|get
argument_list|(
literal|"hive.metastore.local"
argument_list|,
literal|null
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|l4j
operator|.
name|warn
argument_list|(
literal|"DEPRECATED: Configuration property hive.metastore.local no longer has any "
operator|+
literal|"effect. Make sure to provide a valid value for hive.metastore.uris if you are "
operator|+
literal|"connecting to a remote metastore."
argument_list|)
expr_stmt|;
block|}
comment|// if the running class was loaded directly (through eclipse) rather than through a
comment|// jar then this would be needed
if|if
condition|(
name|hiveJar
operator|==
literal|null
condition|)
block|{
name|hiveJar
operator|=
name|this
operator|.
name|get
argument_list|(
name|ConfVars
operator|.
name|HIVEJAR
operator|.
name|varname
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|auxJars
operator|==
literal|null
condition|)
block|{
name|auxJars
operator|=
name|this
operator|.
name|get
argument_list|(
name|ConfVars
operator|.
name|HIVEAUXJARS
operator|.
name|varname
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Apply system properties to this object if the property name is defined in ConfVars    * and the value is non-null and not an empty string.    */
specifier|private
name|void
name|applySystemProperties
parameter_list|()
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|systemProperties
init|=
name|getConfSystemProperties
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|systemProperty
range|:
name|systemProperties
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|this
operator|.
name|set
argument_list|(
name|systemProperty
operator|.
name|getKey
argument_list|()
argument_list|,
name|systemProperty
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * This method returns a mapping from config variable name to its value for all config variables    * which have been set using System properties    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getConfSystemProperties
parameter_list|()
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|systemProperties
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|ConfVars
name|oneVar
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|System
operator|.
name|getProperty
argument_list|(
name|oneVar
operator|.
name|varname
argument_list|)
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|System
operator|.
name|getProperty
argument_list|(
name|oneVar
operator|.
name|varname
argument_list|)
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|systemProperties
operator|.
name|put
argument_list|(
name|oneVar
operator|.
name|varname
argument_list|,
name|System
operator|.
name|getProperty
argument_list|(
name|oneVar
operator|.
name|varname
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|systemProperties
return|;
block|}
comment|/**    * Overlays ConfVar properties with non-null values    */
specifier|private
specifier|static
name|void
name|applyDefaultNonNullConfVars
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
for|for
control|(
name|ConfVars
name|var
range|:
name|ConfVars
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|var
operator|.
name|defaultVal
operator|==
literal|null
condition|)
block|{
comment|// Don't override ConfVars with null values
continue|continue;
block|}
if|if
condition|(
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|l4j
operator|.
name|debug
argument_list|(
literal|"Overriding Hadoop conf property "
operator|+
name|var
operator|.
name|varname
operator|+
literal|"='"
operator|+
name|conf
operator|.
name|get
argument_list|(
name|var
operator|.
name|varname
argument_list|)
operator|+
literal|"' with Hive default value '"
operator|+
name|var
operator|.
name|defaultVal
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
name|var
operator|.
name|varname
argument_list|,
name|var
operator|.
name|defaultVal
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|Properties
name|getChangedProperties
parameter_list|()
block|{
name|Properties
name|ret
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|Properties
name|newProp
init|=
name|getAllProperties
argument_list|()
decl_stmt|;
for|for
control|(
name|Object
name|one
range|:
name|newProp
operator|.
name|keySet
argument_list|()
control|)
block|{
name|String
name|oneProp
init|=
operator|(
name|String
operator|)
name|one
decl_stmt|;
name|String
name|oldValue
init|=
name|origProp
operator|.
name|getProperty
argument_list|(
name|oneProp
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|StringUtils
operator|.
name|equals
argument_list|(
name|oldValue
argument_list|,
name|newProp
operator|.
name|getProperty
argument_list|(
name|oneProp
argument_list|)
argument_list|)
condition|)
block|{
name|ret
operator|.
name|setProperty
argument_list|(
name|oneProp
argument_list|,
name|newProp
operator|.
name|getProperty
argument_list|(
name|oneProp
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|ret
operator|)
return|;
block|}
specifier|public
name|String
name|getJar
parameter_list|()
block|{
return|return
name|hiveJar
return|;
block|}
comment|/**    * @return the auxJars    */
specifier|public
name|String
name|getAuxJars
parameter_list|()
block|{
return|return
name|auxJars
return|;
block|}
comment|/**    * @param auxJars the auxJars to set    */
specifier|public
name|void
name|setAuxJars
parameter_list|(
name|String
name|auxJars
parameter_list|)
block|{
name|this
operator|.
name|auxJars
operator|=
name|auxJars
expr_stmt|;
name|setVar
argument_list|(
name|this
argument_list|,
name|ConfVars
operator|.
name|HIVEAUXJARS
argument_list|,
name|auxJars
argument_list|)
expr_stmt|;
block|}
specifier|public
name|URL
name|getHiveDefaultLocation
parameter_list|()
block|{
return|return
name|hiveDefaultURL
return|;
block|}
specifier|public
name|URL
name|getHiveSiteLocation
parameter_list|()
block|{
return|return
name|hiveSiteURL
return|;
block|}
comment|/**    * @return the user name set in hadoop.job.ugi param or the current user from System    * @throws IOException    */
specifier|public
name|String
name|getUser
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|UserGroupInformation
name|ugi
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getUGIForConf
argument_list|(
name|this
argument_list|)
decl_stmt|;
return|return
name|ugi
operator|.
name|getUserName
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|LoginException
name|le
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|le
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|String
name|getColumnInternalName
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
return|return
literal|"_col"
operator|+
name|pos
return|;
block|}
specifier|public
specifier|static
name|int
name|getPositionFromInternalName
parameter_list|(
name|String
name|internalName
parameter_list|)
block|{
name|Pattern
name|internalPattern
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"_col([0-9]+)"
argument_list|)
decl_stmt|;
name|Matcher
name|m
init|=
name|internalPattern
operator|.
name|matcher
argument_list|(
name|internalName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|m
operator|.
name|group
argument_list|(
literal|1
argument_list|)
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

