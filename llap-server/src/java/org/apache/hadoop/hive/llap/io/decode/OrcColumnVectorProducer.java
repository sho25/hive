begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|Consumer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|api
operator|.
name|EncodedColumnBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|api
operator|.
name|impl
operator|.
name|ColumnVectorBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|api
operator|.
name|orc
operator|.
name|OrcBatchKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|orc
operator|.
name|streams
operator|.
name|ColumnStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|orc
operator|.
name|streams
operator|.
name|DoubleColumnStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|orc
operator|.
name|streams
operator|.
name|FloatColumnStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|orc
operator|.
name|streams
operator|.
name|IntegerColumnStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|orc
operator|.
name|streams
operator|.
name|StringColumnStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|encoded
operator|.
name|EncodedDataProducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|encoded
operator|.
name|OrcEncodedDataProducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|metadata
operator|.
name|OrcFileMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|metadata
operator|.
name|OrcMetadataCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|metadata
operator|.
name|OrcStripeMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|ColumnVector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedRowBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|CompressionCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcProto
import|;
end_import

begin_import
import|import
name|com
operator|.
name|clearspring
operator|.
name|analytics
operator|.
name|util
operator|.
name|Lists
import|;
end_import

begin_class
specifier|public
class|class
name|OrcColumnVectorProducer
extends|extends
name|ColumnVectorProducer
argument_list|<
name|OrcBatchKey
argument_list|>
block|{
specifier|private
specifier|final
name|OrcEncodedDataProducer
name|edp
decl_stmt|;
specifier|private
specifier|final
name|OrcMetadataCache
name|metadataCache
decl_stmt|;
specifier|private
name|ColumnVectorBatch
name|cvb
decl_stmt|;
specifier|public
name|OrcColumnVectorProducer
parameter_list|(
name|ExecutorService
name|executor
parameter_list|,
name|OrcEncodedDataProducer
name|edp
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|super
argument_list|(
name|executor
argument_list|)
expr_stmt|;
name|this
operator|.
name|edp
operator|=
name|edp
expr_stmt|;
name|this
operator|.
name|metadataCache
operator|=
name|OrcMetadataCache
operator|.
name|getInstance
argument_list|()
expr_stmt|;
name|this
operator|.
name|cvb
operator|=
literal|null
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|EncodedDataProducer
argument_list|<
name|OrcBatchKey
argument_list|>
name|getEncodedDataProducer
parameter_list|()
block|{
return|return
name|edp
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|decodeBatch
parameter_list|(
name|EncodedColumnBatch
argument_list|<
name|OrcBatchKey
argument_list|>
name|batch
parameter_list|,
name|Consumer
argument_list|<
name|ColumnVectorBatch
argument_list|>
name|downstreamConsumer
parameter_list|)
block|{
name|String
name|fileName
init|=
name|batch
operator|.
name|batchKey
operator|.
name|file
decl_stmt|;
comment|// OrcEncodedDataProducer should have just loaded cache entries from this file.
comment|// The default LRU algorithm shouldn't have dropped the entries. To make it
comment|// safe, untie the code from EDP into separate class and make use of loading cache.
try|try
block|{
name|OrcFileMetadata
name|fileMetadata
init|=
name|metadataCache
operator|.
name|getFileMetadata
argument_list|(
name|fileName
argument_list|)
decl_stmt|;
name|OrcBatchKey
name|stripeKey
init|=
name|batch
operator|.
name|batchKey
operator|.
name|clone
argument_list|()
decl_stmt|;
comment|// we are interested only in the stripe number. To make sure we get the correct stripe
comment|// metadata, set row group index to 0. That's how it is cached. See OrcEncodedDataProducer
name|stripeKey
operator|.
name|rgIx
operator|=
literal|0
expr_stmt|;
name|OrcStripeMetadata
name|stripeMetadata
init|=
name|metadataCache
operator|.
name|getStripeMetadata
argument_list|(
name|stripeKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|cvb
operator|==
literal|null
condition|)
block|{
name|cvb
operator|=
operator|new
name|ColumnVectorBatch
argument_list|(
name|batch
operator|.
name|columnIxs
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
comment|// Get non null row count from root column
name|int
name|rgIdx
init|=
name|batch
operator|.
name|batchKey
operator|.
name|rgIx
decl_stmt|;
name|OrcProto
operator|.
name|RowIndexEntry
name|rowIndex
init|=
name|stripeMetadata
operator|.
name|getRowIndexes
argument_list|()
index|[
literal|0
index|]
operator|.
name|getEntry
argument_list|(
name|rgIdx
argument_list|)
decl_stmt|;
name|long
name|nonNullRowCount
init|=
name|getRowCount
argument_list|(
name|rowIndex
argument_list|)
decl_stmt|;
name|int
name|maxBatchesRG
init|=
call|(
name|int
call|)
argument_list|(
operator|(
name|nonNullRowCount
operator|/
name|VectorizedRowBatch
operator|.
name|DEFAULT_SIZE
operator|)
operator|+
literal|1
argument_list|)
decl_stmt|;
name|int
name|batchSize
init|=
name|VectorizedRowBatch
operator|.
name|DEFAULT_SIZE
decl_stmt|;
name|int
name|numCols
init|=
name|batch
operator|.
name|columnIxs
operator|.
name|length
decl_stmt|;
name|ColumnStream
index|[]
name|columnStreams
init|=
name|createColumnStreamReaders
argument_list|(
name|numCols
argument_list|,
name|batch
argument_list|,
name|fileMetadata
argument_list|,
name|stripeMetadata
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|maxBatchesRG
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|maxBatchesRG
operator|-
literal|1
condition|)
block|{
name|batchSize
operator|=
call|(
name|int
call|)
argument_list|(
name|nonNullRowCount
operator|%
name|VectorizedRowBatch
operator|.
name|DEFAULT_SIZE
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|batch
operator|.
name|columnIxs
operator|.
name|length
condition|;
name|idx
operator|++
control|)
block|{
name|cvb
operator|.
name|cols
index|[
name|idx
index|]
operator|=
name|columnStreams
index|[
name|idx
index|]
operator|.
name|nextVector
argument_list|(
literal|null
argument_list|,
name|batchSize
argument_list|)
expr_stmt|;
block|}
comment|// we are done reading a batch, send it to consumer for processing
name|downstreamConsumer
operator|.
name|consumeData
argument_list|(
name|cvb
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|downstreamConsumer
operator|.
name|setError
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|CloneNotSupportedException
name|e
parameter_list|)
block|{
name|downstreamConsumer
operator|.
name|setError
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|ColumnStream
index|[]
name|createColumnStreamReaders
parameter_list|(
name|int
name|numCols
parameter_list|,
name|EncodedColumnBatch
argument_list|<
name|OrcBatchKey
argument_list|>
name|batch
parameter_list|,
name|OrcFileMetadata
name|fileMetadata
parameter_list|,
name|OrcStripeMetadata
name|stripeMetadata
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|file
init|=
name|batch
operator|.
name|batchKey
operator|.
name|file
decl_stmt|;
name|ColumnStream
index|[]
name|columnStreams
init|=
operator|new
name|ColumnStream
index|[
name|numCols
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numCols
condition|;
name|i
operator|++
control|)
block|{
name|int
name|colIx
init|=
name|batch
operator|.
name|columnIxs
index|[
name|i
index|]
decl_stmt|;
name|int
name|rgIdx
init|=
name|batch
operator|.
name|batchKey
operator|.
name|rgIx
decl_stmt|;
name|OrcProto
operator|.
name|RowIndexEntry
name|rowIndex
init|=
name|stripeMetadata
operator|.
name|getRowIndexes
argument_list|()
index|[
name|colIx
index|]
operator|.
name|getEntry
argument_list|(
name|rgIdx
argument_list|)
decl_stmt|;
name|EncodedColumnBatch
operator|.
name|StreamBuffer
index|[]
name|streamBuffers
init|=
name|batch
operator|.
name|columnData
index|[
name|i
index|]
decl_stmt|;
name|OrcProto
operator|.
name|Type
name|colType
init|=
name|fileMetadata
operator|.
name|getTypes
argument_list|()
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
comment|// TODO: EncodedColumnBatch is already decompressed, we don't really need to pass codec.
comment|// But we need to know if the original data is compressed or not. This is used to skip positions
comment|// in row index. If the file is originally compressed, then 1st position (compressed offset)
comment|// in row index should be skipped to get uncompressed offset, else 1st position should not
comment|// be skipped.
name|CompressionCodec
name|codec
init|=
name|fileMetadata
operator|.
name|getCompressionCodec
argument_list|()
decl_stmt|;
name|int
name|bufferSize
init|=
name|fileMetadata
operator|.
name|getCompressionBufferSize
argument_list|()
decl_stmt|;
name|OrcProto
operator|.
name|ColumnEncoding
name|columnEncoding
init|=
name|stripeMetadata
operator|.
name|getEncodings
argument_list|()
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
name|ColumnVector
name|cv
init|=
literal|null
decl_stmt|;
comment|// FIXME: See if the stream buffers are in this same order. What will happen if some stream
comment|// does not exist? Will stream buffer be null?
name|EncodedColumnBatch
operator|.
name|StreamBuffer
name|present
init|=
literal|null
decl_stmt|;
name|EncodedColumnBatch
operator|.
name|StreamBuffer
name|data
init|=
literal|null
decl_stmt|;
name|EncodedColumnBatch
operator|.
name|StreamBuffer
name|dictionary
init|=
literal|null
decl_stmt|;
name|EncodedColumnBatch
operator|.
name|StreamBuffer
name|lengths
init|=
literal|null
decl_stmt|;
name|EncodedColumnBatch
operator|.
name|StreamBuffer
name|secondary
init|=
literal|null
decl_stmt|;
switch|switch
condition|(
name|colType
operator|.
name|getKind
argument_list|()
condition|)
block|{
case|case
name|SHORT
case|:
case|case
name|INT
case|:
case|case
name|LONG
case|:
comment|// TODO: EncodedDataProducer should produce stream buffers in enum order of stream kind.
comment|// So if a stream does not exist, it should have null instead.
if|if
condition|(
name|streamBuffers
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
name|present
operator|=
literal|null
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
block|}
else|else
block|{
name|present
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|1
index|]
expr_stmt|;
block|}
comment|// FIXME: Creating column stream readers for every row group will be expensive.
name|columnStreams
index|[
name|i
index|]
operator|=
operator|new
name|IntegerColumnStream
argument_list|(
name|file
argument_list|,
name|colIx
argument_list|,
name|present
argument_list|,
name|data
argument_list|,
name|columnEncoding
argument_list|,
name|codec
argument_list|,
name|bufferSize
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
break|break;
case|case
name|FLOAT
case|:
if|if
condition|(
name|streamBuffers
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
name|present
operator|=
literal|null
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
block|}
else|else
block|{
name|present
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|1
index|]
expr_stmt|;
block|}
name|columnStreams
index|[
name|i
index|]
operator|=
operator|new
name|FloatColumnStream
argument_list|(
name|file
argument_list|,
name|colIx
argument_list|,
name|present
argument_list|,
name|data
argument_list|,
name|codec
argument_list|,
name|bufferSize
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
break|break;
case|case
name|DOUBLE
case|:
if|if
condition|(
name|streamBuffers
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
name|present
operator|=
literal|null
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
block|}
else|else
block|{
name|present
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|1
index|]
expr_stmt|;
block|}
name|columnStreams
index|[
name|i
index|]
operator|=
operator|new
name|DoubleColumnStream
argument_list|(
name|file
argument_list|,
name|colIx
argument_list|,
name|present
argument_list|,
name|data
argument_list|,
name|codec
argument_list|,
name|bufferSize
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
break|break;
case|case
name|CHAR
case|:
case|case
name|VARCHAR
case|:
case|case
name|STRING
case|:
comment|// FIXME: This is hacky! Will never work. Fix it cleanly everywhere. Hopefully encoded
comment|// data producer will provide streams in enum order of stream kind
name|present
operator|=
name|streamBuffers
index|[
literal|0
index|]
expr_stmt|;
name|data
operator|=
name|streamBuffers
index|[
literal|1
index|]
expr_stmt|;
name|dictionary
operator|=
name|streamBuffers
index|[
literal|2
index|]
expr_stmt|;
name|lengths
operator|=
name|streamBuffers
index|[
literal|3
index|]
expr_stmt|;
name|columnStreams
index|[
name|i
index|]
operator|=
operator|new
name|StringColumnStream
argument_list|(
name|file
argument_list|,
name|colIx
argument_list|,
name|present
argument_list|,
name|data
argument_list|,
name|dictionary
argument_list|,
name|lengths
argument_list|,
name|columnEncoding
argument_list|,
name|codec
argument_list|,
name|bufferSize
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Data type not supported yet! "
operator|+
name|colType
argument_list|)
throw|;
block|}
block|}
return|return
name|columnStreams
return|;
block|}
specifier|private
name|List
argument_list|<
name|OrcProto
operator|.
name|Stream
argument_list|>
name|getDataStreams
parameter_list|(
name|int
name|colIx
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Stream
argument_list|>
name|streams
parameter_list|)
block|{
name|List
argument_list|<
name|OrcProto
operator|.
name|Stream
argument_list|>
name|result
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|OrcProto
operator|.
name|Stream
name|stream
range|:
name|streams
control|)
block|{
if|if
condition|(
name|stream
operator|.
name|getColumn
argument_list|()
operator|==
name|colIx
condition|)
block|{
switch|switch
condition|(
name|stream
operator|.
name|getKind
argument_list|()
condition|)
block|{
case|case
name|PRESENT
case|:
case|case
name|DATA
case|:
case|case
name|LENGTH
case|:
case|case
name|DICTIONARY_DATA
case|:
case|case
name|SECONDARY
case|:
name|result
operator|.
name|add
argument_list|(
name|stream
argument_list|)
expr_stmt|;
default|default:
comment|// ignore
block|}
block|}
block|}
return|return
name|result
return|;
block|}
specifier|private
name|long
name|getRowCount
parameter_list|(
name|OrcProto
operator|.
name|RowIndexEntry
name|rowIndexEntry
parameter_list|)
block|{
return|return
name|rowIndexEntry
operator|.
name|getStatistics
argument_list|()
operator|.
name|getNumberOfValues
argument_list|()
return|;
block|}
block|}
end_class

end_unit

