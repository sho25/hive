begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|api
operator|.
name|impl
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|ConsumerFeedback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|counters
operator|.
name|FragmentCountersMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|counters
operator|.
name|LlapIOCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|counters
operator|.
name|QueryFragmentCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|daemon
operator|.
name|impl
operator|.
name|StatsRecordingThreadPool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|ColumnVectorProducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|ColumnVectorProducer
operator|.
name|Includes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|ColumnVectorProducer
operator|.
name|SchemaEvolutionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|ReadPipeline
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|tezplugins
operator|.
name|LlapTezUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
operator|.
name|DagUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedRowBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedRowBatchCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcRecordUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|VectorizedOrcAcidRowBatchReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|Consumer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|ConvertAstToSearchArg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|SearchArgument
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|BaseWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
operator|.
name|Category
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|DecimalTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|PrimitiveTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|TypeDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|SchemaEvolution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|common
operator|.
name|counters
operator|.
name|TezCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|MDC
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_class
class|class
name|LlapRecordReader
implements|implements
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|VectorizedRowBatch
argument_list|>
implements|,
name|Consumer
argument_list|<
name|ColumnVectorBatch
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|LlapRecordReader
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Object
name|DONE_OBJECT
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|FileSplit
name|split
decl_stmt|;
specifier|private
specifier|final
name|IncludesImpl
name|includes
decl_stmt|;
specifier|private
specifier|final
name|SearchArgument
name|sarg
decl_stmt|;
specifier|private
specifier|final
name|VectorizedRowBatchCtx
name|rbCtx
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isVectorized
decl_stmt|;
specifier|private
name|VectorizedOrcAcidRowBatchReader
name|acidReader
decl_stmt|;
specifier|private
specifier|final
name|Object
index|[]
name|partitionValues
decl_stmt|;
specifier|private
specifier|final
name|LinkedBlockingQueue
argument_list|<
name|Object
argument_list|>
name|queue
decl_stmt|;
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|Throwable
argument_list|>
name|pendingError
init|=
operator|new
name|AtomicReference
argument_list|<>
argument_list|(
literal|null
argument_list|)
decl_stmt|;
comment|/** Vector that is currently being processed by our user. */
specifier|private
name|ColumnVectorBatch
name|lastCvb
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|isFirst
init|=
literal|true
decl_stmt|;
specifier|private
name|int
name|maxQueueSize
init|=
literal|0
decl_stmt|;
specifier|private
name|boolean
name|isClosed
init|=
literal|false
decl_stmt|,
name|isInterrupted
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|ConsumerFeedback
argument_list|<
name|ColumnVectorBatch
argument_list|>
name|feedback
decl_stmt|;
specifier|private
specifier|final
name|QueryFragmentCounters
name|counters
decl_stmt|;
specifier|private
name|long
name|firstReturnTime
decl_stmt|;
specifier|private
specifier|final
name|JobConf
name|jobConf
decl_stmt|;
specifier|private
specifier|final
name|ReadPipeline
name|rp
decl_stmt|;
specifier|private
specifier|final
name|ExecutorService
name|executor
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isAcidScan
decl_stmt|;
comment|/**    * Creates the record reader and checks the input-specific compatibility.    * @return The reader if the split can be read, null otherwise.    */
specifier|public
specifier|static
name|LlapRecordReader
name|create
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|FileSplit
name|split
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|tableIncludedCols
parameter_list|,
name|String
name|hostName
parameter_list|,
name|ColumnVectorProducer
name|cvp
parameter_list|,
name|ExecutorService
name|executor
parameter_list|,
name|InputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|sourceInputFormat
parameter_list|,
name|Deserializer
name|sourceSerDe
parameter_list|,
name|Reporter
name|reporter
parameter_list|,
name|Configuration
name|daemonConf
parameter_list|)
throws|throws
name|IOException
throws|,
name|HiveException
block|{
name|MapWork
name|mapWork
init|=
name|findMapWork
argument_list|(
name|job
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapWork
operator|==
literal|null
condition|)
return|return
literal|null
return|;
comment|// No compatible MapWork.
name|LlapRecordReader
name|rr
init|=
operator|new
name|LlapRecordReader
argument_list|(
name|mapWork
argument_list|,
name|job
argument_list|,
name|split
argument_list|,
name|tableIncludedCols
argument_list|,
name|hostName
argument_list|,
name|cvp
argument_list|,
name|executor
argument_list|,
name|sourceInputFormat
argument_list|,
name|sourceSerDe
argument_list|,
name|reporter
argument_list|,
name|daemonConf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|rr
operator|.
name|checkOrcSchemaEvolution
argument_list|()
condition|)
block|{
name|rr
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
return|return
name|rr
return|;
block|}
specifier|private
name|LlapRecordReader
parameter_list|(
name|MapWork
name|mapWork
parameter_list|,
name|JobConf
name|job
parameter_list|,
name|FileSplit
name|split
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|tableIncludedCols
parameter_list|,
name|String
name|hostName
parameter_list|,
name|ColumnVectorProducer
name|cvp
parameter_list|,
name|ExecutorService
name|executor
parameter_list|,
name|InputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|sourceInputFormat
parameter_list|,
name|Deserializer
name|sourceSerDe
parameter_list|,
name|Reporter
name|reporter
parameter_list|,
name|Configuration
name|daemonConf
parameter_list|)
throws|throws
name|IOException
throws|,
name|HiveException
block|{
name|this
operator|.
name|executor
operator|=
name|executor
expr_stmt|;
name|this
operator|.
name|jobConf
operator|=
name|job
expr_stmt|;
name|this
operator|.
name|split
operator|=
name|split
expr_stmt|;
name|this
operator|.
name|sarg
operator|=
name|ConvertAstToSearchArg
operator|.
name|createFromConf
argument_list|(
name|job
argument_list|)
expr_stmt|;
specifier|final
name|String
name|fragmentId
init|=
name|LlapTezUtils
operator|.
name|getFragmentId
argument_list|(
name|job
argument_list|)
decl_stmt|;
specifier|final
name|String
name|dagId
init|=
name|LlapTezUtils
operator|.
name|getDagId
argument_list|(
name|job
argument_list|)
decl_stmt|;
specifier|final
name|String
name|queryId
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|job
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEQUERYID
argument_list|)
decl_stmt|;
name|MDC
operator|.
name|put
argument_list|(
literal|"dagId"
argument_list|,
name|dagId
argument_list|)
expr_stmt|;
name|MDC
operator|.
name|put
argument_list|(
literal|"queryId"
argument_list|,
name|queryId
argument_list|)
expr_stmt|;
name|TezCounters
name|taskCounters
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|fragmentId
operator|!=
literal|null
condition|)
block|{
name|MDC
operator|.
name|put
argument_list|(
literal|"fragmentId"
argument_list|,
name|fragmentId
argument_list|)
expr_stmt|;
name|taskCounters
operator|=
name|FragmentCountersMap
operator|.
name|getCountersForFragment
argument_list|(
name|fragmentId
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Received fragment id: {}"
argument_list|,
name|fragmentId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Not using tez counters as fragment id string is null"
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|counters
operator|=
operator|new
name|QueryFragmentCounters
argument_list|(
name|job
argument_list|,
name|taskCounters
argument_list|)
expr_stmt|;
name|this
operator|.
name|counters
operator|.
name|setDesc
argument_list|(
name|QueryFragmentCounters
operator|.
name|Desc
operator|.
name|MACHINE
argument_list|,
name|hostName
argument_list|)
expr_stmt|;
name|VectorizedRowBatchCtx
name|ctx
init|=
name|mapWork
operator|.
name|getVectorizedRowBatchCtx
argument_list|()
decl_stmt|;
name|rbCtx
operator|=
name|ctx
operator|!=
literal|null
condition|?
name|ctx
else|:
name|LlapInputFormat
operator|.
name|createFakeVrbCtx
argument_list|(
name|mapWork
argument_list|)
expr_stmt|;
name|isAcidScan
operator|=
name|AcidUtils
operator|.
name|isFullAcidScan
argument_list|(
name|jobConf
argument_list|)
expr_stmt|;
name|TypeDescription
name|schema
init|=
name|OrcInputFormat
operator|.
name|getDesiredRowTypeDescr
argument_list|(
name|job
argument_list|,
name|isAcidScan
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
name|this
operator|.
name|includes
operator|=
operator|new
name|IncludesImpl
argument_list|(
name|tableIncludedCols
argument_list|,
name|isAcidScan
argument_list|,
name|rbCtx
argument_list|,
name|schema
argument_list|,
name|job
argument_list|)
expr_stmt|;
name|int
name|queueLimitBase
init|=
name|getQueueVar
argument_list|(
name|ConfVars
operator|.
name|LLAP_IO_VRB_QUEUE_LIMIT_BASE
argument_list|,
name|job
argument_list|,
name|daemonConf
argument_list|)
decl_stmt|;
name|int
name|queueLimitMin
init|=
name|getQueueVar
argument_list|(
name|ConfVars
operator|.
name|LLAP_IO_VRB_QUEUE_LIMIT_MIN
argument_list|,
name|job
argument_list|,
name|daemonConf
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|decimal64Support
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|job
argument_list|,
name|ConfVars
operator|.
name|HIVE_VECTORIZED_INPUT_FORMAT_SUPPORTS_ENABLED
argument_list|)
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"decimal_64"
argument_list|)
decl_stmt|;
name|int
name|limit
init|=
name|determineQueueLimit
argument_list|(
name|queueLimitBase
argument_list|,
name|queueLimitMin
argument_list|,
name|rbCtx
operator|.
name|getRowColumnTypeInfos
argument_list|()
argument_list|,
name|decimal64Support
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Queue limit for LlapRecordReader is "
operator|+
name|limit
argument_list|)
expr_stmt|;
name|this
operator|.
name|queue
operator|=
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|(
name|limit
argument_list|)
expr_stmt|;
name|int
name|partitionColumnCount
init|=
name|rbCtx
operator|.
name|getPartitionColumnCount
argument_list|()
decl_stmt|;
if|if
condition|(
name|partitionColumnCount
operator|>
literal|0
condition|)
block|{
name|partitionValues
operator|=
operator|new
name|Object
index|[
name|partitionColumnCount
index|]
expr_stmt|;
name|VectorizedRowBatchCtx
operator|.
name|getPartitionValues
argument_list|(
name|rbCtx
argument_list|,
name|mapWork
argument_list|,
name|split
argument_list|,
name|partitionValues
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partitionValues
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|isVectorized
operator|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|jobConf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_VECTORIZATION_ENABLED
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAcidScan
condition|)
block|{
name|this
operator|.
name|acidReader
operator|=
operator|new
name|VectorizedOrcAcidRowBatchReader
argument_list|(
operator|(
name|OrcSplit
operator|)
name|split
argument_list|,
name|jobConf
argument_list|,
name|Reporter
operator|.
name|NULL
argument_list|,
literal|null
argument_list|,
name|rbCtx
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Create the consumer of encoded data; it will coordinate decoding to CVBs.
name|feedback
operator|=
name|rp
operator|=
name|cvp
operator|.
name|createReadPipeline
argument_list|(
name|this
argument_list|,
name|split
argument_list|,
name|includes
argument_list|,
name|sarg
argument_list|,
name|counters
argument_list|,
name|includes
argument_list|,
name|sourceInputFormat
argument_list|,
name|sourceSerDe
argument_list|,
name|reporter
argument_list|,
name|job
argument_list|,
name|mapWork
operator|.
name|getPathToPartitionInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|int
name|getQueueVar
parameter_list|(
name|ConfVars
name|var
parameter_list|,
name|JobConf
name|jobConf
parameter_list|,
name|Configuration
name|daemonConf
parameter_list|)
block|{
comment|// Check job config for overrides, otherwise use the default server value.
name|int
name|jobVal
init|=
name|jobConf
operator|.
name|getInt
argument_list|(
name|var
operator|.
name|varname
argument_list|,
operator|-
literal|1
argument_list|)
decl_stmt|;
return|return
operator|(
name|jobVal
operator|!=
operator|-
literal|1
operator|)
condition|?
name|jobVal
else|:
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|daemonConf
argument_list|,
name|var
argument_list|)
return|;
block|}
comment|// For queue size estimation purposes, we assume all columns have weight one, and the following
comment|// types are counted as multiple columns. This is very primitive; if we wanted to make it better,
comment|// we'd increase the base limit, and adjust dynamically based on IO and processing perf delays.
specifier|private
specifier|static
specifier|final
name|int
name|COL_WEIGHT_COMPLEX
init|=
literal|16
decl_stmt|,
name|COL_WEIGHT_HIVEDECIMAL
init|=
literal|4
decl_stmt|,
name|COL_WEIGHT_STRING
init|=
literal|8
decl_stmt|;
specifier|private
specifier|static
name|int
name|determineQueueLimit
parameter_list|(
name|int
name|queueLimitBase
parameter_list|,
name|int
name|queueLimitMin
parameter_list|,
name|TypeInfo
index|[]
name|typeInfos
parameter_list|,
specifier|final
name|boolean
name|decimal64Support
parameter_list|)
block|{
comment|// If the values are equal, the queue limit is fixed.
if|if
condition|(
name|queueLimitBase
operator|==
name|queueLimitMin
condition|)
return|return
name|queueLimitBase
return|;
comment|// If there are no columns (projection only join?) just assume no weight.
if|if
condition|(
name|typeInfos
operator|==
literal|null
operator|||
name|typeInfos
operator|.
name|length
operator|==
literal|0
condition|)
return|return
name|queueLimitBase
return|;
name|double
name|totalWeight
init|=
literal|0
decl_stmt|;
for|for
control|(
name|TypeInfo
name|ti
range|:
name|typeInfos
control|)
block|{
name|int
name|colWeight
decl_stmt|;
if|if
condition|(
name|ti
operator|.
name|getCategory
argument_list|()
operator|!=
name|Category
operator|.
name|PRIMITIVE
condition|)
block|{
name|colWeight
operator|=
name|COL_WEIGHT_COMPLEX
expr_stmt|;
block|}
else|else
block|{
name|PrimitiveTypeInfo
name|pti
init|=
operator|(
name|PrimitiveTypeInfo
operator|)
name|ti
decl_stmt|;
switch|switch
condition|(
name|pti
operator|.
name|getPrimitiveCategory
argument_list|()
condition|)
block|{
case|case
name|BINARY
case|:
case|case
name|CHAR
case|:
case|case
name|VARCHAR
case|:
case|case
name|STRING
case|:
name|colWeight
operator|=
name|COL_WEIGHT_STRING
expr_stmt|;
break|break;
case|case
name|DECIMAL
case|:
name|boolean
name|useDecimal64
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|ti
operator|instanceof
name|DecimalTypeInfo
condition|)
block|{
name|DecimalTypeInfo
name|dti
init|=
operator|(
name|DecimalTypeInfo
operator|)
name|ti
decl_stmt|;
if|if
condition|(
name|dti
operator|.
name|getPrecision
argument_list|()
operator|<=
name|TypeDescription
operator|.
name|MAX_DECIMAL64_PRECISION
operator|&&
name|decimal64Support
condition|)
block|{
name|useDecimal64
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|// decimal_64 column vectors gets the same weight as long column vectors
if|if
condition|(
name|useDecimal64
condition|)
block|{
name|colWeight
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|colWeight
operator|=
name|COL_WEIGHT_HIVEDECIMAL
expr_stmt|;
block|}
break|break;
default|default:
name|colWeight
operator|=
literal|1
expr_stmt|;
block|}
block|}
name|totalWeight
operator|+=
name|colWeight
expr_stmt|;
block|}
return|return
name|Math
operator|.
name|max
argument_list|(
name|queueLimitMin
argument_list|,
call|(
name|int
call|)
argument_list|(
name|queueLimitBase
operator|/
name|totalWeight
argument_list|)
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|MapWork
name|findMapWork
parameter_list|(
name|JobConf
name|job
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
name|inputName
init|=
name|job
operator|.
name|get
argument_list|(
name|Utilities
operator|.
name|INPUT_NAME
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initializing for input "
operator|+
name|inputName
argument_list|)
expr_stmt|;
block|}
name|String
name|prefixes
init|=
name|job
operator|.
name|get
argument_list|(
name|DagUtils
operator|.
name|TEZ_MERGE_WORK_FILE_PREFIXES
argument_list|)
decl_stmt|;
if|if
condition|(
name|prefixes
operator|!=
literal|null
operator|&&
operator|!
name|StringUtils
operator|.
name|isBlank
argument_list|(
name|prefixes
argument_list|)
condition|)
block|{
comment|// Currently SMB is broken, so we cannot check if it's  compatible with IO elevator.
comment|// So, we don't use the below code that would get the correct MapWork. See HIVE-16985.
return|return
literal|null
return|;
block|}
name|BaseWork
name|work
init|=
literal|null
decl_stmt|;
comment|// HIVE-16985: try to find the fake merge work for SMB join, that is really another MapWork.
if|if
condition|(
name|inputName
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|prefixes
operator|==
literal|null
operator|||
operator|!
name|Lists
operator|.
name|newArrayList
argument_list|(
name|prefixes
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
operator|.
name|contains
argument_list|(
name|inputName
argument_list|)
condition|)
block|{
name|inputName
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|inputName
operator|!=
literal|null
condition|)
block|{
name|work
operator|=
name|Utilities
operator|.
name|getMergeWork
argument_list|(
name|job
argument_list|,
name|inputName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|work
operator|==
literal|null
operator|||
operator|!
operator|(
name|work
operator|instanceof
name|MapWork
operator|)
condition|)
block|{
name|work
operator|=
name|Utilities
operator|.
name|getMapWork
argument_list|(
name|job
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|MapWork
operator|)
name|work
return|;
block|}
comment|/**    * Starts the data read pipeline    */
specifier|public
name|void
name|start
parameter_list|()
block|{
comment|// perform the data read asynchronously
if|if
condition|(
name|executor
operator|instanceof
name|StatsRecordingThreadPool
condition|)
block|{
comment|// Every thread created by this thread pool will use the same handler
operator|(
operator|(
name|StatsRecordingThreadPool
operator|)
name|executor
operator|)
operator|.
name|setUncaughtExceptionHandler
argument_list|(
operator|new
name|IOUncaughtExceptionHandler
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|executor
operator|.
name|submit
argument_list|(
name|rp
operator|.
name|getReadCallable
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|boolean
name|checkOrcSchemaEvolution
parameter_list|()
block|{
name|SchemaEvolution
name|evolution
init|=
name|rp
operator|.
name|getSchemaEvolution
argument_list|()
decl_stmt|;
if|if
condition|(
name|evolution
operator|.
name|hasConversion
argument_list|()
operator|&&
operator|!
name|evolution
operator|.
name|isOnlyImplicitConversion
argument_list|()
condition|)
block|{
comment|// We do not support data type conversion when reading encoded ORC data.
return|return
literal|false
return|;
block|}
comment|// TODO: should this just use physical IDs?
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|includes
operator|.
name|getReaderLogicalColumnIds
argument_list|()
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|int
name|projectedColId
init|=
name|includes
operator|.
name|getReaderLogicalColumnIds
argument_list|()
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// Adjust file column index for ORC struct.
name|int
name|fileColId
init|=
name|OrcInputFormat
operator|.
name|getRootColumn
argument_list|(
operator|!
name|isAcidScan
argument_list|)
operator|+
name|projectedColId
operator|+
literal|1
decl_stmt|;
if|if
condition|(
operator|!
name|evolution
operator|.
name|isPPDSafeConversion
argument_list|(
name|fileColId
argument_list|)
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unsupported schema evolution! Disabling Llap IO for {}"
argument_list|,
name|split
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|NullWritable
name|key
parameter_list|,
name|VectorizedRowBatch
name|vrb
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|vrb
operator|!=
literal|null
assert|;
if|if
condition|(
name|isClosed
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"next called after close"
argument_list|)
throw|;
block|}
comment|// Add partition cols if necessary (see VectorizedOrcInputFormat for details).
name|boolean
name|wasFirst
init|=
name|isFirst
decl_stmt|;
if|if
condition|(
name|isFirst
condition|)
block|{
if|if
condition|(
name|partitionValues
operator|!=
literal|null
condition|)
block|{
name|rbCtx
operator|.
name|addPartitionColsToBatch
argument_list|(
name|vrb
argument_list|,
name|partitionValues
argument_list|)
expr_stmt|;
block|}
name|isFirst
operator|=
literal|false
expr_stmt|;
block|}
name|ColumnVectorBatch
name|cvb
init|=
literal|null
decl_stmt|;
try|try
block|{
name|cvb
operator|=
name|nextCvb
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Query might have been canceled. Stop the background processing.
name|feedback
operator|.
name|stop
argument_list|()
expr_stmt|;
name|isInterrupted
operator|=
literal|true
expr_stmt|;
comment|// In case we are stuck in consume.
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|cvb
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|wasFirst
condition|)
block|{
name|firstReturnTime
operator|=
name|counters
operator|.
name|startTimeCounter
argument_list|()
expr_stmt|;
block|}
name|counters
operator|.
name|incrTimeCounter
argument_list|(
name|LlapIOCounters
operator|.
name|CONSUMER_TIME_NS
argument_list|,
name|firstReturnTime
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|isAcidScan
condition|)
block|{
name|vrb
operator|.
name|selectedInUse
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|isVectorized
condition|)
block|{
comment|// TODO: relying everywhere on the magical constants and columns being together means ACID
comment|//       columns are going to be super hard to change in a backward compat manner. I can
comment|//       foresee someone cursing while refactoring all the magic for prefix schema changes.
comment|// Exclude the row column.
name|int
name|acidColCount
init|=
name|OrcInputFormat
operator|.
name|getRootColumn
argument_list|(
literal|false
argument_list|)
operator|-
literal|1
decl_stmt|;
name|VectorizedRowBatch
name|inputVrb
init|=
operator|new
name|VectorizedRowBatch
argument_list|(
name|acidColCount
operator|+
literal|1
operator|+
name|vrb
operator|.
name|getDataColumnCount
argument_list|()
argument_list|)
decl_stmt|;
comment|// By assumption, ACID columns are currently always in the beginning of the arrays.
name|System
operator|.
name|arraycopy
argument_list|(
name|cvb
operator|.
name|cols
argument_list|,
literal|0
argument_list|,
name|inputVrb
operator|.
name|cols
argument_list|,
literal|0
argument_list|,
name|acidColCount
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|ixInReadSet
init|=
name|acidColCount
init|;
name|ixInReadSet
operator|<
name|cvb
operator|.
name|cols
operator|.
name|length
condition|;
operator|++
name|ixInReadSet
control|)
block|{
name|int
name|ixInVrb
init|=
name|includes
operator|.
name|getPhysicalColumnIds
argument_list|()
operator|.
name|get
argument_list|(
name|ixInReadSet
argument_list|)
decl_stmt|;
comment|// TODO: should we create the batch from vrbctx, and reuse the vectors, like below? Future work.
name|inputVrb
operator|.
name|cols
index|[
name|ixInVrb
index|]
operator|=
name|cvb
operator|.
name|cols
index|[
name|ixInReadSet
index|]
expr_stmt|;
block|}
name|inputVrb
operator|.
name|size
operator|=
name|cvb
operator|.
name|size
expr_stmt|;
name|acidReader
operator|.
name|setBaseAndInnerReader
argument_list|(
operator|new
name|AcidWrapper
argument_list|(
name|inputVrb
argument_list|)
argument_list|)
expr_stmt|;
name|acidReader
operator|.
name|next
argument_list|(
name|NullWritable
operator|.
name|get
argument_list|()
argument_list|,
name|vrb
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// TODO: WTF? The old code seems to just drop the ball here.
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unsupported mode"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|includes
operator|.
name|getPhysicalColumnIds
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|cvb
operator|.
name|cols
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected number of columns, VRB has "
operator|+
name|includes
operator|.
name|getPhysicalColumnIds
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|" included, but the reader returned "
operator|+
name|cvb
operator|.
name|cols
operator|.
name|length
argument_list|)
throw|;
block|}
comment|// VRB was created from VrbCtx, so we already have pre-allocated column vectors.
comment|// Return old CVs (if any) to caller. We assume these things all have the same schema.
for|for
control|(
name|int
name|ixInReadSet
init|=
literal|0
init|;
name|ixInReadSet
operator|<
name|cvb
operator|.
name|cols
operator|.
name|length
condition|;
operator|++
name|ixInReadSet
control|)
block|{
name|int
name|ixInVrb
init|=
name|includes
operator|.
name|getPhysicalColumnIds
argument_list|()
operator|.
name|get
argument_list|(
name|ixInReadSet
argument_list|)
decl_stmt|;
name|cvb
operator|.
name|swapColumnVector
argument_list|(
name|ixInReadSet
argument_list|,
name|vrb
operator|.
name|cols
argument_list|,
name|ixInVrb
argument_list|)
expr_stmt|;
block|}
name|vrb
operator|.
name|selectedInUse
operator|=
literal|false
expr_stmt|;
name|vrb
operator|.
name|size
operator|=
name|cvb
operator|.
name|size
expr_stmt|;
block|}
if|if
condition|(
name|wasFirst
condition|)
block|{
name|firstReturnTime
operator|=
name|counters
operator|.
name|startTimeCounter
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
name|VectorizedRowBatchCtx
name|getVectorizedRowBatchCtx
parameter_list|()
block|{
return|return
name|rbCtx
return|;
block|}
specifier|private
specifier|static
specifier|final
class|class
name|AcidWrapper
implements|implements
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|VectorizedRowBatch
argument_list|>
block|{
specifier|private
specifier|final
name|VectorizedRowBatch
name|acidVrb
decl_stmt|;
specifier|private
name|AcidWrapper
parameter_list|(
name|VectorizedRowBatch
name|acidVrb
parameter_list|)
block|{
name|this
operator|.
name|acidVrb
operator|=
name|acidVrb
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|NullWritable
name|key
parameter_list|,
name|VectorizedRowBatch
name|value
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|NullWritable
name|createKey
parameter_list|()
block|{
return|return
name|NullWritable
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|VectorizedRowBatch
name|createValue
parameter_list|()
block|{
return|return
name|acidVrb
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{     }
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|0
return|;
block|}
block|}
specifier|private
specifier|final
class|class
name|IOUncaughtExceptionHandler
implements|implements
name|Thread
operator|.
name|UncaughtExceptionHandler
block|{
annotation|@
name|Override
specifier|public
name|void
name|uncaughtException
parameter_list|(
specifier|final
name|Thread
name|t
parameter_list|,
specifier|final
name|Throwable
name|e
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Unhandled error from reader thread. threadName: {} threadId: {}"
operator|+
literal|" Message: {}"
argument_list|,
name|t
operator|.
name|getName
argument_list|()
argument_list|,
name|t
operator|.
name|getId
argument_list|()
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|setError
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"IOUncaughtExceptionHandler interrupted; ignoring"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|ColumnVectorBatch
name|nextCvb
parameter_list|()
throws|throws
name|InterruptedException
throws|,
name|IOException
block|{
name|boolean
name|isFirst
init|=
operator|(
name|lastCvb
operator|==
literal|null
operator|)
decl_stmt|;
if|if
condition|(
operator|!
name|isFirst
condition|)
block|{
name|feedback
operator|.
name|returnData
argument_list|(
name|lastCvb
argument_list|)
expr_stmt|;
block|}
comment|// We are waiting for next block. Either we will get it, or be told we are done.
name|int
name|queueSize
init|=
name|queue
operator|.
name|size
argument_list|()
decl_stmt|;
name|maxQueueSize
operator|=
name|Math
operator|.
name|max
argument_list|(
name|queueSize
argument_list|,
name|maxQueueSize
argument_list|)
expr_stmt|;
name|boolean
name|doLogBlocking
init|=
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
operator|&&
name|queueSize
operator|==
literal|0
decl_stmt|;
if|if
condition|(
name|doLogBlocking
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"next will block"
argument_list|)
expr_stmt|;
block|}
comment|// We rely on the fact that poll() checks interrupt even when there's something in the queue.
comment|// If the structure is replaced with smth that doesn't, we MUST check interrupt here because
comment|// Hive operators rely on recordreader to handle task interruption, and unlike most RRs we
comment|// do not do any blocking IO ops on this thread.
name|Object
name|next
init|=
literal|null
decl_stmt|;
do|do
block|{
name|rethrowErrorIfAny
argument_list|(
name|pendingError
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
comment|// Best-effort check; see the comment in the method.
name|next
operator|=
name|queue
operator|.
name|poll
argument_list|(
literal|100
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|next
operator|==
literal|null
condition|)
do|;
if|if
condition|(
name|doLogBlocking
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"next is unblocked"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|next
operator|==
name|DONE_OBJECT
condition|)
block|{
return|return
literal|null
return|;
comment|// We are done.
block|}
if|if
condition|(
name|next
operator|instanceof
name|Throwable
condition|)
block|{
name|rethrowErrorIfAny
argument_list|(
operator|(
name|Throwable
operator|)
name|next
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unreachable"
argument_list|)
throw|;
block|}
name|lastCvb
operator|=
operator|(
name|ColumnVectorBatch
operator|)
name|next
expr_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Processing will receive vector {}"
argument_list|,
name|lastCvb
argument_list|)
expr_stmt|;
block|}
return|return
name|lastCvb
return|;
block|}
annotation|@
name|Override
specifier|public
name|NullWritable
name|createKey
parameter_list|()
block|{
return|return
name|NullWritable
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|VectorizedRowBatch
name|createValue
parameter_list|()
block|{
return|return
name|rbCtx
operator|.
name|createVectorizedRowBatch
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|-
literal|1
return|;
comment|// Position doesn't make sense for async reader, chunk order is arbitrary.
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"close called; closed {}, interrupted {}, err {}, pending {}"
argument_list|,
name|isClosed
argument_list|,
name|isInterrupted
argument_list|,
name|pendingError
operator|.
name|get
argument_list|()
argument_list|,
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Maximum queue length observed "
operator|+
name|maxQueueSize
argument_list|)
expr_stmt|;
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Llap counters: {}"
argument_list|,
name|counters
argument_list|)
expr_stmt|;
comment|// This is where counters are logged!
name|feedback
operator|.
name|stop
argument_list|()
expr_stmt|;
name|isClosed
operator|=
literal|true
expr_stmt|;
name|rethrowErrorIfAny
argument_list|(
name|pendingError
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|MDC
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|rethrowErrorIfAny
parameter_list|(
name|Throwable
name|pendingError
parameter_list|)
throws|throws
name|IOException
block|{
comment|// This is called either with an error that was queued, or an error that was set into the
comment|// atomic reference in this class. The latter is best-effort and is used to opportunistically
comment|// skip processing of a long queue when the error happens.
if|if
condition|(
name|pendingError
operator|==
literal|null
condition|)
return|return;
if|if
condition|(
name|pendingError
operator|instanceof
name|IOException
condition|)
block|{
throw|throw
operator|(
name|IOException
operator|)
name|pendingError
throw|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
name|pendingError
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setDone
parameter_list|()
throws|throws
name|InterruptedException
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"setDone called; closed {}, interrupted {}, err {}, pending {}"
argument_list|,
name|isClosed
argument_list|,
name|isInterrupted
argument_list|,
name|pendingError
operator|.
name|get
argument_list|()
argument_list|,
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|enqueueInternal
argument_list|(
name|DONE_OBJECT
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|consumeData
parameter_list|(
name|ColumnVectorBatch
name|data
parameter_list|)
throws|throws
name|InterruptedException
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"consume called; closed {}, interrupted {}, err {}, pending {}"
argument_list|,
name|isClosed
argument_list|,
name|isInterrupted
argument_list|,
name|pendingError
operator|.
name|get
argument_list|()
argument_list|,
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|enqueueInternal
argument_list|(
name|data
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setError
parameter_list|(
name|Throwable
name|t
parameter_list|)
throws|throws
name|InterruptedException
block|{
name|counters
operator|.
name|incrCounter
argument_list|(
name|LlapIOCounters
operator|.
name|NUM_ERRORS
argument_list|)
expr_stmt|;
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"setError called; closed {}, interrupted {},  err {}, pending {}"
argument_list|,
name|isClosed
argument_list|,
name|isInterrupted
argument_list|,
name|pendingError
operator|.
name|get
argument_list|()
argument_list|,
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"setError called with an error"
argument_list|,
name|t
argument_list|)
expr_stmt|;
assert|assert
name|t
operator|!=
literal|null
assert|;
name|pendingError
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|t
argument_list|)
expr_stmt|;
name|enqueueInternal
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|enqueueInternal
parameter_list|(
name|Object
name|o
parameter_list|)
throws|throws
name|InterruptedException
block|{
comment|// We need to loop here to handle the case where consumer goes away.
do|do
block|{}
do|while
condition|(
operator|!
name|isClosed
operator|&&
operator|!
name|isInterrupted
operator|&&
operator|!
name|queue
operator|.
name|offer
argument_list|(
name|o
argument_list|,
literal|100
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
do|;
block|}
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
comment|// TODO: plumb progress info thru the reader if we can get metadata from loader first.
return|return
literal|0.0f
return|;
block|}
comment|/** This class encapsulates include-related logic for LLAP readers. It is not actually specific    *  to LLAP IO but in LLAP IO in particular, I want to encapsulate all this mess for now until    *  we have smth better like Schema Evolution v2. This can also hypothetically encapsulate    *  field pruning inside structs and stuff like that. */
specifier|private
specifier|static
class|class
name|IncludesImpl
implements|implements
name|SchemaEvolutionFactory
implements|,
name|Includes
block|{
specifier|private
name|List
argument_list|<
name|Integer
argument_list|>
name|readerLogicalColumnIds
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Integer
argument_list|>
name|filePhysicalColumnIds
decl_stmt|;
specifier|private
name|Integer
name|acidStructColumnId
init|=
literal|null
decl_stmt|;
comment|// For current schema evolution.
specifier|private
name|TypeDescription
name|readerSchema
decl_stmt|;
specifier|private
name|JobConf
name|jobConf
decl_stmt|;
specifier|public
name|IncludesImpl
parameter_list|(
name|List
argument_list|<
name|Integer
argument_list|>
name|tableIncludedCols
parameter_list|,
name|boolean
name|isAcidScan
parameter_list|,
name|VectorizedRowBatchCtx
name|rbCtx
parameter_list|,
name|TypeDescription
name|readerSchema
parameter_list|,
name|JobConf
name|jobConf
parameter_list|)
block|{
comment|// Note: columnIds below makes additional changes for ACID. Don't use this var directly.
name|this
operator|.
name|readerSchema
operator|=
name|readerSchema
expr_stmt|;
name|this
operator|.
name|jobConf
operator|=
name|jobConf
expr_stmt|;
if|if
condition|(
name|tableIncludedCols
operator|==
literal|null
condition|)
block|{
comment|// Assume including everything means the VRB will have everything.
comment|// TODO: this is rather brittle, esp. in view of schema evolution (in abstract, not as
comment|//       currently implemented in Hive). The compile should supply the columns it expects
comment|//       to see, which is not "all, of any schema". Is VRB row CVs the right mechanism
comment|//       for that? Who knows. Perhaps resolve in schema evolution v2.
name|tableIncludedCols
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|rbCtx
operator|.
name|getRowColumnTypeInfos
argument_list|()
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rbCtx
operator|.
name|getRowColumnTypeInfos
argument_list|()
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|tableIncludedCols
operator|.
name|add
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Logical table includes: {}"
argument_list|,
name|tableIncludedCols
argument_list|)
expr_stmt|;
name|this
operator|.
name|readerLogicalColumnIds
operator|=
name|tableIncludedCols
expr_stmt|;
comment|// Note: schema evolution currently does not support column index changes.
comment|//       So, the indices should line up... to be fixed in SE v2?
name|List
argument_list|<
name|Integer
argument_list|>
name|filePhysicalColumnIds
init|=
name|readerLogicalColumnIds
decl_stmt|;
if|if
condition|(
name|isAcidScan
condition|)
block|{
name|int
name|rootCol
init|=
name|OrcInputFormat
operator|.
name|getRootColumn
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|filePhysicalColumnIds
operator|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|(
name|filePhysicalColumnIds
operator|.
name|size
argument_list|()
operator|+
name|rootCol
argument_list|)
expr_stmt|;
name|this
operator|.
name|acidStructColumnId
operator|=
name|rootCol
operator|-
literal|1
expr_stmt|;
comment|// OrcRecordUpdater.ROW. This is somewhat fragile...
comment|// Note: this guarantees that physical column IDs are in order.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rootCol
condition|;
operator|++
name|i
control|)
block|{
comment|// We don't want to include the root struct in ACID case; it would cause the whole
comment|// struct to get read without projection.
if|if
condition|(
name|acidStructColumnId
operator|==
name|i
condition|)
continue|continue;
name|filePhysicalColumnIds
operator|.
name|add
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|tableColumnId
range|:
name|readerLogicalColumnIds
control|)
block|{
name|filePhysicalColumnIds
operator|.
name|add
argument_list|(
name|rootCol
operator|+
name|tableColumnId
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|filePhysicalColumnIds
operator|=
name|filePhysicalColumnIds
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"logical columns "
operator|+
name|readerLogicalColumnIds
operator|+
literal|", physical columns "
operator|+
name|filePhysicalColumnIds
return|;
block|}
annotation|@
name|Override
specifier|public
name|SchemaEvolution
name|createSchemaEvolution
parameter_list|(
name|TypeDescription
name|fileSchema
parameter_list|)
block|{
if|if
condition|(
name|readerSchema
operator|==
literal|null
condition|)
block|{
name|readerSchema
operator|=
name|fileSchema
expr_stmt|;
block|}
comment|// TODO: will this work correctly with ACID?
name|boolean
index|[]
name|readerIncludes
init|=
name|OrcInputFormat
operator|.
name|genIncludedColumns
argument_list|(
name|readerSchema
argument_list|,
name|readerLogicalColumnIds
argument_list|)
decl_stmt|;
name|Reader
operator|.
name|Options
name|options
init|=
operator|new
name|Reader
operator|.
name|Options
argument_list|(
name|jobConf
argument_list|)
operator|.
name|include
argument_list|(
name|readerIncludes
argument_list|)
decl_stmt|;
return|return
operator|new
name|SchemaEvolution
argument_list|(
name|fileSchema
argument_list|,
name|readerSchema
argument_list|,
name|options
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
index|[]
name|generateFileIncludes
parameter_list|(
name|TypeDescription
name|fileSchema
parameter_list|)
block|{
return|return
name|OrcInputFormat
operator|.
name|genIncludedColumns
argument_list|(
name|fileSchema
argument_list|,
name|filePhysicalColumnIds
argument_list|,
name|acidStructColumnId
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Integer
argument_list|>
name|getPhysicalColumnIds
parameter_list|()
block|{
return|return
name|filePhysicalColumnIds
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Integer
argument_list|>
name|getReaderLogicalColumnIds
parameter_list|()
block|{
return|return
name|readerLogicalColumnIds
return|;
block|}
annotation|@
name|Override
specifier|public
name|TypeDescription
index|[]
name|getBatchReaderTypes
parameter_list|(
name|TypeDescription
name|fileSchema
parameter_list|)
block|{
return|return
name|OrcInputFormat
operator|.
name|genIncludedTypes
argument_list|(
name|fileSchema
argument_list|,
name|filePhysicalColumnIds
argument_list|,
name|acidStructColumnId
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

