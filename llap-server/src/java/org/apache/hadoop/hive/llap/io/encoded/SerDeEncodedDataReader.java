begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|encoded
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedExceptionAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|Pool
operator|.
name|PoolObjectHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DataCache
operator|.
name|BooleanRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DiskRangeList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DataCache
operator|.
name|DiskRangeListFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|encoded
operator|.
name|EncodedColumnBatch
operator|.
name|ColumnStreamData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|encoded
operator|.
name|MemoryBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|ConsumerFeedback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|DebugUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|cache
operator|.
name|BufferUsageManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|cache
operator|.
name|LlapDataBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|cache
operator|.
name|LowLevelCache
operator|.
name|Priority
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|cache
operator|.
name|SerDeLowLevelCacheImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|cache
operator|.
name|SerDeLowLevelCacheImpl
operator|.
name|FileData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|cache
operator|.
name|SerDeLowLevelCacheImpl
operator|.
name|StripeData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|counters
operator|.
name|LlapIOCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|counters
operator|.
name|QueryFragmentCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|api
operator|.
name|impl
operator|.
name|LlapIoImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|GenericColumnVectorProducer
operator|.
name|SerDeStripeMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|decode
operator|.
name|OrcEncodedDataConsumer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|encoded
operator|.
name|SerDeEncodedDataReader
operator|.
name|CacheWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|io
operator|.
name|encoded
operator|.
name|VertorDeserializeOrcWriter
operator|.
name|AsyncCallback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|ColumnVector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedRowBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HdfsUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcFile
operator|.
name|WriterOptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Writer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|CacheChunk
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|Reader
operator|.
name|OrcEncodedColumnBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|LineRecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SplitLocationInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|FixedSizedObjectPool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|Ref
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionKind
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcFile
operator|.
name|EncodingStrategy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcFile
operator|.
name|Version
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
operator|.
name|ColumnEncoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|TypeDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OutStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|PhysicalWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|PhysicalWriter
operator|.
name|OutputReceiver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|SchemaEvolution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|StreamName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|common
operator|.
name|CallableWithNdc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|common
operator|.
name|counters
operator|.
name|TezCounters
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_class
specifier|public
class|class
name|SerDeEncodedDataReader
extends|extends
name|CallableWithNdc
argument_list|<
name|Void
argument_list|>
implements|implements
name|ConsumerFeedback
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
block|{
specifier|public
specifier|static
specifier|final
name|FixedSizedObjectPool
argument_list|<
name|ColumnStreamData
argument_list|>
name|CSD_POOL
init|=
operator|new
name|FixedSizedObjectPool
argument_list|<>
argument_list|(
literal|8192
argument_list|,
operator|new
name|PoolObjectHelper
argument_list|<
name|ColumnStreamData
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|ColumnStreamData
name|create
parameter_list|()
block|{
return|return
operator|new
name|ColumnStreamData
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|resetBeforeOffer
parameter_list|(
name|ColumnStreamData
name|t
parameter_list|)
block|{
name|t
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|FixedSizedObjectPool
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
name|ECB_POOL
init|=
operator|new
name|FixedSizedObjectPool
argument_list|<>
argument_list|(
literal|1024
argument_list|,
operator|new
name|PoolObjectHelper
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|OrcEncodedColumnBatch
name|create
parameter_list|()
block|{
return|return
operator|new
name|OrcEncodedColumnBatch
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|resetBeforeOffer
parameter_list|(
name|OrcEncodedColumnBatch
name|t
parameter_list|)
block|{
name|t
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|FixedSizedObjectPool
argument_list|<
name|CacheChunk
argument_list|>
name|TCC_POOL
init|=
operator|new
name|FixedSizedObjectPool
argument_list|<>
argument_list|(
literal|1024
argument_list|,
operator|new
name|PoolObjectHelper
argument_list|<
name|CacheChunk
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|CacheChunk
name|create
parameter_list|()
block|{
return|return
operator|new
name|CacheChunk
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|resetBeforeOffer
parameter_list|(
name|CacheChunk
name|t
parameter_list|)
block|{
name|t
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
argument_list|)
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|DiskRangeListFactory
name|CC_FACTORY
init|=
operator|new
name|DiskRangeListFactory
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DiskRangeList
name|createCacheChunk
parameter_list|(
name|MemoryBuffer
name|buffer
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|end
parameter_list|)
block|{
name|CacheChunk
name|tcc
init|=
name|TCC_POOL
operator|.
name|take
argument_list|()
decl_stmt|;
name|tcc
operator|.
name|init
argument_list|(
name|buffer
argument_list|,
name|offset
argument_list|,
name|end
argument_list|)
expr_stmt|;
return|return
name|tcc
return|;
block|}
block|}
decl_stmt|;
specifier|private
specifier|final
name|SerDeLowLevelCacheImpl
name|cache
decl_stmt|;
specifier|private
specifier|final
name|BufferUsageManager
name|bufferManager
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|daemonConf
decl_stmt|;
specifier|private
specifier|final
name|FileSplit
name|split
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Integer
argument_list|>
name|columnIds
decl_stmt|;
specifier|private
specifier|final
name|OrcEncodedDataConsumer
name|consumer
decl_stmt|;
specifier|private
specifier|final
name|QueryFragmentCounters
name|counters
decl_stmt|;
specifier|private
specifier|final
name|UserGroupInformation
name|ugi
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|Path
argument_list|,
name|PartitionDesc
argument_list|>
name|parts
decl_stmt|;
specifier|private
specifier|final
name|Object
name|fileKey
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|isStopped
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|Deserializer
name|sourceSerDe
decl_stmt|;
specifier|private
specifier|final
name|InputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|sourceInputFormat
decl_stmt|;
specifier|private
specifier|final
name|Reporter
name|reporter
decl_stmt|;
specifier|private
specifier|final
name|JobConf
name|jobConf
decl_stmt|;
specifier|private
specifier|final
name|TypeDescription
name|schema
decl_stmt|;
specifier|private
specifier|final
name|int
name|allocSize
decl_stmt|;
specifier|private
specifier|final
name|int
name|targetSliceRowCount
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isLrrEnabled
decl_stmt|;
specifier|private
specifier|final
name|boolean
index|[]
name|writerIncludes
decl_stmt|;
specifier|private
name|FileReaderYieldReturn
name|currentFileRead
init|=
literal|null
decl_stmt|;
comment|/**    * Data from cache currently being processed. We store it here so that we could decref    * it in case of failures. We remove each slice from the data after it has been sent to    * the consumer, at which point the consumer is responsible for it.    */
specifier|private
name|FileData
name|cachedData
decl_stmt|;
specifier|private
name|List
argument_list|<
name|VertorDeserializeOrcWriter
argument_list|>
name|asyncWriters
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|public
name|SerDeEncodedDataReader
parameter_list|(
name|SerDeLowLevelCacheImpl
name|cache
parameter_list|,
name|BufferUsageManager
name|bufferManager
parameter_list|,
name|Configuration
name|daemonConf
parameter_list|,
name|FileSplit
name|split
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|columnIds
parameter_list|,
name|OrcEncodedDataConsumer
name|consumer
parameter_list|,
name|JobConf
name|jobConf
parameter_list|,
name|Reporter
name|reporter
parameter_list|,
name|InputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|sourceInputFormat
parameter_list|,
name|Deserializer
name|sourceSerDe
parameter_list|,
name|QueryFragmentCounters
name|counters
parameter_list|,
name|TypeDescription
name|schema
parameter_list|,
name|Map
argument_list|<
name|Path
argument_list|,
name|PartitionDesc
argument_list|>
name|parts
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|cache
operator|=
name|cache
expr_stmt|;
name|this
operator|.
name|bufferManager
operator|=
name|bufferManager
expr_stmt|;
name|this
operator|.
name|parts
operator|=
name|parts
expr_stmt|;
name|this
operator|.
name|daemonConf
operator|=
operator|new
name|Configuration
argument_list|(
name|daemonConf
argument_list|)
expr_stmt|;
comment|// Disable dictionary encoding for the writer.
name|this
operator|.
name|daemonConf
operator|.
name|setDouble
argument_list|(
name|OrcConf
operator|.
name|DICTIONARY_KEY_SIZE_THRESHOLD
operator|.
name|name
argument_list|()
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|split
operator|=
name|split
expr_stmt|;
name|this
operator|.
name|columnIds
operator|=
name|columnIds
expr_stmt|;
name|this
operator|.
name|allocSize
operator|=
name|determineAllocSize
argument_list|(
name|bufferManager
argument_list|,
name|daemonConf
argument_list|)
expr_stmt|;
name|boolean
name|isInTest
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|daemonConf
argument_list|,
name|ConfVars
operator|.
name|HIVE_IN_TEST
argument_list|)
decl_stmt|;
name|Configuration
name|sliceConf
init|=
name|isInTest
condition|?
name|jobConf
else|:
name|daemonConf
decl_stmt|;
name|this
operator|.
name|targetSliceRowCount
operator|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|sliceConf
argument_list|,
name|ConfVars
operator|.
name|LLAP_IO_ENCODE_SLICE_ROW_COUNT
argument_list|)
expr_stmt|;
name|this
operator|.
name|isLrrEnabled
operator|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|sliceConf
argument_list|,
name|ConfVars
operator|.
name|LLAP_IO_ENCODE_SLICE_LRR
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|columnIds
operator|!=
literal|null
condition|)
block|{
name|Collections
operator|.
name|sort
argument_list|(
name|this
operator|.
name|columnIds
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|consumer
operator|=
name|consumer
expr_stmt|;
name|this
operator|.
name|counters
operator|=
name|counters
expr_stmt|;
try|try
block|{
name|this
operator|.
name|ugi
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|fs
operator|=
name|split
operator|.
name|getPath
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|daemonConf
argument_list|)
expr_stmt|;
name|fileKey
operator|=
name|determineFileId
argument_list|(
name|fs
argument_list|,
name|split
argument_list|,
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|daemonConf
argument_list|,
name|ConfVars
operator|.
name|LLAP_CACHE_ALLOW_SYNTHETIC_FILEID
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|sourceInputFormat
operator|=
name|sourceInputFormat
expr_stmt|;
name|this
operator|.
name|sourceSerDe
operator|=
name|sourceSerDe
expr_stmt|;
name|this
operator|.
name|reporter
operator|=
name|reporter
expr_stmt|;
name|this
operator|.
name|jobConf
operator|=
name|jobConf
expr_stmt|;
name|this
operator|.
name|schema
operator|=
name|schema
expr_stmt|;
name|this
operator|.
name|writerIncludes
operator|=
name|OrcInputFormat
operator|.
name|genIncludedColumns
argument_list|(
name|schema
argument_list|,
name|columnIds
argument_list|)
expr_stmt|;
name|SchemaEvolution
name|evolution
init|=
operator|new
name|SchemaEvolution
argument_list|(
name|schema
argument_list|,
operator|new
name|Reader
operator|.
name|Options
argument_list|(
name|jobConf
argument_list|)
operator|.
name|include
argument_list|(
name|writerIncludes
argument_list|)
argument_list|)
decl_stmt|;
name|consumer
operator|.
name|setSchemaEvolution
argument_list|(
name|evolution
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|int
name|determineAllocSize
parameter_list|(
name|BufferUsageManager
name|bufferManager
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|long
name|allocSize
init|=
name|HiveConf
operator|.
name|getSizeVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|LLAP_IO_ENCODE_ALLOC_SIZE
argument_list|)
decl_stmt|;
name|int
name|maxAllocSize
init|=
name|bufferManager
operator|.
name|getAllocator
argument_list|()
operator|.
name|getMaxAllocation
argument_list|()
decl_stmt|;
if|if
condition|(
name|allocSize
operator|>
name|maxAllocSize
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Encode allocation size "
operator|+
name|allocSize
operator|+
literal|" is being capped to the maximum "
operator|+
literal|"allocation size "
operator|+
name|bufferManager
operator|.
name|getAllocator
argument_list|()
operator|.
name|getMaxAllocation
argument_list|()
argument_list|)
expr_stmt|;
name|allocSize
operator|=
name|maxAllocSize
expr_stmt|;
block|}
return|return
operator|(
name|int
operator|)
name|allocSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|stop
parameter_list|()
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Encoded reader is being stopped"
argument_list|)
expr_stmt|;
name|isStopped
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|pause
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|unpause
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
block|}
comment|// TODO: move to a base class?
annotation|@
name|Override
specifier|protected
name|Void
name|callInternal
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|performDataRead
argument_list|()
return|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/** A row-based (Writable) reader that may also be able to report file offsets. */
interface|interface
name|ReaderWithOffsets
block|{
comment|/** Moves the reader to the next row. */
name|boolean
name|next
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/** Gets the current row. */
name|Writable
name|getCurrentRow
parameter_list|()
function_decl|;
comment|/** Closes the reader. */
name|void
name|close
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/** Whether this reader actually supports offsets. */
name|boolean
name|hasOffsets
parameter_list|()
function_decl|;
comment|/** Gets the start offset of the current row, or -1 if unknown. */
name|long
name|getCurrentRowStartOffset
parameter_list|()
function_decl|;
comment|/** Gets the end offset of the current row, or -1 if unknown. */
name|long
name|getCurrentRowEndOffset
parameter_list|()
function_decl|;
block|}
specifier|public
specifier|static
class|class
name|CacheWriter
implements|implements
name|PhysicalWriter
block|{
comment|// Struct.
specifier|private
specifier|static
class|class
name|CacheStreamData
block|{
specifier|private
specifier|final
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|data
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isSuppressed
decl_stmt|;
specifier|private
specifier|final
name|StreamName
name|name
decl_stmt|;
specifier|public
name|CacheStreamData
parameter_list|(
name|boolean
name|isSuppressed
parameter_list|,
name|StreamName
name|name
parameter_list|,
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|data
parameter_list|)
block|{
name|this
operator|.
name|isSuppressed
operator|=
name|isSuppressed
expr_stmt|;
name|this
operator|.
name|name
operator|=
name|name
expr_stmt|;
name|this
operator|.
name|data
operator|=
name|data
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"CacheStreamData [name="
operator|+
name|name
operator|+
literal|", isSuppressed="
operator|+
name|isSuppressed
operator|+
literal|", data="
operator|+
name|toString
argument_list|(
name|data
argument_list|)
operator|+
literal|"]"
return|;
block|}
specifier|private
specifier|static
name|String
name|toString
parameter_list|(
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|data
parameter_list|)
block|{
name|String
name|s
init|=
literal|""
decl_stmt|;
for|for
control|(
name|MemoryBuffer
name|buffer
range|:
name|data
control|)
block|{
name|s
operator|+=
name|LlapDataBuffer
operator|.
name|toDataString
argument_list|(
name|buffer
argument_list|)
operator|+
literal|", "
expr_stmt|;
block|}
return|return
name|s
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|CacheStripeData
block|{
specifier|private
name|List
argument_list|<
name|ColumnEncoding
argument_list|>
name|encodings
decl_stmt|;
specifier|private
name|long
name|rowCount
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|long
name|knownTornStart
decl_stmt|,
name|firstRowStart
decl_stmt|,
name|lastRowStart
decl_stmt|,
name|lastRowEnd
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|CacheStreamData
argument_list|>
argument_list|>
name|colStreams
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
operator|(
literal|"{disk data knownTornStart="
operator|+
name|knownTornStart
operator|+
literal|", firstRowStart="
operator|+
name|firstRowStart
operator|+
literal|", lastRowStart="
operator|+
name|lastRowStart
operator|+
literal|", lastRowEnd="
operator|+
name|lastRowEnd
operator|+
literal|", rowCount="
operator|+
name|rowCount
operator|+
literal|", encodings="
operator|+
name|encodings
operator|+
literal|", streams="
operator|+
name|colStreams
operator|+
literal|"}"
operator|)
operator|.
name|replace
argument_list|(
literal|'\n'
argument_list|,
literal|' '
argument_list|)
return|;
block|}
specifier|public
name|String
name|toCoordinateString
parameter_list|()
block|{
return|return
literal|"knownTornStart="
operator|+
name|knownTornStart
operator|+
literal|", firstRowStart="
operator|+
name|firstRowStart
operator|+
literal|", lastRowStart="
operator|+
name|lastRowStart
operator|+
literal|", lastRowEnd="
operator|+
name|lastRowEnd
return|;
block|}
block|}
specifier|private
name|CacheStripeData
name|currentStripe
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|CacheStripeData
argument_list|>
name|stripes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|BufferUsageManager
name|bufferManager
decl_stmt|;
comment|/**      * For !doesSourceHaveIncludes case, stores global column IDs to verify writer columns.      * For doesSourceHaveIncludes case, stores source column IDs used to map things.      */
specifier|private
specifier|final
name|List
argument_list|<
name|Integer
argument_list|>
name|columnIds
decl_stmt|;
specifier|private
specifier|final
name|boolean
index|[]
name|writerIncludes
decl_stmt|;
comment|// These are global since ORC reuses objects between stripes.
specifier|private
specifier|final
name|Map
argument_list|<
name|StreamName
argument_list|,
name|OutputReceiver
argument_list|>
name|streams
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|CacheOutputReceiver
argument_list|>
argument_list|>
name|colStreams
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|doesSourceHaveIncludes
decl_stmt|;
specifier|public
name|CacheWriter
parameter_list|(
name|BufferUsageManager
name|bufferManager
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|columnIds
parameter_list|,
name|boolean
index|[]
name|writerIncludes
parameter_list|,
name|boolean
name|doesSourceHaveIncludes
parameter_list|)
block|{
name|this
operator|.
name|bufferManager
operator|=
name|bufferManager
expr_stmt|;
assert|assert
name|writerIncludes
operator|!=
literal|null
assert|;
comment|// Taken care of on higher level.
name|this
operator|.
name|writerIncludes
operator|=
name|writerIncludes
expr_stmt|;
name|this
operator|.
name|doesSourceHaveIncludes
operator|=
name|doesSourceHaveIncludes
expr_stmt|;
name|this
operator|.
name|columnIds
operator|=
name|columnIds
expr_stmt|;
name|startStripe
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|startStripe
parameter_list|()
block|{
if|if
condition|(
name|currentStripe
operator|!=
literal|null
condition|)
block|{
name|stripes
operator|.
name|add
argument_list|(
name|currentStripe
argument_list|)
expr_stmt|;
block|}
name|currentStripe
operator|=
operator|new
name|CacheStripeData
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|writeFileMetadata
parameter_list|(
name|OrcProto
operator|.
name|Metadata
operator|.
name|Builder
name|builder
parameter_list|)
throws|throws
name|IOException
block|{     }
annotation|@
name|Override
specifier|public
name|void
name|writeFileFooter
parameter_list|(
name|OrcProto
operator|.
name|Footer
operator|.
name|Builder
name|builder
parameter_list|)
throws|throws
name|IOException
block|{
name|OrcProto
operator|.
name|Footer
name|footer
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
name|validateIncludes
argument_list|(
name|footer
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|validateIncludes
parameter_list|(
name|OrcProto
operator|.
name|Footer
name|footer
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|doesSourceHaveIncludes
condition|)
return|return;
comment|// Irrelevant.
name|boolean
index|[]
name|translatedIncludes
init|=
name|columnIds
operator|==
literal|null
condition|?
literal|null
else|:
name|OrcInputFormat
operator|.
name|genIncludedColumns
argument_list|(
name|OrcUtils
operator|.
name|convertTypeFromProtobuf
argument_list|(
name|footer
operator|.
name|getTypesList
argument_list|()
argument_list|,
literal|0
argument_list|)
argument_list|,
name|columnIds
argument_list|)
decl_stmt|;
if|if
condition|(
name|translatedIncludes
operator|==
literal|null
condition|)
block|{
name|throwIncludesMismatchError
argument_list|(
name|translatedIncludes
argument_list|)
expr_stmt|;
block|}
name|int
name|len
init|=
name|Math
operator|.
name|min
argument_list|(
name|translatedIncludes
operator|.
name|length
argument_list|,
name|writerIncludes
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|len
condition|;
operator|++
name|i
control|)
block|{
comment|// Translated includes may be a superset of writer includes due to cache.
if|if
condition|(
operator|!
name|translatedIncludes
index|[
name|i
index|]
operator|&&
name|writerIncludes
index|[
name|i
index|]
condition|)
block|{
name|throwIncludesMismatchError
argument_list|(
name|translatedIncludes
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|translatedIncludes
operator|.
name|length
operator|<
name|writerIncludes
operator|.
name|length
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
name|len
init|;
name|i
operator|<
name|writerIncludes
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|writerIncludes
index|[
name|i
index|]
condition|)
block|{
name|throwIncludesMismatchError
argument_list|(
name|translatedIncludes
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|String
name|throwIncludesMismatchError
parameter_list|(
name|boolean
index|[]
name|translated
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|s
init|=
literal|"Includes derived from the original table: "
operator|+
name|DebugUtils
operator|.
name|toString
argument_list|(
name|writerIncludes
argument_list|)
operator|+
literal|" but the ones derived from writer types are: "
operator|+
name|DebugUtils
operator|.
name|toString
argument_list|(
name|translated
argument_list|)
decl_stmt|;
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
name|s
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|s
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|writePostScript
parameter_list|(
name|OrcProto
operator|.
name|PostScript
operator|.
name|Builder
name|builder
parameter_list|)
block|{
return|return
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Closed from ORC writer, we still need the data. Do not discard anything.
block|}
specifier|public
name|void
name|discardData
parameter_list|()
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Discarding disk data (if any wasn't cached)"
argument_list|)
expr_stmt|;
for|for
control|(
name|CacheStripeData
name|stripe
range|:
name|stripes
control|)
block|{
if|if
condition|(
name|stripe
operator|.
name|colStreams
operator|==
literal|null
operator|||
name|stripe
operator|.
name|colStreams
operator|.
name|isEmpty
argument_list|()
condition|)
continue|continue;
for|for
control|(
name|List
argument_list|<
name|CacheStreamData
argument_list|>
name|streams
range|:
name|stripe
operator|.
name|colStreams
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|CacheStreamData
name|cos
range|:
name|streams
control|)
block|{
for|for
control|(
name|MemoryBuffer
name|buffer
range|:
name|cos
operator|.
name|data
control|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|trace
argument_list|(
literal|"Deallocating "
operator|+
name|buffer
argument_list|)
expr_stmt|;
block|}
name|bufferManager
operator|.
name|getAllocator
argument_list|()
operator|.
name|deallocate
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|stripe
operator|.
name|colStreams
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|OutputReceiver
name|createDataStream
parameter_list|(
name|StreamName
name|name
parameter_list|)
throws|throws
name|IOException
block|{
name|OutputReceiver
name|or
init|=
name|streams
operator|.
name|get
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|or
operator|!=
literal|null
condition|)
return|return
name|or
return|;
if|if
condition|(
name|isNeeded
argument_list|(
name|name
argument_list|)
condition|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Creating cache receiver for "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
name|CacheOutputReceiver
name|cor
init|=
operator|new
name|CacheOutputReceiver
argument_list|(
name|bufferManager
argument_list|,
name|name
argument_list|)
decl_stmt|;
name|or
operator|=
name|cor
expr_stmt|;
name|List
argument_list|<
name|CacheOutputReceiver
argument_list|>
name|list
init|=
name|colStreams
operator|.
name|get
argument_list|(
name|name
operator|.
name|getColumn
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|colStreams
operator|.
name|put
argument_list|(
name|name
operator|.
name|getColumn
argument_list|()
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
name|list
operator|.
name|add
argument_list|(
name|cor
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Creating null receiver for "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
name|or
operator|=
operator|new
name|NullOutputReceiver
argument_list|(
name|name
argument_list|)
expr_stmt|;
block|}
name|streams
operator|.
name|put
argument_list|(
name|name
argument_list|,
name|or
argument_list|)
expr_stmt|;
return|return
name|or
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|writeHeader
parameter_list|()
throws|throws
name|IOException
block|{     }
annotation|@
name|Override
specifier|public
name|void
name|writeIndex
parameter_list|(
name|StreamName
name|name
parameter_list|,
name|OrcProto
operator|.
name|RowIndex
operator|.
name|Builder
name|index
parameter_list|,
name|CompressionCodec
name|codec
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: right now we treat each slice as a stripe with a single RG and never bother
comment|//       with indexes. In phase 4, we need to add indexing and filtering.
block|}
annotation|@
name|Override
specifier|public
name|void
name|writeBloomFilter
parameter_list|(
name|StreamName
name|name
parameter_list|,
name|OrcProto
operator|.
name|BloomFilterIndex
operator|.
name|Builder
name|bloom
parameter_list|,
name|CompressionCodec
name|codec
parameter_list|)
throws|throws
name|IOException
block|{     }
annotation|@
name|Override
specifier|public
name|void
name|finalizeStripe
parameter_list|(
name|OrcProto
operator|.
name|StripeFooter
operator|.
name|Builder
name|footer
parameter_list|,
name|OrcProto
operator|.
name|StripeInformation
operator|.
name|Builder
name|dirEntry
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|ColumnEncoding
argument_list|>
name|allEnc
init|=
name|footer
operator|.
name|getColumnsList
argument_list|()
decl_stmt|;
name|OrcProto
operator|.
name|StripeInformation
name|si
init|=
name|dirEntry
operator|.
name|build
argument_list|()
decl_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
operator|(
literal|"Finalizing stripe "
operator|+
name|footer
operator|.
name|build
argument_list|()
operator|+
literal|" => "
operator|+
name|si
operator|)
operator|.
name|replace
argument_list|(
literal|'\n'
argument_list|,
literal|' '
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|doesSourceHaveIncludes
condition|)
block|{
name|currentStripe
operator|.
name|encodings
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|writerIncludes
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|writerIncludes
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|currentStripe
operator|.
name|encodings
operator|.
name|add
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|currentStripe
operator|.
name|encodings
operator|.
name|set
argument_list|(
literal|0
argument_list|,
name|allEnc
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|allEnc
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|int
name|colIx
init|=
name|getSparseOrcIndexFromDenseDest
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// LlapIoImpl.LOG.info("Setting enc " + i + "; " + colIx + " to " + allEnc.get(i));
name|currentStripe
operator|.
name|encodings
operator|.
name|set
argument_list|(
name|colIx
argument_list|,
name|allEnc
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|currentStripe
operator|.
name|encodings
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|allEnc
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|currentStripe
operator|.
name|encodings
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
comment|// Don't record encodings for unneeded columns.
if|if
condition|(
name|writerIncludes
index|[
name|i
index|]
condition|)
continue|continue;
name|currentStripe
operator|.
name|encodings
operator|.
name|set
argument_list|(
name|i
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
name|currentStripe
operator|.
name|rowCount
operator|=
name|si
operator|.
name|getNumberOfRows
argument_list|()
expr_stmt|;
comment|// ORC writer reuses streams, so we need to clean them here and extract data.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|CacheOutputReceiver
argument_list|>
argument_list|>
name|e
range|:
name|colStreams
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|colIx
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|CacheOutputReceiver
argument_list|>
name|streams
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|CacheStreamData
argument_list|>
name|data
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|streams
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|CacheOutputReceiver
name|receiver
range|:
name|streams
control|)
block|{
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|buffers
init|=
name|receiver
operator|.
name|buffers
decl_stmt|;
if|if
condition|(
name|buffers
operator|==
literal|null
condition|)
block|{
comment|// This can happen e.g. for a data stream when all the values are null.
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Buffers are null for "
operator|+
name|receiver
operator|.
name|name
argument_list|)
expr_stmt|;
block|}
name|data
operator|.
name|add
argument_list|(
operator|new
name|CacheStreamData
argument_list|(
name|receiver
operator|.
name|suppressed
argument_list|,
name|receiver
operator|.
name|name
argument_list|,
name|buffers
operator|==
literal|null
condition|?
operator|new
name|ArrayList
argument_list|<
name|MemoryBuffer
argument_list|>
argument_list|()
else|:
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|buffers
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|receiver
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|doesSourceHaveIncludes
condition|)
block|{
name|int
name|newColIx
init|=
name|getSparseOrcIndexFromDenseDest
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Mapping the ORC writer column "
operator|+
name|colIx
operator|+
literal|" to "
operator|+
name|newColIx
argument_list|)
expr_stmt|;
block|}
name|colIx
operator|=
name|newColIx
expr_stmt|;
block|}
name|currentStripe
operator|.
name|colStreams
operator|.
name|put
argument_list|(
name|colIx
argument_list|,
name|data
argument_list|)
expr_stmt|;
block|}
name|startStripe
argument_list|()
expr_stmt|;
block|}
specifier|private
name|int
name|getSparseOrcIndexFromDenseDest
parameter_list|(
name|int
name|denseColIx
parameter_list|)
block|{
comment|// denseColIx is index in ORC writer with includes. We -1 to skip the root column; get the
comment|// original text file index; then add the root column again. This makes many assumptions.
comment|// Also this only works for primitive types; vectordeserializer only supports these anyway.
comment|// The mapping for complex types with sub-cols in ORC would be much more difficult to build.
return|return
name|columnIds
operator|.
name|get
argument_list|(
name|denseColIx
operator|-
literal|1
argument_list|)
operator|+
literal|1
return|;
block|}
specifier|private
name|boolean
name|isNeeded
parameter_list|(
name|StreamName
name|name
parameter_list|)
block|{
return|return
name|doesSourceHaveIncludes
operator|||
name|writerIncludes
index|[
name|name
operator|.
name|getColumn
argument_list|()
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|flush
parameter_list|()
throws|throws
name|IOException
block|{     }
annotation|@
name|Override
specifier|public
name|void
name|appendRawStripe
parameter_list|(
name|ByteBuffer
name|stripe
parameter_list|,
name|OrcProto
operator|.
name|StripeInformation
operator|.
name|Builder
name|dirEntry
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
comment|// Only used in ACID writer.
block|}
specifier|public
name|void
name|setCurrentStripeOffsets
parameter_list|(
name|long
name|currentKnownTornStart
parameter_list|,
name|long
name|firstStartOffset
parameter_list|,
name|long
name|lastStartOffset
parameter_list|,
name|long
name|currentFileOffset
parameter_list|)
block|{
name|currentStripe
operator|.
name|knownTornStart
operator|=
name|currentKnownTornStart
expr_stmt|;
name|currentStripe
operator|.
name|firstRowStart
operator|=
name|firstStartOffset
expr_stmt|;
name|currentStripe
operator|.
name|lastRowStart
operator|=
name|lastStartOffset
expr_stmt|;
name|currentStripe
operator|.
name|lastRowEnd
operator|=
name|currentFileOffset
expr_stmt|;
block|}
block|}
specifier|private
interface|interface
name|CacheOutput
block|{
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|getData
parameter_list|()
function_decl|;
name|StreamName
name|getName
parameter_list|()
function_decl|;
block|}
specifier|private
specifier|static
specifier|final
class|class
name|CacheOutputReceiver
implements|implements
name|CacheOutput
implements|,
name|OutputReceiver
block|{
specifier|private
specifier|final
name|BufferUsageManager
name|bufferManager
decl_stmt|;
specifier|private
specifier|final
name|StreamName
name|name
decl_stmt|;
specifier|private
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|buffers
init|=
literal|null
decl_stmt|;
specifier|private
name|int
name|lastBufferPos
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|boolean
name|suppressed
init|=
literal|false
decl_stmt|;
specifier|public
name|CacheOutputReceiver
parameter_list|(
name|BufferUsageManager
name|bufferManager
parameter_list|,
name|StreamName
name|name
parameter_list|)
block|{
name|this
operator|.
name|bufferManager
operator|=
name|bufferManager
expr_stmt|;
name|this
operator|.
name|name
operator|=
name|name
expr_stmt|;
block|}
specifier|public
name|void
name|clear
parameter_list|()
block|{
name|buffers
operator|=
literal|null
expr_stmt|;
name|lastBufferPos
operator|=
operator|-
literal|1
expr_stmt|;
name|suppressed
operator|=
literal|false
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|suppress
parameter_list|()
block|{
name|suppressed
operator|=
literal|true
expr_stmt|;
name|lastBufferPos
operator|=
operator|-
literal|1
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|output
parameter_list|(
name|ByteBuffer
name|buffer
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: avoid put() by working directly in OutStream?
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
name|name
operator|+
literal|" receiving a buffer of size "
operator|+
name|buffer
operator|.
name|remaining
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|int
name|size
init|=
name|buffer
operator|.
name|remaining
argument_list|()
decl_stmt|;
name|ByteBuffer
name|bb
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|buffers
operator|==
literal|null
condition|)
block|{
name|buffers
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|buffers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|MemoryBuffer
name|lastBuffer
init|=
name|buffers
operator|.
name|get
argument_list|(
name|buffers
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|bb
operator|=
name|lastBuffer
operator|.
name|getByteBufferRaw
argument_list|()
expr_stmt|;
name|int
name|written
init|=
name|lastBufferPos
operator|-
name|bb
operator|.
name|position
argument_list|()
decl_stmt|;
if|if
condition|(
name|bb
operator|.
name|remaining
argument_list|()
operator|-
name|written
operator|<
name|size
condition|)
block|{
name|lastBufferPos
operator|=
operator|-
literal|1
expr_stmt|;
name|bb
operator|=
literal|null
expr_stmt|;
block|}
block|}
name|boolean
name|isNewBuffer
init|=
operator|(
name|lastBufferPos
operator|==
operator|-
literal|1
operator|)
decl_stmt|;
if|if
condition|(
name|isNewBuffer
condition|)
block|{
name|MemoryBuffer
index|[]
name|dest
init|=
operator|new
name|MemoryBuffer
index|[
literal|1
index|]
decl_stmt|;
name|bufferManager
operator|.
name|getAllocator
argument_list|()
operator|.
name|allocateMultiple
argument_list|(
name|dest
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|LlapDataBuffer
name|newBuffer
init|=
operator|(
name|LlapDataBuffer
operator|)
name|dest
index|[
literal|0
index|]
decl_stmt|;
name|bb
operator|=
name|newBuffer
operator|.
name|getByteBufferRaw
argument_list|()
expr_stmt|;
name|lastBufferPos
operator|=
name|bb
operator|.
name|position
argument_list|()
expr_stmt|;
name|buffers
operator|.
name|add
argument_list|(
name|newBuffer
argument_list|)
expr_stmt|;
block|}
comment|// Since there's no close() here, maintain the initial read position between writes.
name|int
name|pos
init|=
name|bb
operator|.
name|position
argument_list|()
decl_stmt|;
name|bb
operator|.
name|position
argument_list|(
name|lastBufferPos
argument_list|)
expr_stmt|;
name|bb
operator|.
name|put
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|lastBufferPos
operator|=
name|bb
operator|.
name|position
argument_list|()
expr_stmt|;
name|bb
operator|.
name|position
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|getData
parameter_list|()
block|{
return|return
name|buffers
return|;
block|}
annotation|@
name|Override
specifier|public
name|StreamName
name|getName
parameter_list|()
block|{
return|return
name|name
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|NullOutputReceiver
implements|implements
name|OutputReceiver
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unused"
argument_list|)
specifier|private
specifier|final
name|StreamName
name|name
decl_stmt|;
specifier|public
name|NullOutputReceiver
parameter_list|(
name|StreamName
name|name
parameter_list|)
block|{
name|this
operator|.
name|name
operator|=
name|name
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|output
parameter_list|(
name|ByteBuffer
name|buffer
parameter_list|)
throws|throws
name|IOException
block|{     }
annotation|@
name|Override
specifier|public
name|void
name|suppress
parameter_list|()
block|{     }
block|}
specifier|protected
name|Void
name|performDataRead
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|isOk
init|=
literal|false
decl_stmt|;
try|try
block|{
try|try
block|{
name|long
name|startTime
init|=
name|counters
operator|.
name|startTimeCounter
argument_list|()
decl_stmt|;
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Processing data for {}"
argument_list|,
name|split
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|processStop
argument_list|()
condition|)
block|{
name|recordReaderTime
argument_list|(
name|startTime
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|Boolean
name|isFromCache
init|=
literal|null
decl_stmt|;
try|try
block|{
name|isFromCache
operator|=
name|readFileWithCache
argument_list|(
name|startTime
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// Note that the code removes the data from the field as it's passed to the consumer,
comment|// so we expect to have stuff remaining in there only in case of errors.
if|if
condition|(
name|cachedData
operator|!=
literal|null
operator|&&
name|cachedData
operator|.
name|getData
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|StripeData
name|sd
range|:
name|cachedData
operator|.
name|getData
argument_list|()
control|)
block|{
name|unlockAllBuffers
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
name|cachedData
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|isFromCache
operator|==
literal|null
condition|)
return|return
literal|null
return|;
comment|// Stop requested, and handled inside.
if|if
condition|(
operator|!
name|isFromCache
condition|)
block|{
if|if
condition|(
operator|!
name|processOneFileSplit
argument_list|(
name|split
argument_list|,
name|startTime
argument_list|,
name|Ref
operator|.
name|from
argument_list|(
literal|0
argument_list|)
argument_list|,
literal|null
argument_list|)
condition|)
return|return
literal|null
return|;
block|}
comment|// Done with all the things.
name|recordReaderTime
argument_list|(
name|startTime
argument_list|)
expr_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"done processing {}"
argument_list|,
name|split
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while processing"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|setError
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|consumer
operator|.
name|setDone
argument_list|()
expr_stmt|;
name|isOk
operator|=
literal|true
expr_stmt|;
return|return
literal|null
return|;
block|}
finally|finally
block|{
name|cleanup
argument_list|(
operator|!
name|isOk
argument_list|)
expr_stmt|;
comment|// Do not clean up the writers - the callback should do it.
block|}
block|}
specifier|private
name|void
name|unlockAllBuffers
parameter_list|(
name|StripeData
name|si
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|si
operator|.
name|getData
argument_list|()
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|LlapDataBuffer
index|[]
index|[]
name|colData
init|=
name|si
operator|.
name|getData
argument_list|()
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|colData
operator|==
literal|null
condition|)
continue|continue;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|colData
operator|.
name|length
condition|;
operator|++
name|j
control|)
block|{
name|LlapDataBuffer
index|[]
name|streamData
init|=
name|colData
index|[
name|j
index|]
decl_stmt|;
if|if
condition|(
name|streamData
operator|==
literal|null
condition|)
continue|continue;
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|streamData
operator|.
name|length
condition|;
operator|++
name|k
control|)
block|{
name|bufferManager
operator|.
name|decRefBuffer
argument_list|(
name|streamData
index|[
name|k
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|public
name|void
name|cacheFileData
parameter_list|(
name|StripeData
name|sd
parameter_list|)
block|{
if|if
condition|(
name|sd
operator|==
literal|null
operator|||
name|sd
operator|.
name|getEncodings
argument_list|()
operator|==
literal|null
condition|)
return|return;
if|if
condition|(
name|fileKey
operator|!=
literal|null
condition|)
block|{
comment|// Note that we cache each slice separately. We could cache them together at the end, but
comment|// then we won't be able to pass them to users without inc-refing explicitly.
name|ColumnEncoding
index|[]
name|encodings
init|=
name|sd
operator|.
name|getEncodings
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|encodings
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
comment|// Make data consistent with encodings, don't store useless information.
if|if
condition|(
name|sd
operator|.
name|getData
argument_list|()
index|[
name|i
index|]
operator|==
literal|null
condition|)
block|{
name|encodings
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|encodings
index|[
name|i
index|]
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Caching data without an encoding at "
operator|+
name|i
operator|+
literal|": "
operator|+
name|sd
argument_list|)
throw|;
block|}
block|}
name|FileData
name|fd
init|=
operator|new
name|FileData
argument_list|(
name|fileKey
argument_list|,
name|encodings
operator|.
name|length
argument_list|)
decl_stmt|;
name|fd
operator|.
name|addStripe
argument_list|(
name|sd
argument_list|)
expr_stmt|;
name|cache
operator|.
name|putFileData
argument_list|(
name|fd
argument_list|,
name|Priority
operator|.
name|NORMAL
argument_list|,
name|counters
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|lockAllBuffers
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
comment|// We assume that if put/lock throws in the middle, it's ok to treat buffers as not being
comment|// locked and to blindly deallocate them, since they are not going to be used. Therefore
comment|// we don't remove them from the cleanup list - we will do it after sending to consumer.
comment|// This relies on sequence of calls to cacheFileData and sendEcb..
block|}
specifier|private
name|void
name|lockAllBuffers
parameter_list|(
name|StripeData
name|sd
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|sd
operator|.
name|getData
argument_list|()
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|LlapDataBuffer
index|[]
index|[]
name|colData
init|=
name|sd
operator|.
name|getData
argument_list|()
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|colData
operator|==
literal|null
condition|)
continue|continue;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|colData
operator|.
name|length
condition|;
operator|++
name|j
control|)
block|{
name|LlapDataBuffer
index|[]
name|streamData
init|=
name|colData
index|[
name|j
index|]
decl_stmt|;
if|if
condition|(
name|streamData
operator|==
literal|null
condition|)
continue|continue;
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|streamData
operator|.
name|length
condition|;
operator|++
name|k
control|)
block|{
name|boolean
name|canLock
init|=
name|bufferManager
operator|.
name|incRefBuffer
argument_list|(
name|streamData
index|[
name|k
index|]
argument_list|)
decl_stmt|;
assert|assert
name|canLock
assert|;
block|}
block|}
block|}
block|}
specifier|public
name|Boolean
name|readFileWithCache
parameter_list|(
name|long
name|startTime
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fileKey
operator|==
literal|null
condition|)
return|return
literal|false
return|;
name|BooleanRef
name|gotAllData
init|=
operator|new
name|BooleanRef
argument_list|()
decl_stmt|;
name|long
name|endOfSplit
init|=
name|split
operator|.
name|getStart
argument_list|()
operator|+
name|split
operator|.
name|getLength
argument_list|()
decl_stmt|;
name|this
operator|.
name|cachedData
operator|=
name|cache
operator|.
name|getFileData
argument_list|(
name|fileKey
argument_list|,
name|split
operator|.
name|getStart
argument_list|()
argument_list|,
name|endOfSplit
argument_list|,
name|writerIncludes
argument_list|,
name|CC_FACTORY
argument_list|,
name|counters
argument_list|,
name|gotAllData
argument_list|)
expr_stmt|;
if|if
condition|(
name|cachedData
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|trace
argument_list|(
literal|"No data for the split found in cache"
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
name|String
index|[]
name|hosts
init|=
name|extractHosts
argument_list|(
name|split
argument_list|,
literal|false
argument_list|)
decl_stmt|,
name|inMemoryHosts
init|=
name|extractHosts
argument_list|(
name|split
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|StripeData
argument_list|>
name|slices
init|=
name|cachedData
operator|.
name|getData
argument_list|()
decl_stmt|;
if|if
condition|(
name|slices
operator|.
name|isEmpty
argument_list|()
condition|)
return|return
literal|false
return|;
name|long
name|uncachedPrefixEnd
init|=
name|slices
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getKnownTornStart
argument_list|()
decl_stmt|,
name|uncachedSuffixStart
init|=
name|slices
operator|.
name|get
argument_list|(
name|slices
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|.
name|getLastEnd
argument_list|()
decl_stmt|;
name|Ref
argument_list|<
name|Integer
argument_list|>
name|stripeIx
init|=
name|Ref
operator|.
name|from
argument_list|(
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|uncachedPrefixEnd
operator|>
name|split
operator|.
name|getStart
argument_list|()
condition|)
block|{
comment|// TODO: can we merge neighboring splits? So we don't init so many readers.
name|FileSplit
name|sliceSplit
init|=
operator|new
name|FileSplit
argument_list|(
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|split
operator|.
name|getStart
argument_list|()
argument_list|,
name|uncachedPrefixEnd
operator|-
name|split
operator|.
name|getStart
argument_list|()
argument_list|,
name|hosts
argument_list|,
name|inMemoryHosts
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|processOneFileSplit
argument_list|(
name|sliceSplit
argument_list|,
name|startTime
argument_list|,
name|stripeIx
argument_list|,
literal|null
argument_list|)
condition|)
return|return
literal|null
return|;
block|}
while|while
condition|(
operator|!
name|slices
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|StripeData
name|slice
init|=
name|slices
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|long
name|start
init|=
name|slice
operator|.
name|getKnownTornStart
argument_list|()
decl_stmt|;
name|long
name|len
init|=
name|slice
operator|.
name|getLastStart
argument_list|()
operator|-
name|start
decl_stmt|;
comment|// Will also read the last row.
name|FileSplit
name|sliceSplit
init|=
operator|new
name|FileSplit
argument_list|(
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|start
argument_list|,
name|len
argument_list|,
name|hosts
argument_list|,
name|inMemoryHosts
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|processOneFileSplit
argument_list|(
name|sliceSplit
argument_list|,
name|startTime
argument_list|,
name|stripeIx
argument_list|,
name|slice
argument_list|)
condition|)
return|return
literal|null
return|;
block|}
name|boolean
name|isUnfortunate
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|uncachedSuffixStart
operator|==
name|endOfSplit
condition|)
block|{
comment|// This is rather obscure. The end of last row cached is precisely at the split end offset.
comment|// If the split is in the middle of the file, LRR would read one more row after that,
comment|// therefore as unfortunate as it is, we have to do a one-row read. However, for that to
comment|// have happened, someone should have supplied a split that ends inside the last row, i.e.
comment|// a few bytes earlier than the current split, which is pretty unlikely. What is more likely
comment|// is that the split, and the last row, both end at the end of file. Check for this.
name|long
name|size
init|=
name|split
operator|.
name|getPath
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|daemonConf
argument_list|)
operator|.
name|getFileStatus
argument_list|(
name|split
operator|.
name|getPath
argument_list|()
argument_list|)
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|isUnfortunate
operator|=
name|size
operator|>
name|endOfSplit
expr_stmt|;
if|if
condition|(
name|isUnfortunate
condition|)
block|{
comment|// Log at warn, given how unfortunate this is.
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"One-row mismatch at the end of split "
operator|+
name|split
operator|.
name|getPath
argument_list|()
operator|+
literal|" at "
operator|+
name|endOfSplit
operator|+
literal|"; file size is "
operator|+
name|size
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|uncachedSuffixStart
operator|<
name|endOfSplit
operator|||
name|isUnfortunate
condition|)
block|{
comment|// Note: we assume 0-length split is correct given now LRR interprets offsets (reading an
comment|// extra row). Should we instead assume 1+ chars and add 1 for isUnfortunate?
name|FileSplit
name|splitPart
init|=
operator|new
name|FileSplit
argument_list|(
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|uncachedSuffixStart
argument_list|,
name|endOfSplit
operator|-
name|uncachedSuffixStart
argument_list|,
name|hosts
argument_list|,
name|inMemoryHosts
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|processOneFileSplit
argument_list|(
name|splitPart
argument_list|,
name|startTime
argument_list|,
name|stripeIx
argument_list|,
literal|null
argument_list|)
condition|)
return|return
literal|null
return|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
name|boolean
name|processOneFileSplit
parameter_list|(
name|FileSplit
name|split
parameter_list|,
name|long
name|startTime
parameter_list|,
name|Ref
argument_list|<
name|Integer
argument_list|>
name|stripeIxRef
parameter_list|,
name|StripeData
name|slice
parameter_list|)
throws|throws
name|IOException
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Processing one split {"
operator|+
name|split
operator|.
name|getPath
argument_list|()
operator|+
literal|", "
operator|+
name|split
operator|.
name|getStart
argument_list|()
operator|+
literal|", "
operator|+
name|split
operator|.
name|getLength
argument_list|()
operator|+
literal|"}"
argument_list|)
expr_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|trace
argument_list|(
literal|"Cache data for the split is "
operator|+
name|slice
argument_list|)
expr_stmt|;
block|}
name|boolean
index|[]
name|splitIncludes
init|=
name|Arrays
operator|.
name|copyOf
argument_list|(
name|writerIncludes
argument_list|,
name|writerIncludes
operator|.
name|length
argument_list|)
decl_stmt|;
name|boolean
name|hasAllData
init|=
name|slice
operator|!=
literal|null
operator|&&
name|determineSplitIncludes
argument_list|(
name|slice
argument_list|,
name|splitIncludes
argument_list|,
name|writerIncludes
argument_list|)
decl_stmt|;
comment|// We have 3 cases here:
comment|// 1) All the data is in the cache. Always a single slice, no disk read, no cache puts.
comment|// 2) Some data is in the cache. Always a single slice, disk read and a single cache put.
comment|// 3) No data is in the cache. Multiple slices, disk read and multiple cache puts.
if|if
condition|(
name|hasAllData
condition|)
block|{
comment|// Everything comes from cache.
name|CacheWriter
operator|.
name|CacheStripeData
name|csd
init|=
literal|null
decl_stmt|;
name|boolean
name|result
init|=
name|processOneSlice
argument_list|(
name|csd
argument_list|,
name|splitIncludes
argument_list|,
name|stripeIxRef
operator|.
name|value
argument_list|,
name|slice
argument_list|,
name|startTime
argument_list|)
decl_stmt|;
operator|++
name|stripeIxRef
operator|.
name|value
expr_stmt|;
return|return
name|result
return|;
block|}
name|boolean
name|result
init|=
literal|false
decl_stmt|;
comment|// This initializes currentFileRead.
name|startReadSplitFromFile
argument_list|(
name|split
argument_list|,
name|splitIncludes
argument_list|,
name|slice
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|slice
operator|!=
literal|null
condition|)
block|{
comment|// If we had a cache range already, we expect a single matching disk slice.
name|Vectors
name|vectors
init|=
name|currentFileRead
operator|.
name|readNextSlice
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|vectors
operator|.
name|isSupported
argument_list|()
condition|)
block|{
comment|// Not in VRB mode - the new cache data is ready, we should use it.
name|CacheWriter
name|cacheWriter
init|=
name|currentFileRead
operator|.
name|getCacheWriter
argument_list|()
decl_stmt|;
assert|assert
name|cacheWriter
operator|.
name|stripes
operator|.
name|size
argument_list|()
operator|==
literal|1
assert|;
name|result
operator|=
name|processOneSlice
argument_list|(
name|cacheWriter
operator|.
name|stripes
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|,
name|splitIncludes
argument_list|,
name|stripeIxRef
operator|.
name|value
argument_list|,
name|slice
argument_list|,
name|startTime
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// VRB mode - process the VRBs with cache data; the new cache data is coming later.
name|result
operator|=
name|processOneSlice
argument_list|(
name|vectors
argument_list|,
name|splitIncludes
argument_list|,
name|stripeIxRef
operator|.
name|value
argument_list|,
name|slice
argument_list|,
name|startTime
argument_list|)
expr_stmt|;
block|}
assert|assert
literal|null
operator|==
name|currentFileRead
operator|.
name|readNextSlice
argument_list|()
assert|;
operator|++
name|stripeIxRef
operator|.
name|value
expr_stmt|;
block|}
else|else
block|{
comment|// All the data comes from disk. The reader may have split it into multiple slices.
name|Vectors
name|vectors
init|=
name|currentFileRead
operator|.
name|readNextSlice
argument_list|()
decl_stmt|;
assert|assert
name|vectors
operator|!=
literal|null
assert|;
name|result
operator|=
literal|true
expr_stmt|;
if|if
condition|(
operator|!
name|vectors
operator|.
name|isSupported
argument_list|()
condition|)
block|{
comment|// Not in VRB mode - the new cache data is (partially) ready, we should use it.
while|while
condition|(
name|currentFileRead
operator|.
name|readNextSlice
argument_list|()
operator|!=
literal|null
condition|)
empty_stmt|;
comment|// Force the rest of the data thru.
name|CacheWriter
name|cacheWriter
init|=
name|currentFileRead
operator|.
name|getCacheWriter
argument_list|()
decl_stmt|;
for|for
control|(
name|CacheWriter
operator|.
name|CacheStripeData
name|csd
range|:
name|cacheWriter
operator|.
name|stripes
control|)
block|{
if|if
condition|(
operator|!
name|processOneSlice
argument_list|(
name|csd
argument_list|,
name|splitIncludes
argument_list|,
name|stripeIxRef
operator|.
name|value
argument_list|,
literal|null
argument_list|,
name|startTime
argument_list|)
condition|)
block|{
name|result
operator|=
literal|false
expr_stmt|;
break|break;
block|}
operator|++
name|stripeIxRef
operator|.
name|value
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// VRB mode - process the VRBs with cache data; the new cache data is coming later.
do|do
block|{
assert|assert
name|vectors
operator|.
name|isSupported
argument_list|()
assert|;
if|if
condition|(
operator|!
name|processOneSlice
argument_list|(
name|vectors
argument_list|,
name|splitIncludes
argument_list|,
name|stripeIxRef
operator|.
name|value
argument_list|,
literal|null
argument_list|,
name|startTime
argument_list|)
condition|)
block|{
name|result
operator|=
literal|false
expr_stmt|;
break|break;
block|}
operator|++
name|stripeIxRef
operator|.
name|value
expr_stmt|;
block|}
do|while
condition|(
operator|(
name|vectors
operator|=
name|currentFileRead
operator|.
name|readNextSlice
argument_list|()
operator|)
operator|!=
literal|null
condition|)
do|;
block|}
block|}
block|}
finally|finally
block|{
name|cleanUpCurrentRead
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
specifier|private
specifier|static
name|boolean
name|determineSplitIncludes
parameter_list|(
name|StripeData
name|slice
parameter_list|,
name|boolean
index|[]
name|splitIncludes
parameter_list|,
name|boolean
index|[]
name|writerIncludes
parameter_list|)
block|{
name|ColumnEncoding
index|[]
name|cacheEncodings
init|=
name|slice
operator|.
name|getEncodings
argument_list|()
decl_stmt|;
assert|assert
name|cacheEncodings
operator|!=
literal|null
assert|;
name|boolean
name|hasAllData
init|=
literal|true
decl_stmt|;
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|cacheEncodings
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
if|if
condition|(
operator|!
name|splitIncludes
index|[
name|colIx
index|]
condition|)
continue|continue;
if|if
condition|(
operator|(
name|cacheEncodings
index|[
name|colIx
index|]
operator|!=
literal|null
operator|)
operator|!=
operator|(
name|slice
operator|.
name|getData
argument_list|()
index|[
name|colIx
index|]
operator|!=
literal|null
operator|)
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Inconsistent cache slice "
operator|+
name|slice
argument_list|)
throw|;
block|}
if|if
condition|(
name|cacheEncodings
index|[
name|colIx
index|]
operator|!=
literal|null
condition|)
block|{
name|splitIncludes
index|[
name|colIx
index|]
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|hasAllData
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Includes accounting for cached data: before "
operator|+
name|DebugUtils
operator|.
name|toString
argument_list|(
name|writerIncludes
argument_list|)
operator|+
literal|", after "
operator|+
name|DebugUtils
operator|.
name|toString
argument_list|(
name|splitIncludes
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|hasAllData
return|;
block|}
specifier|private
name|boolean
name|processOneSlice
parameter_list|(
name|CacheWriter
operator|.
name|CacheStripeData
name|diskData
parameter_list|,
name|boolean
index|[]
name|splitIncludes
parameter_list|,
name|int
name|stripeIx
parameter_list|,
name|StripeData
name|cacheData
parameter_list|,
name|long
name|startTime
parameter_list|)
throws|throws
name|IOException
block|{
name|logProcessOneSlice
argument_list|(
name|stripeIx
argument_list|,
name|diskData
argument_list|,
name|cacheData
argument_list|)
expr_stmt|;
name|ColumnEncoding
index|[]
name|cacheEncodings
init|=
name|cacheData
operator|==
literal|null
condition|?
literal|null
else|:
name|cacheData
operator|.
name|getEncodings
argument_list|()
decl_stmt|;
name|LlapDataBuffer
index|[]
index|[]
index|[]
name|cacheBuffers
init|=
name|cacheData
operator|==
literal|null
condition|?
literal|null
else|:
name|cacheData
operator|.
name|getData
argument_list|()
decl_stmt|;
name|long
name|cacheRowCount
init|=
name|cacheData
operator|==
literal|null
condition|?
operator|-
literal|1L
else|:
name|cacheData
operator|.
name|getRowCount
argument_list|()
decl_stmt|;
name|SerDeStripeMetadata
name|metadata
init|=
operator|new
name|SerDeStripeMetadata
argument_list|(
name|stripeIx
argument_list|)
decl_stmt|;
name|StripeData
name|sliceToCache
init|=
literal|null
decl_stmt|;
name|boolean
name|hasAllData
init|=
name|diskData
operator|==
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|hasAllData
condition|)
block|{
name|sliceToCache
operator|=
name|createSliceToCache
argument_list|(
name|diskData
argument_list|,
name|cacheData
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|setEncodings
argument_list|(
name|combineCacheAndWriterEncodings
argument_list|(
name|cacheEncodings
argument_list|,
name|diskData
operator|.
name|encodings
argument_list|)
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|setRowCount
argument_list|(
name|diskData
operator|.
name|rowCount
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|metadata
operator|.
name|setEncodings
argument_list|(
name|Lists
operator|.
name|newArrayList
argument_list|(
name|cacheEncodings
argument_list|)
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|setRowCount
argument_list|(
name|cacheRowCount
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Derived stripe metadata for this split is "
operator|+
name|metadata
argument_list|)
expr_stmt|;
block|}
name|consumer
operator|.
name|setStripeMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
name|OrcEncodedColumnBatch
name|ecb
init|=
name|ECB_POOL
operator|.
name|take
argument_list|()
decl_stmt|;
name|ecb
operator|.
name|init
argument_list|(
name|fileKey
argument_list|,
name|metadata
operator|.
name|getStripeIx
argument_list|()
argument_list|,
name|OrcEncodedColumnBatch
operator|.
name|ALL_RGS
argument_list|,
name|writerIncludes
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|writerIncludes
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
if|if
condition|(
operator|!
name|writerIncludes
index|[
name|colIx
index|]
condition|)
continue|continue;
name|ecb
operator|.
name|initColumn
argument_list|(
name|colIx
argument_list|,
name|OrcEncodedColumnBatch
operator|.
name|MAX_DATA_STREAMS
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|hasAllData
operator|&&
name|splitIncludes
index|[
name|colIx
index|]
condition|)
block|{
comment|// The column has been read from disk.
name|List
argument_list|<
name|CacheWriter
operator|.
name|CacheStreamData
argument_list|>
name|streams
init|=
name|diskData
operator|.
name|colStreams
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
name|LlapDataBuffer
index|[]
index|[]
name|newCacheDataForCol
init|=
name|createArrayToCache
argument_list|(
name|sliceToCache
argument_list|,
name|colIx
argument_list|,
name|streams
argument_list|)
decl_stmt|;
if|if
condition|(
name|streams
operator|==
literal|null
condition|)
continue|continue;
comment|// Struct column, such as root?
name|Iterator
argument_list|<
name|CacheWriter
operator|.
name|CacheStreamData
argument_list|>
name|iter
init|=
name|streams
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|CacheWriter
operator|.
name|CacheStreamData
name|stream
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|stream
operator|.
name|isSuppressed
condition|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removing a suppressed stream "
operator|+
name|stream
operator|.
name|name
argument_list|)
expr_stmt|;
block|}
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
name|discardUncachedBuffers
argument_list|(
name|stream
operator|.
name|data
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|int
name|streamIx
init|=
name|setStreamDataToCache
argument_list|(
name|newCacheDataForCol
argument_list|,
name|stream
argument_list|)
decl_stmt|;
name|ColumnStreamData
name|cb
init|=
name|CSD_POOL
operator|.
name|take
argument_list|()
decl_stmt|;
name|cb
operator|.
name|incRef
argument_list|()
expr_stmt|;
name|cb
operator|.
name|setCacheBuffers
argument_list|(
name|stream
operator|.
name|data
argument_list|)
expr_stmt|;
name|ecb
operator|.
name|setStreamData
argument_list|(
name|colIx
argument_list|,
name|streamIx
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|processColumnCacheData
argument_list|(
name|cacheBuffers
argument_list|,
name|ecb
argument_list|,
name|colIx
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|processStop
argument_list|()
condition|)
block|{
name|recordReaderTime
argument_list|(
name|startTime
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Note: we cache slices one by one since we need to lock them before sending to consumer.
comment|//       We could lock here, then cache them together, then unlock here and in return,
comment|//       but for now just rely on the cache put to lock them before we send them over.
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|trace
argument_list|(
literal|"Data to cache from the read "
operator|+
name|sliceToCache
argument_list|)
expr_stmt|;
block|}
name|cacheFileData
argument_list|(
name|sliceToCache
argument_list|)
expr_stmt|;
return|return
name|sendEcbToConsumer
argument_list|(
name|ecb
argument_list|,
name|cacheData
operator|!=
literal|null
argument_list|,
name|diskData
argument_list|)
return|;
block|}
specifier|private
name|void
name|validateCacheAndDisk
parameter_list|(
name|StripeData
name|cacheData
parameter_list|,
name|long
name|rowCount
parameter_list|,
name|long
name|encodingCount
parameter_list|,
name|Object
name|diskDataLog
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|rowCount
operator|!=
name|cacheData
operator|.
name|getRowCount
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Row count mismatch; disk "
operator|+
name|rowCount
operator|+
literal|", cache "
operator|+
name|cacheData
operator|.
name|getRowCount
argument_list|()
operator|+
literal|" from "
operator|+
name|diskDataLog
operator|+
literal|" and "
operator|+
name|cacheData
argument_list|)
throw|;
block|}
if|if
condition|(
name|encodingCount
operator|>
literal|0
operator|&&
name|encodingCount
operator|!=
name|cacheData
operator|.
name|getEncodings
argument_list|()
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Column count mismatch; disk "
operator|+
name|encodingCount
operator|+
literal|", cache "
operator|+
name|cacheData
operator|.
name|getEncodings
argument_list|()
operator|.
name|length
operator|+
literal|" from "
operator|+
name|diskDataLog
operator|+
literal|" and "
operator|+
name|cacheData
argument_list|)
throw|;
block|}
block|}
comment|/** Unlike the other overload of processOneSlice, doesn't cache data. */
specifier|private
name|boolean
name|processOneSlice
parameter_list|(
name|Vectors
name|diskData
parameter_list|,
name|boolean
index|[]
name|splitIncludes
parameter_list|,
name|int
name|stripeIx
parameter_list|,
name|StripeData
name|cacheData
parameter_list|,
name|long
name|startTime
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|diskData
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|()
throw|;
comment|// The other overload should have been used.
block|}
comment|// LlapIoImpl.LOG.debug("diskData " + diskData);
name|logProcessOneSlice
argument_list|(
name|stripeIx
argument_list|,
name|diskData
argument_list|,
name|cacheData
argument_list|)
expr_stmt|;
if|if
condition|(
name|cacheData
operator|==
literal|null
operator|&&
name|diskData
operator|.
name|getRowCount
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|true
return|;
comment|// Nothing to process.
block|}
name|ColumnEncoding
index|[]
name|cacheEncodings
init|=
name|cacheData
operator|==
literal|null
condition|?
literal|null
else|:
name|cacheData
operator|.
name|getEncodings
argument_list|()
decl_stmt|;
name|LlapDataBuffer
index|[]
index|[]
index|[]
name|cacheBuffers
init|=
name|cacheData
operator|==
literal|null
condition|?
literal|null
else|:
name|cacheData
operator|.
name|getData
argument_list|()
decl_stmt|;
if|if
condition|(
name|cacheData
operator|!=
literal|null
condition|)
block|{
comment|// Don't validate column count - no encodings for vectors.
name|validateCacheAndDisk
argument_list|(
name|cacheData
argument_list|,
name|diskData
operator|.
name|getRowCount
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
name|diskData
argument_list|)
expr_stmt|;
block|}
name|SerDeStripeMetadata
name|metadata
init|=
operator|new
name|SerDeStripeMetadata
argument_list|(
name|stripeIx
argument_list|)
decl_stmt|;
name|metadata
operator|.
name|setEncodings
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|cacheEncodings
operator|==
literal|null
condition|?
operator|new
name|ColumnEncoding
index|[
name|splitIncludes
operator|.
name|length
index|]
else|:
name|cacheEncodings
argument_list|)
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|setRowCount
argument_list|(
name|diskData
operator|.
name|getRowCount
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Derived stripe metadata for this split is "
operator|+
name|metadata
argument_list|)
expr_stmt|;
block|}
name|consumer
operator|.
name|setStripeMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
name|OrcEncodedColumnBatch
name|ecb
init|=
name|ECB_POOL
operator|.
name|take
argument_list|()
decl_stmt|;
name|ecb
operator|.
name|init
argument_list|(
name|fileKey
argument_list|,
name|metadata
operator|.
name|getStripeIx
argument_list|()
argument_list|,
name|OrcEncodedColumnBatch
operator|.
name|ALL_RGS
argument_list|,
name|writerIncludes
operator|.
name|length
argument_list|)
expr_stmt|;
name|int
name|vectorsIx
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|writerIncludes
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
if|if
condition|(
operator|!
name|writerIncludes
index|[
name|colIx
index|]
condition|)
continue|continue;
if|if
condition|(
name|splitIncludes
index|[
name|colIx
index|]
condition|)
block|{
comment|// Skip the 0-th column, since it won't have a vector after reading the text source.
if|if
condition|(
name|colIx
operator|!=
literal|0
condition|)
block|{
name|List
argument_list|<
name|ColumnVector
argument_list|>
name|vectors
init|=
name|diskData
operator|.
name|getVectors
argument_list|(
name|vectorsIx
operator|++
argument_list|)
decl_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Processing vectors for column "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|vectors
argument_list|)
expr_stmt|;
block|}
name|ecb
operator|.
name|initColumnWithVectors
argument_list|(
name|colIx
argument_list|,
name|vectors
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ecb
operator|.
name|initColumn
argument_list|(
literal|0
argument_list|,
name|OrcEncodedColumnBatch
operator|.
name|MAX_DATA_STREAMS
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|ecb
operator|.
name|initColumn
argument_list|(
name|colIx
argument_list|,
name|OrcEncodedColumnBatch
operator|.
name|MAX_DATA_STREAMS
argument_list|)
expr_stmt|;
name|processColumnCacheData
argument_list|(
name|cacheBuffers
argument_list|,
name|ecb
argument_list|,
name|colIx
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|processStop
argument_list|()
condition|)
block|{
name|recordReaderTime
argument_list|(
name|startTime
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
name|sendEcbToConsumer
argument_list|(
name|ecb
argument_list|,
name|cacheData
operator|!=
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|private
name|void
name|processAsyncCacheData
parameter_list|(
name|CacheWriter
operator|.
name|CacheStripeData
name|diskData
parameter_list|,
name|boolean
index|[]
name|splitIncludes
parameter_list|)
throws|throws
name|IOException
block|{
name|StripeData
name|sliceToCache
init|=
operator|new
name|StripeData
argument_list|(
name|diskData
operator|.
name|knownTornStart
argument_list|,
name|diskData
operator|.
name|firstRowStart
argument_list|,
name|diskData
operator|.
name|lastRowStart
argument_list|,
name|diskData
operator|.
name|lastRowEnd
argument_list|,
name|diskData
operator|.
name|rowCount
argument_list|,
name|diskData
operator|.
name|encodings
operator|.
name|toArray
argument_list|(
operator|new
name|ColumnEncoding
index|[
name|diskData
operator|.
name|encodings
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|splitIncludes
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
if|if
condition|(
operator|!
name|splitIncludes
index|[
name|colIx
index|]
condition|)
continue|continue;
comment|// The column has been read from disk.
name|List
argument_list|<
name|CacheWriter
operator|.
name|CacheStreamData
argument_list|>
name|streams
init|=
name|diskData
operator|.
name|colStreams
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
name|LlapDataBuffer
index|[]
index|[]
name|newCacheDataForCol
init|=
name|createArrayToCache
argument_list|(
name|sliceToCache
argument_list|,
name|colIx
argument_list|,
name|streams
argument_list|)
decl_stmt|;
if|if
condition|(
name|streams
operator|==
literal|null
condition|)
continue|continue;
comment|// Struct column, such as root?
name|Iterator
argument_list|<
name|CacheWriter
operator|.
name|CacheStreamData
argument_list|>
name|iter
init|=
name|streams
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|CacheWriter
operator|.
name|CacheStreamData
name|stream
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|stream
operator|.
name|isSuppressed
condition|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removing a suppressed stream "
operator|+
name|stream
operator|.
name|name
argument_list|)
expr_stmt|;
block|}
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
name|discardUncachedBuffers
argument_list|(
name|stream
operator|.
name|data
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|setStreamDataToCache
argument_list|(
name|newCacheDataForCol
argument_list|,
name|stream
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|trace
argument_list|(
literal|"Data to cache from async read "
operator|+
name|sliceToCache
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|cacheFileData
argument_list|(
name|sliceToCache
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|unlockAllBuffers
argument_list|(
name|sliceToCache
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|StripeData
name|createSliceToCache
parameter_list|(
name|CacheWriter
operator|.
name|CacheStripeData
name|diskData
parameter_list|,
name|StripeData
name|cacheData
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|diskData
operator|!=
literal|null
assert|;
if|if
condition|(
name|cacheData
operator|==
literal|null
condition|)
block|{
return|return
operator|new
name|StripeData
argument_list|(
name|diskData
operator|.
name|knownTornStart
argument_list|,
name|diskData
operator|.
name|firstRowStart
argument_list|,
name|diskData
operator|.
name|lastRowStart
argument_list|,
name|diskData
operator|.
name|lastRowEnd
argument_list|,
name|diskData
operator|.
name|rowCount
argument_list|,
name|diskData
operator|.
name|encodings
operator|.
name|toArray
argument_list|(
operator|new
name|ColumnEncoding
index|[
name|diskData
operator|.
name|encodings
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
name|long
name|rowCount
init|=
name|diskData
operator|.
name|rowCount
decl_stmt|,
name|encodingCount
init|=
name|diskData
operator|.
name|encodings
operator|.
name|size
argument_list|()
decl_stmt|;
name|validateCacheAndDisk
argument_list|(
name|cacheData
argument_list|,
name|rowCount
argument_list|,
name|encodingCount
argument_list|,
name|diskData
argument_list|)
expr_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating slice to cache in addition to an existing slice "
operator|+
name|cacheData
operator|.
name|toCoordinateString
argument_list|()
operator|+
literal|"; disk offsets were "
operator|+
name|diskData
operator|.
name|toCoordinateString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Note: we could just do what we already do above from disk data, except for the validation
comment|// that is not strictly necessary, and knownTornStart which is an optimization.
name|StripeData
name|sliceToCache
init|=
name|StripeData
operator|.
name|duplicateStructure
argument_list|(
name|cacheData
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|diskData
operator|.
name|encodings
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|sliceToCache
operator|.
name|getEncodings
argument_list|()
index|[
name|i
index|]
operator|=
name|diskData
operator|.
name|encodings
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
name|sliceToCache
operator|.
name|setKnownTornStart
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|diskData
operator|.
name|knownTornStart
argument_list|,
name|sliceToCache
operator|.
name|getKnownTornStart
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|sliceToCache
return|;
block|}
block|}
specifier|private
specifier|static
name|LlapDataBuffer
index|[]
index|[]
name|createArrayToCache
parameter_list|(
name|StripeData
name|sliceToCache
parameter_list|,
name|int
name|colIx
parameter_list|,
name|List
argument_list|<
name|CacheWriter
operator|.
name|CacheStreamData
argument_list|>
name|streams
parameter_list|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Processing streams for column "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|streams
argument_list|)
expr_stmt|;
block|}
name|LlapDataBuffer
index|[]
index|[]
name|newCacheDataForCol
init|=
name|sliceToCache
operator|.
name|getData
argument_list|()
index|[
name|colIx
index|]
operator|=
operator|new
name|LlapDataBuffer
index|[
name|OrcEncodedColumnBatch
operator|.
name|MAX_DATA_STREAMS
index|]
index|[]
decl_stmt|;
return|return
name|newCacheDataForCol
return|;
block|}
specifier|private
specifier|static
name|int
name|setStreamDataToCache
parameter_list|(
name|LlapDataBuffer
index|[]
index|[]
name|newCacheDataForCol
parameter_list|,
name|CacheWriter
operator|.
name|CacheStreamData
name|stream
parameter_list|)
block|{
name|int
name|streamIx
init|=
name|stream
operator|.
name|name
operator|.
name|getKind
argument_list|()
operator|.
name|getNumber
argument_list|()
decl_stmt|;
comment|// This is kinda hacky - we "know" these are LlapDataBuffer-s.
name|newCacheDataForCol
index|[
name|streamIx
index|]
operator|=
name|stream
operator|.
name|data
operator|.
name|toArray
argument_list|(
operator|new
name|LlapDataBuffer
index|[
name|stream
operator|.
name|data
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
return|return
name|streamIx
return|;
block|}
specifier|private
name|void
name|processColumnCacheData
parameter_list|(
name|LlapDataBuffer
index|[]
index|[]
index|[]
name|cacheBuffers
parameter_list|,
name|OrcEncodedColumnBatch
name|ecb
parameter_list|,
name|int
name|colIx
parameter_list|)
block|{
comment|// The column has been obtained from cache.
name|LlapDataBuffer
index|[]
index|[]
name|colData
init|=
name|cacheBuffers
index|[
name|colIx
index|]
decl_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|trace
argument_list|(
literal|"Processing cache data for column "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|SerDeLowLevelCacheImpl
operator|.
name|toString
argument_list|(
name|colData
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|streamIx
init|=
literal|0
init|;
name|streamIx
operator|<
name|colData
operator|.
name|length
condition|;
operator|++
name|streamIx
control|)
block|{
if|if
condition|(
name|colData
index|[
name|streamIx
index|]
operator|==
literal|null
condition|)
continue|continue;
name|ColumnStreamData
name|cb
init|=
name|CSD_POOL
operator|.
name|take
argument_list|()
decl_stmt|;
name|cb
operator|.
name|incRef
argument_list|()
expr_stmt|;
name|cb
operator|.
name|setCacheBuffers
argument_list|(
name|Lists
operator|.
expr|<
name|MemoryBuffer
operator|>
name|newArrayList
argument_list|(
name|colData
index|[
name|streamIx
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|ecb
operator|.
name|setStreamData
argument_list|(
name|colIx
argument_list|,
name|streamIx
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|logProcessOneSlice
parameter_list|(
name|int
name|stripeIx
parameter_list|,
name|Object
name|diskData
parameter_list|,
name|StripeData
name|cacheData
parameter_list|)
block|{
name|String
name|sliceStr
init|=
name|cacheData
operator|==
literal|null
condition|?
literal|"null"
else|:
name|cacheData
operator|.
name|toCoordinateString
argument_list|()
decl_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Processing slice #"
operator|+
name|stripeIx
operator|+
literal|" "
operator|+
name|sliceStr
operator|+
literal|"; has"
operator|+
operator|(
operator|(
name|cacheData
operator|==
literal|null
operator|)
condition|?
literal|" no"
else|:
literal|""
operator|)
operator|+
literal|" cache data; has"
operator|+
operator|(
operator|(
name|diskData
operator|==
literal|null
operator|)
condition|?
literal|" no"
else|:
literal|""
operator|)
operator|+
literal|" disk data"
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|discardUncachedBuffers
parameter_list|(
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|list
parameter_list|)
block|{
for|for
control|(
name|MemoryBuffer
name|buffer
range|:
name|list
control|)
block|{
name|boolean
name|isInvalidated
init|=
operator|(
operator|(
name|LlapDataBuffer
operator|)
name|buffer
operator|)
operator|.
name|invalidate
argument_list|()
decl_stmt|;
assert|assert
name|isInvalidated
assert|;
name|bufferManager
operator|.
name|getAllocator
argument_list|()
operator|.
name|deallocate
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|List
argument_list|<
name|ColumnEncoding
argument_list|>
name|combineCacheAndWriterEncodings
parameter_list|(
name|ColumnEncoding
index|[]
name|cacheEncodings
parameter_list|,
name|List
argument_list|<
name|ColumnEncoding
argument_list|>
name|writerEncodings
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: refactor with cache impl? it has the same merge logic
if|if
condition|(
name|cacheEncodings
operator|==
literal|null
condition|)
block|{
return|return
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|writerEncodings
argument_list|)
return|;
block|}
if|if
condition|(
name|cacheEncodings
operator|.
name|length
operator|!=
name|writerEncodings
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incompatible encoding lengths: "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|cacheEncodings
argument_list|)
operator|+
literal|" vs "
operator|+
name|writerEncodings
argument_list|)
throw|;
block|}
name|ColumnEncoding
index|[]
name|combinedEncodings
init|=
name|Arrays
operator|.
name|copyOf
argument_list|(
name|cacheEncodings
argument_list|,
name|cacheEncodings
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|cacheEncodings
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
name|ColumnEncoding
name|newEncoding
init|=
name|writerEncodings
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
if|if
condition|(
name|newEncoding
operator|==
literal|null
condition|)
continue|continue;
if|if
condition|(
name|combinedEncodings
index|[
name|colIx
index|]
operator|!=
literal|null
operator|&&
operator|!
name|newEncoding
operator|.
name|equals
argument_list|(
name|combinedEncodings
index|[
name|colIx
index|]
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incompatible encodings at "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|cacheEncodings
argument_list|)
operator|+
literal|" vs "
operator|+
name|writerEncodings
argument_list|)
throw|;
block|}
name|combinedEncodings
index|[
name|colIx
index|]
operator|=
name|newEncoding
expr_stmt|;
block|}
return|return
name|Lists
operator|.
name|newArrayList
argument_list|(
name|combinedEncodings
argument_list|)
return|;
block|}
specifier|private
specifier|static
class|class
name|Vectors
block|{
specifier|private
specifier|final
name|List
argument_list|<
name|ColumnVector
argument_list|>
index|[]
name|data
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isSupported
decl_stmt|;
specifier|private
specifier|final
name|long
name|rowCount
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|public
name|Vectors
parameter_list|(
name|List
argument_list|<
name|VectorizedRowBatch
argument_list|>
name|vrbs
parameter_list|)
block|{
if|if
condition|(
name|vrbs
operator|==
literal|null
condition|)
block|{
name|isSupported
operator|=
literal|false
expr_stmt|;
name|data
operator|=
literal|null
expr_stmt|;
name|rowCount
operator|=
literal|0
expr_stmt|;
return|return;
block|}
name|isSupported
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|vrbs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|data
operator|=
literal|null
expr_stmt|;
name|rowCount
operator|=
literal|0
expr_stmt|;
return|return;
block|}
name|data
operator|=
operator|new
name|List
index|[
name|vrbs
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|numCols
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|data
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|data
index|[
name|i
index|]
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|vrbs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|int
name|rowCount
init|=
literal|0
decl_stmt|;
for|for
control|(
name|VectorizedRowBatch
name|vrb
range|:
name|vrbs
control|)
block|{
assert|assert
operator|!
name|vrb
operator|.
name|selectedInUse
assert|;
name|rowCount
operator|+=
name|vrb
operator|.
name|size
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|vrb
operator|.
name|cols
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|data
index|[
name|i
index|]
operator|.
name|add
argument_list|(
name|vrb
operator|.
name|cols
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|rowCount
operator|=
name|rowCount
expr_stmt|;
block|}
specifier|public
name|List
argument_list|<
name|ColumnVector
argument_list|>
name|getVectors
parameter_list|(
name|int
name|ix
parameter_list|)
block|{
return|return
name|data
index|[
name|ix
index|]
return|;
block|}
specifier|public
name|long
name|getRowCount
parameter_list|()
block|{
return|return
name|rowCount
return|;
block|}
specifier|public
name|boolean
name|isSupported
parameter_list|()
block|{
return|return
name|isSupported
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"Vectors {isSupported="
operator|+
name|isSupported
operator|+
literal|", rowCount="
operator|+
name|rowCount
operator|+
literal|", data="
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|data
argument_list|)
operator|+
literal|"}"
return|;
block|}
block|}
comment|/**    * This class only exists because Java doesn't have yield return. The original method    * before this change only needed yield return-s sprinkled here and there; however,    * Java developers are usually paid by class, so here we go.    */
specifier|private
specifier|static
class|class
name|FileReaderYieldReturn
block|{
specifier|private
name|ReaderWithOffsets
name|offsetReader
decl_stmt|;
specifier|private
name|int
name|rowsPerSlice
init|=
literal|0
decl_stmt|;
specifier|private
name|long
name|currentKnownTornStart
decl_stmt|;
specifier|private
name|long
name|lastStartOffset
init|=
name|Long
operator|.
name|MIN_VALUE
decl_stmt|,
name|firstStartOffset
init|=
name|Long
operator|.
name|MIN_VALUE
decl_stmt|;
specifier|private
name|boolean
name|hasUnsplittableData
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|EncodingWriter
name|writer
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|maySplitTheSplit
decl_stmt|;
specifier|private
specifier|final
name|int
name|targetSliceRowCount
decl_stmt|;
specifier|private
specifier|final
name|FileSplit
name|split
decl_stmt|;
specifier|public
name|FileReaderYieldReturn
parameter_list|(
name|ReaderWithOffsets
name|offsetReader
parameter_list|,
name|FileSplit
name|split
parameter_list|,
name|EncodingWriter
name|writer
parameter_list|,
name|boolean
name|maySplitTheSplit
parameter_list|,
name|int
name|targetSliceRowCount
parameter_list|)
block|{
name|this
operator|.
name|offsetReader
operator|=
name|offsetReader
expr_stmt|;
name|currentKnownTornStart
operator|=
name|split
operator|.
name|getStart
argument_list|()
expr_stmt|;
name|this
operator|.
name|writer
operator|=
name|writer
expr_stmt|;
name|this
operator|.
name|maySplitTheSplit
operator|=
name|maySplitTheSplit
expr_stmt|;
name|this
operator|.
name|targetSliceRowCount
operator|=
name|targetSliceRowCount
expr_stmt|;
name|this
operator|.
name|split
operator|=
name|split
expr_stmt|;
block|}
specifier|public
name|CacheWriter
name|getCacheWriter
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|writer
operator|.
name|getCacheWriter
argument_list|()
return|;
block|}
specifier|public
name|Vectors
name|readNextSlice
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|offsetReader
operator|==
literal|null
condition|)
return|return
literal|null
return|;
try|try
block|{
while|while
condition|(
name|offsetReader
operator|.
name|next
argument_list|()
condition|)
block|{
name|hasUnsplittableData
operator|=
literal|true
expr_stmt|;
name|Writable
name|value
init|=
name|offsetReader
operator|.
name|getCurrentRow
argument_list|()
decl_stmt|;
name|lastStartOffset
operator|=
name|offsetReader
operator|.
name|getCurrentRowStartOffset
argument_list|()
expr_stmt|;
if|if
condition|(
name|firstStartOffset
operator|==
name|Long
operator|.
name|MIN_VALUE
condition|)
block|{
name|firstStartOffset
operator|=
name|lastStartOffset
expr_stmt|;
block|}
name|writer
operator|.
name|writeOneRow
argument_list|(
name|value
argument_list|)
expr_stmt|;
if|if
condition|(
name|maySplitTheSplit
operator|&&
operator|++
name|rowsPerSlice
operator|==
name|targetSliceRowCount
condition|)
block|{
assert|assert
name|offsetReader
operator|.
name|hasOffsets
argument_list|()
assert|;
name|writer
operator|.
name|flushIntermediateData
argument_list|()
expr_stmt|;
name|long
name|fileOffset
init|=
name|offsetReader
operator|.
name|getCurrentRowEndOffset
argument_list|()
decl_stmt|;
comment|// Must support offsets to be able to split.
if|if
condition|(
name|firstStartOffset
operator|<
literal|0
operator|||
name|lastStartOffset
operator|<
literal|0
operator|||
name|fileOffset
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unable to get offsets from "
operator|+
name|offsetReader
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
throw|;
block|}
name|writer
operator|.
name|setCurrentStripeOffsets
argument_list|(
name|currentKnownTornStart
argument_list|,
name|firstStartOffset
argument_list|,
name|lastStartOffset
argument_list|,
name|fileOffset
argument_list|)
expr_stmt|;
name|writer
operator|.
name|writeIntermediateFooter
argument_list|()
expr_stmt|;
comment|// Split starting at row start will not read that row.
name|currentKnownTornStart
operator|=
name|lastStartOffset
expr_stmt|;
comment|// Row offsets will be determined from the reader (we could set the first from last).
name|lastStartOffset
operator|=
name|Long
operator|.
name|MIN_VALUE
expr_stmt|;
name|firstStartOffset
operator|=
name|Long
operator|.
name|MIN_VALUE
expr_stmt|;
name|rowsPerSlice
operator|=
literal|0
expr_stmt|;
return|return
operator|new
name|Vectors
argument_list|(
name|writer
operator|.
name|extractCurrentVrbs
argument_list|()
argument_list|)
return|;
block|}
block|}
try|try
block|{
name|Vectors
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|rowsPerSlice
operator|>
literal|0
operator|||
operator|(
operator|!
name|maySplitTheSplit
operator|&&
name|hasUnsplittableData
operator|)
condition|)
block|{
name|long
name|fileOffset
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
operator|!
name|offsetReader
operator|.
name|hasOffsets
argument_list|()
condition|)
block|{
comment|// The reader doesn't support offsets. We adjust offsets to match future splits.
comment|// If cached split was starting at row start, that row would be skipped, so +1
name|firstStartOffset
operator|=
name|split
operator|.
name|getStart
argument_list|()
operator|+
literal|1
expr_stmt|;
comment|// Last row starting at the end of the split would be read.
name|lastStartOffset
operator|=
name|split
operator|.
name|getStart
argument_list|()
operator|+
name|split
operator|.
name|getLength
argument_list|()
expr_stmt|;
comment|// However, it must end after the split end, otherwise the next one would have been read.
name|fileOffset
operator|=
name|lastStartOffset
operator|+
literal|1
expr_stmt|;
if|if
condition|(
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|CACHE_LOGGER
operator|.
name|debug
argument_list|(
literal|"Cache offsets based on the split - 'first row' at "
operator|+
name|firstStartOffset
operator|+
literal|"; 'last row' at "
operator|+
name|lastStartOffset
operator|+
literal|", "
operator|+
name|fileOffset
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|fileOffset
operator|=
name|offsetReader
operator|.
name|getCurrentRowEndOffset
argument_list|()
expr_stmt|;
assert|assert
name|firstStartOffset
operator|>=
literal|0
operator|&&
name|lastStartOffset
operator|>=
literal|0
operator|&&
name|fileOffset
operator|>=
literal|0
assert|;
block|}
name|writer
operator|.
name|setCurrentStripeOffsets
argument_list|(
name|currentKnownTornStart
argument_list|,
name|firstStartOffset
argument_list|,
name|lastStartOffset
argument_list|,
name|fileOffset
argument_list|)
expr_stmt|;
comment|// Close the writer to finalize the metadata.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|result
operator|=
operator|new
name|Vectors
argument_list|(
name|writer
operator|.
name|extractCurrentVrbs
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|closeOffsetReader
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|closeOffsetReader
argument_list|()
expr_stmt|;
throw|throw
operator|(
name|ex
operator|instanceof
name|IOException
operator|)
condition|?
operator|(
name|IOException
operator|)
name|ex
else|:
operator|new
name|IOException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|closeOffsetReader
parameter_list|()
block|{
if|if
condition|(
name|offsetReader
operator|==
literal|null
condition|)
return|return;
try|try
block|{
name|offsetReader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to close source reader"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|offsetReader
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|startReadSplitFromFile
parameter_list|(
name|FileSplit
name|split
parameter_list|,
name|boolean
index|[]
name|splitIncludes
parameter_list|,
name|StripeData
name|slice
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|maySplitTheSplit
init|=
name|slice
operator|==
literal|null
decl_stmt|;
name|ReaderWithOffsets
name|offsetReader
init|=
literal|null
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"rawtypes"
argument_list|)
name|RecordReader
name|sourceReader
init|=
name|sourceInputFormat
operator|.
name|getRecordReader
argument_list|(
name|split
argument_list|,
name|jobConf
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
try|try
block|{
name|offsetReader
operator|=
name|createOffsetReader
argument_list|(
name|sourceReader
argument_list|)
expr_stmt|;
name|sourceReader
operator|=
literal|null
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|sourceReader
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|sourceReader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to close source reader"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|maySplitTheSplit
operator|=
name|maySplitTheSplit
operator|&&
name|offsetReader
operator|.
name|hasOffsets
argument_list|()
expr_stmt|;
try|try
block|{
name|StructObjectInspector
name|originalOi
init|=
operator|(
name|StructObjectInspector
operator|)
name|getOiFromSerDe
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|splitColumnIds
init|=
name|OrcInputFormat
operator|.
name|genIncludedColumnsReverse
argument_list|(
name|schema
argument_list|,
name|splitIncludes
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// fileread writes to the writer, which writes to orcWriter, which writes to cacheWriter
name|EncodingWriter
name|writer
init|=
name|VertorDeserializeOrcWriter
operator|.
name|create
argument_list|(
name|sourceInputFormat
argument_list|,
name|sourceSerDe
argument_list|,
name|parts
argument_list|,
name|daemonConf
argument_list|,
name|jobConf
argument_list|,
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|originalOi
argument_list|,
name|splitColumnIds
argument_list|,
name|splitIncludes
argument_list|,
name|allocSize
argument_list|)
decl_stmt|;
comment|// TODO: move this into ctor? EW would need to create CacheWriter then
name|List
argument_list|<
name|Integer
argument_list|>
name|cwColIds
init|=
name|writer
operator|.
name|isOnlyWritingIncludedColumns
argument_list|()
condition|?
name|splitColumnIds
else|:
name|columnIds
decl_stmt|;
name|writer
operator|.
name|init
argument_list|(
operator|new
name|CacheWriter
argument_list|(
name|bufferManager
argument_list|,
name|cwColIds
argument_list|,
name|splitIncludes
argument_list|,
name|writer
operator|.
name|isOnlyWritingIncludedColumns
argument_list|()
argument_list|)
argument_list|,
name|daemonConf
argument_list|,
name|split
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|writer
operator|instanceof
name|VertorDeserializeOrcWriter
condition|)
block|{
name|VertorDeserializeOrcWriter
name|asyncWriter
init|=
operator|(
name|VertorDeserializeOrcWriter
operator|)
name|writer
decl_stmt|;
name|asyncWriter
operator|.
name|startAsync
argument_list|(
operator|new
name|AsyncCacheDataCallback
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|asyncWriters
operator|.
name|add
argument_list|(
name|asyncWriter
argument_list|)
expr_stmt|;
block|}
name|currentFileRead
operator|=
operator|new
name|FileReaderYieldReturn
argument_list|(
name|offsetReader
argument_list|,
name|split
argument_list|,
name|writer
argument_list|,
name|maySplitTheSplit
argument_list|,
name|targetSliceRowCount
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// Assignment is the last thing in the try, so if it happen we assume success.
if|if
condition|(
name|currentFileRead
operator|!=
literal|null
condition|)
return|return;
if|if
condition|(
name|offsetReader
operator|==
literal|null
condition|)
return|return;
try|try
block|{
name|offsetReader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to close source reader"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
class|class
name|AsyncCacheDataCallback
implements|implements
name|AsyncCallback
block|{
annotation|@
name|Override
specifier|public
name|void
name|onComplete
parameter_list|(
name|VertorDeserializeOrcWriter
name|writer
parameter_list|)
block|{
name|CacheWriter
name|cacheWriter
init|=
literal|null
decl_stmt|;
try|try
block|{
name|cacheWriter
operator|=
name|writer
operator|.
name|getCacheWriter
argument_list|()
expr_stmt|;
comment|// What we were reading from disk originally.
name|boolean
index|[]
name|cacheIncludes
init|=
name|writer
operator|.
name|getOriginalCacheIncludes
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|CacheWriter
operator|.
name|CacheStripeData
argument_list|>
name|iter
init|=
name|cacheWriter
operator|.
name|stripes
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|processAsyncCacheData
argument_list|(
name|iter
operator|.
name|next
argument_list|()
argument_list|,
name|cacheIncludes
argument_list|)
expr_stmt|;
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to cache async data"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|cacheWriter
operator|.
name|discardData
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// TODO: this interface is ugly. The two implementations are so far apart feature-wise
comment|//       after all the perf changes that we might was well hardcode them separately.
specifier|static
specifier|abstract
class|class
name|EncodingWriter
block|{
specifier|protected
name|Writer
name|orcWriter
decl_stmt|;
specifier|protected
name|CacheWriter
name|cacheWriter
decl_stmt|;
specifier|protected
specifier|final
name|StructObjectInspector
name|sourceOi
decl_stmt|;
specifier|private
specifier|final
name|int
name|allocSize
decl_stmt|;
specifier|public
name|EncodingWriter
parameter_list|(
name|StructObjectInspector
name|sourceOi
parameter_list|,
name|int
name|allocSize
parameter_list|)
block|{
name|this
operator|.
name|sourceOi
operator|=
name|sourceOi
expr_stmt|;
name|this
operator|.
name|allocSize
operator|=
name|allocSize
expr_stmt|;
block|}
specifier|public
name|void
name|init
parameter_list|(
name|CacheWriter
name|cacheWriter
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|orcWriter
operator|=
name|createOrcWriter
argument_list|(
name|cacheWriter
argument_list|,
name|conf
argument_list|,
name|path
argument_list|,
name|sourceOi
argument_list|)
expr_stmt|;
name|this
operator|.
name|cacheWriter
operator|=
name|cacheWriter
expr_stmt|;
block|}
specifier|public
name|CacheWriter
name|getCacheWriter
parameter_list|()
block|{
return|return
name|cacheWriter
return|;
block|}
specifier|public
specifier|abstract
name|boolean
name|isOnlyWritingIncludedColumns
parameter_list|()
function_decl|;
specifier|public
specifier|abstract
name|void
name|writeOneRow
parameter_list|(
name|Writable
name|row
parameter_list|)
throws|throws
name|IOException
function_decl|;
specifier|public
specifier|abstract
name|void
name|setCurrentStripeOffsets
parameter_list|(
name|long
name|currentKnownTornStart
parameter_list|,
name|long
name|firstStartOffset
parameter_list|,
name|long
name|lastStartOffset
parameter_list|,
name|long
name|fileOffset
parameter_list|)
function_decl|;
specifier|public
specifier|abstract
name|void
name|flushIntermediateData
parameter_list|()
throws|throws
name|IOException
function_decl|;
specifier|public
specifier|abstract
name|void
name|writeIntermediateFooter
parameter_list|()
throws|throws
name|IOException
function_decl|;
specifier|public
specifier|abstract
name|List
argument_list|<
name|VectorizedRowBatch
argument_list|>
name|extractCurrentVrbs
parameter_list|()
function_decl|;
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|orcWriter
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|orcWriter
operator|.
name|close
argument_list|()
expr_stmt|;
name|orcWriter
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to close ORC writer"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|cacheWriter
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|cacheWriter
operator|.
name|discardData
argument_list|()
expr_stmt|;
name|cacheWriter
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to close cache writer"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|protected
name|Writer
name|createOrcWriter
parameter_list|(
name|CacheWriter
name|cacheWriter
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Path
name|path
parameter_list|,
name|StructObjectInspector
name|oi
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: this is currently broken. We need to set memory manager to a bogus implementation
comment|//       to avoid problems with memory manager actually tracking the usage.
return|return
name|OrcFile
operator|.
name|createWriter
argument_list|(
name|path
argument_list|,
name|createOrcWriterOptions
argument_list|(
name|oi
argument_list|,
name|conf
argument_list|,
name|cacheWriter
argument_list|,
name|allocSize
argument_list|)
argument_list|)
return|;
block|}
block|}
specifier|static
class|class
name|DeserializerOrcWriter
extends|extends
name|EncodingWriter
block|{
specifier|private
specifier|final
name|Deserializer
name|sourceSerDe
decl_stmt|;
specifier|public
name|DeserializerOrcWriter
parameter_list|(
name|Deserializer
name|sourceSerDe
parameter_list|,
name|StructObjectInspector
name|sourceOi
parameter_list|,
name|int
name|allocSize
parameter_list|)
block|{
name|super
argument_list|(
name|sourceOi
argument_list|,
name|allocSize
argument_list|)
expr_stmt|;
name|this
operator|.
name|sourceSerDe
operator|=
name|sourceSerDe
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|orcWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|writeOneRow
parameter_list|(
name|Writable
name|value
parameter_list|)
throws|throws
name|IOException
block|{
name|Object
name|row
init|=
literal|null
decl_stmt|;
try|try
block|{
name|row
operator|=
name|sourceSerDe
operator|.
name|deserialize
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|orcWriter
operator|.
name|addRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|flushIntermediateData
parameter_list|()
block|{
comment|// No-op.
block|}
annotation|@
name|Override
specifier|public
name|void
name|writeIntermediateFooter
parameter_list|()
throws|throws
name|IOException
block|{
name|orcWriter
operator|.
name|writeIntermediateFooter
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isOnlyWritingIncludedColumns
parameter_list|()
block|{
return|return
literal|false
return|;
comment|// LazySimpleSerDe doesn't support projection.
block|}
annotation|@
name|Override
specifier|public
name|void
name|setCurrentStripeOffsets
parameter_list|(
name|long
name|currentKnownTornStart
parameter_list|,
name|long
name|firstStartOffset
parameter_list|,
name|long
name|lastStartOffset
parameter_list|,
name|long
name|fileOffset
parameter_list|)
block|{
name|cacheWriter
operator|.
name|setCurrentStripeOffsets
argument_list|(
name|currentKnownTornStart
argument_list|,
name|firstStartOffset
argument_list|,
name|lastStartOffset
argument_list|,
name|fileOffset
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|VectorizedRowBatch
argument_list|>
name|extractCurrentVrbs
parameter_list|()
block|{
return|return
literal|null
return|;
comment|// Doesn't support creating VRBs.
block|}
block|}
specifier|static
name|WriterOptions
name|createOrcWriterOptions
parameter_list|(
name|ObjectInspector
name|sourceOi
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|CacheWriter
name|cacheWriter
parameter_list|,
name|int
name|allocSize
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|OrcFile
operator|.
name|writerOptions
argument_list|(
name|conf
argument_list|)
operator|.
name|stripeSize
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
operator|.
name|blockSize
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
operator|.
name|rowIndexStride
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
comment|// For now, do not limit this - one RG per split
operator|.
name|blockPadding
argument_list|(
literal|false
argument_list|)
operator|.
name|compress
argument_list|(
name|CompressionKind
operator|.
name|NONE
argument_list|)
operator|.
name|version
argument_list|(
name|Version
operator|.
name|CURRENT
argument_list|)
operator|.
name|encodingStrategy
argument_list|(
name|EncodingStrategy
operator|.
name|SPEED
argument_list|)
operator|.
name|bloomFilterColumns
argument_list|(
literal|null
argument_list|)
operator|.
name|inspector
argument_list|(
name|sourceOi
argument_list|)
operator|.
name|physicalWriter
argument_list|(
name|cacheWriter
argument_list|)
operator|.
name|bufferSize
argument_list|(
name|allocSize
argument_list|)
return|;
block|}
specifier|private
name|ObjectInspector
name|getOiFromSerDe
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|sourceSerDe
operator|.
name|getObjectInspector
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|ReaderWithOffsets
name|createOffsetReader
parameter_list|(
name|RecordReader
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|sourceReader
parameter_list|)
block|{
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using "
operator|+
name|sourceReader
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" to read data"
argument_list|)
expr_stmt|;
block|}
comment|// Handle the special cases here. Perhaps we could have a more general structure, or even
comment|// a configurable set (like storage handlers), but for now we only have one.
if|if
condition|(
name|isLrrEnabled
operator|&&
name|sourceReader
operator|instanceof
name|LineRecordReader
condition|)
block|{
return|return
name|LineRrOffsetReader
operator|.
name|create
argument_list|(
operator|(
name|LineRecordReader
operator|)
name|sourceReader
argument_list|)
return|;
block|}
return|return
operator|new
name|PassThruOffsetReader
argument_list|(
name|sourceReader
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
index|[]
name|extractHosts
parameter_list|(
name|FileSplit
name|split
parameter_list|,
name|boolean
name|isInMemory
parameter_list|)
throws|throws
name|IOException
block|{
name|SplitLocationInfo
index|[]
name|locInfo
init|=
name|split
operator|.
name|getLocationInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|locInfo
operator|==
literal|null
condition|)
return|return
operator|new
name|String
index|[
literal|0
index|]
return|;
name|List
argument_list|<
name|String
argument_list|>
name|hosts
init|=
literal|null
decl_stmt|;
comment|// TODO: most of the time, there's no in-memory. Use an array?
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|locInfo
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|locInfo
index|[
name|i
index|]
operator|.
name|isInMemory
argument_list|()
operator|!=
name|isInMemory
condition|)
continue|continue;
if|if
condition|(
name|hosts
operator|==
literal|null
condition|)
block|{
name|hosts
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
name|hosts
operator|.
name|add
argument_list|(
name|locInfo
index|[
name|i
index|]
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hosts
operator|==
literal|null
condition|)
return|return
operator|new
name|String
index|[
literal|0
index|]
return|;
return|return
name|hosts
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|hosts
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
specifier|private
name|boolean
name|sendEcbToConsumer
parameter_list|(
name|OrcEncodedColumnBatch
name|ecb
parameter_list|,
name|boolean
name|hasCachedSlice
parameter_list|,
name|CacheWriter
operator|.
name|CacheStripeData
name|diskData
parameter_list|)
block|{
if|if
condition|(
name|ecb
operator|==
literal|null
condition|)
block|{
comment|// This basically means stop has been called.
name|cleanup
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Sending a batch over to consumer"
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|consumeData
argument_list|(
name|ecb
argument_list|)
expr_stmt|;
if|if
condition|(
name|hasCachedSlice
condition|)
block|{
name|cachedData
operator|.
name|getData
argument_list|()
operator|.
name|remove
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// See javadoc - no need to clean up the cache data anymore.
block|}
if|if
condition|(
name|diskData
operator|!=
literal|null
condition|)
block|{
name|diskData
operator|.
name|colStreams
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|void
name|cleanup
parameter_list|(
name|boolean
name|isError
parameter_list|)
block|{
name|cleanUpCurrentRead
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|isError
condition|)
return|return;
for|for
control|(
name|VertorDeserializeOrcWriter
name|asyncWriter
range|:
name|asyncWriters
control|)
block|{
try|try
block|{
name|asyncWriter
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to interrupt an async writer"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
name|asyncWriters
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|cleanUpCurrentRead
parameter_list|()
block|{
if|if
condition|(
name|currentFileRead
operator|==
literal|null
condition|)
return|return;
try|try
block|{
name|currentFileRead
operator|.
name|closeOffsetReader
argument_list|()
expr_stmt|;
name|currentFileRead
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to close current file reader"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|recordReaderTime
parameter_list|(
name|long
name|startTime
parameter_list|)
block|{
name|counters
operator|.
name|incrTimeCounter
argument_list|(
name|LlapIOCounters
operator|.
name|TOTAL_IO_TIME_NS
argument_list|,
name|startTime
argument_list|)
expr_stmt|;
block|}
specifier|private
name|boolean
name|processStop
parameter_list|()
block|{
if|if
condition|(
operator|!
name|isStopped
condition|)
return|return
literal|false
return|;
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"SerDe-based data reader is stopping"
argument_list|)
expr_stmt|;
name|cleanup
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|private
specifier|static
name|Object
name|determineFileId
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileSplit
name|split
parameter_list|,
name|boolean
name|allowSynthetic
parameter_list|)
throws|throws
name|IOException
block|{
comment|/* TODO: support this optionally? this is not OrcSplit, but we could add a custom split.       Object fileKey = ((OrcSplit)split).getFileKey();       if (fileKey != null) return fileKey; */
name|LlapIoImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Split for "
operator|+
name|split
operator|.
name|getPath
argument_list|()
operator|+
literal|" ("
operator|+
name|split
operator|.
name|getClass
argument_list|()
operator|+
literal|") does not have file ID"
argument_list|)
expr_stmt|;
return|return
name|HdfsUtils
operator|.
name|getFileId
argument_list|(
name|fs
argument_list|,
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|allowSynthetic
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|returnData
parameter_list|(
name|OrcEncodedColumnBatch
name|ecb
parameter_list|)
block|{
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|ecb
operator|.
name|getTotalColCount
argument_list|()
condition|;
operator|++
name|colIx
control|)
block|{
if|if
condition|(
operator|!
name|ecb
operator|.
name|hasData
argument_list|(
name|colIx
argument_list|)
condition|)
continue|continue;
comment|// TODO: reuse columnvector-s on hasBatch - save the array by column? take apart each list.
name|ColumnStreamData
index|[]
name|datas
init|=
name|ecb
operator|.
name|getColumnData
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
for|for
control|(
name|ColumnStreamData
name|data
range|:
name|datas
control|)
block|{
if|if
condition|(
name|data
operator|==
literal|null
operator|||
name|data
operator|.
name|decRef
argument_list|()
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
name|LlapIoImpl
operator|.
name|LOCKING_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
for|for
control|(
name|MemoryBuffer
name|buf
range|:
name|data
operator|.
name|getCacheBuffers
argument_list|()
control|)
block|{
name|LlapIoImpl
operator|.
name|LOCKING_LOGGER
operator|.
name|trace
argument_list|(
literal|"Unlocking {} at the end of processing"
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
name|bufferManager
operator|.
name|decRefBuffers
argument_list|(
name|data
operator|.
name|getCacheBuffers
argument_list|()
argument_list|)
expr_stmt|;
name|CSD_POOL
operator|.
name|offer
argument_list|(
name|data
argument_list|)
expr_stmt|;
block|}
block|}
comment|// We can offer ECB even with some streams not discarded; reset() will clear the arrays.
name|ECB_POOL
operator|.
name|offer
argument_list|(
name|ecb
argument_list|)
expr_stmt|;
block|}
specifier|public
name|TezCounters
name|getTezCounters
parameter_list|()
block|{
return|return
name|counters
operator|.
name|getTezCounters
argument_list|()
return|;
block|}
block|}
end_class

end_unit

