begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|druid
operator|.
name|serde
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|sql
operator|.
name|Timestamp
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|adapter
operator|.
name|druid
operator|.
name|DruidTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|type
operator|.
name|HiveDecimal
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|druid
operator|.
name|DruidStorageHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|druid
operator|.
name|DruidStorageHandlerUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|AbstractSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|io
operator|.
name|ByteWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|io
operator|.
name|DoubleWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|io
operator|.
name|HiveDecimalWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|io
operator|.
name|ShortWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|io
operator|.
name|TimestampWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructField
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|ByteObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|DoubleObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|FloatObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|HiveDecimalObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|IntObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|LongObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|PrimitiveObjectInspectorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|ShortObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|StringObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|TimestampObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|PrimitiveTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|FloatWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IntWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|fasterxml
operator|.
name|jackson
operator|.
name|core
operator|.
name|type
operator|.
name|TypeReference
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableMap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|Druids
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|Druids
operator|.
name|SegmentMetadataQueryBuilder
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|Query
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|aggregation
operator|.
name|AggregatorFactory
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|aggregation
operator|.
name|PostAggregator
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|dimension
operator|.
name|DimensionSpec
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|groupby
operator|.
name|GroupByQuery
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|metadata
operator|.
name|metadata
operator|.
name|ColumnAnalysis
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|metadata
operator|.
name|metadata
operator|.
name|SegmentAnalysis
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|metadata
operator|.
name|metadata
operator|.
name|SegmentMetadataQuery
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|select
operator|.
name|SelectQuery
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|timeseries
operator|.
name|TimeseriesQuery
import|;
end_import

begin_import
import|import
name|io
operator|.
name|druid
operator|.
name|query
operator|.
name|topn
operator|.
name|TopNQuery
import|;
end_import

begin_comment
comment|/**  * DruidSerDe that is used to  deserialize objects from a Druid data source.  */
end_comment

begin_class
annotation|@
name|SerDeSpec
argument_list|(
name|schemaProps
operator|=
block|{
name|Constants
operator|.
name|DRUID_DATA_SOURCE
block|}
argument_list|)
specifier|public
class|class
name|DruidSerDe
extends|extends
name|AbstractSerDe
block|{
specifier|protected
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|DruidSerDe
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|String
index|[]
name|columns
decl_stmt|;
specifier|private
name|PrimitiveTypeInfo
index|[]
name|types
decl_stmt|;
specifier|private
name|ObjectInspector
name|inspector
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|initialize
parameter_list|(
name|Configuration
name|configuration
parameter_list|,
name|Properties
name|properties
parameter_list|)
throws|throws
name|SerDeException
block|{
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|PrimitiveTypeInfo
argument_list|>
name|columnTypes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|ObjectInspector
argument_list|>
name|inspectors
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// Druid query
name|String
name|druidQuery
init|=
name|properties
operator|.
name|getProperty
argument_list|(
name|Constants
operator|.
name|DRUID_QUERY_JSON
argument_list|)
decl_stmt|;
if|if
condition|(
name|druidQuery
operator|==
literal|null
condition|)
block|{
comment|// No query. Either it is a CTAS, or we need to create a Druid
comment|// Segment Metadata query that retrieves all columns present in
comment|// the data source (dimensions and metrics).
if|if
condition|(
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|properties
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMNS
argument_list|)
argument_list|)
operator|&&
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|properties
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMN_TYPES
argument_list|)
argument_list|)
condition|)
block|{
name|columnNames
operator|.
name|addAll
argument_list|(
name|Utilities
operator|.
name|getColumnNames
argument_list|(
name|properties
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|columnNames
operator|.
name|contains
argument_list|(
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Timestamp column (' "
operator|+
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
operator|+
literal|"') not specified in create table; list of columns is : "
operator|+
name|properties
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMNS
argument_list|)
argument_list|)
throw|;
block|}
name|columnTypes
operator|.
name|addAll
argument_list|(
name|Lists
operator|.
name|transform
argument_list|(
name|Utilities
operator|.
name|getColumnTypes
argument_list|(
name|properties
argument_list|)
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|PrimitiveTypeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|PrimitiveTypeInfo
name|apply
parameter_list|(
name|String
name|type
parameter_list|)
block|{
return|return
name|TypeInfoFactory
operator|.
name|getPrimitiveTypeInfo
argument_list|(
name|type
argument_list|)
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
name|inspectors
operator|.
name|addAll
argument_list|(
name|Lists
operator|.
name|transform
argument_list|(
name|columnTypes
argument_list|,
operator|new
name|Function
argument_list|<
name|PrimitiveTypeInfo
argument_list|,
name|ObjectInspector
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|ObjectInspector
name|apply
parameter_list|(
name|PrimitiveTypeInfo
name|type
parameter_list|)
block|{
return|return
name|PrimitiveObjectInspectorFactory
operator|.
name|getPrimitiveWritableObjectInspector
argument_list|(
name|type
argument_list|)
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
name|columns
operator|=
name|columnNames
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|columnNames
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
name|types
operator|=
name|columnTypes
operator|.
name|toArray
argument_list|(
operator|new
name|PrimitiveTypeInfo
index|[
name|columnTypes
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
name|inspector
operator|=
name|ObjectInspectorFactory
operator|.
name|getStandardStructObjectInspector
argument_list|(
name|columnNames
argument_list|,
name|inspectors
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|dataSource
init|=
name|properties
operator|.
name|getProperty
argument_list|(
name|Constants
operator|.
name|DRUID_DATA_SOURCE
argument_list|)
decl_stmt|;
if|if
condition|(
name|dataSource
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Druid data source not specified; use "
operator|+
name|Constants
operator|.
name|DRUID_DATA_SOURCE
operator|+
literal|" in table properties"
argument_list|)
throw|;
block|}
name|SegmentMetadataQueryBuilder
name|builder
init|=
operator|new
name|Druids
operator|.
name|SegmentMetadataQueryBuilder
argument_list|()
decl_stmt|;
name|builder
operator|.
name|dataSource
argument_list|(
name|dataSource
argument_list|)
expr_stmt|;
name|builder
operator|.
name|merge
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|builder
operator|.
name|analysisTypes
argument_list|()
expr_stmt|;
name|SegmentMetadataQuery
name|query
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
comment|// Execute query in Druid
name|String
name|address
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|configuration
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_DRUID_BROKER_DEFAULT_ADDRESS
argument_list|)
decl_stmt|;
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|address
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Druid broker address not specified in configuration"
argument_list|)
throw|;
block|}
comment|// Infer schema
name|SegmentAnalysis
name|schemaInfo
decl_stmt|;
try|try
block|{
name|schemaInfo
operator|=
name|submitMetadataRequest
argument_list|(
name|address
argument_list|,
name|query
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|ColumnAnalysis
argument_list|>
name|columnInfo
range|:
name|schemaInfo
operator|.
name|getColumns
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|columnInfo
operator|.
name|getKey
argument_list|()
operator|.
name|equals
argument_list|(
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
argument_list|)
condition|)
block|{
comment|// Special handling for timestamp column
name|columnNames
operator|.
name|add
argument_list|(
name|columnInfo
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
comment|// field name
name|PrimitiveTypeInfo
name|type
init|=
name|TypeInfoFactory
operator|.
name|timestampTypeInfo
decl_stmt|;
comment|// field type
name|columnTypes
operator|.
name|add
argument_list|(
name|type
argument_list|)
expr_stmt|;
name|inspectors
operator|.
name|add
argument_list|(
name|PrimitiveObjectInspectorFactory
operator|.
name|getPrimitiveWritableObjectInspector
argument_list|(
name|type
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|columnNames
operator|.
name|add
argument_list|(
name|columnInfo
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
comment|// field name
name|PrimitiveTypeInfo
name|type
init|=
name|DruidSerDeUtils
operator|.
name|convertDruidToHiveType
argument_list|(
name|columnInfo
operator|.
name|getValue
argument_list|()
operator|.
name|getType
argument_list|()
argument_list|)
decl_stmt|;
comment|// field type
name|columnTypes
operator|.
name|add
argument_list|(
name|type
argument_list|)
expr_stmt|;
name|inspectors
operator|.
name|add
argument_list|(
name|PrimitiveObjectInspectorFactory
operator|.
name|getPrimitiveWritableObjectInspector
argument_list|(
name|type
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|columns
operator|=
name|columnNames
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|columnNames
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
name|types
operator|=
name|columnTypes
operator|.
name|toArray
argument_list|(
operator|new
name|PrimitiveTypeInfo
index|[
name|columnTypes
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
name|inspector
operator|=
name|ObjectInspectorFactory
operator|.
name|getStandardStructObjectInspector
argument_list|(
name|columnNames
argument_list|,
name|inspectors
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Query is specified, we can extract the results schema from the query
name|Query
argument_list|<
name|?
argument_list|>
name|query
decl_stmt|;
try|try
block|{
name|query
operator|=
name|DruidStorageHandlerUtils
operator|.
name|JSON_MAPPER
operator|.
name|readValue
argument_list|(
name|druidQuery
argument_list|,
name|Query
operator|.
name|class
argument_list|)
expr_stmt|;
comment|// Extract column names and types (if present)
name|ImmutableMap
operator|.
name|Builder
argument_list|<
name|String
argument_list|,
name|PrimitiveTypeInfo
argument_list|>
name|mapColumnNamesTypes
init|=
name|ImmutableMap
operator|.
name|builder
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|properties
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMNS
argument_list|)
argument_list|)
operator|&&
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|properties
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMN_TYPES
argument_list|)
argument_list|)
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|propColumnNames
init|=
name|Utilities
operator|.
name|getColumnNames
argument_list|(
name|properties
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|propColumnTypes
init|=
name|Utilities
operator|.
name|getColumnTypes
argument_list|(
name|properties
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|propColumnNames
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|mapColumnNamesTypes
operator|.
name|put
argument_list|(
name|propColumnNames
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|TypeInfoFactory
operator|.
name|getPrimitiveTypeInfo
argument_list|(
name|propColumnTypes
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
switch|switch
condition|(
name|query
operator|.
name|getType
argument_list|()
condition|)
block|{
case|case
name|Query
operator|.
name|TIMESERIES
case|:
name|inferSchema
argument_list|(
operator|(
name|TimeseriesQuery
operator|)
name|query
argument_list|,
name|columnNames
argument_list|,
name|columnTypes
argument_list|,
name|mapColumnNamesTypes
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|Query
operator|.
name|TOPN
case|:
name|inferSchema
argument_list|(
operator|(
name|TopNQuery
operator|)
name|query
argument_list|,
name|columnNames
argument_list|,
name|columnTypes
argument_list|,
name|mapColumnNamesTypes
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|Query
operator|.
name|SELECT
case|:
name|String
name|address
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|configuration
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_DRUID_BROKER_DEFAULT_ADDRESS
argument_list|)
decl_stmt|;
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|address
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Druid broker address not specified in configuration"
argument_list|)
throw|;
block|}
name|inferSchema
argument_list|(
operator|(
name|SelectQuery
operator|)
name|query
argument_list|,
name|columnNames
argument_list|,
name|columnTypes
argument_list|,
name|address
argument_list|,
name|mapColumnNamesTypes
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|Query
operator|.
name|GROUP_BY
case|:
name|inferSchema
argument_list|(
operator|(
name|GroupByQuery
operator|)
name|query
argument_list|,
name|columnNames
argument_list|,
name|columnTypes
argument_list|,
name|mapColumnNamesTypes
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Not supported Druid query"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|columns
operator|=
operator|new
name|String
index|[
name|columnNames
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|types
operator|=
operator|new
name|PrimitiveTypeInfo
index|[
name|columnNames
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|columnTypes
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|columns
index|[
name|i
index|]
operator|=
name|columnNames
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|types
index|[
name|i
index|]
operator|=
name|columnTypes
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|inspectors
operator|.
name|add
argument_list|(
name|PrimitiveObjectInspectorFactory
operator|.
name|getPrimitiveWritableObjectInspector
argument_list|(
name|types
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|inspector
operator|=
name|ObjectInspectorFactory
operator|.
name|getStandardStructObjectInspector
argument_list|(
name|columnNames
argument_list|,
name|inspectors
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DruidSerDe initialized with\n"
operator|+
literal|"\t columns: "
operator|+
name|columnNames
operator|+
literal|"\n\t types: "
operator|+
name|columnTypes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Submits the request and returns */
specifier|protected
name|SegmentAnalysis
name|submitMetadataRequest
parameter_list|(
name|String
name|address
parameter_list|,
name|SegmentMetadataQuery
name|query
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|IOException
block|{
name|InputStream
name|response
decl_stmt|;
try|try
block|{
name|response
operator|=
name|DruidStorageHandlerUtils
operator|.
name|submitRequest
argument_list|(
name|DruidStorageHandler
operator|.
name|getHttpClient
argument_list|()
argument_list|,
name|DruidStorageHandlerUtils
operator|.
name|createRequest
argument_list|(
name|address
argument_list|,
name|query
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
throw|;
block|}
comment|// Retrieve results
name|List
argument_list|<
name|SegmentAnalysis
argument_list|>
name|resultsList
decl_stmt|;
try|try
block|{
comment|// This will throw an exception in case of the response from druid is not an array
comment|// this case occurs if for instance druid query execution returns an exception instead of array of results.
name|resultsList
operator|=
name|DruidStorageHandlerUtils
operator|.
name|SMILE_MAPPER
operator|.
name|readValue
argument_list|(
name|response
argument_list|,
operator|new
name|TypeReference
argument_list|<
name|List
argument_list|<
name|SegmentAnalysis
argument_list|>
argument_list|>
argument_list|()
block|{               }
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|SerDeException
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|resultsList
operator|==
literal|null
operator|||
name|resultsList
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Connected to Druid but could not retrieve datasource information"
argument_list|)
throw|;
block|}
if|if
condition|(
name|resultsList
operator|.
name|size
argument_list|()
operator|!=
literal|1
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Information about segments should have been merged"
argument_list|)
throw|;
block|}
return|return
name|resultsList
operator|.
name|get
argument_list|(
literal|0
argument_list|)
return|;
block|}
comment|/* Timeseries query */
specifier|private
name|void
name|inferSchema
parameter_list|(
name|TimeseriesQuery
name|query
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
parameter_list|,
name|List
argument_list|<
name|PrimitiveTypeInfo
argument_list|>
name|columnTypes
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|PrimitiveTypeInfo
argument_list|>
name|mapColumnNamesTypes
parameter_list|)
block|{
comment|// Timestamp column
name|columnNames
operator|.
name|add
argument_list|(
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|timestampTypeInfo
argument_list|)
expr_stmt|;
comment|// Aggregator columns
for|for
control|(
name|AggregatorFactory
name|af
range|:
name|query
operator|.
name|getAggregatorSpecs
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|af
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|PrimitiveTypeInfo
name|typeInfo
init|=
name|mapColumnNamesTypes
operator|.
name|get
argument_list|(
name|af
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeInfo
operator|!=
literal|null
condition|)
block|{
comment|// If datasource was created by Hive, we consider Hive type
name|columnTypes
operator|.
name|add
argument_list|(
name|typeInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|columnTypes
operator|.
name|add
argument_list|(
name|DruidSerDeUtils
operator|.
name|convertDruidToHiveType
argument_list|(
name|af
operator|.
name|getTypeName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Post-aggregator columns
comment|// TODO: Currently Calcite only infers avg for post-aggregate,
comment|// but once we recognize other functions, we will need to infer
comment|// different types for post-aggregation functions
for|for
control|(
name|PostAggregator
name|pa
range|:
name|query
operator|.
name|getPostAggregatorSpecs
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|pa
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|floatTypeInfo
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* TopN query */
specifier|private
name|void
name|inferSchema
parameter_list|(
name|TopNQuery
name|query
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
parameter_list|,
name|List
argument_list|<
name|PrimitiveTypeInfo
argument_list|>
name|columnTypes
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|PrimitiveTypeInfo
argument_list|>
name|mapColumnNamesTypes
parameter_list|)
block|{
comment|// Timestamp column
name|columnNames
operator|.
name|add
argument_list|(
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|timestampTypeInfo
argument_list|)
expr_stmt|;
comment|// Dimension column
name|columnNames
operator|.
name|add
argument_list|(
name|query
operator|.
name|getDimensionSpec
argument_list|()
operator|.
name|getOutputName
argument_list|()
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|stringTypeInfo
argument_list|)
expr_stmt|;
comment|// Aggregator columns
for|for
control|(
name|AggregatorFactory
name|af
range|:
name|query
operator|.
name|getAggregatorSpecs
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|af
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|PrimitiveTypeInfo
name|typeInfo
init|=
name|mapColumnNamesTypes
operator|.
name|get
argument_list|(
name|af
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeInfo
operator|!=
literal|null
condition|)
block|{
comment|// If datasource was created by Hive, we consider Hive type
name|columnTypes
operator|.
name|add
argument_list|(
name|typeInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|columnTypes
operator|.
name|add
argument_list|(
name|DruidSerDeUtils
operator|.
name|convertDruidToHiveType
argument_list|(
name|af
operator|.
name|getTypeName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Post-aggregator columns
comment|// TODO: Currently Calcite only infers avg for post-aggregate,
comment|// but once we recognize other functions, we will need to infer
comment|// different types for post-aggregation functions
for|for
control|(
name|PostAggregator
name|pa
range|:
name|query
operator|.
name|getPostAggregatorSpecs
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|pa
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|floatTypeInfo
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Select query */
specifier|private
name|void
name|inferSchema
parameter_list|(
name|SelectQuery
name|query
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
parameter_list|,
name|List
argument_list|<
name|PrimitiveTypeInfo
argument_list|>
name|columnTypes
parameter_list|,
name|String
name|address
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|PrimitiveTypeInfo
argument_list|>
name|mapColumnNamesTypes
parameter_list|)
throws|throws
name|SerDeException
block|{
comment|// Timestamp column
name|columnNames
operator|.
name|add
argument_list|(
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|timestampTypeInfo
argument_list|)
expr_stmt|;
comment|// Dimension columns
for|for
control|(
name|DimensionSpec
name|ds
range|:
name|query
operator|.
name|getDimensions
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|ds
operator|.
name|getOutputName
argument_list|()
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|stringTypeInfo
argument_list|)
expr_stmt|;
block|}
comment|// The type for metric columns is not explicit in the query, thus in this case
comment|// we need to emit a metadata query to know their type
name|SegmentMetadataQueryBuilder
name|builder
init|=
operator|new
name|Druids
operator|.
name|SegmentMetadataQueryBuilder
argument_list|()
decl_stmt|;
name|builder
operator|.
name|dataSource
argument_list|(
name|query
operator|.
name|getDataSource
argument_list|()
argument_list|)
expr_stmt|;
name|builder
operator|.
name|merge
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|builder
operator|.
name|analysisTypes
argument_list|()
expr_stmt|;
name|SegmentMetadataQuery
name|metadataQuery
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
comment|// Execute query in Druid
name|SegmentAnalysis
name|schemaInfo
decl_stmt|;
try|try
block|{
name|schemaInfo
operator|=
name|submitMetadataRequest
argument_list|(
name|address
argument_list|,
name|metadataQuery
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|schemaInfo
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Connected to Druid but could not retrieve datasource information"
argument_list|)
throw|;
block|}
for|for
control|(
name|String
name|metric
range|:
name|query
operator|.
name|getMetrics
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|metric
argument_list|)
expr_stmt|;
name|PrimitiveTypeInfo
name|typeInfo
init|=
name|mapColumnNamesTypes
operator|.
name|get
argument_list|(
name|metric
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeInfo
operator|!=
literal|null
condition|)
block|{
comment|// If datasource was created by Hive, we consider Hive type
name|columnTypes
operator|.
name|add
argument_list|(
name|typeInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|columnTypes
operator|.
name|add
argument_list|(
name|DruidSerDeUtils
operator|.
name|convertDruidToHiveType
argument_list|(
name|schemaInfo
operator|.
name|getColumns
argument_list|()
operator|.
name|get
argument_list|(
name|metric
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/* GroupBy query */
specifier|private
name|void
name|inferSchema
parameter_list|(
name|GroupByQuery
name|query
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
parameter_list|,
name|List
argument_list|<
name|PrimitiveTypeInfo
argument_list|>
name|columnTypes
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|PrimitiveTypeInfo
argument_list|>
name|mapColumnNamesTypes
parameter_list|)
block|{
comment|// Timestamp column
name|columnNames
operator|.
name|add
argument_list|(
name|DruidTable
operator|.
name|DEFAULT_TIMESTAMP_COLUMN
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|timestampTypeInfo
argument_list|)
expr_stmt|;
comment|// Dimension columns
for|for
control|(
name|DimensionSpec
name|ds
range|:
name|query
operator|.
name|getDimensions
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|ds
operator|.
name|getOutputName
argument_list|()
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|DruidSerDeUtils
operator|.
name|extractTypeFromDimension
argument_list|(
name|ds
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Aggregator columns
for|for
control|(
name|AggregatorFactory
name|af
range|:
name|query
operator|.
name|getAggregatorSpecs
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|af
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|PrimitiveTypeInfo
name|typeInfo
init|=
name|mapColumnNamesTypes
operator|.
name|get
argument_list|(
name|af
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeInfo
operator|!=
literal|null
condition|)
block|{
comment|// If datasource was created by Hive, we consider Hive type
name|columnTypes
operator|.
name|add
argument_list|(
name|typeInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|columnTypes
operator|.
name|add
argument_list|(
name|DruidSerDeUtils
operator|.
name|convertDruidToHiveType
argument_list|(
name|af
operator|.
name|getTypeName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Post-aggregator columns
comment|// TODO: Currently Calcite only infers avg for post-aggregate,
comment|// but once we recognize other functions, we will need to infer
comment|// different types for post-aggregation functions
for|for
control|(
name|PostAggregator
name|pa
range|:
name|query
operator|.
name|getPostAggregatorSpecs
argument_list|()
control|)
block|{
name|columnNames
operator|.
name|add
argument_list|(
name|pa
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|columnTypes
operator|.
name|add
argument_list|(
name|TypeInfoFactory
operator|.
name|floatTypeInfo
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|Writable
argument_list|>
name|getSerializedClass
parameter_list|()
block|{
return|return
name|DruidWritable
operator|.
name|class
return|;
block|}
annotation|@
name|Override
specifier|public
name|Writable
name|serialize
parameter_list|(
name|Object
name|o
parameter_list|,
name|ObjectInspector
name|objectInspector
parameter_list|)
throws|throws
name|SerDeException
block|{
if|if
condition|(
name|objectInspector
operator|.
name|getCategory
argument_list|()
operator|!=
name|ObjectInspector
operator|.
name|Category
operator|.
name|STRUCT
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
name|getClass
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" can only serialize struct types, but we got: "
operator|+
name|objectInspector
operator|.
name|getTypeName
argument_list|()
argument_list|)
throw|;
block|}
comment|// Prepare the field ObjectInspectors
name|StructObjectInspector
name|soi
init|=
operator|(
name|StructObjectInspector
operator|)
name|objectInspector
decl_stmt|;
name|List
argument_list|<
name|?
extends|extends
name|StructField
argument_list|>
name|fields
init|=
name|soi
operator|.
name|getAllStructFieldRefs
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Object
argument_list|>
name|values
init|=
name|soi
operator|.
name|getStructFieldsDataAsList
argument_list|(
name|o
argument_list|)
decl_stmt|;
comment|// We deserialize the result
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|value
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|columns
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|==
literal|null
condition|)
block|{
comment|// null, we just add it
name|value
operator|.
name|put
argument_list|(
name|columns
index|[
name|i
index|]
argument_list|,
literal|null
argument_list|)
expr_stmt|;
continue|continue;
block|}
specifier|final
name|Object
name|res
decl_stmt|;
switch|switch
condition|(
name|types
index|[
name|i
index|]
operator|.
name|getPrimitiveCategory
argument_list|()
condition|)
block|{
case|case
name|TIMESTAMP
case|:
name|res
operator|=
operator|(
operator|(
name|TimestampObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|getPrimitiveJavaObject
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
operator|.
name|getTime
argument_list|()
expr_stmt|;
break|break;
case|case
name|BYTE
case|:
name|res
operator|=
operator|(
operator|(
name|ByteObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|get
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|SHORT
case|:
name|res
operator|=
operator|(
operator|(
name|ShortObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|get
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|INT
case|:
name|res
operator|=
operator|(
operator|(
name|IntObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|get
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|LONG
case|:
name|res
operator|=
operator|(
operator|(
name|LongObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|get
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|FLOAT
case|:
name|res
operator|=
operator|(
operator|(
name|FloatObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|get
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|DOUBLE
case|:
name|res
operator|=
operator|(
operator|(
name|DoubleObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|get
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|DECIMAL
case|:
name|res
operator|=
operator|(
operator|(
name|HiveDecimalObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|getPrimitiveJavaObject
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
operator|.
name|doubleValue
argument_list|()
expr_stmt|;
break|break;
case|case
name|STRING
case|:
name|res
operator|=
operator|(
operator|(
name|StringObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|getPrimitiveJavaObject
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Unknown type: "
operator|+
name|types
index|[
name|i
index|]
operator|.
name|getPrimitiveCategory
argument_list|()
argument_list|)
throw|;
block|}
name|value
operator|.
name|put
argument_list|(
name|columns
index|[
name|i
index|]
argument_list|,
name|res
argument_list|)
expr_stmt|;
block|}
name|value
operator|.
name|put
argument_list|(
name|Constants
operator|.
name|DRUID_TIMESTAMP_GRANULARITY_COL_NAME
argument_list|,
operator|(
operator|(
name|TimestampObjectInspector
operator|)
name|fields
operator|.
name|get
argument_list|(
name|columns
operator|.
name|length
argument_list|)
operator|.
name|getFieldObjectInspector
argument_list|()
operator|)
operator|.
name|getPrimitiveJavaObject
argument_list|(
name|values
operator|.
name|get
argument_list|(
name|columns
operator|.
name|length
argument_list|)
argument_list|)
operator|.
name|getTime
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|DruidWritable
argument_list|(
name|value
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|SerDeStats
name|getSerDeStats
parameter_list|()
block|{
comment|// no support for statistics
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Object
name|deserialize
parameter_list|(
name|Writable
name|writable
parameter_list|)
throws|throws
name|SerDeException
block|{
name|DruidWritable
name|input
init|=
operator|(
name|DruidWritable
operator|)
name|writable
decl_stmt|;
name|List
argument_list|<
name|Object
argument_list|>
name|output
init|=
name|Lists
operator|.
name|newArrayListWithExpectedSize
argument_list|(
name|columns
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|columns
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
specifier|final
name|Object
name|value
init|=
name|input
operator|.
name|getValue
argument_list|()
operator|.
name|get
argument_list|(
name|columns
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|value
operator|==
literal|null
condition|)
block|{
name|output
operator|.
name|add
argument_list|(
literal|null
argument_list|)
expr_stmt|;
continue|continue;
block|}
switch|switch
condition|(
name|types
index|[
name|i
index|]
operator|.
name|getPrimitiveCategory
argument_list|()
condition|)
block|{
case|case
name|TIMESTAMP
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|TimestampWritable
argument_list|(
operator|new
name|Timestamp
argument_list|(
operator|(
name|Long
operator|)
name|value
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|BYTE
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|ByteWritable
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|byteValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|SHORT
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|ShortWritable
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|shortValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|INT
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|IntWritable
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|intValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|LONG
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|LongWritable
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|longValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|FLOAT
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|FloatWritable
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|floatValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|DOUBLE
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|DoubleWritable
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|doubleValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|DECIMAL
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|HiveDecimalWritable
argument_list|(
name|HiveDecimal
operator|.
name|create
argument_list|(
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|doubleValue
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|STRING
case|:
name|output
operator|.
name|add
argument_list|(
operator|new
name|Text
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Unknown type: "
operator|+
name|types
index|[
name|i
index|]
operator|.
name|getPrimitiveCategory
argument_list|()
argument_list|)
throw|;
block|}
block|}
return|return
name|output
return|;
block|}
annotation|@
name|Override
specifier|public
name|ObjectInspector
name|getObjectInspector
parameter_list|()
throws|throws
name|SerDeException
block|{
return|return
name|inspector
return|;
block|}
block|}
end_class

end_unit

