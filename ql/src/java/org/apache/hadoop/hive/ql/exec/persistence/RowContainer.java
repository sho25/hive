begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|persistence
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
operator|.
name|RecordWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveFileFormatUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
operator|.
name|ObjectInspectorCopyOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_comment
comment|/**  * Simple persistent container for rows.  *  * This container interface only accepts adding or appending new rows and iterating through the rows  * in the order of their insertions.  *  * The iterator interface is a lightweight first()/next() API rather than the Java Iterator  * interface. This way we do not need to create an Iterator object every time we want to start a new  * iteration. Below is simple example of how to convert a typical Java's Iterator code to the LW  * iterator interface.  *  * Iterator itr = rowContainer.iterator(); while (itr.hasNext()) { v = itr.next(); // do anything  * with v }  *  * can be rewritten to:  *  * for ( v = rowContainer.first(); v != null; v = rowContainer.next()) { // do anything with v }  *  * Once the first is called, it will not be able to write again. So there can not be any writes  * after read. It can be read multiple times, but it does not support multiple reader interleaving  * reading.  *  */
end_comment

begin_class
specifier|public
class|class
name|RowContainer
parameter_list|<
name|ROW
extends|extends
name|List
parameter_list|<
name|Object
parameter_list|>
parameter_list|>
implements|implements
name|AbstractRowContainer
argument_list|<
name|ROW
argument_list|>
implements|,
name|AbstractRowContainer
operator|.
name|RowIterator
argument_list|<
name|ROW
argument_list|>
block|{
specifier|protected
specifier|static
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|RowContainer
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// max # of rows can be put into one block
specifier|private
specifier|static
specifier|final
name|int
name|BLOCKSIZE
init|=
literal|25000
decl_stmt|;
specifier|private
name|ROW
index|[]
name|currentWriteBlock
decl_stmt|;
comment|// the last block that add() should append to
specifier|private
name|ROW
index|[]
name|currentReadBlock
decl_stmt|;
comment|// the current block where the cursor is in
comment|// since currentReadBlock may assigned to currentWriteBlock, we need to store
comment|// original read block
specifier|private
name|ROW
index|[]
name|firstReadBlockPointer
decl_stmt|;
specifier|private
name|int
name|blockSize
decl_stmt|;
comment|// number of objects in the block before it is spilled
comment|// to disk
specifier|private
name|int
name|numFlushedBlocks
decl_stmt|;
comment|// total # of blocks
specifier|private
name|long
name|size
decl_stmt|;
comment|// total # of elements in the RowContainer
specifier|private
name|File
name|tmpFile
decl_stmt|;
comment|// temporary file holding the spilled blocks
name|Path
name|tempOutPath
init|=
literal|null
decl_stmt|;
specifier|private
name|File
name|parentFile
decl_stmt|;
specifier|private
name|int
name|itrCursor
decl_stmt|;
comment|// iterator cursor in the currBlock
specifier|private
name|int
name|readBlockSize
decl_stmt|;
comment|// size of current read block
specifier|private
name|int
name|addCursor
decl_stmt|;
comment|// append cursor in the lastBlock
specifier|private
name|SerDe
name|serde
decl_stmt|;
comment|// serialization/deserialization for the row
specifier|private
name|ObjectInspector
name|standardOI
decl_stmt|;
comment|// object inspector for the row
specifier|private
name|List
argument_list|<
name|Object
argument_list|>
name|keyObject
decl_stmt|;
specifier|private
name|TableDesc
name|tblDesc
decl_stmt|;
name|boolean
name|firstCalled
init|=
literal|false
decl_stmt|;
comment|// once called first, it will never be able to
comment|// write again.
name|int
name|acutalSplitNum
init|=
literal|0
decl_stmt|;
name|int
name|currentSplitPointer
init|=
literal|0
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
name|rr
init|=
literal|null
decl_stmt|;
comment|// record reader
name|RecordWriter
name|rw
init|=
literal|null
decl_stmt|;
name|InputFormat
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|>
name|inputFormat
init|=
literal|null
decl_stmt|;
name|InputSplit
index|[]
name|inputSplits
init|=
literal|null
decl_stmt|;
specifier|private
name|ROW
name|dummyRow
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|Reporter
name|reporter
decl_stmt|;
name|Writable
name|val
init|=
literal|null
decl_stmt|;
comment|// cached to use serialize data
name|Configuration
name|jc
decl_stmt|;
name|JobConf
name|jobCloneUsingLocalFs
init|=
literal|null
decl_stmt|;
specifier|private
name|LocalFileSystem
name|localFs
decl_stmt|;
specifier|public
name|RowContainer
parameter_list|(
name|Configuration
name|jc
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
argument_list|(
name|BLOCKSIZE
argument_list|,
name|jc
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
block|}
specifier|public
name|RowContainer
parameter_list|(
name|int
name|bs
parameter_list|,
name|Configuration
name|jc
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// no 0-sized block
name|this
operator|.
name|blockSize
operator|=
name|bs
operator|<=
literal|0
condition|?
name|BLOCKSIZE
else|:
name|bs
expr_stmt|;
name|this
operator|.
name|size
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|itrCursor
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|addCursor
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|numFlushedBlocks
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|tmpFile
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|currentWriteBlock
operator|=
operator|(
name|ROW
index|[]
operator|)
operator|new
name|ArrayList
index|[
name|blockSize
index|]
expr_stmt|;
name|this
operator|.
name|currentReadBlock
operator|=
name|this
operator|.
name|currentWriteBlock
expr_stmt|;
name|this
operator|.
name|firstReadBlockPointer
operator|=
name|currentReadBlock
expr_stmt|;
name|this
operator|.
name|serde
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|standardOI
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|jc
operator|=
name|jc
expr_stmt|;
if|if
condition|(
name|reporter
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|reporter
operator|=
name|Reporter
operator|.
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|reporter
operator|=
name|reporter
expr_stmt|;
block|}
block|}
specifier|private
name|JobConf
name|getLocalFSJobConfClone
parameter_list|(
name|Configuration
name|jc
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|jobCloneUsingLocalFs
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|jobCloneUsingLocalFs
operator|=
operator|new
name|JobConf
argument_list|(
name|jc
argument_list|)
expr_stmt|;
name|HiveConf
operator|.
name|setVar
argument_list|(
name|jobCloneUsingLocalFs
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPFS
argument_list|,
name|Utilities
operator|.
name|HADOOP_LOCAL_FS
argument_list|)
expr_stmt|;
block|}
return|return
name|this
operator|.
name|jobCloneUsingLocalFs
return|;
block|}
specifier|public
name|void
name|setSerDe
parameter_list|(
name|SerDe
name|sd
parameter_list|,
name|ObjectInspector
name|oi
parameter_list|)
block|{
name|this
operator|.
name|serde
operator|=
name|sd
expr_stmt|;
name|this
operator|.
name|standardOI
operator|=
name|oi
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|addRow
parameter_list|(
name|ROW
name|t
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|this
operator|.
name|tblDesc
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|willSpill
argument_list|()
condition|)
block|{
comment|// spill the current block to tmp file
name|spillBlock
argument_list|(
name|currentWriteBlock
argument_list|,
name|addCursor
argument_list|)
expr_stmt|;
name|addCursor
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|numFlushedBlocks
operator|==
literal|1
condition|)
block|{
name|currentWriteBlock
operator|=
operator|(
name|ROW
index|[]
operator|)
operator|new
name|ArrayList
index|[
name|blockSize
index|]
expr_stmt|;
block|}
block|}
name|currentWriteBlock
index|[
name|addCursor
operator|++
index|]
operator|=
name|t
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
comment|// the tableDesc will be null in the case that all columns in that table
comment|// is not used. we use a dummy row to denote all rows in that table, and
comment|// the dummy row is added by caller.
name|this
operator|.
name|dummyRow
operator|=
name|t
expr_stmt|;
block|}
operator|++
name|size
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|AbstractRowContainer
operator|.
name|RowIterator
argument_list|<
name|ROW
argument_list|>
name|rowIter
parameter_list|()
block|{
return|return
name|this
return|;
block|}
annotation|@
name|Override
specifier|public
name|ROW
name|first
parameter_list|()
throws|throws
name|HiveException
block|{
if|if
condition|(
name|size
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
try|try
block|{
name|firstCalled
operator|=
literal|true
expr_stmt|;
comment|// when we reach here, we must have some data already (because size>0).
comment|// We need to see if there are any data flushed into file system. If not,
comment|// we can
comment|// directly read from the current write block. Otherwise, we need to read
comment|// from the beginning of the underlying file.
name|this
operator|.
name|itrCursor
operator|=
literal|0
expr_stmt|;
name|closeWriter
argument_list|()
expr_stmt|;
name|closeReader
argument_list|()
expr_stmt|;
if|if
condition|(
name|tblDesc
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|itrCursor
operator|++
expr_stmt|;
return|return
name|dummyRow
return|;
block|}
name|this
operator|.
name|currentReadBlock
operator|=
name|this
operator|.
name|firstReadBlockPointer
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|numFlushedBlocks
operator|==
literal|0
condition|)
block|{
name|this
operator|.
name|readBlockSize
operator|=
name|this
operator|.
name|addCursor
expr_stmt|;
name|this
operator|.
name|currentReadBlock
operator|=
name|this
operator|.
name|currentWriteBlock
expr_stmt|;
block|}
else|else
block|{
name|JobConf
name|localJc
init|=
name|getLocalFSJobConfClone
argument_list|(
name|jc
argument_list|)
decl_stmt|;
if|if
condition|(
name|inputSplits
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|inputFormat
operator|==
literal|null
condition|)
block|{
name|inputFormat
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|tblDesc
operator|.
name|getInputFileFormatClass
argument_list|()
argument_list|,
name|localJc
argument_list|)
expr_stmt|;
block|}
name|HiveConf
operator|.
name|setVar
argument_list|(
name|localJc
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPMAPREDINPUTDIR
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|escapeString
argument_list|(
name|parentFile
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|inputSplits
operator|=
name|inputFormat
operator|.
name|getSplits
argument_list|(
name|localJc
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|acutalSplitNum
operator|=
name|inputSplits
operator|.
name|length
expr_stmt|;
block|}
name|currentSplitPointer
operator|=
literal|0
expr_stmt|;
name|rr
operator|=
name|inputFormat
operator|.
name|getRecordReader
argument_list|(
name|inputSplits
index|[
name|currentSplitPointer
index|]
argument_list|,
name|localJc
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
name|currentSplitPointer
operator|++
expr_stmt|;
name|nextBlock
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
comment|// we are guaranteed that we can get data here (since 'size' is not zero)
name|ROW
name|ret
init|=
name|currentReadBlock
index|[
name|itrCursor
operator|++
index|]
decl_stmt|;
name|removeKeys
argument_list|(
name|ret
argument_list|)
expr_stmt|;
return|return
name|ret
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|ROW
name|next
parameter_list|()
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|firstCalled
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Call first() then call next()."
argument_list|)
throw|;
block|}
if|if
condition|(
name|size
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|tblDesc
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|itrCursor
operator|<
name|size
condition|)
block|{
name|this
operator|.
name|itrCursor
operator|++
expr_stmt|;
return|return
name|dummyRow
return|;
block|}
return|return
literal|null
return|;
block|}
name|ROW
name|ret
decl_stmt|;
if|if
condition|(
name|itrCursor
operator|<
name|this
operator|.
name|readBlockSize
condition|)
block|{
name|ret
operator|=
name|this
operator|.
name|currentReadBlock
index|[
name|itrCursor
operator|++
index|]
expr_stmt|;
name|removeKeys
argument_list|(
name|ret
argument_list|)
expr_stmt|;
return|return
name|ret
return|;
block|}
else|else
block|{
name|nextBlock
argument_list|(
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|readBlockSize
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|currentWriteBlock
operator|!=
literal|null
operator|&&
name|currentReadBlock
operator|!=
name|currentWriteBlock
condition|)
block|{
name|setWriteBlockAsReadBlock
argument_list|()
expr_stmt|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
return|return
name|next
argument_list|()
return|;
block|}
block|}
specifier|private
name|void
name|removeKeys
parameter_list|(
name|ROW
name|ret
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|keyObject
operator|!=
literal|null
operator|&&
name|this
operator|.
name|currentReadBlock
operator|!=
name|this
operator|.
name|currentWriteBlock
condition|)
block|{
name|int
name|len
init|=
name|this
operator|.
name|keyObject
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|rowSize
init|=
name|ret
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|len
condition|;
name|i
operator|++
control|)
block|{
name|ret
operator|.
name|remove
argument_list|(
name|rowSize
operator|-
name|i
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|final
name|ArrayList
argument_list|<
name|Object
argument_list|>
name|row
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
literal|2
argument_list|)
decl_stmt|;
specifier|private
name|void
name|spillBlock
parameter_list|(
name|ROW
index|[]
name|block
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
name|tmpFile
operator|==
literal|null
condition|)
block|{
name|setupWriter
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|rw
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"RowContainer has already been closed for writing."
argument_list|)
throw|;
block|}
name|row
operator|.
name|clear
argument_list|()
expr_stmt|;
name|row
operator|.
name|add
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|row
operator|.
name|add
argument_list|(
literal|null
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|keyObject
operator|!=
literal|null
condition|)
block|{
name|row
operator|.
name|set
argument_list|(
literal|1
argument_list|,
name|this
operator|.
name|keyObject
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|length
condition|;
operator|++
name|i
control|)
block|{
name|ROW
name|currentValRow
init|=
name|block
index|[
name|i
index|]
decl_stmt|;
name|row
operator|.
name|set
argument_list|(
literal|0
argument_list|,
name|currentValRow
argument_list|)
expr_stmt|;
name|Writable
name|outVal
init|=
name|serde
operator|.
name|serialize
argument_list|(
name|row
argument_list|,
name|standardOI
argument_list|)
decl_stmt|;
name|rw
operator|.
name|write
argument_list|(
name|outVal
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|length
condition|;
operator|++
name|i
control|)
block|{
name|ROW
name|currentValRow
init|=
name|block
index|[
name|i
index|]
decl_stmt|;
name|Writable
name|outVal
init|=
name|serde
operator|.
name|serialize
argument_list|(
name|currentValRow
argument_list|,
name|standardOI
argument_list|)
decl_stmt|;
name|rw
operator|.
name|write
argument_list|(
name|outVal
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|block
operator|==
name|this
operator|.
name|currentWriteBlock
condition|)
block|{
name|this
operator|.
name|addCursor
operator|=
literal|0
expr_stmt|;
block|}
name|this
operator|.
name|numFlushedBlocks
operator|++
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|clearRows
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|e
operator|instanceof
name|HiveException
condition|)
block|{
throw|throw
operator|(
name|HiveException
operator|)
name|e
throw|;
block|}
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasRows
parameter_list|()
block|{
return|return
name|size
operator|>
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isSingleRow
parameter_list|()
block|{
return|return
name|size
operator|==
literal|1
return|;
block|}
comment|/**    * Get the number of elements in the RowContainer.    *    * @return number of elements in the RowContainer    */
annotation|@
name|Override
specifier|public
name|int
name|rowCount
parameter_list|()
block|{
return|return
operator|(
name|int
operator|)
name|size
return|;
block|}
specifier|protected
name|boolean
name|nextBlock
parameter_list|(
name|int
name|readIntoOffset
parameter_list|)
throws|throws
name|HiveException
block|{
name|itrCursor
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|readBlockSize
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|numFlushedBlocks
operator|==
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
try|try
block|{
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
name|serde
operator|.
name|getSerializedClass
argument_list|()
operator|.
name|newInstance
argument_list|()
expr_stmt|;
block|}
name|boolean
name|nextSplit
init|=
literal|true
decl_stmt|;
name|int
name|i
init|=
name|readIntoOffset
decl_stmt|;
if|if
condition|(
name|rr
operator|!=
literal|null
condition|)
block|{
name|Object
name|key
init|=
name|rr
operator|.
name|createKey
argument_list|()
decl_stmt|;
while|while
condition|(
name|i
operator|<
name|this
operator|.
name|currentReadBlock
operator|.
name|length
operator|&&
name|rr
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
name|nextSplit
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|currentReadBlock
index|[
name|i
operator|++
index|]
operator|=
operator|(
name|ROW
operator|)
name|ObjectInspectorUtils
operator|.
name|copyToStandardObject
argument_list|(
name|serde
operator|.
name|deserialize
argument_list|(
name|val
argument_list|)
argument_list|,
name|serde
operator|.
name|getObjectInspector
argument_list|()
argument_list|,
name|ObjectInspectorCopyOption
operator|.
name|WRITABLE
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|nextSplit
operator|&&
name|this
operator|.
name|currentSplitPointer
operator|<
name|this
operator|.
name|acutalSplitNum
condition|)
block|{
name|JobConf
name|localJc
init|=
name|getLocalFSJobConfClone
argument_list|(
name|jc
argument_list|)
decl_stmt|;
comment|// open record reader to read next split
name|rr
operator|=
name|inputFormat
operator|.
name|getRecordReader
argument_list|(
name|inputSplits
index|[
name|currentSplitPointer
index|]
argument_list|,
name|jobCloneUsingLocalFs
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
name|currentSplitPointer
operator|++
expr_stmt|;
return|return
name|nextBlock
argument_list|(
literal|0
argument_list|)
return|;
block|}
name|this
operator|.
name|readBlockSize
operator|=
name|i
expr_stmt|;
return|return
name|this
operator|.
name|readBlockSize
operator|>
literal|0
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|clearRows
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|copyToDFSDirecory
parameter_list|(
name|FileSystem
name|destFs
parameter_list|,
name|Path
name|destPath
parameter_list|)
throws|throws
name|IOException
throws|,
name|HiveException
block|{
if|if
condition|(
name|addCursor
operator|>
literal|0
condition|)
block|{
name|this
operator|.
name|spillBlock
argument_list|(
name|this
operator|.
name|currentWriteBlock
argument_list|,
name|addCursor
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|tempOutPath
operator|==
literal|null
operator|||
name|tempOutPath
operator|.
name|toString
argument_list|()
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
return|return;
block|}
name|this
operator|.
name|closeWriter
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"RowContainer copied temp file "
operator|+
name|tmpFile
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|" to dfs directory "
operator|+
name|destPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|destFs
operator|.
name|copyFromLocalFile
argument_list|(
literal|true
argument_list|,
name|tempOutPath
argument_list|,
operator|new
name|Path
argument_list|(
name|destPath
argument_list|,
operator|new
name|Path
argument_list|(
name|tempOutPath
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|clearRows
argument_list|()
expr_stmt|;
block|}
comment|/**    * Remove all elements in the RowContainer.    */
annotation|@
name|Override
specifier|public
name|void
name|clearRows
parameter_list|()
throws|throws
name|HiveException
block|{
name|itrCursor
operator|=
literal|0
expr_stmt|;
name|addCursor
operator|=
literal|0
expr_stmt|;
name|numFlushedBlocks
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|readBlockSize
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|acutalSplitNum
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|currentSplitPointer
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|firstCalled
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|inputSplits
operator|=
literal|null
expr_stmt|;
name|tempOutPath
operator|=
literal|null
expr_stmt|;
name|addCursor
operator|=
literal|0
expr_stmt|;
name|size
operator|=
literal|0
expr_stmt|;
try|try
block|{
if|if
condition|(
name|rw
operator|!=
literal|null
condition|)
block|{
name|rw
operator|.
name|close
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rr
operator|!=
literal|null
condition|)
block|{
name|rr
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|rw
operator|=
literal|null
expr_stmt|;
name|rr
operator|=
literal|null
expr_stmt|;
name|tmpFile
operator|=
literal|null
expr_stmt|;
name|deleteLocalFile
argument_list|(
name|parentFile
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|parentFile
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|deleteLocalFile
parameter_list|(
name|File
name|file
parameter_list|,
name|boolean
name|recursive
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|file
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|file
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|file
operator|.
name|isDirectory
argument_list|()
operator|&&
name|recursive
condition|)
block|{
name|File
index|[]
name|files
init|=
name|file
operator|.
name|listFiles
argument_list|()
decl_stmt|;
for|for
control|(
name|File
name|file2
range|:
name|files
control|)
block|{
name|deleteLocalFile
argument_list|(
name|file2
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
name|boolean
name|deleteSuccess
init|=
name|file
operator|.
name|delete
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|deleteSuccess
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error deleting tmp file:"
operator|+
name|file
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error deleting tmp file:"
operator|+
name|file
operator|.
name|getAbsolutePath
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|closeWriter
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|rw
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|rw
operator|.
name|close
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|rw
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|closeReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|rr
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|rr
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|rr
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|setKeyObject
parameter_list|(
name|List
argument_list|<
name|Object
argument_list|>
name|dummyKey
parameter_list|)
block|{
name|this
operator|.
name|keyObject
operator|=
name|dummyKey
expr_stmt|;
block|}
specifier|public
name|void
name|setTableDesc
parameter_list|(
name|TableDesc
name|tblDesc
parameter_list|)
block|{
name|this
operator|.
name|tblDesc
operator|=
name|tblDesc
expr_stmt|;
block|}
specifier|protected
name|int
name|getAddCursor
parameter_list|()
block|{
return|return
name|addCursor
return|;
block|}
specifier|protected
specifier|final
name|boolean
name|willSpill
parameter_list|()
block|{
return|return
name|addCursor
operator|>=
name|blockSize
return|;
block|}
specifier|protected
name|int
name|getBlockSize
parameter_list|()
block|{
return|return
name|blockSize
return|;
block|}
specifier|protected
name|void
name|setupWriter
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
name|tmpFile
operator|!=
literal|null
condition|)
block|{
return|return;
block|}
name|String
name|suffix
init|=
literal|".tmp"
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|keyObject
operator|!=
literal|null
condition|)
block|{
name|suffix
operator|=
literal|"."
operator|+
name|this
operator|.
name|keyObject
operator|.
name|toString
argument_list|()
operator|+
name|suffix
expr_stmt|;
block|}
while|while
condition|(
literal|true
condition|)
block|{
name|parentFile
operator|=
name|File
operator|.
name|createTempFile
argument_list|(
literal|"hive-rowcontainer"
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|boolean
name|success
init|=
name|parentFile
operator|.
name|delete
argument_list|()
operator|&&
name|parentFile
operator|.
name|mkdir
argument_list|()
decl_stmt|;
if|if
condition|(
name|success
condition|)
block|{
break|break;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"retry creating tmp row-container directory..."
argument_list|)
expr_stmt|;
block|}
name|tmpFile
operator|=
name|File
operator|.
name|createTempFile
argument_list|(
literal|"RowContainer"
argument_list|,
name|suffix
argument_list|,
name|parentFile
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"RowContainer created temp file "
operator|+
name|tmpFile
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
comment|// Delete the temp file if the JVM terminate normally through Hadoop job
comment|// kill command.
comment|// Caveat: it won't be deleted if JVM is killed by 'kill -9'.
name|parentFile
operator|.
name|deleteOnExit
argument_list|()
expr_stmt|;
name|tmpFile
operator|.
name|deleteOnExit
argument_list|()
expr_stmt|;
comment|// rFile = new RandomAccessFile(tmpFile, "rw");
name|HiveOutputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|hiveOutputFormat
init|=
name|HiveFileFormatUtils
operator|.
name|getHiveOutputFormat
argument_list|(
name|jc
argument_list|,
name|tblDesc
argument_list|)
decl_stmt|;
name|tempOutPath
operator|=
operator|new
name|Path
argument_list|(
name|tmpFile
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|JobConf
name|localJc
init|=
name|getLocalFSJobConfClone
argument_list|(
name|jc
argument_list|)
decl_stmt|;
name|rw
operator|=
name|HiveFileFormatUtils
operator|.
name|getRecordWriter
argument_list|(
name|this
operator|.
name|jobCloneUsingLocalFs
argument_list|,
name|hiveOutputFormat
argument_list|,
name|serde
operator|.
name|getSerializedClass
argument_list|()
argument_list|,
literal|false
argument_list|,
name|tblDesc
operator|.
name|getProperties
argument_list|()
argument_list|,
name|tempOutPath
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|clearRows
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|protected
name|RecordWriter
name|getRecordWriter
parameter_list|()
block|{
return|return
name|rw
return|;
block|}
specifier|protected
name|InputSplit
index|[]
name|getInputSplits
parameter_list|()
block|{
return|return
name|inputSplits
return|;
block|}
specifier|protected
name|boolean
name|endOfCurrentReadBlock
parameter_list|()
block|{
if|if
condition|(
name|tblDesc
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|itrCursor
operator|>=
name|this
operator|.
name|readBlockSize
return|;
block|}
specifier|protected
name|int
name|getCurrentReadBlockSize
parameter_list|()
block|{
return|return
name|readBlockSize
return|;
block|}
specifier|protected
name|void
name|setWriteBlockAsReadBlock
parameter_list|()
block|{
name|this
operator|.
name|itrCursor
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|readBlockSize
operator|=
name|this
operator|.
name|addCursor
expr_stmt|;
name|this
operator|.
name|firstReadBlockPointer
operator|=
name|this
operator|.
name|currentReadBlock
expr_stmt|;
name|currentReadBlock
operator|=
name|currentWriteBlock
expr_stmt|;
block|}
specifier|protected
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
name|setReaderAtSplit
parameter_list|(
name|int
name|splitNum
parameter_list|)
throws|throws
name|IOException
block|{
name|JobConf
name|localJc
init|=
name|getLocalFSJobConfClone
argument_list|(
name|jc
argument_list|)
decl_stmt|;
name|currentSplitPointer
operator|=
name|splitNum
expr_stmt|;
if|if
condition|(
name|rr
operator|!=
literal|null
condition|)
block|{
name|rr
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// open record reader to read next split
name|rr
operator|=
name|inputFormat
operator|.
name|getRecordReader
argument_list|(
name|inputSplits
index|[
name|currentSplitPointer
index|]
argument_list|,
name|jobCloneUsingLocalFs
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
name|currentSplitPointer
operator|++
expr_stmt|;
return|return
name|rr
return|;
block|}
specifier|protected
name|ROW
name|getReadBlockRow
parameter_list|(
name|int
name|rowOffset
parameter_list|)
block|{
name|itrCursor
operator|=
name|rowOffset
operator|+
literal|1
expr_stmt|;
return|return
name|currentReadBlock
index|[
name|rowOffset
index|]
return|;
block|}
specifier|protected
name|void
name|resetCurrentReadBlockToFirstReadBlock
parameter_list|()
block|{
name|currentReadBlock
operator|=
name|firstReadBlockPointer
expr_stmt|;
block|}
specifier|protected
name|void
name|resetReadBlocks
parameter_list|()
block|{
name|this
operator|.
name|currentReadBlock
operator|=
name|this
operator|.
name|currentWriteBlock
expr_stmt|;
name|this
operator|.
name|firstReadBlockPointer
operator|=
name|currentReadBlock
expr_stmt|;
block|}
specifier|protected
name|void
name|close
parameter_list|()
throws|throws
name|HiveException
block|{
name|clearRows
argument_list|()
expr_stmt|;
name|currentReadBlock
operator|=
name|firstReadBlockPointer
operator|=
name|currentWriteBlock
operator|=
literal|null
expr_stmt|;
block|}
block|}
end_class

end_unit

