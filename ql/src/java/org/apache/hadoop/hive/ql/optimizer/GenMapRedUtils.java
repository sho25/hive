begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Context
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ColumnInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ConditionalTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|DemuxOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|DependencyCollectionTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|JoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MapJoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MoveTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|NodeUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|OperatorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|OperatorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ReduceSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|RowSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|SMBMapJoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TableScanOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Task
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TaskFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|UnionOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecDriver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|MapRedTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|spark
operator|.
name|SparkTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|ReadEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|RCFileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|merge
operator|.
name|MergeFileWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcFileStripeMergeInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|rcfile
operator|.
name|merge
operator|.
name|RCFileBlockMergeInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|GenMRProcContext
operator|.
name|GenMRUnionCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|GenMRProcContext
operator|.
name|GenMapRedCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|listbucketingpruner
operator|.
name|ListBucketingPruner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|ppr
operator|.
name|PartitionPruner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|BaseSemanticAnalyzer
operator|.
name|TableSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ParseContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|PrunedPartitionList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|BaseWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalResolverMergeFiles
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalResolverMergeFiles
operator|.
name|ConditionalResolverMergeFilesCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DynamicPartitionCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FetchWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FileMergeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FileSinkDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FilterDesc
operator|.
name|SampleDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|LoadFileDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapredLocalWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapredWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MoveWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OrcFileMergeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PlanUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|RCFileMergeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceSinkDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|SparkWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|StatsWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableScanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Interner
import|;
end_import

begin_comment
comment|/**  * General utility common functions for the Processor to convert operator into  * map-reduce tasks.  */
end_comment

begin_class
specifier|public
specifier|final
class|class
name|GenMapRedUtils
block|{
specifier|private
specifier|static
name|Logger
name|LOG
decl_stmt|;
static|static
block|{
name|LOG
operator|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils"
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|boolean
name|needsTagging
parameter_list|(
name|ReduceWork
name|rWork
parameter_list|)
block|{
return|return
name|rWork
operator|!=
literal|null
operator|&&
operator|(
name|rWork
operator|.
name|getReducer
argument_list|()
operator|.
name|getClass
argument_list|()
operator|==
name|JoinOperator
operator|.
name|class
operator|||
name|rWork
operator|.
name|getReducer
argument_list|()
operator|.
name|getClass
argument_list|()
operator|==
name|DemuxOperator
operator|.
name|class
operator|)
return|;
block|}
comment|/**    * Initialize the current plan by adding it to root tasks.    *    * @param op    *          the reduce sink operator encountered    * @param opProcCtx    *          processing context    */
specifier|public
specifier|static
name|void
name|initPlan
parameter_list|(
name|ReduceSinkOperator
name|op
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|reducer
init|=
name|op
operator|.
name|getChildOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|,
name|GenMapRedCtx
argument_list|>
name|mapCurrCtx
init|=
name|opProcCtx
operator|.
name|getMapCurrCtx
argument_list|()
decl_stmt|;
name|GenMapRedCtx
name|mapredCtx
init|=
name|mapCurrCtx
operator|.
name|get
argument_list|(
name|op
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
init|=
name|mapredCtx
operator|.
name|getCurrTask
argument_list|()
decl_stmt|;
name|MapredWork
name|plan
init|=
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|opTaskMap
init|=
name|opProcCtx
operator|.
name|getOpTaskMap
argument_list|()
decl_stmt|;
name|TableScanOperator
name|currTopOp
init|=
name|opProcCtx
operator|.
name|getCurrTopOp
argument_list|()
decl_stmt|;
name|opTaskMap
operator|.
name|put
argument_list|(
name|reducer
argument_list|,
name|currTask
argument_list|)
expr_stmt|;
name|plan
operator|.
name|setReduceWork
argument_list|(
operator|new
name|ReduceWork
argument_list|()
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setReducer
argument_list|(
name|reducer
argument_list|)
expr_stmt|;
name|ReduceSinkDesc
name|desc
init|=
name|op
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setNumReduceTasks
argument_list|(
name|desc
operator|.
name|getNumReducers
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|needsTagging
argument_list|(
name|plan
operator|.
name|getReduceWork
argument_list|()
argument_list|)
condition|)
block|{
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setNeedsTagging
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
assert|assert
name|currTopOp
operator|!=
literal|null
assert|;
name|String
name|currAliasId
init|=
name|opProcCtx
operator|.
name|getCurrAliasId
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|opProcCtx
operator|.
name|isSeenOp
argument_list|(
name|currTask
argument_list|,
name|currTopOp
argument_list|)
condition|)
block|{
name|setTaskPlan
argument_list|(
name|currAliasId
argument_list|,
name|currTopOp
argument_list|,
name|currTask
argument_list|,
literal|false
argument_list|,
name|opProcCtx
argument_list|)
expr_stmt|;
block|}
name|currTopOp
operator|=
literal|null
expr_stmt|;
name|currAliasId
operator|=
literal|null
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrTask
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrTopOp
argument_list|(
name|currTopOp
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrAliasId
argument_list|(
name|currAliasId
argument_list|)
expr_stmt|;
block|}
comment|/**    * Initialize the current union plan.    *    * @param op    *          the reduce sink operator encountered    * @param opProcCtx    *          processing context    */
specifier|public
specifier|static
name|void
name|initUnionPlan
parameter_list|(
name|ReduceSinkOperator
name|op
parameter_list|,
name|UnionOperator
name|currUnionOp
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|unionTask
parameter_list|)
throws|throws
name|SemanticException
block|{
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|reducer
init|=
name|op
operator|.
name|getChildOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|MapredWork
name|plan
init|=
operator|(
name|MapredWork
operator|)
name|unionTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|opTaskMap
init|=
name|opProcCtx
operator|.
name|getOpTaskMap
argument_list|()
decl_stmt|;
name|opTaskMap
operator|.
name|put
argument_list|(
name|reducer
argument_list|,
name|unionTask
argument_list|)
expr_stmt|;
name|plan
operator|.
name|setReduceWork
argument_list|(
operator|new
name|ReduceWork
argument_list|()
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setReducer
argument_list|(
name|reducer
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setReducer
argument_list|(
name|reducer
argument_list|)
expr_stmt|;
name|ReduceSinkDesc
name|desc
init|=
name|op
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setNumReduceTasks
argument_list|(
name|desc
operator|.
name|getNumReducers
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|needsTagging
argument_list|(
name|plan
operator|.
name|getReduceWork
argument_list|()
argument_list|)
condition|)
block|{
name|plan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setNeedsTagging
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
name|initUnionPlan
argument_list|(
name|opProcCtx
argument_list|,
name|currUnionOp
argument_list|,
name|unionTask
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|setUnionPlan
parameter_list|(
name|GenMRProcContext
name|opProcCtx
parameter_list|,
name|boolean
name|local
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|GenMRUnionCtx
name|uCtx
parameter_list|,
name|boolean
name|mergeTask
parameter_list|)
throws|throws
name|SemanticException
block|{
name|TableScanOperator
name|currTopOp
init|=
name|opProcCtx
operator|.
name|getCurrTopOp
argument_list|()
decl_stmt|;
if|if
condition|(
name|currTopOp
operator|!=
literal|null
condition|)
block|{
name|String
name|currAliasId
init|=
name|opProcCtx
operator|.
name|getCurrAliasId
argument_list|()
decl_stmt|;
if|if
condition|(
name|mergeTask
operator|||
operator|!
name|opProcCtx
operator|.
name|isSeenOp
argument_list|(
name|currTask
argument_list|,
name|currTopOp
argument_list|)
condition|)
block|{
name|setTaskPlan
argument_list|(
name|currAliasId
argument_list|,
name|currTopOp
argument_list|,
name|currTask
argument_list|,
name|local
argument_list|,
name|opProcCtx
argument_list|)
expr_stmt|;
block|}
name|currTopOp
operator|=
literal|null
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrTopOp
argument_list|(
name|currTopOp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|String
argument_list|>
name|taskTmpDirLst
init|=
name|uCtx
operator|.
name|getTaskTmpDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|taskTmpDirLst
operator|!=
literal|null
operator|)
operator|&&
operator|!
operator|(
name|taskTmpDirLst
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
name|List
argument_list|<
name|TableDesc
argument_list|>
name|tt_descLst
init|=
name|uCtx
operator|.
name|getTTDesc
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|taskTmpDirLst
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|tt_descLst
operator|.
name|isEmpty
argument_list|()
assert|;
assert|assert
name|taskTmpDirLst
operator|.
name|size
argument_list|()
operator|==
name|tt_descLst
operator|.
name|size
argument_list|()
assert|;
name|int
name|size
init|=
name|taskTmpDirLst
operator|.
name|size
argument_list|()
decl_stmt|;
assert|assert
name|local
operator|==
literal|false
assert|;
name|List
argument_list|<
name|TableScanOperator
argument_list|>
name|topOperators
init|=
name|uCtx
operator|.
name|getListTopOperators
argument_list|()
decl_stmt|;
name|MapredWork
name|plan
init|=
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|size
condition|;
name|pos
operator|++
control|)
block|{
name|String
name|taskTmpDir
init|=
name|taskTmpDirLst
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
name|TableDesc
name|tt_desc
init|=
name|tt_descLst
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
name|MapWork
name|mWork
init|=
name|plan
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|mWork
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|taskTmpDir
argument_list|)
operator|==
literal|null
condition|)
block|{
name|mWork
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|put
argument_list|(
name|taskTmpDir
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|mWork
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|taskTmpDir
argument_list|)
operator|.
name|add
argument_list|(
name|taskTmpDir
argument_list|)
expr_stmt|;
name|mWork
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|taskTmpDir
argument_list|,
operator|new
name|PartitionDesc
argument_list|(
name|tt_desc
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|mWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|taskTmpDir
argument_list|,
name|topOperators
operator|.
name|get
argument_list|(
name|pos
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
comment|/*    * It is a idempotent function to add various intermediate files as the source    * for the union. The plan has already been created.    */
specifier|public
specifier|static
name|void
name|initUnionPlan
parameter_list|(
name|GenMRProcContext
name|opProcCtx
parameter_list|,
name|UnionOperator
name|currUnionOp
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|boolean
name|local
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// In case of lateral views followed by a join, the same tree
comment|// can be traversed more than one
if|if
condition|(
name|currUnionOp
operator|!=
literal|null
condition|)
block|{
name|GenMRUnionCtx
name|uCtx
init|=
name|opProcCtx
operator|.
name|getUnionTask
argument_list|(
name|currUnionOp
argument_list|)
decl_stmt|;
assert|assert
name|uCtx
operator|!=
literal|null
assert|;
name|setUnionPlan
argument_list|(
name|opProcCtx
argument_list|,
name|local
argument_list|,
name|currTask
argument_list|,
name|uCtx
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * join current union task to old task    */
specifier|public
specifier|static
name|void
name|joinUnionPlan
parameter_list|(
name|GenMRProcContext
name|opProcCtx
parameter_list|,
name|UnionOperator
name|currUnionOp
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currentUnionTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|existingTask
parameter_list|,
name|boolean
name|local
parameter_list|)
throws|throws
name|SemanticException
block|{
assert|assert
name|currUnionOp
operator|!=
literal|null
assert|;
name|GenMRUnionCtx
name|uCtx
init|=
name|opProcCtx
operator|.
name|getUnionTask
argument_list|(
name|currUnionOp
argument_list|)
decl_stmt|;
assert|assert
name|uCtx
operator|!=
literal|null
assert|;
name|setUnionPlan
argument_list|(
name|opProcCtx
argument_list|,
name|local
argument_list|,
name|existingTask
argument_list|,
name|uCtx
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|parTasks
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
operator|.
name|contains
argument_list|(
name|currentUnionTask
argument_list|)
condition|)
block|{
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
operator|.
name|remove
argument_list|(
name|currentUnionTask
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
operator|.
name|contains
argument_list|(
name|existingTask
argument_list|)
operator|&&
operator|(
name|existingTask
operator|.
name|getParentTasks
argument_list|()
operator|==
literal|null
operator|||
name|existingTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
operator|.
name|add
argument_list|(
name|existingTask
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|currentUnionTask
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|currentUnionTask
operator|.
name|getParentTasks
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|!
name|currentUnionTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|parTasks
operator|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
name|parTasks
operator|.
name|addAll
argument_list|(
name|currentUnionTask
operator|.
name|getParentTasks
argument_list|()
argument_list|)
expr_stmt|;
name|Object
index|[]
name|parTaskArr
init|=
name|parTasks
operator|.
name|toArray
argument_list|()
decl_stmt|;
for|for
control|(
name|Object
name|parTask
range|:
name|parTaskArr
control|)
block|{
operator|(
operator|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
operator|)
name|parTask
operator|)
operator|.
name|removeDependentTask
argument_list|(
name|currentUnionTask
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|currentUnionTask
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|parTasks
operator|!=
literal|null
operator|)
condition|)
block|{
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parTask
range|:
name|parTasks
control|)
block|{
name|parTask
operator|.
name|addDependentTask
argument_list|(
name|existingTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
operator|.
name|contains
argument_list|(
name|existingTask
argument_list|)
condition|)
block|{
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
operator|.
name|remove
argument_list|(
name|existingTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|opProcCtx
operator|.
name|setCurrTask
argument_list|(
name|existingTask
argument_list|)
expr_stmt|;
block|}
comment|/**    * Merge the current task into the old task for the reducer    *    * @param currTask    *          the current task for the current reducer    * @param oldTask    *          the old task for the current reducer    * @param opProcCtx    *          processing context    */
specifier|public
specifier|static
name|void
name|joinPlan
parameter_list|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|oldTask
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
assert|assert
name|currTask
operator|!=
literal|null
operator|&&
name|oldTask
operator|!=
literal|null
assert|;
name|TableScanOperator
name|currTopOp
init|=
name|opProcCtx
operator|.
name|getCurrTopOp
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|parTasks
init|=
literal|null
decl_stmt|;
comment|// terminate the old task and make current task dependent on it
if|if
condition|(
name|currTask
operator|.
name|getParentTasks
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|currTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|parTasks
operator|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
name|parTasks
operator|.
name|addAll
argument_list|(
name|currTask
operator|.
name|getParentTasks
argument_list|()
argument_list|)
expr_stmt|;
name|Object
index|[]
name|parTaskArr
init|=
name|parTasks
operator|.
name|toArray
argument_list|()
decl_stmt|;
for|for
control|(
name|Object
name|element
range|:
name|parTaskArr
control|)
block|{
operator|(
operator|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
operator|)
name|element
operator|)
operator|.
name|removeDependentTask
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|currTopOp
operator|!=
literal|null
condition|)
block|{
name|mergeInput
argument_list|(
name|currTopOp
argument_list|,
name|opProcCtx
argument_list|,
name|oldTask
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|parTasks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parTask
range|:
name|parTasks
control|)
block|{
name|parTask
operator|.
name|addDependentTask
argument_list|(
name|oldTask
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|oldTask
operator|instanceof
name|MapRedTask
operator|&&
name|currTask
operator|instanceof
name|MapRedTask
condition|)
block|{
operator|(
operator|(
name|MapRedTask
operator|)
name|currTask
operator|)
operator|.
name|getWork
argument_list|()
operator|.
name|getMapWork
argument_list|()
operator|.
name|mergingInto
argument_list|(
operator|(
operator|(
name|MapRedTask
operator|)
name|oldTask
operator|)
operator|.
name|getWork
argument_list|()
operator|.
name|getMapWork
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|opProcCtx
operator|.
name|setCurrTopOp
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrTask
argument_list|(
name|oldTask
argument_list|)
expr_stmt|;
block|}
comment|/**    * If currTopOp is not set for input of the task, add input for to the task    */
specifier|static
name|boolean
name|mergeInput
parameter_list|(
name|TableScanOperator
name|currTopOp
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|task
parameter_list|,
name|boolean
name|local
parameter_list|)
throws|throws
name|SemanticException
block|{
if|if
condition|(
operator|!
name|opProcCtx
operator|.
name|isSeenOp
argument_list|(
name|task
argument_list|,
name|currTopOp
argument_list|)
condition|)
block|{
name|String
name|currAliasId
init|=
name|opProcCtx
operator|.
name|getCurrAliasId
argument_list|()
decl_stmt|;
name|setTaskPlan
argument_list|(
name|currAliasId
argument_list|,
name|currTopOp
argument_list|,
name|task
argument_list|,
name|local
argument_list|,
name|opProcCtx
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Met cRS in pRS(parentTask)-cRS-OP(childTask) case    * Split and link two tasks by temporary file : pRS-FS / TS-cRS-OP    */
specifier|static
name|void
name|splitPlan
parameter_list|(
name|ReduceSinkOperator
name|cRS
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parentTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
assert|assert
name|parentTask
operator|!=
literal|null
operator|&&
name|childTask
operator|!=
literal|null
assert|;
name|splitTasks
argument_list|(
name|cRS
argument_list|,
name|parentTask
argument_list|,
name|childTask
argument_list|,
name|opProcCtx
argument_list|)
expr_stmt|;
block|}
comment|/**    * Met cRS in pOP(parentTask with RS)-cRS-cOP(noTask) case    * Create new child task for cRS-cOP and link two tasks by temporary file : pOP-FS / TS-cRS-cOP    *    * @param cRS    *          the reduce sink operator encountered    * @param opProcCtx    *          processing context    */
specifier|static
name|void
name|splitPlan
parameter_list|(
name|ReduceSinkOperator
name|cRS
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// Generate a new task
name|ParseContext
name|parseCtx
init|=
name|opProcCtx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parentTask
init|=
name|opProcCtx
operator|.
name|getCurrTask
argument_list|()
decl_stmt|;
name|MapredWork
name|childPlan
init|=
name|getMapRedWork
argument_list|(
name|parseCtx
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|childPlan
argument_list|,
name|parseCtx
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|reducer
init|=
name|cRS
operator|.
name|getChildOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// Add the reducer
name|ReduceWork
name|rWork
init|=
operator|new
name|ReduceWork
argument_list|()
decl_stmt|;
name|childPlan
operator|.
name|setReduceWork
argument_list|(
name|rWork
argument_list|)
expr_stmt|;
name|rWork
operator|.
name|setReducer
argument_list|(
name|reducer
argument_list|)
expr_stmt|;
name|ReduceSinkDesc
name|desc
init|=
name|cRS
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|childPlan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setNumReduceTasks
argument_list|(
operator|new
name|Integer
argument_list|(
name|desc
operator|.
name|getNumReducers
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|getOpTaskMap
argument_list|()
operator|.
name|put
argument_list|(
name|reducer
argument_list|,
name|childTask
argument_list|)
expr_stmt|;
name|splitTasks
argument_list|(
name|cRS
argument_list|,
name|parentTask
argument_list|,
name|childTask
argument_list|,
name|opProcCtx
argument_list|)
expr_stmt|;
block|}
comment|/**    * set the current task in the mapredWork.    *    * @param alias_id    *          current alias    * @param topOp    *          the top operator of the stack    * @param plan    *          current plan    * @param local    *          whether you need to add to map-reduce or local work    * @param opProcCtx    *          processing context    */
specifier|public
specifier|static
name|void
name|setTaskPlan
parameter_list|(
name|String
name|alias_id
parameter_list|,
name|TableScanOperator
name|topOp
parameter_list|,
name|Task
argument_list|<
name|?
argument_list|>
name|task
parameter_list|,
name|boolean
name|local
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
name|setTaskPlan
argument_list|(
name|alias_id
argument_list|,
name|topOp
argument_list|,
name|task
argument_list|,
name|local
argument_list|,
name|opProcCtx
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * set the current task in the mapredWork.    *    * @param alias_id    *          current alias    * @param topOp    *          the top operator of the stack    * @param plan    *          current plan    * @param local    *          whether you need to add to map-reduce or local work    * @param opProcCtx    *          processing context    * @param pList    *          pruned partition list. If it is null it will be computed on-the-fly.    */
specifier|public
specifier|static
name|void
name|setTaskPlan
parameter_list|(
name|String
name|alias_id
parameter_list|,
name|TableScanOperator
name|topOp
parameter_list|,
name|Task
argument_list|<
name|?
argument_list|>
name|task
parameter_list|,
name|boolean
name|local
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|,
name|PrunedPartitionList
name|pList
parameter_list|)
throws|throws
name|SemanticException
block|{
name|setMapWork
argument_list|(
operator|(
operator|(
name|MapredWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
operator|)
operator|.
name|getMapWork
argument_list|()
argument_list|,
name|opProcCtx
operator|.
name|getParseCtx
argument_list|()
argument_list|,
name|opProcCtx
operator|.
name|getInputs
argument_list|()
argument_list|,
name|pList
argument_list|,
name|topOp
argument_list|,
name|alias_id
argument_list|,
name|opProcCtx
operator|.
name|getConf
argument_list|()
argument_list|,
name|local
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|addSeenOp
argument_list|(
name|task
argument_list|,
name|topOp
argument_list|)
expr_stmt|;
block|}
comment|/**    * initialize MapWork    *    * @param alias_id    *          current alias    * @param topOp    *          the top operator of the stack    * @param plan    *          map work to initialize    * @param local    *          whether you need to add to map-reduce or local work    * @param pList    *          pruned partition list. If it is null it will be computed on-the-fly.    * @param inputs    *          read entities for the map work    * @param conf    *          current instance of hive conf    */
specifier|public
specifier|static
name|void
name|setMapWork
parameter_list|(
name|MapWork
name|plan
parameter_list|,
name|ParseContext
name|parseCtx
parameter_list|,
name|Set
argument_list|<
name|ReadEntity
argument_list|>
name|inputs
parameter_list|,
name|PrunedPartitionList
name|partsList
parameter_list|,
name|TableScanOperator
name|tsOp
parameter_list|,
name|String
name|alias_id
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|local
parameter_list|)
throws|throws
name|SemanticException
block|{
name|ArrayList
argument_list|<
name|Path
argument_list|>
name|partDir
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
name|ArrayList
argument_list|<
name|PartitionDesc
argument_list|>
name|partDesc
init|=
operator|new
name|ArrayList
argument_list|<
name|PartitionDesc
argument_list|>
argument_list|()
decl_stmt|;
name|boolean
name|isAcidTable
init|=
literal|false
decl_stmt|;
name|Path
name|tblDir
init|=
literal|null
decl_stmt|;
name|plan
operator|.
name|setNameToSplitSample
argument_list|(
name|parseCtx
operator|.
name|getNameToSplitSample
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|partsList
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|partsList
operator|=
name|PartitionPruner
operator|.
name|prune
argument_list|(
name|tsOp
argument_list|,
name|parseCtx
argument_list|,
name|alias_id
argument_list|)
expr_stmt|;
name|isAcidTable
operator|=
name|tsOp
operator|.
name|getConf
argument_list|()
operator|.
name|isAcidTable
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SemanticException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
block|}
comment|// Generate the map work for this alias_id
comment|// pass both confirmed and unknown partitions through the map-reduce
comment|// framework
name|Set
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
name|partsList
operator|.
name|getPartitions
argument_list|()
decl_stmt|;
name|PartitionDesc
name|aliasPartnDesc
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|parts
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|aliasPartnDesc
operator|=
name|Utilities
operator|.
name|getPartitionDesc
argument_list|(
name|parts
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// The table does not have any partitions
if|if
condition|(
name|aliasPartnDesc
operator|==
literal|null
condition|)
block|{
name|aliasPartnDesc
operator|=
operator|new
name|PartitionDesc
argument_list|(
name|Utilities
operator|.
name|getTableDesc
argument_list|(
name|tsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableMetadata
argument_list|()
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
init|=
name|tsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getOpProps
argument_list|()
decl_stmt|;
if|if
condition|(
name|props
operator|!=
literal|null
condition|)
block|{
name|Properties
name|target
init|=
name|aliasPartnDesc
operator|.
name|getProperties
argument_list|()
decl_stmt|;
if|if
condition|(
name|target
operator|==
literal|null
condition|)
block|{
name|aliasPartnDesc
operator|.
name|setProperties
argument_list|(
name|target
operator|=
operator|new
name|Properties
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|target
operator|.
name|putAll
argument_list|(
name|props
argument_list|)
expr_stmt|;
block|}
name|plan
operator|.
name|getAliasToPartnInfo
argument_list|()
operator|.
name|put
argument_list|(
name|alias_id
argument_list|,
name|aliasPartnDesc
argument_list|)
expr_stmt|;
name|long
name|sizeNeeded
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
name|int
name|fileLimit
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|isEnable
argument_list|()
condition|)
block|{
if|if
condition|(
name|isAcidTable
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Skip Global Limit optimization for ACID table"
argument_list|)
expr_stmt|;
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|disableOpt
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|long
name|sizePerRow
init|=
name|HiveConf
operator|.
name|getLongVar
argument_list|(
name|parseCtx
operator|.
name|getConf
argument_list|()
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVELIMITMAXROWSIZE
argument_list|)
decl_stmt|;
name|sizeNeeded
operator|=
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|getGlobalLimit
argument_list|()
operator|*
name|sizePerRow
expr_stmt|;
comment|// for the optimization that reduce number of input file, we limit number
comment|// of files allowed. If more than specific number of files have to be
comment|// selected, we skip this optimization. Since having too many files as
comment|// inputs can cause unpredictable latency. It's not necessarily to be
comment|// cheaper.
name|fileLimit
operator|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|parseCtx
operator|.
name|getConf
argument_list|()
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVELIMITOPTLIMITFILE
argument_list|)
expr_stmt|;
if|if
condition|(
name|sizePerRow
operator|<=
literal|0
operator|||
name|fileLimit
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Skip optimization to reduce input size of 'limit'"
argument_list|)
expr_stmt|;
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|disableOpt
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|parts
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Empty input: skip limit optimiztion"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Try to reduce input size for 'limit' "
operator|+
literal|"sizeNeeded: "
operator|+
name|sizeNeeded
operator|+
literal|"  file limit : "
operator|+
name|fileLimit
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|boolean
name|isFirstPart
init|=
literal|true
decl_stmt|;
name|boolean
name|emptyInput
init|=
literal|true
decl_stmt|;
name|boolean
name|singlePartition
init|=
operator|(
name|parts
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|)
decl_stmt|;
comment|// Track the dependencies for the view. Consider a query like: select * from V;
comment|// where V is a view of the form: select * from T
comment|// The dependencies should include V at depth 0, and T at depth 1 (inferred).
name|Map
argument_list|<
name|String
argument_list|,
name|ReadEntity
argument_list|>
name|viewToInput
init|=
name|parseCtx
operator|.
name|getViewAliasToInput
argument_list|()
decl_stmt|;
name|ReadEntity
name|parentViewInfo
init|=
name|PlanUtils
operator|.
name|getParentViewInfo
argument_list|(
name|alias_id
argument_list|,
name|viewToInput
argument_list|)
decl_stmt|;
comment|// The table should also be considered a part of inputs, even if the table is a
comment|// partitioned table and whether any partition is selected or not
comment|//This read entity is a direct read entity and not an indirect read (that is when
comment|// this is being read because it is a dependency of a view).
name|boolean
name|isDirectRead
init|=
operator|(
name|parentViewInfo
operator|==
literal|null
operator|)
decl_stmt|;
name|TableDesc
name|tblDesc
init|=
literal|null
decl_stmt|;
name|boolean
name|initTableDesc
init|=
literal|false
decl_stmt|;
name|PlanUtils
operator|.
name|addPartitionInputs
argument_list|(
name|parts
argument_list|,
name|inputs
argument_list|,
name|parentViewInfo
argument_list|,
name|isDirectRead
argument_list|)
expr_stmt|;
for|for
control|(
name|Partition
name|part
range|:
name|parts
control|)
block|{
comment|// Later the properties have to come from the partition as opposed
comment|// to from the table in order to support versioning.
name|Path
index|[]
name|paths
init|=
literal|null
decl_stmt|;
name|SampleDesc
name|sampleDescr
init|=
name|parseCtx
operator|.
name|getOpToSamplePruner
argument_list|()
operator|.
name|get
argument_list|(
name|tsOp
argument_list|)
decl_stmt|;
comment|// Lookup list bucketing pruner
name|Map
argument_list|<
name|String
argument_list|,
name|ExprNodeDesc
argument_list|>
name|partToPruner
init|=
name|parseCtx
operator|.
name|getOpToPartToSkewedPruner
argument_list|()
operator|.
name|get
argument_list|(
name|tsOp
argument_list|)
decl_stmt|;
name|ExprNodeDesc
name|listBucketingPruner
init|=
operator|(
name|partToPruner
operator|!=
literal|null
operator|)
condition|?
name|partToPruner
operator|.
name|get
argument_list|(
name|part
operator|.
name|getName
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|sampleDescr
operator|!=
literal|null
condition|)
block|{
assert|assert
operator|(
name|listBucketingPruner
operator|==
literal|null
operator|)
operator|:
literal|"Sampling and list bucketing can't coexit."
assert|;
name|paths
operator|=
name|SamplePruner
operator|.
name|prune
argument_list|(
name|part
argument_list|,
name|sampleDescr
argument_list|)
expr_stmt|;
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|disableOpt
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|listBucketingPruner
operator|!=
literal|null
condition|)
block|{
assert|assert
operator|(
name|sampleDescr
operator|==
literal|null
operator|)
operator|:
literal|"Sampling and list bucketing can't coexist."
assert|;
comment|/* Use list bucketing prunner's path. */
name|paths
operator|=
name|ListBucketingPruner
operator|.
name|prune
argument_list|(
name|parseCtx
argument_list|,
name|part
argument_list|,
name|listBucketingPruner
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Now we only try the first partition, if the first partition doesn't
comment|// contain enough size, we change to normal mode.
if|if
condition|(
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|isEnable
argument_list|()
condition|)
block|{
if|if
condition|(
name|isFirstPart
condition|)
block|{
name|long
name|sizeLeft
init|=
name|sizeNeeded
decl_stmt|;
name|ArrayList
argument_list|<
name|Path
argument_list|>
name|retPathList
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
name|SamplePruner
operator|.
name|LimitPruneRetStatus
name|status
init|=
name|SamplePruner
operator|.
name|limitPrune
argument_list|(
name|part
argument_list|,
name|sizeLeft
argument_list|,
name|fileLimit
argument_list|,
name|retPathList
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|.
name|equals
argument_list|(
name|SamplePruner
operator|.
name|LimitPruneRetStatus
operator|.
name|NoFile
argument_list|)
condition|)
block|{
continue|continue;
block|}
elseif|else
if|if
condition|(
name|status
operator|.
name|equals
argument_list|(
name|SamplePruner
operator|.
name|LimitPruneRetStatus
operator|.
name|NotQualify
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Use full input -- first "
operator|+
name|fileLimit
operator|+
literal|" files are more than "
operator|+
name|sizeNeeded
operator|+
literal|" bytes"
argument_list|)
expr_stmt|;
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|disableOpt
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|emptyInput
operator|=
literal|false
expr_stmt|;
name|paths
operator|=
operator|new
name|Path
index|[
name|retPathList
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|int
name|index
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Path
name|path
range|:
name|retPathList
control|)
block|{
name|paths
index|[
name|index
operator|++
index|]
operator|=
name|path
expr_stmt|;
block|}
if|if
condition|(
name|status
operator|.
name|equals
argument_list|(
name|SamplePruner
operator|.
name|LimitPruneRetStatus
operator|.
name|NeedAllFiles
argument_list|)
operator|&&
name|singlePartition
condition|)
block|{
comment|// if all files are needed to meet the size limit, we disable
comment|// optimization. It usually happens for empty table/partition or
comment|// table/partition with only one file. By disabling this
comment|// optimization, we can avoid retrying the query if there is
comment|// not sufficient rows.
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|disableOpt
argument_list|()
expr_stmt|;
block|}
block|}
name|isFirstPart
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|paths
operator|=
operator|new
name|Path
index|[
literal|0
index|]
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|isEnable
argument_list|()
condition|)
block|{
name|paths
operator|=
name|part
operator|.
name|getPath
argument_list|()
expr_stmt|;
block|}
block|}
comment|// is it a partitioned table ?
if|if
condition|(
operator|!
name|part
operator|.
name|getTable
argument_list|()
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
assert|assert
operator|(
name|tblDir
operator|==
literal|null
operator|)
assert|;
name|tblDir
operator|=
name|paths
index|[
literal|0
index|]
expr_stmt|;
if|if
condition|(
operator|!
name|initTableDesc
condition|)
block|{
name|tblDesc
operator|=
name|Utilities
operator|.
name|getTableDesc
argument_list|(
name|part
operator|.
name|getTable
argument_list|()
argument_list|)
expr_stmt|;
name|initTableDesc
operator|=
literal|true
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|tblDesc
operator|==
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|initTableDesc
condition|)
block|{
name|tblDesc
operator|=
name|Utilities
operator|.
name|getTableDesc
argument_list|(
name|part
operator|.
name|getTable
argument_list|()
argument_list|)
expr_stmt|;
name|initTableDesc
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|props
operator|!=
literal|null
condition|)
block|{
name|Properties
name|target
init|=
name|tblDesc
operator|.
name|getProperties
argument_list|()
decl_stmt|;
if|if
condition|(
name|target
operator|==
literal|null
condition|)
block|{
name|tblDesc
operator|.
name|setProperties
argument_list|(
name|target
operator|=
operator|new
name|Properties
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|target
operator|.
name|putAll
argument_list|(
name|props
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Path
name|p
range|:
name|paths
control|)
block|{
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|String
name|path
init|=
name|p
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding "
operator|+
name|path
operator|+
literal|" of table"
operator|+
name|alias_id
argument_list|)
expr_stmt|;
block|}
name|partDir
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|part
operator|.
name|getTable
argument_list|()
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
name|partDesc
operator|.
name|add
argument_list|(
name|Utilities
operator|.
name|getPartitionDesc
argument_list|(
name|part
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partDesc
operator|.
name|add
argument_list|(
name|Utilities
operator|.
name|getPartitionDescFromTableDesc
argument_list|(
name|tblDesc
argument_list|,
name|part
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|emptyInput
condition|)
block|{
name|parseCtx
operator|.
name|getGlobalLimitCtx
argument_list|()
operator|.
name|disableOpt
argument_list|()
expr_stmt|;
block|}
name|Utilities
operator|.
name|addSchemaEvolutionToTableScanOperator
argument_list|(
name|partsList
operator|.
name|getSourceTable
argument_list|()
argument_list|,
name|tsOp
argument_list|)
expr_stmt|;
name|Iterator
argument_list|<
name|Path
argument_list|>
name|iterPath
init|=
name|partDir
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|PartitionDesc
argument_list|>
name|iterPartnDesc
init|=
name|partDesc
operator|.
name|iterator
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|local
condition|)
block|{
while|while
condition|(
name|iterPath
operator|.
name|hasNext
argument_list|()
condition|)
block|{
assert|assert
name|iterPartnDesc
operator|.
name|hasNext
argument_list|()
assert|;
name|String
name|path
init|=
name|iterPath
operator|.
name|next
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|PartitionDesc
name|prtDesc
init|=
name|iterPartnDesc
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// Add the path to alias mapping
if|if
condition|(
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
operator|==
literal|null
condition|)
block|{
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|put
argument_list|(
name|path
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
operator|.
name|add
argument_list|(
name|alias_id
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|prtDesc
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Information added for path "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
block|}
assert|assert
name|plan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|alias_id
argument_list|)
operator|==
literal|null
assert|;
name|plan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias_id
argument_list|,
name|tsOp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// populate local work if needed
name|MapredLocalWork
name|localPlan
init|=
name|plan
operator|.
name|getMapRedLocalWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|localPlan
operator|==
literal|null
condition|)
block|{
name|localPlan
operator|=
operator|new
name|MapredLocalWork
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
argument_list|()
argument_list|,
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|FetchWork
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
assert|assert
name|localPlan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|alias_id
argument_list|)
operator|==
literal|null
assert|;
assert|assert
name|localPlan
operator|.
name|getAliasToFetchWork
argument_list|()
operator|.
name|get
argument_list|(
name|alias_id
argument_list|)
operator|==
literal|null
assert|;
name|localPlan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias_id
argument_list|,
name|tsOp
argument_list|)
expr_stmt|;
if|if
condition|(
name|tblDir
operator|==
literal|null
condition|)
block|{
name|tblDesc
operator|=
name|Utilities
operator|.
name|getTableDesc
argument_list|(
name|partsList
operator|.
name|getSourceTable
argument_list|()
argument_list|)
expr_stmt|;
name|localPlan
operator|.
name|getAliasToFetchWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias_id
argument_list|,
operator|new
name|FetchWork
argument_list|(
name|partDir
argument_list|,
name|partDesc
argument_list|,
name|tblDesc
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|localPlan
operator|.
name|getAliasToFetchWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias_id
argument_list|,
operator|new
name|FetchWork
argument_list|(
name|tblDir
argument_list|,
name|tblDesc
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|plan
operator|.
name|setMapRedLocalWork
argument_list|(
name|localPlan
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * set the current task in the mapredWork.    *    * @param alias    *          current alias    * @param topOp    *          the top operator of the stack    * @param plan    *          current plan    * @param local    *          whether you need to add to map-reduce or local work    * @param tt_desc    *          table descriptor    * @throws SerDeException    */
specifier|public
specifier|static
name|void
name|setTaskPlan
parameter_list|(
name|String
name|path
parameter_list|,
name|String
name|alias
parameter_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|topOp
parameter_list|,
name|MapWork
name|plan
parameter_list|,
name|boolean
name|local
parameter_list|,
name|TableDesc
name|tt_desc
parameter_list|)
throws|throws
name|SemanticException
block|{
if|if
condition|(
name|path
operator|==
literal|null
operator|||
name|alias
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|topOp
operator|instanceof
name|TableScanOperator
condition|)
block|{
try|try
block|{
name|Utilities
operator|.
name|addSchemaEvolutionToTableScanOperator
argument_list|(
operator|(
name|StructObjectInspector
operator|)
name|tt_desc
operator|.
name|getDeserializer
argument_list|()
operator|.
name|getObjectInspector
argument_list|()
argument_list|,
operator|(
name|TableScanOperator
operator|)
name|topOp
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|local
condition|)
block|{
if|if
condition|(
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
operator|==
literal|null
condition|)
block|{
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|put
argument_list|(
name|path
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
operator|.
name|add
argument_list|(
name|alias
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|path
argument_list|,
operator|new
name|PartitionDesc
argument_list|(
name|tt_desc
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias
argument_list|,
name|topOp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// populate local work if needed
name|MapredLocalWork
name|localPlan
init|=
name|plan
operator|.
name|getMapRedLocalWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|localPlan
operator|==
literal|null
condition|)
block|{
name|localPlan
operator|=
operator|new
name|MapredLocalWork
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
argument_list|()
argument_list|,
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|FetchWork
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
assert|assert
name|localPlan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|alias
argument_list|)
operator|==
literal|null
assert|;
assert|assert
name|localPlan
operator|.
name|getAliasToFetchWork
argument_list|()
operator|.
name|get
argument_list|(
name|alias
argument_list|)
operator|==
literal|null
assert|;
name|localPlan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias
argument_list|,
name|topOp
argument_list|)
expr_stmt|;
name|localPlan
operator|.
name|getAliasToFetchWork
argument_list|()
operator|.
name|put
argument_list|(
name|alias
argument_list|,
operator|new
name|FetchWork
argument_list|(
operator|new
name|Path
argument_list|(
name|alias
argument_list|)
argument_list|,
name|tt_desc
argument_list|)
argument_list|)
expr_stmt|;
name|plan
operator|.
name|setMapRedLocalWork
argument_list|(
name|localPlan
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Set key and value descriptor    * @param work RedueWork    * @param rs ReduceSinkOperator    */
specifier|public
specifier|static
name|void
name|setKeyAndValueDesc
parameter_list|(
name|ReduceWork
name|work
parameter_list|,
name|ReduceSinkOperator
name|rs
parameter_list|)
block|{
name|work
operator|.
name|setKeyDesc
argument_list|(
name|rs
operator|.
name|getConf
argument_list|()
operator|.
name|getKeySerializeInfo
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|tag
init|=
name|Math
operator|.
name|max
argument_list|(
literal|0
argument_list|,
name|rs
operator|.
name|getConf
argument_list|()
operator|.
name|getTag
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|TableDesc
argument_list|>
name|tagToSchema
init|=
name|work
operator|.
name|getTagToValueDesc
argument_list|()
decl_stmt|;
while|while
condition|(
name|tag
operator|+
literal|1
operator|>
name|tagToSchema
operator|.
name|size
argument_list|()
condition|)
block|{
name|tagToSchema
operator|.
name|add
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|tagToSchema
operator|.
name|set
argument_list|(
name|tag
argument_list|,
name|rs
operator|.
name|getConf
argument_list|()
operator|.
name|getValueSerializeInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * set key and value descriptor.    *    * @param plan    *          current plan    * @param topOp    *          current top operator in the path    */
specifier|public
specifier|static
name|void
name|setKeyAndValueDesc
parameter_list|(
name|ReduceWork
name|plan
parameter_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|topOp
parameter_list|)
block|{
if|if
condition|(
name|topOp
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|topOp
operator|instanceof
name|ReduceSinkOperator
condition|)
block|{
name|ReduceSinkOperator
name|rs
init|=
operator|(
name|ReduceSinkOperator
operator|)
name|topOp
decl_stmt|;
name|setKeyAndValueDesc
argument_list|(
name|plan
argument_list|,
name|rs
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|children
init|=
name|topOp
operator|.
name|getChildOperators
argument_list|()
decl_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|op
range|:
name|children
control|)
block|{
name|setKeyAndValueDesc
argument_list|(
name|plan
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Set the key and value description for all the tasks rooted at the given    * task. Loops over all the tasks recursively.    *    * @param task    */
specifier|public
specifier|static
name|void
name|setKeyAndValueDescForTaskTree
parameter_list|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|task
parameter_list|)
block|{
if|if
condition|(
name|task
operator|instanceof
name|ConditionalTask
condition|)
block|{
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|listTasks
init|=
operator|(
operator|(
name|ConditionalTask
operator|)
name|task
operator|)
operator|.
name|getListTasks
argument_list|()
decl_stmt|;
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|tsk
range|:
name|listTasks
control|)
block|{
name|setKeyAndValueDescForTaskTree
argument_list|(
name|tsk
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|task
operator|instanceof
name|ExecDriver
condition|)
block|{
name|MapredWork
name|work
init|=
operator|(
name|MapredWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|work
operator|.
name|getMapWork
argument_list|()
operator|.
name|deriveExplainAttributes
argument_list|()
expr_stmt|;
name|HashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|opMap
init|=
name|work
operator|.
name|getMapWork
argument_list|()
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|opMap
operator|!=
literal|null
operator|&&
operator|!
name|opMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|op
range|:
name|opMap
operator|.
name|values
argument_list|()
control|)
block|{
name|setKeyAndValueDesc
argument_list|(
name|work
operator|.
name|getReduceWork
argument_list|()
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|task
operator|!=
literal|null
operator|&&
operator|(
name|task
operator|.
name|getWork
argument_list|()
operator|instanceof
name|TezWork
operator|)
condition|)
block|{
name|TezWork
name|work
init|=
operator|(
name|TezWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWorkUnsorted
argument_list|()
control|)
block|{
if|if
condition|(
name|w
operator|instanceof
name|MapWork
condition|)
block|{
operator|(
operator|(
name|MapWork
operator|)
name|w
operator|)
operator|.
name|deriveExplainAttributes
argument_list|()
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|task
operator|instanceof
name|SparkTask
condition|)
block|{
name|SparkWork
name|work
init|=
operator|(
name|SparkWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWorkUnsorted
argument_list|()
control|)
block|{
if|if
condition|(
name|w
operator|instanceof
name|MapWork
condition|)
block|{
operator|(
operator|(
name|MapWork
operator|)
name|w
operator|)
operator|.
name|deriveExplainAttributes
argument_list|()
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|task
operator|.
name|getChildTasks
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return;
block|}
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
range|:
name|task
operator|.
name|getChildTasks
argument_list|()
control|)
block|{
name|setKeyAndValueDescForTaskTree
argument_list|(
name|childTask
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Called at the end of TaskCompiler::compile to derive final    * explain attributes based on previous compilation.    */
specifier|public
specifier|static
name|void
name|deriveFinalExplainAttributes
parameter_list|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|task
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
comment|// TODO: deriveExplainAttributes should be called here, code is too fragile to move it around.
if|if
condition|(
name|task
operator|instanceof
name|ConditionalTask
condition|)
block|{
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|tsk
range|:
operator|(
operator|(
name|ConditionalTask
operator|)
name|task
operator|)
operator|.
name|getListTasks
argument_list|()
control|)
block|{
name|deriveFinalExplainAttributes
argument_list|(
name|tsk
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|task
operator|instanceof
name|ExecDriver
condition|)
block|{
name|MapredWork
name|work
init|=
operator|(
name|MapredWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|work
operator|.
name|getMapWork
argument_list|()
operator|.
name|deriveLlap
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|task
operator|!=
literal|null
operator|&&
operator|(
name|task
operator|.
name|getWork
argument_list|()
operator|instanceof
name|TezWork
operator|)
condition|)
block|{
name|TezWork
name|work
init|=
operator|(
name|TezWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWorkUnsorted
argument_list|()
control|)
block|{
if|if
condition|(
name|w
operator|instanceof
name|MapWork
condition|)
block|{
operator|(
operator|(
name|MapWork
operator|)
name|w
operator|)
operator|.
name|deriveLlap
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|task
operator|instanceof
name|SparkTask
condition|)
block|{
name|SparkWork
name|work
init|=
operator|(
name|SparkWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWorkUnsorted
argument_list|()
control|)
block|{
if|if
condition|(
name|w
operator|instanceof
name|MapWork
condition|)
block|{
operator|(
operator|(
name|MapWork
operator|)
name|w
operator|)
operator|.
name|deriveLlap
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|task
operator|.
name|getChildTasks
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return;
block|}
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
range|:
name|task
operator|.
name|getChildTasks
argument_list|()
control|)
block|{
name|deriveFinalExplainAttributes
argument_list|(
name|childTask
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|void
name|internTableDesc
parameter_list|(
name|Task
argument_list|<
name|?
argument_list|>
name|task
parameter_list|,
name|Interner
argument_list|<
name|TableDesc
argument_list|>
name|interner
parameter_list|)
block|{
if|if
condition|(
name|task
operator|instanceof
name|ConditionalTask
condition|)
block|{
for|for
control|(
name|Task
name|tsk
range|:
operator|(
operator|(
name|ConditionalTask
operator|)
name|task
operator|)
operator|.
name|getListTasks
argument_list|()
control|)
block|{
name|internTableDesc
argument_list|(
name|tsk
argument_list|,
name|interner
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|task
operator|instanceof
name|ExecDriver
condition|)
block|{
name|MapredWork
name|work
init|=
operator|(
name|MapredWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|work
operator|.
name|getMapWork
argument_list|()
operator|.
name|internTable
argument_list|(
name|interner
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|task
operator|!=
literal|null
operator|&&
operator|(
name|task
operator|.
name|getWork
argument_list|()
operator|instanceof
name|TezWork
operator|)
condition|)
block|{
name|TezWork
name|work
init|=
operator|(
name|TezWork
operator|)
name|task
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWorkUnsorted
argument_list|()
control|)
block|{
if|if
condition|(
name|w
operator|instanceof
name|MapWork
condition|)
block|{
operator|(
operator|(
name|MapWork
operator|)
name|w
operator|)
operator|.
name|internTable
argument_list|(
name|interner
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|task
operator|.
name|getNumChild
argument_list|()
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|Task
name|childTask
range|:
name|task
operator|.
name|getChildTasks
argument_list|()
control|)
block|{
name|internTableDesc
argument_list|(
name|childTask
argument_list|,
name|interner
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * create a new plan and return.    *    * @return the new plan    */
specifier|public
specifier|static
name|MapredWork
name|getMapRedWork
parameter_list|(
name|ParseContext
name|parseCtx
parameter_list|)
block|{
name|MapredWork
name|work
init|=
name|getMapRedWorkFromConf
argument_list|(
name|parseCtx
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|work
operator|.
name|getMapWork
argument_list|()
operator|.
name|setNameToSplitSample
argument_list|(
name|parseCtx
operator|.
name|getNameToSplitSample
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|work
return|;
block|}
comment|/**    * create a new plan and return. The pan won't contain the name to split    * sample information in parse context.    *    * @return the new plan    */
specifier|public
specifier|static
name|MapredWork
name|getMapRedWorkFromConf
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
name|MapredWork
name|mrWork
init|=
operator|new
name|MapredWork
argument_list|()
decl_stmt|;
name|MapWork
name|work
init|=
name|mrWork
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
name|boolean
name|mapperCannotSpanPartns
init|=
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_MAPPER_CANNOT_SPAN_MULTIPLE_PARTITIONS
argument_list|)
decl_stmt|;
name|work
operator|.
name|setMapperCannotSpanPartns
argument_list|(
name|mapperCannotSpanPartns
argument_list|)
expr_stmt|;
name|work
operator|.
name|setPathToAliases
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|work
operator|.
name|setPathToPartitionInfo
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|PartitionDesc
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|work
operator|.
name|setAliasToWork
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|mrWork
return|;
block|}
specifier|public
specifier|static
name|TableScanOperator
name|createTemporaryTableScanOperator
parameter_list|(
name|RowSchema
name|rowSchema
parameter_list|)
block|{
name|TableScanOperator
name|tableScanOp
init|=
operator|(
name|TableScanOperator
operator|)
name|OperatorFactory
operator|.
name|get
argument_list|(
operator|new
name|TableScanDesc
argument_list|(
literal|null
argument_list|)
argument_list|,
name|rowSchema
argument_list|)
decl_stmt|;
comment|// Set needed columns for this dummy TableScanOperator
name|List
argument_list|<
name|Integer
argument_list|>
name|neededColumnIds
init|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|neededColumnNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|ColumnInfo
argument_list|>
name|parentColumnInfos
init|=
name|rowSchema
operator|.
name|getSignature
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|parentColumnInfos
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|neededColumnIds
operator|.
name|add
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|neededColumnNames
operator|.
name|add
argument_list|(
name|parentColumnInfos
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getInternalName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|tableScanOp
operator|.
name|setNeededColumnIDs
argument_list|(
name|neededColumnIds
argument_list|)
expr_stmt|;
name|tableScanOp
operator|.
name|setNeededColumns
argument_list|(
name|neededColumnNames
argument_list|)
expr_stmt|;
name|tableScanOp
operator|.
name|setReferencedColumns
argument_list|(
name|neededColumnNames
argument_list|)
expr_stmt|;
return|return
name|tableScanOp
return|;
block|}
comment|/**    * Break the pipeline between parent and child, and then    * output data generated by parent to a temporary file stored in taskTmpDir.    * A FileSinkOperator is added after parent to output the data.    * Before child, we add a TableScanOperator to load data stored in the temporary    * file back.    * @param parent    * @param child    * @param taskTmpDir    * @param tt_desc    * @param parseCtx    * @return The TableScanOperator inserted before child.    */
specifier|public
specifier|static
name|TableScanOperator
name|createTemporaryFile
parameter_list|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parent
parameter_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|child
parameter_list|,
name|Path
name|taskTmpDir
parameter_list|,
name|TableDesc
name|tt_desc
parameter_list|,
name|ParseContext
name|parseCtx
parameter_list|)
block|{
comment|// Create a FileSinkOperator for the file name of taskTmpDir
name|boolean
name|compressIntermediate
init|=
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|COMPRESSINTERMEDIATE
argument_list|)
decl_stmt|;
name|FileSinkDesc
name|desc
init|=
operator|new
name|FileSinkDesc
argument_list|(
name|taskTmpDir
argument_list|,
name|tt_desc
argument_list|,
name|compressIntermediate
argument_list|)
decl_stmt|;
if|if
condition|(
name|compressIntermediate
condition|)
block|{
name|desc
operator|.
name|setCompressCodec
argument_list|(
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|COMPRESSINTERMEDIATECODEC
argument_list|)
argument_list|)
expr_stmt|;
name|desc
operator|.
name|setCompressType
argument_list|(
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|COMPRESSINTERMEDIATETYPE
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|fileSinkOp
init|=
name|OperatorFactory
operator|.
name|get
argument_list|(
name|desc
argument_list|,
name|parent
operator|.
name|getSchema
argument_list|()
argument_list|)
decl_stmt|;
comment|// Connect parent to fileSinkOp
name|parent
operator|.
name|replaceChild
argument_list|(
name|child
argument_list|,
name|fileSinkOp
argument_list|)
expr_stmt|;
name|fileSinkOp
operator|.
name|setParentOperators
argument_list|(
name|Utilities
operator|.
name|makeList
argument_list|(
name|parent
argument_list|)
argument_list|)
expr_stmt|;
comment|// Create a dummy TableScanOperator for the file generated through fileSinkOp
name|TableScanOperator
name|tableScanOp
init|=
name|createTemporaryTableScanOperator
argument_list|(
name|parent
operator|.
name|getSchema
argument_list|()
argument_list|)
decl_stmt|;
comment|// Connect this TableScanOperator to child.
name|tableScanOp
operator|.
name|setChildOperators
argument_list|(
name|Utilities
operator|.
name|makeList
argument_list|(
name|child
argument_list|)
argument_list|)
expr_stmt|;
name|child
operator|.
name|replaceParent
argument_list|(
name|parent
argument_list|,
name|tableScanOp
argument_list|)
expr_stmt|;
return|return
name|tableScanOp
return|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"nls"
argument_list|)
comment|/**    * Split two tasks by creating a temporary file between them.    *    * @param op reduce sink operator being processed    * @param parentTask the parent task    * @param childTask the child task    * @param opProcCtx context    **/
specifier|private
specifier|static
name|void
name|splitTasks
parameter_list|(
name|ReduceSinkOperator
name|op
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parentTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
parameter_list|,
name|GenMRProcContext
name|opProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
if|if
condition|(
name|op
operator|.
name|getNumParent
argument_list|()
operator|!=
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Expecting operator "
operator|+
name|op
operator|+
literal|" to have one parent. "
operator|+
literal|"But found multiple parents : "
operator|+
name|op
operator|.
name|getParentOperators
argument_list|()
argument_list|)
throw|;
block|}
name|ParseContext
name|parseCtx
init|=
name|opProcCtx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|childTask
argument_list|)
expr_stmt|;
comment|// Root Task cannot depend on any other task, therefore childTask cannot be
comment|// a root Task
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|rootTasks
init|=
name|opProcCtx
operator|.
name|getRootTasks
argument_list|()
decl_stmt|;
if|if
condition|(
name|rootTasks
operator|.
name|contains
argument_list|(
name|childTask
argument_list|)
condition|)
block|{
name|rootTasks
operator|.
name|remove
argument_list|(
name|childTask
argument_list|)
expr_stmt|;
block|}
comment|// Generate the temporary file name
name|Context
name|baseCtx
init|=
name|parseCtx
operator|.
name|getContext
argument_list|()
decl_stmt|;
name|Path
name|taskTmpDir
init|=
name|baseCtx
operator|.
name|getMRTmpPath
argument_list|()
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parent
init|=
name|op
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|TableDesc
name|tt_desc
init|=
name|PlanUtils
operator|.
name|getIntermediateFileTableDesc
argument_list|(
name|PlanUtils
operator|.
name|getFieldSchemasFromRowSchema
argument_list|(
name|parent
operator|.
name|getSchema
argument_list|()
argument_list|,
literal|"temporarycol"
argument_list|)
argument_list|)
decl_stmt|;
comment|// Create the temporary file, its corresponding FileSinkOperaotr, and
comment|// its corresponding TableScanOperator.
name|TableScanOperator
name|tableScanOp
init|=
name|createTemporaryFile
argument_list|(
name|parent
argument_list|,
name|op
argument_list|,
name|taskTmpDir
argument_list|,
name|tt_desc
argument_list|,
name|parseCtx
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|,
name|GenMapRedCtx
argument_list|>
name|mapCurrCtx
init|=
name|opProcCtx
operator|.
name|getMapCurrCtx
argument_list|()
decl_stmt|;
name|mapCurrCtx
operator|.
name|put
argument_list|(
name|tableScanOp
argument_list|,
operator|new
name|GenMapRedCtx
argument_list|(
name|childTask
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|streamDesc
init|=
name|taskTmpDir
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|MapredWork
name|cplan
init|=
operator|(
name|MapredWork
operator|)
name|childTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|needsTagging
argument_list|(
name|cplan
operator|.
name|getReduceWork
argument_list|()
argument_list|)
condition|)
block|{
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|reducerOp
init|=
name|cplan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|getReducer
argument_list|()
decl_stmt|;
name|String
name|id
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|reducerOp
operator|instanceof
name|JoinOperator
condition|)
block|{
if|if
condition|(
name|parseCtx
operator|.
name|getJoinOps
argument_list|()
operator|.
name|contains
argument_list|(
name|reducerOp
argument_list|)
condition|)
block|{
name|id
operator|=
operator|(
operator|(
name|JoinOperator
operator|)
name|reducerOp
operator|)
operator|.
name|getConf
argument_list|()
operator|.
name|getId
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|reducerOp
operator|instanceof
name|MapJoinOperator
condition|)
block|{
if|if
condition|(
name|parseCtx
operator|.
name|getMapJoinOps
argument_list|()
operator|.
name|contains
argument_list|(
name|reducerOp
argument_list|)
condition|)
block|{
name|id
operator|=
operator|(
operator|(
name|MapJoinOperator
operator|)
name|reducerOp
operator|)
operator|.
name|getConf
argument_list|()
operator|.
name|getId
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|reducerOp
operator|instanceof
name|SMBMapJoinOperator
condition|)
block|{
if|if
condition|(
name|parseCtx
operator|.
name|getSmbMapJoinOps
argument_list|()
operator|.
name|contains
argument_list|(
name|reducerOp
argument_list|)
condition|)
block|{
name|id
operator|=
operator|(
operator|(
name|SMBMapJoinOperator
operator|)
name|reducerOp
operator|)
operator|.
name|getConf
argument_list|()
operator|.
name|getId
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|id
operator|!=
literal|null
condition|)
block|{
name|streamDesc
operator|=
name|id
operator|+
literal|":$INTNAME"
expr_stmt|;
block|}
else|else
block|{
name|streamDesc
operator|=
literal|"$INTNAME"
expr_stmt|;
block|}
name|String
name|origStreamDesc
init|=
name|streamDesc
decl_stmt|;
name|int
name|pos
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|cplan
operator|.
name|getMapWork
argument_list|()
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|streamDesc
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|streamDesc
operator|=
name|origStreamDesc
operator|.
name|concat
argument_list|(
name|String
operator|.
name|valueOf
argument_list|(
operator|++
name|pos
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// TODO: Allocate work to remove the temporary files and make that
comment|// dependent on the redTask
name|cplan
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setNeedsTagging
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Add the path to alias mapping
name|setTaskPlan
argument_list|(
name|taskTmpDir
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|streamDesc
argument_list|,
name|tableScanOp
argument_list|,
name|cplan
operator|.
name|getMapWork
argument_list|()
argument_list|,
literal|false
argument_list|,
name|tt_desc
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrTopOp
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrAliasId
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|setCurrTask
argument_list|(
name|childTask
argument_list|)
expr_stmt|;
name|opProcCtx
operator|.
name|addRootIfPossible
argument_list|(
name|parentTask
argument_list|)
expr_stmt|;
block|}
specifier|static
name|boolean
name|hasBranchFinished
parameter_list|(
name|Object
modifier|...
name|children
parameter_list|)
block|{
for|for
control|(
name|Object
name|child
range|:
name|children
control|)
block|{
if|if
condition|(
name|child
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Replace the Map-side operator tree associated with targetAlias in    * target with the Map-side operator tree associated with sourceAlias in source.    * @param sourceAlias    * @param targetAlias    * @param source    * @param target    */
specifier|public
specifier|static
name|void
name|replaceMapWork
parameter_list|(
name|String
name|sourceAlias
parameter_list|,
name|String
name|targetAlias
parameter_list|,
name|MapWork
name|source
parameter_list|,
name|MapWork
name|target
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|sourcePathToAliases
init|=
name|source
operator|.
name|getPathToAliases
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|PartitionDesc
argument_list|>
name|sourcePathToPartitionInfo
init|=
name|source
operator|.
name|getPathToPartitionInfo
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|sourceAliasToWork
init|=
name|source
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|PartitionDesc
argument_list|>
name|sourceAliasToPartnInfo
init|=
name|source
operator|.
name|getAliasToPartnInfo
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|targetPathToAliases
init|=
name|target
operator|.
name|getPathToAliases
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|PartitionDesc
argument_list|>
name|targetPathToPartitionInfo
init|=
name|target
operator|.
name|getPathToPartitionInfo
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|targetAliasToWork
init|=
name|target
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|PartitionDesc
argument_list|>
name|targetAliasToPartnInfo
init|=
name|target
operator|.
name|getAliasToPartnInfo
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|sourceAliasToWork
operator|.
name|containsKey
argument_list|(
name|sourceAlias
argument_list|)
operator|||
operator|!
name|targetAliasToWork
operator|.
name|containsKey
argument_list|(
name|targetAlias
argument_list|)
condition|)
block|{
comment|// Nothing to do if there is no operator tree associated with
comment|// sourceAlias in source or there is not operator tree associated
comment|// with targetAlias in target.
return|return;
block|}
if|if
condition|(
name|sourceAliasToWork
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
comment|// If there are multiple aliases in source, we do not know
comment|// how to merge.
return|return;
block|}
comment|// Remove unnecessary information from target
name|targetAliasToWork
operator|.
name|remove
argument_list|(
name|targetAlias
argument_list|)
expr_stmt|;
name|targetAliasToPartnInfo
operator|.
name|remove
argument_list|(
name|targetAlias
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|pathsToRemove
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|entry
range|:
name|targetPathToAliases
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|ArrayList
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|aliases
operator|.
name|remove
argument_list|(
name|targetAlias
argument_list|)
expr_stmt|;
if|if
condition|(
name|aliases
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|pathsToRemove
operator|.
name|add
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|String
name|pathToRemove
range|:
name|pathsToRemove
control|)
block|{
name|targetPathToAliases
operator|.
name|remove
argument_list|(
name|pathToRemove
argument_list|)
expr_stmt|;
name|targetPathToPartitionInfo
operator|.
name|remove
argument_list|(
name|pathToRemove
argument_list|)
expr_stmt|;
block|}
comment|// Add new information from source to target
name|targetAliasToWork
operator|.
name|put
argument_list|(
name|sourceAlias
argument_list|,
name|sourceAliasToWork
operator|.
name|get
argument_list|(
name|sourceAlias
argument_list|)
argument_list|)
expr_stmt|;
name|targetAliasToPartnInfo
operator|.
name|putAll
argument_list|(
name|sourceAliasToPartnInfo
argument_list|)
expr_stmt|;
name|targetPathToPartitionInfo
operator|.
name|putAll
argument_list|(
name|sourcePathToPartitionInfo
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|pathsToAdd
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|entry
range|:
name|sourcePathToAliases
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|ArrayList
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|aliases
operator|.
name|contains
argument_list|(
name|sourceAlias
argument_list|)
condition|)
block|{
name|pathsToAdd
operator|.
name|add
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|String
name|pathToAdd
range|:
name|pathsToAdd
control|)
block|{
if|if
condition|(
operator|!
name|targetPathToAliases
operator|.
name|containsKey
argument_list|(
name|pathToAdd
argument_list|)
condition|)
block|{
name|targetPathToAliases
operator|.
name|put
argument_list|(
name|pathToAdd
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|targetPathToAliases
operator|.
name|get
argument_list|(
name|pathToAdd
argument_list|)
operator|.
name|add
argument_list|(
name|sourceAlias
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @param fsInput The FileSink operator.    * @param ctx The MR processing context.    * @param finalName the final destination path the merge job should output.    * @param dependencyTask    * @param mvTasks    * @param conf    * @param currTask    * @throws SemanticException     * create a Map-only merge job using CombineHiveInputFormat for all partitions with    * following operators:    *          MR job J0:    *          ...    *          |    *          v    *          FileSinkOperator_1 (fsInput)    *          |    *          v    *          Merge job J1:    *          |    *          v    *          TableScan (using CombineHiveInputFormat) (tsMerge)    *          |    *          v    *          FileSinkOperator (fsMerge)    *    *          Here the pathToPartitionInfo& pathToAlias will remain the same, which means the paths    *          do    *          not contain the dynamic partitions (their parent). So after the dynamic partitions are    *          created (after the first job finished before the moveTask or ConditionalTask start),    *          we need to change the pathToPartitionInfo& pathToAlias to include the dynamic    *          partition    *          directories.    *    */
specifier|public
specifier|static
name|void
name|createMRWorkForMergingFiles
parameter_list|(
name|FileSinkOperator
name|fsInput
parameter_list|,
name|Path
name|finalName
parameter_list|,
name|DependencyCollectionTask
name|dependencyTask
parameter_list|,
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|//
comment|// 1. create the operator tree
comment|//
name|FileSinkDesc
name|fsInputDesc
init|=
name|fsInput
operator|.
name|getConf
argument_list|()
decl_stmt|;
comment|// Create a TableScan operator
name|RowSchema
name|inputRS
init|=
name|fsInput
operator|.
name|getSchema
argument_list|()
decl_stmt|;
name|TableScanOperator
name|tsMerge
init|=
name|GenMapRedUtils
operator|.
name|createTemporaryTableScanOperator
argument_list|(
name|inputRS
argument_list|)
decl_stmt|;
comment|// Create a FileSink operator
name|TableDesc
name|ts
init|=
operator|(
name|TableDesc
operator|)
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|clone
argument_list|()
decl_stmt|;
name|FileSinkDesc
name|fsOutputDesc
init|=
operator|new
name|FileSinkDesc
argument_list|(
name|finalName
argument_list|,
name|ts
argument_list|,
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|COMPRESSRESULT
argument_list|)
argument_list|)
decl_stmt|;
name|FileSinkOperator
name|fsOutput
init|=
operator|(
name|FileSinkOperator
operator|)
name|OperatorFactory
operator|.
name|getAndMakeChild
argument_list|(
name|fsOutputDesc
argument_list|,
name|inputRS
argument_list|,
name|tsMerge
argument_list|)
decl_stmt|;
comment|// If the input FileSinkOperator is a dynamic partition enabled, the tsMerge input schema
comment|// needs to include the partition column, and the fsOutput should have
comment|// a DynamicPartitionCtx to indicate that it needs to dynamically partitioned.
name|DynamicPartitionCtx
name|dpCtx
init|=
name|fsInputDesc
operator|.
name|getDynPartCtx
argument_list|()
decl_stmt|;
if|if
condition|(
name|dpCtx
operator|!=
literal|null
operator|&&
name|dpCtx
operator|.
name|getNumDPCols
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// adding DP ColumnInfo to the RowSchema signature
name|ArrayList
argument_list|<
name|ColumnInfo
argument_list|>
name|signature
init|=
name|inputRS
operator|.
name|getSignature
argument_list|()
decl_stmt|;
name|String
name|tblAlias
init|=
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getTableName
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|dpCol
range|:
name|dpCtx
operator|.
name|getDPColNames
argument_list|()
control|)
block|{
name|ColumnInfo
name|colInfo
init|=
operator|new
name|ColumnInfo
argument_list|(
name|dpCol
argument_list|,
name|TypeInfoFactory
operator|.
name|stringTypeInfo
argument_list|,
comment|// all partition column type should be string
name|tblAlias
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// partition column is virtual column
name|signature
operator|.
name|add
argument_list|(
name|colInfo
argument_list|)
expr_stmt|;
block|}
name|inputRS
operator|.
name|setSignature
argument_list|(
name|signature
argument_list|)
expr_stmt|;
comment|// create another DynamicPartitionCtx, which has a different input-to-DP column mapping
name|DynamicPartitionCtx
name|dpCtx2
init|=
operator|new
name|DynamicPartitionCtx
argument_list|(
name|dpCtx
argument_list|)
decl_stmt|;
name|fsOutputDesc
operator|.
name|setDynPartCtx
argument_list|(
name|dpCtx2
argument_list|)
expr_stmt|;
comment|// update the FileSinkOperator to include partition columns
name|usePartitionColumns
argument_list|(
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getProperties
argument_list|()
argument_list|,
name|dpCtx
operator|.
name|getDPColNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// non-partitioned table
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|)
expr_stmt|;
block|}
comment|//
comment|// 2. Constructing a conditional task consisting of a move task and a map reduce task
comment|//
name|MoveWork
name|dummyMv
init|=
operator|new
name|MoveWork
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
operator|new
name|LoadFileDesc
argument_list|(
name|fsInputDesc
operator|.
name|getFinalDirName
argument_list|()
argument_list|,
name|finalName
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|MapWork
name|cplan
decl_stmt|;
name|Serializable
name|work
decl_stmt|;
if|if
condition|(
operator|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGERCFILEBLOCKLEVEL
argument_list|)
operator|&&
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|RCFileInputFormat
operator|.
name|class
argument_list|)
operator|)
operator|||
operator|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGEORCFILESTRIPELEVEL
argument_list|)
operator|&&
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|OrcInputFormat
operator|.
name|class
argument_list|)
operator|)
condition|)
block|{
name|cplan
operator|=
name|GenMapRedUtils
operator|.
name|createMergeTask
argument_list|(
name|fsInputDesc
argument_list|,
name|finalName
argument_list|,
name|dpCtx
operator|!=
literal|null
operator|&&
name|dpCtx
operator|.
name|getNumDPCols
argument_list|()
operator|>
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|)
operator|.
name|equals
argument_list|(
literal|"tez"
argument_list|)
condition|)
block|{
name|work
operator|=
operator|new
name|TezWork
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEQUERYID
argument_list|)
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setName
argument_list|(
literal|"File Merge"
argument_list|)
expr_stmt|;
operator|(
operator|(
name|TezWork
operator|)
name|work
operator|)
operator|.
name|add
argument_list|(
name|cplan
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|conf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|)
operator|.
name|equals
argument_list|(
literal|"spark"
argument_list|)
condition|)
block|{
name|work
operator|=
operator|new
name|SparkWork
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEQUERYID
argument_list|)
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setName
argument_list|(
literal|"Spark Merge File Work"
argument_list|)
expr_stmt|;
operator|(
operator|(
name|SparkWork
operator|)
name|work
operator|)
operator|.
name|add
argument_list|(
name|cplan
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|work
operator|=
name|cplan
expr_stmt|;
block|}
block|}
else|else
block|{
name|cplan
operator|=
name|createMRWorkForMergingFiles
argument_list|(
name|conf
argument_list|,
name|tsMerge
argument_list|,
name|fsInputDesc
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|)
operator|.
name|equals
argument_list|(
literal|"tez"
argument_list|)
condition|)
block|{
name|work
operator|=
operator|new
name|TezWork
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEQUERYID
argument_list|)
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setName
argument_list|(
literal|"File Merge"
argument_list|)
expr_stmt|;
operator|(
operator|(
name|TezWork
operator|)
name|work
operator|)
operator|.
name|add
argument_list|(
name|cplan
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|conf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|)
operator|.
name|equals
argument_list|(
literal|"spark"
argument_list|)
condition|)
block|{
name|work
operator|=
operator|new
name|SparkWork
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEQUERYID
argument_list|)
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setName
argument_list|(
literal|"Spark Merge File Work"
argument_list|)
expr_stmt|;
operator|(
operator|(
name|SparkWork
operator|)
name|work
operator|)
operator|.
name|add
argument_list|(
name|cplan
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|work
operator|=
operator|new
name|MapredWork
argument_list|()
expr_stmt|;
operator|(
operator|(
name|MapredWork
operator|)
name|work
operator|)
operator|.
name|setMapWork
argument_list|(
name|cplan
argument_list|)
expr_stmt|;
block|}
block|}
comment|// use CombineHiveInputFormat for map-only merging
name|cplan
operator|.
name|setInputformat
argument_list|(
literal|"org.apache.hadoop.hive.ql.io.CombineHiveInputFormat"
argument_list|)
expr_stmt|;
comment|// NOTE: we should gather stats in MR1 rather than MR2 at merge job since we don't
comment|// know if merge MR2 will be triggered at execution time
name|ConditionalTask
name|cndTsk
init|=
name|GenMapRedUtils
operator|.
name|createCondTask
argument_list|(
name|conf
argument_list|,
name|currTask
argument_list|,
name|dummyMv
argument_list|,
name|work
argument_list|,
name|fsInputDesc
operator|.
name|getFinalDirName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
comment|// keep the dynamic partition context in conditional task resolver context
name|ConditionalResolverMergeFilesCtx
name|mrCtx
init|=
operator|(
name|ConditionalResolverMergeFilesCtx
operator|)
name|cndTsk
operator|.
name|getResolverCtx
argument_list|()
decl_stmt|;
name|mrCtx
operator|.
name|setDPCtx
argument_list|(
name|fsInputDesc
operator|.
name|getDynPartCtx
argument_list|()
argument_list|)
expr_stmt|;
name|mrCtx
operator|.
name|setLbCtx
argument_list|(
name|fsInputDesc
operator|.
name|getLbCtx
argument_list|()
argument_list|)
expr_stmt|;
comment|//
comment|// 3. add the moveTask as the children of the conditional task
comment|//
name|linkMoveTask
argument_list|(
name|fsOutput
argument_list|,
name|cndTsk
argument_list|,
name|mvTasks
argument_list|,
name|conf
argument_list|,
name|dependencyTask
argument_list|)
expr_stmt|;
block|}
comment|/**    * Make the move task in the GenMRProcContext following the FileSinkOperator a dependent of all    * possible subtrees branching from the ConditionalTask.    *    * @param newOutput    * @param cndTsk    * @param mvTasks    * @param hconf    * @param dependencyTask    */
specifier|public
specifier|static
name|void
name|linkMoveTask
parameter_list|(
name|FileSinkOperator
name|newOutput
parameter_list|,
name|ConditionalTask
name|cndTsk
parameter_list|,
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
parameter_list|,
name|HiveConf
name|hconf
parameter_list|,
name|DependencyCollectionTask
name|dependencyTask
parameter_list|)
block|{
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
init|=
name|GenMapRedUtils
operator|.
name|findMoveTask
argument_list|(
name|mvTasks
argument_list|,
name|newOutput
argument_list|)
decl_stmt|;
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|tsk
range|:
name|cndTsk
operator|.
name|getListTasks
argument_list|()
control|)
block|{
name|linkMoveTask
argument_list|(
name|mvTask
argument_list|,
name|tsk
argument_list|,
name|hconf
argument_list|,
name|dependencyTask
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Follows the task tree down from task and makes all leaves parents of mvTask    *    * @param mvTask    * @param task    * @param hconf    * @param dependencyTask    */
specifier|public
specifier|static
name|void
name|linkMoveTask
parameter_list|(
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|task
parameter_list|,
name|HiveConf
name|hconf
parameter_list|,
name|DependencyCollectionTask
name|dependencyTask
parameter_list|)
block|{
if|if
condition|(
name|task
operator|.
name|getDependentTasks
argument_list|()
operator|==
literal|null
operator|||
name|task
operator|.
name|getDependentTasks
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// If it's a leaf, add the move task as a child
name|addDependentMoveTasks
argument_list|(
name|mvTask
argument_list|,
name|hconf
argument_list|,
name|task
argument_list|,
name|dependencyTask
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Otherwise, for each child run this method recursively
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
range|:
name|task
operator|.
name|getDependentTasks
argument_list|()
control|)
block|{
name|linkMoveTask
argument_list|(
name|mvTask
argument_list|,
name|childTask
argument_list|,
name|hconf
argument_list|,
name|dependencyTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Adds the dependencyTaskForMultiInsert in ctx as a dependent of parentTask. If mvTask is a    * load table, and HIVE_MULTI_INSERT_ATOMIC_OUTPUTS is set, adds mvTask as a dependent of    * dependencyTaskForMultiInsert in ctx, otherwise adds mvTask as a dependent of parentTask as    * well.    *    * @param mvTask    * @param hconf    * @param parentTask    * @param dependencyTask    */
specifier|public
specifier|static
name|void
name|addDependentMoveTasks
parameter_list|(
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
parameter_list|,
name|HiveConf
name|hconf
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parentTask
parameter_list|,
name|DependencyCollectionTask
name|dependencyTask
parameter_list|)
block|{
if|if
condition|(
name|mvTask
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|dependencyTask
operator|!=
literal|null
condition|)
block|{
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|dependencyTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|mvTask
operator|.
name|getWork
argument_list|()
operator|.
name|getLoadTableWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// Moving tables/partitions depend on the dependencyTask
name|dependencyTask
operator|.
name|addDependentTask
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Moving files depends on the parentTask (we still want the dependencyTask to depend
comment|// on the parentTask)
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Add the StatsTask as a dependent task of the MoveTask    * because StatsTask will change the Table/Partition metadata. For atomicity, we    * should not change it before the data is actually there done by MoveTask.    *    * @param nd    *          the FileSinkOperator whose results are taken care of by the MoveTask.    * @param mvTask    *          The MoveTask that moves the FileSinkOperator's results.    * @param currTask    *          The MapRedTask that the FileSinkOperator belongs to.    * @param hconf    *          HiveConf    */
specifier|public
specifier|static
name|void
name|addStatsTask
parameter_list|(
name|FileSinkOperator
name|nd
parameter_list|,
name|MoveTask
name|mvTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|HiveConf
name|hconf
parameter_list|)
block|{
name|MoveWork
name|mvWork
init|=
name|mvTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|StatsWork
name|statsWork
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|statsWork
operator|=
operator|new
name|StatsWork
argument_list|(
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|statsWork
operator|=
operator|new
name|StatsWork
argument_list|(
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
argument_list|)
expr_stmt|;
block|}
assert|assert
name|statsWork
operator|!=
literal|null
operator|:
literal|"Error when genereting StatsTask"
assert|;
name|statsWork
operator|.
name|setSourceTask
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
name|statsWork
operator|.
name|setStatsReliable
argument_list|(
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_STATS_RELIABLE
argument_list|)
argument_list|)
expr_stmt|;
name|statsWork
operator|.
name|setStatsTmpDir
argument_list|(
name|nd
operator|.
name|getConf
argument_list|()
operator|.
name|getStatsTmpDir
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|currTask
operator|.
name|getWork
argument_list|()
operator|instanceof
name|MapredWork
condition|)
block|{
name|MapredWork
name|mrWork
init|=
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|mrWork
operator|.
name|getMapWork
argument_list|()
operator|.
name|setGatheringStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|mrWork
operator|.
name|getReduceWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|mrWork
operator|.
name|getReduceWork
argument_list|()
operator|.
name|setGatheringStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|currTask
operator|.
name|getWork
argument_list|()
operator|instanceof
name|SparkWork
condition|)
block|{
name|SparkWork
name|work
init|=
operator|(
name|SparkWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWork
argument_list|()
control|)
block|{
name|w
operator|.
name|setGatheringStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// must be TezWork
name|TezWork
name|work
init|=
operator|(
name|TezWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
for|for
control|(
name|BaseWork
name|w
range|:
name|work
operator|.
name|getAllWork
argument_list|()
control|)
block|{
name|w
operator|.
name|setGatheringStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
comment|// AggKey in StatsWork is used for stats aggregation while StatsAggPrefix
comment|// in FileSinkDesc is used for stats publishing. They should be consistent.
name|statsWork
operator|.
name|setAggKey
argument_list|(
name|nd
operator|.
name|getConf
argument_list|()
operator|.
name|getStatsAggPrefix
argument_list|()
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|statsTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|statsWork
argument_list|,
name|hconf
argument_list|)
decl_stmt|;
comment|// mark the MapredWork and FileSinkOperator for gathering stats
name|nd
operator|.
name|getConf
argument_list|()
operator|.
name|setGatherStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|nd
operator|.
name|getConf
argument_list|()
operator|.
name|setStatsReliable
argument_list|(
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_STATS_RELIABLE
argument_list|)
argument_list|)
expr_stmt|;
comment|// mrWork.addDestinationTable(nd.getConf().getTableInfo().getTableName());
comment|// subscribe feeds from the MoveTask so that MoveTask can forward the list
comment|// of dynamic partition list to the StatsTask
name|mvTask
operator|.
name|addDependentTask
argument_list|(
name|statsTask
argument_list|)
expr_stmt|;
name|statsTask
operator|.
name|subscribeFeed
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
comment|/**    * Returns true iff current query is an insert into for the given file sink    *    * @param parseCtx    * @param fsOp    * @return    */
specifier|public
specifier|static
name|boolean
name|isInsertInto
parameter_list|(
name|ParseContext
name|parseCtx
parameter_list|,
name|FileSinkOperator
name|fsOp
parameter_list|)
block|{
return|return
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getTableName
argument_list|()
operator|!=
literal|null
return|;
block|}
comment|/**    * Create a MapredWork based on input path, the top operator and the input    * table descriptor.    *    * @param conf    * @param topOp    *          the table scan operator that is the root of the MapReduce task.    * @param fsDesc    *          the file sink descriptor that serves as the input to this merge task.    * @param parentMR    *          the parent MapReduce work    * @param parentFS    *          the last FileSinkOperator in the parent MapReduce work    * @return the MapredWork    */
specifier|private
specifier|static
name|MapWork
name|createMRWorkForMergingFiles
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|TableScanOperator
name|topOp
parameter_list|,
name|FileSinkDesc
name|fsDesc
parameter_list|)
block|{
name|ArrayList
argument_list|<
name|String
argument_list|>
name|aliases
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|inputDir
init|=
name|fsDesc
operator|.
name|getFinalDirName
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|TableDesc
name|tblDesc
init|=
name|fsDesc
operator|.
name|getTableInfo
argument_list|()
decl_stmt|;
name|aliases
operator|.
name|add
argument_list|(
name|inputDir
argument_list|)
expr_stmt|;
comment|// dummy alias: just use the input path
comment|// constructing the default MapredWork
name|MapredWork
name|cMrPlan
init|=
name|GenMapRedUtils
operator|.
name|getMapRedWorkFromConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|MapWork
name|cplan
init|=
name|cMrPlan
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
name|cplan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
name|aliases
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
operator|new
name|PartitionDesc
argument_list|(
name|tblDesc
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
name|topOp
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setMapperCannotSpanPartns
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|cplan
return|;
block|}
comment|/**    * Create a block level merge task for RCFiles or stripe level merge task for    * ORCFiles    *    * @param fsInputDesc    * @param finalName    * @param inputFormatClass    * @return MergeWork if table is stored as RCFile or ORCFile,    *         null otherwise    */
specifier|public
specifier|static
name|MapWork
name|createMergeTask
parameter_list|(
name|FileSinkDesc
name|fsInputDesc
parameter_list|,
name|Path
name|finalName
parameter_list|,
name|boolean
name|hasDynamicPartitions
parameter_list|)
throws|throws
name|SemanticException
block|{
name|Path
name|inputDir
init|=
name|fsInputDesc
operator|.
name|getFinalDirName
argument_list|()
decl_stmt|;
name|TableDesc
name|tblDesc
init|=
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|inputDirs
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|String
argument_list|>
name|inputDirstr
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|// this will be populated by MergeFileWork.resolveDynamicPartitionStoredAsSubDirsMerge
comment|// in case of dynamic partitioning and list bucketing
if|if
condition|(
operator|!
name|hasDynamicPartitions
operator|&&
operator|!
name|GenMapRedUtils
operator|.
name|isSkewedStoredAsDirs
argument_list|(
name|fsInputDesc
argument_list|)
condition|)
block|{
name|inputDirs
operator|.
name|add
argument_list|(
name|inputDir
argument_list|)
expr_stmt|;
block|}
name|inputDirstr
operator|.
name|add
argument_list|(
name|inputDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// internal input format class for CombineHiveInputFormat
specifier|final
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|internalIFClass
decl_stmt|;
if|if
condition|(
name|tblDesc
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|RCFileInputFormat
operator|.
name|class
argument_list|)
condition|)
block|{
name|internalIFClass
operator|=
name|RCFileBlockMergeInputFormat
operator|.
name|class
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|tblDesc
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|OrcInputFormat
operator|.
name|class
argument_list|)
condition|)
block|{
name|internalIFClass
operator|=
name|OrcFileStripeMergeInputFormat
operator|.
name|class
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"createMergeTask called on a table with file"
operator|+
literal|" format other than RCFile or ORCFile"
argument_list|)
throw|;
block|}
comment|// create the merge file work
name|MergeFileWork
name|work
init|=
operator|new
name|MergeFileWork
argument_list|(
name|inputDirs
argument_list|,
name|finalName
argument_list|,
name|hasDynamicPartitions
argument_list|,
name|tblDesc
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|pathToAliases
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|pathToAliases
operator|.
name|put
argument_list|(
name|inputDir
operator|.
name|toString
argument_list|()
argument_list|,
name|inputDirstr
argument_list|)
expr_stmt|;
name|work
operator|.
name|setMapperCannotSpanPartns
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|work
operator|.
name|setPathToAliases
argument_list|(
name|pathToAliases
argument_list|)
expr_stmt|;
name|PartitionDesc
name|pDesc
init|=
operator|new
name|PartitionDesc
argument_list|(
name|tblDesc
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|pDesc
operator|.
name|setInputFileFormatClass
argument_list|(
name|internalIFClass
argument_list|)
expr_stmt|;
name|work
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
operator|.
name|toString
argument_list|()
argument_list|,
name|pDesc
argument_list|)
expr_stmt|;
name|work
operator|.
name|setListBucketingCtx
argument_list|(
name|fsInputDesc
operator|.
name|getLbCtx
argument_list|()
argument_list|)
expr_stmt|;
comment|// create alias to work which contains the merge operator
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|aliasToWork
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|mergeOp
init|=
literal|null
decl_stmt|;
specifier|final
name|FileMergeDesc
name|fmd
decl_stmt|;
if|if
condition|(
name|tblDesc
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|RCFileInputFormat
operator|.
name|class
argument_list|)
condition|)
block|{
name|fmd
operator|=
operator|new
name|RCFileMergeDesc
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|fmd
operator|=
operator|new
name|OrcFileMergeDesc
argument_list|()
expr_stmt|;
block|}
name|fmd
operator|.
name|setDpCtx
argument_list|(
name|fsInputDesc
operator|.
name|getDynPartCtx
argument_list|()
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setOutputPath
argument_list|(
name|finalName
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setHasDynamicPartitions
argument_list|(
name|work
operator|.
name|hasDynamicPartitions
argument_list|()
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setListBucketingAlterTableConcatenate
argument_list|(
name|work
operator|.
name|isListBucketingAlterTableConcatenate
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|lbLevel
init|=
name|work
operator|.
name|getListBucketingCtx
argument_list|()
operator|==
literal|null
condition|?
literal|0
else|:
name|work
operator|.
name|getListBucketingCtx
argument_list|()
operator|.
name|calculateListBucketingLevel
argument_list|()
decl_stmt|;
name|fmd
operator|.
name|setListBucketingDepth
argument_list|(
name|lbLevel
argument_list|)
expr_stmt|;
name|mergeOp
operator|=
name|OperatorFactory
operator|.
name|get
argument_list|(
name|fmd
argument_list|)
expr_stmt|;
name|aliasToWork
operator|.
name|put
argument_list|(
name|inputDir
operator|.
name|toString
argument_list|()
argument_list|,
name|mergeOp
argument_list|)
expr_stmt|;
name|work
operator|.
name|setAliasToWork
argument_list|(
name|aliasToWork
argument_list|)
expr_stmt|;
return|return
name|work
return|;
block|}
comment|/**    * Construct a conditional task given the current leaf task, the MoveWork and the MapredWork.    *    * @param conf    *          HiveConf    * @param currTask    *          current leaf task    * @param mvWork    *          MoveWork for the move task    * @param mergeWork    *          MapredWork for the merge task.    * @param inputPath    *          the input directory of the merge/move task    * @return The conditional task    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|public
specifier|static
name|ConditionalTask
name|createCondTask
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|MoveWork
name|mvWork
parameter_list|,
name|Serializable
name|mergeWork
parameter_list|,
name|String
name|inputPath
parameter_list|)
block|{
comment|// There are 3 options for this ConditionalTask:
comment|// 1) Merge the partitions
comment|// 2) Move the partitions (i.e. don't merge the partitions)
comment|// 3) Merge some partitions and move other partitions (i.e. merge some partitions and don't
comment|// merge others) in this case the merge is done first followed by the move to prevent
comment|// conflicts.
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mergeOnlyMergeTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mergeWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|moveOnlyMoveTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mvWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mergeAndMoveMergeTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mergeWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mergeAndMoveMoveTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mvWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
comment|// NOTE! It is necessary merge task is the parent of the move task, and not
comment|// the other way around, for the proper execution of the execute method of
comment|// ConditionalTask
name|mergeAndMoveMergeTask
operator|.
name|addDependentTask
argument_list|(
name|mergeAndMoveMoveTask
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Serializable
argument_list|>
name|listWorks
init|=
operator|new
name|ArrayList
argument_list|<
name|Serializable
argument_list|>
argument_list|()
decl_stmt|;
name|listWorks
operator|.
name|add
argument_list|(
name|mvWork
argument_list|)
expr_stmt|;
name|listWorks
operator|.
name|add
argument_list|(
name|mergeWork
argument_list|)
expr_stmt|;
name|ConditionalWork
name|cndWork
init|=
operator|new
name|ConditionalWork
argument_list|(
name|listWorks
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|listTasks
init|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|moveOnlyMoveTask
argument_list|)
expr_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|mergeOnlyMergeTask
argument_list|)
expr_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|mergeAndMoveMergeTask
argument_list|)
expr_stmt|;
name|ConditionalTask
name|cndTsk
init|=
operator|(
name|ConditionalTask
operator|)
name|TaskFactory
operator|.
name|get
argument_list|(
name|cndWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|cndTsk
operator|.
name|setListTasks
argument_list|(
name|listTasks
argument_list|)
expr_stmt|;
comment|// create resolver
name|cndTsk
operator|.
name|setResolver
argument_list|(
operator|new
name|ConditionalResolverMergeFiles
argument_list|()
argument_list|)
expr_stmt|;
name|ConditionalResolverMergeFilesCtx
name|mrCtx
init|=
operator|new
name|ConditionalResolverMergeFilesCtx
argument_list|(
name|listTasks
argument_list|,
name|inputPath
argument_list|)
decl_stmt|;
name|cndTsk
operator|.
name|setResolverCtx
argument_list|(
name|mrCtx
argument_list|)
expr_stmt|;
comment|// make the conditional task as the child of the current leaf task
name|currTask
operator|.
name|addDependentTask
argument_list|(
name|cndTsk
argument_list|)
expr_stmt|;
return|return
name|cndTsk
return|;
block|}
comment|/**    * check if it is skewed table and stored as dirs.    *    * @param fsInputDesc    * @return    */
specifier|public
specifier|static
name|boolean
name|isSkewedStoredAsDirs
parameter_list|(
name|FileSinkDesc
name|fsInputDesc
parameter_list|)
block|{
return|return
operator|(
name|fsInputDesc
operator|.
name|getLbCtx
argument_list|()
operator|==
literal|null
operator|)
condition|?
literal|false
else|:
name|fsInputDesc
operator|.
name|getLbCtx
argument_list|()
operator|.
name|isSkewedStoredAsDir
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|findMoveTask
parameter_list|(
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
parameter_list|,
name|FileSinkOperator
name|fsOp
parameter_list|)
block|{
comment|// find the move task
for|for
control|(
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTsk
range|:
name|mvTasks
control|)
block|{
name|MoveWork
name|mvWork
init|=
name|mvTsk
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|Path
name|srcDir
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|srcDir
operator|=
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
operator|.
name|getSourcePath
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|srcDir
operator|=
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
operator|.
name|getSourcePath
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|srcDir
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|srcDir
operator|.
name|equals
argument_list|(
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getFinalDirName
argument_list|()
argument_list|)
operator|)
condition|)
block|{
return|return
name|mvTsk
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Returns true iff the fsOp requires a merge    * @param mvTasks    * @param hconf    * @param fsOp    * @param currTask    * @param isInsertTable    * @return    */
specifier|public
specifier|static
name|boolean
name|isMergeRequired
parameter_list|(
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
parameter_list|,
name|HiveConf
name|hconf
parameter_list|,
name|FileSinkOperator
name|fsOp
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|boolean
name|isInsertTable
parameter_list|)
block|{
comment|// Has the user enabled merging of files for map-only jobs or for all jobs
if|if
condition|(
operator|(
name|mvTasks
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|mvTasks
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
comment|// no need of merging if the move is to a local file system
name|MoveTask
name|mvTask
init|=
operator|(
name|MoveTask
operator|)
name|GenMapRedUtils
operator|.
name|findMoveTask
argument_list|(
name|mvTasks
argument_list|,
name|fsOp
argument_list|)
decl_stmt|;
if|if
condition|(
name|mvTask
operator|!=
literal|null
operator|&&
name|isInsertTable
operator|&&
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVESTATSAUTOGATHER
argument_list|)
condition|)
block|{
name|GenMapRedUtils
operator|.
name|addStatsTask
argument_list|(
name|fsOp
argument_list|,
name|mvTask
argument_list|,
name|currTask
argument_list|,
name|hconf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|mvTask
operator|!=
literal|null
operator|)
operator|&&
operator|!
name|mvTask
operator|.
name|isLocal
argument_list|()
operator|&&
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|canBeMerged
argument_list|()
condition|)
block|{
if|if
condition|(
name|currTask
operator|.
name|getWork
argument_list|()
operator|instanceof
name|TezWork
condition|)
block|{
comment|// tez blurs the boundary between map and reduce, thus it has it's own
comment|// config
return|return
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGETEZFILES
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|currTask
operator|.
name|getWork
argument_list|()
operator|instanceof
name|SparkWork
condition|)
block|{
comment|// spark has its own config for merging
return|return
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGESPARKFILES
argument_list|)
return|;
block|}
if|if
condition|(
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|isLinkedFileSink
argument_list|()
condition|)
block|{
comment|// If the user has HIVEMERGEMAPREDFILES set to false, the idea was the
comment|// number of reducers are few, so the number of files anyway are small.
comment|// However, with this optimization, we are increasing the number of files
comment|// possibly by a big margin. So, merge aggresively.
if|if
condition|(
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGEMAPFILES
argument_list|)
operator|||
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGEMAPREDFILES
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
else|else
block|{
comment|// There are separate configuration parameters to control whether to
comment|// merge for a map-only job
comment|// or for a map-reduce job
if|if
condition|(
name|currTask
operator|.
name|getWork
argument_list|()
operator|instanceof
name|MapredWork
condition|)
block|{
name|ReduceWork
name|reduceWork
init|=
operator|(
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
operator|)
operator|.
name|getReduceWork
argument_list|()
decl_stmt|;
name|boolean
name|mergeMapOnly
init|=
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGEMAPFILES
argument_list|)
operator|&&
name|reduceWork
operator|==
literal|null
decl_stmt|;
name|boolean
name|mergeMapRed
init|=
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVEMERGEMAPREDFILES
argument_list|)
operator|&&
name|reduceWork
operator|!=
literal|null
decl_stmt|;
if|if
condition|(
name|mergeMapOnly
operator|||
name|mergeMapRed
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Create and add any dependent move tasks    *    * @param currTask    * @param chDir    * @param fsOp    * @param parseCtx    * @param mvTasks    * @param hconf    * @param dependencyTask    * @return    */
specifier|public
specifier|static
name|Path
name|createMoveTask
parameter_list|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|boolean
name|chDir
parameter_list|,
name|FileSinkOperator
name|fsOp
parameter_list|,
name|ParseContext
name|parseCtx
parameter_list|,
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
parameter_list|,
name|HiveConf
name|hconf
parameter_list|,
name|DependencyCollectionTask
name|dependencyTask
parameter_list|)
block|{
name|Path
name|dest
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|chDir
condition|)
block|{
name|dest
operator|=
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getFinalDirName
argument_list|()
expr_stmt|;
comment|// generate the temporary file
comment|// it must be on the same file system as the current destination
name|Context
name|baseCtx
init|=
name|parseCtx
operator|.
name|getContext
argument_list|()
decl_stmt|;
name|Path
name|tmpDir
init|=
name|baseCtx
operator|.
name|getExternalTmpPath
argument_list|(
name|dest
argument_list|)
decl_stmt|;
name|FileSinkDesc
name|fileSinkDesc
init|=
name|fsOp
operator|.
name|getConf
argument_list|()
decl_stmt|;
comment|// Change all the linked file sink descriptors
if|if
condition|(
name|fileSinkDesc
operator|.
name|isLinkedFileSink
argument_list|()
condition|)
block|{
for|for
control|(
name|FileSinkDesc
name|fsConf
range|:
name|fileSinkDesc
operator|.
name|getLinkedFileSinkDesc
argument_list|()
control|)
block|{
name|fsConf
operator|.
name|setParentDir
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
name|fsConf
operator|.
name|setDirName
argument_list|(
operator|new
name|Path
argument_list|(
name|tmpDir
argument_list|,
name|fsConf
operator|.
name|getDirName
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|fileSinkDesc
operator|.
name|setDirName
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
block|}
block|}
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|chDir
condition|)
block|{
name|mvTask
operator|=
name|GenMapRedUtils
operator|.
name|findMoveTask
argument_list|(
name|mvTasks
argument_list|,
name|fsOp
argument_list|)
expr_stmt|;
block|}
comment|// Set the move task to be dependent on the current task
if|if
condition|(
name|mvTask
operator|!=
literal|null
condition|)
block|{
name|GenMapRedUtils
operator|.
name|addDependentMoveTasks
argument_list|(
name|mvTask
argument_list|,
name|hconf
argument_list|,
name|currTask
argument_list|,
name|dependencyTask
argument_list|)
expr_stmt|;
block|}
return|return
name|dest
return|;
block|}
specifier|public
specifier|static
name|Set
argument_list|<
name|Partition
argument_list|>
name|getConfirmedPartitionsForScan
parameter_list|(
name|TableScanOperator
name|tableScanOp
parameter_list|)
block|{
name|Set
argument_list|<
name|Partition
argument_list|>
name|confirmedPartns
init|=
operator|new
name|HashSet
argument_list|<
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
name|TableSpec
name|tblSpec
init|=
name|tableScanOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableMetadata
argument_list|()
operator|.
name|getTableSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|tblSpec
operator|.
name|specType
operator|==
name|TableSpec
operator|.
name|SpecType
operator|.
name|STATIC_PARTITION
condition|)
block|{
comment|// static partition
if|if
condition|(
name|tblSpec
operator|.
name|partHandle
operator|!=
literal|null
condition|)
block|{
name|confirmedPartns
operator|.
name|add
argument_list|(
name|tblSpec
operator|.
name|partHandle
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// partial partition spec has null partHandle
name|confirmedPartns
operator|.
name|addAll
argument_list|(
name|tblSpec
operator|.
name|partitions
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|tblSpec
operator|.
name|specType
operator|==
name|TableSpec
operator|.
name|SpecType
operator|.
name|DYNAMIC_PARTITION
condition|)
block|{
comment|// dynamic partition
name|confirmedPartns
operator|.
name|addAll
argument_list|(
name|tblSpec
operator|.
name|partitions
argument_list|)
expr_stmt|;
block|}
return|return
name|confirmedPartns
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionColumns
parameter_list|(
name|TableScanOperator
name|tableScanOp
parameter_list|)
block|{
name|TableSpec
name|tblSpec
init|=
name|tableScanOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableMetadata
argument_list|()
operator|.
name|getTableSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|tblSpec
operator|.
name|tableHandle
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
return|return
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|tblSpec
operator|.
name|getPartSpec
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
return|;
block|}
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|Path
argument_list|>
name|getInputPathsForPartialScan
parameter_list|(
name|TableScanOperator
name|tableScanOp
parameter_list|,
name|Appendable
name|aggregationKey
parameter_list|)
throws|throws
name|SemanticException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|inputPaths
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|tableScanOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableMetadata
argument_list|()
operator|.
name|getTableSpec
argument_list|()
operator|.
name|specType
condition|)
block|{
case|case
name|TABLE_ONLY
case|:
name|inputPaths
operator|.
name|add
argument_list|(
name|tableScanOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableMetadata
argument_list|()
operator|.
name|getTableSpec
argument_list|()
operator|.
name|tableHandle
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|STATIC_PARTITION
case|:
name|Partition
name|part
init|=
name|tableScanOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableMetadata
argument_list|()
operator|.
name|getTableSpec
argument_list|()
operator|.
name|partHandle
decl_stmt|;
try|try
block|{
name|aggregationKey
operator|.
name|append
argument_list|(
name|Warehouse
operator|.
name|makePartPath
argument_list|(
name|part
operator|.
name|getSpec
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|ANALYZE_TABLE_PARTIALSCAN_AGGKEY
operator|.
name|getMsg
argument_list|(
name|part
operator|.
name|getDataLocation
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|inputPaths
operator|.
name|add
argument_list|(
name|part
operator|.
name|getDataLocation
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
assert|assert
literal|false
assert|;
block|}
return|return
name|inputPaths
return|;
block|}
specifier|public
specifier|static
name|Set
argument_list|<
name|String
argument_list|>
name|findAliases
parameter_list|(
specifier|final
name|MapWork
name|work
parameter_list|,
name|Operator
argument_list|<
name|?
argument_list|>
name|startOp
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|aliases
init|=
operator|new
name|LinkedHashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
argument_list|>
name|topOp
range|:
name|findTopOps
argument_list|(
name|startOp
argument_list|,
literal|null
argument_list|)
control|)
block|{
name|String
name|alias
init|=
name|findAlias
argument_list|(
name|work
argument_list|,
name|topOp
argument_list|)
decl_stmt|;
if|if
condition|(
name|alias
operator|!=
literal|null
condition|)
block|{
name|aliases
operator|.
name|add
argument_list|(
name|alias
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|aliases
return|;
block|}
specifier|public
specifier|static
name|Set
argument_list|<
name|Operator
argument_list|<
name|?
argument_list|>
argument_list|>
name|findTopOps
parameter_list|(
name|Operator
argument_list|<
name|?
argument_list|>
name|startOp
parameter_list|,
specifier|final
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
parameter_list|)
block|{
specifier|final
name|Set
argument_list|<
name|Operator
argument_list|<
name|?
argument_list|>
argument_list|>
name|operators
init|=
operator|new
name|LinkedHashSet
argument_list|<
name|Operator
argument_list|<
name|?
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|OperatorUtils
operator|.
name|iterateParents
argument_list|(
name|startOp
argument_list|,
operator|new
name|NodeUtils
operator|.
name|Function
argument_list|<
name|Operator
argument_list|<
name|?
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|apply
parameter_list|(
name|Operator
argument_list|<
name|?
argument_list|>
name|argument
parameter_list|)
block|{
if|if
condition|(
name|argument
operator|.
name|getNumParent
argument_list|()
operator|==
literal|0
operator|&&
operator|(
name|clazz
operator|==
literal|null
operator|||
name|clazz
operator|.
name|isInstance
argument_list|(
name|argument
argument_list|)
operator|)
condition|)
block|{
name|operators
operator|.
name|add
argument_list|(
name|argument
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|)
function|;
return|return
name|operators
return|;
block|}
end_class

begin_function
specifier|public
specifier|static
name|String
name|findAlias
parameter_list|(
name|MapWork
name|work
parameter_list|,
name|Operator
argument_list|<
name|?
argument_list|>
name|operator
parameter_list|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
argument_list|>
argument_list|>
name|entry
range|:
name|work
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|entry
operator|.
name|getValue
argument_list|()
operator|==
name|operator
condition|)
block|{
return|return
name|entry
operator|.
name|getKey
argument_list|()
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
end_function

begin_comment
comment|/**    * Uses only specified partition columns.    * Provided properties should be pre-populated with partition column names and types.    * This function retains only information related to the columns from the list.    * @param properties properties to update    * @param partColNames list of columns to use    */
end_comment

begin_function
specifier|static
name|void
name|usePartitionColumns
parameter_list|(
name|Properties
name|properties
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partColNames
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|partColNames
operator|.
name|isEmpty
argument_list|()
argument_list|,
literal|"No partition columns provided to use"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|partColNames
argument_list|)
operator|.
name|size
argument_list|()
operator|==
name|partColNames
operator|.
name|size
argument_list|()
argument_list|,
literal|"Partition columns should be unique: "
operator|+
name|partColNames
argument_list|)
expr_stmt|;
name|String
index|[]
name|partNames
init|=
name|properties
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|)
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|String
index|[]
name|partTypes
init|=
name|properties
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMN_TYPES
argument_list|)
operator|.
name|split
argument_list|(
literal|":"
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|partNames
operator|.
name|length
operator|==
name|partTypes
operator|.
name|length
argument_list|,
literal|"Partition Names, "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|partNames
argument_list|)
operator|+
literal|" don't match partition Types, "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|partTypes
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|typeMap
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partNames
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|previousValue
init|=
name|typeMap
operator|.
name|put
argument_list|(
name|partNames
index|[
name|i
index|]
argument_list|,
name|partTypes
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|previousValue
operator|==
literal|null
argument_list|,
literal|"Partition columns configuration is inconsistent. "
operator|+
literal|"There are duplicates in partition column names: "
operator|+
name|partNames
argument_list|)
expr_stmt|;
block|}
name|StringBuilder
name|partNamesBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|partTypesBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|partName
range|:
name|partColNames
control|)
block|{
name|partNamesBuf
operator|.
name|append
argument_list|(
name|partName
argument_list|)
operator|.
name|append
argument_list|(
literal|'/'
argument_list|)
expr_stmt|;
name|String
name|partType
init|=
name|typeMap
operator|.
name|get
argument_list|(
name|partName
argument_list|)
decl_stmt|;
if|if
condition|(
name|partType
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Type information for partition column "
operator|+
name|partName
operator|+
literal|" is missing."
argument_list|)
throw|;
block|}
name|partTypesBuf
operator|.
name|append
argument_list|(
name|partType
argument_list|)
operator|.
name|append
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
block|}
name|partNamesBuf
operator|.
name|setLength
argument_list|(
name|partNamesBuf
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
name|partTypesBuf
operator|.
name|setLength
argument_list|(
name|partTypesBuf
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
name|properties
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|,
name|partNamesBuf
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|properties
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMN_TYPES
argument_list|,
name|partTypesBuf
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
end_function

begin_constructor
specifier|private
name|GenMapRedUtils
parameter_list|()
block|{
comment|// prevent instantiation
block|}
end_constructor

unit|}
end_unit

