begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|events
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Collections2
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|RawStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ReplChangeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NotificationEvent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WriteEventInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|messaging
operator|.
name|CommitTxnMessage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
operator|.
name|util
operator|.
name|ReplUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|EximUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|DumpType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|DumpMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStreamWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_class
class|class
name|CommitTxnHandler
extends|extends
name|AbstractEventHandler
argument_list|<
name|CommitTxnMessage
argument_list|>
block|{
name|CommitTxnHandler
parameter_list|(
name|NotificationEvent
name|event
parameter_list|)
block|{
name|super
argument_list|(
name|event
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
name|CommitTxnMessage
name|eventMessage
parameter_list|(
name|String
name|stringRepresentation
parameter_list|)
block|{
return|return
name|deserializer
operator|.
name|getCommitTxnMessage
argument_list|(
name|stringRepresentation
argument_list|)
return|;
block|}
specifier|private
name|BufferedWriter
name|writer
parameter_list|(
name|Context
name|withinContext
parameter_list|,
name|Path
name|dataPath
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|filesPath
init|=
operator|new
name|Path
argument_list|(
name|dataPath
argument_list|,
name|EximUtil
operator|.
name|FILES_NAME
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|dataPath
operator|.
name|getFileSystem
argument_list|(
name|withinContext
operator|.
name|hiveConf
argument_list|)
decl_stmt|;
return|return
operator|new
name|BufferedWriter
argument_list|(
operator|new
name|OutputStreamWriter
argument_list|(
name|fs
operator|.
name|create
argument_list|(
name|filesPath
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|void
name|writeDumpFiles
parameter_list|(
name|Context
name|withinContext
parameter_list|,
name|Iterable
argument_list|<
name|String
argument_list|>
name|files
parameter_list|,
name|Path
name|dataPath
parameter_list|)
throws|throws
name|IOException
block|{
comment|// encoded filename/checksum of files, write into _files
try|try
init|(
name|BufferedWriter
name|fileListWriter
init|=
name|writer
argument_list|(
name|withinContext
argument_list|,
name|dataPath
argument_list|)
init|)
block|{
for|for
control|(
name|String
name|file
range|:
name|files
control|)
block|{
name|fileListWriter
operator|.
name|write
argument_list|(
name|file
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|createDumpFile
parameter_list|(
name|Context
name|withinContext
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
name|qlMdTable
parameter_list|,
name|List
argument_list|<
name|Partition
argument_list|>
name|qlPtns
parameter_list|,
name|List
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|fileListArray
parameter_list|)
throws|throws
name|IOException
throws|,
name|SemanticException
block|{
if|if
condition|(
name|fileListArray
operator|==
literal|null
operator|||
name|fileListArray
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|Path
name|metaDataPath
init|=
operator|new
name|Path
argument_list|(
name|withinContext
operator|.
name|eventRoot
argument_list|,
name|EximUtil
operator|.
name|METADATA_NAME
argument_list|)
decl_stmt|;
comment|// In case of ACID operations, same directory may have many other sub directory for different write id stmt id
comment|// combination. So we can not set isreplace to true.
name|withinContext
operator|.
name|replicationSpec
operator|.
name|setIsReplace
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|EximUtil
operator|.
name|createExportDump
argument_list|(
name|metaDataPath
operator|.
name|getFileSystem
argument_list|(
name|withinContext
operator|.
name|hiveConf
argument_list|)
argument_list|,
name|metaDataPath
argument_list|,
name|qlMdTable
argument_list|,
name|qlPtns
argument_list|,
name|withinContext
operator|.
name|replicationSpec
argument_list|,
name|withinContext
operator|.
name|hiveConf
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
literal|null
operator|==
name|qlPtns
operator|)
operator|||
name|qlPtns
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Path
name|dataPath
init|=
operator|new
name|Path
argument_list|(
name|withinContext
operator|.
name|eventRoot
argument_list|,
name|EximUtil
operator|.
name|DATA_PATH_NAME
argument_list|)
decl_stmt|;
name|writeDumpFiles
argument_list|(
name|withinContext
argument_list|,
name|fileListArray
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|,
name|dataPath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|qlPtns
operator|.
name|size
argument_list|()
condition|;
name|idx
operator|++
control|)
block|{
name|Path
name|dataPath
init|=
operator|new
name|Path
argument_list|(
name|withinContext
operator|.
name|eventRoot
argument_list|,
name|qlPtns
operator|.
name|get
argument_list|(
name|idx
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|writeDumpFiles
argument_list|(
name|withinContext
argument_list|,
name|fileListArray
operator|.
name|get
argument_list|(
name|idx
argument_list|)
argument_list|,
name|dataPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|createDumpFileForTable
parameter_list|(
name|Context
name|withinContext
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
name|qlMdTable
parameter_list|,
name|List
argument_list|<
name|Partition
argument_list|>
name|qlPtns
parameter_list|,
name|List
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|fileListArray
parameter_list|)
throws|throws
name|IOException
throws|,
name|SemanticException
block|{
name|Path
name|newPath
init|=
name|HiveUtils
operator|.
name|getDumpPath
argument_list|(
name|withinContext
operator|.
name|eventRoot
argument_list|,
name|qlMdTable
operator|.
name|getDbName
argument_list|()
argument_list|,
name|qlMdTable
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|Context
name|context
init|=
operator|new
name|Context
argument_list|(
name|withinContext
argument_list|)
decl_stmt|;
name|context
operator|.
name|setEventRoot
argument_list|(
name|newPath
argument_list|)
expr_stmt|;
name|createDumpFile
argument_list|(
name|context
argument_list|,
name|qlMdTable
argument_list|,
name|qlPtns
argument_list|,
name|fileListArray
argument_list|)
expr_stmt|;
block|}
specifier|private
name|List
argument_list|<
name|WriteEventInfo
argument_list|>
name|getAllWriteEventInfo
parameter_list|(
name|Context
name|withinContext
parameter_list|)
throws|throws
name|Exception
block|{
name|String
name|contextDbName
init|=
name|StringUtils
operator|.
name|normalizeIdentifier
argument_list|(
name|withinContext
operator|.
name|replScope
operator|.
name|getDbName
argument_list|()
argument_list|)
decl_stmt|;
name|RawStore
name|rawStore
init|=
name|HiveMetaStore
operator|.
name|HMSHandler
operator|.
name|getMSForConf
argument_list|(
name|withinContext
operator|.
name|hiveConf
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|WriteEventInfo
argument_list|>
name|writeEventInfoList
init|=
name|rawStore
operator|.
name|getAllWriteEventInfo
argument_list|(
name|eventMessage
operator|.
name|getTxnId
argument_list|()
argument_list|,
name|contextDbName
argument_list|,
literal|null
argument_list|)
decl_stmt|;
return|return
operator|(
operator|(
name|writeEventInfoList
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|Collections2
operator|.
name|filter
argument_list|(
name|writeEventInfoList
argument_list|,
name|writeEventInfo
lambda|->
block|{
assert|assert
operator|(
name|writeEventInfo
operator|!=
literal|null
operator|)
assert|;
comment|// If replication policy is replaced with new included/excluded tables list, then events
comment|// corresponding to tables which are included in both old and new policies should be dumped.
comment|// If table is included in new policy but not in old policy, then it should be skipped.
comment|// Those tables would be bootstrapped along with the current incremental
comment|// replication dump. If the table is in the list of tables to be bootstrapped, then
comment|// it should be skipped.
return|return
operator|(
name|ReplUtils
operator|.
name|tableIncludedInReplScope
argument_list|(
name|withinContext
operator|.
name|replScope
argument_list|,
name|writeEventInfo
operator|.
name|getTable
argument_list|()
argument_list|)
operator|&&
name|ReplUtils
operator|.
name|tableIncludedInReplScope
argument_list|(
name|withinContext
operator|.
name|oldReplScope
argument_list|,
name|writeEventInfo
operator|.
name|getTable
argument_list|()
argument_list|)
operator|&&
operator|!
name|withinContext
operator|.
name|getTablesForBootstrap
argument_list|()
operator|.
name|contains
argument_list|(
name|writeEventInfo
operator|.
name|getTable
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
operator|)
return|;
block|}
argument_list|)
argument_list|)
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handle
parameter_list|(
name|Context
name|withinContext
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
operator|!
name|ReplUtils
operator|.
name|includeAcidTableInDump
argument_list|(
name|withinContext
operator|.
name|hiveConf
argument_list|)
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Processing#{} COMMIT_TXN message : {}"
argument_list|,
name|fromEventId
argument_list|()
argument_list|,
name|eventMessageAsJSON
argument_list|)
expr_stmt|;
name|String
name|payload
init|=
name|eventMessageAsJSON
decl_stmt|;
if|if
condition|(
operator|!
name|withinContext
operator|.
name|hiveConf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_DUMP_METADATA_ONLY
argument_list|)
condition|)
block|{
name|boolean
name|replicatingAcidEvents
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|withinContext
operator|.
name|hiveConf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_BOOTSTRAP_ACID_TABLES
argument_list|)
condition|)
block|{
comment|// We do not dump ACID table related events when taking a bootstrap dump of ACID tables as
comment|// part of an incremental dump. So we shouldn't be dumping any changes to ACID table as
comment|// part of the commit. At the same time we need to dump the commit transaction event so
comment|// that replication can end a transaction opened when replaying open transaction event.
name|LOG
operator|.
name|debug
argument_list|(
literal|"writeEventsInfoList will be removed from commit message because we are "
operator|+
literal|"bootstrapping acid tables."
argument_list|)
expr_stmt|;
name|replicatingAcidEvents
operator|=
literal|false
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|ReplUtils
operator|.
name|includeAcidTableInDump
argument_list|(
name|withinContext
operator|.
name|hiveConf
argument_list|)
condition|)
block|{
comment|// Similar to the above condition, only for testing purposes, if the config doesn't allow
comment|// ACID tables to be replicated, we don't dump any changes to the ACID tables as part of
comment|// commit.
name|LOG
operator|.
name|debug
argument_list|(
literal|"writeEventsInfoList will be removed from commit message because we are "
operator|+
literal|"not dumping acid tables."
argument_list|)
expr_stmt|;
name|replicatingAcidEvents
operator|=
literal|false
expr_stmt|;
block|}
name|List
argument_list|<
name|WriteEventInfo
argument_list|>
name|writeEventInfoList
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|replicatingAcidEvents
condition|)
block|{
name|writeEventInfoList
operator|=
name|getAllWriteEventInfo
argument_list|(
name|withinContext
argument_list|)
expr_stmt|;
block|}
name|int
name|numEntry
init|=
operator|(
name|writeEventInfoList
operator|!=
literal|null
condition|?
name|writeEventInfoList
operator|.
name|size
argument_list|()
else|:
literal|0
operator|)
decl_stmt|;
if|if
condition|(
name|numEntry
operator|!=
literal|0
condition|)
block|{
name|eventMessage
operator|.
name|addWriteEventInfo
argument_list|(
name|writeEventInfoList
argument_list|)
expr_stmt|;
name|payload
operator|=
name|jsonMessageEncoder
operator|.
name|getSerializer
argument_list|()
operator|.
name|serialize
argument_list|(
name|eventMessage
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"payload for commit txn event : "
operator|+
name|eventMessageAsJSON
argument_list|)
expr_stmt|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
name|qlMdTablePrev
init|=
literal|null
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
name|qlMdTable
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|qlPtns
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|filesTobeAdded
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// The below loop creates dump directory for each table. It reads through the list of write notification events,
comment|// groups the entries per table and creates the lists of files to be replicated. The event directory in the dump
comment|// path will have subdirectory for each table. This folder will have metadata for the table and the list of files
comment|// to be replicated. The entries are added in the table with txn id, db name,table name, partition name
comment|// combination as primary key, so the entries with same table will come together. Only basic table metadata is
comment|// used during import, so we need not dump the latest table metadata.
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|numEntry
condition|;
name|idx
operator|++
control|)
block|{
name|qlMdTable
operator|=
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
argument_list|(
name|eventMessage
operator|.
name|getTableObj
argument_list|(
name|idx
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|qlMdTablePrev
operator|==
literal|null
condition|)
block|{
name|qlMdTablePrev
operator|=
name|qlMdTable
expr_stmt|;
block|}
comment|// one dump directory per table
if|if
condition|(
operator|!
name|qlMdTablePrev
operator|.
name|getCompleteName
argument_list|()
operator|.
name|equals
argument_list|(
name|qlMdTable
operator|.
name|getCompleteName
argument_list|()
argument_list|)
condition|)
block|{
name|createDumpFileForTable
argument_list|(
name|withinContext
argument_list|,
name|qlMdTablePrev
argument_list|,
name|qlPtns
argument_list|,
name|filesTobeAdded
argument_list|)
expr_stmt|;
name|qlPtns
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|filesTobeAdded
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|qlMdTablePrev
operator|=
name|qlMdTable
expr_stmt|;
block|}
if|if
condition|(
name|qlMdTable
operator|.
name|isPartitioned
argument_list|()
operator|&&
operator|(
literal|null
operator|!=
name|eventMessage
operator|.
name|getPartitionObj
argument_list|(
name|idx
argument_list|)
operator|)
condition|)
block|{
name|qlPtns
operator|.
name|add
argument_list|(
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Partition
argument_list|(
name|qlMdTable
argument_list|,
name|eventMessage
operator|.
name|getPartitionObj
argument_list|(
name|idx
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|filesTobeAdded
operator|.
name|add
argument_list|(
name|Lists
operator|.
name|newArrayList
argument_list|(
name|ReplChangeManager
operator|.
name|getListFromSeparatedString
argument_list|(
name|eventMessage
operator|.
name|getFiles
argument_list|(
name|idx
argument_list|)
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//Dump last table in the list
if|if
condition|(
name|qlMdTablePrev
operator|!=
literal|null
condition|)
block|{
name|createDumpFileForTable
argument_list|(
name|withinContext
argument_list|,
name|qlMdTablePrev
argument_list|,
name|qlPtns
argument_list|,
name|filesTobeAdded
argument_list|)
expr_stmt|;
block|}
block|}
name|DumpMetaData
name|dmd
init|=
name|withinContext
operator|.
name|createDmd
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|dmd
operator|.
name|setPayload
argument_list|(
name|payload
argument_list|)
expr_stmt|;
name|dmd
operator|.
name|write
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|DumpType
name|dumpType
parameter_list|()
block|{
return|return
name|DumpType
operator|.
name|EVENT_COMMIT_TXN
return|;
block|}
block|}
end_class

end_unit

