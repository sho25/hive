begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableScanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|api
operator|.
name|OperatorType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|stats
operator|.
name|StatsPublisher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|stats
operator|.
name|StatsSetupConst
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
operator|.
name|ObjectInspectorCopyOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructField
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_comment
comment|/**  * Table Scan Operator If the data is coming from the map-reduce framework, just  * forward it. This will be needed as part of local work when data is not being  * read as part of map-reduce framework  **/
end_comment

begin_class
specifier|public
class|class
name|TableScanOperator
extends|extends
name|Operator
argument_list|<
name|TableScanDesc
argument_list|>
implements|implements
name|Serializable
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|protected
specifier|transient
name|JobConf
name|jc
decl_stmt|;
specifier|private
specifier|transient
name|Configuration
name|hconf
decl_stmt|;
specifier|private
specifier|transient
name|Stat
name|stat
decl_stmt|;
specifier|private
specifier|transient
name|String
name|partitionSpecs
decl_stmt|;
comment|/**    * Other than gathering statistics for the ANALYZE command, the table scan operator    * does not do anything special other than just forwarding the row. Since the table    * data is always read as part of the map-reduce framework by the mapper. But, this    * assumption is not true, i.e table data is not only read by the mapper, this    * operator will be enhanced to read the table.    **/
annotation|@
name|Override
specifier|public
name|void
name|processOp
parameter_list|(
name|Object
name|row
parameter_list|,
name|int
name|tag
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|conf
operator|!=
literal|null
operator|&&
name|conf
operator|.
name|isGatherStats
argument_list|()
condition|)
block|{
name|gatherStats
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
name|forward
argument_list|(
name|row
argument_list|,
name|inputObjInspectors
index|[
name|tag
index|]
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|gatherStats
parameter_list|(
name|Object
name|row
parameter_list|)
block|{
if|if
condition|(
name|stat
operator|==
literal|null
condition|)
block|{
comment|// first row/call
name|stat
operator|=
operator|new
name|Stat
argument_list|()
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|==
literal|null
operator|||
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|partitionSpecs
operator|=
literal|""
expr_stmt|;
block|}
else|else
block|{
comment|// Figure out the partition spec from the input.
comment|// This is only done once for the first row (when stat == null)
comment|// since all rows in the same mapper should be from the same partition.
name|List
argument_list|<
name|Object
argument_list|>
name|writable
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|values
decl_stmt|;
name|int
name|dpStartCol
decl_stmt|;
comment|// the first position of partition column
assert|assert
name|inputObjInspectors
index|[
literal|0
index|]
operator|.
name|getCategory
argument_list|()
operator|==
name|ObjectInspector
operator|.
name|Category
operator|.
name|STRUCT
operator|:
literal|"input object inspector is not struct"
assert|;
name|writable
operator|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|values
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|dpStartCol
operator|=
literal|0
expr_stmt|;
name|StructObjectInspector
name|soi
init|=
operator|(
name|StructObjectInspector
operator|)
name|inputObjInspectors
index|[
literal|0
index|]
decl_stmt|;
for|for
control|(
name|StructField
name|sf
range|:
name|soi
operator|.
name|getAllStructFieldRefs
argument_list|()
control|)
block|{
name|String
name|fn
init|=
name|sf
operator|.
name|getFieldName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|.
name|contains
argument_list|(
name|fn
argument_list|)
condition|)
block|{
name|dpStartCol
operator|++
expr_stmt|;
block|}
else|else
block|{
break|break;
block|}
block|}
name|ObjectInspectorUtils
operator|.
name|partialCopyToStandardObject
argument_list|(
name|writable
argument_list|,
name|row
argument_list|,
name|dpStartCol
argument_list|,
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
operator|(
name|StructObjectInspector
operator|)
name|inputObjInspectors
index|[
literal|0
index|]
argument_list|,
name|ObjectInspectorCopyOption
operator|.
name|WRITABLE
argument_list|)
expr_stmt|;
for|for
control|(
name|Object
name|o
range|:
name|writable
control|)
block|{
assert|assert
operator|(
name|o
operator|!=
literal|null
operator|&&
name|o
operator|.
name|toString
argument_list|()
operator|.
name|length
argument_list|()
operator|>
literal|0
operator|)
assert|;
name|values
operator|.
name|add
argument_list|(
name|o
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|partitionSpecs
operator|=
name|FileUtils
operator|.
name|makePartName
argument_list|(
name|conf
operator|.
name|getPartColumns
argument_list|()
argument_list|,
name|values
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Stats Gathering found a new partition spec = "
operator|+
name|partitionSpecs
argument_list|)
expr_stmt|;
block|}
block|}
name|stat
operator|.
name|increaseNumRows
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|initializeOp
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|HiveException
block|{
name|initializeChildren
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|conf
operator|.
name|isGatherStats
argument_list|()
condition|)
block|{
return|return;
block|}
name|this
operator|.
name|hconf
operator|=
name|hconf
expr_stmt|;
if|if
condition|(
name|hconf
operator|instanceof
name|JobConf
condition|)
block|{
name|jc
operator|=
operator|(
name|JobConf
operator|)
name|hconf
expr_stmt|;
block|}
else|else
block|{
comment|// test code path
name|jc
operator|=
operator|new
name|JobConf
argument_list|(
name|hconf
argument_list|,
name|ExecDriver
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
name|stat
operator|=
literal|null
expr_stmt|;
name|partitionSpecs
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|==
literal|null
operator|||
name|conf
operator|.
name|getPartColumns
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// NON PARTITIONED table
return|return;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeOp
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|conf
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|conf
operator|.
name|isGatherStats
argument_list|()
operator|&&
name|stat
operator|!=
literal|null
condition|)
block|{
name|publishStats
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * The operator name for this operator type. This is used to construct the    * rule for an operator    *    * @return the operator name    **/
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
operator|new
name|String
argument_list|(
literal|"TS"
argument_list|)
return|;
block|}
comment|// this 'neededColumnIDs' field is included in this operator class instead of
comment|// its desc class.The reason is that 1)tableScanDesc can not be instantiated,
comment|// and 2) it will fail some join and union queries if this is added forcibly
comment|// into tableScanDesc
name|java
operator|.
name|util
operator|.
name|ArrayList
argument_list|<
name|Integer
argument_list|>
name|neededColumnIDs
decl_stmt|;
specifier|public
name|void
name|setNeededColumnIDs
parameter_list|(
name|java
operator|.
name|util
operator|.
name|ArrayList
argument_list|<
name|Integer
argument_list|>
name|orign_columns
parameter_list|)
block|{
name|neededColumnIDs
operator|=
name|orign_columns
expr_stmt|;
block|}
specifier|public
name|java
operator|.
name|util
operator|.
name|ArrayList
argument_list|<
name|Integer
argument_list|>
name|getNeededColumnIDs
parameter_list|()
block|{
return|return
name|neededColumnIDs
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getType
parameter_list|()
block|{
return|return
name|OperatorType
operator|.
name|TABLESCAN
return|;
block|}
specifier|private
name|void
name|publishStats
parameter_list|()
block|{
comment|// Initializing a stats publisher
name|StatsPublisher
name|statsPublisher
init|=
name|Utilities
operator|.
name|getStatsPublisher
argument_list|(
name|jc
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|statsPublisher
operator|.
name|connect
argument_list|(
name|jc
argument_list|)
condition|)
block|{
comment|// just return, stats gathering should not block the main query.
name|LOG
operator|.
name|info
argument_list|(
literal|"StatsPublishing error: cannot connect to database."
argument_list|)
expr_stmt|;
return|return;
block|}
name|String
name|key
decl_stmt|;
name|String
name|taskID
init|=
name|Utilities
operator|.
name|getTaskIdFromFilename
argument_list|(
name|Utilities
operator|.
name|getTaskId
argument_list|(
name|hconf
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|partitionSpecs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// In case of a non-partitioned table, the key for temp storage is just
comment|// "tableName + taskID"
name|key
operator|=
name|conf
operator|.
name|getStatsAggPrefix
argument_list|()
operator|+
name|taskID
expr_stmt|;
block|}
else|else
block|{
comment|// In case of a partition, the key for temp storage is
comment|// "tableName + partitionSpecs + taskID"
name|key
operator|=
name|conf
operator|.
name|getStatsAggPrefix
argument_list|()
operator|+
name|partitionSpecs
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|taskID
expr_stmt|;
block|}
name|statsPublisher
operator|.
name|publishStat
argument_list|(
name|key
argument_list|,
name|StatsSetupConst
operator|.
name|ROW_COUNT
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|stat
operator|.
name|getNumRows
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|statsPublisher
operator|.
name|closeConnection
argument_list|()
expr_stmt|;
block|}
block|}
end_class

end_unit

