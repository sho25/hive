begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed under the Apache License, Version 2.0 (the "License");  * you may not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  * http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|parquet
operator|.
name|serde
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|AbstractSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|io
operator|.
name|ParquetHiveRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
operator|.
name|Category
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|StructTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|ArrayWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|parquet
operator|.
name|hadoop
operator|.
name|ParquetOutputFormat
import|;
end_import

begin_import
import|import
name|parquet
operator|.
name|hadoop
operator|.
name|ParquetWriter
import|;
end_import

begin_comment
comment|/**  *  * A ParquetHiveSerDe for Hive (with the deprecated package mapred)  *  */
end_comment

begin_class
annotation|@
name|SerDeSpec
argument_list|(
name|schemaProps
operator|=
block|{
name|serdeConstants
operator|.
name|LIST_COLUMNS
block|,
name|serdeConstants
operator|.
name|LIST_COLUMN_TYPES
block|,
name|ParquetOutputFormat
operator|.
name|COMPRESSION
block|}
argument_list|)
specifier|public
class|class
name|ParquetHiveSerDe
extends|extends
name|AbstractSerDe
block|{
specifier|public
specifier|static
specifier|final
name|Text
name|MAP_KEY
init|=
operator|new
name|Text
argument_list|(
literal|"key"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Text
name|MAP_VALUE
init|=
operator|new
name|Text
argument_list|(
literal|"value"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Text
name|MAP
init|=
operator|new
name|Text
argument_list|(
literal|"map"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Text
name|ARRAY
init|=
operator|new
name|Text
argument_list|(
literal|"bag"
argument_list|)
decl_stmt|;
comment|// default compression type for parquet output format
specifier|private
specifier|static
specifier|final
name|String
name|DEFAULTCOMPRESSION
init|=
name|ParquetWriter
operator|.
name|DEFAULT_COMPRESSION_CODEC_NAME
operator|.
name|name
argument_list|()
decl_stmt|;
comment|// Map precision to the number bytes needed for binary conversion.
specifier|public
specifier|static
specifier|final
name|int
name|PRECISION_TO_BYTE_COUNT
index|[]
init|=
operator|new
name|int
index|[
literal|38
index|]
decl_stmt|;
static|static
block|{
for|for
control|(
name|int
name|prec
init|=
literal|1
init|;
name|prec
operator|<=
literal|38
condition|;
name|prec
operator|++
control|)
block|{
comment|// Estimated number of bytes needed.
name|PRECISION_TO_BYTE_COUNT
index|[
name|prec
operator|-
literal|1
index|]
operator|=
operator|(
name|int
operator|)
name|Math
operator|.
name|ceil
argument_list|(
operator|(
name|Math
operator|.
name|log
argument_list|(
name|Math
operator|.
name|pow
argument_list|(
literal|10
argument_list|,
name|prec
argument_list|)
operator|-
literal|1
argument_list|)
operator|/
name|Math
operator|.
name|log
argument_list|(
literal|2
argument_list|)
operator|+
literal|1
operator|)
operator|/
literal|8
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|SerDeStats
name|stats
decl_stmt|;
specifier|private
name|ObjectInspector
name|objInspector
decl_stmt|;
specifier|private
enum|enum
name|LAST_OPERATION
block|{
name|SERIALIZE
block|,
name|DESERIALIZE
block|,
name|UNKNOWN
block|}
specifier|private
name|LAST_OPERATION
name|status
decl_stmt|;
specifier|private
name|long
name|serializedSize
decl_stmt|;
specifier|private
name|long
name|deserializedSize
decl_stmt|;
specifier|private
name|String
name|compressionType
decl_stmt|;
specifier|private
name|ParquetHiveRecord
name|parquetRow
decl_stmt|;
specifier|public
name|ParquetHiveSerDe
parameter_list|()
block|{
name|parquetRow
operator|=
operator|new
name|ParquetHiveRecord
argument_list|()
expr_stmt|;
name|stats
operator|=
operator|new
name|SerDeStats
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|final
name|void
name|initialize
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Properties
name|tbl
parameter_list|)
throws|throws
name|SerDeException
block|{
specifier|final
name|TypeInfo
name|rowTypeInfo
decl_stmt|;
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
decl_stmt|;
specifier|final
name|List
argument_list|<
name|TypeInfo
argument_list|>
name|columnTypes
decl_stmt|;
comment|// Get column names and sort order
specifier|final
name|String
name|columnNameProperty
init|=
name|tbl
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMNS
argument_list|)
decl_stmt|;
specifier|final
name|String
name|columnTypeProperty
init|=
name|tbl
operator|.
name|getProperty
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMN_TYPES
argument_list|)
decl_stmt|;
comment|// Get compression properties
name|compressionType
operator|=
name|tbl
operator|.
name|getProperty
argument_list|(
name|ParquetOutputFormat
operator|.
name|COMPRESSION
argument_list|,
name|DEFAULTCOMPRESSION
argument_list|)
expr_stmt|;
if|if
condition|(
name|columnNameProperty
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|columnNames
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|columnNames
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|columnNameProperty
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|columnTypeProperty
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|columnTypes
operator|=
operator|new
name|ArrayList
argument_list|<
name|TypeInfo
argument_list|>
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|columnTypes
operator|=
name|TypeInfoUtils
operator|.
name|getTypeInfosFromTypeString
argument_list|(
name|columnTypeProperty
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|columnNames
operator|.
name|size
argument_list|()
operator|!=
name|columnTypes
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"ParquetHiveSerde initialization failed. Number of column "
operator|+
literal|"name and column type differs. columnNames = "
operator|+
name|columnNames
operator|+
literal|", columnTypes = "
operator|+
name|columnTypes
argument_list|)
throw|;
block|}
comment|// Create row related objects
name|rowTypeInfo
operator|=
name|TypeInfoFactory
operator|.
name|getStructTypeInfo
argument_list|(
name|columnNames
argument_list|,
name|columnTypes
argument_list|)
expr_stmt|;
name|this
operator|.
name|objInspector
operator|=
operator|new
name|ArrayWritableObjectInspector
argument_list|(
operator|(
name|StructTypeInfo
operator|)
name|rowTypeInfo
argument_list|)
expr_stmt|;
comment|// Stats part
name|serializedSize
operator|=
literal|0
expr_stmt|;
name|deserializedSize
operator|=
literal|0
expr_stmt|;
name|status
operator|=
name|LAST_OPERATION
operator|.
name|UNKNOWN
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Object
name|deserialize
parameter_list|(
specifier|final
name|Writable
name|blob
parameter_list|)
throws|throws
name|SerDeException
block|{
name|status
operator|=
name|LAST_OPERATION
operator|.
name|DESERIALIZE
expr_stmt|;
name|deserializedSize
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|blob
operator|instanceof
name|ArrayWritable
condition|)
block|{
name|deserializedSize
operator|=
operator|(
operator|(
name|ArrayWritable
operator|)
name|blob
operator|)
operator|.
name|get
argument_list|()
operator|.
name|length
expr_stmt|;
return|return
name|blob
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|ObjectInspector
name|getObjectInspector
parameter_list|()
throws|throws
name|SerDeException
block|{
return|return
name|objInspector
return|;
block|}
annotation|@
name|Override
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|Writable
argument_list|>
name|getSerializedClass
parameter_list|()
block|{
return|return
name|ParquetHiveRecord
operator|.
name|class
return|;
block|}
annotation|@
name|Override
specifier|public
name|Writable
name|serialize
parameter_list|(
specifier|final
name|Object
name|obj
parameter_list|,
specifier|final
name|ObjectInspector
name|objInspector
parameter_list|)
throws|throws
name|SerDeException
block|{
if|if
condition|(
operator|!
name|objInspector
operator|.
name|getCategory
argument_list|()
operator|.
name|equals
argument_list|(
name|Category
operator|.
name|STRUCT
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|SerDeException
argument_list|(
literal|"Cannot serialize "
operator|+
name|objInspector
operator|.
name|getCategory
argument_list|()
operator|+
literal|". Can only serialize a struct"
argument_list|)
throw|;
block|}
name|serializedSize
operator|=
operator|(
operator|(
name|StructObjectInspector
operator|)
name|objInspector
operator|)
operator|.
name|getAllStructFieldRefs
argument_list|()
operator|.
name|size
argument_list|()
expr_stmt|;
name|status
operator|=
name|LAST_OPERATION
operator|.
name|SERIALIZE
expr_stmt|;
name|parquetRow
operator|.
name|value
operator|=
name|obj
expr_stmt|;
name|parquetRow
operator|.
name|inspector
operator|=
operator|(
name|StructObjectInspector
operator|)
name|objInspector
expr_stmt|;
return|return
name|parquetRow
return|;
block|}
annotation|@
name|Override
specifier|public
name|SerDeStats
name|getSerDeStats
parameter_list|()
block|{
comment|// must be different
assert|assert
operator|(
name|status
operator|!=
name|LAST_OPERATION
operator|.
name|UNKNOWN
operator|)
assert|;
if|if
condition|(
name|status
operator|==
name|LAST_OPERATION
operator|.
name|SERIALIZE
condition|)
block|{
name|stats
operator|.
name|setRawDataSize
argument_list|(
name|serializedSize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|stats
operator|.
name|setRawDataSize
argument_list|(
name|deserializedSize
argument_list|)
expr_stmt|;
block|}
return|return
name|stats
return|;
block|}
block|}
end_class

end_unit

