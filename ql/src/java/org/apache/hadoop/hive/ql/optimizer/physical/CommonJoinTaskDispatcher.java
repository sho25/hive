begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|physical
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Context
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ConditionalTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|JoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|LateralViewForwardOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|OperatorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TableScanOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Task
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TaskFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|MapRedTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|Dispatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|GenMapRedUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|MapJoinProcessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ParseContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|QBJoinTree
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalResolverCommonJoin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalResolverCommonJoin
operator|.
name|ConditionalResolverCommonJoinCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|JoinDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapredLocalWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapredWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceWork
import|;
end_import

begin_comment
comment|/*  * Convert tasks involving JOIN into MAPJOIN.  * If hive.auto.convert.join is true, the tasks involving join are converted.  * Consider the query:  * select .... from T1 join T2 on T1.key = T2.key join T3 on T1.key = T3.key  *  * There is a map-reduce task which performs a 3-way join (T1, T2, T3).  * The task would be converted to a conditional task which would have 4 children  * a. Mapjoin considering T1 as the big table  * b. Mapjoin considering T2 as the big table  * c. Mapjoin considering T3 as the big table  * d. Map-reduce join (the original task).  *  *  Note that the sizes of all the inputs may not be available at compile time. At runtime, it is  *  determined which branch we want to pick up from the above.  *  * However, if hive.auto.convert.join.noconditionaltask is set to true, and  * the sum of any n-1 tables is smaller than hive.auto.convert.join.noconditionaltask.size,  * then a mapjoin is created instead of the conditional task. For the above, if the size of  * T1 + T2 is less than the threshold, then the task is converted to a mapjoin task with T3 as  * the big table.  *  * In this case, further optimization is performed by merging 2 consecutive map-only jobs.  * Consider the query:  * select ... from T1 join T2 on T1.key1 = T2.key1 join T3 on T1.key2 = T3.key2  *  * Initially, the plan would consist of 2 Map-reduce jobs (1 to perform join for T1 and T2)  * followed by another map-reduce job (to perform join of the result with T3). After the  * optimization, both these tasks would be converted to map-only tasks. These 2 map-only jobs  * are then merged into a single map-only job. As a followup (HIVE-3952), it would be possible to  * merge a map-only task with a map-reduce task.  * Consider the query:  * select T1.key2, count(*) from T1 join T2 on T1.key1 = T2.key1 group by T1.key2;  * Initially, the plan would consist of 2 Map-reduce jobs (1 to perform join for T1 and T2)  * followed by another map-reduce job (to perform groupby of the result). After the  * optimization, the join task would be converted to map-only tasks. After HIVE-3952, the map-only  * task would be merged with the map-reduce task to create a single map-reduce task.  */
end_comment

begin_comment
comment|/**  * Iterator each tasks. If this task has a local work,create a new task for this local work, named  * MapredLocalTask. then make this new generated task depends on current task's parent task, and  * make current task depends on this new generated task  */
end_comment

begin_class
specifier|public
class|class
name|CommonJoinTaskDispatcher
extends|extends
name|AbstractJoinTaskDispatcher
implements|implements
name|Dispatcher
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|aliasToSize
init|=
literal|null
decl_stmt|;
specifier|public
name|CommonJoinTaskDispatcher
parameter_list|(
name|PhysicalContext
name|context
parameter_list|)
block|{
name|super
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
comment|/**    * Calculate the total size of local tables in loclWork.    * @param localWork    * @return the total size of local tables. Or -1, if the total    * size is unknown.    */
specifier|private
name|long
name|calculateLocalTableTotalSize
parameter_list|(
name|MapredLocalWork
name|localWork
parameter_list|)
block|{
name|long
name|localTableTotalSize
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|localWork
operator|==
literal|null
condition|)
block|{
return|return
name|localTableTotalSize
return|;
block|}
for|for
control|(
name|String
name|alias
range|:
name|localWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
name|Long
name|tabSize
init|=
name|aliasToSize
operator|.
name|get
argument_list|(
name|alias
argument_list|)
decl_stmt|;
if|if
condition|(
name|tabSize
operator|==
literal|null
condition|)
block|{
comment|// if the size is unavailable, we need to assume a size 1 greater than
comment|// localTableTotalSizeLimit this implies that merge cannot happen
comment|// so we will return false.
return|return
operator|-
literal|1
return|;
block|}
name|localTableTotalSize
operator|+=
name|tabSize
expr_stmt|;
block|}
return|return
name|localTableTotalSize
return|;
block|}
comment|/**    * Check if the total size of local tables will be under    * the limit after we merge localWork1 and localWork2.    * The limit of the total size of local tables is defined by    * HiveConf.ConfVars.HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD.    * @param conf    * @param localWorks    * @return    */
specifier|private
name|boolean
name|isLocalTableTotalSizeUnderLimitAfterMerge
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|MapredLocalWork
modifier|...
name|localWorks
parameter_list|)
block|{
specifier|final
name|long
name|localTableTotalSizeLimit
init|=
name|HiveConf
operator|.
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD
argument_list|)
decl_stmt|;
name|long
name|localTableTotalSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|localWorks
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
specifier|final
name|long
name|localWorkTableTotalSize
init|=
name|calculateLocalTableTotalSize
argument_list|(
name|localWorks
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|localWorkTableTotalSize
operator|<
literal|0
condition|)
block|{
comment|// The total size of local tables in localWork[i] is unknown.
return|return
literal|false
return|;
block|}
name|localTableTotalSize
operator|+=
name|localWorkTableTotalSize
expr_stmt|;
block|}
if|if
condition|(
name|localTableTotalSize
operator|>
name|localTableTotalSizeLimit
condition|)
block|{
comment|// The total size of local tables after we merge localWorks
comment|// is larger than the limit set by
comment|// HiveConf.ConfVars.HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD.
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
comment|// create map join task and set big table as bigTablePosition
specifier|private
name|MapRedTask
name|convertTaskToMapJoinTask
parameter_list|(
name|MapredWork
name|newWork
parameter_list|,
name|int
name|bigTablePosition
parameter_list|)
throws|throws
name|UnsupportedEncodingException
throws|,
name|SemanticException
block|{
comment|// create a mapred task for this work
name|MapRedTask
name|newTask
init|=
operator|(
name|MapRedTask
operator|)
name|TaskFactory
operator|.
name|get
argument_list|(
name|newWork
argument_list|,
name|physicalContext
operator|.
name|getParseContext
argument_list|()
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|JoinOperator
name|newJoinOp
init|=
name|getJoinOp
argument_list|(
name|newTask
argument_list|)
decl_stmt|;
comment|// optimize this newWork given the big table position
name|MapJoinProcessor
operator|.
name|genMapJoinOpAndLocalWork
argument_list|(
name|physicalContext
operator|.
name|getParseContext
argument_list|()
operator|.
name|getConf
argument_list|()
argument_list|,
name|newWork
argument_list|,
name|newJoinOp
argument_list|,
name|bigTablePosition
argument_list|)
expr_stmt|;
return|return
name|newTask
return|;
block|}
comment|/*    * A task and its child task has been converted from join to mapjoin.    * See if the two tasks can be merged.    */
specifier|private
name|void
name|mergeMapJoinTaskIntoItsChildMapRedTask
parameter_list|(
name|MapRedTask
name|mapJoinTask
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// Step 1: Check if mapJoinTask has a single child.
comment|// If so, check if we can merge mapJoinTask into that child.
if|if
condition|(
name|mapJoinTask
operator|.
name|getChildTasks
argument_list|()
operator|==
literal|null
operator|||
name|mapJoinTask
operator|.
name|getChildTasks
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
comment|// No child-task to merge, nothing to do or there are more than one
comment|// child-tasks in which case we don't want to do anything.
return|return;
block|}
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
init|=
name|mapJoinTask
operator|.
name|getChildTasks
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|childTask
operator|instanceof
name|MapRedTask
operator|)
condition|)
block|{
comment|// Nothing to do if it is not a MapReduce task.
return|return;
block|}
name|MapRedTask
name|childMapRedTask
init|=
operator|(
name|MapRedTask
operator|)
name|childTask
decl_stmt|;
name|MapWork
name|mapJoinMapWork
init|=
name|mapJoinTask
operator|.
name|getWork
argument_list|()
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
name|MapWork
name|childMapWork
init|=
name|childMapRedTask
operator|.
name|getWork
argument_list|()
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|mapJoinAliasToWork
init|=
name|mapJoinMapWork
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|mapJoinAliasToWork
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
comment|// Do not merge if the MapredWork of MapJoin has multiple input aliases.
return|return;
block|}
name|Entry
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|mapJoinAliasToWorkEntry
init|=
name|mapJoinAliasToWork
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|mapJoinAlias
init|=
name|mapJoinAliasToWorkEntry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|TableScanOperator
name|mapJoinTaskTableScanOperator
init|=
name|OperatorUtils
operator|.
name|findSingleOperator
argument_list|(
name|mapJoinAliasToWorkEntry
operator|.
name|getValue
argument_list|()
argument_list|,
name|TableScanOperator
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapJoinTaskTableScanOperator
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Expected a "
operator|+
name|TableScanOperator
operator|.
name|getOperatorName
argument_list|()
operator|+
literal|" operator as the work associated with alias "
operator|+
name|mapJoinAlias
operator|+
literal|". Found a "
operator|+
name|mapJoinAliasToWork
operator|.
name|get
argument_list|(
name|mapJoinAlias
argument_list|)
operator|.
name|getName
argument_list|()
operator|+
literal|" operator."
argument_list|)
throw|;
block|}
name|FileSinkOperator
name|mapJoinTaskFileSinkOperator
init|=
name|OperatorUtils
operator|.
name|findSingleOperator
argument_list|(
name|mapJoinTaskTableScanOperator
argument_list|,
name|FileSinkOperator
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapJoinTaskFileSinkOperator
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Cannot find the "
operator|+
name|FileSinkOperator
operator|.
name|getOperatorName
argument_list|()
operator|+
literal|" operator at the last operator of the MapJoin Task."
argument_list|)
throw|;
block|}
comment|// The mapJoinTaskFileSinkOperator writes to a different directory
name|String
name|childMRPath
init|=
name|mapJoinTaskFileSinkOperator
operator|.
name|getConf
argument_list|()
operator|.
name|getDirName
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|childMRAliases
init|=
name|childMapWork
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|childMRPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|childMRAliases
operator|==
literal|null
operator|||
name|childMRAliases
operator|.
name|size
argument_list|()
operator|!=
literal|1
condition|)
block|{
return|return;
block|}
name|String
name|childMRAlias
init|=
name|childMRAliases
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// Sanity check to make sure there is no alias conflict after merge.
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|entry
range|:
name|childMapWork
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|path
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|equals
argument_list|(
name|childMRPath
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|aliases
operator|.
name|contains
argument_list|(
name|mapJoinAlias
argument_list|)
condition|)
block|{
comment|// alias confict should not happen here.
return|return;
block|}
block|}
name|MapredLocalWork
name|mapJoinLocalWork
init|=
name|mapJoinMapWork
operator|.
name|getMapLocalWork
argument_list|()
decl_stmt|;
name|MapredLocalWork
name|childLocalWork
init|=
name|childMapWork
operator|.
name|getMapLocalWork
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|mapJoinLocalWork
operator|!=
literal|null
operator|&&
name|mapJoinLocalWork
operator|.
name|getBucketMapjoinContext
argument_list|()
operator|!=
literal|null
operator|)
operator|||
operator|(
name|childLocalWork
operator|!=
literal|null
operator|&&
name|childLocalWork
operator|.
name|getBucketMapjoinContext
argument_list|()
operator|!=
literal|null
operator|)
condition|)
block|{
comment|// Right now, we do not handle the case that either of them is bucketed.
comment|// We should relax this constraint with a follow-up jira.
return|return;
block|}
comment|// We need to check if the total size of local tables is under the limit.
comment|// At here, we are using a strong condition, which is the total size of
comment|// local tables used by all input paths. Actually, we can relax this condition
comment|// to check the total size of local tables for every input path.
comment|// Example:
comment|//               UNION_ALL
comment|//              /         \
comment|//             /           \
comment|//            /             \
comment|//           /               \
comment|//       MapJoin1          MapJoin2
comment|//      /   |   \         /   |   \
comment|//     /    |    \       /    |    \
comment|//   Big1   S1   S2    Big2   S3   S4
comment|// In this case, we have two MapJoins, MapJoin1 and MapJoin2. Big1 and Big2 are two
comment|// big tables, and S1, S2, S3, and S4 are four small tables. Hash tables of S1 and S2
comment|// will only be used by Map tasks processing Big1. Hash tables of S3 and S4 will only
comment|// be used by Map tasks processing Big2. If Big1!=Big2, we should only check if the size
comment|// of S1 + S2 is under the limit, and if the size of S3 + S4 is under the limit.
comment|// But, right now, we are checking the size of S1 + S2 + S3 + S4 is under the limit.
comment|// If Big1=Big2, we will only scan a path once. So, MapJoin1 and MapJoin2 will be executed
comment|// in the same Map task. In this case, we need to make sure the size of S1 + S2 + S3 + S4
comment|// is under the limit.
if|if
condition|(
operator|!
name|isLocalTableTotalSizeUnderLimitAfterMerge
argument_list|(
name|conf
argument_list|,
name|mapJoinLocalWork
argument_list|,
name|childLocalWork
argument_list|)
condition|)
block|{
comment|// The total size of local tables may not be under
comment|// the limit after we merge mapJoinLocalWork and childLocalWork.
comment|// Do not merge.
return|return;
block|}
name|TableScanOperator
name|childMRTaskTableScanOperator
init|=
name|OperatorUtils
operator|.
name|findSingleOperator
argument_list|(
name|childMapWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|childMRAlias
argument_list|)
argument_list|,
name|TableScanOperator
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|childMRTaskTableScanOperator
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Expected a "
operator|+
name|TableScanOperator
operator|.
name|getOperatorName
argument_list|()
operator|+
literal|" operator as the work associated with alias "
operator|+
name|childMRAlias
operator|+
literal|". Found a "
operator|+
name|childMapWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|childMRAlias
argument_list|)
operator|.
name|getName
argument_list|()
operator|+
literal|" operator."
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|parentsInMapJoinTask
init|=
name|mapJoinTaskFileSinkOperator
operator|.
name|getParentOperators
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|childrenInChildMRTask
init|=
name|childMRTaskTableScanOperator
operator|.
name|getChildOperators
argument_list|()
decl_stmt|;
if|if
condition|(
name|parentsInMapJoinTask
operator|.
name|size
argument_list|()
operator|>
literal|1
operator|||
name|childrenInChildMRTask
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
comment|// Do not merge if we do not know how to connect two operator trees.
return|return;
block|}
comment|// Step 2: Merge mapJoinTask into the Map-side of its child.
comment|// Step 2.1: Connect the operator trees of two MapRedTasks.
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parentInMapJoinTask
init|=
name|parentsInMapJoinTask
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|childInChildMRTask
init|=
name|childrenInChildMRTask
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|parentInMapJoinTask
operator|.
name|replaceChild
argument_list|(
name|mapJoinTaskFileSinkOperator
argument_list|,
name|childInChildMRTask
argument_list|)
expr_stmt|;
name|childInChildMRTask
operator|.
name|replaceParent
argument_list|(
name|childMRTaskTableScanOperator
argument_list|,
name|parentInMapJoinTask
argument_list|)
expr_stmt|;
comment|// Step 2.2: Replace the corresponding part childMRWork's MapWork.
name|GenMapRedUtils
operator|.
name|replaceMapWork
argument_list|(
name|mapJoinAlias
argument_list|,
name|childMRAlias
argument_list|,
name|mapJoinMapWork
argument_list|,
name|childMapWork
argument_list|)
expr_stmt|;
comment|// Step 2.3: Fill up stuff in local work
if|if
condition|(
name|mapJoinLocalWork
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|childLocalWork
operator|==
literal|null
condition|)
block|{
name|childMapWork
operator|.
name|setMapLocalWork
argument_list|(
name|mapJoinLocalWork
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|childLocalWork
operator|.
name|getAliasToFetchWork
argument_list|()
operator|.
name|putAll
argument_list|(
name|mapJoinLocalWork
operator|.
name|getAliasToFetchWork
argument_list|()
argument_list|)
expr_stmt|;
name|childLocalWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|putAll
argument_list|(
name|mapJoinLocalWork
operator|.
name|getAliasToWork
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Step 2.4: Remove this MapJoin task
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|parentTasks
init|=
name|mapJoinTask
operator|.
name|getParentTasks
argument_list|()
decl_stmt|;
name|mapJoinTask
operator|.
name|setParentTasks
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|mapJoinTask
operator|.
name|setChildTasks
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|childMapRedTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|remove
argument_list|(
name|mapJoinTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|parentTasks
operator|!=
literal|null
condition|)
block|{
name|childMapRedTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|addAll
argument_list|(
name|parentTasks
argument_list|)
expr_stmt|;
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parentTask
range|:
name|parentTasks
control|)
block|{
name|parentTask
operator|.
name|getChildTasks
argument_list|()
operator|.
name|remove
argument_list|(
name|mapJoinTask
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|parentTask
operator|.
name|getChildTasks
argument_list|()
operator|.
name|contains
argument_list|(
name|childMapRedTask
argument_list|)
condition|)
block|{
name|parentTask
operator|.
name|getChildTasks
argument_list|()
operator|.
name|add
argument_list|(
name|childMapRedTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
if|if
condition|(
name|physicalContext
operator|.
name|getRootTasks
argument_list|()
operator|.
name|contains
argument_list|(
name|mapJoinTask
argument_list|)
condition|)
block|{
name|physicalContext
operator|.
name|removeFromRootTask
argument_list|(
name|mapJoinTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|childMapRedTask
operator|.
name|getParentTasks
argument_list|()
operator|!=
literal|null
operator|&&
name|childMapRedTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
operator|!
name|physicalContext
operator|.
name|getRootTasks
argument_list|()
operator|.
name|contains
argument_list|(
name|childMapRedTask
argument_list|)
condition|)
block|{
name|physicalContext
operator|.
name|addToRootTask
argument_list|(
name|childMapRedTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|childMapRedTask
operator|.
name|getParentTasks
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|childMapRedTask
operator|.
name|setParentTasks
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|boolean
name|cannotConvert
parameter_list|(
name|long
name|aliasKnownSize
parameter_list|,
name|long
name|aliasTotalKnownInputSize
parameter_list|,
name|long
name|ThresholdOfSmallTblSizeSum
parameter_list|)
block|{
if|if
condition|(
name|aliasKnownSize
operator|>
literal|0
operator|&&
name|aliasTotalKnownInputSize
operator|-
name|aliasKnownSize
operator|>
name|ThresholdOfSmallTblSizeSum
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|processCurrentTask
parameter_list|(
name|MapRedTask
name|currTask
parameter_list|,
name|ConditionalTask
name|conditionalTask
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// whether it contains common join op; if contains, return this common join op
name|JoinOperator
name|joinOp
init|=
name|getJoinOp
argument_list|(
name|currTask
argument_list|)
decl_stmt|;
if|if
condition|(
name|joinOp
operator|==
literal|null
operator|||
name|joinOp
operator|.
name|getConf
argument_list|()
operator|.
name|isFixedAsSorted
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|currTask
operator|.
name|setTaskTag
argument_list|(
name|Task
operator|.
name|COMMON_JOIN
argument_list|)
expr_stmt|;
name|MapWork
name|currWork
init|=
name|currTask
operator|.
name|getWork
argument_list|()
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
comment|// create conditional work list and task list
name|List
argument_list|<
name|Serializable
argument_list|>
name|listWorks
init|=
operator|new
name|ArrayList
argument_list|<
name|Serializable
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|listTasks
init|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
comment|// create task to aliases mapping and alias to input file mapping for resolver
name|HashMap
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|taskToAliases
init|=
operator|new
name|HashMap
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|pathToAliases
init|=
name|currWork
operator|.
name|getPathToAliases
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|aliasToWork
init|=
name|currWork
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
comment|// get parseCtx for this Join Operator
name|ParseContext
name|parseCtx
init|=
name|physicalContext
operator|.
name|getParseContext
argument_list|()
decl_stmt|;
name|QBJoinTree
name|joinTree
init|=
name|parseCtx
operator|.
name|getJoinContext
argument_list|()
operator|.
name|get
argument_list|(
name|joinOp
argument_list|)
decl_stmt|;
comment|// start to generate multiple map join tasks
name|JoinDesc
name|joinDesc
init|=
name|joinOp
operator|.
name|getConf
argument_list|()
decl_stmt|;
if|if
condition|(
name|aliasToSize
operator|==
literal|null
condition|)
block|{
name|aliasToSize
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|long
name|aliasTotalKnownInputSize
init|=
name|getTotalKnownInputSize
argument_list|(
name|context
argument_list|,
name|currWork
argument_list|,
name|pathToAliases
argument_list|,
name|aliasToSize
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|Integer
argument_list|>
name|bigTableCandidates
init|=
name|MapJoinProcessor
operator|.
name|getBigTableCandidates
argument_list|(
name|joinDesc
operator|.
name|getConds
argument_list|()
argument_list|)
decl_stmt|;
comment|// no table could be the big table; there is no need to convert
if|if
condition|(
name|bigTableCandidates
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// if any of bigTableCandidates is from multi-sourced, bigTableCandidates should
comment|// only contain multi-sourced because multi-sourced cannot be hashed or direct readable
name|bigTableCandidates
operator|=
name|multiInsertBigTableCheck
argument_list|(
name|joinOp
argument_list|,
name|bigTableCandidates
argument_list|)
expr_stmt|;
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConf
argument_list|()
decl_stmt|;
comment|// If sizes of at least n-1 tables in a n-way join is known, and their sum is smaller than
comment|// the threshold size, convert the join into map-join and don't create a conditional task
name|boolean
name|convertJoinMapJoin
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOINNOCONDITIONALTASK
argument_list|)
decl_stmt|;
name|int
name|bigTablePosition
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|convertJoinMapJoin
condition|)
block|{
comment|// This is the threshold that the user has specified to fit in mapjoin
name|long
name|mapJoinSize
init|=
name|HiveConf
operator|.
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD
argument_list|)
decl_stmt|;
name|Long
name|bigTableSize
init|=
literal|null
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|aliasToWork
operator|.
name|keySet
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|tablePosition
range|:
name|bigTableCandidates
control|)
block|{
name|Operator
argument_list|<
name|?
argument_list|>
name|parent
init|=
name|joinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
name|tablePosition
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|participants
init|=
name|GenMapRedUtils
operator|.
name|findAliases
argument_list|(
name|currWork
argument_list|,
name|parent
argument_list|)
decl_stmt|;
name|long
name|sumOfOthers
init|=
name|Utilities
operator|.
name|sumOfExcept
argument_list|(
name|aliasToSize
argument_list|,
name|aliases
argument_list|,
name|participants
argument_list|)
decl_stmt|;
if|if
condition|(
name|sumOfOthers
argument_list|<
literal|0
operator|||
name|sumOfOthers
argument_list|>
name|mapJoinSize
condition|)
block|{
continue|continue;
comment|// some small alias is not known or too big
block|}
if|if
condition|(
name|bigTableSize
operator|==
literal|null
operator|&&
name|bigTablePosition
operator|>=
literal|0
operator|&&
name|tablePosition
operator|<
name|bigTablePosition
condition|)
block|{
continue|continue;
comment|// prefer right most alias
block|}
name|long
name|aliasSize
init|=
name|Utilities
operator|.
name|sumOf
argument_list|(
name|aliasToSize
argument_list|,
name|participants
argument_list|)
decl_stmt|;
if|if
condition|(
name|bigTableSize
operator|==
literal|null
operator|||
name|bigTableSize
operator|<
literal|0
operator|||
operator|(
name|aliasSize
operator|>=
literal|0
operator|&&
name|aliasSize
operator|>=
name|bigTableSize
operator|)
condition|)
block|{
name|bigTablePosition
operator|=
name|tablePosition
expr_stmt|;
name|bigTableSize
operator|=
name|aliasSize
expr_stmt|;
block|}
block|}
block|}
name|currWork
operator|.
name|setOpParseCtxMap
argument_list|(
name|parseCtx
operator|.
name|getOpParseCtx
argument_list|()
argument_list|)
expr_stmt|;
name|currWork
operator|.
name|setJoinTree
argument_list|(
name|joinTree
argument_list|)
expr_stmt|;
if|if
condition|(
name|bigTablePosition
operator|>=
literal|0
condition|)
block|{
comment|// create map join task and set big table as bigTablePosition
name|MapRedTask
name|newTask
init|=
name|convertTaskToMapJoinTask
argument_list|(
name|currTask
operator|.
name|getWork
argument_list|()
argument_list|,
name|bigTablePosition
argument_list|)
decl_stmt|;
name|newTask
operator|.
name|setTaskTag
argument_list|(
name|Task
operator|.
name|MAPJOIN_ONLY_NOBACKUP
argument_list|)
expr_stmt|;
name|replaceTask
argument_list|(
name|currTask
argument_list|,
name|newTask
argument_list|,
name|physicalContext
argument_list|)
expr_stmt|;
comment|// Can this task be merged with the child task. This can happen if a big table is being
comment|// joined with multiple small tables on different keys
if|if
condition|(
operator|(
name|newTask
operator|.
name|getChildTasks
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|newTask
operator|.
name|getChildTasks
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|)
condition|)
block|{
name|mergeMapJoinTaskIntoItsChildMapRedTask
argument_list|(
name|newTask
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
return|return
name|newTask
return|;
block|}
name|long
name|ThresholdOfSmallTblSizeSum
init|=
name|HiveConf
operator|.
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESMALLTABLESFILESIZE
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|joinOp
operator|.
name|getNumParent
argument_list|()
condition|;
name|pos
operator|++
control|)
block|{
comment|// this table cannot be big table
if|if
condition|(
operator|!
name|bigTableCandidates
operator|.
name|contains
argument_list|(
name|pos
argument_list|)
condition|)
block|{
continue|continue;
block|}
comment|// deep copy a new mapred work from xml
comment|// Once HIVE-4396 is in, it would be faster to use a cheaper method to clone the plan
name|MapredWork
name|newWork
init|=
name|Utilities
operator|.
name|clonePlan
argument_list|(
name|currTask
operator|.
name|getWork
argument_list|()
argument_list|)
decl_stmt|;
comment|// create map join task and set big table as i
name|MapRedTask
name|newTask
init|=
name|convertTaskToMapJoinTask
argument_list|(
name|newWork
argument_list|,
name|pos
argument_list|)
decl_stmt|;
name|Operator
argument_list|<
name|?
argument_list|>
name|startOp
init|=
name|joinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|GenMapRedUtils
operator|.
name|findAliases
argument_list|(
name|currWork
argument_list|,
name|startOp
argument_list|)
decl_stmt|;
name|long
name|aliasKnownSize
init|=
name|Utilities
operator|.
name|sumOf
argument_list|(
name|aliasToSize
argument_list|,
name|aliases
argument_list|)
decl_stmt|;
if|if
condition|(
name|cannotConvert
argument_list|(
name|aliasKnownSize
argument_list|,
name|aliasTotalKnownInputSize
argument_list|,
name|ThresholdOfSmallTblSizeSum
argument_list|)
condition|)
block|{
continue|continue;
block|}
comment|// add into conditional task
name|listWorks
operator|.
name|add
argument_list|(
name|newTask
operator|.
name|getWork
argument_list|()
argument_list|)
expr_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|newTask
argument_list|)
expr_stmt|;
name|newTask
operator|.
name|setTaskTag
argument_list|(
name|Task
operator|.
name|CONVERTED_MAPJOIN
argument_list|)
expr_stmt|;
comment|// set up backup task
name|newTask
operator|.
name|setBackupTask
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
name|newTask
operator|.
name|setBackupChildrenTasks
argument_list|(
name|currTask
operator|.
name|getChildTasks
argument_list|()
argument_list|)
expr_stmt|;
comment|// put the mapping task to aliases
name|taskToAliases
operator|.
name|put
argument_list|(
name|newTask
argument_list|,
name|aliases
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Generate Map Join Task Error: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
comment|// insert current common join task to conditional task
name|listWorks
operator|.
name|add
argument_list|(
name|currTask
operator|.
name|getWork
argument_list|()
argument_list|)
expr_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
comment|// clear JoinTree and OP Parse Context
name|currWork
operator|.
name|setOpParseCtxMap
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|currWork
operator|.
name|setJoinTree
argument_list|(
literal|null
argument_list|)
expr_stmt|;
comment|// create conditional task and insert conditional task into task tree
name|ConditionalWork
name|cndWork
init|=
operator|new
name|ConditionalWork
argument_list|(
name|listWorks
argument_list|)
decl_stmt|;
name|ConditionalTask
name|cndTsk
init|=
operator|(
name|ConditionalTask
operator|)
name|TaskFactory
operator|.
name|get
argument_list|(
name|cndWork
argument_list|,
name|parseCtx
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|cndTsk
operator|.
name|setListTasks
argument_list|(
name|listTasks
argument_list|)
expr_stmt|;
comment|// set resolver and resolver context
name|cndTsk
operator|.
name|setResolver
argument_list|(
operator|new
name|ConditionalResolverCommonJoin
argument_list|()
argument_list|)
expr_stmt|;
name|ConditionalResolverCommonJoinCtx
name|resolverCtx
init|=
operator|new
name|ConditionalResolverCommonJoinCtx
argument_list|()
decl_stmt|;
name|resolverCtx
operator|.
name|setPathToAliases
argument_list|(
name|pathToAliases
argument_list|)
expr_stmt|;
name|resolverCtx
operator|.
name|setAliasToKnownSize
argument_list|(
name|aliasToSize
argument_list|)
expr_stmt|;
name|resolverCtx
operator|.
name|setTaskToAliases
argument_list|(
name|taskToAliases
argument_list|)
expr_stmt|;
name|resolverCtx
operator|.
name|setCommonJoinTask
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
name|resolverCtx
operator|.
name|setLocalTmpDir
argument_list|(
name|context
operator|.
name|getLocalScratchDir
argument_list|(
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|resolverCtx
operator|.
name|setHdfsTmpDir
argument_list|(
name|context
operator|.
name|getMRScratchDir
argument_list|()
argument_list|)
expr_stmt|;
name|cndTsk
operator|.
name|setResolverCtx
argument_list|(
name|resolverCtx
argument_list|)
expr_stmt|;
comment|// replace the current task with the new generated conditional task
name|replaceTaskWithConditionalTask
argument_list|(
name|currTask
argument_list|,
name|cndTsk
argument_list|,
name|physicalContext
argument_list|)
expr_stmt|;
return|return
name|cndTsk
return|;
block|}
comment|/*    * If any operator which does not allow map-side conversion is present in the mapper, dont    * convert it into a conditional task.    */
specifier|private
name|boolean
name|checkOperatorOKMapJoinConversion
parameter_list|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|op
parameter_list|)
block|{
if|if
condition|(
operator|!
name|op
operator|.
name|opAllowedConvertMapJoin
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|op
operator|.
name|getChildOperators
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|childOp
range|:
name|op
operator|.
name|getChildOperators
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|checkOperatorOKMapJoinConversion
argument_list|(
name|childOp
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|JoinOperator
name|getJoinOp
parameter_list|(
name|MapRedTask
name|task
parameter_list|)
throws|throws
name|SemanticException
block|{
name|MapWork
name|mWork
init|=
name|task
operator|.
name|getWork
argument_list|()
operator|.
name|getMapWork
argument_list|()
decl_stmt|;
name|ReduceWork
name|rWork
init|=
name|task
operator|.
name|getWork
argument_list|()
operator|.
name|getReduceWork
argument_list|()
decl_stmt|;
if|if
condition|(
name|rWork
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|reducerOp
init|=
name|rWork
operator|.
name|getReducer
argument_list|()
decl_stmt|;
if|if
condition|(
name|reducerOp
operator|instanceof
name|JoinOperator
condition|)
block|{
comment|/* Is any operator present, which prevents the conversion */
name|Map
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|aliasToWork
init|=
name|mWork
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|op
range|:
name|aliasToWork
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|checkOperatorOKMapJoinConversion
argument_list|(
name|op
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
return|return
operator|(
name|JoinOperator
operator|)
name|reducerOp
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/**    * In the case of a multi-insert statement the Source Operator will have multiple children.    * For e.g.    * from src b    * INSERT OVERWRITE TABLE src_4    *  select *    *  where b.key in    *    (select a.key from src a where b.value = a.value and a.key> '9')    * INSERT OVERWRITE TABLE src_5    * select *    * where b.key not in    *   ( select key from src s1 where s1.key> '2')    *    * The TableScan on 'src'(for alias b) will have 2 children one for each destination.    *    * In such cases only the Source side of the Join is the candidate Big Table.    * The reason being, it cannot be replaced by a HashTable as its rows must flow into the other children    * of the TableScan Operator.    */
specifier|private
name|Set
argument_list|<
name|Integer
argument_list|>
name|multiInsertBigTableCheck
parameter_list|(
name|JoinOperator
name|joinOp
parameter_list|,
name|Set
argument_list|<
name|Integer
argument_list|>
name|bigTableCandidates
parameter_list|)
block|{
name|int
name|multiChildrenSource
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|tablePosition
range|:
name|bigTableCandidates
operator|.
name|toArray
argument_list|(
operator|new
name|Integer
index|[
literal|0
index|]
argument_list|)
control|)
block|{
name|Operator
argument_list|<
name|?
argument_list|>
name|parent
init|=
name|joinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
name|tablePosition
argument_list|)
decl_stmt|;
for|for
control|(
init|;
name|parent
operator|!=
literal|null
condition|;
name|parent
operator|=
name|parent
operator|.
name|getNumParent
argument_list|()
operator|>
literal|0
condition|?
name|parent
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
else|:
literal|null
control|)
block|{
if|if
condition|(
name|parent
operator|.
name|getNumChild
argument_list|()
operator|>
literal|1
operator|&&
operator|!
operator|(
name|parent
operator|instanceof
name|LateralViewForwardOperator
operator|)
condition|)
block|{
if|if
condition|(
name|multiChildrenSource
operator|>=
literal|0
condition|)
block|{
return|return
name|Collections
operator|.
name|emptySet
argument_list|()
return|;
block|}
name|multiChildrenSource
operator|=
name|tablePosition
expr_stmt|;
block|}
block|}
block|}
return|return
name|multiChildrenSource
operator|<
literal|0
condition|?
name|bigTableCandidates
else|:
operator|new
name|HashSet
argument_list|<
name|Integer
argument_list|>
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|multiChildrenSource
argument_list|)
argument_list|)
return|;
block|}
block|}
end_class

end_unit

