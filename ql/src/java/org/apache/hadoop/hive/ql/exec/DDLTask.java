begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListenableFuture
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FsShell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|StatsSetupConst
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|DefaultHiveMetaHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Msck
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MsckInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|PartitionDropOptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|CompactionResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|EnvironmentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|GetOpenTxnsInfoResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Order
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowCompactResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowCompactResponseElement
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowLocksRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowLocksResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowLocksResponseElement
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SkewedInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|TxnInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMFullResourcePlan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMNullableResourcePlan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMResourcePlanStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMTrigger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|WMValidateResourcePlanResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|conf
operator|.
name|MetastoreConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|TxnStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|CompilationOpContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Context
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|DriverContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|QueryPlan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|QueryState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ArchiveUtils
operator|.
name|PartSpecInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
operator|.
name|TezSessionPoolManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
operator|.
name|TezTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
operator|.
name|WorkloadManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|ReadEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|WriteEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|RCFileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|merge
operator|.
name|MergeFileTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|merge
operator|.
name|MergeFileWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcSerde
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|parquet
operator|.
name|serde
operator|.
name|ParquetHiveSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|DbLockManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveLockManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveLockMode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveLockObject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveLockObject
operator|.
name|HiveLockObjectData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveTxnManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Hive
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|InvalidTableException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|PartitionIterable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|formatting
operator|.
name|MetaDataFormatUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|formatting
operator|.
name|MetaDataFormatter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|formatting
operator|.
name|TextMetaDataTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|AlterTablePartMergeFilesDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|DDLSemanticAnalyzer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ExplainConfiguration
operator|.
name|AnalyzeState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ReplicationSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AbortTxnsDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AddPartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterResourcePlanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterTableAlterPartDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterTableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterTableDesc
operator|.
name|AlterTableTypes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterTableExchangePartition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterTableSimpleDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterWMTriggerDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CacheMetadataDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateOrAlterWMMappingDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateOrAlterWMPoolDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateOrDropTriggerToPoolMappingDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateResourcePlanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateWMTriggerDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DDLWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DropPartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DropResourcePlanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DropWMMappingDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DropWMPoolDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DropWMTriggerDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FileMergeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|InsertCommitHookDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|KillQueryDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ListBucketingCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|LoadMultiFilesDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MoveWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MsckDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OrcFileMergeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|RCFileMergeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|RenamePartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReplRemoveFirstIncLoadPendFlagDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowColumnsDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowCompactionsDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowConfDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowLocksDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowPartitionsDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowResourcePlanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ShowTxnsDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|api
operator|.
name|StageType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
operator|.
name|util
operator|.
name|ReplUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|wm
operator|.
name|ExecutionTrigger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|MetadataTypedColumnsetSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|avro
operator|.
name|AvroSerdeUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|columnar
operator|.
name|ColumnarSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|dynamic_type
operator|.
name|DynamicSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorConverters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorConverters
operator|.
name|Converter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|PrimitiveObjectInspectorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tools
operator|.
name|HadoopArchives
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|ReflectionUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * DDLTask implementation.  *  **/
end_comment

begin_class
specifier|public
class|class
name|DDLTask
extends|extends
name|Task
argument_list|<
name|DDLWork
argument_list|>
implements|implements
name|Serializable
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"hive.ql.exec.DDLTask"
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|separator
init|=
name|Utilities
operator|.
name|tabCode
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|terminator
init|=
name|Utilities
operator|.
name|newLineCode
decl_stmt|;
comment|// These are suffixes attached to intermediate directory names used in the
comment|// archiving / un-archiving process.
specifier|private
specifier|static
name|String
name|INTERMEDIATE_ARCHIVED_DIR_SUFFIX
decl_stmt|;
specifier|private
specifier|static
name|String
name|INTERMEDIATE_ORIGINAL_DIR_SUFFIX
decl_stmt|;
specifier|private
specifier|static
name|String
name|INTERMEDIATE_EXTRACTED_DIR_SUFFIX
decl_stmt|;
specifier|private
name|MetaDataFormatter
name|formatter
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|requireLock
parameter_list|()
block|{
return|return
name|this
operator|.
name|work
operator|!=
literal|null
operator|&&
name|this
operator|.
name|work
operator|.
name|getNeedLock
argument_list|()
return|;
block|}
specifier|public
name|DDLTask
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|initialize
parameter_list|(
name|QueryState
name|queryState
parameter_list|,
name|QueryPlan
name|queryPlan
parameter_list|,
name|DriverContext
name|ctx
parameter_list|,
name|CompilationOpContext
name|opContext
parameter_list|)
block|{
name|super
operator|.
name|initialize
argument_list|(
name|queryState
argument_list|,
name|queryPlan
argument_list|,
name|ctx
argument_list|,
name|opContext
argument_list|)
expr_stmt|;
comment|// Pick the formatter to use to display the results.  Either the
comment|// normal human readable output or a json object.
name|formatter
operator|=
name|MetaDataFormatUtils
operator|.
name|getFormatter
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|INTERMEDIATE_ARCHIVED_DIR_SUFFIX
operator|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|METASTORE_INT_ARCHIVED
argument_list|)
expr_stmt|;
name|INTERMEDIATE_ORIGINAL_DIR_SUFFIX
operator|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|METASTORE_INT_ORIGINAL
argument_list|)
expr_stmt|;
name|INTERMEDIATE_EXTRACTED_DIR_SUFFIX
operator|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|METASTORE_INT_EXTRACTED
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|execute
parameter_list|(
name|DriverContext
name|driverContext
parameter_list|)
block|{
if|if
condition|(
name|driverContext
operator|.
name|getCtx
argument_list|()
operator|.
name|getExplainAnalyze
argument_list|()
operator|==
name|AnalyzeState
operator|.
name|RUNNING
condition|)
block|{
return|return
literal|0
return|;
block|}
comment|// Create the db
name|Hive
name|db
decl_stmt|;
try|try
block|{
name|db
operator|=
name|Hive
operator|.
name|get
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|DropPartitionDesc
name|dropPartition
init|=
name|work
operator|.
name|getDropPartitionDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|dropPartition
operator|!=
literal|null
condition|)
block|{
name|dropPartitions
argument_list|(
name|db
argument_list|,
name|dropPartition
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
name|AlterTableDesc
name|alterTbl
init|=
name|work
operator|.
name|getAlterTblDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|alterTbl
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|allowOperationInReplicationScope
argument_list|(
name|db
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|,
literal|null
argument_list|,
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
argument_list|)
condition|)
block|{
comment|// no alter, the table is missing either due to drop/rename which follows the alter.
comment|// or the existing table is newer than our update.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DDLTask: Alter Table is skipped as table {} is newer than update"
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|DROPCONSTRAINT
condition|)
block|{
return|return
name|dropConstraint
argument_list|(
name|db
argument_list|,
name|alterTbl
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|ADDCONSTRAINT
condition|)
block|{
return|return
name|addConstraints
argument_list|(
name|db
argument_list|,
name|alterTbl
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|alterTable
argument_list|(
name|db
argument_list|,
name|alterTbl
argument_list|)
return|;
block|}
block|}
name|AddPartitionDesc
name|addPartitionDesc
init|=
name|work
operator|.
name|getAddPartitionDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|addPartitionDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|addPartitions
argument_list|(
name|db
argument_list|,
name|addPartitionDesc
argument_list|)
return|;
block|}
name|RenamePartitionDesc
name|renamePartitionDesc
init|=
name|work
operator|.
name|getRenamePartitionDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|renamePartitionDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|renamePartition
argument_list|(
name|db
argument_list|,
name|renamePartitionDesc
argument_list|)
return|;
block|}
name|AlterTableSimpleDesc
name|simpleDesc
init|=
name|work
operator|.
name|getAlterTblSimpleDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|simpleDesc
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|simpleDesc
operator|.
name|getType
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|TOUCH
condition|)
block|{
return|return
name|touch
argument_list|(
name|db
argument_list|,
name|simpleDesc
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|simpleDesc
operator|.
name|getType
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|ARCHIVE
condition|)
block|{
return|return
name|archive
argument_list|(
name|db
argument_list|,
name|simpleDesc
argument_list|,
name|driverContext
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|simpleDesc
operator|.
name|getType
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|UNARCHIVE
condition|)
block|{
return|return
name|unarchive
argument_list|(
name|db
argument_list|,
name|simpleDesc
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|simpleDesc
operator|.
name|getType
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|COMPACT
condition|)
block|{
return|return
name|compact
argument_list|(
name|db
argument_list|,
name|simpleDesc
argument_list|)
return|;
block|}
block|}
name|MsckDesc
name|msckDesc
init|=
name|work
operator|.
name|getMsckDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|msckDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|msck
argument_list|(
name|db
argument_list|,
name|msckDesc
argument_list|)
return|;
block|}
name|ShowColumnsDesc
name|showCols
init|=
name|work
operator|.
name|getShowColumnsDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|showCols
operator|!=
literal|null
condition|)
block|{
return|return
name|showColumns
argument_list|(
name|db
argument_list|,
name|showCols
argument_list|)
return|;
block|}
name|ShowLocksDesc
name|showLocks
init|=
name|work
operator|.
name|getShowLocksDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|showLocks
operator|!=
literal|null
condition|)
block|{
return|return
name|showLocks
argument_list|(
name|db
argument_list|,
name|showLocks
argument_list|)
return|;
block|}
name|ShowCompactionsDesc
name|compactionsDesc
init|=
name|work
operator|.
name|getShowCompactionsDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|compactionsDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|showCompactions
argument_list|(
name|db
argument_list|,
name|compactionsDesc
argument_list|)
return|;
block|}
name|ShowTxnsDesc
name|txnsDesc
init|=
name|work
operator|.
name|getShowTxnsDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|txnsDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|showTxns
argument_list|(
name|db
argument_list|,
name|txnsDesc
argument_list|)
return|;
block|}
name|AbortTxnsDesc
name|abortTxnsDesc
init|=
name|work
operator|.
name|getAbortTxnsDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|abortTxnsDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|abortTxns
argument_list|(
name|db
argument_list|,
name|abortTxnsDesc
argument_list|)
return|;
block|}
name|ShowPartitionsDesc
name|showParts
init|=
name|work
operator|.
name|getShowPartsDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|showParts
operator|!=
literal|null
condition|)
block|{
return|return
name|showPartitions
argument_list|(
name|db
argument_list|,
name|showParts
argument_list|)
return|;
block|}
name|ShowConfDesc
name|showConf
init|=
name|work
operator|.
name|getShowConfDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|showConf
operator|!=
literal|null
condition|)
block|{
return|return
name|showConf
argument_list|(
name|db
argument_list|,
name|showConf
argument_list|)
return|;
block|}
name|AlterTablePartMergeFilesDesc
name|mergeFilesDesc
init|=
name|work
operator|.
name|getMergeFilesDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|mergeFilesDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|mergeFiles
argument_list|(
name|db
argument_list|,
name|mergeFilesDesc
argument_list|,
name|driverContext
argument_list|)
return|;
block|}
name|AlterTableAlterPartDesc
name|alterPartDesc
init|=
name|work
operator|.
name|getAlterTableAlterPartDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|alterPartDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|alterTableAlterPart
argument_list|(
name|db
argument_list|,
name|alterPartDesc
argument_list|)
return|;
block|}
name|AlterTableExchangePartition
name|alterTableExchangePartition
init|=
name|work
operator|.
name|getAlterTableExchangePartition
argument_list|()
decl_stmt|;
if|if
condition|(
name|alterTableExchangePartition
operator|!=
literal|null
condition|)
block|{
return|return
name|exchangeTablePartition
argument_list|(
name|db
argument_list|,
name|alterTableExchangePartition
argument_list|)
return|;
block|}
name|CacheMetadataDesc
name|cacheMetadataDesc
init|=
name|work
operator|.
name|getCacheMetadataDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|cacheMetadataDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|cacheMetadata
argument_list|(
name|db
argument_list|,
name|cacheMetadataDesc
argument_list|)
return|;
block|}
name|InsertCommitHookDesc
name|insertCommitHookDesc
init|=
name|work
operator|.
name|getInsertCommitHookDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|insertCommitHookDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|insertCommitWork
argument_list|(
name|db
argument_list|,
name|insertCommitHookDesc
argument_list|)
return|;
block|}
name|KillQueryDesc
name|killQueryDesc
init|=
name|work
operator|.
name|getKillQueryDesc
argument_list|()
decl_stmt|;
if|if
condition|(
name|killQueryDesc
operator|!=
literal|null
condition|)
block|{
return|return
name|killQuery
argument_list|(
name|db
argument_list|,
name|killQueryDesc
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getCreateResourcePlanDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|createResourcePlan
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getCreateResourcePlanDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getShowResourcePlanDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|showResourcePlans
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getShowResourcePlanDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getAlterResourcePlanDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|alterResourcePlan
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getAlterResourcePlanDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getDropResourcePlanDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|dropResourcePlan
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getDropResourcePlanDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getCreateWMTriggerDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|createWMTrigger
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getCreateWMTriggerDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getAlterWMTriggerDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|alterWMTrigger
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getAlterWMTriggerDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getDropWMTriggerDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|dropWMTrigger
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getDropWMTriggerDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getWmPoolDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|createOrAlterWMPool
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getWmPoolDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getDropWMPoolDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|dropWMPool
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getDropWMPoolDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getWmMappingDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|createOrAlterWMMapping
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getWmMappingDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getDropWMMappingDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|dropWMMapping
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getDropWMMappingDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getTriggerToPoolMappingDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|createOrDropTriggerToPoolMapping
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getTriggerToPoolMappingDesc
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getReplSetFirstIncLoadFlagDesc
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|remFirstIncPendFlag
argument_list|(
name|db
argument_list|,
name|work
operator|.
name|getReplSetFirstIncLoadFlagDesc
argument_list|()
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|failed
argument_list|(
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
assert|assert
literal|false
assert|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|createResourcePlan
parameter_list|(
name|Hive
name|db
parameter_list|,
name|CreateResourcePlanDesc
name|createResourcePlanDesc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|createResourcePlan
argument_list|(
name|createResourcePlanDesc
operator|.
name|getResourcePlan
argument_list|()
argument_list|,
name|createResourcePlanDesc
operator|.
name|getCopyFromName
argument_list|()
argument_list|,
name|createResourcePlanDesc
operator|.
name|getIfNotExists
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|showResourcePlans
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowResourcePlanDesc
name|showResourcePlanDesc
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Note: Enhance showResourcePlan to display all the pools, triggers and mappings.
name|DataOutputStream
name|out
init|=
name|getOutputStream
argument_list|(
name|showResourcePlanDesc
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|String
name|rpName
init|=
name|showResourcePlanDesc
operator|.
name|getResourcePlanName
argument_list|()
decl_stmt|;
if|if
condition|(
name|rpName
operator|!=
literal|null
condition|)
block|{
name|formatter
operator|.
name|showFullResourcePlan
argument_list|(
name|out
argument_list|,
name|db
operator|.
name|getResourcePlan
argument_list|(
name|rpName
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|formatter
operator|.
name|showResourcePlans
argument_list|(
name|out
argument_list|,
name|db
operator|.
name|getAllResourcePlans
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
comment|// Note: the resource plan operations are going to be annotated with namespace based on the config
comment|//       inside Hive.java. We don't want HS2 to be aware of namespaces beyond that, or to even see
comment|//       that there exist other namespaces, because one HS2 always operates inside just one and we
comment|//       don't want this complexity to bleed everywhere. Therefore, this code doesn't care about
comment|//       namespaces - Hive.java will transparently scope everything. That's the idea anyway.
specifier|private
name|int
name|alterResourcePlan
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterResourcePlanDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|desc
operator|.
name|shouldValidate
argument_list|()
condition|)
block|{
name|WMValidateResourcePlanResponse
name|result
init|=
name|db
operator|.
name|validateResourcePlan
argument_list|(
name|desc
operator|.
name|getResourcePlanName
argument_list|()
argument_list|)
decl_stmt|;
try|try
init|(
name|DataOutputStream
name|out
init|=
name|getOutputStream
argument_list|(
name|desc
operator|.
name|getResFile
argument_list|()
argument_list|)
init|)
block|{
name|formatter
operator|.
name|showErrors
argument_list|(
name|out
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
empty_stmt|;
return|return
literal|0
return|;
block|}
name|WMNullableResourcePlan
name|resourcePlan
init|=
name|desc
operator|.
name|getResourcePlan
argument_list|()
decl_stmt|;
specifier|final
name|WorkloadManager
name|wm
init|=
name|WorkloadManager
operator|.
name|getInstance
argument_list|()
decl_stmt|;
specifier|final
name|TezSessionPoolManager
name|pm
init|=
name|TezSessionPoolManager
operator|.
name|getInstance
argument_list|()
decl_stmt|;
name|boolean
name|isActivate
init|=
literal|false
decl_stmt|,
name|isInTest
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_IN_TEST
argument_list|)
decl_stmt|;
if|if
condition|(
name|resourcePlan
operator|.
name|getStatus
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|isActivate
operator|=
name|resourcePlan
operator|.
name|getStatus
argument_list|()
operator|==
name|WMResourcePlanStatus
operator|.
name|ACTIVE
expr_stmt|;
block|}
name|WMFullResourcePlan
name|appliedRp
init|=
name|db
operator|.
name|alterResourcePlan
argument_list|(
name|desc
operator|.
name|getResourcePlanName
argument_list|()
argument_list|,
name|resourcePlan
argument_list|,
name|desc
operator|.
name|isEnableActivate
argument_list|()
argument_list|,
name|desc
operator|.
name|isForceDeactivate
argument_list|()
argument_list|,
name|desc
operator|.
name|isReplace
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|mustHaveAppliedChange
init|=
name|isActivate
operator|||
name|desc
operator|.
name|isForceDeactivate
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|mustHaveAppliedChange
operator|&&
operator|!
name|desc
operator|.
name|isReplace
argument_list|()
condition|)
block|{
return|return
literal|0
return|;
comment|// The modification cannot affect an active plan.
block|}
if|if
condition|(
name|appliedRp
operator|==
literal|null
operator|&&
operator|!
name|mustHaveAppliedChange
condition|)
block|{
return|return
literal|0
return|;
comment|// Replacing an inactive plan.
block|}
if|if
condition|(
name|wm
operator|==
literal|null
operator|&&
name|isInTest
condition|)
block|{
return|return
literal|0
return|;
comment|// Skip for tests if WM is not present.
block|}
if|if
condition|(
operator|(
name|appliedRp
operator|==
literal|null
operator|)
operator|!=
name|desc
operator|.
name|isForceDeactivate
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Cannot get a resource plan to apply; or non-null plan on disable"
argument_list|)
throw|;
comment|// TODO: shut down HS2?
block|}
assert|assert
name|appliedRp
operator|==
literal|null
operator|||
name|appliedRp
operator|.
name|getPlan
argument_list|()
operator|.
name|getStatus
argument_list|()
operator|==
name|WMResourcePlanStatus
operator|.
name|ACTIVE
assert|;
name|handleWorkloadManagementServiceChange
argument_list|(
name|wm
argument_list|,
name|pm
argument_list|,
name|isActivate
argument_list|,
name|appliedRp
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|handleWorkloadManagementServiceChange
parameter_list|(
name|WorkloadManager
name|wm
parameter_list|,
name|TezSessionPoolManager
name|pm
parameter_list|,
name|boolean
name|isActivate
parameter_list|,
name|WMFullResourcePlan
name|appliedRp
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
name|name
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isActivate
condition|)
block|{
name|name
operator|=
name|appliedRp
operator|.
name|getPlan
argument_list|()
operator|.
name|getName
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Activating a new resource plan "
operator|+
name|name
operator|+
literal|": "
operator|+
name|appliedRp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Disabling workload management"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|wm
operator|!=
literal|null
condition|)
block|{
comment|// Note: as per our current constraints, the behavior of two parallel activates is
comment|//       undefined; although only one will succeed and the other will receive exception.
comment|//       We need proper (semi-)transactional modifications to support this without hacks.
name|ListenableFuture
argument_list|<
name|Boolean
argument_list|>
name|future
init|=
name|wm
operator|.
name|updateResourcePlanAsync
argument_list|(
name|appliedRp
argument_list|)
decl_stmt|;
name|boolean
name|isOk
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// Note: we may add an async option in future. For now, let the task fail for the user.
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
name|isOk
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|isActivate
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully activated resource plan "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully disabled workload management"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|isOk
condition|)
block|{
if|if
condition|(
name|isActivate
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to activate resource plan "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to disable workload management"
argument_list|)
expr_stmt|;
block|}
comment|// TODO: shut down HS2?
block|}
block|}
block|}
if|if
condition|(
name|pm
operator|!=
literal|null
condition|)
block|{
name|Collection
argument_list|<
name|String
argument_list|>
name|appliedTriggers
init|=
name|pm
operator|.
name|updateTriggers
argument_list|(
name|appliedRp
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated tez session pool manager with active resource plan: {} appliedTriggers: {}"
argument_list|,
name|name
argument_list|,
name|appliedTriggers
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|dropResourcePlan
parameter_list|(
name|Hive
name|db
parameter_list|,
name|DropResourcePlanDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|dropResourcePlan
argument_list|(
name|desc
operator|.
name|getRpName
argument_list|()
argument_list|,
name|desc
operator|.
name|getIfExists
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|createWMTrigger
parameter_list|(
name|Hive
name|db
parameter_list|,
name|CreateWMTriggerDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|validateTrigger
argument_list|(
name|desc
operator|.
name|getTrigger
argument_list|()
argument_list|)
expr_stmt|;
name|db
operator|.
name|createWMTrigger
argument_list|(
name|desc
operator|.
name|getTrigger
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|void
name|validateTrigger
parameter_list|(
specifier|final
name|WMTrigger
name|trigger
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|ExecutionTrigger
operator|.
name|fromWMTrigger
argument_list|(
name|trigger
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|int
name|alterWMTrigger
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterWMTriggerDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|validateTrigger
argument_list|(
name|desc
operator|.
name|getTrigger
argument_list|()
argument_list|)
expr_stmt|;
name|db
operator|.
name|alterWMTrigger
argument_list|(
name|desc
operator|.
name|getTrigger
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|dropWMTrigger
parameter_list|(
name|Hive
name|db
parameter_list|,
name|DropWMTriggerDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|dropWMTrigger
argument_list|(
name|desc
operator|.
name|getRpName
argument_list|()
argument_list|,
name|desc
operator|.
name|getTriggerName
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|createOrAlterWMPool
parameter_list|(
name|Hive
name|db
parameter_list|,
name|CreateOrAlterWMPoolDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|desc
operator|.
name|isUpdate
argument_list|()
condition|)
block|{
name|db
operator|.
name|alterWMPool
argument_list|(
name|desc
operator|.
name|getAlterPool
argument_list|()
argument_list|,
name|desc
operator|.
name|getPoolPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|db
operator|.
name|createWMPool
argument_list|(
name|desc
operator|.
name|getCreatePool
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|dropWMPool
parameter_list|(
name|Hive
name|db
parameter_list|,
name|DropWMPoolDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|dropWMPool
argument_list|(
name|desc
operator|.
name|getResourcePlanName
argument_list|()
argument_list|,
name|desc
operator|.
name|getPoolPath
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|createOrAlterWMMapping
parameter_list|(
name|Hive
name|db
parameter_list|,
name|CreateOrAlterWMMappingDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|createOrUpdateWMMapping
argument_list|(
name|desc
operator|.
name|getMapping
argument_list|()
argument_list|,
name|desc
operator|.
name|isUpdate
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|dropWMMapping
parameter_list|(
name|Hive
name|db
parameter_list|,
name|DropWMMappingDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|dropWMMapping
argument_list|(
name|desc
operator|.
name|getMapping
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|createOrDropTriggerToPoolMapping
parameter_list|(
name|Hive
name|db
parameter_list|,
name|CreateOrDropTriggerToPoolMappingDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|desc
operator|.
name|isUnmanagedPool
argument_list|()
condition|)
block|{
name|db
operator|.
name|createOrDropTriggerToPoolMapping
argument_list|(
name|desc
operator|.
name|getResourcePlanName
argument_list|()
argument_list|,
name|desc
operator|.
name|getTriggerName
argument_list|()
argument_list|,
name|desc
operator|.
name|getPoolPath
argument_list|()
argument_list|,
name|desc
operator|.
name|shouldDrop
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
assert|assert
name|desc
operator|.
name|getPoolPath
argument_list|()
operator|==
literal|null
assert|;
name|WMTrigger
name|trigger
init|=
operator|new
name|WMTrigger
argument_list|(
name|desc
operator|.
name|getResourcePlanName
argument_list|()
argument_list|,
name|desc
operator|.
name|getTriggerName
argument_list|()
argument_list|)
decl_stmt|;
comment|// If we are dropping from unmanaged, unset the flag; and vice versa
name|trigger
operator|.
name|setIsInUnmanaged
argument_list|(
operator|!
name|desc
operator|.
name|shouldDrop
argument_list|()
argument_list|)
expr_stmt|;
name|db
operator|.
name|alterWMTrigger
argument_list|(
name|trigger
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|insertCommitWork
parameter_list|(
name|Hive
name|db
parameter_list|,
name|InsertCommitHookDesc
name|insertCommitHookDesc
parameter_list|)
throws|throws
name|MetaException
block|{
name|boolean
name|failed
init|=
literal|true
decl_stmt|;
name|HiveMetaHook
name|hook
init|=
name|insertCommitHookDesc
operator|.
name|getTable
argument_list|()
operator|.
name|getStorageHandler
argument_list|()
operator|.
name|getMetaHook
argument_list|()
decl_stmt|;
if|if
condition|(
name|hook
operator|==
literal|null
operator|||
operator|!
operator|(
name|hook
operator|instanceof
name|DefaultHiveMetaHook
operator|)
condition|)
block|{
return|return
literal|0
return|;
block|}
name|DefaultHiveMetaHook
name|hiveMetaHook
init|=
operator|(
name|DefaultHiveMetaHook
operator|)
name|hook
decl_stmt|;
try|try
block|{
name|hiveMetaHook
operator|.
name|commitInsertTable
argument_list|(
name|insertCommitHookDesc
operator|.
name|getTable
argument_list|()
operator|.
name|getTTable
argument_list|()
argument_list|,
name|insertCommitHookDesc
operator|.
name|isOverwrite
argument_list|()
argument_list|)
expr_stmt|;
name|failed
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|failed
condition|)
block|{
name|hiveMetaHook
operator|.
name|rollbackInsertTable
argument_list|(
name|insertCommitHookDesc
operator|.
name|getTable
argument_list|()
operator|.
name|getTTable
argument_list|()
argument_list|,
name|insertCommitHookDesc
operator|.
name|isOverwrite
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|cacheMetadata
parameter_list|(
name|Hive
name|db
parameter_list|,
name|CacheMetadataDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|cacheFileMetadata
argument_list|(
name|desc
operator|.
name|getDbName
argument_list|()
argument_list|,
name|desc
operator|.
name|getTableName
argument_list|()
argument_list|,
name|desc
operator|.
name|getPartName
argument_list|()
argument_list|,
name|desc
operator|.
name|isAllParts
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|void
name|failed
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
while|while
condition|(
name|e
operator|.
name|getCause
argument_list|()
operator|!=
literal|null
operator|&&
name|e
operator|.
name|getClass
argument_list|()
operator|==
name|RuntimeException
operator|.
name|class
condition|)
block|{
name|e
operator|=
name|e
operator|.
name|getCause
argument_list|()
expr_stmt|;
block|}
name|setException
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
specifier|private
name|int
name|showConf
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowConfDesc
name|showConf
parameter_list|)
throws|throws
name|Exception
block|{
name|ConfVars
name|conf
init|=
name|HiveConf
operator|.
name|getConfVars
argument_list|(
name|showConf
operator|.
name|getConfName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"invalid configuration name "
operator|+
name|showConf
operator|.
name|getConfName
argument_list|()
argument_list|)
throw|;
block|}
name|String
name|description
init|=
name|conf
operator|.
name|getDescription
argument_list|()
decl_stmt|;
name|String
name|defaultValue
init|=
name|conf
operator|.
name|getDefaultValue
argument_list|()
decl_stmt|;
name|DataOutputStream
name|output
init|=
name|getOutputStream
argument_list|(
name|showConf
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
name|defaultValue
operator|!=
literal|null
condition|)
block|{
name|output
operator|.
name|write
argument_list|(
name|defaultValue
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|output
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|output
operator|.
name|write
argument_list|(
name|conf
operator|.
name|typeString
argument_list|()
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
name|output
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
if|if
condition|(
name|description
operator|!=
literal|null
condition|)
block|{
name|output
operator|.
name|write
argument_list|(
name|description
operator|.
name|replaceAll
argument_list|(
literal|" *\n *"
argument_list|,
literal|" "
argument_list|)
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|output
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|DataOutputStream
name|getOutputStream
parameter_list|(
name|String
name|resFile
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getOutputStream
argument_list|(
operator|new
name|Path
argument_list|(
name|resFile
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|DataOutputStream
name|getOutputStream
parameter_list|(
name|Path
name|outputFile
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|FileSystem
name|fs
init|=
name|outputFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|create
argument_list|(
name|outputFile
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * First, make sure the source table/partition is not    * archived/indexes/non-rcfile. If either of these is true, throw an    * exception.    *    * The way how it does the merge is to create a BlockMergeTask from the    * mergeFilesDesc.    *    * @param db    * @param mergeFilesDesc    * @return    * @throws HiveException    */
specifier|private
name|int
name|mergeFiles
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTablePartMergeFilesDesc
name|mergeFilesDesc
parameter_list|,
name|DriverContext
name|driverContext
parameter_list|)
throws|throws
name|HiveException
block|{
name|ListBucketingCtx
name|lbCtx
init|=
name|mergeFilesDesc
operator|.
name|getLbCtx
argument_list|()
decl_stmt|;
name|boolean
name|lbatc
init|=
name|lbCtx
operator|==
literal|null
condition|?
literal|false
else|:
name|lbCtx
operator|.
name|isSkewedStoredAsDir
argument_list|()
decl_stmt|;
name|int
name|lbd
init|=
name|lbCtx
operator|==
literal|null
condition|?
literal|0
else|:
name|lbCtx
operator|.
name|calculateListBucketingLevel
argument_list|()
decl_stmt|;
comment|// merge work only needs input and output.
name|MergeFileWork
name|mergeWork
init|=
operator|new
name|MergeFileWork
argument_list|(
name|mergeFilesDesc
operator|.
name|getInputDir
argument_list|()
argument_list|,
name|mergeFilesDesc
operator|.
name|getOutputDir
argument_list|()
argument_list|,
name|mergeFilesDesc
operator|.
name|getInputFormatClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|mergeFilesDesc
operator|.
name|getTableDesc
argument_list|()
argument_list|)
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|Path
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|pathToAliases
init|=
operator|new
name|LinkedHashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|ArrayList
argument_list|<
name|String
argument_list|>
name|inputDirstr
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|inputDirstr
operator|.
name|add
argument_list|(
name|mergeFilesDesc
operator|.
name|getInputDir
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|pathToAliases
operator|.
name|put
argument_list|(
name|mergeFilesDesc
operator|.
name|getInputDir
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|,
name|inputDirstr
argument_list|)
expr_stmt|;
name|mergeWork
operator|.
name|setPathToAliases
argument_list|(
name|pathToAliases
argument_list|)
expr_stmt|;
name|mergeWork
operator|.
name|setListBucketingCtx
argument_list|(
name|mergeFilesDesc
operator|.
name|getLbCtx
argument_list|()
argument_list|)
expr_stmt|;
name|mergeWork
operator|.
name|resolveConcatenateMerge
argument_list|(
name|db
operator|.
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|mergeWork
operator|.
name|setMapperCannotSpanPartns
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|mergeWork
operator|.
name|setSourceTableInputFormat
argument_list|(
name|mergeFilesDesc
operator|.
name|getInputFormatClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
specifier|final
name|FileMergeDesc
name|fmd
decl_stmt|;
if|if
condition|(
name|mergeFilesDesc
operator|.
name|getInputFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|RCFileInputFormat
operator|.
name|class
argument_list|)
condition|)
block|{
name|fmd
operator|=
operator|new
name|RCFileMergeDesc
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// safe to assume else is ORC as semantic analyzer will check for RC/ORC
name|fmd
operator|=
operator|new
name|OrcFileMergeDesc
argument_list|()
expr_stmt|;
block|}
name|fmd
operator|.
name|setDpCtx
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setHasDynamicPartitions
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setListBucketingAlterTableConcatenate
argument_list|(
name|lbatc
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setListBucketingDepth
argument_list|(
name|lbd
argument_list|)
expr_stmt|;
name|fmd
operator|.
name|setOutputPath
argument_list|(
name|mergeFilesDesc
operator|.
name|getOutputDir
argument_list|()
argument_list|)
expr_stmt|;
name|CompilationOpContext
name|opContext
init|=
name|driverContext
operator|.
name|getCtx
argument_list|()
operator|.
name|getOpContext
argument_list|()
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|mergeOp
init|=
name|OperatorFactory
operator|.
name|get
argument_list|(
name|opContext
argument_list|,
name|fmd
argument_list|)
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|aliasToWork
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|aliasToWork
operator|.
name|put
argument_list|(
name|mergeFilesDesc
operator|.
name|getInputDir
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|mergeOp
argument_list|)
expr_stmt|;
name|mergeWork
operator|.
name|setAliasToWork
argument_list|(
name|aliasToWork
argument_list|)
expr_stmt|;
name|DriverContext
name|driverCxt
init|=
operator|new
name|DriverContext
argument_list|()
decl_stmt|;
name|Task
argument_list|<
name|?
argument_list|>
name|task
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|)
operator|.
name|equals
argument_list|(
literal|"tez"
argument_list|)
condition|)
block|{
name|TezWork
name|tezWork
init|=
operator|new
name|TezWork
argument_list|(
name|queryState
operator|.
name|getQueryId
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|mergeWork
operator|.
name|setName
argument_list|(
literal|"File Merge"
argument_list|)
expr_stmt|;
name|tezWork
operator|.
name|add
argument_list|(
name|mergeWork
argument_list|)
expr_stmt|;
name|task
operator|=
operator|new
name|TezTask
argument_list|()
expr_stmt|;
operator|(
operator|(
name|TezTask
operator|)
name|task
operator|)
operator|.
name|setWork
argument_list|(
name|tezWork
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|task
operator|=
operator|new
name|MergeFileTask
argument_list|()
expr_stmt|;
operator|(
operator|(
name|MergeFileTask
operator|)
name|task
operator|)
operator|.
name|setWork
argument_list|(
name|mergeWork
argument_list|)
expr_stmt|;
block|}
comment|// initialize the task and execute
name|task
operator|.
name|initialize
argument_list|(
name|queryState
argument_list|,
name|getQueryPlan
argument_list|()
argument_list|,
name|driverCxt
argument_list|,
name|opContext
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|subtask
init|=
name|task
decl_stmt|;
name|int
name|ret
init|=
name|task
operator|.
name|execute
argument_list|(
name|driverCxt
argument_list|)
decl_stmt|;
if|if
condition|(
name|subtask
operator|.
name|getException
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|setException
argument_list|(
name|subtask
operator|.
name|getException
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
comment|/**    * Add a partitions to a table.    *    * @param db    *          Database to add the partition to.    * @param addPartitionDesc    *          Add these partitions.    * @return Returns 0 when execution succeeds and above 0 if it fails.    * @throws HiveException    */
specifier|private
name|int
name|addPartitions
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AddPartitionDesc
name|addPartitionDesc
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
name|db
operator|.
name|createPartitions
argument_list|(
name|addPartitionDesc
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|part
range|:
name|parts
control|)
block|{
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|part
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|INSERT
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * Rename a partition in a table    *    * @param db    *          Database to rename the partition.    * @param renamePartitionDesc    *          rename old Partition to new one.    * @return Returns 0 when execution succeeds and above 0 if it fails.    * @throws HiveException    */
specifier|private
name|int
name|renamePartition
parameter_list|(
name|Hive
name|db
parameter_list|,
name|RenamePartitionDesc
name|renamePartitionDesc
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
name|tableName
init|=
name|renamePartitionDesc
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|oldPartSpec
init|=
name|renamePartitionDesc
operator|.
name|getOldPartSpec
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|allowOperationInReplicationScope
argument_list|(
name|db
argument_list|,
name|tableName
argument_list|,
name|oldPartSpec
argument_list|,
name|renamePartitionDesc
operator|.
name|getReplicationSpec
argument_list|()
argument_list|)
condition|)
block|{
comment|// no rename, the table is missing either due to drop/rename which follows the current rename.
comment|// or the existing table is newer than our update.
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DDLTask: Rename Partition is skipped as table {} / partition {} is newer than update"
argument_list|,
name|tableName
argument_list|,
name|FileUtils
operator|.
name|makePartName
argument_list|(
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|oldPartSpec
operator|.
name|keySet
argument_list|()
argument_list|)
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|oldPartSpec
operator|.
name|values
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
name|String
name|names
index|[]
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|Utils
operator|.
name|isBootstrapDumpInProgress
argument_list|(
name|db
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"DDLTask: Rename Partition not allowed as bootstrap dump in progress"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Rename Partition: Not allowed as bootstrap dump in progress"
argument_list|)
throw|;
block|}
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|Partition
name|oldPart
init|=
name|db
operator|.
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|oldPartSpec
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldPart
operator|==
literal|null
condition|)
block|{
name|String
name|partName
init|=
name|FileUtils
operator|.
name|makePartName
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|oldPartSpec
operator|.
name|keySet
argument_list|()
argument_list|)
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|oldPartSpec
operator|.
name|values
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Rename partition: source partition ["
operator|+
name|partName
operator|+
literal|"] does not exist."
argument_list|)
throw|;
block|}
name|Partition
name|part
init|=
name|db
operator|.
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|oldPartSpec
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|part
operator|.
name|setValues
argument_list|(
name|renamePartitionDesc
operator|.
name|getNewPartSpec
argument_list|()
argument_list|)
expr_stmt|;
name|long
name|writeId
init|=
name|renamePartitionDesc
operator|.
name|getWriteId
argument_list|()
decl_stmt|;
if|if
condition|(
name|renamePartitionDesc
operator|.
name|getReplicationSpec
argument_list|()
operator|!=
literal|null
operator|&&
name|renamePartitionDesc
operator|.
name|getReplicationSpec
argument_list|()
operator|.
name|isMigratingToTxnTable
argument_list|()
condition|)
block|{
name|Long
name|tmpWriteId
init|=
name|ReplUtils
operator|.
name|getMigrationCurrentTblWriteId
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmpWriteId
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"DDLTask : Write id is not set in the config by open txn task for migration"
argument_list|)
throw|;
block|}
name|writeId
operator|=
name|tmpWriteId
expr_stmt|;
block|}
name|db
operator|.
name|renamePartition
argument_list|(
name|tbl
argument_list|,
name|oldPartSpec
argument_list|,
name|part
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
name|Partition
name|newPart
init|=
name|db
operator|.
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|renamePartitionDesc
operator|.
name|getNewPartSpec
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|oldPart
argument_list|)
argument_list|)
expr_stmt|;
comment|// We've already obtained a lock on the table, don't lock the partition too
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|newPart
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
comment|/**    * Alter partition column type in a table    *    * @param db    *          Database to rename the partition.    * @param alterPartitionDesc    *          change partition column type.    * @return Returns 0 when execution succeeds and above 0 if it fails.    * @throws HiveException    */
specifier|private
name|int
name|alterTableAlterPart
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableAlterPartDesc
name|alterPartitionDesc
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|alterPartitionDesc
operator|.
name|getTableName
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// This is checked by DDLSemanticAnalyzer
assert|assert
operator|(
name|tbl
operator|.
name|isPartitioned
argument_list|()
operator|)
assert|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newPartitionKeys
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
comment|//Check if the existing partition values can be type casted to the new column type
comment|// with a non null value before trying to alter the partition column type.
try|try
block|{
name|Set
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|db
operator|.
name|getAllPartitionsOf
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
name|int
name|colIndex
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
name|colIndex
operator|++
expr_stmt|;
if|if
condition|(
name|col
operator|.
name|getName
argument_list|()
operator|.
name|compareTo
argument_list|(
name|alterPartitionDesc
operator|.
name|getPartKeySpec
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
operator|==
literal|0
condition|)
block|{
break|break;
block|}
block|}
if|if
condition|(
name|colIndex
operator|==
operator|-
literal|1
operator|||
name|colIndex
operator|==
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Cannot find partition column "
operator|+
name|alterPartitionDesc
operator|.
name|getPartKeySpec
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
name|TypeInfo
name|expectedType
init|=
name|TypeInfoUtils
operator|.
name|getTypeInfoFromTypeString
argument_list|(
name|alterPartitionDesc
operator|.
name|getPartKeySpec
argument_list|()
operator|.
name|getType
argument_list|()
argument_list|)
decl_stmt|;
name|ObjectInspector
name|outputOI
init|=
name|TypeInfoUtils
operator|.
name|getStandardWritableObjectInspectorFromTypeInfo
argument_list|(
name|expectedType
argument_list|)
decl_stmt|;
name|Converter
name|converter
init|=
name|ObjectInspectorConverters
operator|.
name|getConverter
argument_list|(
name|PrimitiveObjectInspectorFactory
operator|.
name|javaStringObjectInspector
argument_list|,
name|outputOI
argument_list|)
decl_stmt|;
comment|// For all the existing partitions, check if the value can be type casted to a non-null object
for|for
control|(
name|Partition
name|part
range|:
name|partitions
control|)
block|{
if|if
condition|(
name|part
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DEFAULTPARTITIONNAME
argument_list|)
argument_list|)
condition|)
block|{
continue|continue;
block|}
try|try
block|{
name|String
name|value
init|=
name|part
operator|.
name|getValues
argument_list|()
operator|.
name|get
argument_list|(
name|colIndex
argument_list|)
decl_stmt|;
name|Object
name|convertedValue
init|=
name|converter
operator|.
name|convert
argument_list|(
name|value
argument_list|)
decl_stmt|;
if|if
condition|(
name|convertedValue
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|" Converting from "
operator|+
name|TypeInfoFactory
operator|.
name|stringTypeInfo
operator|+
literal|" to "
operator|+
name|expectedType
operator|+
literal|" for value : "
operator|+
name|value
operator|+
literal|" resulted in NULL object"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Exception while converting "
operator|+
name|TypeInfoFactory
operator|.
name|stringTypeInfo
operator|+
literal|" to "
operator|+
name|expectedType
operator|+
literal|" for value : "
operator|+
name|part
operator|.
name|getValues
argument_list|()
operator|.
name|get
argument_list|(
name|colIndex
argument_list|)
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Exception while checking type conversion of existing partition values to "
operator|+
name|alterPartitionDesc
operator|.
name|getPartKeySpec
argument_list|()
operator|+
literal|" : "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
for|for
control|(
name|FieldSchema
name|col
range|:
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
if|if
condition|(
name|col
operator|.
name|getName
argument_list|()
operator|.
name|compareTo
argument_list|(
name|alterPartitionDesc
operator|.
name|getPartKeySpec
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
operator|==
literal|0
condition|)
block|{
name|newPartitionKeys
operator|.
name|add
argument_list|(
name|alterPartitionDesc
operator|.
name|getPartKeySpec
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|newPartitionKeys
operator|.
name|add
argument_list|(
name|col
argument_list|)
expr_stmt|;
block|}
block|}
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|setPartitionKeys
argument_list|(
name|newPartitionKeys
argument_list|)
expr_stmt|;
name|db
operator|.
name|alterTable
argument_list|(
name|tbl
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|tbl
argument_list|)
argument_list|)
expr_stmt|;
comment|// We've already locked the table as the input, don't relock it as the output.
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|tbl
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
comment|/**    * Rewrite the partition's metadata and force the pre/post execute hooks to    * be fired.    *    * @param db    * @param touchDesc    * @return    * @throws HiveException    */
specifier|private
name|int
name|touch
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableSimpleDesc
name|touchDesc
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// TODO: catalog
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|touchDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|EnvironmentContext
name|environmentContext
init|=
operator|new
name|EnvironmentContext
argument_list|()
decl_stmt|;
name|environmentContext
operator|.
name|putToProperties
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
if|if
condition|(
name|touchDesc
operator|.
name|getPartSpec
argument_list|()
operator|==
literal|null
condition|)
block|{
name|db
operator|.
name|alterTable
argument_list|(
name|tbl
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|tbl
argument_list|)
argument_list|)
expr_stmt|;
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|tbl
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Partition
name|part
init|=
name|db
operator|.
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|touchDesc
operator|.
name|getPartSpec
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|part
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Specified partition does not exist"
argument_list|)
throw|;
block|}
try|try
block|{
name|db
operator|.
name|alterPartition
argument_list|(
name|tbl
operator|.
name|getCatalogName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|part
argument_list|,
name|environmentContext
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|part
argument_list|)
argument_list|)
expr_stmt|;
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|part
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * Sets archiving flag locally; it has to be pushed into metastore    * @param p partition to set flag    * @param state desired state of IS_ARCHIVED flag    * @param level desired level for state == true, anything for false    */
specifier|private
name|void
name|setIsArchived
parameter_list|(
name|Partition
name|p
parameter_list|,
name|boolean
name|state
parameter_list|,
name|int
name|level
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|p
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|state
condition|)
block|{
name|params
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|params
operator|.
name|put
argument_list|(
name|ArchiveUtils
operator|.
name|ARCHIVING_LEVEL
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|level
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|params
operator|.
name|remove
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|)
expr_stmt|;
name|params
operator|.
name|remove
argument_list|(
name|ArchiveUtils
operator|.
name|ARCHIVING_LEVEL
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Returns original partition of archived partition, null for unarchived one    */
specifier|private
name|String
name|getOriginalLocation
parameter_list|(
name|Partition
name|p
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|p
operator|.
name|getParameters
argument_list|()
decl_stmt|;
return|return
name|params
operator|.
name|get
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
return|;
block|}
comment|/**    * Sets original location of partition which is to be archived    */
specifier|private
name|void
name|setOriginalLocation
parameter_list|(
name|Partition
name|p
parameter_list|,
name|String
name|loc
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|p
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|loc
operator|==
literal|null
condition|)
block|{
name|params
operator|.
name|remove
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|params
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|,
name|loc
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Sets the appropriate attributes in the supplied Partition object to mark    * it as archived. Note that the metastore is not touched - a separate    * call to alter_partition is needed.    *    * @param p - the partition object to modify    * @param harPath - new location of partition (har schema URI)    */
specifier|private
name|void
name|setArchived
parameter_list|(
name|Partition
name|p
parameter_list|,
name|Path
name|harPath
parameter_list|,
name|int
name|level
parameter_list|)
block|{
assert|assert
operator|(
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
operator|==
literal|false
operator|)
assert|;
name|setIsArchived
argument_list|(
name|p
argument_list|,
literal|true
argument_list|,
name|level
argument_list|)
expr_stmt|;
name|setOriginalLocation
argument_list|(
name|p
argument_list|,
name|p
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
name|p
operator|.
name|setLocation
argument_list|(
name|harPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Sets the appropriate attributes in the supplied Partition object to mark    * it as not archived. Note that the metastore is not touched - a separate    * call to alter_partition is needed.    *    * @param p - the partition to modify    */
specifier|private
name|void
name|setUnArchived
parameter_list|(
name|Partition
name|p
parameter_list|)
block|{
assert|assert
operator|(
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
operator|==
literal|true
operator|)
assert|;
name|String
name|parentDir
init|=
name|getOriginalLocation
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|setIsArchived
argument_list|(
name|p
argument_list|,
literal|false
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|setOriginalLocation
argument_list|(
name|p
argument_list|,
literal|null
argument_list|)
expr_stmt|;
assert|assert
operator|(
name|parentDir
operator|!=
literal|null
operator|)
assert|;
name|p
operator|.
name|setLocation
argument_list|(
name|parentDir
argument_list|)
expr_stmt|;
block|}
specifier|private
name|boolean
name|pathExists
parameter_list|(
name|Path
name|p
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|FileSystem
name|fs
init|=
name|p
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|moveDir
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|from
parameter_list|,
name|Path
name|to
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|from
argument_list|,
name|to
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Moving "
operator|+
name|from
operator|+
literal|" to "
operator|+
name|to
operator|+
literal|" failed!"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|deleteDir
parameter_list|(
name|Path
name|dir
parameter_list|,
name|Database
name|db
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|Warehouse
name|wh
init|=
operator|new
name|Warehouse
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|wh
operator|.
name|deleteDir
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|,
name|db
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Checks in partition is in custom (not-standard) location.    * @param tbl - table in which partition is    * @param p - partition    * @return true if partition location is custom, false if it is standard    */
name|boolean
name|partitionInCustomLocation
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Partition
name|p
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
name|subdir
init|=
literal|null
decl_stmt|;
try|try
block|{
name|subdir
operator|=
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|tbl
operator|.
name|getPartCols
argument_list|()
argument_list|,
name|p
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to get partition's directory"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Path
name|tableDir
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
decl_stmt|;
if|if
condition|(
name|tableDir
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Table has no location set"
argument_list|)
throw|;
block|}
name|String
name|standardLocation
init|=
operator|(
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|subdir
argument_list|)
operator|)
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
condition|)
block|{
return|return
operator|!
name|getOriginalLocation
argument_list|(
name|p
argument_list|)
operator|.
name|equals
argument_list|(
name|standardLocation
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|!
name|p
operator|.
name|getLocation
argument_list|()
operator|.
name|equals
argument_list|(
name|standardLocation
argument_list|)
return|;
block|}
block|}
specifier|private
name|int
name|archive
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableSimpleDesc
name|simpleDesc
parameter_list|,
name|DriverContext
name|driverContext
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|simpleDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|tbl
operator|.
name|getTableType
argument_list|()
operator|!=
name|TableType
operator|.
name|MANAGED_TABLE
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"ARCHIVE can only be performed on managed tables"
argument_list|)
throw|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|simpleDesc
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
name|PartSpecInfo
name|partSpecInfo
init|=
name|PartSpecInfo
operator|.
name|create
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|db
operator|.
name|getPartitions
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
name|Path
name|originalDir
init|=
literal|null
decl_stmt|;
comment|// when we have partial partitions specification we must assume partitions
comment|// lie in standard place - if they were in custom locations putting
comment|// them into one archive would involve mass amount of copying
comment|// in full partition specification case we allow custom locations
comment|// to keep backward compatibility
if|if
condition|(
name|partitions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"No partition matches the specification"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|partSpecInfo
operator|.
name|values
operator|.
name|size
argument_list|()
operator|!=
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|size
argument_list|()
condition|)
block|{
comment|// for partial specifications we need partitions to follow the scheme
for|for
control|(
name|Partition
name|p
range|:
name|partitions
control|)
block|{
if|if
condition|(
name|partitionInCustomLocation
argument_list|(
name|tbl
argument_list|,
name|p
argument_list|)
condition|)
block|{
name|String
name|message
init|=
name|String
operator|.
name|format
argument_list|(
literal|"ARCHIVE cannot run for partition "
operator|+
literal|"groups with custom locations like %s"
argument_list|,
name|p
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|message
argument_list|)
throw|;
block|}
block|}
name|originalDir
operator|=
name|partSpecInfo
operator|.
name|createPath
argument_list|(
name|tbl
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Partition
name|p
init|=
name|partitions
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// partition can be archived if during recovery
if|if
condition|(
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|originalDir
operator|=
operator|new
name|Path
argument_list|(
name|getOriginalLocation
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|originalDir
operator|=
name|p
operator|.
name|getDataLocation
argument_list|()
expr_stmt|;
block|}
block|}
name|Path
name|intermediateArchivedDir
init|=
operator|new
name|Path
argument_list|(
name|originalDir
operator|.
name|getParent
argument_list|()
argument_list|,
name|originalDir
operator|.
name|getName
argument_list|()
operator|+
name|INTERMEDIATE_ARCHIVED_DIR_SUFFIX
argument_list|)
decl_stmt|;
name|Path
name|intermediateOriginalDir
init|=
operator|new
name|Path
argument_list|(
name|originalDir
operator|.
name|getParent
argument_list|()
argument_list|,
name|originalDir
operator|.
name|getName
argument_list|()
operator|+
name|INTERMEDIATE_ORIGINAL_DIR_SUFFIX
argument_list|)
decl_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"intermediate.archived is "
operator|+
name|intermediateArchivedDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"intermediate.original is "
operator|+
name|intermediateOriginalDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|archiveName
init|=
literal|"data.har"
decl_stmt|;
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
try|try
block|{
name|fs
operator|=
name|originalDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|URI
name|archiveUri
init|=
operator|(
operator|new
name|Path
argument_list|(
name|originalDir
argument_list|,
name|archiveName
argument_list|)
operator|)
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|URI
name|originalUri
init|=
name|ArchiveUtils
operator|.
name|addSlash
argument_list|(
name|originalDir
operator|.
name|toUri
argument_list|()
argument_list|)
decl_stmt|;
name|ArchiveUtils
operator|.
name|HarPathHelper
name|harHelper
init|=
operator|new
name|ArchiveUtils
operator|.
name|HarPathHelper
argument_list|(
name|conf
argument_list|,
name|archiveUri
argument_list|,
name|originalUri
argument_list|)
decl_stmt|;
comment|// we checked if partitions matching specification are marked as archived
comment|// in the metadata; if they are and their levels are the same as we would
comment|// set it later it means previous run failed and we have to do the recovery;
comment|// if they are different, we throw an error
for|for
control|(
name|Partition
name|p
range|:
name|partitions
control|)
block|{
if|if
condition|(
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
condition|)
block|{
if|if
condition|(
name|ArchiveUtils
operator|.
name|getArchivingLevel
argument_list|(
name|p
argument_list|)
operator|!=
name|partSpecInfo
operator|.
name|values
operator|.
name|size
argument_list|()
condition|)
block|{
name|String
name|name
init|=
name|ArchiveUtils
operator|.
name|getPartialName
argument_list|(
name|p
argument_list|,
name|ArchiveUtils
operator|.
name|getArchivingLevel
argument_list|(
name|p
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|m
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Conflict with existing archive %s"
argument_list|,
name|name
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|m
argument_list|)
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition(s) already archived"
argument_list|)
throw|;
block|}
block|}
block|}
name|boolean
name|recovery
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
operator|||
name|pathExists
argument_list|(
name|intermediateOriginalDir
argument_list|)
condition|)
block|{
name|recovery
operator|=
literal|true
expr_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"Starting recovery after failed ARCHIVE"
argument_list|)
expr_stmt|;
block|}
comment|// The following steps seem roundabout, but they are meant to aid in
comment|// recovery if a failure occurs and to keep a consistent state in the FS
comment|// Steps:
comment|// 1. Create the archive in a temporary folder
comment|// 2. Move the archive dir to an intermediate dir that is in at the same
comment|//    dir as the original partition dir. Call the new dir
comment|//    intermediate-archive.
comment|// 3. Rename the original partition dir to an intermediate dir. Call the
comment|//    renamed dir intermediate-original
comment|// 4. Rename intermediate-archive to the original partition dir
comment|// 5. Change the metadata
comment|// 6. Delete the original partition files in intermediate-original
comment|// The original partition files are deleted after the metadata change
comment|// because the presence of those files are used to indicate whether
comment|// the original partition directory contains archived or unarchived files.
comment|// Create an archived version of the partition in a directory ending in
comment|// ARCHIVE_INTERMEDIATE_DIR_SUFFIX that's the same level as the partition,
comment|// if it does not already exist. If it does exist, we assume the dir is good
comment|// to use as the move operation that created it is atomic.
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
operator|&&
operator|!
name|pathExists
argument_list|(
name|intermediateOriginalDir
argument_list|)
condition|)
block|{
comment|// First create the archive in a tmp dir so that if the job fails, the
comment|// bad files don't pollute the filesystem
name|Path
name|tmpPath
init|=
operator|new
name|Path
argument_list|(
name|driverContext
operator|.
name|getCtx
argument_list|()
operator|.
name|getExternalTmpPath
argument_list|(
name|originalDir
argument_list|)
argument_list|,
literal|"partlevel"
argument_list|)
decl_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"Creating "
operator|+
name|archiveName
operator|+
literal|" for "
operator|+
name|originalDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"in "
operator|+
name|tmpPath
argument_list|)
expr_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"Please wait... (this may take a while)"
argument_list|)
expr_stmt|;
comment|// Create the Hadoop archive
name|int
name|ret
init|=
literal|0
decl_stmt|;
try|try
block|{
name|int
name|maxJobNameLen
init|=
name|conf
operator|.
name|getIntVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEJOBNAMELENGTH
argument_list|)
decl_stmt|;
name|String
name|jobname
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Archiving %s@%s"
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partSpecInfo
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|jobname
operator|=
name|Utilities
operator|.
name|abbreviate
argument_list|(
name|jobname
argument_list|,
name|maxJobNameLen
operator|-
literal|6
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_NAME
argument_list|,
name|jobname
argument_list|)
expr_stmt|;
name|HadoopArchives
name|har
init|=
operator|new
name|HadoopArchives
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|args
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"-archiveName"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|archiveName
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"-p"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|originalDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|tmpPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|ret
operator|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|har
argument_list|,
name|args
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|ret
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error while creating HAR"
argument_list|)
throw|;
block|}
comment|// Move from the tmp dir to an intermediate directory, in the same level as
comment|// the partition directory. e.g. .../hr=12-intermediate-archived
try|try
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Moving "
operator|+
name|tmpPath
operator|+
literal|" to "
operator|+
name|intermediateArchivedDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"The intermediate archive directory already exists."
argument_list|)
throw|;
block|}
name|fs
operator|.
name|rename
argument_list|(
name|tmpPath
argument_list|,
name|intermediateArchivedDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error while moving tmp directory"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Intermediate archive directory "
operator|+
name|intermediateArchivedDir
operator|+
literal|" already exists. Assuming it contains an archived version of the partition"
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we get to here, we know that we've archived the partition files, but
comment|// they may be in the original partition location, or in the intermediate
comment|// original dir.
comment|// Move the original parent directory to the intermediate original directory
comment|// if the move hasn't been made already
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|intermediateOriginalDir
argument_list|)
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Moving "
operator|+
name|originalDir
operator|+
literal|" to "
operator|+
name|intermediateOriginalDir
argument_list|)
expr_stmt|;
name|moveDir
argument_list|(
name|fs
argument_list|,
name|originalDir
argument_list|,
name|intermediateOriginalDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|console
operator|.
name|printInfo
argument_list|(
name|intermediateOriginalDir
operator|+
literal|" already exists. "
operator|+
literal|"Assuming it contains the original files in the partition"
argument_list|)
expr_stmt|;
block|}
comment|// If there's a failure from here to when the metadata is updated,
comment|// there will be no data in the partition, or an error while trying to read
comment|// the partition (if the archive files have been moved to the original
comment|// partition directory.) But re-running the archive command will allow
comment|// recovery
comment|// Move the intermediate archived directory to the original parent directory
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|originalDir
argument_list|)
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Moving "
operator|+
name|intermediateArchivedDir
operator|+
literal|" to "
operator|+
name|originalDir
argument_list|)
expr_stmt|;
name|moveDir
argument_list|(
name|fs
argument_list|,
name|intermediateArchivedDir
argument_list|,
name|originalDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|console
operator|.
name|printInfo
argument_list|(
name|originalDir
operator|+
literal|" already exists. "
operator|+
literal|"Assuming it contains the archived version of the partition"
argument_list|)
expr_stmt|;
block|}
comment|// Record this change in the metastore
try|try
block|{
for|for
control|(
name|Partition
name|p
range|:
name|partitions
control|)
block|{
name|URI
name|originalPartitionUri
init|=
name|ArchiveUtils
operator|.
name|addSlash
argument_list|(
name|p
operator|.
name|getDataLocation
argument_list|()
operator|.
name|toUri
argument_list|()
argument_list|)
decl_stmt|;
name|URI
name|harPartitionDir
init|=
name|harHelper
operator|.
name|getHarUri
argument_list|(
name|originalPartitionUri
argument_list|)
decl_stmt|;
name|StringBuilder
name|authority
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
if|if
condition|(
name|harPartitionDir
operator|.
name|getUserInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|authority
operator|.
name|append
argument_list|(
name|harPartitionDir
operator|.
name|getUserInfo
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|"@"
argument_list|)
expr_stmt|;
block|}
name|authority
operator|.
name|append
argument_list|(
name|harPartitionDir
operator|.
name|getHost
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|harPartitionDir
operator|.
name|getPort
argument_list|()
operator|!=
operator|-
literal|1
condition|)
block|{
name|authority
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
operator|.
name|append
argument_list|(
name|harPartitionDir
operator|.
name|getPort
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Path
name|harPath
init|=
operator|new
name|Path
argument_list|(
name|harPartitionDir
operator|.
name|getScheme
argument_list|()
argument_list|,
name|authority
operator|.
name|toString
argument_list|()
argument_list|,
name|harPartitionDir
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
comment|// make in Path to ensure no slash at the end
name|setArchived
argument_list|(
name|p
argument_list|,
name|harPath
argument_list|,
name|partSpecInfo
operator|.
name|values
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// TODO: catalog
name|db
operator|.
name|alterPartition
argument_list|(
name|simpleDesc
operator|.
name|getTableName
argument_list|()
argument_list|,
name|p
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to change the partition info for HAR"
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// If a failure occurs here, the directory containing the original files
comment|// will not be deleted. The user will run ARCHIVE again to clear this up
if|if
condition|(
name|pathExists
argument_list|(
name|intermediateOriginalDir
argument_list|)
condition|)
block|{
name|deleteDir
argument_list|(
name|intermediateOriginalDir
argument_list|,
name|db
operator|.
name|getDatabase
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|recovery
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Recovery after ARCHIVE succeeded"
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|unarchive
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableSimpleDesc
name|simpleDesc
parameter_list|)
throws|throws
name|HiveException
throws|,
name|URISyntaxException
block|{
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|simpleDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
comment|// Means user specified a table, not a partition
if|if
condition|(
name|simpleDesc
operator|.
name|getPartSpec
argument_list|()
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"UNARCHIVE is for partitions only"
argument_list|)
throw|;
block|}
if|if
condition|(
name|tbl
operator|.
name|getTableType
argument_list|()
operator|!=
name|TableType
operator|.
name|MANAGED_TABLE
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"UNARCHIVE can only be performed on managed tables"
argument_list|)
throw|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|simpleDesc
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
name|PartSpecInfo
name|partSpecInfo
init|=
name|PartSpecInfo
operator|.
name|create
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|db
operator|.
name|getPartitions
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
name|int
name|partSpecLevel
init|=
name|partSpec
operator|.
name|size
argument_list|()
decl_stmt|;
name|Path
name|originalDir
init|=
literal|null
decl_stmt|;
comment|// when we have partial partitions specification we must assume partitions
comment|// lie in standard place - if they were in custom locations putting
comment|// them into one archive would involve mass amount of copying
comment|// in full partition specification case we allow custom locations
comment|// to keep backward compatibility
if|if
condition|(
name|partitions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"No partition matches the specification"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|partSpecInfo
operator|.
name|values
operator|.
name|size
argument_list|()
operator|!=
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|size
argument_list|()
condition|)
block|{
comment|// for partial specifications we need partitions to follow the scheme
for|for
control|(
name|Partition
name|p
range|:
name|partitions
control|)
block|{
if|if
condition|(
name|partitionInCustomLocation
argument_list|(
name|tbl
argument_list|,
name|p
argument_list|)
condition|)
block|{
name|String
name|message
init|=
name|String
operator|.
name|format
argument_list|(
literal|"UNARCHIVE cannot run for partition "
operator|+
literal|"groups with custom locations like %s"
argument_list|,
name|p
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|message
argument_list|)
throw|;
block|}
block|}
name|originalDir
operator|=
name|partSpecInfo
operator|.
name|createPath
argument_list|(
name|tbl
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Partition
name|p
init|=
name|partitions
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|originalDir
operator|=
operator|new
name|Path
argument_list|(
name|getOriginalLocation
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|originalDir
operator|=
operator|new
name|Path
argument_list|(
name|p
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|URI
name|originalUri
init|=
name|ArchiveUtils
operator|.
name|addSlash
argument_list|(
name|originalDir
operator|.
name|toUri
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|intermediateArchivedDir
init|=
operator|new
name|Path
argument_list|(
name|originalDir
operator|.
name|getParent
argument_list|()
argument_list|,
name|originalDir
operator|.
name|getName
argument_list|()
operator|+
name|INTERMEDIATE_ARCHIVED_DIR_SUFFIX
argument_list|)
decl_stmt|;
name|Path
name|intermediateExtractedDir
init|=
operator|new
name|Path
argument_list|(
name|originalDir
operator|.
name|getParent
argument_list|()
argument_list|,
name|originalDir
operator|.
name|getName
argument_list|()
operator|+
name|INTERMEDIATE_EXTRACTED_DIR_SUFFIX
argument_list|)
decl_stmt|;
name|boolean
name|recovery
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
operator|||
name|pathExists
argument_list|(
name|intermediateExtractedDir
argument_list|)
condition|)
block|{
name|recovery
operator|=
literal|true
expr_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"Starting recovery after failed UNARCHIVE"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Partition
name|p
range|:
name|partitions
control|)
block|{
name|checkArchiveProperty
argument_list|(
name|partSpecLevel
argument_list|,
name|recovery
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
name|String
name|archiveName
init|=
literal|"data.har"
decl_stmt|;
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
try|try
block|{
name|fs
operator|=
name|originalDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
comment|// assume the archive is in the original dir, check if it exists
name|Path
name|archivePath
init|=
operator|new
name|Path
argument_list|(
name|originalDir
argument_list|,
name|archiveName
argument_list|)
decl_stmt|;
name|URI
name|archiveUri
init|=
name|archivePath
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|ArchiveUtils
operator|.
name|HarPathHelper
name|harHelper
init|=
operator|new
name|ArchiveUtils
operator|.
name|HarPathHelper
argument_list|(
name|conf
argument_list|,
name|archiveUri
argument_list|,
name|originalUri
argument_list|)
decl_stmt|;
name|URI
name|sourceUri
init|=
name|harHelper
operator|.
name|getHarUri
argument_list|(
name|originalUri
argument_list|)
decl_stmt|;
name|Path
name|sourceDir
init|=
operator|new
name|Path
argument_list|(
name|sourceUri
operator|.
name|getScheme
argument_list|()
argument_list|,
name|sourceUri
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|sourceUri
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
operator|&&
operator|!
name|pathExists
argument_list|(
name|archivePath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Haven't found any archive where it should be"
argument_list|)
throw|;
block|}
name|Path
name|tmpPath
init|=
name|driverContext
operator|.
name|getCtx
argument_list|()
operator|.
name|getExternalTmpPath
argument_list|(
name|originalDir
argument_list|)
decl_stmt|;
try|try
block|{
name|fs
operator|=
name|tmpPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
comment|// Clarification of terms:
comment|// - The originalDir directory represents the original directory of the
comment|//   partitions' files. They now contain an archived version of those files
comment|//   eg. hdfs:/warehouse/myTable/ds=1/
comment|// - The source directory is the directory containing all the files that
comment|//   should be in the partitions. e.g. har:/warehouse/myTable/ds=1/myTable.har/
comment|//   Note the har:/ scheme
comment|// Steps:
comment|// 1. Extract the archive in a temporary folder
comment|// 2. Move the archive dir to an intermediate dir that is in at the same
comment|//    dir as originalLocation. Call the new dir intermediate-extracted.
comment|// 3. Rename the original partitions dir to an intermediate dir. Call the
comment|//    renamed dir intermediate-archive
comment|// 4. Rename intermediate-extracted to the original partitions dir
comment|// 5. Change the metadata
comment|// 6. Delete the archived partitions files in intermediate-archive
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|intermediateExtractedDir
argument_list|)
operator|&&
operator|!
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
condition|)
block|{
try|try
block|{
comment|// Copy the files out of the archive into the temporary directory
name|String
name|copySource
init|=
name|sourceDir
operator|.
name|toString
argument_list|()
decl_stmt|;
name|String
name|copyDest
init|=
name|tmpPath
operator|.
name|toString
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|args
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"-cp"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|copySource
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|copyDest
argument_list|)
expr_stmt|;
name|console
operator|.
name|printInfo
argument_list|(
literal|"Copying "
operator|+
name|copySource
operator|+
literal|" to "
operator|+
name|copyDest
argument_list|)
expr_stmt|;
name|FileSystem
name|srcFs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|sourceDir
operator|.
name|toUri
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|srcFs
operator|.
name|initialize
argument_list|(
name|sourceDir
operator|.
name|toUri
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|FsShell
name|fss
init|=
operator|new
name|FsShell
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|int
name|ret
init|=
literal|0
decl_stmt|;
try|try
block|{
name|ret
operator|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|fss
argument_list|,
name|args
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|ret
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error while copying files from archive, return code="
operator|+
name|ret
argument_list|)
throw|;
block|}
else|else
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Successfully Copied "
operator|+
name|copySource
operator|+
literal|" to "
operator|+
name|copyDest
argument_list|)
expr_stmt|;
block|}
name|console
operator|.
name|printInfo
argument_list|(
literal|"Moving "
operator|+
name|tmpPath
operator|+
literal|" to "
operator|+
name|intermediateExtractedDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|intermediateExtractedDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Invalid state: the intermediate extracted "
operator|+
literal|"directory already exists."
argument_list|)
throw|;
block|}
name|fs
operator|.
name|rename
argument_list|(
name|tmpPath
argument_list|,
name|intermediateExtractedDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// At this point, we know that the extracted files are in the intermediate
comment|// extracted dir, or in the the original directory.
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
condition|)
block|{
try|try
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Moving "
operator|+
name|originalDir
operator|+
literal|" to "
operator|+
name|intermediateArchivedDir
argument_list|)
expr_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|originalDir
argument_list|,
name|intermediateArchivedDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|console
operator|.
name|printInfo
argument_list|(
name|intermediateArchivedDir
operator|+
literal|" already exists. "
operator|+
literal|"Assuming it contains the archived version of the partition"
argument_list|)
expr_stmt|;
block|}
comment|// If there is a failure from here to until when the metadata is changed,
comment|// the partition will be empty or throw errors on read.
comment|// If the original location exists here, then it must be the extracted files
comment|// because in the previous step, we moved the previous original location
comment|// (containing the archived version of the files) to intermediateArchiveDir
if|if
condition|(
operator|!
name|pathExists
argument_list|(
name|originalDir
argument_list|)
condition|)
block|{
try|try
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Moving "
operator|+
name|intermediateExtractedDir
operator|+
literal|" to "
operator|+
name|originalDir
argument_list|)
expr_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|intermediateExtractedDir
argument_list|,
name|originalDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|console
operator|.
name|printInfo
argument_list|(
name|originalDir
operator|+
literal|" already exists. "
operator|+
literal|"Assuming it contains the extracted files in the partition"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Partition
name|p
range|:
name|partitions
control|)
block|{
name|setUnArchived
argument_list|(
name|p
argument_list|)
expr_stmt|;
try|try
block|{
comment|// TODO: catalog
name|db
operator|.
name|alterPartition
argument_list|(
name|simpleDesc
operator|.
name|getTableName
argument_list|()
argument_list|,
name|p
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// If a failure happens here, the intermediate archive files won't be
comment|// deleted. The user will need to call unarchive again to clear those up.
if|if
condition|(
name|pathExists
argument_list|(
name|intermediateArchivedDir
argument_list|)
condition|)
block|{
name|deleteDir
argument_list|(
name|intermediateArchivedDir
argument_list|,
name|db
operator|.
name|getDatabase
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|recovery
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Recovery after UNARCHIVE succeeded"
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|void
name|checkArchiveProperty
parameter_list|(
name|int
name|partSpecLevel
parameter_list|,
name|boolean
name|recovery
parameter_list|,
name|Partition
name|p
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|ArchiveUtils
operator|.
name|isArchived
argument_list|(
name|p
argument_list|)
operator|&&
operator|!
name|recovery
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition "
operator|+
name|p
operator|.
name|getName
argument_list|()
operator|+
literal|" is not archived."
argument_list|)
throw|;
block|}
name|int
name|archiveLevel
init|=
name|ArchiveUtils
operator|.
name|getArchivingLevel
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|partSpecLevel
operator|>
name|archiveLevel
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition "
operator|+
name|p
operator|.
name|getName
argument_list|()
operator|+
literal|" is archived at level "
operator|+
name|archiveLevel
operator|+
literal|", and given partspec only has "
operator|+
name|partSpecLevel
operator|+
literal|" specs."
argument_list|)
throw|;
block|}
block|}
specifier|private
name|int
name|compact
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableSimpleDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|desc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|tbl
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|NONACID_COMPACTION_NOT_SUPPORTED
argument_list|,
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
throw|;
block|}
name|String
name|partName
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|desc
operator|.
name|getPartSpec
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// Compaction can only be done on the whole table if the table is non-partitioned.
if|if
condition|(
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|NO_COMPACTION_PARTITION
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|desc
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|db
operator|.
name|getPartitions
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
if|if
condition|(
name|partitions
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|TOO_MANY_COMPACTION_PARTITIONS
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|partitions
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PARTITION_SPEC
argument_list|)
throw|;
block|}
name|partName
operator|=
name|partitions
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|CompactionResponse
name|resp
init|=
name|db
operator|.
name|compact2
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partName
argument_list|,
name|desc
operator|.
name|getCompactionType
argument_list|()
argument_list|,
name|desc
operator|.
name|getProps
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|resp
operator|.
name|isAccepted
argument_list|()
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Compaction enqueued with id "
operator|+
name|resp
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Compaction already enqueued with id "
operator|+
name|resp
operator|.
name|getId
argument_list|()
operator|+
literal|"; State is "
operator|+
name|resp
operator|.
name|getState
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|desc
operator|.
name|isBlocking
argument_list|()
operator|&&
name|resp
operator|.
name|isAccepted
argument_list|()
condition|)
block|{
name|StringBuilder
name|progressDots
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|long
name|waitTimeMs
init|=
literal|1000
decl_stmt|;
name|wait
label|:
while|while
condition|(
literal|true
condition|)
block|{
comment|//double wait time until 5min
name|waitTimeMs
operator|=
name|waitTimeMs
operator|*
literal|2
expr_stmt|;
name|waitTimeMs
operator|=
name|waitTimeMs
operator|<
literal|5
operator|*
literal|60
operator|*
literal|1000
condition|?
name|waitTimeMs
else|:
literal|5
operator|*
literal|60
operator|*
literal|1000
expr_stmt|;
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|waitTimeMs
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ex
parameter_list|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Interrupted while waiting for compaction with id="
operator|+
name|resp
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
break|break;
block|}
comment|//this could be expensive when there are a lot of compactions....
comment|//todo: update to search by ID once HIVE-13353 is done
name|ShowCompactResponse
name|allCompactions
init|=
name|db
operator|.
name|showCompactions
argument_list|()
decl_stmt|;
for|for
control|(
name|ShowCompactResponseElement
name|compaction
range|:
name|allCompactions
operator|.
name|getCompacts
argument_list|()
control|)
block|{
if|if
condition|(
name|resp
operator|.
name|getId
argument_list|()
operator|!=
name|compaction
operator|.
name|getId
argument_list|()
condition|)
block|{
continue|continue;
block|}
switch|switch
condition|(
name|compaction
operator|.
name|getState
argument_list|()
condition|)
block|{
case|case
name|TxnStore
operator|.
name|WORKING_RESPONSE
case|:
case|case
name|TxnStore
operator|.
name|INITIATED_RESPONSE
case|:
comment|//still working
name|console
operator|.
name|printInfo
argument_list|(
name|progressDots
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|progressDots
operator|.
name|append
argument_list|(
literal|"."
argument_list|)
expr_stmt|;
continue|continue
name|wait
continue|;
default|default:
comment|//done
name|console
operator|.
name|printInfo
argument_list|(
literal|"Compaction with id "
operator|+
name|resp
operator|.
name|getId
argument_list|()
operator|+
literal|" finished with status: "
operator|+
name|compaction
operator|.
name|getState
argument_list|()
argument_list|)
expr_stmt|;
break|break
name|wait
break|;
block|}
block|}
block|}
block|}
return|return
literal|0
return|;
block|}
comment|/**    * MetastoreCheck, see if the data in the metastore matches what is on the    * dfs. Current version checks for tables and partitions that are either    * missing on disk on in the metastore.    *    * @param db    *          The database in question.    * @param msckDesc    *          Information about the tables and partitions we want to check for.    * @return Returns 0 when execution succeeds and above 0 if it fails.    */
specifier|private
name|int
name|msck
parameter_list|(
name|Hive
name|db
parameter_list|,
name|MsckDesc
name|msckDesc
parameter_list|)
block|{
name|Msck
name|msck
decl_stmt|;
try|try
block|{
name|msck
operator|=
operator|new
name|Msck
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|msck
operator|.
name|init
argument_list|(
name|db
operator|.
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|msckDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|MsckInfo
name|msckInfo
init|=
operator|new
name|MsckInfo
argument_list|(
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentCatalog
argument_list|()
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|msckDesc
operator|.
name|getPartSpecs
argument_list|()
argument_list|,
name|msckDesc
operator|.
name|getResFile
argument_list|()
argument_list|,
name|msckDesc
operator|.
name|isRepairPartitions
argument_list|()
argument_list|,
name|msckDesc
operator|.
name|isAddPartitions
argument_list|()
argument_list|,
name|msckDesc
operator|.
name|isDropPartitions
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|)
decl_stmt|;
return|return
name|msck
operator|.
name|repair
argument_list|(
name|msckInfo
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to create msck instance."
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
catch|catch
parameter_list|(
name|SemanticException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Msck failed."
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
block|}
comment|/**    * Write a list of partitions to a file.    *    * @param db    *          The database in question.    * @param showParts    *          These are the partitions we're interested in.    * @return Returns 0 when execution succeeds and above 0 if it fails.    * @throws HiveException    *           Throws this exception if an unexpected error occurs.    */
specifier|private
name|int
name|showPartitions
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowPartitionsDesc
name|showParts
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// get the partitions for the table and populate the output
name|String
name|tabName
init|=
name|showParts
operator|.
name|getTabName
argument_list|()
decl_stmt|;
name|Table
name|tbl
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|parts
init|=
literal|null
decl_stmt|;
name|tbl
operator|=
name|db
operator|.
name|getTable
argument_list|(
name|tabName
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|TABLE_NOT_PARTITIONED
argument_list|,
name|tabName
argument_list|)
throw|;
block|}
if|if
condition|(
name|showParts
operator|.
name|getPartSpec
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|parts
operator|=
name|db
operator|.
name|getPartitionNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|showParts
operator|.
name|getPartSpec
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|parts
operator|=
name|db
operator|.
name|getPartitionNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|// write the results in the file
name|DataOutputStream
name|outStream
init|=
name|getOutputStream
argument_list|(
name|showParts
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|formatter
operator|.
name|showTablePartitions
argument_list|(
name|outStream
argument_list|,
name|parts
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|,
name|ErrorMsg
operator|.
name|GENERIC_ERROR
argument_list|,
literal|"show partitions for table "
operator|+
name|tabName
argument_list|)
throw|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|outStream
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * Write a list of the columns in the table to a file.    *    * @param db    *          The database in context.    * @param showCols    *        A ShowColumnsDesc for columns we're interested in.    * @return Returns 0 when execution succeeds.    * @throws HiveException    *        Throws this exception if an unexpected error occurs.    */
specifier|public
name|int
name|showColumns
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowColumnsDesc
name|showCols
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|table
init|=
name|db
operator|.
name|getTable
argument_list|(
name|showCols
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
comment|// write the results in the file
name|DataOutputStream
name|outStream
init|=
name|getOutputStream
argument_list|(
name|showCols
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|allCols
init|=
name|table
operator|.
name|getCols
argument_list|()
decl_stmt|;
name|allCols
operator|.
name|addAll
argument_list|(
name|table
operator|.
name|getPartCols
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
init|=
name|getColumnsByPattern
argument_list|(
name|allCols
argument_list|,
name|showCols
operator|.
name|getPattern
argument_list|()
argument_list|)
decl_stmt|;
comment|// In case the query is served by HiveServer2, don't pad it with spaces,
comment|// as HiveServer2 output is consumed by JDBC/ODBC clients.
name|boolean
name|isOutputPadded
init|=
operator|!
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|isHiveServerQuery
argument_list|()
decl_stmt|;
name|TextMetaDataTable
name|tmd
init|=
operator|new
name|TextMetaDataTable
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
name|tmd
operator|.
name|addRow
argument_list|(
name|MetaDataFormatUtils
operator|.
name|extractColumnValues
argument_list|(
name|fieldSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|outStream
operator|.
name|writeBytes
argument_list|(
name|tmd
operator|.
name|renderTable
argument_list|(
name|isOutputPadded
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|,
name|ErrorMsg
operator|.
name|GENERIC_ERROR
argument_list|)
throw|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|outStream
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * Returns a sorted list of columns matching a column pattern.    *    * @param cols    *        Columns of a table.    * @param columnPattern    *        we want to find columns similar to a column pattern.    * @return sorted list of columns.    */
specifier|private
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|getColumnsByPattern
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|,
name|String
name|columnPattern
parameter_list|)
block|{
if|if
condition|(
name|columnPattern
operator|==
literal|null
condition|)
block|{
name|columnPattern
operator|=
literal|"*"
expr_stmt|;
block|}
name|columnPattern
operator|=
name|columnPattern
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
name|columnPattern
operator|=
name|columnPattern
operator|.
name|replaceAll
argument_list|(
literal|"\\*"
argument_list|,
literal|".*"
argument_list|)
expr_stmt|;
name|Pattern
name|pattern
init|=
name|Pattern
operator|.
name|compile
argument_list|(
name|columnPattern
argument_list|)
decl_stmt|;
name|Matcher
name|matcher
init|=
name|pattern
operator|.
name|matcher
argument_list|(
literal|""
argument_list|)
decl_stmt|;
name|SortedSet
argument_list|<
name|FieldSchema
argument_list|>
name|sortedCol
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
operator|new
name|Comparator
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|FieldSchema
name|f1
parameter_list|,
name|FieldSchema
name|f2
parameter_list|)
block|{
return|return
name|f1
operator|.
name|getName
argument_list|()
operator|.
name|compareTo
argument_list|(
name|f2
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|column
range|:
name|cols
control|)
block|{
name|matcher
operator|.
name|reset
argument_list|(
name|column
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|matcher
operator|.
name|matches
argument_list|()
condition|)
block|{
name|sortedCol
operator|.
name|add
argument_list|(
name|column
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|(
name|sortedCol
argument_list|)
return|;
block|}
comment|/**    * Write a list of the current locks to a file.    * @param db    *    * @param showLocks    *          the locks we're interested in.    * @return Returns 0 when execution succeeds and above 0 if it fails.    * @throws HiveException    *           Throws this exception if an unexpected error occurs.    */
specifier|private
name|int
name|showLocks
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowLocksDesc
name|showLocks
parameter_list|)
throws|throws
name|HiveException
block|{
name|Context
name|ctx
init|=
name|driverContext
operator|.
name|getCtx
argument_list|()
decl_stmt|;
name|HiveTxnManager
name|txnManager
init|=
name|ctx
operator|.
name|getHiveTxnManager
argument_list|()
decl_stmt|;
name|HiveLockManager
name|lockMgr
init|=
name|txnManager
operator|.
name|getLockManager
argument_list|()
decl_stmt|;
if|if
condition|(
name|txnManager
operator|.
name|useNewShowLocksFormat
argument_list|()
condition|)
block|{
return|return
name|showLocksNewFormat
argument_list|(
name|showLocks
argument_list|,
name|lockMgr
argument_list|)
return|;
block|}
name|boolean
name|isExt
init|=
name|showLocks
operator|.
name|isExt
argument_list|()
decl_stmt|;
if|if
condition|(
name|lockMgr
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"show Locks LockManager not specified"
argument_list|)
throw|;
block|}
comment|// write the results in the file
name|DataOutputStream
name|outStream
init|=
name|getOutputStream
argument_list|(
name|showLocks
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|HiveLock
argument_list|>
name|locks
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|showLocks
operator|.
name|getTableName
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// TODO should be doing security check here.  Users should not be
comment|// able to see each other's locks.
name|locks
operator|=
name|lockMgr
operator|.
name|getLocks
argument_list|(
literal|false
argument_list|,
name|isExt
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|locks
operator|=
name|lockMgr
operator|.
name|getLocks
argument_list|(
name|HiveLockObject
operator|.
name|createFrom
argument_list|(
name|db
argument_list|,
name|showLocks
operator|.
name|getTableName
argument_list|()
argument_list|,
name|showLocks
operator|.
name|getPartSpec
argument_list|()
argument_list|)
argument_list|,
literal|true
argument_list|,
name|isExt
argument_list|)
expr_stmt|;
block|}
name|Collections
operator|.
name|sort
argument_list|(
name|locks
argument_list|,
operator|new
name|Comparator
argument_list|<
name|HiveLock
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|HiveLock
name|o1
parameter_list|,
name|HiveLock
name|o2
parameter_list|)
block|{
name|int
name|cmp
init|=
name|o1
operator|.
name|getHiveLockObject
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|compareTo
argument_list|(
name|o2
operator|.
name|getHiveLockObject
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|o1
operator|.
name|getHiveLockMode
argument_list|()
operator|==
name|o2
operator|.
name|getHiveLockMode
argument_list|()
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// EXCLUSIVE locks occur before SHARED locks
if|if
condition|(
name|o1
operator|.
name|getHiveLockMode
argument_list|()
operator|==
name|HiveLockMode
operator|.
name|EXCLUSIVE
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
return|return
operator|+
literal|1
return|;
block|}
return|return
name|cmp
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|Iterator
argument_list|<
name|HiveLock
argument_list|>
name|locksIter
init|=
name|locks
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|locksIter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|HiveLock
name|lock
init|=
name|locksIter
operator|.
name|next
argument_list|()
decl_stmt|;
name|outStream
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getHiveLockObject
argument_list|()
operator|.
name|getDisplayName
argument_list|()
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getHiveLockMode
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isExt
condition|)
block|{
name|HiveLockObjectData
name|lockData
init|=
name|lock
operator|.
name|getHiveLockObject
argument_list|()
operator|.
name|getData
argument_list|()
decl_stmt|;
if|if
condition|(
name|lockData
operator|!=
literal|null
condition|)
block|{
name|outStream
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|writeBytes
argument_list|(
literal|"LOCK_QUERYID:"
operator|+
name|lockData
operator|.
name|getQueryId
argument_list|()
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|writeBytes
argument_list|(
literal|"LOCK_TIME:"
operator|+
name|lockData
operator|.
name|getLockTime
argument_list|()
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|writeBytes
argument_list|(
literal|"LOCK_MODE:"
operator|+
name|lockData
operator|.
name|getLockMode
argument_list|()
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
name|outStream
operator|.
name|writeBytes
argument_list|(
literal|"LOCK_QUERYSTRING:"
operator|+
name|lockData
operator|.
name|getQueryStr
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|outStream
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"show function: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"show function: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|outStream
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|public
specifier|static
name|void
name|dumpLockInfo
parameter_list|(
name|DataOutputStream
name|os
parameter_list|,
name|ShowLocksResponse
name|rsp
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Write a header
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Lock ID"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Database"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Table"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Partition"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"State"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Blocked By"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Type"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Transaction ID"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Last Heartbeat"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Acquired At"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"User"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Hostname"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Agent Info"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|ShowLocksResponseElement
argument_list|>
name|locks
init|=
name|rsp
operator|.
name|getLocks
argument_list|()
decl_stmt|;
if|if
condition|(
name|locks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|ShowLocksResponseElement
name|lock
range|:
name|locks
control|)
block|{
if|if
condition|(
name|lock
operator|.
name|isSetLockIdInternal
argument_list|()
condition|)
block|{
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getLockid
argument_list|()
argument_list|)
operator|+
literal|"."
operator|+
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getLockIdInternal
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getLockid
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getDbname
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
operator|(
name|lock
operator|.
name|getTablename
argument_list|()
operator|==
literal|null
operator|)
condition|?
literal|"NULL"
else|:
name|lock
operator|.
name|getTablename
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
operator|(
name|lock
operator|.
name|getPartname
argument_list|()
operator|==
literal|null
operator|)
condition|?
literal|"NULL"
else|:
name|lock
operator|.
name|getPartname
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getState
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|.
name|isSetBlockedByExtId
argument_list|()
condition|)
block|{
comment|//both "blockedby" are either there or not
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getBlockedByExtId
argument_list|()
argument_list|)
operator|+
literal|"."
operator|+
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getBlockedByIntId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|os
operator|.
name|writeBytes
argument_list|(
literal|"            "
argument_list|)
expr_stmt|;
comment|//12 chars - try to keep cols aligned
block|}
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getType
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
operator|(
name|lock
operator|.
name|getTxnid
argument_list|()
operator|==
literal|0
operator|)
condition|?
literal|"NULL"
else|:
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getTxnid
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getLastheartbeat
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
operator|(
name|lock
operator|.
name|getAcquiredat
argument_list|()
operator|==
literal|0
operator|)
condition|?
literal|"NULL"
else|:
name|Long
operator|.
name|toString
argument_list|(
name|lock
operator|.
name|getAcquiredat
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getUser
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getHostname
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|lock
operator|.
name|getAgentInfo
argument_list|()
operator|==
literal|null
condition|?
literal|"NULL"
else|:
name|lock
operator|.
name|getAgentInfo
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|int
name|showLocksNewFormat
parameter_list|(
name|ShowLocksDesc
name|showLocks
parameter_list|,
name|HiveLockManager
name|lm
parameter_list|)
throws|throws
name|HiveException
block|{
name|DbLockManager
name|lockMgr
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|lm
operator|instanceof
name|DbLockManager
operator|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"New lock format only supported with db lock manager."
argument_list|)
throw|;
block|}
name|lockMgr
operator|=
operator|(
name|DbLockManager
operator|)
name|lm
expr_stmt|;
name|String
name|dbName
init|=
name|showLocks
operator|.
name|getDbName
argument_list|()
decl_stmt|;
name|String
name|tblName
init|=
name|showLocks
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|showLocks
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|dbName
operator|==
literal|null
operator|&&
name|tblName
operator|!=
literal|null
condition|)
block|{
name|dbName
operator|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentDatabase
argument_list|()
expr_stmt|;
block|}
name|ShowLocksRequest
name|rqst
init|=
operator|new
name|ShowLocksRequest
argument_list|()
decl_stmt|;
name|rqst
operator|.
name|setDbname
argument_list|(
name|dbName
argument_list|)
expr_stmt|;
name|rqst
operator|.
name|setTablename
argument_list|(
name|tblName
argument_list|)
expr_stmt|;
if|if
condition|(
name|partSpec
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|keyList
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|valList
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|partKey
range|:
name|partSpec
operator|.
name|keySet
argument_list|()
control|)
block|{
name|String
name|partVal
init|=
name|partSpec
operator|.
name|remove
argument_list|(
name|partKey
argument_list|)
decl_stmt|;
name|keyList
operator|.
name|add
argument_list|(
name|partKey
argument_list|)
expr_stmt|;
name|valList
operator|.
name|add
argument_list|(
name|partVal
argument_list|)
expr_stmt|;
block|}
name|String
name|partName
init|=
name|FileUtils
operator|.
name|makePartName
argument_list|(
name|keyList
argument_list|,
name|valList
argument_list|)
decl_stmt|;
name|rqst
operator|.
name|setPartname
argument_list|(
name|partName
argument_list|)
expr_stmt|;
block|}
name|ShowLocksResponse
name|rsp
init|=
name|lockMgr
operator|.
name|getLocks
argument_list|(
name|rqst
argument_list|)
decl_stmt|;
comment|// write the results in the file
name|DataOutputStream
name|os
init|=
name|getOutputStream
argument_list|(
name|showLocks
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|dumpLockInfo
argument_list|(
name|os
argument_list|,
name|rsp
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"show function: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"show function: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|os
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|showCompactions
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowCompactionsDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Call the metastore to get the status of all known compactions (completed get purged eventually)
name|ShowCompactResponse
name|rsp
init|=
name|db
operator|.
name|showCompactions
argument_list|()
decl_stmt|;
comment|// Write the results into the file
specifier|final
name|String
name|noVal
init|=
literal|" --- "
decl_stmt|;
name|DataOutputStream
name|os
init|=
name|getOutputStream
argument_list|(
name|desc
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Write a header
name|os
operator|.
name|writeBytes
argument_list|(
literal|"CompactionId"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Database"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Table"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Partition"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Type"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"State"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Hostname"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Worker"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Start Time"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Duration(ms)"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"HadoopJobId"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsp
operator|.
name|getCompacts
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|ShowCompactResponseElement
name|e
range|:
name|rsp
operator|.
name|getCompacts
argument_list|()
control|)
block|{
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|e
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|getDbname
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|getTablename
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|String
name|part
init|=
name|e
operator|.
name|getPartitionname
argument_list|()
decl_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|part
operator|==
literal|null
condition|?
name|noVal
else|:
name|part
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|getType
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|getState
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|String
name|wid
init|=
name|e
operator|.
name|getWorkerid
argument_list|()
decl_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|wid
operator|==
literal|null
condition|?
name|noVal
else|:
name|wid
operator|.
name|split
argument_list|(
literal|"-"
argument_list|)
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|wid
operator|==
literal|null
condition|?
name|noVal
else|:
name|wid
operator|.
name|split
argument_list|(
literal|"-"
argument_list|)
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|isSetStart
argument_list|()
condition|?
name|Long
operator|.
name|toString
argument_list|(
name|e
operator|.
name|getStart
argument_list|()
argument_list|)
else|:
name|noVal
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|isSetEndTime
argument_list|()
condition|?
name|Long
operator|.
name|toString
argument_list|(
name|e
operator|.
name|getEndTime
argument_list|()
operator|-
name|e
operator|.
name|getStart
argument_list|()
argument_list|)
else|:
name|noVal
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|e
operator|.
name|isSetHadoopJobId
argument_list|()
condition|?
name|e
operator|.
name|getHadoopJobId
argument_list|()
else|:
name|noVal
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"show compactions: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|os
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|showTxns
parameter_list|(
name|Hive
name|db
parameter_list|,
name|ShowTxnsDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Call the metastore to get the currently queued and running compactions.
name|GetOpenTxnsInfoResponse
name|rsp
init|=
name|db
operator|.
name|showTransactions
argument_list|()
decl_stmt|;
comment|// Write the results into the file
name|DataOutputStream
name|os
init|=
name|getOutputStream
argument_list|(
name|desc
operator|.
name|getResFile
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Write a header
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Transaction ID"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Transaction State"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Started Time"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Last Heartbeat Time"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"User"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
literal|"Hostname"
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
for|for
control|(
name|TxnInfo
name|txn
range|:
name|rsp
operator|.
name|getOpen_txns
argument_list|()
control|)
block|{
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|txn
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|txn
operator|.
name|getState
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|txn
operator|.
name|getStartedTime
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|txn
operator|.
name|getLastHeartbeatTime
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|txn
operator|.
name|getUser
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeBytes
argument_list|(
name|txn
operator|.
name|getHostname
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|write
argument_list|(
name|terminator
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"show transactions: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|os
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|abortTxns
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AbortTxnsDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|db
operator|.
name|abortTransactions
argument_list|(
name|desc
operator|.
name|getTxnids
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|killQuery
parameter_list|(
name|Hive
name|db
parameter_list|,
name|KillQueryDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
block|{
name|SessionState
name|sessionState
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|queryId
range|:
name|desc
operator|.
name|getQueryIds
argument_list|()
control|)
block|{
name|sessionState
operator|.
name|getKillQuery
argument_list|()
operator|.
name|killQuery
argument_list|(
name|queryId
argument_list|,
literal|"User invoked KILL QUERY"
argument_list|,
name|db
operator|.
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"kill query called ({})"
argument_list|,
name|desc
operator|.
name|getQueryIds
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
comment|/**    * Alter a given table.    *    * @param db    *          The database in question.    * @param alterTbl    *          This is the table we're altering.    * @return Returns 0 when execution succeeds and above 0 if it fails.    * @throws HiveException    *           Throws this exception if an unexpected error occurs.    */
specifier|private
name|int
name|alterTable
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableDesc
name|alterTbl
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|RENAME
condition|)
block|{
name|String
name|names
index|[]
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|Utils
operator|.
name|isBootstrapDumpInProgress
argument_list|(
name|db
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"DDLTask: Rename Table not allowed as bootstrap dump in progress"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Rename Table: Not allowed as bootstrap dump in progress"
argument_list|)
throw|;
block|}
block|}
comment|// alter the table
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|allPartitions
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|alterTbl
operator|.
name|getPartSpec
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|alterTbl
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|DDLSemanticAnalyzer
operator|.
name|isFullSpec
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|)
condition|)
block|{
name|allPartitions
operator|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
expr_stmt|;
name|Partition
name|part
init|=
name|db
operator|.
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|part
operator|==
literal|null
condition|)
block|{
comment|// User provided a fully specified partition spec but it doesn't exist, fail.
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PARTITION
argument_list|,
name|StringUtils
operator|.
name|join
argument_list|(
name|alterTbl
operator|.
name|getPartSpec
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|,
literal|','
argument_list|)
operator|+
literal|" for table "
operator|+
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
name|allPartitions
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// DDLSemanticAnalyzer has already checked if partial partition specs are allowed,
comment|// thus we should not need to check it here.
name|allPartitions
operator|=
name|db
operator|.
name|getPartitions
argument_list|(
name|tbl
argument_list|,
name|alterTbl
operator|.
name|getPartSpec
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Don't change the table object returned by the metastore, as we'll mess with it's caches.
name|Table
name|oldTbl
init|=
name|tbl
decl_stmt|;
name|tbl
operator|=
name|oldTbl
operator|.
name|copy
argument_list|()
expr_stmt|;
comment|// Handle child tasks here. We could add them directly whereever we need,
comment|// but let's make it a little bit more explicit.
if|if
condition|(
name|allPartitions
operator|!=
literal|null
condition|)
block|{
comment|// Alter all partitions
for|for
control|(
name|Partition
name|part
range|:
name|allPartitions
control|)
block|{
name|addChildTasks
argument_list|(
name|alterTableOrSinglePartition
argument_list|(
name|alterTbl
argument_list|,
name|tbl
argument_list|,
name|part
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Just alter the table
name|addChildTasks
argument_list|(
name|alterTableOrSinglePartition
argument_list|(
name|alterTbl
argument_list|,
name|tbl
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|allPartitions
operator|==
literal|null
condition|)
block|{
name|updateModifiedParameters
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getParameters
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|checkValidity
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|Partition
name|tmpPart
range|:
name|allPartitions
control|)
block|{
name|updateModifiedParameters
argument_list|(
name|tmpPart
operator|.
name|getParameters
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|EnvironmentContext
name|environmentContext
init|=
name|alterTbl
operator|.
name|getEnvironmentContext
argument_list|()
decl_stmt|;
if|if
condition|(
name|environmentContext
operator|==
literal|null
condition|)
block|{
name|environmentContext
operator|=
operator|new
name|EnvironmentContext
argument_list|()
expr_stmt|;
block|}
name|environmentContext
operator|.
name|putToProperties
argument_list|(
name|HiveMetaHook
operator|.
name|ALTER_TABLE_OPERATION_TYPE
argument_list|,
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|allPartitions
operator|==
literal|null
condition|)
block|{
name|long
name|writeId
init|=
name|alterTbl
operator|.
name|getWriteId
argument_list|()
operator|!=
literal|null
condition|?
name|alterTbl
operator|.
name|getWriteId
argument_list|()
else|:
literal|0
decl_stmt|;
if|if
condition|(
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
operator|!=
literal|null
operator|&&
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
operator|.
name|isMigratingToTxnTable
argument_list|()
condition|)
block|{
name|Long
name|tmpWriteId
init|=
name|ReplUtils
operator|.
name|getMigrationCurrentTblWriteId
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmpWriteId
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"DDLTask : Write id is not set in the config by open txn task for migration"
argument_list|)
throw|;
block|}
name|writeId
operator|=
name|tmpWriteId
expr_stmt|;
block|}
name|db
operator|.
name|alterTable
argument_list|(
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|,
name|tbl
argument_list|,
name|alterTbl
operator|.
name|getIsCascade
argument_list|()
argument_list|,
name|environmentContext
argument_list|,
literal|true
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Note: this is necessary for UPDATE_STATISTICS command, that operates via ADDPROPS (why?).
comment|//       For any other updates, we don't want to do txn check on partitions when altering table.
name|boolean
name|isTxn
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|alterTbl
operator|.
name|getPartSpec
argument_list|()
operator|!=
literal|null
operator|&&
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|ADDPROPS
condition|)
block|{
comment|// ADDPROPS is used to add replication properties like repl.last.id, which isn't
comment|// transactional change. In case of replication check for transactional properties
comment|// explicitly.
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
init|=
name|alterTbl
operator|.
name|getProps
argument_list|()
decl_stmt|;
if|if
condition|(
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
operator|!=
literal|null
operator|&&
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
operator|.
name|isInReplicationScope
argument_list|()
condition|)
block|{
name|isTxn
operator|=
operator|(
name|props
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|COLUMN_STATS_ACCURATE
argument_list|)
operator|!=
literal|null
operator|)
expr_stmt|;
block|}
else|else
block|{
name|isTxn
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|db
operator|.
name|alterPartitions
argument_list|(
name|Warehouse
operator|.
name|getQualifiedName
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
argument_list|)
argument_list|,
name|allPartitions
argument_list|,
name|environmentContext
argument_list|,
name|isTxn
argument_list|)
expr_stmt|;
block|}
comment|// Add constraints if necessary
name|addConstraints
argument_list|(
name|db
argument_list|,
name|alterTbl
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"alter table: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|,
name|ErrorMsg
operator|.
name|GENERIC_ERROR
argument_list|)
throw|;
block|}
comment|// This is kind of hacky - the read entity contains the old table, whereas
comment|// the write entity
comment|// contains the new table. This is needed for rename - both the old and the
comment|// new table names are
comment|// passed
comment|// Don't acquire locks for any of these, we have already asked for them in DDLSemanticAnalyzer.
if|if
condition|(
name|allPartitions
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Partition
name|tmpPart
range|:
name|allPartitions
control|)
block|{
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|tmpPart
argument_list|)
argument_list|)
expr_stmt|;
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|tmpPart
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|oldTbl
argument_list|)
argument_list|)
expr_stmt|;
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|tbl
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * There are many places where "duplicate" Read/WriteEnity objects are added.  The way this was    * initially implemented, the duplicate just replaced the previous object.    * (work.getOutputs() is a Set and WriteEntity#equals() relies on name)    * This may be benign for ReadEntity and perhaps was benign for WriteEntity before WriteType was    * added. Now that WriteEntity has a WriteType it replaces it with one with possibly different    * {@link org.apache.hadoop.hive.ql.hooks.WriteEntity.WriteType}.  It's hard to imagine    * how this is desirable.    *    * As of HIVE-14993, WriteEntity with different WriteType must be considered different.    * So WriteEntity created in DDLTask cause extra output in golden files, but only because    * DDLTask sets a different WriteType for the same Entity.    *    * In the spirit of bug-for-bug compatibility, this method ensures we only add new    * WriteEntity if it's really new.    *    * @return {@code true} if item was added    */
specifier|static
name|boolean
name|addIfAbsentByName
parameter_list|(
name|WriteEntity
name|newWriteEntity
parameter_list|,
name|Set
argument_list|<
name|WriteEntity
argument_list|>
name|outputs
parameter_list|)
block|{
for|for
control|(
name|WriteEntity
name|writeEntity
range|:
name|outputs
control|)
block|{
if|if
condition|(
name|writeEntity
operator|.
name|getName
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|newWriteEntity
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Ignoring request to add {} because {} is present"
argument_list|,
name|newWriteEntity
operator|.
name|toStringDetail
argument_list|()
argument_list|,
name|writeEntity
operator|.
name|toStringDetail
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|outputs
operator|.
name|add
argument_list|(
name|newWriteEntity
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|private
name|boolean
name|addIfAbsentByName
parameter_list|(
name|WriteEntity
name|newWriteEntity
parameter_list|)
block|{
return|return
name|addIfAbsentByName
argument_list|(
name|newWriteEntity
argument_list|,
name|work
operator|.
name|getOutputs
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|void
name|addChildTasks
parameter_list|(
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|extraTasks
parameter_list|)
block|{
if|if
condition|(
name|extraTasks
operator|==
literal|null
condition|)
block|{
return|return;
block|}
for|for
control|(
name|Task
argument_list|<
name|?
argument_list|>
name|newTask
range|:
name|extraTasks
control|)
block|{
name|addDependentTask
argument_list|(
name|newTask
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|boolean
name|isSchemaEvolutionEnabled
parameter_list|(
name|Table
name|tbl
parameter_list|)
block|{
name|boolean
name|isAcid
init|=
name|AcidUtils
operator|.
name|isTablePropertyTransactional
argument_list|(
name|tbl
operator|.
name|getMetadata
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|isAcid
operator|||
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_SCHEMA_EVOLUTION
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
specifier|static
name|StorageDescriptor
name|retrieveStorageDescriptor
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Partition
name|part
parameter_list|)
block|{
return|return
operator|(
name|part
operator|==
literal|null
condition|?
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
else|:
name|part
operator|.
name|getTPartition
argument_list|()
operator|.
name|getSd
argument_list|()
operator|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|alterTableOrSinglePartition
parameter_list|(
name|AlterTableDesc
name|alterTbl
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Partition
name|part
parameter_list|)
throws|throws
name|HiveException
block|{
name|EnvironmentContext
name|environmentContext
init|=
name|alterTbl
operator|.
name|getEnvironmentContext
argument_list|()
decl_stmt|;
if|if
condition|(
name|environmentContext
operator|==
literal|null
condition|)
block|{
name|environmentContext
operator|=
operator|new
name|EnvironmentContext
argument_list|()
expr_stmt|;
name|alterTbl
operator|.
name|setEnvironmentContext
argument_list|(
name|environmentContext
argument_list|)
expr_stmt|;
block|}
comment|// do not need update stats in alter table/partition operations
if|if
condition|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|==
literal|null
operator|||
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
operator|==
literal|null
condition|)
block|{
name|environmentContext
operator|.
name|putToProperties
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|RENAME
condition|)
block|{
name|tbl
operator|.
name|setDbName
argument_list|(
name|Utilities
operator|.
name|getDatabaseName
argument_list|(
name|alterTbl
operator|.
name|getNewName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setTableName
argument_list|(
name|Utilities
operator|.
name|getTableName
argument_list|(
name|alterTbl
operator|.
name|getNewName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDCOLS
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
name|String
name|serializationLib
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
name|AvroSerdeUtils
operator|.
name|handleAlterTableForAvro
argument_list|(
name|conf
argument_list|,
name|serializationLib
argument_list|,
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
init|=
operator|(
name|part
operator|==
literal|null
condition|?
name|tbl
operator|.
name|getColsForMetastore
argument_list|()
else|:
name|part
operator|.
name|getColsForMetastore
argument_list|()
operator|)
decl_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
init|=
name|alterTbl
operator|.
name|getNewCols
argument_list|()
decl_stmt|;
if|if
condition|(
name|serializationLib
operator|.
name|equals
argument_list|(
literal|"org.apache.hadoop.hive.serde.thrift.columnsetSerDe"
argument_list|)
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Replacing columns for columnsetSerDe and changing to LazySimpleSerDe"
argument_list|)
expr_stmt|;
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setCols
argument_list|(
name|newCols
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// make sure the columns does not already exist
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|iterNewCols
init|=
name|newCols
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iterNewCols
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FieldSchema
name|newCol
init|=
name|iterNewCols
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|newColName
init|=
name|newCol
operator|.
name|getName
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|iterOldCols
init|=
name|oldCols
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iterOldCols
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|String
name|oldColName
init|=
name|iterOldCols
operator|.
name|next
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldColName
operator|.
name|equalsIgnoreCase
argument_list|(
name|newColName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|DUPLICATE_COLUMN_NAMES
argument_list|,
name|newColName
argument_list|)
throw|;
block|}
block|}
name|oldCols
operator|.
name|add
argument_list|(
name|newCol
argument_list|)
expr_stmt|;
block|}
name|sd
operator|.
name|setCols
argument_list|(
name|oldCols
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|RENAMECOLUMN
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
name|String
name|serializationLib
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
name|AvroSerdeUtils
operator|.
name|handleAlterTableForAvro
argument_list|(
name|conf
argument_list|,
name|serializationLib
argument_list|,
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
init|=
operator|(
name|part
operator|==
literal|null
condition|?
name|tbl
operator|.
name|getColsForMetastore
argument_list|()
else|:
name|part
operator|.
name|getColsForMetastore
argument_list|()
operator|)
decl_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|FieldSchema
argument_list|>
name|iterOldCols
init|=
name|oldCols
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|String
name|oldName
init|=
name|alterTbl
operator|.
name|getOldColName
argument_list|()
decl_stmt|;
name|String
name|newName
init|=
name|alterTbl
operator|.
name|getNewColName
argument_list|()
decl_stmt|;
name|String
name|type
init|=
name|alterTbl
operator|.
name|getNewColType
argument_list|()
decl_stmt|;
name|String
name|comment
init|=
name|alterTbl
operator|.
name|getNewColComment
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
name|alterTbl
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|String
name|afterCol
init|=
name|alterTbl
operator|.
name|getAfterCol
argument_list|()
decl_stmt|;
comment|// if orc table, restrict reordering columns as it will break schema evolution
name|boolean
name|isOrcSchemaEvolution
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|.
name|equals
argument_list|(
name|OrcInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
name|isSchemaEvolutionEnabled
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
if|if
condition|(
name|isOrcSchemaEvolution
operator|&&
operator|(
name|first
operator|||
operator|(
name|afterCol
operator|!=
literal|null
operator|&&
operator|!
name|afterCol
operator|.
name|trim
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|CANNOT_REORDER_COLUMNS
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
name|FieldSchema
name|column
init|=
literal|null
decl_stmt|;
name|boolean
name|found
init|=
literal|false
decl_stmt|;
name|int
name|position
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|first
condition|)
block|{
name|position
operator|=
literal|0
expr_stmt|;
block|}
name|int
name|i
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|iterOldCols
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FieldSchema
name|col
init|=
name|iterOldCols
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|oldColName
init|=
name|col
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldColName
operator|.
name|equalsIgnoreCase
argument_list|(
name|newName
argument_list|)
operator|&&
operator|!
name|oldColName
operator|.
name|equalsIgnoreCase
argument_list|(
name|oldName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|DUPLICATE_COLUMN_NAMES
argument_list|,
name|newName
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|oldColName
operator|.
name|equalsIgnoreCase
argument_list|(
name|oldName
argument_list|)
condition|)
block|{
name|col
operator|.
name|setName
argument_list|(
name|newName
argument_list|)
expr_stmt|;
if|if
condition|(
name|type
operator|!=
literal|null
operator|&&
operator|!
name|type
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
name|col
operator|.
name|setType
argument_list|(
name|type
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|comment
operator|!=
literal|null
condition|)
block|{
name|col
operator|.
name|setComment
argument_list|(
name|comment
argument_list|)
expr_stmt|;
block|}
name|found
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|first
operator|||
operator|(
name|afterCol
operator|!=
literal|null
operator|&&
operator|!
name|afterCol
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|)
condition|)
block|{
name|column
operator|=
name|col
expr_stmt|;
continue|continue;
block|}
block|}
if|if
condition|(
name|afterCol
operator|!=
literal|null
operator|&&
operator|!
name|afterCol
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|&&
name|oldColName
operator|.
name|equalsIgnoreCase
argument_list|(
name|afterCol
argument_list|)
condition|)
block|{
name|position
operator|=
name|i
expr_stmt|;
block|}
name|i
operator|++
expr_stmt|;
name|newCols
operator|.
name|add
argument_list|(
name|col
argument_list|)
expr_stmt|;
block|}
comment|// did not find the column
if|if
condition|(
operator|!
name|found
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_COLUMN
argument_list|,
name|oldName
argument_list|)
throw|;
block|}
comment|// after column is not null, but we did not find it.
if|if
condition|(
operator|(
name|afterCol
operator|!=
literal|null
operator|&&
operator|!
name|afterCol
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|)
operator|&&
name|position
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_COLUMN
argument_list|,
name|afterCol
argument_list|)
throw|;
block|}
if|if
condition|(
name|position
operator|>=
literal|0
condition|)
block|{
name|newCols
operator|.
name|add
argument_list|(
name|position
argument_list|,
name|column
argument_list|)
expr_stmt|;
block|}
name|sd
operator|.
name|setCols
argument_list|(
name|newCols
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|REPLACECOLS
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
comment|// change SerDe to LazySimpleSerDe if it is columnsetSerDe
name|String
name|serializationLib
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
if|if
condition|(
name|serializationLib
operator|.
name|equals
argument_list|(
literal|"org.apache.hadoop.hive.serde.thrift.columnsetSerDe"
argument_list|)
condition|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Replacing columns for columnsetSerDe and changing to LazySimpleSerDe"
argument_list|)
expr_stmt|;
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|serializationLib
operator|.
name|equals
argument_list|(
name|MetadataTypedColumnsetSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|serializationLib
operator|.
name|equals
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|serializationLib
operator|.
name|equals
argument_list|(
name|ColumnarSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|serializationLib
operator|.
name|equals
argument_list|(
name|DynamicSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|serializationLib
operator|.
name|equals
argument_list|(
name|ParquetHiveSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|serializationLib
operator|.
name|equals
argument_list|(
name|OrcSerde
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|CANNOT_REPLACE_COLUMNS
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
specifier|final
name|boolean
name|isOrcSchemaEvolution
init|=
name|serializationLib
operator|.
name|equals
argument_list|(
name|OrcSerde
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
name|isSchemaEvolutionEnabled
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
comment|// adding columns and limited integer type promotion is supported for ORC schema evolution
if|if
condition|(
name|isOrcSchemaEvolution
condition|)
block|{
specifier|final
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|existingCols
init|=
name|sd
operator|.
name|getCols
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|replaceCols
init|=
name|alterTbl
operator|.
name|getNewCols
argument_list|()
decl_stmt|;
if|if
condition|(
name|replaceCols
operator|.
name|size
argument_list|()
operator|<
name|existingCols
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|REPLACE_CANNOT_DROP_COLUMNS
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
block|}
name|boolean
name|partitioned
init|=
name|tbl
operator|.
name|isPartitioned
argument_list|()
decl_stmt|;
name|boolean
name|droppingColumns
init|=
name|alterTbl
operator|.
name|getNewCols
argument_list|()
operator|.
name|size
argument_list|()
operator|<
name|sd
operator|.
name|getCols
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|ParquetHiveSerDe
operator|.
name|isParquetTable
argument_list|(
name|tbl
argument_list|)
operator|&&
name|isSchemaEvolutionEnabled
argument_list|(
name|tbl
argument_list|)
operator|&&
operator|!
name|alterTbl
operator|.
name|getIsCascade
argument_list|()
operator|&&
name|droppingColumns
operator|&&
name|partitioned
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot drop columns from a partitioned parquet table without the CASCADE option"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|REPLACE_CANNOT_DROP_COLUMNS
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
name|sd
operator|.
name|setCols
argument_list|(
name|alterTbl
operator|.
name|getNewCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDPROPS
condition|)
block|{
return|return
name|alterTableAddProps
argument_list|(
name|alterTbl
argument_list|,
name|tbl
argument_list|,
name|part
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|DROPPROPS
condition|)
block|{
return|return
name|alterTableDropProps
argument_list|(
name|alterTbl
argument_list|,
name|tbl
argument_list|,
name|part
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDSERDEPROPS
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|putAll
argument_list|(
name|alterTbl
operator|.
name|getProps
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDSERDE
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
name|String
name|serdeName
init|=
name|alterTbl
operator|.
name|getSerdeName
argument_list|()
decl_stmt|;
name|String
name|oldSerdeName
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
comment|// if orc table, restrict changing the serde as it can break schema evolution
if|if
condition|(
name|isSchemaEvolutionEnabled
argument_list|(
name|tbl
argument_list|)
operator|&&
name|oldSerdeName
operator|.
name|equalsIgnoreCase
argument_list|(
name|OrcSerde
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|serdeName
operator|.
name|equalsIgnoreCase
argument_list|(
name|OrcSerde
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|CANNOT_CHANGE_SERDE
argument_list|,
name|OrcSerde
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|serdeName
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|alterTbl
operator|.
name|getProps
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|alterTbl
operator|.
name|getProps
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
condition|)
block|{
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|putAll
argument_list|(
name|alterTbl
operator|.
name|getProps
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|part
operator|!=
literal|null
condition|)
block|{
comment|// TODO: wtf? This doesn't do anything.
name|part
operator|.
name|getTPartition
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|setCols
argument_list|(
name|part
operator|.
name|getTPartition
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|Table
operator|.
name|shouldStoreFieldsInMetastore
argument_list|(
name|conf
argument_list|,
name|serdeName
argument_list|,
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|)
operator|&&
operator|!
name|Table
operator|.
name|hasMetastoreBasedSchema
argument_list|(
name|conf
argument_list|,
name|oldSerdeName
argument_list|)
condition|)
block|{
comment|// If new SerDe needs to store fields in metastore, but the old serde doesn't, save
comment|// the fields so that new SerDe could operate. Note that this may fail if some fields
comment|// from old SerDe are too long to be stored in metastore, but there's nothing we can do.
try|try
block|{
name|Deserializer
name|oldSerde
init|=
name|HiveMetaStoreUtils
operator|.
name|getDeserializer
argument_list|(
name|conf
argument_list|,
name|tbl
operator|.
name|getTTable
argument_list|()
argument_list|,
literal|false
argument_list|,
name|oldSerdeName
argument_list|)
decl_stmt|;
name|tbl
operator|.
name|setFields
argument_list|(
name|Hive
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|oldSerde
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDFILEFORMAT
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
comment|// if orc table, restrict changing the file format as it can break schema evolution
if|if
condition|(
name|isSchemaEvolutionEnabled
argument_list|(
name|tbl
argument_list|)
operator|&&
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|.
name|equals
argument_list|(
name|OrcInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|&&
operator|!
name|alterTbl
operator|.
name|getInputFormat
argument_list|()
operator|.
name|equals
argument_list|(
name|OrcInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|CANNOT_CHANGE_FILEFORMAT
argument_list|,
literal|"ORC"
argument_list|,
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
throw|;
block|}
name|sd
operator|.
name|setInputFormat
argument_list|(
name|alterTbl
operator|.
name|getInputFormat
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setOutputFormat
argument_list|(
name|alterTbl
operator|.
name|getOutputFormat
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|alterTbl
operator|.
name|getSerdeName
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|alterTbl
operator|.
name|getSerdeName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDCLUSTERSORTCOLUMN
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
comment|// validate sort columns and bucket columns
name|List
argument_list|<
name|String
argument_list|>
name|columns
init|=
name|Utilities
operator|.
name|getColumnNamesFromFieldSchema
argument_list|(
name|tbl
operator|.
name|getCols
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|alterTbl
operator|.
name|isTurnOffSorting
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|validateColumnNames
argument_list|(
name|columns
argument_list|,
name|alterTbl
operator|.
name|getBucketColumns
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getSortColumns
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|Utilities
operator|.
name|validateColumnNames
argument_list|(
name|columns
argument_list|,
name|Utilities
operator|.
name|getColumnNamesFromSortCols
argument_list|(
name|alterTbl
operator|.
name|getSortColumns
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|isTurnOffSorting
argument_list|()
condition|)
block|{
name|sd
operator|.
name|setSortCols
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Order
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getNumberBuckets
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
comment|// -1 buckets means to turn off bucketing
name|sd
operator|.
name|setBucketCols
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setNumBuckets
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setSortCols
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Order
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sd
operator|.
name|setBucketCols
argument_list|(
name|alterTbl
operator|.
name|getBucketColumns
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setNumBuckets
argument_list|(
name|alterTbl
operator|.
name|getNumberBuckets
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setSortCols
argument_list|(
name|alterTbl
operator|.
name|getSortColumns
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ALTERLOCATION
condition|)
block|{
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
name|String
name|newLocation
init|=
name|alterTbl
operator|.
name|getNewLocation
argument_list|()
decl_stmt|;
try|try
block|{
name|URI
name|locUri
init|=
operator|new
name|URI
argument_list|(
name|newLocation
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
operator|new
name|Path
argument_list|(
name|locUri
argument_list|)
operator|.
name|isAbsolute
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|BAD_LOCATION_VALUE
argument_list|,
name|newLocation
argument_list|)
throw|;
block|}
name|sd
operator|.
name|setLocation
argument_list|(
name|newLocation
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDSKEWEDBY
condition|)
block|{
comment|// Validation's been done at compile time. no validation is needed here.
name|List
argument_list|<
name|String
argument_list|>
name|skewedColNames
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|skewedValues
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|alterTbl
operator|.
name|isTurnOffSkewed
argument_list|()
condition|)
block|{
comment|// Convert skewed table to non-skewed table.
name|skewedColNames
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|skewedValues
operator|=
operator|new
name|ArrayList
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|skewedColNames
operator|=
name|alterTbl
operator|.
name|getSkewedColNames
argument_list|()
expr_stmt|;
name|skewedValues
operator|=
name|alterTbl
operator|.
name|getSkewedColValues
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
literal|null
operator|==
name|tbl
operator|.
name|getSkewedInfo
argument_list|()
condition|)
block|{
comment|// Convert non-skewed table to skewed table.
name|SkewedInfo
name|skewedInfo
init|=
operator|new
name|SkewedInfo
argument_list|()
decl_stmt|;
name|skewedInfo
operator|.
name|setSkewedColNames
argument_list|(
name|skewedColNames
argument_list|)
expr_stmt|;
name|skewedInfo
operator|.
name|setSkewedColValues
argument_list|(
name|skewedValues
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setSkewedInfo
argument_list|(
name|skewedInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tbl
operator|.
name|setSkewedColNames
argument_list|(
name|skewedColNames
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setSkewedColValues
argument_list|(
name|skewedValues
argument_list|)
expr_stmt|;
block|}
name|tbl
operator|.
name|setStoredAsSubDirectories
argument_list|(
name|alterTbl
operator|.
name|isStoredAsSubDirectories
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|OWNER
condition|)
block|{
if|if
condition|(
name|alterTbl
operator|.
name|getOwnerPrincipal
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|tbl
operator|.
name|setOwner
argument_list|(
name|alterTbl
operator|.
name|getOwnerPrincipal
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setOwnerType
argument_list|(
name|alterTbl
operator|.
name|getOwnerPrincipal
argument_list|()
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ALTERSKEWEDLOCATION
condition|)
block|{
comment|// process location one-by-one
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|locMaps
init|=
name|alterTbl
operator|.
name|getSkewedLocations
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|keys
init|=
name|locMaps
operator|.
name|keySet
argument_list|()
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|String
argument_list|>
name|key
range|:
name|keys
control|)
block|{
name|String
name|newLocation
init|=
name|locMaps
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
try|try
block|{
name|URI
name|locUri
init|=
operator|new
name|URI
argument_list|(
name|newLocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|part
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|slk
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|part
operator|.
name|setSkewedValueLocationMap
argument_list|(
name|slk
argument_list|,
name|locUri
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|String
argument_list|>
name|slk
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|tbl
operator|.
name|setSkewedValueLocationMap
argument_list|(
name|slk
argument_list|,
name|locUri
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|ALTERBUCKETNUM
condition|)
block|{
if|if
condition|(
name|part
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|part
operator|.
name|getBucketCount
argument_list|()
operator|==
name|alterTbl
operator|.
name|getNumberBuckets
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|part
operator|.
name|setBucketCount
argument_list|(
name|alterTbl
operator|.
name|getNumberBuckets
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|tbl
operator|.
name|getNumBuckets
argument_list|()
operator|==
name|alterTbl
operator|.
name|getNumberBuckets
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|tbl
operator|.
name|setNumBuckets
argument_list|(
name|alterTbl
operator|.
name|getNumberBuckets
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|==
name|AlterTableTypes
operator|.
name|UPDATECOLUMNS
condition|)
block|{
name|updateColumns
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|UNSUPPORTED_ALTER_TBL_OP
argument_list|,
name|alterTbl
operator|.
name|getOp
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
specifier|private
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|alterTableDropProps
parameter_list|(
name|AlterTableDesc
name|alterTbl
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Partition
name|part
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|StatsSetupConst
operator|.
name|USER
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
comment|// drop a stats parameter, which triggers recompute stats update automatically
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|part
operator|==
literal|null
condition|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|removedSet
init|=
name|alterTbl
operator|.
name|getProps
argument_list|()
operator|.
name|keySet
argument_list|()
decl_stmt|;
name|boolean
name|isFromMmTable
init|=
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|,
name|isRemoved
init|=
name|AcidUtils
operator|.
name|isRemovedInsertOnlyTable
argument_list|(
name|removedSet
argument_list|)
decl_stmt|;
if|if
condition|(
name|isFromMmTable
operator|&&
name|isRemoved
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Cannot convert an ACID table to non-ACID"
argument_list|)
throw|;
block|}
comment|// Check if external table property being removed
if|if
condition|(
name|removedSet
operator|.
name|contains
argument_list|(
literal|"EXTERNAL"
argument_list|)
operator|&&
name|tbl
operator|.
name|getTableType
argument_list|()
operator|==
name|TableType
operator|.
name|EXTERNAL_TABLE
condition|)
block|{
name|tbl
operator|.
name|setTableType
argument_list|(
name|TableType
operator|.
name|MANAGED_TABLE
argument_list|)
expr_stmt|;
block|}
block|}
name|Iterator
argument_list|<
name|String
argument_list|>
name|keyItr
init|=
name|alterTbl
operator|.
name|getProps
argument_list|()
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|keyItr
operator|.
name|hasNext
argument_list|()
condition|)
block|{
if|if
condition|(
name|part
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getTPartition
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|keyItr
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|keyItr
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
specifier|private
name|void
name|checkMmLb
parameter_list|(
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isStoredAsSubDirectories
argument_list|()
condition|)
block|{
return|return;
block|}
comment|// TODO [MM gap?]: by design; no-one seems to use LB tables. They will work, but not convert.
comment|//                 It's possible to work around this by re-creating and re-inserting the table.
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Converting list bucketed tables stored as subdirectories "
operator|+
literal|" to MM is not supported. Please re-create a table in the desired format."
argument_list|)
throw|;
block|}
specifier|private
name|void
name|checkMmLb
parameter_list|(
name|Partition
name|part
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|part
operator|.
name|isStoredAsSubDirectories
argument_list|()
condition|)
block|{
return|return;
block|}
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Converting list bucketed tables stored as subdirectories "
operator|+
literal|" to MM is not supported. Please re-create a table in the desired format."
argument_list|)
throw|;
block|}
specifier|private
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|generateAddMmTasks
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Long
name|writeId
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// We will move all the files in the table/partition directories into the first MM
comment|// directory, then commit the first write ID.
name|List
argument_list|<
name|Path
argument_list|>
name|srcs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|,
name|tgts
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|writeId
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Internal error - write ID not set for MM conversion"
argument_list|)
throw|;
block|}
name|int
name|stmtId
init|=
literal|0
decl_stmt|;
name|String
name|mmDir
init|=
name|AcidUtils
operator|.
name|deltaSubdir
argument_list|(
name|writeId
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|)
decl_stmt|;
name|Hive
name|db
init|=
name|getHive
argument_list|()
decl_stmt|;
if|if
condition|(
name|tbl
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|PartitionIterable
name|parts
init|=
operator|new
name|PartitionIterable
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|,
literal|null
argument_list|,
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|METASTORE_BATCH_RETRIEVE_MAX
argument_list|)
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Partition
argument_list|>
name|partIter
init|=
name|parts
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|partIter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Partition
name|part
init|=
name|partIter
operator|.
name|next
argument_list|()
decl_stmt|;
name|checkMmLb
argument_list|(
name|part
argument_list|)
expr_stmt|;
name|Path
name|src
init|=
name|part
operator|.
name|getDataLocation
argument_list|()
decl_stmt|,
name|tgt
init|=
operator|new
name|Path
argument_list|(
name|src
argument_list|,
name|mmDir
argument_list|)
decl_stmt|;
name|srcs
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
name|tgts
operator|.
name|add
argument_list|(
name|tgt
argument_list|)
expr_stmt|;
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Will move "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|tgt
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|checkMmLb
argument_list|(
name|tbl
argument_list|)
expr_stmt|;
name|Path
name|src
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
decl_stmt|,
name|tgt
init|=
operator|new
name|Path
argument_list|(
name|src
argument_list|,
name|mmDir
argument_list|)
decl_stmt|;
name|srcs
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
name|tgts
operator|.
name|add
argument_list|(
name|tgt
argument_list|)
expr_stmt|;
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Will move "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|tgt
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Don't set inputs and outputs - the locks have already been taken so it's pointless.
name|MoveWork
name|mw
init|=
operator|new
name|MoveWork
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|mw
operator|.
name|setMultiFilesDesc
argument_list|(
operator|new
name|LoadMultiFilesDesc
argument_list|(
name|srcs
argument_list|,
name|tgts
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|Lists
operator|.
expr|<
name|Task
argument_list|<
name|?
argument_list|>
operator|>
name|newArrayList
argument_list|(
name|TaskFactory
operator|.
name|get
argument_list|(
name|mw
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|alterTableAddProps
parameter_list|(
name|AlterTableDesc
name|alterTbl
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Partition
name|part
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|StatsSetupConst
operator|.
name|USER
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|Task
argument_list|<
name|?
argument_list|>
argument_list|>
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|part
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getTPartition
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|putAll
argument_list|(
name|alterTbl
operator|.
name|getProps
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|boolean
name|isFromMmTable
init|=
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
name|Boolean
name|isToMmTable
init|=
name|AcidUtils
operator|.
name|isToInsertOnlyTable
argument_list|(
name|tbl
argument_list|,
name|alterTbl
operator|.
name|getProps
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|isToMmTable
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|isFromMmTable
operator|&&
name|isToMmTable
condition|)
block|{
if|if
condition|(
operator|!
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_MM_ALLOW_ORIGINALS
argument_list|)
condition|)
block|{
name|result
operator|=
name|generateAddMmTasks
argument_list|(
name|tbl
argument_list|,
name|alterTbl
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|tbl
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|Hive
name|db
init|=
name|getHive
argument_list|()
decl_stmt|;
name|PartitionIterable
name|parts
init|=
operator|new
name|PartitionIterable
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|,
literal|null
argument_list|,
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|METASTORE_BATCH_RETRIEVE_MAX
argument_list|)
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Partition
argument_list|>
name|partIter
init|=
name|parts
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|partIter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Partition
name|part0
init|=
name|partIter
operator|.
name|next
argument_list|()
decl_stmt|;
name|checkMmLb
argument_list|(
name|part0
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|checkMmLb
argument_list|(
name|tbl
argument_list|)
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|isFromMmTable
operator|&&
operator|!
name|isToMmTable
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Cannot convert an ACID table to non-ACID"
argument_list|)
throw|;
block|}
block|}
comment|// Converting to/from external table
name|String
name|externalProp
init|=
name|alterTbl
operator|.
name|getProps
argument_list|()
operator|.
name|get
argument_list|(
literal|"EXTERNAL"
argument_list|)
decl_stmt|;
if|if
condition|(
name|externalProp
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|externalProp
argument_list|)
operator|&&
name|tbl
operator|.
name|getTableType
argument_list|()
operator|==
name|TableType
operator|.
name|MANAGED_TABLE
condition|)
block|{
name|tbl
operator|.
name|setTableType
argument_list|(
name|TableType
operator|.
name|EXTERNAL_TABLE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|externalProp
argument_list|)
operator|&&
name|tbl
operator|.
name|getTableType
argument_list|()
operator|==
name|TableType
operator|.
name|EXTERNAL_TABLE
condition|)
block|{
name|tbl
operator|.
name|setTableType
argument_list|(
name|TableType
operator|.
name|MANAGED_TABLE
argument_list|)
expr_stmt|;
block|}
block|}
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|putAll
argument_list|(
name|alterTbl
operator|.
name|getProps
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
specifier|private
name|int
name|dropConstraint
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableDesc
name|alterTbl
parameter_list|)
throws|throws
name|SemanticException
throws|,
name|HiveException
block|{
try|try
block|{
name|db
operator|.
name|dropConstraint
argument_list|(
name|Utilities
operator|.
name|getDatabaseName
argument_list|(
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
argument_list|,
name|Utilities
operator|.
name|getTableName
argument_list|(
name|alterTbl
operator|.
name|getOldName
argument_list|()
argument_list|)
argument_list|,
name|alterTbl
operator|.
name|getConstraintName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|addConstraints
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableDesc
name|alterTbl
parameter_list|)
throws|throws
name|SemanticException
throws|,
name|HiveException
block|{
try|try
block|{
comment|// This is either an alter table add foreign key or add primary key command.
if|if
condition|(
name|alterTbl
operator|.
name|getPrimaryKeyCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|alterTbl
operator|.
name|getPrimaryKeyCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|db
operator|.
name|addPrimaryKey
argument_list|(
name|alterTbl
operator|.
name|getPrimaryKeyCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getForeignKeyCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|alterTbl
operator|.
name|getForeignKeyCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|db
operator|.
name|addForeignKey
argument_list|(
name|alterTbl
operator|.
name|getForeignKeyCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getCause
argument_list|()
operator|instanceof
name|InvalidObjectException
operator|&&
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
operator|!=
literal|null
operator|&&
name|alterTbl
operator|.
name|getReplicationSpec
argument_list|()
operator|.
name|isInReplicationScope
argument_list|()
condition|)
block|{
comment|// During repl load, NoSuchObjectException in foreign key shall
comment|// ignore as the foreign table may not be part of the replication
name|LOG
operator|.
name|debug
argument_list|(
literal|"InvalidObjectException: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getUniqueConstraintCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|alterTbl
operator|.
name|getUniqueConstraintCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|db
operator|.
name|addUniqueConstraint
argument_list|(
name|alterTbl
operator|.
name|getUniqueConstraintCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getNotNullConstraintCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|alterTbl
operator|.
name|getNotNullConstraintCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|db
operator|.
name|addNotNullConstraint
argument_list|(
name|alterTbl
operator|.
name|getNotNullConstraintCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getDefaultConstraintCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|alterTbl
operator|.
name|getDefaultConstraintCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|db
operator|.
name|addDefaultConstraint
argument_list|(
name|alterTbl
operator|.
name|getDefaultConstraintCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|alterTbl
operator|.
name|getCheckConstraintCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|alterTbl
operator|.
name|getCheckConstraintCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|db
operator|.
name|addCheckConstraint
argument_list|(
name|alterTbl
operator|.
name|getCheckConstraintCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|int
name|updateColumns
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Partition
name|part
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
name|serializationLib
init|=
name|tbl
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
if|if
condition|(
name|MetastoreConf
operator|.
name|getStringCollection
argument_list|(
name|conf
argument_list|,
name|MetastoreConf
operator|.
name|ConfVars
operator|.
name|SERDES_USING_METASTORE_FOR_SCHEMA
argument_list|)
operator|.
name|contains
argument_list|(
name|serializationLib
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" has serde "
operator|+
name|serializationLib
operator|+
literal|" for which schema "
operator|+
literal|"is already handled by HMS."
argument_list|)
throw|;
block|}
name|Deserializer
name|deserializer
init|=
name|tbl
operator|.
name|getDeserializer
argument_list|(
literal|true
argument_list|)
decl_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating metastore columns for table: {}"
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
specifier|final
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fields
init|=
name|HiveMetaStoreUtils
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|deserializer
argument_list|)
decl_stmt|;
name|StorageDescriptor
name|sd
init|=
name|retrieveStorageDescriptor
argument_list|(
name|tbl
argument_list|,
name|part
argument_list|)
decl_stmt|;
name|sd
operator|.
name|setCols
argument_list|(
name|fields
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
decl||
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"alter table update columns: {}"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|,
name|ErrorMsg
operator|.
name|GENERIC_ERROR
argument_list|)
throw|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * Drop a given partitions.    *    * @param db    *          The database in question.    * @param dropPartition    *          This is the partition we're dropping.    * @throws HiveException    *           Throws this exception if an unexpected error occurs.    */
specifier|private
name|void
name|dropPartitions
parameter_list|(
name|Hive
name|db
parameter_list|,
name|DropPartitionDesc
name|dropPartition
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// We need to fetch the table before it is dropped so that it can be passed to
comment|// post-execution hook
name|Table
name|tbl
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tbl
operator|=
name|db
operator|.
name|getTable
argument_list|(
name|dropPartition
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidTableException
name|e
parameter_list|)
block|{
comment|// drop table is idempotent
block|}
name|ReplicationSpec
name|replicationSpec
init|=
name|dropPartition
operator|.
name|getReplicationSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|replicationSpec
operator|.
name|isInReplicationScope
argument_list|()
condition|)
block|{
comment|/**        * ALTER TABLE DROP PARTITION ... FOR REPLICATION(x) behaves as a DROP PARTITION IF OLDER THAN x        *        * So, we check each partition that matches our DropTableDesc.getPartSpecs(), and drop it only        * if it's older than the event that spawned this replicated request to drop partition        */
comment|// TODO: Current implementation of replication will result in DROP_PARTITION under replication
comment|// scope being called per-partition instead of multiple partitions. However, to be robust, we
comment|// must still handle the case of multiple partitions in case this assumption changes in the
comment|// future. However, if this assumption changes, we will not be very performant if we fetch
comment|// each partition one-by-one, and then decide on inspection whether or not this is a candidate
comment|// for dropping. Thus, we need a way to push this filter (replicationSpec.allowEventReplacementInto)
comment|// to the  metastore to allow it to do drop a partition or not, depending on a Predicate on the
comment|// parameter key values.
if|if
condition|(
name|tbl
operator|==
literal|null
condition|)
block|{
comment|// If table is missing, then partitions are also would've been dropped. Just no-op.
return|return;
block|}
for|for
control|(
name|DropPartitionDesc
operator|.
name|PartSpec
name|partSpec
range|:
name|dropPartition
operator|.
name|getPartSpecs
argument_list|()
control|)
block|{
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
try|try
block|{
name|db
operator|.
name|getPartitionsByExpr
argument_list|(
name|tbl
argument_list|,
name|partSpec
operator|.
name|getPartSpec
argument_list|()
argument_list|,
name|conf
argument_list|,
name|partitions
argument_list|)
expr_stmt|;
for|for
control|(
name|Partition
name|p
range|:
name|Iterables
operator|.
name|filter
argument_list|(
name|partitions
argument_list|,
name|replicationSpec
operator|.
name|allowEventReplacementInto
argument_list|()
argument_list|)
control|)
block|{
name|db
operator|.
name|dropPartition
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|p
operator|.
name|getValues
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
comment|// ignore NSOE because that means there's nothing to drop.
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
return|return;
block|}
comment|// ifExists is currently verified in DDLSemanticAnalyzer
name|List
argument_list|<
name|Partition
argument_list|>
name|droppedParts
init|=
name|db
operator|.
name|dropPartitions
argument_list|(
name|dropPartition
operator|.
name|getTableName
argument_list|()
argument_list|,
name|dropPartition
operator|.
name|getPartSpecs
argument_list|()
argument_list|,
name|PartitionDropOptions
operator|.
name|instance
argument_list|()
operator|.
name|deleteData
argument_list|(
literal|true
argument_list|)
operator|.
name|ifExists
argument_list|(
literal|true
argument_list|)
operator|.
name|purgeData
argument_list|(
name|dropPartition
operator|.
name|getIfPurge
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|partition
range|:
name|droppedParts
control|)
block|{
name|console
operator|.
name|printInfo
argument_list|(
literal|"Dropped the partition "
operator|+
name|partition
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
comment|// We have already locked the table, don't lock the partitions.
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|partition
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_NO_LOCK
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Update last_modified_by and last_modified_time parameters in parameter map.    *    * @param params    *          Parameters.    * @param conf    *          HiveConf of session    */
specifier|private
name|boolean
name|updateModifiedParameters
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
name|user
init|=
literal|null
decl_stmt|;
name|user
operator|=
name|SessionState
operator|.
name|getUserFromAuthenticator
argument_list|()
expr_stmt|;
name|params
operator|.
name|put
argument_list|(
literal|"last_modified_by"
argument_list|,
name|user
argument_list|)
expr_stmt|;
name|params
operator|.
name|put
argument_list|(
literal|"last_modified_time"
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|/
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Check if the given serde is valid.    */
specifier|public
specifier|static
name|void
name|validateSerDe
parameter_list|(
name|String
name|serdeName
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|Deserializer
name|d
init|=
name|ReflectionUtil
operator|.
name|newInstance
argument_list|(
name|conf
operator|.
name|getClassByName
argument_list|(
name|serdeName
argument_list|)
operator|.
name|asSubclass
argument_list|(
name|Deserializer
operator|.
name|class
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|d
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found class for {}"
argument_list|,
name|serdeName
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Cannot validate serde: "
operator|+
name|serdeName
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|int
name|exchangeTablePartition
parameter_list|(
name|Hive
name|db
parameter_list|,
name|AlterTableExchangePartition
name|exchangePartition
parameter_list|)
throws|throws
name|HiveException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionSpecs
init|=
name|exchangePartition
operator|.
name|getPartitionSpecs
argument_list|()
decl_stmt|;
name|Table
name|destTable
init|=
name|exchangePartition
operator|.
name|getDestinationTable
argument_list|()
decl_stmt|;
name|Table
name|sourceTable
init|=
name|exchangePartition
operator|.
name|getSourceTable
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|db
operator|.
name|exchangeTablePartitions
argument_list|(
name|partitionSpecs
argument_list|,
name|sourceTable
operator|.
name|getDbName
argument_list|()
argument_list|,
name|sourceTable
operator|.
name|getTableName
argument_list|()
argument_list|,
name|destTable
operator|.
name|getDbName
argument_list|()
argument_list|,
name|destTable
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|partition
range|:
name|partitions
control|)
block|{
comment|// Reuse the partition specs from dest partition since they should be the same
name|work
operator|.
name|getInputs
argument_list|()
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
operator|new
name|Partition
argument_list|(
name|sourceTable
argument_list|,
name|partition
operator|.
name|getSpec
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
operator|new
name|Partition
argument_list|(
name|sourceTable
argument_list|,
name|partition
operator|.
name|getSpec
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DELETE
argument_list|)
argument_list|)
expr_stmt|;
name|addIfAbsentByName
argument_list|(
operator|new
name|WriteEntity
argument_list|(
operator|new
name|Partition
argument_list|(
name|destTable
argument_list|,
name|partition
operator|.
name|getSpec
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|INSERT
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|StageType
name|getType
parameter_list|()
block|{
return|return
name|StageType
operator|.
name|DDL
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
literal|"DDL"
return|;
block|}
comment|/**    * Validate if the given table/partition is eligible for update    *    * @param db Database.    * @param tableName Table name of format db.table    * @param partSpec Partition spec for the partition    * @param replicationSpec Replications specification    *    * @return boolean true if allow the operation    * @throws HiveException    */
specifier|private
name|boolean
name|allowOperationInReplicationScope
parameter_list|(
name|Hive
name|db
parameter_list|,
name|String
name|tableName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|ReplicationSpec
name|replicationSpec
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|(
literal|null
operator|==
name|replicationSpec
operator|)
operator|||
operator|(
operator|!
name|replicationSpec
operator|.
name|isInReplicationScope
argument_list|()
operator|)
condition|)
block|{
comment|// Always allow the operation if it is not in replication scope.
return|return
literal|true
return|;
block|}
comment|// If the table/partition exist and is older than the event, then just apply
comment|// the event else noop.
name|Table
name|existingTable
init|=
name|db
operator|.
name|getTable
argument_list|(
name|tableName
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|existingTable
operator|!=
literal|null
operator|)
operator|&&
name|replicationSpec
operator|.
name|allowEventReplacementInto
argument_list|(
name|existingTable
operator|.
name|getParameters
argument_list|()
argument_list|)
condition|)
block|{
comment|// Table exists and is older than the update. Now, need to ensure if update allowed on the
comment|// partition.
if|if
condition|(
name|partSpec
operator|!=
literal|null
condition|)
block|{
name|Partition
name|existingPtn
init|=
name|db
operator|.
name|getPartition
argument_list|(
name|existingTable
argument_list|,
name|partSpec
argument_list|,
literal|false
argument_list|)
decl_stmt|;
return|return
operator|(
operator|(
name|existingPtn
operator|!=
literal|null
operator|)
operator|&&
name|replicationSpec
operator|.
name|allowEventReplacementInto
argument_list|(
name|existingPtn
operator|.
name|getParameters
argument_list|()
argument_list|)
operator|)
return|;
block|}
comment|// Replacement is allowed as the existing table is older than event
return|return
literal|true
return|;
block|}
comment|// The table is missing either due to drop/rename which follows the operation.
comment|// Or the existing table is newer than our update. So, don't allow the update.
return|return
literal|false
return|;
block|}
specifier|private
name|int
name|remFirstIncPendFlag
parameter_list|(
name|Hive
name|hive
parameter_list|,
name|ReplRemoveFirstIncLoadPendFlagDesc
name|desc
parameter_list|)
throws|throws
name|HiveException
throws|,
name|TException
block|{
name|String
name|dbNameOrPattern
init|=
name|desc
operator|.
name|getDatabaseName
argument_list|()
decl_stmt|;
name|String
name|tableNameOrPattern
init|=
name|desc
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
decl_stmt|;
comment|// For database level load tableNameOrPattern will be null. Flag is set only in database for db level load.
if|if
condition|(
name|tableNameOrPattern
operator|!=
literal|null
operator|&&
operator|!
name|tableNameOrPattern
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// For table level load, dbNameOrPattern is db name and not a pattern.
for|for
control|(
name|String
name|tableName
range|:
name|Utils
operator|.
name|matchesTbl
argument_list|(
name|hive
argument_list|,
name|dbNameOrPattern
argument_list|,
name|tableNameOrPattern
argument_list|)
control|)
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tbl
init|=
name|hive
operator|.
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|dbNameOrPattern
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|parameters
operator|=
name|tbl
operator|.
name|getParameters
argument_list|()
expr_stmt|;
name|String
name|incPendPara
init|=
name|parameters
operator|!=
literal|null
condition|?
name|parameters
operator|.
name|get
argument_list|(
name|ReplUtils
operator|.
name|REPL_FIRST_INC_PENDING_FLAG
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|incPendPara
operator|!=
literal|null
condition|)
block|{
name|parameters
operator|.
name|remove
argument_list|(
name|ReplUtils
operator|.
name|REPL_FIRST_INC_PENDING_FLAG
argument_list|)
expr_stmt|;
name|hive
operator|.
name|getMSC
argument_list|()
operator|.
name|alter_table
argument_list|(
name|dbNameOrPattern
argument_list|,
name|tableName
argument_list|,
name|tbl
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
for|for
control|(
name|String
name|dbName
range|:
name|Utils
operator|.
name|matchesDb
argument_list|(
name|hive
argument_list|,
name|dbNameOrPattern
argument_list|)
control|)
block|{
name|Database
name|database
init|=
name|hive
operator|.
name|getMSC
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|dbName
argument_list|)
decl_stmt|;
name|parameters
operator|=
name|database
operator|.
name|getParameters
argument_list|()
expr_stmt|;
name|String
name|incPendPara
init|=
name|parameters
operator|!=
literal|null
condition|?
name|parameters
operator|.
name|get
argument_list|(
name|ReplUtils
operator|.
name|REPL_FIRST_INC_PENDING_FLAG
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|incPendPara
operator|!=
literal|null
condition|)
block|{
name|parameters
operator|.
name|remove
argument_list|(
name|ReplUtils
operator|.
name|REPL_FIRST_INC_PENDING_FLAG
argument_list|)
expr_stmt|;
name|hive
operator|.
name|getMSC
argument_list|()
operator|.
name|alterDatabase
argument_list|(
name|dbName
argument_list|,
name|database
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
literal|0
return|;
block|}
comment|/*   uses the authorizer from SessionState will need some more work to get this to run in parallel,   however this should not be a bottle neck so might not need to parallelize this.    */
annotation|@
name|Override
specifier|public
name|boolean
name|canExecuteInParallel
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
block|}
end_class

end_unit

