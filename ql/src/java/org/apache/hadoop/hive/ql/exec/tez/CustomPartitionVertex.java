begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|LinkedListMultimap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|split
operator|.
name|SplitLocationProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|api
operator|.
name|events
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezWork
operator|.
name|VertexType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|DataOutputBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|serializer
operator|.
name|SerializationFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|split
operator|.
name|TezGroupedSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|split
operator|.
name|TezMapReduceSplitsGrouper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|common
operator|.
name|TezUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeProperty
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeProperty
operator|.
name|DataMovementType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeManagerPluginDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|InputDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|UserPayload
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|VertexLocationHint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|VertexManagerPlugin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|VertexManagerPluginContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MRInputHelpers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|protos
operator|.
name|MRRuntimeProtos
operator|.
name|MRInputUserPayloadProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|protos
operator|.
name|MRRuntimeProtos
operator|.
name|MRSplitProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|api
operator|.
name|Event
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|api
operator|.
name|InputSpecUpdate
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ArrayListMultimap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|HashMultimap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Multimap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|ByteString
import|;
end_import

begin_comment
comment|/*  * This is the central piece for Bucket Map Join and SMB join. It has the following  * responsibilities:  * 1. Group incoming splits based on bucketing.  * 2. Generate new serialized events for the grouped splits.  * 3. Create a routing table for the bucket map join and send a serialized version as payload  * for the EdgeManager.  * 4. For SMB join, generate a grouping according to bucketing for the "small" table side.  */
end_comment

begin_class
specifier|public
class|class
name|CustomPartitionVertex
extends|extends
name|VertexManagerPlugin
block|{
specifier|public
class|class
name|PathComparatorForSplit
implements|implements
name|Comparator
argument_list|<
name|InputSplit
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|InputSplit
name|inp1
parameter_list|,
name|InputSplit
name|inp2
parameter_list|)
block|{
name|FileSplit
name|fs1
init|=
operator|(
name|FileSplit
operator|)
name|inp1
decl_stmt|;
name|FileSplit
name|fs2
init|=
operator|(
name|FileSplit
operator|)
name|inp2
decl_stmt|;
name|int
name|retval
init|=
name|fs1
operator|.
name|getPath
argument_list|()
operator|.
name|compareTo
argument_list|(
name|fs2
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|retval
operator|!=
literal|0
condition|)
block|{
return|return
name|retval
return|;
block|}
if|if
condition|(
name|fs1
operator|.
name|getStart
argument_list|()
operator|!=
name|fs2
operator|.
name|getStart
argument_list|()
condition|)
block|{
return|return
call|(
name|int
call|)
argument_list|(
name|fs1
operator|.
name|getStart
argument_list|()
operator|-
name|fs2
operator|.
name|getStart
argument_list|()
argument_list|)
return|;
block|}
return|return
literal|0
return|;
block|}
block|}
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|CustomPartitionVertex
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|VertexManagerPluginContext
name|context
decl_stmt|;
specifier|private
name|InputConfigureVertexTasksEvent
name|configureVertexTaskEvent
decl_stmt|;
specifier|private
name|int
name|numBuckets
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|Configuration
name|conf
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|SplitGrouper
name|grouper
init|=
operator|new
name|SplitGrouper
argument_list|()
decl_stmt|;
specifier|private
name|int
name|taskCount
init|=
literal|0
decl_stmt|;
specifier|private
name|VertexType
name|vertexType
decl_stmt|;
specifier|private
name|String
name|mainWorkName
decl_stmt|;
specifier|private
specifier|final
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|Integer
argument_list|>
name|bucketToTaskMap
init|=
name|HashMultimap
operator|.
expr|<
name|Integer
decl_stmt|,
name|Integer
decl|>
name|create
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
argument_list|>
name|inputToGroupedSplitMap
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
name|int
name|numInputsAffectingRootInputSpecUpdate
init|=
literal|1
decl_stmt|;
specifier|private
name|int
name|numInputsSeenSoFar
init|=
literal|0
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|EdgeManagerPluginDescriptor
argument_list|>
name|emMap
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|InputSplit
argument_list|>
name|finalSplits
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|InputSpecUpdate
argument_list|>
name|inputNameInputSpecMap
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|InputSpecUpdate
argument_list|>
argument_list|()
decl_stmt|;
specifier|public
name|CustomPartitionVertex
parameter_list|(
name|VertexManagerPluginContext
name|context
parameter_list|)
block|{
name|super
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|initialize
parameter_list|()
block|{
name|this
operator|.
name|context
operator|=
name|getContext
argument_list|()
expr_stmt|;
name|ByteBuffer
name|payload
init|=
name|context
operator|.
name|getUserPayload
argument_list|()
operator|.
name|getPayload
argument_list|()
decl_stmt|;
name|CustomVertexConfiguration
name|vertexConf
init|=
operator|new
name|CustomVertexConfiguration
argument_list|()
decl_stmt|;
name|DataInputByteBuffer
name|dibb
init|=
operator|new
name|DataInputByteBuffer
argument_list|()
decl_stmt|;
name|dibb
operator|.
name|reset
argument_list|(
name|payload
argument_list|)
expr_stmt|;
try|try
block|{
name|vertexConf
operator|.
name|readFields
argument_list|(
name|dibb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|this
operator|.
name|numBuckets
operator|=
name|vertexConf
operator|.
name|getNumBuckets
argument_list|()
expr_stmt|;
name|this
operator|.
name|mainWorkName
operator|=
name|vertexConf
operator|.
name|getInputName
argument_list|()
expr_stmt|;
name|this
operator|.
name|vertexType
operator|=
name|vertexConf
operator|.
name|getVertexType
argument_list|()
expr_stmt|;
name|this
operator|.
name|numInputsAffectingRootInputSpecUpdate
operator|=
name|vertexConf
operator|.
name|getNumInputs
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|onVertexStarted
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|Integer
argument_list|>
argument_list|>
name|completions
parameter_list|)
block|{
name|int
name|numTasks
init|=
name|context
operator|.
name|getVertexNumTasks
argument_list|(
name|context
operator|.
name|getVertexName
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|VertexManagerPluginContext
operator|.
name|TaskWithLocationHint
argument_list|>
name|scheduledTasks
init|=
operator|new
name|ArrayList
argument_list|<
name|VertexManagerPluginContext
operator|.
name|TaskWithLocationHint
argument_list|>
argument_list|(
name|numTasks
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numTasks
condition|;
operator|++
name|i
control|)
block|{
name|scheduledTasks
operator|.
name|add
argument_list|(
operator|new
name|VertexManagerPluginContext
operator|.
name|TaskWithLocationHint
argument_list|(
operator|new
name|Integer
argument_list|(
name|i
argument_list|)
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|context
operator|.
name|scheduleVertexTasks
argument_list|(
name|scheduledTasks
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|onSourceTaskCompleted
parameter_list|(
name|String
name|srcVertexName
parameter_list|,
name|Integer
name|attemptId
parameter_list|)
block|{   }
annotation|@
name|Override
specifier|public
name|void
name|onVertexManagerEventReceived
parameter_list|(
name|VertexManagerEvent
name|vmEvent
parameter_list|)
block|{   }
comment|// One call per root Input
annotation|@
name|Override
specifier|public
name|void
name|onRootVertexInitialized
parameter_list|(
name|String
name|inputName
parameter_list|,
name|InputDescriptor
name|inputDescriptor
parameter_list|,
name|List
argument_list|<
name|Event
argument_list|>
name|events
parameter_list|)
block|{
name|numInputsSeenSoFar
operator|++
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"On root vertex initialized "
operator|+
name|inputName
argument_list|)
expr_stmt|;
try|try
block|{
comment|// This is using the payload from the RootVertexInitializer corresponding
comment|// to InputName. Ideally it should be using it's own configuration class -
comment|// but that
comment|// means serializing another instance.
name|MRInputUserPayloadProto
name|protoPayload
init|=
name|MRInputHelpers
operator|.
name|parseMRInputPayload
argument_list|(
name|inputDescriptor
operator|.
name|getUserPayload
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|conf
operator|=
name|TezUtils
operator|.
name|createConfFromByteString
argument_list|(
name|protoPayload
operator|.
name|getConfigurationBytes
argument_list|()
argument_list|)
expr_stmt|;
comment|/*        * Currently in tez, the flow of events is thus:        * "Generate Splits -> Initialize Vertex" (with parallelism info obtained        * from the generate splits phase). The generate splits phase groups        * splits using the TezGroupedSplitsInputFormat. However, for bucket map        * joins the grouping done by this input format results in incorrect        * results as the grouper has no knowledge of buckets. So, we initially        * set the input format to be HiveInputFormat (in DagUtils) for the case        * of bucket map joins so as to obtain un-grouped splits. We then group        * the splits corresponding to buckets using the tez grouper which returns        * TezGroupedSplits.        */
comment|// This assumes that Grouping will always be used.
comment|// Enabling grouping on the payload.
name|MRInputUserPayloadProto
name|updatedPayload
init|=
name|MRInputUserPayloadProto
operator|.
name|newBuilder
argument_list|(
name|protoPayload
argument_list|)
operator|.
name|setGroupingEnabled
argument_list|(
literal|true
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|inputDescriptor
operator|.
name|setUserPayload
argument_list|(
name|UserPayload
operator|.
name|create
argument_list|(
name|updatedPayload
operator|.
name|toByteString
argument_list|()
operator|.
name|asReadOnlyByteBuffer
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|boolean
name|dataInformationEventSeen
init|=
literal|false
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Set
argument_list|<
name|FileSplit
argument_list|>
argument_list|>
name|pathFileSplitsMap
init|=
operator|new
name|TreeMap
argument_list|<
name|String
argument_list|,
name|Set
argument_list|<
name|FileSplit
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Event
name|event
range|:
name|events
control|)
block|{
if|if
condition|(
name|event
operator|instanceof
name|InputConfigureVertexTasksEvent
condition|)
block|{
comment|// No tasks should have been started yet. Checked by initial state
comment|// check.
name|LOG
operator|.
name|info
argument_list|(
literal|"Got a input configure vertex event for input: "
operator|+
name|inputName
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|dataInformationEventSeen
operator|==
literal|false
argument_list|)
expr_stmt|;
name|InputConfigureVertexTasksEvent
name|cEvent
init|=
operator|(
name|InputConfigureVertexTasksEvent
operator|)
name|event
decl_stmt|;
comment|// The vertex cannot be configured until all DataEvents are seen - to
comment|// build the routing table.
name|configureVertexTaskEvent
operator|=
name|cEvent
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Configure task for input name: "
operator|+
name|inputName
operator|+
literal|" num tasks: "
operator|+
name|configureVertexTaskEvent
operator|.
name|getNumTasks
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|event
operator|instanceof
name|InputUpdatePayloadEvent
condition|)
block|{
comment|// this event can never occur. If it does, fail.
name|Preconditions
operator|.
name|checkState
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|event
operator|instanceof
name|InputDataInformationEvent
condition|)
block|{
name|dataInformationEventSeen
operator|=
literal|true
expr_stmt|;
name|InputDataInformationEvent
name|diEvent
init|=
operator|(
name|InputDataInformationEvent
operator|)
name|event
decl_stmt|;
name|FileSplit
name|fileSplit
decl_stmt|;
try|try
block|{
name|fileSplit
operator|=
name|getFileSplitFromEvent
argument_list|(
name|diEvent
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed to get file split for event: "
operator|+
name|diEvent
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Set
argument_list|<
name|FileSplit
argument_list|>
name|fsList
init|=
name|pathFileSplitsMap
operator|.
name|get
argument_list|(
name|Utilities
operator|.
name|getBucketFileNameFromPathSubString
argument_list|(
name|fileSplit
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fsList
operator|==
literal|null
condition|)
block|{
name|fsList
operator|=
operator|new
name|TreeSet
argument_list|<
name|FileSplit
argument_list|>
argument_list|(
operator|new
name|PathComparatorForSplit
argument_list|()
argument_list|)
expr_stmt|;
name|pathFileSplitsMap
operator|.
name|put
argument_list|(
name|Utilities
operator|.
name|getBucketFileNameFromPathSubString
argument_list|(
name|fileSplit
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|fsList
argument_list|)
expr_stmt|;
block|}
name|fsList
operator|.
name|add
argument_list|(
name|fileSplit
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path file splits map for input name: "
operator|+
name|inputName
operator|+
literal|" is "
operator|+
name|pathFileSplitsMap
argument_list|)
expr_stmt|;
block|}
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|bucketToInitialSplitMap
init|=
name|getBucketSplitMapForPath
argument_list|(
name|pathFileSplitsMap
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|totalResource
init|=
name|context
operator|.
name|getTotalAvailableResource
argument_list|()
operator|.
name|getMemory
argument_list|()
decl_stmt|;
name|int
name|taskResource
init|=
name|context
operator|.
name|getVertexTaskResource
argument_list|()
operator|.
name|getMemory
argument_list|()
decl_stmt|;
name|float
name|waves
init|=
name|conf
operator|.
name|getFloat
argument_list|(
name|TezMapReduceSplitsGrouper
operator|.
name|TEZ_GROUPING_SPLIT_WAVES
argument_list|,
name|TezMapReduceSplitsGrouper
operator|.
name|TEZ_GROUPING_SPLIT_WAVES_DEFAULT
argument_list|)
decl_stmt|;
name|int
name|availableSlots
init|=
name|totalResource
operator|/
name|taskResource
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Grouping splits. "
operator|+
name|availableSlots
operator|+
literal|" available slots, "
operator|+
name|waves
operator|+
literal|" waves. Bucket initial splits map: "
operator|+
name|bucketToInitialSplitMap
argument_list|)
expr_stmt|;
block|}
name|JobConf
name|jobConf
init|=
operator|new
name|JobConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getMergedCredentials
argument_list|(
name|jobConf
argument_list|)
expr_stmt|;
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|bucketToGroupedSplitMap
init|=
name|HashMultimap
operator|.
expr|<
name|Integer
decl_stmt|,
name|InputSplit
decl|>
name|create
argument_list|()
decl_stmt|;
name|boolean
name|secondLevelGroupingDone
init|=
literal|false
decl_stmt|;
if|if
condition|(
operator|(
name|mainWorkName
operator|.
name|isEmpty
argument_list|()
operator|)
operator|||
operator|(
name|inputName
operator|.
name|compareTo
argument_list|(
name|mainWorkName
argument_list|)
operator|==
literal|0
operator|)
condition|)
block|{
name|SplitLocationProvider
name|splitLocationProvider
init|=
name|Utils
operator|.
name|getSplitLocationProvider
argument_list|(
name|conf
argument_list|,
name|LOG
argument_list|)
decl_stmt|;
for|for
control|(
name|Integer
name|key
range|:
name|bucketToInitialSplitMap
operator|.
name|keySet
argument_list|()
control|)
block|{
name|InputSplit
index|[]
name|inputSplitArray
init|=
operator|(
name|bucketToInitialSplitMap
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|.
name|toArray
argument_list|(
operator|new
name|InputSplit
index|[
literal|0
index|]
argument_list|)
operator|)
decl_stmt|;
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|groupedSplit
init|=
name|grouper
operator|.
name|generateGroupedSplits
argument_list|(
name|jobConf
argument_list|,
name|conf
argument_list|,
name|inputSplitArray
argument_list|,
name|waves
argument_list|,
name|availableSlots
argument_list|,
name|inputName
argument_list|,
name|mainWorkName
operator|.
name|isEmpty
argument_list|()
argument_list|,
name|splitLocationProvider
argument_list|)
decl_stmt|;
if|if
condition|(
name|mainWorkName
operator|.
name|isEmpty
argument_list|()
operator|==
literal|false
condition|)
block|{
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|singleBucketToGroupedSplit
init|=
name|HashMultimap
operator|.
expr|<
name|Integer
decl_stmt|,
name|InputSplit
decl|>
name|create
argument_list|()
decl_stmt|;
name|singleBucketToGroupedSplit
operator|.
name|putAll
argument_list|(
name|key
argument_list|,
name|groupedSplit
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
name|groupedSplit
operator|=
name|grouper
operator|.
name|group
argument_list|(
name|jobConf
argument_list|,
name|singleBucketToGroupedSplit
argument_list|,
name|availableSlots
argument_list|,
name|HiveConf
operator|.
name|getFloatVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|TEZ_SMB_NUMBER_WAVES
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|secondLevelGroupingDone
operator|=
literal|true
expr_stmt|;
block|}
name|bucketToGroupedSplitMap
operator|.
name|putAll
argument_list|(
name|key
argument_list|,
name|groupedSplit
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|processAllEvents
argument_list|(
name|inputName
argument_list|,
name|bucketToGroupedSplitMap
argument_list|,
name|secondLevelGroupingDone
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|SplitLocationProvider
name|splitLocationProvider
init|=
name|Utils
operator|.
name|getSplitLocationProvider
argument_list|(
name|conf
argument_list|,
name|LOG
argument_list|)
decl_stmt|;
comment|// do not group across files in case of side work because there is only 1 KV reader per
comment|// grouped split. This would affect SMB joins where we want to find the smallest key in
comment|// all the bucket files.
for|for
control|(
name|Integer
name|key
range|:
name|bucketToInitialSplitMap
operator|.
name|keySet
argument_list|()
control|)
block|{
name|InputSplit
index|[]
name|inputSplitArray
init|=
operator|(
name|bucketToInitialSplitMap
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|.
name|toArray
argument_list|(
operator|new
name|InputSplit
index|[
literal|0
index|]
argument_list|)
operator|)
decl_stmt|;
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|groupedSplit
init|=
name|grouper
operator|.
name|generateGroupedSplits
argument_list|(
name|jobConf
argument_list|,
name|conf
argument_list|,
name|inputSplitArray
argument_list|,
name|waves
argument_list|,
name|availableSlots
argument_list|,
name|inputName
argument_list|,
literal|false
argument_list|,
name|splitLocationProvider
argument_list|)
decl_stmt|;
name|bucketToGroupedSplitMap
operator|.
name|putAll
argument_list|(
name|key
argument_list|,
name|groupedSplit
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/*          * this is the small table side. In case of SMB join, we need to send each split to the          * corresponding bucket-based task on the other side. In case a split needs to go to          * multiple downstream tasks, we need to clone the event and send it to the right          * destination.          */
name|LOG
operator|.
name|info
argument_list|(
literal|"This is the side work - multi-mr work."
argument_list|)
expr_stmt|;
name|processAllSideEventsSetParallelism
argument_list|(
name|inputName
argument_list|,
name|bucketToGroupedSplitMap
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|processAllSideEventsSetParallelism
parameter_list|(
name|String
name|inputName
parameter_list|,
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|bucketToGroupedSplitMap
parameter_list|)
throws|throws
name|IOException
block|{
comment|// the bucket to task map should have been setup by the big table.
name|LOG
operator|.
name|info
argument_list|(
literal|"Processing events for input "
operator|+
name|inputName
argument_list|)
expr_stmt|;
if|if
condition|(
name|inputNameInputSpecMap
operator|.
name|get
argument_list|(
name|mainWorkName
argument_list|)
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"We don't have a routing table yet. Will need to wait for the main input "
operator|+
name|mainWorkName
operator|+
literal|" initialization"
argument_list|)
expr_stmt|;
name|inputToGroupedSplitMap
operator|.
name|put
argument_list|(
name|inputName
argument_list|,
name|bucketToGroupedSplitMap
argument_list|)
expr_stmt|;
return|return;
block|}
name|processAllSideEvents
argument_list|(
name|inputName
argument_list|,
name|bucketToGroupedSplitMap
argument_list|)
expr_stmt|;
name|setVertexParallelismAndRootInputSpec
argument_list|(
name|inputNameInputSpecMap
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|processAllSideEvents
parameter_list|(
name|String
name|inputName
parameter_list|,
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|bucketToGroupedSplitMap
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|InputDataInformationEvent
argument_list|>
name|taskEvents
init|=
operator|new
name|ArrayList
argument_list|<
name|InputDataInformationEvent
argument_list|>
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"We have a routing table and we are going to set the destination tasks for the"
operator|+
literal|" multi mr inputs. "
operator|+
name|bucketToTaskMap
argument_list|)
expr_stmt|;
name|Integer
index|[]
name|numSplitsForTask
init|=
operator|new
name|Integer
index|[
name|taskCount
index|]
decl_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|numSplitsForTask
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|ByteBuffer
argument_list|>
name|bucketToSerializedSplitMap
init|=
name|LinkedListMultimap
operator|.
name|create
argument_list|()
decl_stmt|;
comment|// Create the list of serialized splits for each bucket.
for|for
control|(
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Collection
argument_list|<
name|InputSplit
argument_list|>
argument_list|>
name|entry
range|:
name|bucketToGroupedSplitMap
operator|.
name|asMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
for|for
control|(
name|InputSplit
name|split
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|MRSplitProto
name|serializedSplit
init|=
name|MRInputHelpers
operator|.
name|createSplitProto
argument_list|(
name|split
argument_list|)
decl_stmt|;
name|ByteBuffer
name|bs
init|=
name|serializedSplit
operator|.
name|toByteString
argument_list|()
operator|.
name|asReadOnlyByteBuffer
argument_list|()
decl_stmt|;
name|bucketToSerializedSplitMap
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|bs
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Collection
argument_list|<
name|ByteBuffer
argument_list|>
argument_list|>
name|entry
range|:
name|bucketToSerializedSplitMap
operator|.
name|asMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Collection
argument_list|<
name|Integer
argument_list|>
name|destTasks
init|=
name|bucketToTaskMap
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|destTasks
operator|==
literal|null
operator|)
operator|||
operator|(
name|destTasks
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|Integer
name|task
range|:
name|destTasks
control|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ByteBuffer
name|buf
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|count
operator|++
expr_stmt|;
name|InputDataInformationEvent
name|diEvent
init|=
name|InputDataInformationEvent
operator|.
name|createWithSerializedPayload
argument_list|(
name|count
argument_list|,
name|buf
argument_list|)
decl_stmt|;
name|diEvent
operator|.
name|setTargetIndex
argument_list|(
name|task
argument_list|)
expr_stmt|;
name|taskEvents
operator|.
name|add
argument_list|(
name|diEvent
argument_list|)
expr_stmt|;
block|}
name|numSplitsForTask
index|[
name|task
index|]
operator|=
name|count
expr_stmt|;
block|}
block|}
name|inputNameInputSpecMap
operator|.
name|put
argument_list|(
name|inputName
argument_list|,
name|InputSpecUpdate
operator|.
name|createPerTaskInputSpecUpdate
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|numSplitsForTask
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"For input name: "
operator|+
name|inputName
operator|+
literal|" task events size is "
operator|+
name|taskEvents
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|context
operator|.
name|addRootInputEvents
argument_list|(
name|inputName
argument_list|,
name|taskEvents
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|processAllEvents
parameter_list|(
name|String
name|inputName
parameter_list|,
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|bucketToGroupedSplitMap
parameter_list|,
name|boolean
name|secondLevelGroupingDone
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|totalInputsCount
init|=
literal|0
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|numSplitsForTask
init|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Collection
argument_list|<
name|InputSplit
argument_list|>
argument_list|>
name|entry
range|:
name|bucketToGroupedSplitMap
operator|.
name|asMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|bucketNum
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|InputSplit
argument_list|>
name|initialSplits
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|finalSplits
operator|.
name|addAll
argument_list|(
name|initialSplits
argument_list|)
expr_stmt|;
for|for
control|(
name|InputSplit
name|inputSplit
range|:
name|initialSplits
control|)
block|{
name|bucketToTaskMap
operator|.
name|put
argument_list|(
name|bucketNum
argument_list|,
name|taskCount
argument_list|)
expr_stmt|;
if|if
condition|(
name|secondLevelGroupingDone
condition|)
block|{
name|TezGroupedSplit
name|groupedSplit
init|=
operator|(
name|TezGroupedSplit
operator|)
name|inputSplit
decl_stmt|;
name|numSplitsForTask
operator|.
name|add
argument_list|(
name|groupedSplit
operator|.
name|getGroupedSplits
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|totalInputsCount
operator|+=
name|groupedSplit
operator|.
name|getGroupedSplits
argument_list|()
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|numSplitsForTask
operator|.
name|add
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|totalInputsCount
operator|+=
literal|1
expr_stmt|;
block|}
name|taskCount
operator|++
expr_stmt|;
block|}
block|}
name|inputNameInputSpecMap
operator|.
name|put
argument_list|(
name|inputName
argument_list|,
name|InputSpecUpdate
operator|.
name|createPerTaskInputSpecUpdate
argument_list|(
name|numSplitsForTask
argument_list|)
argument_list|)
expr_stmt|;
comment|// Construct the EdgeManager descriptor to be used by all edges which need
comment|// the routing table.
name|EdgeManagerPluginDescriptor
name|hiveEdgeManagerDesc
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|(
name|vertexType
operator|==
name|VertexType
operator|.
name|MULTI_INPUT_INITIALIZED_EDGES
operator|)
operator|||
operator|(
name|vertexType
operator|==
name|VertexType
operator|.
name|INITIALIZED_EDGES
operator|)
condition|)
block|{
name|hiveEdgeManagerDesc
operator|=
name|EdgeManagerPluginDescriptor
operator|.
name|create
argument_list|(
name|CustomPartitionEdge
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|UserPayload
name|payload
init|=
name|getBytePayload
argument_list|(
name|bucketToTaskMap
argument_list|)
decl_stmt|;
name|hiveEdgeManagerDesc
operator|.
name|setUserPayload
argument_list|(
name|payload
argument_list|)
expr_stmt|;
block|}
comment|// Replace the edge manager for all vertices which have routing type custom.
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|EdgeProperty
argument_list|>
name|edgeEntry
range|:
name|context
operator|.
name|getInputVertexEdgeProperties
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|edgeEntry
operator|.
name|getValue
argument_list|()
operator|.
name|getDataMovementType
argument_list|()
operator|==
name|DataMovementType
operator|.
name|CUSTOM
operator|&&
name|edgeEntry
operator|.
name|getValue
argument_list|()
operator|.
name|getEdgeManagerDescriptor
argument_list|()
operator|.
name|getClassName
argument_list|()
operator|.
name|equals
argument_list|(
name|CustomPartitionEdge
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|emMap
operator|.
name|put
argument_list|(
name|edgeEntry
operator|.
name|getKey
argument_list|()
argument_list|,
name|hiveEdgeManagerDesc
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Task count is "
operator|+
name|taskCount
operator|+
literal|" for input name: "
operator|+
name|inputName
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|InputDataInformationEvent
argument_list|>
name|taskEvents
init|=
name|Lists
operator|.
name|newArrayListWithCapacity
argument_list|(
name|totalInputsCount
argument_list|)
decl_stmt|;
comment|// Re-serialize the splits after grouping.
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|InputSplit
name|inputSplit
range|:
name|finalSplits
control|)
block|{
if|if
condition|(
name|secondLevelGroupingDone
condition|)
block|{
name|TezGroupedSplit
name|tezGroupedSplit
init|=
operator|(
name|TezGroupedSplit
operator|)
name|inputSplit
decl_stmt|;
for|for
control|(
name|InputSplit
name|subSplit
range|:
name|tezGroupedSplit
operator|.
name|getGroupedSplits
argument_list|()
control|)
block|{
if|if
condition|(
operator|(
name|subSplit
operator|instanceof
name|TezGroupedSplit
operator|)
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unexpected split type found: "
operator|+
name|subSplit
operator|.
name|getClass
argument_list|()
operator|.
name|getCanonicalName
argument_list|()
argument_list|)
throw|;
block|}
name|MRSplitProto
name|serializedSplit
init|=
name|MRInputHelpers
operator|.
name|createSplitProto
argument_list|(
name|subSplit
argument_list|)
decl_stmt|;
name|InputDataInformationEvent
name|diEvent
init|=
name|InputDataInformationEvent
operator|.
name|createWithSerializedPayload
argument_list|(
name|count
argument_list|,
name|serializedSplit
operator|.
name|toByteString
argument_list|()
operator|.
name|asReadOnlyByteBuffer
argument_list|()
argument_list|)
decl_stmt|;
name|diEvent
operator|.
name|setTargetIndex
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|taskEvents
operator|.
name|add
argument_list|(
name|diEvent
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|MRSplitProto
name|serializedSplit
init|=
name|MRInputHelpers
operator|.
name|createSplitProto
argument_list|(
name|inputSplit
argument_list|)
decl_stmt|;
name|InputDataInformationEvent
name|diEvent
init|=
name|InputDataInformationEvent
operator|.
name|createWithSerializedPayload
argument_list|(
name|count
argument_list|,
name|serializedSplit
operator|.
name|toByteString
argument_list|()
operator|.
name|asReadOnlyByteBuffer
argument_list|()
argument_list|)
decl_stmt|;
name|diEvent
operator|.
name|setTargetIndex
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|taskEvents
operator|.
name|add
argument_list|(
name|diEvent
argument_list|)
expr_stmt|;
block|}
name|count
operator|++
expr_stmt|;
block|}
comment|// Set the actual events for the tasks.
name|LOG
operator|.
name|info
argument_list|(
literal|"For input name: "
operator|+
name|inputName
operator|+
literal|" task events size is "
operator|+
name|taskEvents
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|context
operator|.
name|addRootInputEvents
argument_list|(
name|inputName
argument_list|,
name|taskEvents
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|inputToGroupedSplitMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
argument_list|>
name|entry
range|:
name|inputToGroupedSplitMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|processAllSideEvents
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|setVertexParallelismAndRootInputSpec
argument_list|(
name|inputNameInputSpecMap
argument_list|)
expr_stmt|;
name|inputToGroupedSplitMap
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|// Only done when it is a bucket map join only no SMB.
if|if
condition|(
name|numInputsAffectingRootInputSpecUpdate
operator|==
literal|1
condition|)
block|{
name|setVertexParallelismAndRootInputSpec
argument_list|(
name|inputNameInputSpecMap
argument_list|)
expr_stmt|;
comment|// Send the bucket IDs associated with the tasks, must happen after parallelism is set.
name|sendBucketIdsToProcessor
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|sendBucketIdsToProcessor
parameter_list|()
block|{
for|for
control|(
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Collection
argument_list|<
name|Integer
argument_list|>
argument_list|>
name|entry
range|:
name|bucketToTaskMap
operator|.
name|asMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|bucketNum
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
for|for
control|(
name|Integer
name|taskId
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
comment|// Create payload
name|ByteBuffer
name|buffer
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
literal|8
argument_list|)
decl_stmt|;
name|buffer
operator|.
name|putInt
argument_list|(
name|numBuckets
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putInt
argument_list|(
name|bucketNum
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
comment|// Create the event and send it tez. Tez will route it to appropriate processor
name|CustomProcessorEvent
name|cpEvent
init|=
name|CustomProcessorEvent
operator|.
name|create
argument_list|(
name|buffer
argument_list|)
decl_stmt|;
name|context
operator|.
name|sendEventToProcessor
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|cpEvent
argument_list|)
argument_list|,
name|taskId
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|setVertexParallelismAndRootInputSpec
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|InputSpecUpdate
argument_list|>
name|rootInputSpecUpdate
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|numInputsAffectingRootInputSpecUpdate
operator|!=
name|numInputsSeenSoFar
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting vertex parallelism since we have seen all inputs."
argument_list|)
expr_stmt|;
name|boolean
name|generateConsistentSplits
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_TEZ_GENERATE_CONSISTENT_SPLITS
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"GenerateConsistenSplitsInHive="
operator|+
name|generateConsistentSplits
argument_list|)
expr_stmt|;
name|context
operator|.
name|setVertexParallelism
argument_list|(
name|taskCount
argument_list|,
name|VertexLocationHint
operator|.
name|create
argument_list|(
name|grouper
operator|.
name|createTaskLocationHints
argument_list|(
name|finalSplits
operator|.
name|toArray
argument_list|(
operator|new
name|InputSplit
index|[
name|finalSplits
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
name|generateConsistentSplits
argument_list|)
argument_list|)
argument_list|,
name|emMap
argument_list|,
name|rootInputSpecUpdate
argument_list|)
expr_stmt|;
name|finalSplits
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|UserPayload
name|getBytePayload
parameter_list|(
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|Integer
argument_list|>
name|routingTable
parameter_list|)
throws|throws
name|IOException
block|{
name|CustomEdgeConfiguration
name|edgeConf
init|=
operator|new
name|CustomEdgeConfiguration
argument_list|(
name|numBuckets
argument_list|,
name|routingTable
argument_list|)
decl_stmt|;
name|DataOutputBuffer
name|dob
init|=
operator|new
name|DataOutputBuffer
argument_list|()
decl_stmt|;
name|edgeConf
operator|.
name|write
argument_list|(
name|dob
argument_list|)
expr_stmt|;
name|byte
index|[]
name|serialized
init|=
name|dob
operator|.
name|getData
argument_list|()
decl_stmt|;
return|return
name|UserPayload
operator|.
name|create
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|serialized
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|FileSplit
name|getFileSplitFromEvent
parameter_list|(
name|InputDataInformationEvent
name|event
parameter_list|)
throws|throws
name|IOException
block|{
name|InputSplit
name|inputSplit
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|event
operator|.
name|getDeserializedUserPayload
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|inputSplit
operator|=
operator|(
name|InputSplit
operator|)
name|event
operator|.
name|getDeserializedUserPayload
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|MRSplitProto
name|splitProto
init|=
name|MRSplitProto
operator|.
name|parseFrom
argument_list|(
name|ByteString
operator|.
name|copyFrom
argument_list|(
name|event
operator|.
name|getUserPayload
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|SerializationFactory
name|serializationFactory
init|=
operator|new
name|SerializationFactory
argument_list|(
operator|new
name|Configuration
argument_list|()
argument_list|)
decl_stmt|;
name|inputSplit
operator|=
name|MRInputHelpers
operator|.
name|createOldFormatSplitFromUserPayload
argument_list|(
name|splitProto
argument_list|,
name|serializationFactory
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
name|inputSplit
operator|instanceof
name|FileSplit
operator|)
condition|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Cannot handle splits other than FileSplit for the moment. Current input split type: "
operator|+
name|inputSplit
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
throw|;
block|}
return|return
operator|(
name|FileSplit
operator|)
name|inputSplit
return|;
block|}
comment|/*    * This method generates the map of bucket to file splits.    */
specifier|private
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|getBucketSplitMapForPath
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|Set
argument_list|<
name|FileSplit
argument_list|>
argument_list|>
name|pathFileSplitsMap
parameter_list|)
block|{
name|int
name|bucketNum
init|=
literal|0
decl_stmt|;
name|Multimap
argument_list|<
name|Integer
argument_list|,
name|InputSplit
argument_list|>
name|bucketToInitialSplitMap
init|=
name|ArrayListMultimap
operator|.
expr|<
name|Integer
decl_stmt|,
name|InputSplit
decl|>
name|create
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Set
argument_list|<
name|FileSplit
argument_list|>
argument_list|>
name|entry
range|:
name|pathFileSplitsMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|bucketId
init|=
name|bucketNum
operator|%
name|numBuckets
decl_stmt|;
for|for
control|(
name|FileSplit
name|fsplit
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|bucketToInitialSplitMap
operator|.
name|put
argument_list|(
name|bucketId
argument_list|,
name|fsplit
argument_list|)
expr_stmt|;
block|}
name|bucketNum
operator|++
expr_stmt|;
block|}
comment|// this is just for SMB join use-case. The numBuckets would be equal to that of the big table
comment|// and the small table could have lesser number of buckets. In this case, we want to send the
comment|// data from the right buckets to the big table side. For e.g. Big table has 8 buckets and small
comment|// table has 4 buckets, bucket 0 of small table needs to be sent to bucket 4 of the big table as
comment|// well.
if|if
condition|(
name|bucketNum
operator|<
name|numBuckets
condition|)
block|{
name|int
name|loopedBucketId
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
name|bucketNum
operator|<
name|numBuckets
condition|;
name|bucketNum
operator|++
control|)
block|{
for|for
control|(
name|InputSplit
name|fsplit
range|:
name|bucketToInitialSplitMap
operator|.
name|get
argument_list|(
name|loopedBucketId
argument_list|)
control|)
block|{
name|bucketToInitialSplitMap
operator|.
name|put
argument_list|(
name|bucketNum
argument_list|,
name|fsplit
argument_list|)
expr_stmt|;
block|}
name|loopedBucketId
operator|++
expr_stmt|;
block|}
block|}
return|return
name|bucketToInitialSplitMap
return|;
block|}
block|}
end_class

end_unit

