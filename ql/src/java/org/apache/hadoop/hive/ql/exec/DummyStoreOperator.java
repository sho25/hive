begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DummyStoreDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|api
operator|.
name|OperatorType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|InspectableObject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
operator|.
name|ObjectInspectorCopyOption
import|;
end_import

begin_comment
comment|/**  * For SortMerge joins, this is a dummy operator, which stores the row for the  * small table before it reaches the sort merge join operator.  *  * Consider a query like:  *  * select * from  *   (subq1 --> has a filter)  *   join  *   (subq2 --> has a filter)  * on some key  *  * Let us assume that subq1 is the small table (either specified by the user or inferred  * automatically). Since there can be multiple buckets/partitions for the table corresponding  * to subq1 given a file in subq2, a priority queue is present in SMBMapJoinOperator to scan the  * various buckets and fetch the least row (corresponding to the join key). The tree corresponding  * to subq1 needs to be evaluated in order to compute the join key (since the select list for the  * join key can move across different object inspectors).  *  * Therefore the following operator tree is created:  *  * TableScan (subq1) --> Select --> Filter --> DummyStore  *                                                         \  *                                                          \     SMBJoin  *                                                          /  *                                                         /  * TableScan (subq2) --> Select --> Filter  *  * In order to fetch the row with the least join key from the small table, the row from subq1  * is partially processed, and stored in DummyStore. For the actual processing of the join,  * SMBJoin (child of DummyStore) is processed for the transformed row. Note that in the absence of  * support for joins for sub-queries, this was not needed, since all transformations were done  * after SMBJoin, or for the small tables, nothing could have been present between TableScan and  * SMBJoin.  */
end_comment

begin_class
specifier|public
class|class
name|DummyStoreOperator
extends|extends
name|Operator
argument_list|<
name|DummyStoreDesc
argument_list|>
implements|implements
name|Serializable
block|{
specifier|protected
specifier|transient
name|InspectableObject
name|result
decl_stmt|;
specifier|public
name|DummyStoreOperator
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|initializeOp
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|HiveException
block|{
name|super
operator|.
name|initializeOp
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
comment|/*      * The conversion to standard object inspector was necessitated by HIVE-5973. The issue      * happens when a select operator preceeds this operator as in the case of a subquery. The      * select operator does not allocate a new object to hold the deserialized row. This affects      * the operation of the SMB join which puts the object in a priority queue. Since all elements      * of the priority queue point to the same object, the join was resulting in incorrect      * results.      *      * So the fix is to make a copy of the object as done in the processOp phase below. This      * however necessitates a change in the object inspector that can be used in processing the      * row downstream.      */
name|outputObjInspector
operator|=
name|ObjectInspectorUtils
operator|.
name|getStandardObjectInspector
argument_list|(
name|inputObjInspectors
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|result
operator|=
operator|new
name|InspectableObject
argument_list|(
literal|null
argument_list|,
name|outputObjInspector
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|process
parameter_list|(
name|Object
name|row
parameter_list|,
name|int
name|tag
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Store the row. See comments above for why we need a new copy of the row.
name|result
operator|.
name|o
operator|=
name|ObjectInspectorUtils
operator|.
name|copyToStandardObject
argument_list|(
name|row
argument_list|,
name|inputObjInspectors
index|[
literal|0
index|]
argument_list|,
name|ObjectInspectorCopyOption
operator|.
name|WRITABLE
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reset
parameter_list|()
block|{
name|result
operator|=
operator|new
name|InspectableObject
argument_list|(
literal|null
argument_list|,
name|result
operator|.
name|oi
argument_list|)
expr_stmt|;
block|}
specifier|public
name|InspectableObject
name|getResult
parameter_list|()
block|{
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|OperatorType
name|getType
parameter_list|()
block|{
return|return
name|OperatorType
operator|.
name|FORWARD
return|;
block|}
block|}
end_class

end_unit

