begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed under the Apache License, Version 2.0 (the "License");  * you may not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  * http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|parquet
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|IOConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|parquet
operator|.
name|convert
operator|.
name|HiveSchemaConverter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|parquet
operator|.
name|write
operator|.
name|DataWritableWriteSupport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|parquet
operator|.
name|write
operator|.
name|ParquetRecordWriterWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|ArrayWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|OutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|parquet
operator|.
name|hadoop
operator|.
name|ParquetOutputFormat
import|;
end_import

begin_import
import|import
name|parquet
operator|.
name|hadoop
operator|.
name|metadata
operator|.
name|CompressionCodecName
import|;
end_import

begin_import
import|import
name|parquet
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ContextUtil
import|;
end_import

begin_comment
comment|/**  *  * A Parquet OutputFormat for Hive (with the deprecated package mapred)  *  */
end_comment

begin_class
specifier|public
class|class
name|MapredParquetOutputFormat
extends|extends
name|FileOutputFormat
argument_list|<
name|Void
argument_list|,
name|ArrayWritable
argument_list|>
implements|implements
name|HiveOutputFormat
argument_list|<
name|Void
argument_list|,
name|ArrayWritable
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|MapredParquetOutputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|protected
name|ParquetOutputFormat
argument_list|<
name|ArrayWritable
argument_list|>
name|realOutputFormat
decl_stmt|;
specifier|public
name|MapredParquetOutputFormat
parameter_list|()
block|{
name|realOutputFormat
operator|=
operator|new
name|ParquetOutputFormat
argument_list|<
name|ArrayWritable
argument_list|>
argument_list|(
operator|new
name|DataWritableWriteSupport
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|MapredParquetOutputFormat
parameter_list|(
specifier|final
name|OutputFormat
argument_list|<
name|Void
argument_list|,
name|ArrayWritable
argument_list|>
name|mapreduceOutputFormat
parameter_list|)
block|{
name|realOutputFormat
operator|=
operator|(
name|ParquetOutputFormat
argument_list|<
name|ArrayWritable
argument_list|>
operator|)
name|mapreduceOutputFormat
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|checkOutputSpecs
parameter_list|(
specifier|final
name|FileSystem
name|ignored
parameter_list|,
specifier|final
name|JobConf
name|job
parameter_list|)
throws|throws
name|IOException
block|{
name|realOutputFormat
operator|.
name|checkOutputSpecs
argument_list|(
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getHCatShim
argument_list|()
operator|.
name|createJobContext
argument_list|(
name|job
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|RecordWriter
argument_list|<
name|Void
argument_list|,
name|ArrayWritable
argument_list|>
name|getRecordWriter
parameter_list|(
specifier|final
name|FileSystem
name|ignored
parameter_list|,
specifier|final
name|JobConf
name|job
parameter_list|,
specifier|final
name|String
name|name
parameter_list|,
specifier|final
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Should never be used"
argument_list|)
throw|;
block|}
comment|/**    *    * Create the parquet schema from the hive schema, and return the RecordWriterWrapper which    * contains the real output format    */
annotation|@
name|Override
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
operator|.
name|RecordWriter
name|getHiveRecordWriter
parameter_list|(
specifier|final
name|JobConf
name|jobConf
parameter_list|,
specifier|final
name|Path
name|finalOutPath
parameter_list|,
specifier|final
name|Class
argument_list|<
name|?
extends|extends
name|Writable
argument_list|>
name|valueClass
parameter_list|,
specifier|final
name|boolean
name|isCompressed
parameter_list|,
specifier|final
name|Properties
name|tableProperties
parameter_list|,
specifier|final
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"creating new record writer..."
operator|+
name|this
argument_list|)
expr_stmt|;
specifier|final
name|String
name|columnNameProperty
init|=
name|tableProperties
operator|.
name|getProperty
argument_list|(
name|IOConstants
operator|.
name|COLUMNS
argument_list|)
decl_stmt|;
specifier|final
name|String
name|columnTypeProperty
init|=
name|tableProperties
operator|.
name|getProperty
argument_list|(
name|IOConstants
operator|.
name|COLUMNS_TYPES
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|columnNames
decl_stmt|;
name|List
argument_list|<
name|TypeInfo
argument_list|>
name|columnTypes
decl_stmt|;
if|if
condition|(
name|columnNameProperty
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|columnNames
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|columnNames
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|columnNameProperty
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|columnTypeProperty
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|columnTypes
operator|=
operator|new
name|ArrayList
argument_list|<
name|TypeInfo
argument_list|>
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|columnTypes
operator|=
name|TypeInfoUtils
operator|.
name|getTypeInfosFromTypeString
argument_list|(
name|columnTypeProperty
argument_list|)
expr_stmt|;
block|}
name|DataWritableWriteSupport
operator|.
name|setSchema
argument_list|(
name|HiveSchemaConverter
operator|.
name|convert
argument_list|(
name|columnNames
argument_list|,
name|columnTypes
argument_list|)
argument_list|,
name|jobConf
argument_list|)
expr_stmt|;
return|return
name|getParquerRecordWriterWrapper
argument_list|(
name|realOutputFormat
argument_list|,
name|jobConf
argument_list|,
name|finalOutPath
operator|.
name|toString
argument_list|()
argument_list|,
name|progress
argument_list|,
name|tableProperties
argument_list|)
return|;
block|}
specifier|protected
name|ParquetRecordWriterWrapper
name|getParquerRecordWriterWrapper
parameter_list|(
name|ParquetOutputFormat
argument_list|<
name|ArrayWritable
argument_list|>
name|realOutputFormat
parameter_list|,
name|JobConf
name|jobConf
parameter_list|,
name|String
name|finalOutPath
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|Properties
name|tableProperties
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|ParquetRecordWriterWrapper
argument_list|(
name|realOutputFormat
argument_list|,
name|jobConf
argument_list|,
name|finalOutPath
operator|.
name|toString
argument_list|()
argument_list|,
name|progress
argument_list|,
name|tableProperties
argument_list|)
return|;
block|}
block|}
end_class

end_unit

