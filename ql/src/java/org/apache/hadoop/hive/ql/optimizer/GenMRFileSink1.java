begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Stack
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Context
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|AbstractMapJoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ColumnInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ConditionalTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|DependencyCollectionTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MapJoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MapRedTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MoveTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|OperatorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|RowSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Task
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TaskFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|UnionOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|RCFileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|rcfile
operator|.
name|merge
operator|.
name|MergeWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|NodeProcessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|NodeProcessorCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|GenMRProcContext
operator|.
name|GenMRMapJoinCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ParseContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|RowResolver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticAnalyzer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|TypeCheckProcFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalResolverMergeFiles
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalResolverMergeFiles
operator|.
name|ConditionalResolverMergeFilesCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ConditionalWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DynamicPartitionCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeColumnDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExtractDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FileSinkDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|LoadFileDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapJoinDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapredWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MoveWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PlanUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceSinkDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|StatsWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableScanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_comment
comment|/**  * Processor for the rule - table scan followed by reduce sink.  */
end_comment

begin_class
specifier|public
class|class
name|GenMRFileSink1
implements|implements
name|NodeProcessor
block|{
specifier|static
specifier|final
specifier|private
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|GenMRFileSink1
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|public
name|GenMRFileSink1
parameter_list|()
block|{   }
comment|/**    * File Sink Operator encountered.    *    * @param nd    *          the file sink operator encountered    * @param opProcCtx    *          context    */
specifier|public
name|Object
name|process
parameter_list|(
name|Node
name|nd
parameter_list|,
name|Stack
argument_list|<
name|Node
argument_list|>
name|stack
parameter_list|,
name|NodeProcessorCtx
name|opProcCtx
parameter_list|,
name|Object
modifier|...
name|nodeOutputs
parameter_list|)
throws|throws
name|SemanticException
block|{
name|GenMRProcContext
name|ctx
init|=
operator|(
name|GenMRProcContext
operator|)
name|opProcCtx
decl_stmt|;
name|ParseContext
name|parseCtx
init|=
name|ctx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|boolean
name|chDir
init|=
literal|false
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
init|=
name|ctx
operator|.
name|getCurrTask
argument_list|()
decl_stmt|;
name|FileSinkOperator
name|fsOp
init|=
operator|(
name|FileSinkOperator
operator|)
name|nd
decl_stmt|;
name|boolean
name|isInsertTable
init|=
comment|// is INSERT OVERWRITE TABLE
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getTableName
argument_list|()
operator|!=
literal|null
operator|&&
name|parseCtx
operator|.
name|getQB
argument_list|()
operator|.
name|getParseInfo
argument_list|()
operator|.
name|isInsertToTable
argument_list|()
decl_stmt|;
name|HiveConf
name|hconf
init|=
name|parseCtx
operator|.
name|getConf
argument_list|()
decl_stmt|;
comment|// Has the user enabled merging of files for map-only jobs or for all jobs
if|if
condition|(
operator|(
name|ctx
operator|.
name|getMvTask
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|ctx
operator|.
name|getMvTask
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
init|=
name|ctx
operator|.
name|getMvTask
argument_list|()
decl_stmt|;
comment|// In case of unions or map-joins, it is possible that the file has
comment|// already been seen.
comment|// So, no need to attempt to merge the files again.
if|if
condition|(
operator|(
name|ctx
operator|.
name|getSeenFileSinkOps
argument_list|()
operator|==
literal|null
operator|)
operator|||
operator|(
operator|!
name|ctx
operator|.
name|getSeenFileSinkOps
argument_list|()
operator|.
name|contains
argument_list|(
name|nd
argument_list|)
operator|)
condition|)
block|{
comment|// no need of merging if the move is to a local file system
name|MoveTask
name|mvTask
init|=
operator|(
name|MoveTask
operator|)
name|findMoveTask
argument_list|(
name|mvTasks
argument_list|,
name|fsOp
argument_list|)
decl_stmt|;
if|if
condition|(
name|isInsertTable
operator|&&
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESTATSAUTOGATHER
argument_list|)
condition|)
block|{
name|addStatsTask
argument_list|(
name|fsOp
argument_list|,
name|mvTask
argument_list|,
name|currTask
argument_list|,
name|parseCtx
operator|.
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|mvTask
operator|!=
literal|null
operator|)
operator|&&
operator|!
name|mvTask
operator|.
name|isLocal
argument_list|()
condition|)
block|{
comment|// There are separate configuration parameters to control whether to
comment|// merge for a map-only job
comment|// or for a map-reduce job
name|MapredWork
name|currWork
init|=
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|boolean
name|mergeMapOnly
init|=
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMERGEMAPFILES
argument_list|)
operator|&&
name|currWork
operator|.
name|getReducer
argument_list|()
operator|==
literal|null
decl_stmt|;
name|boolean
name|mergeMapRed
init|=
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMERGEMAPREDFILES
argument_list|)
operator|&&
name|currWork
operator|.
name|getReducer
argument_list|()
operator|!=
literal|null
decl_stmt|;
if|if
condition|(
name|mergeMapOnly
operator|||
name|mergeMapRed
condition|)
block|{
name|chDir
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
block|}
name|String
name|finalName
init|=
name|processFS
argument_list|(
name|nd
argument_list|,
name|stack
argument_list|,
name|opProcCtx
argument_list|,
name|chDir
argument_list|)
decl_stmt|;
comment|// need to merge the files in the destination table/partitions
if|if
condition|(
name|chDir
operator|&&
operator|(
name|finalName
operator|!=
literal|null
operator|)
condition|)
block|{
name|createMergeJob
argument_list|(
operator|(
name|FileSinkOperator
operator|)
name|nd
argument_list|,
name|ctx
argument_list|,
name|finalName
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Add the StatsTask as a dependent task of the MoveTask    * because StatsTask will change the Table/Partition metadata. For atomicity, we    * should not change it before the data is actually there done by MoveTask.    * @param nd the FileSinkOperator whose results are taken care of by the MoveTask.    * @param mvTask The MoveTask that moves the FileSinkOperator's results.    * @param currTask The MapRedTask that the FileSinkOperator belongs to.    * @param hconf HiveConf    */
specifier|private
name|void
name|addStatsTask
parameter_list|(
name|FileSinkOperator
name|nd
parameter_list|,
name|MoveTask
name|mvTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|HiveConf
name|hconf
parameter_list|)
block|{
name|MoveWork
name|mvWork
init|=
operator|(
operator|(
name|MoveTask
operator|)
name|mvTask
operator|)
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|StatsWork
name|statsWork
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|statsWork
operator|=
operator|new
name|StatsWork
argument_list|(
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|statsWork
operator|=
operator|new
name|StatsWork
argument_list|(
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
argument_list|)
expr_stmt|;
block|}
assert|assert
name|statsWork
operator|!=
literal|null
operator|:
literal|"Error when genereting StatsTask"
assert|;
name|statsWork
operator|.
name|setStatsReliable
argument_list|(
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_STATS_RELIABLE
argument_list|)
argument_list|)
expr_stmt|;
name|MapredWork
name|mrWork
init|=
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
comment|// AggKey in StatsWork is used for stats aggregation while StatsAggPrefix
comment|// in FileSinkDesc is used for stats publishing. They should be consistent.
name|statsWork
operator|.
name|setAggKey
argument_list|(
operator|(
operator|(
name|FileSinkOperator
operator|)
name|nd
operator|)
operator|.
name|getConf
argument_list|()
operator|.
name|getStatsAggPrefix
argument_list|()
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|statsTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|statsWork
argument_list|,
name|hconf
argument_list|)
decl_stmt|;
comment|// mark the MapredWork and FileSinkOperator for gathering stats
name|nd
operator|.
name|getConf
argument_list|()
operator|.
name|setGatherStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|mrWork
operator|.
name|setGatheringStats
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|nd
operator|.
name|getConf
argument_list|()
operator|.
name|setStatsReliable
argument_list|(
name|hconf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_STATS_RELIABLE
argument_list|)
argument_list|)
expr_stmt|;
comment|// mrWork.addDestinationTable(nd.getConf().getTableInfo().getTableName());
comment|// subscribe feeds from the MoveTask so that MoveTask can forward the list
comment|// of dynamic partition list to the StatsTask
name|mvTask
operator|.
name|addDependentTask
argument_list|(
name|statsTask
argument_list|)
expr_stmt|;
name|statsTask
operator|.
name|subscribeFeed
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|createMapReduce4Merge
parameter_list|(
name|FileSinkOperator
name|fsOp
parameter_list|,
name|GenMRProcContext
name|ctx
parameter_list|,
name|String
name|finalName
parameter_list|)
throws|throws
name|SemanticException
block|{
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
init|=
name|ctx
operator|.
name|getCurrTask
argument_list|()
decl_stmt|;
name|RowSchema
name|inputRS
init|=
name|fsOp
operator|.
name|getSchema
argument_list|()
decl_stmt|;
comment|// create a reduce Sink operator - key is the first column
name|ArrayList
argument_list|<
name|ExprNodeDesc
argument_list|>
name|keyCols
init|=
operator|new
name|ArrayList
argument_list|<
name|ExprNodeDesc
argument_list|>
argument_list|()
decl_stmt|;
name|keyCols
operator|.
name|add
argument_list|(
name|TypeCheckProcFactory
operator|.
name|DefaultExprProcessor
operator|.
name|getFuncExprNodeDesc
argument_list|(
literal|"rand"
argument_list|)
argument_list|)
expr_stmt|;
comment|// value is all the columns in the FileSink operator input
name|ArrayList
argument_list|<
name|ExprNodeDesc
argument_list|>
name|valueCols
init|=
operator|new
name|ArrayList
argument_list|<
name|ExprNodeDesc
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|ColumnInfo
name|ci
range|:
name|inputRS
operator|.
name|getSignature
argument_list|()
control|)
block|{
name|valueCols
operator|.
name|add
argument_list|(
operator|new
name|ExprNodeColumnDesc
argument_list|(
name|ci
operator|.
name|getType
argument_list|()
argument_list|,
name|ci
operator|.
name|getInternalName
argument_list|()
argument_list|,
name|ci
operator|.
name|getTabAlias
argument_list|()
argument_list|,
name|ci
operator|.
name|getIsVirtualCol
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// create a dummy tableScan operator
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|tsMerge
init|=
name|OperatorFactory
operator|.
name|get
argument_list|(
name|TableScanDesc
operator|.
name|class
argument_list|,
name|inputRS
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|String
argument_list|>
name|outputColumns
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|valueCols
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|outputColumns
operator|.
name|add
argument_list|(
name|SemanticAnalyzer
operator|.
name|getColumnInternalName
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ReduceSinkDesc
name|rsDesc
init|=
name|PlanUtils
operator|.
name|getReduceSinkDesc
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|ExprNodeDesc
argument_list|>
argument_list|()
argument_list|,
name|valueCols
argument_list|,
name|outputColumns
argument_list|,
literal|false
argument_list|,
operator|-
literal|1
argument_list|,
operator|-
literal|1
argument_list|,
operator|-
literal|1
argument_list|)
decl_stmt|;
name|OperatorFactory
operator|.
name|getAndMakeChild
argument_list|(
name|rsDesc
argument_list|,
name|inputRS
argument_list|,
name|tsMerge
argument_list|)
expr_stmt|;
name|ParseContext
name|parseCtx
init|=
name|ctx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|FileSinkDesc
name|fsConf
init|=
name|fsOp
operator|.
name|getConf
argument_list|()
decl_stmt|;
comment|// Add the extract operator to get the value fields
name|RowResolver
name|out_rwsch
init|=
operator|new
name|RowResolver
argument_list|()
decl_stmt|;
name|RowResolver
name|interim_rwsch
init|=
name|ctx
operator|.
name|getParseCtx
argument_list|()
operator|.
name|getOpParseCtx
argument_list|()
operator|.
name|get
argument_list|(
name|fsOp
argument_list|)
operator|.
name|getRowResolver
argument_list|()
decl_stmt|;
name|Integer
name|pos
init|=
name|Integer
operator|.
name|valueOf
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|ColumnInfo
name|colInfo
range|:
name|interim_rwsch
operator|.
name|getColumnInfos
argument_list|()
control|)
block|{
name|String
index|[]
name|info
init|=
name|interim_rwsch
operator|.
name|reverseLookup
argument_list|(
name|colInfo
operator|.
name|getInternalName
argument_list|()
argument_list|)
decl_stmt|;
name|out_rwsch
operator|.
name|put
argument_list|(
name|info
index|[
literal|0
index|]
argument_list|,
name|info
index|[
literal|1
index|]
argument_list|,
operator|new
name|ColumnInfo
argument_list|(
name|pos
operator|.
name|toString
argument_list|()
argument_list|,
name|colInfo
operator|.
name|getType
argument_list|()
argument_list|,
name|info
index|[
literal|0
index|]
argument_list|,
name|colInfo
operator|.
name|getIsVirtualCol
argument_list|()
argument_list|,
name|colInfo
operator|.
name|isHiddenVirtualCol
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|pos
operator|=
name|Integer
operator|.
name|valueOf
argument_list|(
name|pos
operator|.
name|intValue
argument_list|()
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
name|Operator
argument_list|<
name|ExtractDesc
argument_list|>
name|extract
init|=
name|OperatorFactory
operator|.
name|getAndMakeChild
argument_list|(
operator|new
name|ExtractDesc
argument_list|(
operator|new
name|ExprNodeColumnDesc
argument_list|(
name|TypeInfoFactory
operator|.
name|stringTypeInfo
argument_list|,
name|Utilities
operator|.
name|ReduceField
operator|.
name|VALUE
operator|.
name|toString
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|false
argument_list|)
argument_list|)
argument_list|,
operator|new
name|RowSchema
argument_list|(
name|out_rwsch
operator|.
name|getColumnInfos
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|TableDesc
name|ts
init|=
operator|(
name|TableDesc
operator|)
name|fsConf
operator|.
name|getTableInfo
argument_list|()
operator|.
name|clone
argument_list|()
decl_stmt|;
name|fsConf
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|)
expr_stmt|;
name|FileSinkDesc
name|newFSD
init|=
operator|new
name|FileSinkDesc
argument_list|(
name|finalName
argument_list|,
name|ts
argument_list|,
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|COMPRESSRESULT
argument_list|)
argument_list|)
decl_stmt|;
name|FileSinkOperator
name|newOutput
init|=
operator|(
name|FileSinkOperator
operator|)
name|OperatorFactory
operator|.
name|getAndMakeChild
argument_list|(
name|newFSD
argument_list|,
name|inputRS
argument_list|,
name|extract
argument_list|)
decl_stmt|;
name|HiveConf
name|conf
init|=
name|parseCtx
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|MapredWork
name|cplan
init|=
name|createMergeTask
argument_list|(
name|conf
argument_list|,
name|tsMerge
argument_list|,
name|fsConf
argument_list|)
decl_stmt|;
name|cplan
operator|.
name|setReducer
argument_list|(
name|extract
argument_list|)
expr_stmt|;
comment|// NOTE: we should gather stats in MR1 (rather than the merge MR job)
comment|// since it is unknown if the merge MR will be triggered at execution time.
name|MoveWork
name|dummyMv
init|=
operator|new
name|MoveWork
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
operator|new
name|LoadFileDesc
argument_list|(
name|fsConf
operator|.
name|getDirName
argument_list|()
argument_list|,
name|finalName
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|ConditionalTask
name|cndTsk
init|=
name|createCondTask
argument_list|(
name|conf
argument_list|,
name|currTask
argument_list|,
name|dummyMv
argument_list|,
name|cplan
argument_list|,
name|fsConf
operator|.
name|getDirName
argument_list|()
argument_list|)
decl_stmt|;
name|linkMoveTask
argument_list|(
name|ctx
argument_list|,
name|newOutput
argument_list|,
name|cndTsk
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a MapReduce job for a particular partition if Hadoop version is pre 0.20,    * otherwise create a Map-only job using CombineHiveInputFormat for all partitions.    * @param fsOp The FileSink operator.    * @param ctx The MR processing context.    * @param finalName the final destination path the merge job should output.    * @throws SemanticException    */
specifier|private
name|void
name|createMergeJob
parameter_list|(
name|FileSinkOperator
name|fsOp
parameter_list|,
name|GenMRProcContext
name|ctx
parameter_list|,
name|String
name|finalName
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// if the hadoop version support CombineFileInputFormat (version>= 0.20),
comment|// create a Map-only job for merge, otherwise create a MapReduce merge job.
name|ParseContext
name|parseCtx
init|=
name|ctx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|HiveConf
name|conf
init|=
name|parseCtx
operator|.
name|getConf
argument_list|()
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMERGEMAPONLY
argument_list|)
operator|&&
name|Utilities
operator|.
name|supportCombineFileInputFormat
argument_list|()
condition|)
block|{
comment|// create Map-only merge job
name|createMap4Merge
argument_list|(
name|fsOp
argument_list|,
name|ctx
argument_list|,
name|finalName
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"use CombineHiveInputformat for the merge job"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getDynPartCtx
argument_list|()
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|DYNAMIC_PARTITION_MERGE
operator|.
name|getMsg
argument_list|()
argument_list|)
throw|;
block|}
name|createMapReduce4Merge
argument_list|(
name|fsOp
argument_list|,
name|ctx
argument_list|,
name|finalName
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"use HiveInputFormat for the merge job"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * create a Map-only merge job with the following operators:    * @param fsInput    * @param ctx    * @param finalName    *  MR job J0:    *          ...    *              |    *              v    *         FileSinkOperator_1 (fsInput)    *             |    *             v    *  Merge job J1:    *             |    *             v    *         TableScan (using CombineHiveInputFormat) (tsMerge)    *             |    *             v    *         FileSinkOperator (fsMerge)    *    * Here the pathToPartitionInfo& pathToAlias will remain the same, which means the paths do    * not contain the dynamic partitions (their parent). So after the dynamic partitions are    * created (after the first job finished before the moveTask or ConditionalTask start),    * we need to change the pathToPartitionInfo& pathToAlias to include the dynamic partition    * directories.    *    */
specifier|private
name|void
name|createMap4Merge
parameter_list|(
name|FileSinkOperator
name|fsInput
parameter_list|,
name|GenMRProcContext
name|ctx
parameter_list|,
name|String
name|finalName
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|//
comment|// 1. create the operator tree
comment|//
name|ParseContext
name|parseCtx
init|=
name|ctx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|FileSinkDesc
name|fsInputDesc
init|=
name|fsInput
operator|.
name|getConf
argument_list|()
decl_stmt|;
comment|// Create a TableScan operator
name|RowSchema
name|inputRS
init|=
name|fsInput
operator|.
name|getSchema
argument_list|()
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|tsMerge
init|=
name|OperatorFactory
operator|.
name|get
argument_list|(
name|TableScanDesc
operator|.
name|class
argument_list|,
name|inputRS
argument_list|)
decl_stmt|;
comment|// Create a FileSink operator
name|TableDesc
name|ts
init|=
operator|(
name|TableDesc
operator|)
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|clone
argument_list|()
decl_stmt|;
name|FileSinkDesc
name|fsOutputDesc
init|=
operator|new
name|FileSinkDesc
argument_list|(
name|finalName
argument_list|,
name|ts
argument_list|,
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|COMPRESSRESULT
argument_list|)
argument_list|)
decl_stmt|;
name|FileSinkOperator
name|fsOutput
init|=
operator|(
name|FileSinkOperator
operator|)
name|OperatorFactory
operator|.
name|getAndMakeChild
argument_list|(
name|fsOutputDesc
argument_list|,
name|inputRS
argument_list|,
name|tsMerge
argument_list|)
decl_stmt|;
comment|// If the input FileSinkOperator is a dynamic partition enabled, the tsMerge input schema
comment|// needs to include the partition column, and the fsOutput should have
comment|// a DynamicPartitionCtx to indicate that it needs to dynamically partitioned.
name|DynamicPartitionCtx
name|dpCtx
init|=
name|fsInputDesc
operator|.
name|getDynPartCtx
argument_list|()
decl_stmt|;
if|if
condition|(
name|dpCtx
operator|!=
literal|null
operator|&&
name|dpCtx
operator|.
name|getNumDPCols
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// adding DP ColumnInfo to the RowSchema signature
name|ArrayList
argument_list|<
name|ColumnInfo
argument_list|>
name|signature
init|=
name|inputRS
operator|.
name|getSignature
argument_list|()
decl_stmt|;
name|String
name|tblAlias
init|=
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|colMap
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|StringBuilder
name|partCols
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|dpCol
range|:
name|dpCtx
operator|.
name|getDPColNames
argument_list|()
control|)
block|{
name|ColumnInfo
name|colInfo
init|=
operator|new
name|ColumnInfo
argument_list|(
name|dpCol
argument_list|,
name|TypeInfoFactory
operator|.
name|stringTypeInfo
argument_list|,
comment|// all partition column type should be string
name|tblAlias
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// partition column is virtual column
name|signature
operator|.
name|add
argument_list|(
name|colInfo
argument_list|)
expr_stmt|;
name|colMap
operator|.
name|put
argument_list|(
name|dpCol
argument_list|,
name|dpCol
argument_list|)
expr_stmt|;
comment|// input and output have the same column name
name|partCols
operator|.
name|append
argument_list|(
name|dpCol
argument_list|)
operator|.
name|append
argument_list|(
literal|'/'
argument_list|)
expr_stmt|;
block|}
name|partCols
operator|.
name|setLength
argument_list|(
name|partCols
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
comment|// remove the last '/'
name|inputRS
operator|.
name|setSignature
argument_list|(
name|signature
argument_list|)
expr_stmt|;
comment|// create another DynamicPartitionCtx, which has a different input-to-DP column mapping
name|DynamicPartitionCtx
name|dpCtx2
init|=
operator|new
name|DynamicPartitionCtx
argument_list|(
name|dpCtx
argument_list|)
decl_stmt|;
name|dpCtx2
operator|.
name|setInputToDPCols
argument_list|(
name|colMap
argument_list|)
expr_stmt|;
name|fsOutputDesc
operator|.
name|setDynPartCtx
argument_list|(
name|dpCtx2
argument_list|)
expr_stmt|;
comment|// update the FileSinkOperator to include partition columns
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getProperties
argument_list|()
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|,
name|partCols
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// list of dynamic partition column names
block|}
else|else
block|{
comment|// non-partitioned table
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getProperties
argument_list|()
operator|.
name|remove
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|)
expr_stmt|;
block|}
comment|//
comment|// 2. Constructing a conditional task consisting of a move task and a map reduce task
comment|//
name|MapRedTask
name|currTask
init|=
operator|(
name|MapRedTask
operator|)
name|ctx
operator|.
name|getCurrTask
argument_list|()
decl_stmt|;
name|MoveWork
name|dummyMv
init|=
operator|new
name|MoveWork
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
operator|new
name|LoadFileDesc
argument_list|(
name|fsInputDesc
operator|.
name|getDirName
argument_list|()
argument_list|,
name|finalName
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|MapredWork
name|cplan
decl_stmt|;
if|if
condition|(
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMERGERCFILEBLOCKLEVEL
argument_list|)
operator|&&
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|RCFileInputFormat
operator|.
name|class
argument_list|)
condition|)
block|{
comment|// Check if InputFormatClass is valid
name|String
name|inputFormatClass
init|=
name|parseCtx
operator|.
name|getConf
argument_list|()
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMERGEINPUTFORMATBLOCKLEVEL
argument_list|)
decl_stmt|;
try|try
block|{
name|Class
name|c
init|=
operator|(
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|inputFormatClass
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"RCFile format- Using block level merge"
argument_list|)
expr_stmt|;
name|cplan
operator|=
name|createRCFileMergeTask
argument_list|(
name|fsInputDesc
argument_list|,
name|finalName
argument_list|,
name|dpCtx
operator|!=
literal|null
operator|&&
name|dpCtx
operator|.
name|getNumDPCols
argument_list|()
operator|>
literal|0
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Illegal input format class: "
operator|+
name|inputFormatClass
decl_stmt|;
throw|throw
operator|new
name|SemanticException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|cplan
operator|=
name|createMergeTask
argument_list|(
name|ctx
operator|.
name|getConf
argument_list|()
argument_list|,
name|tsMerge
argument_list|,
name|fsInputDesc
argument_list|)
expr_stmt|;
comment|// use CombineHiveInputFormat for map-only merging
block|}
name|cplan
operator|.
name|setInputformat
argument_list|(
literal|"org.apache.hadoop.hive.ql.io.CombineHiveInputFormat"
argument_list|)
expr_stmt|;
comment|// NOTE: we should gather stats in MR1 rather than MR2 at merge job since we don't
comment|// know if merge MR2 will be triggered at execution time
name|ConditionalTask
name|cndTsk
init|=
name|createCondTask
argument_list|(
name|ctx
operator|.
name|getConf
argument_list|()
argument_list|,
name|ctx
operator|.
name|getCurrTask
argument_list|()
argument_list|,
name|dummyMv
argument_list|,
name|cplan
argument_list|,
name|fsInputDesc
operator|.
name|getDirName
argument_list|()
argument_list|)
decl_stmt|;
comment|// keep the dynamic partition context in conditional task resolver context
name|ConditionalResolverMergeFilesCtx
name|mrCtx
init|=
operator|(
name|ConditionalResolverMergeFilesCtx
operator|)
name|cndTsk
operator|.
name|getResolverCtx
argument_list|()
decl_stmt|;
name|mrCtx
operator|.
name|setDPCtx
argument_list|(
name|fsInputDesc
operator|.
name|getDynPartCtx
argument_list|()
argument_list|)
expr_stmt|;
comment|//
comment|// 3. add the moveTask as the children of the conditional task
comment|//
name|linkMoveTask
argument_list|(
name|ctx
argument_list|,
name|fsOutput
argument_list|,
name|cndTsk
argument_list|)
expr_stmt|;
block|}
comment|/**    * Make the move task in the GenMRProcContext following the FileSinkOperator a dependent of all    * possible subtrees branching from the ConditionalTask.    *    * @param ctx    * @param newOutput    * @param cndTsk    */
specifier|private
name|void
name|linkMoveTask
parameter_list|(
name|GenMRProcContext
name|ctx
parameter_list|,
name|FileSinkOperator
name|newOutput
parameter_list|,
name|ConditionalTask
name|cndTsk
parameter_list|)
block|{
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
init|=
name|ctx
operator|.
name|getMvTask
argument_list|()
decl_stmt|;
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
init|=
name|findMoveTask
argument_list|(
name|mvTasks
argument_list|,
name|newOutput
argument_list|)
decl_stmt|;
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|tsk
range|:
name|cndTsk
operator|.
name|getListTasks
argument_list|()
control|)
block|{
name|linkMoveTask
argument_list|(
name|ctx
argument_list|,
name|mvTask
argument_list|,
name|tsk
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Follows the task tree down from task and makes all leaves parents of mvTask    *    * @param ctx    * @param mvTask    * @param task    */
specifier|private
name|void
name|linkMoveTask
parameter_list|(
name|GenMRProcContext
name|ctx
parameter_list|,
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|task
parameter_list|)
block|{
if|if
condition|(
name|task
operator|.
name|getDependentTasks
argument_list|()
operator|==
literal|null
operator|||
name|task
operator|.
name|getDependentTasks
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// If it's a leaf, add the move task as a child
name|addDependentMoveTasks
argument_list|(
name|ctx
argument_list|,
name|mvTask
argument_list|,
name|task
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Otherwise, for each child run this method recursively
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|childTask
range|:
name|task
operator|.
name|getDependentTasks
argument_list|()
control|)
block|{
name|linkMoveTask
argument_list|(
name|ctx
argument_list|,
name|mvTask
argument_list|,
name|childTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Adds the dependencyTaskForMultiInsert in ctx as a dependent of parentTask.  If mvTask is a    * load table, and HIVE_MULTI_INSERT_ATOMIC_OUTPUTS is set, adds mvTask as a dependent of    * dependencyTaskForMultiInsert in ctx, otherwise adds mvTask as a dependent of parentTask as    * well.    * @param ctx    * @param mvTask    * @param parentTask    */
specifier|private
name|void
name|addDependentMoveTasks
parameter_list|(
name|GenMRProcContext
name|ctx
parameter_list|,
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|parentTask
parameter_list|)
block|{
if|if
condition|(
name|mvTask
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|ctx
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_MULTI_INSERT_MOVE_TASKS_SHARE_DEPENDENCIES
argument_list|)
condition|)
block|{
name|DependencyCollectionTask
name|dependencyTask
init|=
name|ctx
operator|.
name|getDependencyTaskForMultiInsert
argument_list|()
decl_stmt|;
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|dependencyTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|mvTask
operator|.
name|getWork
argument_list|()
operator|.
name|getLoadTableWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// Moving tables/partitions depend on the dependencyTask
name|dependencyTask
operator|.
name|addDependentTask
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Moving files depends on the parentTask (we still want the dependencyTask to depend
comment|// on the parentTask)
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|parentTask
operator|.
name|addDependentTask
argument_list|(
name|mvTask
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Create a MapredWork based on input path, the top operator and the input    * table descriptor.    * @param conf    * @param topOp the table scan operator that is the root of the MapReduce task.    * @param fsDesc the file sink descriptor that serves as the input to this merge task.    * @param parentMR the parent MapReduce work    * @param parentFS the last FileSinkOperator in the parent MapReduce work    * @return the MapredWork    */
specifier|private
name|MapredWork
name|createMergeTask
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|topOp
parameter_list|,
name|FileSinkDesc
name|fsDesc
parameter_list|)
block|{
name|ArrayList
argument_list|<
name|String
argument_list|>
name|aliases
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|inputDir
init|=
name|fsDesc
operator|.
name|getDirName
argument_list|()
decl_stmt|;
name|TableDesc
name|tblDesc
init|=
name|fsDesc
operator|.
name|getTableInfo
argument_list|()
decl_stmt|;
name|aliases
operator|.
name|add
argument_list|(
name|inputDir
argument_list|)
expr_stmt|;
comment|// dummy alias: just use the input path
comment|// constructing the default MapredWork
name|MapredWork
name|cplan
init|=
name|GenMapRedUtils
operator|.
name|getMapRedWorkFromConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|cplan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
name|aliases
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
operator|new
name|PartitionDesc
argument_list|(
name|tblDesc
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setNumReduceTasks
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
name|topOp
argument_list|)
expr_stmt|;
name|cplan
operator|.
name|setMapperCannotSpanPartns
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|cplan
return|;
block|}
comment|/**    * Create a block level merge task for RCFiles.    * @param fsInputDesc    * @param finalName    * @return MergeWork if table is stored as RCFile,    *         null otherwise    */
specifier|private
name|MapredWork
name|createRCFileMergeTask
parameter_list|(
name|FileSinkDesc
name|fsInputDesc
parameter_list|,
name|String
name|finalName
parameter_list|,
name|boolean
name|hasDynamicPartitions
parameter_list|)
throws|throws
name|SemanticException
block|{
name|String
name|inputDir
init|=
name|fsInputDesc
operator|.
name|getDirName
argument_list|()
decl_stmt|;
name|TableDesc
name|tblDesc
init|=
name|fsInputDesc
operator|.
name|getTableInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|tblDesc
operator|.
name|getInputFileFormatClass
argument_list|()
operator|.
name|equals
argument_list|(
name|RCFileInputFormat
operator|.
name|class
argument_list|)
condition|)
block|{
name|ArrayList
argument_list|<
name|String
argument_list|>
name|inputDirs
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|hasDynamicPartitions
condition|)
block|{
name|inputDirs
operator|.
name|add
argument_list|(
name|inputDir
argument_list|)
expr_stmt|;
block|}
name|MergeWork
name|work
init|=
operator|new
name|MergeWork
argument_list|(
name|inputDirs
argument_list|,
name|finalName
argument_list|,
name|hasDynamicPartitions
argument_list|,
name|fsInputDesc
operator|.
name|getDynPartCtx
argument_list|()
argument_list|)
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|pathToAliases
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|pathToAliases
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
operator|(
name|ArrayList
argument_list|<
name|String
argument_list|>
operator|)
name|inputDirs
operator|.
name|clone
argument_list|()
argument_list|)
expr_stmt|;
name|work
operator|.
name|setMapperCannotSpanPartns
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|work
operator|.
name|setPathToAliases
argument_list|(
name|pathToAliases
argument_list|)
expr_stmt|;
name|work
operator|.
name|setAliasToWork
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|hasDynamicPartitions
condition|)
block|{
name|work
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|inputDir
argument_list|,
operator|new
name|PartitionDesc
argument_list|(
name|tblDesc
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|work
return|;
block|}
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"createRCFileMergeTask called on non-RCFile table"
argument_list|)
throw|;
block|}
comment|/**    * Construct a conditional task given the current leaf task, the MoveWork and the MapredWork.    * @param conf HiveConf    * @param currTask current leaf task    * @param mvWork MoveWork for the move task    * @param mergeWork MapredWork for the merge task.    * @param inputPath the input directory of the merge/move task    * @return The conditional task    */
specifier|private
name|ConditionalTask
name|createCondTask
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
parameter_list|,
name|MoveWork
name|mvWork
parameter_list|,
name|MapredWork
name|mergeWork
parameter_list|,
name|String
name|inputPath
parameter_list|)
block|{
comment|// There are 3 options for this ConditionalTask:
comment|// 1) Merge the partitions
comment|// 2) Move the partitions (i.e. don't merge the partitions)
comment|// 3) Merge some partitions and move other partitions (i.e. merge some partitions and don't
comment|//    merge others) in this case the merge is done first followed by the move to prevent
comment|//    conflicts.
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mergeOnlyMergeTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mergeWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|moveOnlyMoveTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mvWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mergeAndMoveMergeTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mergeWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mergeAndMoveMoveTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
name|mvWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
comment|// NOTE! It is necessary merge task is the parent of the move task, and not
comment|// the other way around, for the proper execution of the execute method of
comment|// ConditionalTask
name|mergeAndMoveMergeTask
operator|.
name|addDependentTask
argument_list|(
name|mergeAndMoveMoveTask
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Serializable
argument_list|>
name|listWorks
init|=
operator|new
name|ArrayList
argument_list|<
name|Serializable
argument_list|>
argument_list|()
decl_stmt|;
name|listWorks
operator|.
name|add
argument_list|(
name|mvWork
argument_list|)
expr_stmt|;
name|listWorks
operator|.
name|add
argument_list|(
name|mergeWork
argument_list|)
expr_stmt|;
name|ConditionalWork
name|cndWork
init|=
operator|new
name|ConditionalWork
argument_list|(
name|listWorks
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|listTasks
init|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|moveOnlyMoveTask
argument_list|)
expr_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|mergeOnlyMergeTask
argument_list|)
expr_stmt|;
name|listTasks
operator|.
name|add
argument_list|(
name|mergeAndMoveMergeTask
argument_list|)
expr_stmt|;
name|ConditionalTask
name|cndTsk
init|=
operator|(
name|ConditionalTask
operator|)
name|TaskFactory
operator|.
name|get
argument_list|(
name|cndWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|cndTsk
operator|.
name|setListTasks
argument_list|(
name|listTasks
argument_list|)
expr_stmt|;
comment|// create resolver
name|cndTsk
operator|.
name|setResolver
argument_list|(
operator|new
name|ConditionalResolverMergeFiles
argument_list|()
argument_list|)
expr_stmt|;
name|ConditionalResolverMergeFilesCtx
name|mrCtx
init|=
operator|new
name|ConditionalResolverMergeFilesCtx
argument_list|(
name|listTasks
argument_list|,
name|inputPath
argument_list|)
decl_stmt|;
name|cndTsk
operator|.
name|setResolverCtx
argument_list|(
name|mrCtx
argument_list|)
expr_stmt|;
comment|// make the conditional task as the child of the current leaf task
name|currTask
operator|.
name|addDependentTask
argument_list|(
name|cndTsk
argument_list|)
expr_stmt|;
return|return
name|cndTsk
return|;
block|}
specifier|private
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|findMoveTask
parameter_list|(
name|List
argument_list|<
name|Task
argument_list|<
name|MoveWork
argument_list|>
argument_list|>
name|mvTasks
parameter_list|,
name|FileSinkOperator
name|fsOp
parameter_list|)
block|{
comment|// find the move task
for|for
control|(
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTsk
range|:
name|mvTasks
control|)
block|{
name|MoveWork
name|mvWork
init|=
name|mvTsk
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|String
name|srcDir
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|srcDir
operator|=
name|mvWork
operator|.
name|getLoadFileWork
argument_list|()
operator|.
name|getSourceDir
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|srcDir
operator|=
name|mvWork
operator|.
name|getLoadTableWork
argument_list|()
operator|.
name|getSourceDir
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|srcDir
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|srcDir
operator|.
name|equalsIgnoreCase
argument_list|(
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getDirName
argument_list|()
argument_list|)
operator|)
condition|)
block|{
return|return
name|mvTsk
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Process the FileSink operator to generate a MoveTask if necessary.    * @param nd current FileSink operator    * @param stack parent operators    * @param opProcCtx    * @param chDir whether the operator should be first output to a tmp dir and then merged    *        to the final dir later    * @return the final file name to which the FileSinkOperator should store.    * @throws SemanticException    */
specifier|private
name|String
name|processFS
parameter_list|(
name|Node
name|nd
parameter_list|,
name|Stack
argument_list|<
name|Node
argument_list|>
name|stack
parameter_list|,
name|NodeProcessorCtx
name|opProcCtx
parameter_list|,
name|boolean
name|chDir
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// Is it the dummy file sink after the mapjoin
name|FileSinkOperator
name|fsOp
init|=
operator|(
name|FileSinkOperator
operator|)
name|nd
decl_stmt|;
if|if
condition|(
operator|(
name|fsOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|)
operator|&&
operator|(
name|fsOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|instanceof
name|MapJoinOperator
operator|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|GenMRProcContext
name|ctx
init|=
operator|(
name|GenMRProcContext
operator|)
name|opProcCtx
decl_stmt|;
name|List
argument_list|<
name|FileSinkOperator
argument_list|>
name|seenFSOps
init|=
name|ctx
operator|.
name|getSeenFileSinkOps
argument_list|()
decl_stmt|;
if|if
condition|(
name|seenFSOps
operator|==
literal|null
condition|)
block|{
name|seenFSOps
operator|=
operator|new
name|ArrayList
argument_list|<
name|FileSinkOperator
argument_list|>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|seenFSOps
operator|.
name|contains
argument_list|(
name|fsOp
argument_list|)
condition|)
block|{
name|seenFSOps
operator|.
name|add
argument_list|(
name|fsOp
argument_list|)
expr_stmt|;
block|}
name|ctx
operator|.
name|setSeenFileSinkOps
argument_list|(
name|seenFSOps
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTask
init|=
name|ctx
operator|.
name|getCurrTask
argument_list|()
decl_stmt|;
comment|// If the directory needs to be changed, send the new directory
name|String
name|dest
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|chDir
condition|)
block|{
name|dest
operator|=
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|getDirName
argument_list|()
expr_stmt|;
comment|// generate the temporary file
comment|// it must be on the same file system as the current destination
name|ParseContext
name|parseCtx
init|=
name|ctx
operator|.
name|getParseCtx
argument_list|()
decl_stmt|;
name|Context
name|baseCtx
init|=
name|parseCtx
operator|.
name|getContext
argument_list|()
decl_stmt|;
name|String
name|tmpDir
init|=
name|baseCtx
operator|.
name|getExternalTmpFileURI
argument_list|(
operator|(
operator|new
name|Path
argument_list|(
name|dest
argument_list|)
operator|)
operator|.
name|toUri
argument_list|()
argument_list|)
decl_stmt|;
name|fsOp
operator|.
name|getConf
argument_list|()
operator|.
name|setDirName
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
block|}
name|Task
argument_list|<
name|MoveWork
argument_list|>
name|mvTask
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|chDir
condition|)
block|{
name|mvTask
operator|=
name|findMoveTask
argument_list|(
name|ctx
operator|.
name|getMvTask
argument_list|()
argument_list|,
name|fsOp
argument_list|)
expr_stmt|;
block|}
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|currTopOp
init|=
name|ctx
operator|.
name|getCurrTopOp
argument_list|()
decl_stmt|;
name|String
name|currAliasId
init|=
name|ctx
operator|.
name|getCurrAliasId
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|opTaskMap
init|=
name|ctx
operator|.
name|getOpTaskMap
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|seenOps
init|=
name|ctx
operator|.
name|getSeenOps
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|rootTasks
init|=
name|ctx
operator|.
name|getRootTasks
argument_list|()
decl_stmt|;
comment|// Set the move task to be dependent on the current task
if|if
condition|(
name|mvTask
operator|!=
literal|null
condition|)
block|{
name|addDependentMoveTasks
argument_list|(
name|ctx
argument_list|,
name|mvTask
argument_list|,
name|currTask
argument_list|)
expr_stmt|;
block|}
comment|// In case of multi-table insert, the path to alias mapping is needed for
comment|// all the sources. Since there is no
comment|// reducer, treat it as a plan with null reducer
comment|// If it is a map-only job, the task needs to be processed
if|if
condition|(
name|currTopOp
operator|!=
literal|null
condition|)
block|{
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|mapTask
init|=
name|opTaskMap
operator|.
name|get
argument_list|(
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapTask
operator|==
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|seenOps
operator|.
name|contains
argument_list|(
name|currTopOp
argument_list|)
condition|)
block|{
name|seenOps
operator|.
name|add
argument_list|(
name|currTopOp
argument_list|)
expr_stmt|;
name|GenMapRedUtils
operator|.
name|setTaskPlan
argument_list|(
name|currAliasId
argument_list|,
name|currTopOp
argument_list|,
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
argument_list|,
literal|false
argument_list|,
name|ctx
argument_list|)
expr_stmt|;
block|}
name|opTaskMap
operator|.
name|put
argument_list|(
literal|null
argument_list|,
name|currTask
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|rootTasks
operator|.
name|contains
argument_list|(
name|currTask
argument_list|)
condition|)
block|{
name|rootTasks
operator|.
name|add
argument_list|(
name|currTask
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|seenOps
operator|.
name|contains
argument_list|(
name|currTopOp
argument_list|)
condition|)
block|{
name|seenOps
operator|.
name|add
argument_list|(
name|currTopOp
argument_list|)
expr_stmt|;
name|GenMapRedUtils
operator|.
name|setTaskPlan
argument_list|(
name|currAliasId
argument_list|,
name|currTopOp
argument_list|,
operator|(
name|MapredWork
operator|)
name|mapTask
operator|.
name|getWork
argument_list|()
argument_list|,
literal|false
argument_list|,
name|ctx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|UnionOperator
name|currUnionOp
init|=
name|ctx
operator|.
name|getCurrUnionOp
argument_list|()
decl_stmt|;
if|if
condition|(
name|currUnionOp
operator|!=
literal|null
condition|)
block|{
name|opTaskMap
operator|.
name|put
argument_list|(
literal|null
argument_list|,
name|currTask
argument_list|)
expr_stmt|;
name|ctx
operator|.
name|setCurrTopOp
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|GenMapRedUtils
operator|.
name|initUnionPlan
argument_list|(
name|ctx
argument_list|,
name|currTask
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
name|dest
return|;
block|}
block|}
comment|// mapTask and currTask should be merged by and join/union operator
comment|// (e.g., GenMRUnion1j) which has multiple topOps.
comment|// assert mapTask == currTask : "mapTask.id = " + mapTask.getId()
comment|// + "; currTask.id = " + currTask.getId();
block|}
return|return
name|dest
return|;
block|}
name|UnionOperator
name|currUnionOp
init|=
name|ctx
operator|.
name|getCurrUnionOp
argument_list|()
decl_stmt|;
if|if
condition|(
name|currUnionOp
operator|!=
literal|null
condition|)
block|{
name|opTaskMap
operator|.
name|put
argument_list|(
literal|null
argument_list|,
name|currTask
argument_list|)
expr_stmt|;
name|GenMapRedUtils
operator|.
name|initUnionPlan
argument_list|(
name|ctx
argument_list|,
name|currTask
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
name|dest
return|;
block|}
name|AbstractMapJoinOperator
argument_list|<
name|?
extends|extends
name|MapJoinDesc
argument_list|>
name|currMapJoinOp
init|=
name|ctx
operator|.
name|getCurrMapJoinOp
argument_list|()
decl_stmt|;
if|if
condition|(
name|currMapJoinOp
operator|!=
literal|null
condition|)
block|{
name|opTaskMap
operator|.
name|put
argument_list|(
literal|null
argument_list|,
name|currTask
argument_list|)
expr_stmt|;
name|GenMRMapJoinCtx
name|mjCtx
init|=
name|ctx
operator|.
name|getMapJoinCtx
argument_list|(
name|currMapJoinOp
argument_list|)
decl_stmt|;
name|MapredWork
name|plan
init|=
operator|(
name|MapredWork
operator|)
name|currTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|String
name|taskTmpDir
init|=
name|mjCtx
operator|.
name|getTaskTmpDir
argument_list|()
decl_stmt|;
name|TableDesc
name|tt_desc
init|=
name|mjCtx
operator|.
name|getTTDesc
argument_list|()
decl_stmt|;
assert|assert
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|taskTmpDir
argument_list|)
operator|==
literal|null
assert|;
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|put
argument_list|(
name|taskTmpDir
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|taskTmpDir
argument_list|)
operator|.
name|add
argument_list|(
name|taskTmpDir
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|put
argument_list|(
name|taskTmpDir
argument_list|,
operator|new
name|PartitionDesc
argument_list|(
name|tt_desc
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|plan
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|put
argument_list|(
name|taskTmpDir
argument_list|,
name|mjCtx
operator|.
name|getRootMapJoinOp
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|dest
return|;
block|}
return|return
name|dest
return|;
block|}
block|}
end_class

end_unit

