begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Stack
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MapJoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ReduceSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|NodeProcessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|NodeProcessorCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|GenTezProcContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|BaseWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezWork
operator|.
name|EdgeType
import|;
end_import

begin_class
specifier|public
class|class
name|ReduceSinkMapJoinProc
implements|implements
name|NodeProcessor
block|{
comment|/* (non-Javadoc)    * This processor addresses the RS-MJ case that occurs in tez on the small/hash    * table side of things. The connection between the work that RS will be a part of    * must be connected to the MJ work via be a broadcast edge.    * We should not walk down the tree when we encounter this pattern because:    * the type of work (map work or reduce work) needs to be determined    * on the basis of the big table side because it may be a mapwork (no need for shuffle)    * or reduce work.    */
annotation|@
name|Override
specifier|public
name|Object
name|process
parameter_list|(
name|Node
name|nd
parameter_list|,
name|Stack
argument_list|<
name|Node
argument_list|>
name|stack
parameter_list|,
name|NodeProcessorCtx
name|procContext
parameter_list|,
name|Object
modifier|...
name|nodeOutputs
parameter_list|)
throws|throws
name|SemanticException
block|{
name|GenTezProcContext
name|context
init|=
operator|(
name|GenTezProcContext
operator|)
name|procContext
decl_stmt|;
name|context
operator|.
name|preceedingWork
operator|=
literal|null
expr_stmt|;
name|context
operator|.
name|currentRootOperator
operator|=
literal|null
expr_stmt|;
name|MapJoinOperator
name|mapJoinOp
init|=
operator|(
name|MapJoinOperator
operator|)
name|nd
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|childOp
init|=
name|mapJoinOp
operator|.
name|getChildOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|ReduceSinkOperator
name|parentRS
init|=
operator|(
name|ReduceSinkOperator
operator|)
name|stack
operator|.
name|get
argument_list|(
name|stack
operator|.
name|size
argument_list|()
operator|-
literal|2
argument_list|)
decl_stmt|;
while|while
condition|(
name|childOp
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|(
name|childOp
operator|instanceof
name|ReduceSinkOperator
operator|)
operator|||
operator|(
name|childOp
operator|instanceof
name|FileSinkOperator
operator|)
condition|)
block|{
comment|/*          *  if there was a pre-existing work generated for the big-table mapjoin side,          *  we need to hook the work generated for the RS (associated with the RS-MJ pattern)          *  with the pre-existing work.          *          *  Otherwise, we need to associate that the reduce sink/file sink down the MJ path          *  to be linked to the RS work (associated with the RS-MJ pattern).          *          */
name|BaseWork
name|myWork
init|=
name|context
operator|.
name|operatorWorkMap
operator|.
name|get
argument_list|(
name|childOp
argument_list|)
decl_stmt|;
name|BaseWork
name|parentWork
init|=
name|context
operator|.
name|operatorWorkMap
operator|.
name|get
argument_list|(
name|parentRS
argument_list|)
decl_stmt|;
if|if
condition|(
name|myWork
operator|!=
literal|null
condition|)
block|{
comment|// link the work with the work associated with the reduce sink that triggered this rule
name|TezWork
name|tezWork
init|=
name|context
operator|.
name|currentTask
operator|.
name|getWork
argument_list|()
decl_stmt|;
name|tezWork
operator|.
name|connect
argument_list|(
name|parentWork
argument_list|,
name|myWork
argument_list|,
name|EdgeType
operator|.
name|BROADCAST_EDGE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|BaseWork
argument_list|>
name|linkWorkList
init|=
name|context
operator|.
name|linkOpWithWorkMap
operator|.
name|get
argument_list|(
name|childOp
argument_list|)
decl_stmt|;
if|if
condition|(
name|linkWorkList
operator|==
literal|null
condition|)
block|{
name|linkWorkList
operator|=
operator|new
name|ArrayList
argument_list|<
name|BaseWork
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|linkWorkList
operator|.
name|add
argument_list|(
name|parentWork
argument_list|)
expr_stmt|;
name|context
operator|.
name|linkOpWithWorkMap
operator|.
name|put
argument_list|(
name|childOp
argument_list|,
name|linkWorkList
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
if|if
condition|(
operator|(
name|childOp
operator|.
name|getChildOperators
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|childOp
operator|.
name|getChildOperators
argument_list|()
operator|.
name|size
argument_list|()
operator|>=
literal|1
operator|)
condition|)
block|{
name|childOp
operator|=
name|childOp
operator|.
name|getChildOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
break|break;
block|}
block|}
comment|// cut the operator tree so as to not retain connections from the parent RS downstream
name|parentRS
operator|.
name|removeChild
argument_list|(
name|mapJoinOp
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
end_class

end_unit

