begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|mapredWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|tableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|partitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|PrimitiveObjectInspectorFactory
import|;
end_import

begin_comment
comment|/**  * Map operator. This triggers overall map side processing.  * This is a little different from regular operators in that  * it starts off by processing a Writable data structure from  * a Table (instead of a Hive Object).  **/
end_comment

begin_class
specifier|public
class|class
name|MapOperator
extends|extends
name|Operator
argument_list|<
name|mapredWork
argument_list|>
implements|implements
name|Serializable
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|public
specifier|static
enum|enum
name|Counter
block|{
name|DESERIALIZE_ERRORS
block|}
specifier|transient
specifier|private
name|LongWritable
name|deserialize_error_count
init|=
operator|new
name|LongWritable
argument_list|()
decl_stmt|;
specifier|transient
specifier|private
name|Deserializer
name|deserializer
decl_stmt|;
specifier|transient
specifier|private
name|Object
name|row
decl_stmt|;
specifier|transient
specifier|private
name|Object
index|[]
name|rowWithPart
decl_stmt|;
specifier|transient
specifier|private
name|StructObjectInspector
name|rowObjectInspector
decl_stmt|;
specifier|transient
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|partNames
decl_stmt|;
specifier|transient
specifier|private
name|Object
index|[]
name|partValues
decl_stmt|;
specifier|transient
specifier|private
name|List
argument_list|<
name|ObjectInspector
argument_list|>
name|partObjectInspectors
decl_stmt|;
specifier|public
name|void
name|initialize
parameter_list|(
name|Configuration
name|hconf
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|HiveException
block|{
name|super
operator|.
name|initialize
argument_list|(
name|hconf
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
name|Path
name|fpath
init|=
operator|new
name|Path
argument_list|(
operator|(
operator|new
name|Path
argument_list|(
name|HiveConf
operator|.
name|getVar
argument_list|(
name|hconf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPMAPFILENAME
argument_list|)
argument_list|)
operator|)
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|todo
init|=
operator|new
name|ArrayList
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|statsMap
operator|.
name|put
argument_list|(
name|Counter
operator|.
name|DESERIALIZE_ERRORS
argument_list|,
name|deserialize_error_count
argument_list|)
expr_stmt|;
comment|// for each configuration path that fpath can be relativized against ..
for|for
control|(
name|String
name|onefile
range|:
name|conf
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
name|Path
name|onepath
init|=
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|onefile
argument_list|)
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|onepath
operator|.
name|toUri
argument_list|()
operator|.
name|relativize
argument_list|(
name|fpath
operator|.
name|toUri
argument_list|()
argument_list|)
operator|.
name|equals
argument_list|(
name|fpath
operator|.
name|toUri
argument_list|()
argument_list|)
condition|)
block|{
comment|// pick up work corresponding to this configuration path
name|List
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|conf
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|get
argument_list|(
name|onefile
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|onealias
range|:
name|aliases
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Adding alias "
operator|+
name|onealias
operator|+
literal|" to work list for file "
operator|+
name|fpath
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|todo
operator|.
name|add
argument_list|(
name|conf
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|onealias
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// initialize decoder once based on what table we are processing
if|if
condition|(
name|deserializer
operator|!=
literal|null
condition|)
block|{
continue|continue;
block|}
name|partitionDesc
name|pd
init|=
name|conf
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|get
argument_list|(
name|onefile
argument_list|)
decl_stmt|;
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|pd
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
name|tableDesc
name|td
init|=
name|pd
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
name|Properties
name|p
init|=
name|td
operator|.
name|getProperties
argument_list|()
decl_stmt|;
comment|// Add alias, table name, and partitions to hadoop conf
name|HiveConf
operator|.
name|setVar
argument_list|(
name|hconf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVETABLENAME
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|p
operator|.
name|getProperty
argument_list|(
literal|"name"
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|HiveConf
operator|.
name|setVar
argument_list|(
name|hconf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEPARTITIONNAME
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|partSpec
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|Class
name|sdclass
init|=
name|td
operator|.
name|getDeserializerClass
argument_list|()
decl_stmt|;
if|if
condition|(
name|sdclass
operator|==
literal|null
condition|)
block|{
name|String
name|className
init|=
name|td
operator|.
name|getSerdeClassName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|className
operator|==
literal|""
operator|)
operator|||
operator|(
name|className
operator|==
literal|null
operator|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"SerDe class or the SerDe class name is not set for table: "
operator|+
name|td
operator|.
name|getProperties
argument_list|()
operator|.
name|getProperty
argument_list|(
literal|"name"
argument_list|)
argument_list|)
throw|;
block|}
name|sdclass
operator|=
name|MapOperator
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
operator|.
name|loadClass
argument_list|(
name|className
argument_list|)
expr_stmt|;
block|}
name|deserializer
operator|=
operator|(
name|Deserializer
operator|)
name|sdclass
operator|.
name|newInstance
argument_list|()
expr_stmt|;
name|deserializer
operator|.
name|initialize
argument_list|(
name|hconf
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|rowObjectInspector
operator|=
operator|(
name|StructObjectInspector
operator|)
name|deserializer
operator|.
name|getObjectInspector
argument_list|()
expr_stmt|;
comment|// Next check if this table has partitions and if so
comment|// get the list of partition names as well as allocate
comment|// the serdes for the partition columns
name|String
name|pcols
init|=
name|p
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|)
decl_stmt|;
if|if
condition|(
name|pcols
operator|!=
literal|null
operator|&&
name|pcols
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|String
index|[]
name|partKeys
init|=
name|pcols
operator|.
name|trim
argument_list|()
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|partNames
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|partKeys
operator|.
name|length
argument_list|)
expr_stmt|;
name|partValues
operator|=
operator|new
name|Object
index|[
name|partKeys
operator|.
name|length
index|]
expr_stmt|;
name|partObjectInspectors
operator|=
operator|new
name|ArrayList
argument_list|<
name|ObjectInspector
argument_list|>
argument_list|(
name|partKeys
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partKeys
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|key
init|=
name|partKeys
index|[
name|i
index|]
decl_stmt|;
name|partNames
operator|.
name|add
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|partValues
index|[
name|i
index|]
operator|=
operator|new
name|Text
argument_list|(
name|partSpec
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|partObjectInspectors
operator|.
name|add
argument_list|(
name|PrimitiveObjectInspectorFactory
operator|.
name|writableStringObjectInspector
argument_list|)
expr_stmt|;
block|}
name|StructObjectInspector
name|partObjectInspector
init|=
name|ObjectInspectorFactory
operator|.
name|getStandardStructObjectInspector
argument_list|(
name|partNames
argument_list|,
name|partObjectInspectors
argument_list|)
decl_stmt|;
name|rowWithPart
operator|=
operator|new
name|Object
index|[
literal|2
index|]
expr_stmt|;
name|rowWithPart
index|[
literal|1
index|]
operator|=
name|partValues
expr_stmt|;
name|rowObjectInspector
operator|=
name|ObjectInspectorFactory
operator|.
name|getUnionStructObjectInspector
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
operator|new
name|StructObjectInspector
index|[]
block|{
name|rowObjectInspector
block|,
name|partObjectInspector
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partNames
operator|=
literal|null
expr_stmt|;
name|partValues
operator|=
literal|null
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Got partitions: "
operator|+
name|pcols
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|InstantiationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IllegalAccessException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|todo
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// didn't find match for input file path in configuration!
comment|// serious problem ..
name|LOG
operator|.
name|error
argument_list|(
literal|"Configuration does not have any alias for path: "
operator|+
name|fpath
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Configuration and input path are inconsistent"
argument_list|)
throw|;
block|}
comment|// we found all the operators that we are supposed to process. now bootstrap
name|this
operator|.
name|setChildOperators
argument_list|(
name|todo
argument_list|)
expr_stmt|;
comment|// the child operators may need the global mr configuration. set it now so
comment|// that they can get access during initiaize.
name|this
operator|.
name|setMapredWork
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// way hacky - need to inform child operators about output collector
name|this
operator|.
name|setOutputCollector
argument_list|(
name|out
argument_list|)
expr_stmt|;
for|for
control|(
name|Operator
name|op
range|:
name|todo
control|)
block|{
name|op
operator|.
name|initialize
argument_list|(
name|hconf
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|process
parameter_list|(
name|Writable
name|value
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
name|partNames
operator|==
literal|null
condition|)
block|{
name|row
operator|=
name|deserializer
operator|.
name|deserialize
argument_list|(
name|value
argument_list|)
expr_stmt|;
name|forward
argument_list|(
name|row
argument_list|,
name|rowObjectInspector
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|rowWithPart
index|[
literal|0
index|]
operator|=
name|deserializer
operator|.
name|deserialize
argument_list|(
name|value
argument_list|)
expr_stmt|;
name|forward
argument_list|(
name|rowWithPart
argument_list|,
name|rowObjectInspector
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
comment|// TODO: policy on deserialization errors
name|deserialize_error_count
operator|.
name|set
argument_list|(
name|deserialize_error_count
operator|.
name|get
argument_list|()
operator|+
literal|1
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|process
parameter_list|(
name|Object
name|row
parameter_list|,
name|ObjectInspector
name|rowInspector
parameter_list|)
throws|throws
name|HiveException
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Hive 2 Internal error: should not be called!"
argument_list|)
throw|;
block|}
block|}
end_class

end_unit

