begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidTxnList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidWriteIdList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|IMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NotificationEvent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SQLForeignKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SQLNotNullConstraint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SQLPrimaryKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SQLUniqueConstraint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|messaging
operator|.
name|event
operator|.
name|filters
operator|.
name|AndFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|messaging
operator|.
name|event
operator|.
name|filters
operator|.
name|DatabaseAndTableFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|messaging
operator|.
name|event
operator|.
name|filters
operator|.
name|EventBoundaryFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|DriverContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Task
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
operator|.
name|util
operator|.
name|ReplUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|LockException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Hive
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|InvalidTableException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|events
operator|.
name|EventUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|BaseSemanticAnalyzer
operator|.
name|TableSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|EximUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ReplicationSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|DumpType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|ReplLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|HiveWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|TableExport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|events
operator|.
name|EventHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|events
operator|.
name|EventHandlerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|io
operator|.
name|ConstraintsSerializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|io
operator|.
name|FunctionSerializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|io
operator|.
name|JsonWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|log
operator|.
name|BootstrapDumpLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|log
operator|.
name|IncrementalDumpLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|DumpMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExportWork
operator|.
name|MmContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|api
operator|.
name|StageType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
operator|.
name|ReplExternalTables
operator|.
name|Writer
import|;
end_import

begin_class
specifier|public
class|class
name|ReplDumpTask
extends|extends
name|Task
argument_list|<
name|ReplDumpWork
argument_list|>
implements|implements
name|Serializable
block|{
specifier|private
specifier|static
specifier|final
name|String
name|dumpSchema
init|=
literal|"dump_dir,last_repl_id#string,string"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|FUNCTION_METADATA_FILE_NAME
init|=
name|EximUtil
operator|.
name|METADATA_NAME
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|SLEEP_TIME
init|=
literal|60000
decl_stmt|;
specifier|public
enum|enum
name|ConstraintFileType
block|{
name|COMMON
argument_list|(
literal|"common"
argument_list|,
literal|"c_"
argument_list|)
block|,
name|FOREIGNKEY
argument_list|(
literal|"fk"
argument_list|,
literal|"f_"
argument_list|)
block|;
specifier|private
specifier|final
name|String
name|name
decl_stmt|;
specifier|private
specifier|final
name|String
name|prefix
decl_stmt|;
name|ConstraintFileType
parameter_list|(
name|String
name|name
parameter_list|,
name|String
name|prefix
parameter_list|)
block|{
name|this
operator|.
name|name
operator|=
name|name
expr_stmt|;
name|this
operator|.
name|prefix
operator|=
name|prefix
expr_stmt|;
block|}
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
name|this
operator|.
name|name
return|;
block|}
specifier|public
name|String
name|getPrefix
parameter_list|()
block|{
return|return
name|prefix
return|;
block|}
block|}
specifier|private
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|ReplDumpTask
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|ReplLogger
name|replLogger
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
literal|"REPL_DUMP"
return|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|execute
parameter_list|(
name|DriverContext
name|driverContext
parameter_list|)
block|{
try|try
block|{
name|Hive
name|hiveDb
init|=
name|getHive
argument_list|()
decl_stmt|;
name|Path
name|dumpRoot
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPLDIR
argument_list|)
argument_list|,
name|getNextDumpDir
argument_list|()
argument_list|)
decl_stmt|;
name|DumpMetaData
name|dmd
init|=
operator|new
name|DumpMetaData
argument_list|(
name|dumpRoot
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Path
name|cmRoot
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPLCMDIR
argument_list|)
argument_list|)
decl_stmt|;
name|Long
name|lastReplId
decl_stmt|;
if|if
condition|(
name|work
operator|.
name|isBootStrapDump
argument_list|()
condition|)
block|{
name|lastReplId
operator|=
name|bootStrapDump
argument_list|(
name|dumpRoot
argument_list|,
name|dmd
argument_list|,
name|cmRoot
argument_list|,
name|hiveDb
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|lastReplId
operator|=
name|incrementalDump
argument_list|(
name|dumpRoot
argument_list|,
name|dmd
argument_list|,
name|cmRoot
argument_list|,
name|hiveDb
argument_list|)
expr_stmt|;
block|}
name|prepareReturnValues
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|dumpRoot
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|lastReplId
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setException
argument_list|(
name|e
argument_list|)
expr_stmt|;
return|return
name|ErrorMsg
operator|.
name|getErrorMsg
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
operator|.
name|getErrorCode
argument_list|()
return|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|void
name|prepareReturnValues
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|values
parameter_list|)
throws|throws
name|SemanticException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"prepareReturnValues : "
operator|+
name|dumpSchema
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|values
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"> "
operator|+
name|s
argument_list|)
expr_stmt|;
block|}
name|Utils
operator|.
name|writeOutput
argument_list|(
name|values
argument_list|,
operator|new
name|Path
argument_list|(
name|work
operator|.
name|resultTempPath
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
specifier|private
name|Long
name|incrementalDump
parameter_list|(
name|Path
name|dumpRoot
parameter_list|,
name|DumpMetaData
name|dmd
parameter_list|,
name|Path
name|cmRoot
parameter_list|,
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|Exception
block|{
name|Long
name|lastReplId
decl_stmt|;
comment|// get list of events matching dbPattern& tblPattern
comment|// go through each event, and dump out each event to a event-level dump dir inside dumproot
comment|// TODO : instead of simply restricting by message format, we should eventually
comment|// move to a jdbc-driver-stype registering of message format, and picking message
comment|// factory per event to decode. For now, however, since all messages have the
comment|// same factory, restricting by message format is effectively a guard against
comment|// older leftover data that would cause us problems.
name|work
operator|.
name|overrideEventTo
argument_list|(
name|hiveDb
argument_list|)
expr_stmt|;
name|IMetaStoreClient
operator|.
name|NotificationFilter
name|evFilter
init|=
operator|new
name|AndFilter
argument_list|(
operator|new
name|DatabaseAndTableFilter
argument_list|(
name|work
operator|.
name|dbNameOrPattern
argument_list|,
name|work
operator|.
name|tableNameOrPattern
argument_list|)
argument_list|,
operator|new
name|EventBoundaryFilter
argument_list|(
name|work
operator|.
name|eventFrom
argument_list|,
name|work
operator|.
name|eventTo
argument_list|)
argument_list|)
decl_stmt|;
name|EventUtils
operator|.
name|MSClientNotificationFetcher
name|evFetcher
init|=
operator|new
name|EventUtils
operator|.
name|MSClientNotificationFetcher
argument_list|(
name|hiveDb
argument_list|)
decl_stmt|;
name|EventUtils
operator|.
name|NotificationEventIterator
name|evIter
init|=
operator|new
name|EventUtils
operator|.
name|NotificationEventIterator
argument_list|(
name|evFetcher
argument_list|,
name|work
operator|.
name|eventFrom
argument_list|,
name|work
operator|.
name|maxEventLimit
argument_list|()
argument_list|,
name|evFilter
argument_list|)
decl_stmt|;
name|lastReplId
operator|=
name|work
operator|.
name|eventTo
expr_stmt|;
comment|// Right now the only pattern allowed to be specified is *, which matches all the database
comment|// names. So passing dbname as is works since getDbNotificationEventsCount can exclude filter
comment|// on database name when it's *. In future, if we support more elaborate patterns, we will
comment|// have to pass DatabaseAndTableFilter created above to getDbNotificationEventsCount() to get
comment|// correct event count.
name|String
name|dbName
init|=
operator|(
literal|null
operator|!=
name|work
operator|.
name|dbNameOrPattern
operator|&&
operator|!
name|work
operator|.
name|dbNameOrPattern
operator|.
name|isEmpty
argument_list|()
operator|)
condition|?
name|work
operator|.
name|dbNameOrPattern
else|:
literal|"?"
decl_stmt|;
name|replLogger
operator|=
operator|new
name|IncrementalDumpLogger
argument_list|(
name|dbName
argument_list|,
name|dumpRoot
operator|.
name|toString
argument_list|()
argument_list|,
name|evFetcher
operator|.
name|getDbNotificationEventsCount
argument_list|(
name|work
operator|.
name|eventFrom
argument_list|,
name|dbName
argument_list|,
name|work
operator|.
name|eventTo
argument_list|,
name|work
operator|.
name|maxEventLimit
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|replLogger
operator|.
name|startLog
argument_list|()
expr_stmt|;
while|while
condition|(
name|evIter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|NotificationEvent
name|ev
init|=
name|evIter
operator|.
name|next
argument_list|()
decl_stmt|;
name|lastReplId
operator|=
name|ev
operator|.
name|getEventId
argument_list|()
expr_stmt|;
name|Path
name|evRoot
init|=
operator|new
name|Path
argument_list|(
name|dumpRoot
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|lastReplId
argument_list|)
argument_list|)
decl_stmt|;
name|dumpEvent
argument_list|(
name|ev
argument_list|,
name|evRoot
argument_list|,
name|cmRoot
argument_list|,
name|hiveDb
argument_list|)
expr_stmt|;
block|}
name|replLogger
operator|.
name|endLog
argument_list|(
name|lastReplId
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Done dumping events, preparing to return {},{}"
argument_list|,
name|dumpRoot
operator|.
name|toUri
argument_list|()
argument_list|,
name|lastReplId
argument_list|)
expr_stmt|;
name|Utils
operator|.
name|writeOutput
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
literal|"incremental"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|work
operator|.
name|eventFrom
argument_list|)
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|lastReplId
argument_list|)
argument_list|)
argument_list|,
name|dmd
operator|.
name|getDumpFilePath
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|dmd
operator|.
name|setDump
argument_list|(
name|DumpType
operator|.
name|INCREMENTAL
argument_list|,
name|work
operator|.
name|eventFrom
argument_list|,
name|lastReplId
argument_list|,
name|cmRoot
argument_list|)
expr_stmt|;
name|dmd
operator|.
name|write
argument_list|()
expr_stmt|;
comment|// If external tables are enabled for replication and
comment|// - If bootstrap is enabled, then need to combine bootstrap dump of external tables.
comment|// - If metadata-only dump is enabled, then shall skip dumping external tables data locations to
comment|//   _external_tables_info file. If not metadata-only, then dump the data locations.
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_INCLUDE_EXTERNAL_TABLES
argument_list|)
operator|&&
operator|(
operator|!
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_DUMP_METADATA_ONLY
argument_list|)
operator|||
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_BOOTSTRAP_EXTERNAL_TABLES
argument_list|)
operator|)
condition|)
block|{
name|Path
name|dbRoot
init|=
name|getBootstrapDbRoot
argument_list|(
name|dumpRoot
argument_list|,
name|dbName
argument_list|,
literal|true
argument_list|)
decl_stmt|;
try|try
init|(
name|Writer
name|writer
init|=
operator|new
name|Writer
argument_list|(
name|dumpRoot
argument_list|,
name|conf
argument_list|)
init|)
block|{
for|for
control|(
name|String
name|tableName
range|:
name|Utils
operator|.
name|matchesTbl
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|,
name|work
operator|.
name|tableNameOrPattern
argument_list|)
control|)
block|{
name|Table
name|table
init|=
name|hiveDb
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|TableType
operator|.
name|EXTERNAL_TABLE
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
condition|)
block|{
name|writer
operator|.
name|dataLocationDump
argument_list|(
name|table
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_BOOTSTRAP_EXTERNAL_TABLES
argument_list|)
condition|)
block|{
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Table
argument_list|>
name|tableTuple
init|=
operator|new
name|HiveWrapper
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|)
operator|.
name|table
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|dumpTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
literal|null
argument_list|,
name|dbRoot
argument_list|,
literal|0
argument_list|,
name|hiveDb
argument_list|,
name|tableTuple
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
return|return
name|lastReplId
return|;
block|}
specifier|private
name|Path
name|getBootstrapDbRoot
parameter_list|(
name|Path
name|dumpRoot
parameter_list|,
name|String
name|dbName
parameter_list|,
name|boolean
name|isIncrementalPhase
parameter_list|)
block|{
if|if
condition|(
name|isIncrementalPhase
condition|)
block|{
name|dumpRoot
operator|=
operator|new
name|Path
argument_list|(
name|dumpRoot
argument_list|,
name|ReplUtils
operator|.
name|INC_BOOTSTRAP_ROOT_DIR_NAME
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|dumpRoot
argument_list|,
name|dbName
argument_list|)
return|;
block|}
specifier|private
name|void
name|dumpEvent
parameter_list|(
name|NotificationEvent
name|ev
parameter_list|,
name|Path
name|evRoot
parameter_list|,
name|Path
name|cmRoot
parameter_list|,
name|Hive
name|db
parameter_list|)
throws|throws
name|Exception
block|{
name|EventHandler
operator|.
name|Context
name|context
init|=
operator|new
name|EventHandler
operator|.
name|Context
argument_list|(
name|evRoot
argument_list|,
name|cmRoot
argument_list|,
name|db
argument_list|,
name|conf
argument_list|,
name|getNewEventOnlyReplicationSpec
argument_list|(
name|ev
operator|.
name|getEventId
argument_list|()
argument_list|)
argument_list|,
name|work
operator|.
name|dbNameOrPattern
argument_list|,
name|work
operator|.
name|tableNameOrPattern
argument_list|)
decl_stmt|;
name|EventHandler
name|eventHandler
init|=
name|EventHandlerFactory
operator|.
name|handlerFor
argument_list|(
name|ev
argument_list|)
decl_stmt|;
name|eventHandler
operator|.
name|handle
argument_list|(
name|context
argument_list|)
expr_stmt|;
name|replLogger
operator|.
name|eventLog
argument_list|(
name|String
operator|.
name|valueOf
argument_list|(
name|ev
operator|.
name|getEventId
argument_list|()
argument_list|)
argument_list|,
name|eventHandler
operator|.
name|dumpType
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|ReplicationSpec
name|getNewEventOnlyReplicationSpec
parameter_list|(
name|Long
name|eventId
parameter_list|)
block|{
name|ReplicationSpec
name|rspec
init|=
name|getNewReplicationSpec
argument_list|(
name|eventId
operator|.
name|toString
argument_list|()
argument_list|,
name|eventId
operator|.
name|toString
argument_list|()
argument_list|,
name|conf
operator|.
name|getBoolean
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_DUMP_METADATA_ONLY
operator|.
name|varname
argument_list|,
literal|false
argument_list|)
argument_list|)
decl_stmt|;
name|rspec
operator|.
name|setReplSpecType
argument_list|(
name|ReplicationSpec
operator|.
name|Type
operator|.
name|INCREMENTAL_DUMP
argument_list|)
expr_stmt|;
return|return
name|rspec
return|;
block|}
name|Long
name|bootStrapDump
parameter_list|(
name|Path
name|dumpRoot
parameter_list|,
name|DumpMetaData
name|dmd
parameter_list|,
name|Path
name|cmRoot
parameter_list|,
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|Exception
block|{
comment|// bootstrap case
comment|// Last repl id would've been captured during compile phase in queryState configs before opening txn.
comment|// This is needed as we dump data on ACID/MM tables based on read snapshot or else we may lose data from
comment|// concurrent txns when bootstrap dump in progress. If it is not available, then get it from metastore.
name|Long
name|bootDumpBeginReplId
init|=
name|queryState
operator|.
name|getConf
argument_list|()
operator|.
name|getLong
argument_list|(
name|ReplUtils
operator|.
name|LAST_REPL_ID_KEY
argument_list|,
operator|-
literal|1L
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|bootDumpBeginReplId
operator|>=
literal|0L
operator|)
assert|;
name|String
name|validTxnList
init|=
name|getValidTxnListForReplDump
argument_list|(
name|hiveDb
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|dbName
range|:
name|Utils
operator|.
name|matchesDb
argument_list|(
name|hiveDb
argument_list|,
name|work
operator|.
name|dbNameOrPattern
argument_list|)
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer: analyzeReplDump dumping db: "
operator|+
name|dbName
argument_list|)
expr_stmt|;
name|replLogger
operator|=
operator|new
name|BootstrapDumpLogger
argument_list|(
name|dbName
argument_list|,
name|dumpRoot
operator|.
name|toString
argument_list|()
argument_list|,
name|Utils
operator|.
name|getAllTables
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|)
operator|.
name|size
argument_list|()
argument_list|,
name|hiveDb
operator|.
name|getAllFunctions
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|replLogger
operator|.
name|startLog
argument_list|()
expr_stmt|;
name|Path
name|dbRoot
init|=
name|dumpDbMetadata
argument_list|(
name|dbName
argument_list|,
name|dumpRoot
argument_list|,
name|bootDumpBeginReplId
argument_list|,
name|hiveDb
argument_list|)
decl_stmt|;
name|dumpFunctionMetadata
argument_list|(
name|dbName
argument_list|,
name|dumpRoot
argument_list|,
name|hiveDb
argument_list|)
expr_stmt|;
name|String
name|uniqueKey
init|=
name|Utils
operator|.
name|setDbBootstrapDumpState
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|)
decl_stmt|;
name|Exception
name|caught
init|=
literal|null
decl_stmt|;
name|boolean
name|shouldWriteExternalTableLocationInfo
init|=
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_INCLUDE_EXTERNAL_TABLES
argument_list|)
operator|&&
operator|!
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_DUMP_METADATA_ONLY
argument_list|)
decl_stmt|;
try|try
init|(
name|Writer
name|writer
init|=
operator|new
name|Writer
argument_list|(
name|dbRoot
argument_list|,
name|conf
argument_list|)
init|)
block|{
for|for
control|(
name|String
name|tblName
range|:
name|Utils
operator|.
name|matchesTbl
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|,
name|work
operator|.
name|tableNameOrPattern
argument_list|)
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"analyzeReplDump dumping table: "
operator|+
name|tblName
operator|+
literal|" to db root "
operator|+
name|dbRoot
operator|.
name|toUri
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Table
argument_list|>
name|tableTuple
init|=
operator|new
name|HiveWrapper
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|)
operator|.
name|table
argument_list|(
name|tblName
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|shouldWriteExternalTableLocationInfo
operator|&&
name|TableType
operator|.
name|EXTERNAL_TABLE
operator|.
name|equals
argument_list|(
name|tableTuple
operator|.
name|object
operator|.
name|getTableType
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding table {} to external tables list"
argument_list|,
name|tblName
argument_list|)
expr_stmt|;
name|writer
operator|.
name|dataLocationDump
argument_list|(
name|tableTuple
operator|.
name|object
argument_list|)
expr_stmt|;
block|}
name|dumpTable
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|validTxnList
argument_list|,
name|dbRoot
argument_list|,
name|bootDumpBeginReplId
argument_list|,
name|hiveDb
argument_list|,
name|tableTuple
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidTableException
name|te
parameter_list|)
block|{
comment|// Bootstrap dump shouldn't fail if the table is dropped/renamed while dumping it.
comment|// Just log a debug message and skip it.
name|LOG
operator|.
name|debug
argument_list|(
name|te
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|dumpConstraintMetadata
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|dbRoot
argument_list|,
name|hiveDb
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|caught
operator|=
name|e
expr_stmt|;
block|}
finally|finally
block|{
try|try
block|{
name|Utils
operator|.
name|resetDbBootstrapDumpState
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|,
name|uniqueKey
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|caught
operator|==
literal|null
condition|)
block|{
throw|throw
name|e
throw|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"failed to reset the db state for "
operator|+
name|uniqueKey
operator|+
literal|" on failure of repl dump"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|caught
throw|;
block|}
block|}
if|if
condition|(
name|caught
operator|!=
literal|null
condition|)
block|{
throw|throw
name|caught
throw|;
block|}
block|}
name|replLogger
operator|.
name|endLog
argument_list|(
name|bootDumpBeginReplId
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Long
name|bootDumpEndReplId
init|=
name|currentNotificationId
argument_list|(
name|hiveDb
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Preparing to return {},{}->{}"
argument_list|,
name|dumpRoot
operator|.
name|toUri
argument_list|()
argument_list|,
name|bootDumpBeginReplId
argument_list|,
name|bootDumpEndReplId
argument_list|)
expr_stmt|;
name|dmd
operator|.
name|setDump
argument_list|(
name|DumpType
operator|.
name|BOOTSTRAP
argument_list|,
name|bootDumpBeginReplId
argument_list|,
name|bootDumpEndReplId
argument_list|,
name|cmRoot
argument_list|)
expr_stmt|;
name|dmd
operator|.
name|write
argument_list|()
expr_stmt|;
comment|// Set the correct last repl id to return to the user
comment|// Currently returned bootDumpBeginReplId as we don't consolidate the events after bootstrap
return|return
name|bootDumpBeginReplId
return|;
block|}
name|long
name|currentNotificationId
parameter_list|(
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|TException
block|{
return|return
name|hiveDb
operator|.
name|getMSC
argument_list|()
operator|.
name|getCurrentNotificationEventId
argument_list|()
operator|.
name|getEventId
argument_list|()
return|;
block|}
name|Path
name|dumpDbMetadata
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Path
name|dumpRoot
parameter_list|,
name|long
name|lastReplId
parameter_list|,
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|Exception
block|{
name|Path
name|dbRoot
init|=
name|getBootstrapDbRoot
argument_list|(
name|dumpRoot
argument_list|,
name|dbName
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// TODO : instantiating FS objects are generally costly. Refactor
name|FileSystem
name|fs
init|=
name|dbRoot
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|dumpPath
init|=
operator|new
name|Path
argument_list|(
name|dbRoot
argument_list|,
name|EximUtil
operator|.
name|METADATA_NAME
argument_list|)
decl_stmt|;
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Database
argument_list|>
name|database
init|=
operator|new
name|HiveWrapper
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|,
name|lastReplId
argument_list|)
operator|.
name|database
argument_list|()
decl_stmt|;
name|EximUtil
operator|.
name|createDbExportDump
argument_list|(
name|fs
argument_list|,
name|dumpPath
argument_list|,
name|database
operator|.
name|object
argument_list|,
name|database
operator|.
name|replicationSpec
argument_list|)
expr_stmt|;
return|return
name|dbRoot
return|;
block|}
name|void
name|dumpTable
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|validTxnList
parameter_list|,
name|Path
name|dbRoot
parameter_list|,
name|long
name|lastReplId
parameter_list|,
name|Hive
name|hiveDb
parameter_list|,
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Table
argument_list|>
name|tuple
parameter_list|)
throws|throws
name|Exception
block|{
name|TableSpec
name|tableSpec
init|=
operator|new
name|TableSpec
argument_list|(
name|tuple
operator|.
name|object
argument_list|)
decl_stmt|;
name|TableExport
operator|.
name|Paths
name|exportPaths
init|=
operator|new
name|TableExport
operator|.
name|Paths
argument_list|(
name|work
operator|.
name|astRepresentationForErrorMsg
argument_list|,
name|dbRoot
argument_list|,
name|tblName
argument_list|,
name|conf
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|String
name|distCpDoAsUser
init|=
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_DISTCP_DOAS_USER
argument_list|)
decl_stmt|;
name|tuple
operator|.
name|replicationSpec
operator|.
name|setIsReplace
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// by default for all other objects this is false
if|if
condition|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|tableSpec
operator|.
name|tableHandle
argument_list|)
condition|)
block|{
name|tuple
operator|.
name|replicationSpec
operator|.
name|setValidTxnList
argument_list|(
name|validTxnList
argument_list|)
expr_stmt|;
name|tuple
operator|.
name|replicationSpec
operator|.
name|setValidWriteIdList
argument_list|(
name|getValidWriteIdList
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|validTxnList
argument_list|)
argument_list|)
expr_stmt|;
comment|// For transactional table, data would be valid snapshot for current txn and doesn't include data
comment|// added/modified by concurrent txns which are later than current txn. So, need to set last repl Id of this table
comment|// as bootstrap dump's last repl Id.
name|tuple
operator|.
name|replicationSpec
operator|.
name|setCurrentReplicationState
argument_list|(
name|String
operator|.
name|valueOf
argument_list|(
name|lastReplId
argument_list|)
argument_list|)
expr_stmt|;
comment|// For now we do not replicate stats for ACID table. So, wipe out column stats if any.
name|tableSpec
operator|.
name|tableHandle
operator|.
name|getTTable
argument_list|()
operator|.
name|unsetColStats
argument_list|()
expr_stmt|;
block|}
name|MmContext
name|mmCtx
init|=
name|MmContext
operator|.
name|createIfNeeded
argument_list|(
name|tableSpec
operator|.
name|tableHandle
argument_list|)
decl_stmt|;
operator|new
name|TableExport
argument_list|(
name|exportPaths
argument_list|,
name|tableSpec
argument_list|,
name|tuple
operator|.
name|replicationSpec
argument_list|,
name|hiveDb
argument_list|,
name|distCpDoAsUser
argument_list|,
name|conf
argument_list|,
name|mmCtx
argument_list|)
operator|.
name|write
argument_list|()
expr_stmt|;
name|replLogger
operator|.
name|tableLog
argument_list|(
name|tblName
argument_list|,
name|tableSpec
operator|.
name|tableHandle
operator|.
name|getTableType
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|String
name|getValidWriteIdList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|validTxnString
parameter_list|)
throws|throws
name|LockException
block|{
if|if
condition|(
operator|(
name|validTxnString
operator|==
literal|null
operator|)
operator|||
name|validTxnString
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|String
name|fullTableName
init|=
name|AcidUtils
operator|.
name|getFullTableName
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|ValidWriteIdList
name|validWriteIds
init|=
name|getTxnMgr
argument_list|()
operator|.
name|getValidWriteIds
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|fullTableName
argument_list|)
argument_list|,
name|validTxnString
argument_list|)
operator|.
name|getTableValidWriteIdList
argument_list|(
name|fullTableName
argument_list|)
decl_stmt|;
return|return
operator|(
operator|(
name|validWriteIds
operator|!=
literal|null
operator|)
condition|?
name|validWriteIds
operator|.
name|toString
argument_list|()
else|:
literal|null
operator|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|Long
argument_list|>
name|getOpenTxns
parameter_list|(
name|ValidTxnList
name|validTxnList
parameter_list|)
block|{
name|long
index|[]
name|invalidTxns
init|=
name|validTxnList
operator|.
name|getInvalidTransactions
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|openTxns
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|long
name|invalidTxn
range|:
name|invalidTxns
control|)
block|{
if|if
condition|(
operator|!
name|validTxnList
operator|.
name|isTxnAborted
argument_list|(
name|invalidTxn
argument_list|)
condition|)
block|{
name|openTxns
operator|.
name|add
argument_list|(
name|invalidTxn
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|openTxns
return|;
block|}
name|String
name|getValidTxnListForReplDump
parameter_list|(
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Key design point for REPL DUMP is to not have any txns older than current txn in which dump runs.
comment|// This is needed to ensure that Repl dump doesn't copy any data files written by any open txns
comment|// mainly for streaming ingest case where one delta file shall have data from committed/aborted/open txns.
comment|// It may also have data inconsistency if the on-going txns doesn't have corresponding open/write
comment|// events captured which means, catch-up incremental phase won't be able to replicate those txns.
comment|// So, the logic is to wait for configured amount of time to see if all open txns< current txn is
comment|// getting aborted/committed. If not, then we forcefully abort those txns just like AcidHouseKeeperService.
name|ValidTxnList
name|validTxnList
init|=
name|getTxnMgr
argument_list|()
operator|.
name|getValidTxns
argument_list|()
decl_stmt|;
name|long
name|timeoutInMs
init|=
name|HiveConf
operator|.
name|getTimeVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPL_BOOTSTRAP_DUMP_OPEN_TXN_TIMEOUT
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
name|long
name|waitUntilTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|+
name|timeoutInMs
decl_stmt|;
while|while
condition|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|<
name|waitUntilTime
condition|)
block|{
comment|// If there are no txns which are open for the given ValidTxnList snapshot, then just return it.
if|if
condition|(
name|getOpenTxns
argument_list|(
name|validTxnList
argument_list|)
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|validTxnList
operator|.
name|toString
argument_list|()
return|;
block|}
comment|// Wait for 1 minute and check again.
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|SLEEP_TIME
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"REPL DUMP thread sleep interrupted"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|validTxnList
operator|=
name|getTxnMgr
argument_list|()
operator|.
name|getValidTxns
argument_list|()
expr_stmt|;
block|}
comment|// After the timeout just force abort the open txns
name|List
argument_list|<
name|Long
argument_list|>
name|openTxns
init|=
name|getOpenTxns
argument_list|(
name|validTxnList
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|openTxns
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|hiveDb
operator|.
name|abortTransactions
argument_list|(
name|openTxns
argument_list|)
expr_stmt|;
name|validTxnList
operator|=
name|getTxnMgr
argument_list|()
operator|.
name|getValidTxns
argument_list|()
expr_stmt|;
if|if
condition|(
name|validTxnList
operator|.
name|getMinOpenTxn
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|openTxns
operator|=
name|getOpenTxns
argument_list|(
name|validTxnList
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"REPL DUMP unable to force abort all the open txns: {} after timeout due to unknown reasons. "
operator|+
literal|"However, this is rare case that shouldn't happen."
argument_list|,
name|openTxns
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"REPL DUMP triggered abort txns failed for unknown reasons."
argument_list|)
throw|;
block|}
block|}
return|return
name|validTxnList
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
name|ReplicationSpec
name|getNewReplicationSpec
parameter_list|(
name|String
name|evState
parameter_list|,
name|String
name|objState
parameter_list|,
name|boolean
name|isMetadataOnly
parameter_list|)
block|{
return|return
operator|new
name|ReplicationSpec
argument_list|(
literal|true
argument_list|,
name|isMetadataOnly
argument_list|,
name|evState
argument_list|,
name|objState
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
return|;
block|}
specifier|private
name|String
name|getNextDumpDir
parameter_list|()
block|{
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_IN_TEST
argument_list|)
condition|)
block|{
comment|// make it easy to write .q unit tests, instead of unique id generation.
comment|// however, this does mean that in writing tests, we have to be aware that
comment|// repl dump will clash with prior dumps, and thus have to clean up properly.
if|if
condition|(
name|ReplDumpWork
operator|.
name|testInjectDumpDir
operator|==
literal|null
condition|)
block|{
return|return
literal|"next"
return|;
block|}
else|else
block|{
return|return
name|ReplDumpWork
operator|.
name|testInjectDumpDir
return|;
block|}
block|}
else|else
block|{
return|return
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
return|;
comment|// TODO: time good enough for now - we'll likely improve this.
comment|// We may also work in something the equivalent of pid, thrid and move to nanos to ensure
comment|// uniqueness.
block|}
block|}
name|void
name|dumpFunctionMetadata
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Path
name|dumpRoot
parameter_list|,
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|Exception
block|{
name|Path
name|functionsRoot
init|=
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|dumpRoot
argument_list|,
name|dbName
argument_list|)
argument_list|,
name|ReplUtils
operator|.
name|FUNCTIONS_ROOT_DIR_NAME
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|functionNames
init|=
name|hiveDb
operator|.
name|getFunctions
argument_list|(
name|dbName
argument_list|,
literal|"*"
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|functionName
range|:
name|functionNames
control|)
block|{
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Function
argument_list|>
name|tuple
init|=
name|functionTuple
argument_list|(
name|functionName
argument_list|,
name|dbName
argument_list|,
name|hiveDb
argument_list|)
decl_stmt|;
if|if
condition|(
name|tuple
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|Path
name|functionRoot
init|=
operator|new
name|Path
argument_list|(
name|functionsRoot
argument_list|,
name|functionName
argument_list|)
decl_stmt|;
name|Path
name|functionMetadataFile
init|=
operator|new
name|Path
argument_list|(
name|functionRoot
argument_list|,
name|FUNCTION_METADATA_FILE_NAME
argument_list|)
decl_stmt|;
try|try
init|(
name|JsonWriter
name|jsonWriter
init|=
operator|new
name|JsonWriter
argument_list|(
name|functionMetadataFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|functionMetadataFile
argument_list|)
init|)
block|{
name|FunctionSerializer
name|serializer
init|=
operator|new
name|FunctionSerializer
argument_list|(
name|tuple
operator|.
name|object
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|serializer
operator|.
name|writeTo
argument_list|(
name|jsonWriter
argument_list|,
name|tuple
operator|.
name|replicationSpec
argument_list|)
expr_stmt|;
block|}
name|replLogger
operator|.
name|functionLog
argument_list|(
name|functionName
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|dumpConstraintMetadata
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|Path
name|dbRoot
parameter_list|,
name|Hive
name|hiveDb
parameter_list|)
throws|throws
name|Exception
block|{
try|try
block|{
name|Path
name|constraintsRoot
init|=
operator|new
name|Path
argument_list|(
name|dbRoot
argument_list|,
name|ReplUtils
operator|.
name|CONSTRAINTS_ROOT_DIR_NAME
argument_list|)
decl_stmt|;
name|Path
name|commonConstraintsFile
init|=
operator|new
name|Path
argument_list|(
name|constraintsRoot
argument_list|,
name|ConstraintFileType
operator|.
name|COMMON
operator|.
name|getPrefix
argument_list|()
operator|+
name|tblName
argument_list|)
decl_stmt|;
name|Path
name|fkConstraintsFile
init|=
operator|new
name|Path
argument_list|(
name|constraintsRoot
argument_list|,
name|ConstraintFileType
operator|.
name|FOREIGNKEY
operator|.
name|getPrefix
argument_list|()
operator|+
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|SQLPrimaryKey
argument_list|>
name|pks
init|=
name|hiveDb
operator|.
name|getPrimaryKeyList
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|SQLForeignKey
argument_list|>
name|fks
init|=
name|hiveDb
operator|.
name|getForeignKeyList
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|SQLUniqueConstraint
argument_list|>
name|uks
init|=
name|hiveDb
operator|.
name|getUniqueConstraintList
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|SQLNotNullConstraint
argument_list|>
name|nns
init|=
name|hiveDb
operator|.
name|getNotNullConstraintList
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|pks
operator|!=
literal|null
operator|&&
operator|!
name|pks
operator|.
name|isEmpty
argument_list|()
operator|)
operator|||
operator|(
name|uks
operator|!=
literal|null
operator|&&
operator|!
name|uks
operator|.
name|isEmpty
argument_list|()
operator|)
operator|||
operator|(
name|nns
operator|!=
literal|null
operator|&&
operator|!
name|nns
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
try|try
init|(
name|JsonWriter
name|jsonWriter
init|=
operator|new
name|JsonWriter
argument_list|(
name|commonConstraintsFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|commonConstraintsFile
argument_list|)
init|)
block|{
name|ConstraintsSerializer
name|serializer
init|=
operator|new
name|ConstraintsSerializer
argument_list|(
name|pks
argument_list|,
literal|null
argument_list|,
name|uks
argument_list|,
name|nns
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|serializer
operator|.
name|writeTo
argument_list|(
name|jsonWriter
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|fks
operator|!=
literal|null
operator|&&
operator|!
name|fks
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
init|(
name|JsonWriter
name|jsonWriter
init|=
operator|new
name|JsonWriter
argument_list|(
name|fkConstraintsFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|fkConstraintsFile
argument_list|)
init|)
block|{
name|ConstraintsSerializer
name|serializer
init|=
operator|new
name|ConstraintsSerializer
argument_list|(
literal|null
argument_list|,
name|fks
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|serializer
operator|.
name|writeTo
argument_list|(
name|jsonWriter
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
comment|// Bootstrap constraint dump shouldn't fail if the table is dropped/renamed while dumping it.
comment|// Just log a debug message and skip it.
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Function
argument_list|>
name|functionTuple
parameter_list|(
name|String
name|functionName
parameter_list|,
name|String
name|dbName
parameter_list|,
name|Hive
name|hiveDb
parameter_list|)
block|{
try|try
block|{
name|HiveWrapper
operator|.
name|Tuple
argument_list|<
name|Function
argument_list|>
name|tuple
init|=
operator|new
name|HiveWrapper
argument_list|(
name|hiveDb
argument_list|,
name|dbName
argument_list|)
operator|.
name|function
argument_list|(
name|functionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|tuple
operator|.
name|object
operator|.
name|getResourceUris
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Not replicating function: "
operator|+
name|functionName
operator|+
literal|" as it seems to have been created "
operator|+
literal|"without USING clause"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
return|return
name|tuple
return|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
comment|//This can happen as we are querying the getFunctions before we are getting the actual function
comment|//in between there can be a drop function by a user in which case our call will fail.
name|LOG
operator|.
name|info
argument_list|(
literal|"Function "
operator|+
name|functionName
operator|+
literal|" could not be found, we are ignoring it as it can be a valid state "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|StageType
name|getType
parameter_list|()
block|{
return|return
name|StageType
operator|.
name|REPL_DUMP
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|canExecuteInParallel
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
block|}
end_class

end_unit

