begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.You may obtain a copy of the License at  *  * http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ObjectPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|persistence
operator|.
name|RowContainer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|BucketMapJoinContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FetchWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapJoinDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapredLocalWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|SMBJoinDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|api
operator|.
name|OperatorType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|ColumnProjectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|InspectableObject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|PriorityQueue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_comment
comment|/**  * Sorted Merge Map Join Operator.  */
end_comment

begin_class
specifier|public
class|class
name|SMBMapJoinOperator
extends|extends
name|AbstractMapJoinOperator
argument_list|<
name|SMBJoinDesc
argument_list|>
implements|implements
name|Serializable
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SMBMapJoinOperator
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
name|MapredLocalWork
name|localWork
init|=
literal|null
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|MergeQueue
argument_list|>
name|aliasToMergeQueue
init|=
name|Collections
operator|.
name|emptyMap
argument_list|()
decl_stmt|;
specifier|transient
name|List
argument_list|<
name|Object
argument_list|>
index|[]
name|keyWritables
decl_stmt|;
specifier|transient
name|List
argument_list|<
name|Object
argument_list|>
index|[]
name|nextKeyWritables
decl_stmt|;
name|RowContainer
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|>
index|[]
name|nextGroupStorage
decl_stmt|;
name|RowContainer
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|>
index|[]
name|candidateStorage
decl_stmt|;
specifier|transient
name|String
index|[]
name|tagToAlias
decl_stmt|;
specifier|private
specifier|transient
name|boolean
index|[]
name|fetchDone
decl_stmt|;
specifier|private
specifier|transient
name|boolean
index|[]
name|foundNextKeyGroup
decl_stmt|;
specifier|transient
name|boolean
name|firstFetchHappened
init|=
literal|false
decl_stmt|;
specifier|private
specifier|transient
name|boolean
name|inputFileChanged
init|=
literal|false
decl_stmt|;
specifier|transient
name|boolean
name|localWorkInited
init|=
literal|false
decl_stmt|;
specifier|transient
name|boolean
name|initDone
init|=
literal|false
decl_stmt|;
comment|// This join has been converted to a SMB join by the hive optimizer. The user did not
comment|// give a mapjoin hint in the query. The hive optimizer figured out that the join can be
comment|// performed as a smb join, based on all the tables/partitions being joined.
specifier|private
specifier|transient
name|boolean
name|convertedAutomaticallySMBJoin
init|=
literal|false
decl_stmt|;
specifier|public
name|SMBMapJoinOperator
parameter_list|()
block|{   }
specifier|public
name|SMBMapJoinOperator
parameter_list|(
name|AbstractMapJoinOperator
argument_list|<
name|?
extends|extends
name|MapJoinDesc
argument_list|>
name|mapJoinOp
parameter_list|)
block|{
name|super
argument_list|(
name|mapJoinOp
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|initializeOp
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// If there is a sort-merge join followed by a regular join, the SMBJoinOperator may not
comment|// get initialized at all. Consider the following query:
comment|// A SMB B JOIN C
comment|// For the mapper processing C, The SMJ is not initialized, no need to close it either.
name|initDone
operator|=
literal|true
expr_stmt|;
name|super
operator|.
name|initializeOp
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
name|firstRow
operator|=
literal|true
expr_stmt|;
name|closeCalled
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|firstFetchHappened
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|inputFileChanged
operator|=
literal|false
expr_stmt|;
comment|// get the largest table alias from order
name|int
name|maxAlias
init|=
literal|0
decl_stmt|;
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|pos
operator|>
name|maxAlias
condition|)
block|{
name|maxAlias
operator|=
name|pos
expr_stmt|;
block|}
block|}
name|maxAlias
operator|+=
literal|1
expr_stmt|;
name|nextGroupStorage
operator|=
operator|new
name|RowContainer
index|[
name|maxAlias
index|]
expr_stmt|;
name|candidateStorage
operator|=
operator|new
name|RowContainer
index|[
name|maxAlias
index|]
expr_stmt|;
name|keyWritables
operator|=
operator|new
name|ArrayList
index|[
name|maxAlias
index|]
expr_stmt|;
name|nextKeyWritables
operator|=
operator|new
name|ArrayList
index|[
name|maxAlias
index|]
expr_stmt|;
name|fetchDone
operator|=
operator|new
name|boolean
index|[
name|maxAlias
index|]
expr_stmt|;
name|foundNextKeyGroup
operator|=
operator|new
name|boolean
index|[
name|maxAlias
index|]
expr_stmt|;
name|int
name|bucketSize
decl_stmt|;
comment|// For backwards compatibility reasons we honor the older
comment|// HIVEMAPJOINBUCKETCACHESIZE if set different from default.
comment|// By hive 0.13 we should remove this code.
name|int
name|oldVar
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|hconf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMAPJOINBUCKETCACHESIZE
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldVar
operator|!=
literal|100
condition|)
block|{
name|bucketSize
operator|=
name|oldVar
expr_stmt|;
block|}
else|else
block|{
name|bucketSize
operator|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|hconf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESMBJOINCACHEROWS
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
name|RowContainer
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|>
name|rc
init|=
name|JoinUtil
operator|.
name|getRowContainer
argument_list|(
name|hconf
argument_list|,
name|rowContainerStandardObjectInspectors
index|[
name|pos
index|]
argument_list|,
name|pos
argument_list|,
name|bucketSize
argument_list|,
name|spillTableDesc
argument_list|,
name|conf
argument_list|,
operator|!
name|hasFilter
argument_list|(
name|pos
argument_list|)
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
name|nextGroupStorage
index|[
name|pos
index|]
operator|=
name|rc
expr_stmt|;
name|RowContainer
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|>
name|candidateRC
init|=
name|JoinUtil
operator|.
name|getRowContainer
argument_list|(
name|hconf
argument_list|,
name|rowContainerStandardObjectInspectors
index|[
name|pos
index|]
argument_list|,
name|pos
argument_list|,
name|bucketSize
argument_list|,
name|spillTableDesc
argument_list|,
name|conf
argument_list|,
operator|!
name|hasFilter
argument_list|(
name|pos
argument_list|)
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
name|candidateStorage
index|[
name|pos
index|]
operator|=
name|candidateRC
expr_stmt|;
block|}
name|tagToAlias
operator|=
name|conf
operator|.
name|convertToArray
argument_list|(
name|conf
operator|.
name|getTagToAlias
argument_list|()
argument_list|,
name|String
operator|.
name|class
argument_list|)
expr_stmt|;
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|pos
operator|!=
name|posBigTable
condition|)
block|{
name|fetchDone
index|[
name|pos
index|]
operator|=
literal|false
expr_stmt|;
block|}
name|foundNextKeyGroup
index|[
name|pos
index|]
operator|=
literal|false
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|initializeLocalWork
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|HiveException
block|{
name|initializeMapredLocalWork
argument_list|(
name|this
operator|.
name|getConf
argument_list|()
argument_list|,
name|hconf
argument_list|,
name|this
operator|.
name|getConf
argument_list|()
operator|.
name|getLocalWork
argument_list|()
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
name|super
operator|.
name|initializeLocalWork
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|initializeMapredLocalWork
parameter_list|(
name|MapJoinDesc
name|mjConf
parameter_list|,
name|Configuration
name|hconf
parameter_list|,
name|MapredLocalWork
name|localWork
parameter_list|,
name|Log
name|l4j
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|localWork
operator|==
literal|null
operator|||
name|localWorkInited
condition|)
block|{
return|return;
block|}
name|localWorkInited
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|localWork
operator|=
name|localWork
expr_stmt|;
name|aliasToMergeQueue
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|MergeQueue
argument_list|>
argument_list|()
expr_stmt|;
comment|// create map local operators
name|Map
argument_list|<
name|String
argument_list|,
name|FetchWork
argument_list|>
name|aliasToFetchWork
init|=
name|localWork
operator|.
name|getAliasToFetchWork
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|aliasToWork
init|=
name|localWork
operator|.
name|getAliasToWork
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|DummyStoreOperator
argument_list|>
name|aliasToSinkWork
init|=
name|conf
operator|.
name|getAliasToSink
argument_list|()
decl_stmt|;
comment|// The operator tree till the sink operator needs to be processed while
comment|// fetching the next row to fetch from the priority queue (possibly containing
comment|// multiple files in the small table given a file in the big table). The remaining
comment|// tree will be processed while processing the join.
comment|// Look at comments in DummyStoreOperator for additional explanation.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|FetchWork
argument_list|>
name|entry
range|:
name|aliasToFetchWork
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|alias
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|FetchWork
name|fetchWork
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|JobConf
name|jobClone
init|=
operator|new
name|JobConf
argument_list|(
name|hconf
argument_list|)
decl_stmt|;
name|TableScanOperator
name|ts
init|=
operator|(
name|TableScanOperator
operator|)
name|aliasToWork
operator|.
name|get
argument_list|(
name|alias
argument_list|)
decl_stmt|;
comment|// push down projections
name|ColumnProjectionUtils
operator|.
name|appendReadColumns
argument_list|(
name|jobClone
argument_list|,
name|ts
operator|.
name|getNeededColumnIDs
argument_list|()
argument_list|,
name|ts
operator|.
name|getNeededColumns
argument_list|()
argument_list|)
expr_stmt|;
comment|// push down filters
name|HiveInputFormat
operator|.
name|pushFilters
argument_list|(
name|jobClone
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|ts
operator|.
name|setExecContext
argument_list|(
name|getExecContext
argument_list|()
argument_list|)
expr_stmt|;
name|FetchOperator
name|fetchOp
init|=
operator|new
name|FetchOperator
argument_list|(
name|fetchWork
argument_list|,
name|jobClone
argument_list|)
decl_stmt|;
name|ts
operator|.
name|initialize
argument_list|(
name|jobClone
argument_list|,
operator|new
name|ObjectInspector
index|[]
block|{
name|fetchOp
operator|.
name|getOutputObjectInspector
argument_list|()
block|}
argument_list|)
expr_stmt|;
name|fetchOp
operator|.
name|clearFetchContext
argument_list|()
expr_stmt|;
name|DummyStoreOperator
name|sinkOp
init|=
name|aliasToSinkWork
operator|.
name|get
argument_list|(
name|alias
argument_list|)
decl_stmt|;
name|MergeQueue
name|mergeQueue
init|=
operator|new
name|MergeQueue
argument_list|(
name|alias
argument_list|,
name|fetchWork
argument_list|,
name|jobClone
argument_list|,
name|ts
argument_list|,
name|sinkOp
argument_list|)
decl_stmt|;
name|aliasToMergeQueue
operator|.
name|put
argument_list|(
name|alias
argument_list|,
name|mergeQueue
argument_list|)
expr_stmt|;
name|l4j
operator|.
name|info
argument_list|(
literal|"fetch operators for "
operator|+
name|alias
operator|+
literal|" initialized"
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|byte
name|tagForAlias
parameter_list|(
name|String
name|alias
parameter_list|)
block|{
for|for
control|(
name|byte
name|tag
init|=
literal|0
init|;
name|tag
operator|<
name|tagToAlias
operator|.
name|length
condition|;
name|tag
operator|++
control|)
block|{
if|if
condition|(
name|alias
operator|.
name|equals
argument_list|(
name|tagToAlias
index|[
name|tag
index|]
argument_list|)
condition|)
block|{
return|return
name|tag
return|;
block|}
block|}
return|return
operator|-
literal|1
return|;
block|}
comment|// The input file has changed - load the correct hash bucket
annotation|@
name|Override
specifier|public
name|void
name|cleanUpInputFileChangedOp
parameter_list|()
throws|throws
name|HiveException
block|{
name|inputFileChanged
operator|=
literal|true
expr_stmt|;
block|}
specifier|protected
name|List
argument_list|<
name|Object
argument_list|>
name|smbJoinComputeKeys
parameter_list|(
name|Object
name|row
parameter_list|,
name|byte
name|alias
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|JoinUtil
operator|.
name|computeKeys
argument_list|(
name|row
argument_list|,
name|joinKeys
index|[
name|alias
index|]
argument_list|,
name|joinKeysObjectInspectors
index|[
name|alias
index|]
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|processOp
parameter_list|(
name|Object
name|row
parameter_list|,
name|int
name|tag
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tag
operator|==
name|posBigTable
condition|)
block|{
if|if
condition|(
name|inputFileChanged
condition|)
block|{
if|if
condition|(
name|firstFetchHappened
condition|)
block|{
comment|// we need to first join and flush out data left by the previous file.
name|joinFinalLeftData
argument_list|()
expr_stmt|;
block|}
comment|// set up the fetch operator for the new input file.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|MergeQueue
argument_list|>
name|entry
range|:
name|aliasToMergeQueue
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|alias
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|MergeQueue
name|mergeQueue
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|setUpFetchContexts
argument_list|(
name|alias
argument_list|,
name|mergeQueue
argument_list|)
expr_stmt|;
block|}
name|firstFetchHappened
operator|=
literal|false
expr_stmt|;
name|inputFileChanged
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|firstFetchHappened
condition|)
block|{
name|firstFetchHappened
operator|=
literal|true
expr_stmt|;
comment|// fetch the first group for all small table aliases
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|pos
operator|!=
name|posBigTable
condition|)
block|{
name|fetchNextGroup
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|byte
name|alias
init|=
operator|(
name|byte
operator|)
name|tag
decl_stmt|;
comment|// compute keys and values as StandardObjects
name|List
argument_list|<
name|Object
argument_list|>
name|key
init|=
name|smbJoinComputeKeys
argument_list|(
name|row
argument_list|,
name|alias
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Object
argument_list|>
name|value
init|=
name|getFilteredValue
argument_list|(
name|alias
argument_list|,
name|row
argument_list|)
decl_stmt|;
comment|//have we reached a new key group?
name|boolean
name|nextKeyGroup
init|=
name|processKey
argument_list|(
name|alias
argument_list|,
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|nextKeyGroup
condition|)
block|{
comment|//assert this.nextGroupStorage[alias].size() == 0;
name|this
operator|.
name|nextGroupStorage
index|[
name|alias
index|]
operator|.
name|addRow
argument_list|(
name|value
argument_list|)
expr_stmt|;
name|foundNextKeyGroup
index|[
name|tag
index|]
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|tag
operator|!=
name|posBigTable
condition|)
block|{
return|return;
block|}
block|}
name|reportProgress
argument_list|()
expr_stmt|;
name|numMapRowsRead
operator|++
expr_stmt|;
comment|// the big table has reached a new key group. try to let the small tables
comment|// catch up with the big table.
if|if
condition|(
name|nextKeyGroup
condition|)
block|{
assert|assert
name|tag
operator|==
name|posBigTable
assert|;
name|List
argument_list|<
name|Byte
argument_list|>
name|smallestPos
init|=
literal|null
decl_stmt|;
do|do
block|{
name|smallestPos
operator|=
name|joinOneGroup
argument_list|()
expr_stmt|;
comment|//jump out the loop if we need input from the big table
block|}
do|while
condition|(
name|smallestPos
operator|!=
literal|null
operator|&&
name|smallestPos
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
operator|!
name|smallestPos
operator|.
name|contains
argument_list|(
name|this
operator|.
name|posBigTable
argument_list|)
condition|)
do|;
return|return;
block|}
assert|assert
operator|!
name|nextKeyGroup
assert|;
name|candidateStorage
index|[
name|tag
index|]
operator|.
name|addRow
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
comment|/*    * this happens either when the input file of the big table is changed or in    * closeop. It needs to fetch all the left data from the small tables and try    * to join them.    */
specifier|private
name|void
name|joinFinalLeftData
parameter_list|()
throws|throws
name|HiveException
block|{
name|RowContainer
name|bigTblRowContainer
init|=
name|this
operator|.
name|candidateStorage
index|[
name|this
operator|.
name|posBigTable
index|]
decl_stmt|;
name|boolean
name|allFetchDone
init|=
name|allFetchDone
argument_list|()
decl_stmt|;
comment|// if all left data in small tables are less than and equal to the left data
comment|// in big table, let's them catch up
while|while
condition|(
name|bigTblRowContainer
operator|!=
literal|null
operator|&&
name|bigTblRowContainer
operator|.
name|rowCount
argument_list|()
operator|>
literal|0
operator|&&
operator|!
name|allFetchDone
condition|)
block|{
name|joinOneGroup
argument_list|()
expr_stmt|;
name|bigTblRowContainer
operator|=
name|this
operator|.
name|candidateStorage
index|[
name|this
operator|.
name|posBigTable
index|]
expr_stmt|;
name|allFetchDone
operator|=
name|allFetchDone
argument_list|()
expr_stmt|;
block|}
while|while
condition|(
operator|!
name|allFetchDone
condition|)
block|{
name|List
argument_list|<
name|Byte
argument_list|>
name|ret
init|=
name|joinOneGroup
argument_list|()
decl_stmt|;
if|if
condition|(
name|ret
operator|==
literal|null
operator|||
name|ret
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
break|break;
block|}
name|reportProgress
argument_list|()
expr_stmt|;
name|numMapRowsRead
operator|++
expr_stmt|;
name|allFetchDone
operator|=
name|allFetchDone
argument_list|()
expr_stmt|;
block|}
name|boolean
name|dataInCache
init|=
literal|true
decl_stmt|;
while|while
condition|(
name|dataInCache
condition|)
block|{
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|this
operator|.
name|foundNextKeyGroup
index|[
name|pos
index|]
operator|&&
name|this
operator|.
name|nextKeyWritables
index|[
name|pos
index|]
operator|!=
literal|null
condition|)
block|{
name|promoteNextGroupToCandidate
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
block|}
name|joinOneGroup
argument_list|()
expr_stmt|;
name|dataInCache
operator|=
literal|false
expr_stmt|;
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|this
operator|.
name|candidateStorage
index|[
name|pos
index|]
operator|.
name|rowCount
argument_list|()
operator|>
literal|0
condition|)
block|{
name|dataInCache
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
block|}
block|}
specifier|private
name|boolean
name|allFetchDone
parameter_list|()
block|{
name|boolean
name|allFetchDone
init|=
literal|true
decl_stmt|;
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|pos
operator|==
name|posBigTable
condition|)
block|{
continue|continue;
block|}
name|allFetchDone
operator|=
name|allFetchDone
operator|&&
name|fetchDone
index|[
name|pos
index|]
expr_stmt|;
block|}
return|return
name|allFetchDone
return|;
block|}
specifier|private
name|List
argument_list|<
name|Byte
argument_list|>
name|joinOneGroup
parameter_list|()
throws|throws
name|HiveException
block|{
name|int
index|[]
name|smallestPos
init|=
name|findSmallestKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Byte
argument_list|>
name|listOfNeedFetchNext
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|smallestPos
operator|!=
literal|null
condition|)
block|{
name|listOfNeedFetchNext
operator|=
name|joinObject
argument_list|(
name|smallestPos
argument_list|)
expr_stmt|;
if|if
condition|(
name|listOfNeedFetchNext
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// listOfNeedFetchNext contains all tables that we have joined data in their
comment|// candidateStorage, and we need to clear candidate storage and promote their
comment|// nextGroupStorage to candidateStorage and fetch data until we reach a
comment|// new group.
for|for
control|(
name|Byte
name|b
range|:
name|listOfNeedFetchNext
control|)
block|{
name|fetchNextGroup
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|listOfNeedFetchNext
return|;
block|}
specifier|private
name|List
argument_list|<
name|Byte
argument_list|>
name|joinObject
parameter_list|(
name|int
index|[]
name|smallestPos
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|Byte
argument_list|>
name|needFetchList
init|=
operator|new
name|ArrayList
argument_list|<
name|Byte
argument_list|>
argument_list|()
decl_stmt|;
name|byte
name|index
init|=
call|(
name|byte
call|)
argument_list|(
name|smallestPos
operator|.
name|length
operator|-
literal|1
argument_list|)
decl_stmt|;
for|for
control|(
init|;
name|index
operator|>=
literal|0
condition|;
name|index
operator|--
control|)
block|{
if|if
condition|(
name|smallestPos
index|[
name|index
index|]
operator|>
literal|0
operator|||
name|keyWritables
index|[
name|index
index|]
operator|==
literal|null
condition|)
block|{
name|putDummyOrEmpty
argument_list|(
name|index
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|storage
index|[
name|index
index|]
operator|=
name|candidateStorage
index|[
name|index
index|]
expr_stmt|;
name|needFetchList
operator|.
name|add
argument_list|(
name|index
argument_list|)
expr_stmt|;
if|if
condition|(
name|smallestPos
index|[
name|index
index|]
operator|<
literal|0
condition|)
block|{
break|break;
block|}
block|}
for|for
control|(
name|index
operator|--
init|;
name|index
operator|>=
literal|0
condition|;
name|index
operator|--
control|)
block|{
name|putDummyOrEmpty
argument_list|(
name|index
argument_list|)
expr_stmt|;
block|}
name|checkAndGenObject
argument_list|()
expr_stmt|;
for|for
control|(
name|Byte
name|pos
range|:
name|needFetchList
control|)
block|{
name|this
operator|.
name|candidateStorage
index|[
name|pos
index|]
operator|.
name|clearRows
argument_list|()
expr_stmt|;
name|this
operator|.
name|keyWritables
index|[
name|pos
index|]
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|needFetchList
return|;
block|}
specifier|private
name|void
name|fetchNextGroup
parameter_list|(
name|Byte
name|t
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|foundNextKeyGroup
index|[
name|t
index|]
condition|)
block|{
comment|// first promote the next group to be the current group if we reached a
comment|// new group in the previous fetch
if|if
condition|(
name|this
operator|.
name|nextKeyWritables
index|[
name|t
index|]
operator|!=
literal|null
condition|)
block|{
name|promoteNextGroupToCandidate
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|keyWritables
index|[
name|t
index|]
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|candidateStorage
index|[
name|t
index|]
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|nextGroupStorage
index|[
name|t
index|]
operator|=
literal|null
expr_stmt|;
block|}
name|foundNextKeyGroup
index|[
name|t
index|]
operator|=
literal|false
expr_stmt|;
block|}
comment|//for the big table, we only need to promote the next group to the current group.
if|if
condition|(
name|t
operator|==
name|posBigTable
condition|)
block|{
return|return;
block|}
comment|//for tables other than the big table, we need to fetch more data until reach a new group or done.
while|while
condition|(
operator|!
name|foundNextKeyGroup
index|[
name|t
index|]
condition|)
block|{
if|if
condition|(
name|fetchDone
index|[
name|t
index|]
condition|)
block|{
break|break;
block|}
name|fetchOneRow
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|foundNextKeyGroup
index|[
name|t
index|]
operator|&&
name|fetchDone
index|[
name|t
index|]
condition|)
block|{
name|this
operator|.
name|nextKeyWritables
index|[
name|t
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|promoteNextGroupToCandidate
parameter_list|(
name|Byte
name|t
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
operator|.
name|keyWritables
index|[
name|t
index|]
operator|=
name|this
operator|.
name|nextKeyWritables
index|[
name|t
index|]
expr_stmt|;
name|this
operator|.
name|nextKeyWritables
index|[
name|t
index|]
operator|=
literal|null
expr_stmt|;
name|RowContainer
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|>
name|oldRowContainer
init|=
name|this
operator|.
name|candidateStorage
index|[
name|t
index|]
decl_stmt|;
name|oldRowContainer
operator|.
name|clearRows
argument_list|()
expr_stmt|;
name|this
operator|.
name|candidateStorage
index|[
name|t
index|]
operator|=
name|this
operator|.
name|nextGroupStorage
index|[
name|t
index|]
expr_stmt|;
name|this
operator|.
name|nextGroupStorage
index|[
name|t
index|]
operator|=
name|oldRowContainer
expr_stmt|;
block|}
specifier|private
name|int
name|compareKeys
parameter_list|(
name|List
argument_list|<
name|Object
argument_list|>
name|k1
parameter_list|,
name|List
argument_list|<
name|Object
argument_list|>
name|k2
parameter_list|)
block|{
name|int
name|ret
init|=
literal|0
decl_stmt|;
comment|// join keys have difference sizes?
name|ret
operator|=
name|k1
operator|.
name|size
argument_list|()
operator|-
name|k2
operator|.
name|size
argument_list|()
expr_stmt|;
if|if
condition|(
name|ret
operator|!=
literal|0
condition|)
block|{
return|return
name|ret
return|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|k1
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|WritableComparable
name|key_1
init|=
operator|(
name|WritableComparable
operator|)
name|k1
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|WritableComparable
name|key_2
init|=
operator|(
name|WritableComparable
operator|)
name|k2
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|key_1
operator|==
literal|null
operator|&&
name|key_2
operator|==
literal|null
condition|)
block|{
return|return
name|nullsafes
operator|!=
literal|null
operator|&&
name|nullsafes
index|[
name|i
index|]
condition|?
literal|0
else|:
operator|-
literal|1
return|;
comment|// just return k1 is smaller than k2
block|}
elseif|else
if|if
condition|(
name|key_1
operator|==
literal|null
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
elseif|else
if|if
condition|(
name|key_2
operator|==
literal|null
condition|)
block|{
return|return
literal|1
return|;
block|}
name|ret
operator|=
name|WritableComparator
operator|.
name|get
argument_list|(
name|key_1
operator|.
name|getClass
argument_list|()
argument_list|)
operator|.
name|compare
argument_list|(
name|key_1
argument_list|,
name|key_2
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
operator|!=
literal|0
condition|)
block|{
return|return
name|ret
return|;
block|}
block|}
return|return
name|ret
return|;
block|}
specifier|private
name|void
name|putDummyOrEmpty
parameter_list|(
name|Byte
name|i
parameter_list|)
block|{
comment|// put a empty list or null
if|if
condition|(
name|noOuterJoin
condition|)
block|{
name|storage
index|[
name|i
index|]
operator|=
name|emptyList
expr_stmt|;
block|}
else|else
block|{
name|storage
index|[
name|i
index|]
operator|=
name|dummyObjVectors
index|[
name|i
index|]
expr_stmt|;
block|}
block|}
specifier|private
name|int
index|[]
name|findSmallestKey
parameter_list|()
block|{
name|int
index|[]
name|result
init|=
operator|new
name|int
index|[
name|order
operator|.
name|length
index|]
decl_stmt|;
name|List
argument_list|<
name|Object
argument_list|>
name|smallestOne
init|=
literal|null
decl_stmt|;
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
name|List
argument_list|<
name|Object
argument_list|>
name|key
init|=
name|keyWritables
index|[
name|pos
index|]
decl_stmt|;
if|if
condition|(
name|key
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|smallestOne
operator|==
literal|null
condition|)
block|{
name|smallestOne
operator|=
name|key
expr_stmt|;
name|result
index|[
name|pos
index|]
operator|=
operator|-
literal|1
expr_stmt|;
continue|continue;
block|}
name|result
index|[
name|pos
index|]
operator|=
name|compareKeys
argument_list|(
name|key
argument_list|,
name|smallestOne
argument_list|)
expr_stmt|;
if|if
condition|(
name|result
index|[
name|pos
index|]
operator|<
literal|0
condition|)
block|{
name|smallestOne
operator|=
name|key
expr_stmt|;
block|}
block|}
return|return
name|smallestOne
operator|==
literal|null
condition|?
literal|null
else|:
name|result
return|;
block|}
specifier|private
name|boolean
name|processKey
parameter_list|(
name|byte
name|alias
parameter_list|,
name|List
argument_list|<
name|Object
argument_list|>
name|key
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|Object
argument_list|>
name|keyWritable
init|=
name|keyWritables
index|[
name|alias
index|]
decl_stmt|;
if|if
condition|(
name|keyWritable
operator|==
literal|null
condition|)
block|{
comment|//the first group.
name|keyWritables
index|[
name|alias
index|]
operator|=
name|key
expr_stmt|;
return|return
literal|false
return|;
block|}
else|else
block|{
name|int
name|cmp
init|=
name|compareKeys
argument_list|(
name|key
argument_list|,
name|keyWritable
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
name|nextKeyWritables
index|[
name|alias
index|]
operator|=
name|key
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
block|}
specifier|private
name|void
name|setUpFetchContexts
parameter_list|(
name|String
name|alias
parameter_list|,
name|MergeQueue
name|mergeQueue
parameter_list|)
throws|throws
name|HiveException
block|{
name|mergeQueue
operator|.
name|clearFetchContext
argument_list|()
expr_stmt|;
name|Path
name|currentInputPath
init|=
name|getExecContext
argument_list|()
operator|.
name|getCurrentInputPath
argument_list|()
decl_stmt|;
name|BucketMapJoinContext
name|bucketMatcherCxt
init|=
name|localWork
operator|.
name|getBucketMapjoinContext
argument_list|()
decl_stmt|;
name|Class
argument_list|<
name|?
extends|extends
name|BucketMatcher
argument_list|>
name|bucketMatcherCls
init|=
name|bucketMatcherCxt
operator|.
name|getBucketMatcherClass
argument_list|()
decl_stmt|;
name|BucketMatcher
name|bucketMatcher
init|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|bucketMatcherCls
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|getExecContext
argument_list|()
operator|.
name|setFileId
argument_list|(
name|bucketMatcherCxt
operator|.
name|createFileId
argument_list|(
name|currentInputPath
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"set task id: "
operator|+
name|getExecContext
argument_list|()
operator|.
name|getFileId
argument_list|()
argument_list|)
expr_stmt|;
name|bucketMatcher
operator|.
name|setAliasBucketFileNameMapping
argument_list|(
name|bucketMatcherCxt
operator|.
name|getAliasBucketFileNameMapping
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|aliasFiles
init|=
name|bucketMatcher
operator|.
name|getAliasBucketFiles
argument_list|(
name|currentInputPath
operator|.
name|toString
argument_list|()
argument_list|,
name|bucketMatcherCxt
operator|.
name|getMapJoinBigTableAlias
argument_list|()
argument_list|,
name|alias
argument_list|)
decl_stmt|;
name|mergeQueue
operator|.
name|setupContext
argument_list|(
name|aliasFiles
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|fetchOneRow
parameter_list|(
name|byte
name|tag
parameter_list|)
block|{
name|String
name|table
init|=
name|tagToAlias
index|[
name|tag
index|]
decl_stmt|;
name|MergeQueue
name|mergeQueue
init|=
name|aliasToMergeQueue
operator|.
name|get
argument_list|(
name|table
argument_list|)
decl_stmt|;
comment|// The operator tree till the sink operator has already been processed while
comment|// fetching the next row to fetch from the priority queue (possibly containing
comment|// multiple files in the small table given a file in the big table). Now, process
comment|// the remaining tree. Look at comments in DummyStoreOperator for additional
comment|// explanation.
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|forwardOp
init|=
name|conf
operator|.
name|getAliasToSink
argument_list|()
operator|.
name|get
argument_list|(
name|table
argument_list|)
operator|.
name|getChildOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
try|try
block|{
name|InspectableObject
name|row
init|=
name|mergeQueue
operator|.
name|getNextRow
argument_list|()
decl_stmt|;
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
name|fetchDone
index|[
name|tag
index|]
operator|=
literal|true
expr_stmt|;
return|return;
block|}
name|forwardOp
operator|.
name|processOp
argument_list|(
name|row
operator|.
name|o
argument_list|,
name|tag
argument_list|)
expr_stmt|;
comment|// check if any operator had a fatal error or early exit during
comment|// execution
if|if
condition|(
name|forwardOp
operator|.
name|getDone
argument_list|()
condition|)
block|{
name|fetchDone
index|[
name|tag
index|]
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|instanceof
name|OutOfMemoryError
condition|)
block|{
comment|// Don't create a new object if we are already out of memory
throw|throw
operator|(
name|OutOfMemoryError
operator|)
name|e
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Map local work failed"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
specifier|transient
name|boolean
name|closeCalled
init|=
literal|false
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|closeOp
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|closeCalled
condition|)
block|{
return|return;
block|}
name|closeCalled
operator|=
literal|true
expr_stmt|;
comment|// If there is a sort-merge join followed by a regular join, the SMBJoinOperator may not
comment|// get initialized at all. Consider the following query:
comment|// A SMB B JOIN C
comment|// For the mapper processing C, The SMJ is not initialized, no need to close it either.
if|if
condition|(
operator|!
name|initDone
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|inputFileChanged
operator|||
operator|!
name|firstFetchHappened
condition|)
block|{
comment|//set up the fetch operator for the new input file.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|MergeQueue
argument_list|>
name|entry
range|:
name|aliasToMergeQueue
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|alias
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|MergeQueue
name|mergeQueue
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|setUpFetchContexts
argument_list|(
name|alias
argument_list|,
name|mergeQueue
argument_list|)
expr_stmt|;
block|}
name|firstFetchHappened
operator|=
literal|true
expr_stmt|;
for|for
control|(
name|byte
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|pos
operator|!=
name|posBigTable
condition|)
block|{
name|fetchNextGroup
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
block|}
name|inputFileChanged
operator|=
literal|false
expr_stmt|;
block|}
name|joinFinalLeftData
argument_list|()
expr_stmt|;
comment|//clean up
for|for
control|(
name|int
name|pos
init|=
literal|0
init|;
name|pos
operator|<
name|order
operator|.
name|length
condition|;
name|pos
operator|++
control|)
block|{
if|if
condition|(
name|pos
operator|!=
name|posBigTable
condition|)
block|{
name|fetchDone
index|[
name|pos
index|]
operator|=
literal|false
expr_stmt|;
block|}
name|foundNextKeyGroup
index|[
name|pos
index|]
operator|=
literal|false
expr_stmt|;
block|}
name|localWorkInited
operator|=
literal|false
expr_stmt|;
name|super
operator|.
name|closeOp
argument_list|(
name|abort
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|MergeQueue
argument_list|>
name|entry
range|:
name|aliasToMergeQueue
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|alias
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|MergeQueue
name|mergeQueue
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Operator
name|forwardOp
init|=
name|localWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|get
argument_list|(
name|alias
argument_list|)
decl_stmt|;
name|forwardOp
operator|.
name|close
argument_list|(
name|abort
argument_list|)
expr_stmt|;
name|mergeQueue
operator|.
name|clearFetchContext
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|protected
name|boolean
name|allInitializedParentsAreClosed
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
comment|/**    * Implements the getName function for the Node Interface.    *    * @return the name of the operator    */
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
name|getOperatorName
argument_list|()
return|;
block|}
specifier|static
specifier|public
name|String
name|getOperatorName
parameter_list|()
block|{
return|return
literal|"MAPJOIN"
return|;
block|}
annotation|@
name|Override
specifier|public
name|OperatorType
name|getType
parameter_list|()
block|{
return|return
name|OperatorType
operator|.
name|MAPJOIN
return|;
block|}
specifier|public
name|boolean
name|isConvertedAutomaticallySMBJoin
parameter_list|()
block|{
return|return
name|convertedAutomaticallySMBJoin
return|;
block|}
specifier|public
name|void
name|setConvertedAutomaticallySMBJoin
parameter_list|(
name|boolean
name|convertedAutomaticallySMBJoin
parameter_list|)
block|{
name|this
operator|.
name|convertedAutomaticallySMBJoin
operator|=
name|convertedAutomaticallySMBJoin
expr_stmt|;
block|}
comment|// returns rows from possibly multiple bucket files of small table in ascending order
comment|// by utilizing primary queue (borrowed from hadoop)
comment|// elements of queue (Integer) are index to FetchOperator[] (segments)
specifier|private
class|class
name|MergeQueue
extends|extends
name|PriorityQueue
argument_list|<
name|Integer
argument_list|>
block|{
specifier|private
specifier|final
name|String
name|alias
decl_stmt|;
specifier|private
specifier|final
name|FetchWork
name|fetchWork
decl_stmt|;
specifier|private
specifier|final
name|JobConf
name|jobConf
decl_stmt|;
comment|// for keeping track of the number of elements read. just for debugging
specifier|transient
name|int
name|counter
decl_stmt|;
specifier|transient
name|FetchOperator
index|[]
name|segments
decl_stmt|;
specifier|transient
name|List
argument_list|<
name|ExprNodeEvaluator
argument_list|>
name|keyFields
decl_stmt|;
specifier|transient
name|List
argument_list|<
name|ObjectInspector
argument_list|>
name|keyFieldOIs
decl_stmt|;
specifier|transient
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|forwardOp
decl_stmt|;
specifier|transient
name|DummyStoreOperator
name|sinkOp
decl_stmt|;
comment|// index of FetchOperator which is providing smallest one
specifier|transient
name|Integer
name|currentMinSegment
decl_stmt|;
specifier|transient
name|ObjectPair
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|,
name|InspectableObject
argument_list|>
index|[]
name|keys
decl_stmt|;
specifier|public
name|MergeQueue
parameter_list|(
name|String
name|alias
parameter_list|,
name|FetchWork
name|fetchWork
parameter_list|,
name|JobConf
name|jobConf
parameter_list|,
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|forwardOp
parameter_list|,
name|DummyStoreOperator
name|sinkOp
parameter_list|)
block|{
name|this
operator|.
name|alias
operator|=
name|alias
expr_stmt|;
name|this
operator|.
name|fetchWork
operator|=
name|fetchWork
expr_stmt|;
name|this
operator|.
name|jobConf
operator|=
name|jobConf
expr_stmt|;
name|this
operator|.
name|forwardOp
operator|=
name|forwardOp
expr_stmt|;
name|this
operator|.
name|sinkOp
operator|=
name|sinkOp
expr_stmt|;
block|}
comment|// paths = bucket files of small table for current bucket file of big table
comment|// initializes a FetchOperator for each file in paths, reuses FetchOperator if possible
comment|// currently, number of paths is always the same (bucket numbers are all the same over
comment|// all partitions in a table).
comment|// But if hive supports assigning bucket number for each partition, this can be vary
specifier|public
name|void
name|setupContext
parameter_list|(
name|List
argument_list|<
name|Path
argument_list|>
name|paths
parameter_list|)
throws|throws
name|HiveException
block|{
name|int
name|segmentLen
init|=
name|paths
operator|.
name|size
argument_list|()
decl_stmt|;
name|FetchOperator
index|[]
name|segments
init|=
name|segmentsForSize
argument_list|(
name|segmentLen
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|segmentLen
condition|;
name|i
operator|++
control|)
block|{
name|Path
name|path
init|=
name|paths
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|segments
index|[
name|i
index|]
operator|==
literal|null
condition|)
block|{
name|segments
index|[
name|i
index|]
operator|=
operator|new
name|FetchOperator
argument_list|(
name|fetchWork
argument_list|,
operator|new
name|JobConf
argument_list|(
name|jobConf
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|segments
index|[
name|i
index|]
operator|.
name|setupContext
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|initialize
argument_list|(
name|segmentLen
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|segmentLen
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|nextHive
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|put
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|counter
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|FetchOperator
index|[]
name|segmentsForSize
parameter_list|(
name|int
name|segmentLen
parameter_list|)
block|{
if|if
condition|(
name|segments
operator|==
literal|null
operator|||
name|segments
operator|.
name|length
operator|<
name|segmentLen
condition|)
block|{
name|FetchOperator
index|[]
name|newSegments
init|=
operator|new
name|FetchOperator
index|[
name|segmentLen
index|]
decl_stmt|;
name|ObjectPair
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|,
name|InspectableObject
argument_list|>
index|[]
name|newKeys
init|=
operator|new
name|ObjectPair
index|[
name|segmentLen
index|]
decl_stmt|;
if|if
condition|(
name|segments
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|segments
argument_list|,
literal|0
argument_list|,
name|newSegments
argument_list|,
literal|0
argument_list|,
name|segments
operator|.
name|length
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|keys
argument_list|,
literal|0
argument_list|,
name|newKeys
argument_list|,
literal|0
argument_list|,
name|keys
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
name|segments
operator|=
name|newSegments
expr_stmt|;
name|keys
operator|=
name|newKeys
expr_stmt|;
block|}
return|return
name|segments
return|;
block|}
specifier|public
name|void
name|clearFetchContext
parameter_list|()
throws|throws
name|HiveException
block|{
if|if
condition|(
name|segments
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FetchOperator
name|op
range|:
name|segments
control|)
block|{
if|if
condition|(
name|op
operator|!=
literal|null
condition|)
block|{
name|op
operator|.
name|clearFetchContext
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|Override
specifier|protected
name|boolean
name|lessThan
parameter_list|(
name|Object
name|a
parameter_list|,
name|Object
name|b
parameter_list|)
block|{
return|return
name|compareKeys
argument_list|(
name|keys
index|[
operator|(
name|Integer
operator|)
name|a
index|]
operator|.
name|getFirst
argument_list|()
argument_list|,
name|keys
index|[
operator|(
name|Integer
operator|)
name|b
index|]
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|<
literal|0
return|;
block|}
specifier|public
specifier|final
name|InspectableObject
name|getNextRow
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|currentMinSegment
operator|!=
literal|null
condition|)
block|{
name|adjustPriorityQueue
argument_list|(
name|currentMinSegment
argument_list|)
expr_stmt|;
block|}
name|Integer
name|current
init|=
name|top
argument_list|()
decl_stmt|;
if|if
condition|(
name|current
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"MergeQueue forwarded "
operator|+
name|counter
operator|+
literal|" rows"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|counter
operator|++
expr_stmt|;
return|return
name|keys
index|[
name|currentMinSegment
operator|=
name|current
index|]
operator|.
name|getSecond
argument_list|()
return|;
block|}
specifier|private
name|void
name|adjustPriorityQueue
parameter_list|(
name|Integer
name|current
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|nextIO
argument_list|(
name|current
argument_list|)
condition|)
block|{
name|adjustTop
argument_list|()
expr_stmt|;
comment|// sort
block|}
else|else
block|{
name|pop
argument_list|()
expr_stmt|;
block|}
block|}
comment|// wrapping for exception handling
specifier|private
name|boolean
name|nextHive
parameter_list|(
name|Integer
name|current
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|next
argument_list|(
name|current
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// wrapping for exception handling
specifier|private
name|boolean
name|nextIO
parameter_list|(
name|Integer
name|current
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|next
argument_list|(
name|current
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// return true if current min segment(FetchOperator) has next row
specifier|private
name|boolean
name|next
parameter_list|(
name|Integer
name|current
parameter_list|)
throws|throws
name|IOException
throws|,
name|HiveException
block|{
if|if
condition|(
name|keyFields
operator|==
literal|null
condition|)
block|{
name|byte
name|tag
init|=
name|tagForAlias
argument_list|(
name|alias
argument_list|)
decl_stmt|;
comment|// joinKeys/joinKeysOI are initialized after making merge queue, so setup lazily at runtime
name|keyFields
operator|=
name|joinKeys
index|[
name|tag
index|]
expr_stmt|;
name|keyFieldOIs
operator|=
name|joinKeysObjectInspectors
index|[
name|tag
index|]
expr_stmt|;
block|}
name|InspectableObject
name|nextRow
init|=
name|segments
index|[
name|current
index|]
operator|.
name|getNextRow
argument_list|()
decl_stmt|;
while|while
condition|(
name|nextRow
operator|!=
literal|null
condition|)
block|{
name|sinkOp
operator|.
name|reset
argument_list|()
expr_stmt|;
if|if
condition|(
name|keys
index|[
name|current
index|]
operator|==
literal|null
condition|)
block|{
name|keys
index|[
name|current
index|]
operator|=
operator|new
name|ObjectPair
argument_list|<
name|List
argument_list|<
name|Object
argument_list|>
argument_list|,
name|InspectableObject
argument_list|>
argument_list|()
expr_stmt|;
block|}
comment|// Pass the row though the operator tree. It is guaranteed that not more than 1 row can
comment|// be produced from a input row.
name|forwardOp
operator|.
name|processOp
argument_list|(
name|nextRow
operator|.
name|o
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|nextRow
operator|=
name|sinkOp
operator|.
name|getResult
argument_list|()
expr_stmt|;
comment|// It is possible that the row got absorbed in the operator tree.
if|if
condition|(
name|nextRow
operator|.
name|o
operator|!=
literal|null
condition|)
block|{
comment|// todo this should be changed to be evaluated lazily, especially for single segment case
name|keys
index|[
name|current
index|]
operator|.
name|setFirst
argument_list|(
name|JoinUtil
operator|.
name|computeKeys
argument_list|(
name|nextRow
operator|.
name|o
argument_list|,
name|keyFields
argument_list|,
name|keyFieldOIs
argument_list|)
argument_list|)
expr_stmt|;
name|keys
index|[
name|current
index|]
operator|.
name|setSecond
argument_list|(
name|nextRow
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|nextRow
operator|=
name|segments
index|[
name|current
index|]
operator|.
name|getNextRow
argument_list|()
expr_stmt|;
block|}
name|keys
index|[
name|current
index|]
operator|=
literal|null
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|opAllowedConvertMapJoin
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
block|}
end_class

end_unit

