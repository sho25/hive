begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|BlockLocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedInputFormatInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedRowBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|InputFormatChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|SearchArgument
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableScanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|ColumnProjectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InvalidInputException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * A MapReduce/Hive input format for ORC files.  */
end_comment

begin_class
specifier|public
class|class
name|OrcInputFormat
implements|implements
name|InputFormat
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
implements|,
name|InputFormatChecker
implements|,
name|VectorizedInputFormatInterface
block|{
name|VectorizedOrcInputFormat
name|voif
init|=
operator|new
name|VectorizedOrcInputFormat
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|OrcInputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|String
name|MIN_SPLIT_SIZE
init|=
literal|"mapred.min.split.size"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MAX_SPLIT_SIZE
init|=
literal|"mapred.max.split.size"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MIN_SPLIT_SIZE
init|=
literal|16
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MAX_SPLIT_SIZE
init|=
literal|256
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
comment|/**    * When picking the hosts for a split that crosses block boundaries,    * any drop any host that has fewer than MIN_INCLUDED_LOCATION of the    * number of bytes available on the host with the most.    * If host1 has 10MB of the split, host2 has 20MB, and host3 has 18MB the    * split will contain host2 (100% of host2) and host3 (90% of host2). Host1    * with 50% will be dropped.    */
specifier|private
specifier|static
specifier|final
name|double
name|MIN_INCLUDED_LOCATION
init|=
literal|0.80
decl_stmt|;
specifier|private
specifier|static
class|class
name|OrcRecordReader
implements|implements
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
block|{
specifier|private
specifier|final
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|RecordReader
name|reader
decl_stmt|;
specifier|private
specifier|final
name|long
name|offset
decl_stmt|;
specifier|private
specifier|final
name|long
name|length
decl_stmt|;
specifier|private
specifier|final
name|int
name|numColumns
decl_stmt|;
specifier|private
name|float
name|progress
init|=
literal|0.0f
decl_stmt|;
name|OrcRecordReader
parameter_list|(
name|Reader
name|file
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
init|=
name|file
operator|.
name|getTypes
argument_list|()
decl_stmt|;
name|numColumns
operator|=
operator|(
name|types
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getSubtypesCount
argument_list|()
expr_stmt|;
name|boolean
index|[]
name|includedColumns
init|=
name|findIncludedColumns
argument_list|(
name|types
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|String
index|[]
name|columnNames
init|=
name|getIncludedColumnNames
argument_list|(
name|types
argument_list|,
name|includedColumns
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|SearchArgument
name|sarg
init|=
name|createSarg
argument_list|(
name|types
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|this
operator|.
name|reader
operator|=
name|file
operator|.
name|rows
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
name|includedColumns
argument_list|,
name|sarg
argument_list|,
name|columnNames
argument_list|)
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|length
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|NullWritable
name|key
parameter_list|,
name|OrcStruct
name|value
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|reader
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|reader
operator|.
name|next
argument_list|(
name|value
argument_list|)
expr_stmt|;
name|progress
operator|=
name|reader
operator|.
name|getProgress
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|NullWritable
name|createKey
parameter_list|()
block|{
return|return
name|NullWritable
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OrcStruct
name|createValue
parameter_list|()
block|{
return|return
operator|new
name|OrcStruct
argument_list|(
name|numColumns
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|offset
operator|+
call|(
name|long
call|)
argument_list|(
name|progress
operator|*
name|length
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|progress
return|;
block|}
block|}
specifier|private
specifier|static
specifier|final
name|PathFilter
name|hiddenFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
name|name
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Recurse down into a type subtree turning on all of the sub-columns.    * @param types the types of the file    * @param result the global view of columns that should be included    * @param typeId the root of tree to enable    */
specifier|static
name|void
name|includeColumnRecursive
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|boolean
index|[]
name|result
parameter_list|,
name|int
name|typeId
parameter_list|)
block|{
name|result
index|[
name|typeId
index|]
operator|=
literal|true
expr_stmt|;
name|OrcProto
operator|.
name|Type
name|type
init|=
name|types
operator|.
name|get
argument_list|(
name|typeId
argument_list|)
decl_stmt|;
name|int
name|children
init|=
name|type
operator|.
name|getSubtypesCount
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|children
condition|;
operator|++
name|i
control|)
block|{
name|includeColumnRecursive
argument_list|(
name|types
argument_list|,
name|result
argument_list|,
name|type
operator|.
name|getSubtypes
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|SearchArgument
name|createSarg
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|serializedPushdown
init|=
name|conf
operator|.
name|get
argument_list|(
name|TableScanDesc
operator|.
name|FILTER_EXPR_CONF_STR
argument_list|)
decl_stmt|;
if|if
condition|(
name|serializedPushdown
operator|==
literal|null
operator|||
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_NAMES_CONF_STR
argument_list|)
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No ORC pushdown predicate"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|SearchArgument
name|sarg
init|=
name|SearchArgument
operator|.
name|FACTORY
operator|.
name|create
argument_list|(
name|Utilities
operator|.
name|deserializeExpression
argument_list|(
name|serializedPushdown
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"ORC pushdown predicate: "
operator|+
name|sarg
argument_list|)
expr_stmt|;
return|return
name|sarg
return|;
block|}
specifier|public
specifier|static
name|String
index|[]
name|getIncludedColumnNames
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|boolean
index|[]
name|includedColumns
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|columnNamesString
init|=
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_NAMES_CONF_STR
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"included columns names = "
operator|+
name|columnNamesString
argument_list|)
expr_stmt|;
if|if
condition|(
name|columnNamesString
operator|==
literal|null
operator|||
name|conf
operator|.
name|get
argument_list|(
name|TableScanDesc
operator|.
name|FILTER_EXPR_CONF_STR
argument_list|)
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|String
index|[]
name|neededColumnNames
init|=
name|columnNamesString
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
name|String
index|[]
name|columnNames
init|=
operator|new
name|String
index|[
name|types
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|columnId
range|:
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getSubtypesList
argument_list|()
control|)
block|{
if|if
condition|(
name|includedColumns
operator|==
literal|null
operator|||
name|includedColumns
index|[
name|columnId
index|]
condition|)
block|{
name|columnNames
index|[
name|columnId
index|]
operator|=
name|neededColumnNames
index|[
name|i
operator|++
index|]
expr_stmt|;
block|}
block|}
return|return
name|columnNames
return|;
block|}
comment|/**    * Take the configuration and figure out which columns we need to include.    * @param types the types of the file    * @param conf the configuration    * @return true for each column that should be included    */
specifier|public
specifier|static
name|boolean
index|[]
name|findIncludedColumns
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"included column ids = "
operator|+
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_IDS_CONF_STR
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|ColumnProjectionUtils
operator|.
name|isReadAllColumns
argument_list|(
name|conf
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
name|int
name|numColumns
init|=
name|types
operator|.
name|size
argument_list|()
decl_stmt|;
name|boolean
index|[]
name|result
init|=
operator|new
name|boolean
index|[
name|numColumns
index|]
decl_stmt|;
name|result
index|[
literal|0
index|]
operator|=
literal|true
expr_stmt|;
name|OrcProto
operator|.
name|Type
name|root
init|=
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|included
init|=
name|ColumnProjectionUtils
operator|.
name|getReadColumnIDs
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|root
operator|.
name|getSubtypesCount
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|included
operator|.
name|contains
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|includeColumnRecursive
argument_list|(
name|types
argument_list|,
name|result
argument_list|,
name|root
operator|.
name|getSubtypes
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// if we are filtering at least one column, return the boolean array
for|for
control|(
name|boolean
name|include
range|:
name|result
control|)
block|{
if|if
condition|(
operator|!
name|include
condition|)
block|{
return|return
name|result
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
name|getRecordReader
parameter_list|(
name|InputSplit
name|inputSplit
parameter_list|,
name|JobConf
name|conf
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isVectorMode
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|VectorizedRowBatch
argument_list|>
name|vorr
init|=
name|voif
operator|.
name|getRecordReader
argument_list|(
name|inputSplit
argument_list|,
name|conf
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
return|return
operator|(
name|RecordReader
operator|)
name|vorr
return|;
block|}
name|FileSplit
name|fileSplit
init|=
operator|(
name|FileSplit
operator|)
name|inputSplit
decl_stmt|;
name|Path
name|path
init|=
name|fileSplit
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|reporter
operator|.
name|setStatus
argument_list|(
name|fileSplit
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|OrcRecordReader
argument_list|(
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
argument_list|,
name|conf
argument_list|,
name|fileSplit
operator|.
name|getStart
argument_list|()
argument_list|,
name|fileSplit
operator|.
name|getLength
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|validateInput
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
name|files
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isVectorMode
argument_list|(
name|conf
argument_list|)
condition|)
block|{
return|return
name|voif
operator|.
name|validateInput
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|files
argument_list|)
return|;
block|}
if|if
condition|(
name|files
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
try|try
block|{
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|boolean
name|isVectorMode
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|Utilities
operator|.
name|getPlanPath
argument_list|(
name|conf
argument_list|)
operator|!=
literal|null
operator|&&
name|Utilities
operator|.
name|getMapRedWork
argument_list|(
name|conf
argument_list|)
operator|.
name|getMapWork
argument_list|()
operator|.
name|getVectorMode
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Get the list of input {@link Path}s for the map-reduce job.    *    * @param conf The configuration of the job    * @return the list of input {@link Path}s for the map-reduce job.    */
specifier|static
name|Path
index|[]
name|getInputPaths
parameter_list|(
name|JobConf
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|dirs
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"mapred.input.dir"
argument_list|)
decl_stmt|;
if|if
condition|(
name|dirs
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Configuration mapred.input.dir is not defined."
argument_list|)
throw|;
block|}
name|String
index|[]
name|list
init|=
name|StringUtils
operator|.
name|split
argument_list|(
name|dirs
argument_list|)
decl_stmt|;
name|Path
index|[]
name|result
init|=
operator|new
name|Path
index|[
name|list
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|list
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
operator|new
name|Path
argument_list|(
name|StringUtils
operator|.
name|unEscapeString
argument_list|(
name|list
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * The global information about the split generation that we pass around to    * the different worker threads.    */
specifier|static
class|class
name|Context
block|{
specifier|private
specifier|final
name|ExecutorService
name|threadPool
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
literal|10
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|FileSplit
argument_list|>
name|splits
init|=
operator|new
name|ArrayList
argument_list|<
name|FileSplit
argument_list|>
argument_list|(
literal|10000
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|Throwable
argument_list|>
name|errors
init|=
operator|new
name|ArrayList
argument_list|<
name|Throwable
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|HadoopShims
name|shims
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxSize
decl_stmt|;
specifier|private
specifier|final
name|long
name|minSize
decl_stmt|;
comment|/**      * A count of the number of threads that may create more work for the      * thread pool.      */
specifier|private
name|int
name|schedulers
init|=
literal|0
decl_stmt|;
name|Context
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|minSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MIN_SPLIT_SIZE
argument_list|,
name|DEFAULT_MIN_SPLIT_SIZE
argument_list|)
expr_stmt|;
name|maxSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MAX_SPLIT_SIZE
argument_list|,
name|DEFAULT_MAX_SPLIT_SIZE
argument_list|)
expr_stmt|;
block|}
name|int
name|getSchedulers
parameter_list|()
block|{
return|return
name|schedulers
return|;
block|}
comment|/**      * Get the Nth split.      * @param index if index>= 0, count from the front, otherwise count from      *     the back.      * @result the Nth file split      */
name|FileSplit
name|getResult
parameter_list|(
name|int
name|index
parameter_list|)
block|{
if|if
condition|(
name|index
operator|>=
literal|0
condition|)
block|{
return|return
name|splits
operator|.
name|get
argument_list|(
name|index
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|splits
operator|.
name|get
argument_list|(
name|splits
operator|.
name|size
argument_list|()
operator|+
name|index
argument_list|)
return|;
block|}
block|}
name|List
argument_list|<
name|Throwable
argument_list|>
name|getErrors
parameter_list|()
block|{
return|return
name|errors
return|;
block|}
comment|/**      * Add a unit of work.      * @param runnable the object to run      */
specifier|synchronized
name|void
name|schedule
parameter_list|(
name|Runnable
name|runnable
parameter_list|)
block|{
if|if
condition|(
name|runnable
operator|instanceof
name|FileGenerator
condition|)
block|{
name|schedulers
operator|+=
literal|1
expr_stmt|;
block|}
name|threadPool
operator|.
name|execute
argument_list|(
name|runnable
argument_list|)
expr_stmt|;
block|}
comment|/**      * Mark a worker that may generate more work as done.      */
specifier|synchronized
name|void
name|decrementSchedulers
parameter_list|()
block|{
name|schedulers
operator|-=
literal|1
expr_stmt|;
if|if
condition|(
name|schedulers
operator|==
literal|0
condition|)
block|{
name|notify
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * Wait until all of the tasks are done. It waits until all of the      * threads that may create more work are done and then shuts down the      * thread pool and waits for the final threads to finish.      */
specifier|synchronized
name|void
name|waitForTasks
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
name|schedulers
operator|!=
literal|0
condition|)
block|{
name|wait
argument_list|()
expr_stmt|;
block|}
name|threadPool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|threadPool
operator|.
name|awaitTermination
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
name|TimeUnit
operator|.
name|DAYS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"interrupted"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Given a directory, get the list of files and blocks in those files.    * A thread is used for each directory.    */
specifier|static
specifier|final
class|class
name|FileGenerator
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
name|FileGenerator
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|)
block|{
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
block|}
comment|/**      * For each path, get the list of files and blocks that they consist of.      */
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|Iterator
argument_list|<
name|FileStatus
argument_list|>
name|itr
init|=
name|context
operator|.
name|shims
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
while|while
condition|(
name|itr
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FileStatus
name|file
init|=
name|itr
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|file
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|context
operator|.
name|schedule
argument_list|(
operator|new
name|SplitGenerator
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|file
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// mark the fact that we are done
name|context
operator|.
name|decrementSchedulers
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|th
parameter_list|)
block|{
name|context
operator|.
name|decrementSchedulers
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|context
operator|.
name|errors
init|)
block|{
name|context
operator|.
name|errors
operator|.
name|add
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Split the stripes of a given file into input splits.    * A thread is used for each file.    */
specifier|static
specifier|final
class|class
name|SplitGenerator
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|FileStatus
name|file
decl_stmt|;
specifier|private
specifier|final
name|long
name|blockSize
decl_stmt|;
specifier|private
specifier|final
name|BlockLocation
index|[]
name|locations
decl_stmt|;
name|SplitGenerator
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|file
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|file
operator|=
name|file
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
name|file
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|locations
operator|=
name|context
operator|.
name|shims
operator|.
name|getLocations
argument_list|(
name|fs
argument_list|,
name|file
argument_list|)
expr_stmt|;
block|}
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|file
operator|.
name|getPath
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"splitter("
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|")"
return|;
block|}
comment|/**      * Compute the number of bytes that overlap between the two ranges.      * @param offset1 start of range1      * @param length1 length of range1      * @param offset2 start of range2      * @param length2 length of range2      * @return the number of bytes in the overlap range      */
specifier|static
name|long
name|getOverlap
parameter_list|(
name|long
name|offset1
parameter_list|,
name|long
name|length1
parameter_list|,
name|long
name|offset2
parameter_list|,
name|long
name|length2
parameter_list|)
block|{
name|long
name|end1
init|=
name|offset1
operator|+
name|length1
decl_stmt|;
name|long
name|end2
init|=
name|offset2
operator|+
name|length2
decl_stmt|;
if|if
condition|(
name|end2
operator|<=
name|offset1
operator|||
name|end1
operator|<=
name|offset2
condition|)
block|{
return|return
literal|0
return|;
block|}
else|else
block|{
return|return
name|Math
operator|.
name|min
argument_list|(
name|end1
argument_list|,
name|end2
argument_list|)
operator|-
name|Math
operator|.
name|max
argument_list|(
name|offset1
argument_list|,
name|offset2
argument_list|)
return|;
block|}
block|}
comment|/**      * Create an input split over the given range of bytes. The location of the      * split is based on where the majority of the byte are coming from. ORC      * files are unlikely to have splits that cross between blocks because they      * are written with large block sizes.      * @param offset the start of the split      * @param length the length of the split      * @throws IOException      */
name|void
name|createSplit
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|String
index|[]
name|hosts
decl_stmt|;
if|if
condition|(
operator|(
name|offset
operator|%
name|blockSize
operator|)
operator|+
name|length
operator|<=
name|blockSize
condition|)
block|{
comment|// handle the single block case
name|hosts
operator|=
name|locations
index|[
call|(
name|int
call|)
argument_list|(
name|offset
operator|/
name|blockSize
argument_list|)
index|]
operator|.
name|getHosts
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Calculate the number of bytes in the split that are local to each
comment|// host.
name|Map
argument_list|<
name|String
argument_list|,
name|LongWritable
argument_list|>
name|sizes
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LongWritable
argument_list|>
argument_list|()
decl_stmt|;
name|long
name|maxSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|BlockLocation
name|block
range|:
name|locations
control|)
block|{
name|long
name|overlap
init|=
name|getOverlap
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
name|block
operator|.
name|getOffset
argument_list|()
argument_list|,
name|block
operator|.
name|getLength
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|overlap
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|String
name|host
range|:
name|block
operator|.
name|getHosts
argument_list|()
control|)
block|{
name|LongWritable
name|val
init|=
name|sizes
operator|.
name|get
argument_list|(
name|host
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
operator|new
name|LongWritable
argument_list|()
expr_stmt|;
name|sizes
operator|.
name|put
argument_list|(
name|host
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
name|val
operator|.
name|set
argument_list|(
name|val
operator|.
name|get
argument_list|()
operator|+
name|overlap
argument_list|)
expr_stmt|;
name|maxSize
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxSize
argument_list|,
name|val
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// filter the list of locations to those that have at least 80% of the
comment|// max
name|long
name|threshold
init|=
call|(
name|long
call|)
argument_list|(
name|maxSize
operator|*
name|MIN_INCLUDED_LOCATION
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|hostList
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
comment|// build the locations in a predictable order to simplify testing
for|for
control|(
name|BlockLocation
name|block
range|:
name|locations
control|)
block|{
for|for
control|(
name|String
name|host
range|:
name|block
operator|.
name|getHosts
argument_list|()
control|)
block|{
if|if
condition|(
name|sizes
operator|.
name|containsKey
argument_list|(
name|host
argument_list|)
condition|)
block|{
if|if
condition|(
name|sizes
operator|.
name|get
argument_list|(
name|host
argument_list|)
operator|.
name|get
argument_list|()
operator|>=
name|threshold
condition|)
block|{
name|hostList
operator|.
name|add
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
name|sizes
operator|.
name|remove
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|hosts
operator|=
operator|new
name|String
index|[
name|hostList
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|hostList
operator|.
name|toArray
argument_list|(
name|hosts
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|context
operator|.
name|splits
init|)
block|{
name|context
operator|.
name|splits
operator|.
name|add
argument_list|(
operator|new
name|FileSplit
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|hosts
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Divide the adjacent stripes in the file into input splits based on the      * block size and the configured minimum and maximum sizes.      */
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|Reader
name|orcReader
init|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|currentOffset
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|currentLength
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StripeInformation
name|stripe
range|:
name|orcReader
operator|.
name|getStripes
argument_list|()
control|)
block|{
comment|// if we are working on a stripe, over the min stripe size, and
comment|// crossed a block boundary, cut the input split here.
if|if
condition|(
name|currentOffset
operator|!=
operator|-
literal|1
operator|&&
name|currentLength
operator|>
name|context
operator|.
name|minSize
operator|&&
operator|(
name|currentOffset
operator|/
name|blockSize
operator|!=
name|stripe
operator|.
name|getOffset
argument_list|()
operator|/
name|blockSize
operator|)
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// if we aren't building a split, start a new one.
if|if
condition|(
name|currentOffset
operator|==
operator|-
literal|1
condition|)
block|{
name|currentOffset
operator|=
name|stripe
operator|.
name|getOffset
argument_list|()
expr_stmt|;
name|currentLength
operator|=
name|stripe
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|currentLength
operator|+=
name|stripe
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|currentLength
operator|>=
name|context
operator|.
name|maxSize
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
if|if
condition|(
name|currentOffset
operator|!=
operator|-
literal|1
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|th
parameter_list|)
block|{
synchronized|synchronized
init|(
name|context
operator|.
name|errors
init|)
block|{
name|context
operator|.
name|errors
operator|.
name|add
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|InputSplit
index|[]
name|getSplits
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|int
name|numSplits
parameter_list|)
throws|throws
name|IOException
block|{
comment|// use threads to resolve directories into splits
name|Context
name|context
init|=
operator|new
name|Context
argument_list|(
name|job
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|dir
range|:
name|getInputPaths
argument_list|(
name|job
argument_list|)
control|)
block|{
name|FileSystem
name|fs
init|=
name|dir
operator|.
name|getFileSystem
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|context
operator|.
name|schedule
argument_list|(
operator|new
name|FileGenerator
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|context
operator|.
name|waitForTasks
argument_list|()
expr_stmt|;
comment|// deal with exceptions
if|if
condition|(
operator|!
name|context
operator|.
name|errors
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|IOException
argument_list|>
name|errors
init|=
operator|new
name|ArrayList
argument_list|<
name|IOException
argument_list|>
argument_list|(
name|context
operator|.
name|errors
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Throwable
name|th
range|:
name|context
operator|.
name|errors
control|)
block|{
if|if
condition|(
name|th
operator|instanceof
name|IOException
condition|)
block|{
name|errors
operator|.
name|add
argument_list|(
operator|(
name|IOException
operator|)
name|th
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"serious problem"
argument_list|,
name|th
argument_list|)
throw|;
block|}
block|}
throw|throw
operator|new
name|InvalidInputException
argument_list|(
name|errors
argument_list|)
throw|;
block|}
name|InputSplit
index|[]
name|result
init|=
operator|new
name|InputSplit
index|[
name|context
operator|.
name|splits
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|context
operator|.
name|splits
operator|.
name|toArray
argument_list|(
name|result
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
block|}
end_class

end_unit

