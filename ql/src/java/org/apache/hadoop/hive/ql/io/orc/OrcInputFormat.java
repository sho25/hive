begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|BlockLocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedInputFormatInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedRowBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|InputFormatChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Metadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Reader
operator|.
name|FileMetaInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|RecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|PredicateLeaf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|SearchArgument
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|log
operator|.
name|PerfLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|SearchArgument
operator|.
name|TruthValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableScanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|ColumnProjectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InvalidInputException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|Cache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_comment
comment|/**  * A MapReduce/Hive input format for ORC files.  */
end_comment

begin_class
specifier|public
class|class
name|OrcInputFormat
implements|implements
name|InputFormat
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
implements|,
name|InputFormatChecker
implements|,
name|VectorizedInputFormatInterface
block|{
name|VectorizedOrcInputFormat
name|voif
init|=
operator|new
name|VectorizedOrcInputFormat
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|OrcInputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|String
name|MIN_SPLIT_SIZE
init|=
literal|"mapred.min.split.size"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MAX_SPLIT_SIZE
init|=
literal|"mapred.max.split.size"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MIN_SPLIT_SIZE
init|=
literal|16
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MAX_SPLIT_SIZE
init|=
literal|256
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|PerfLogger
name|perfLogger
init|=
name|PerfLogger
operator|.
name|getPerfLogger
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|CLASS_NAME
init|=
name|ReaderImpl
operator|.
name|class
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|/**    * When picking the hosts for a split that crosses block boundaries,    * any drop any host that has fewer than MIN_INCLUDED_LOCATION of the    * number of bytes available on the host with the most.    * If host1 has 10MB of the split, host2 has 20MB, and host3 has 18MB the    * split will contain host2 (100% of host2) and host3 (90% of host2). Host1    * with 50% will be dropped.    */
specifier|private
specifier|static
specifier|final
name|double
name|MIN_INCLUDED_LOCATION
init|=
literal|0.80
decl_stmt|;
specifier|private
specifier|static
class|class
name|OrcRecordReader
implements|implements
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
block|{
specifier|private
specifier|final
name|RecordReader
name|reader
decl_stmt|;
specifier|private
specifier|final
name|long
name|offset
decl_stmt|;
specifier|private
specifier|final
name|long
name|length
decl_stmt|;
specifier|private
specifier|final
name|int
name|numColumns
decl_stmt|;
specifier|private
name|float
name|progress
init|=
literal|0.0f
decl_stmt|;
name|OrcRecordReader
parameter_list|(
name|Reader
name|file
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
init|=
name|file
operator|.
name|getTypes
argument_list|()
decl_stmt|;
name|numColumns
operator|=
operator|(
name|types
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getSubtypesCount
argument_list|()
expr_stmt|;
name|this
operator|.
name|reader
operator|=
name|createReaderFromFile
argument_list|(
name|file
argument_list|,
name|conf
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|length
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|NullWritable
name|key
parameter_list|,
name|OrcStruct
name|value
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|reader
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|reader
operator|.
name|next
argument_list|(
name|value
argument_list|)
expr_stmt|;
name|progress
operator|=
name|reader
operator|.
name|getProgress
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|NullWritable
name|createKey
parameter_list|()
block|{
return|return
name|NullWritable
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OrcStruct
name|createValue
parameter_list|()
block|{
return|return
operator|new
name|OrcStruct
argument_list|(
name|numColumns
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|offset
operator|+
call|(
name|long
call|)
argument_list|(
name|progress
operator|*
name|length
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|progress
return|;
block|}
block|}
specifier|static
name|RecordReader
name|createReaderFromFile
parameter_list|(
name|Reader
name|file
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
init|=
name|file
operator|.
name|getTypes
argument_list|()
decl_stmt|;
name|boolean
index|[]
name|includedColumns
init|=
name|findIncludedColumns
argument_list|(
name|types
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|String
index|[]
name|columnNames
init|=
name|getIncludedColumnNames
argument_list|(
name|types
argument_list|,
name|includedColumns
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|SearchArgument
name|sarg
init|=
name|createSarg
argument_list|(
name|types
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|RecordReader
name|reader
init|=
name|file
operator|.
name|rows
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
name|includedColumns
argument_list|,
name|sarg
argument_list|,
name|columnNames
argument_list|)
decl_stmt|;
return|return
name|reader
return|;
block|}
specifier|private
specifier|static
specifier|final
name|PathFilter
name|hiddenFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
name|name
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Recurse down into a type subtree turning on all of the sub-columns.    * @param types the types of the file    * @param result the global view of columns that should be included    * @param typeId the root of tree to enable    */
specifier|static
name|void
name|includeColumnRecursive
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|boolean
index|[]
name|result
parameter_list|,
name|int
name|typeId
parameter_list|)
block|{
name|result
index|[
name|typeId
index|]
operator|=
literal|true
expr_stmt|;
name|OrcProto
operator|.
name|Type
name|type
init|=
name|types
operator|.
name|get
argument_list|(
name|typeId
argument_list|)
decl_stmt|;
name|int
name|children
init|=
name|type
operator|.
name|getSubtypesCount
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|children
condition|;
operator|++
name|i
control|)
block|{
name|includeColumnRecursive
argument_list|(
name|types
argument_list|,
name|result
argument_list|,
name|type
operator|.
name|getSubtypes
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|SearchArgument
name|createSarg
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|serializedPushdown
init|=
name|conf
operator|.
name|get
argument_list|(
name|TableScanDesc
operator|.
name|FILTER_EXPR_CONF_STR
argument_list|)
decl_stmt|;
if|if
condition|(
name|serializedPushdown
operator|==
literal|null
operator|||
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_NAMES_CONF_STR
argument_list|)
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No ORC pushdown predicate"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|SearchArgument
name|sarg
init|=
name|SearchArgument
operator|.
name|FACTORY
operator|.
name|create
argument_list|(
name|Utilities
operator|.
name|deserializeExpression
argument_list|(
name|serializedPushdown
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"ORC pushdown predicate: "
operator|+
name|sarg
argument_list|)
expr_stmt|;
return|return
name|sarg
return|;
block|}
specifier|public
specifier|static
name|String
index|[]
name|getIncludedColumnNames
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|boolean
index|[]
name|includedColumns
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|columnNamesString
init|=
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_NAMES_CONF_STR
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"included columns names = "
operator|+
name|columnNamesString
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|columnNamesString
operator|==
literal|null
operator|||
name|conf
operator|.
name|get
argument_list|(
name|TableScanDesc
operator|.
name|FILTER_EXPR_CONF_STR
argument_list|)
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|String
index|[]
name|neededColumnNames
init|=
name|columnNamesString
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
name|String
index|[]
name|columnNames
init|=
operator|new
name|String
index|[
name|types
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|columnId
range|:
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getSubtypesList
argument_list|()
control|)
block|{
if|if
condition|(
name|includedColumns
operator|==
literal|null
operator|||
name|includedColumns
index|[
name|columnId
index|]
condition|)
block|{
name|columnNames
index|[
name|columnId
index|]
operator|=
name|neededColumnNames
index|[
name|i
operator|++
index|]
expr_stmt|;
block|}
block|}
return|return
name|columnNames
return|;
block|}
comment|/**    * Take the configuration and figure out which columns we need to include.    * @param types the types of the file    * @param conf the configuration    * @return true for each column that should be included    */
specifier|public
specifier|static
name|boolean
index|[]
name|findIncludedColumns
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"included column ids = "
operator|+
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_IDS_CONF_STR
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|ColumnProjectionUtils
operator|.
name|isReadAllColumns
argument_list|(
name|conf
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
name|int
name|numColumns
init|=
name|types
operator|.
name|size
argument_list|()
decl_stmt|;
name|boolean
index|[]
name|result
init|=
operator|new
name|boolean
index|[
name|numColumns
index|]
decl_stmt|;
name|result
index|[
literal|0
index|]
operator|=
literal|true
expr_stmt|;
name|OrcProto
operator|.
name|Type
name|root
init|=
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|included
init|=
name|ColumnProjectionUtils
operator|.
name|getReadColumnIDs
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|root
operator|.
name|getSubtypesCount
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|included
operator|.
name|contains
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|includeColumnRecursive
argument_list|(
name|types
argument_list|,
name|result
argument_list|,
name|root
operator|.
name|getSubtypes
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// if we are filtering at least one column, return the boolean array
for|for
control|(
name|boolean
name|include
range|:
name|result
control|)
block|{
if|if
condition|(
operator|!
name|include
condition|)
block|{
return|return
name|result
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
annotation|@
name|Override
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
name|getRecordReader
parameter_list|(
name|InputSplit
name|inputSplit
parameter_list|,
name|JobConf
name|conf
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isVectorMode
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|VectorizedRowBatch
argument_list|>
name|vorr
init|=
name|voif
operator|.
name|getRecordReader
argument_list|(
name|inputSplit
argument_list|,
name|conf
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
return|return
operator|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
operator|)
name|vorr
return|;
block|}
name|FileSplit
name|fSplit
init|=
operator|(
name|FileSplit
operator|)
name|inputSplit
decl_stmt|;
name|reporter
operator|.
name|setStatus
argument_list|(
name|fSplit
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|fSplit
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|fSplit
operator|instanceof
name|OrcSplit
operator|)
condition|)
block|{
comment|//If CombineHiveInputFormat is used, it works with FileSplit and not OrcSplit
name|reader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//We have OrcSplit, which may have footer metadata cached, so use the appropriate reader
comment|//constructor
name|OrcSplit
name|orcSplit
init|=
operator|(
name|OrcSplit
operator|)
name|fSplit
decl_stmt|;
if|if
condition|(
name|orcSplit
operator|.
name|hasFooter
argument_list|()
condition|)
block|{
name|FileMetaInfo
name|fMetaInfo
init|=
name|orcSplit
operator|.
name|getFileMetaInfo
argument_list|()
decl_stmt|;
name|reader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|fMetaInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|reader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|OrcRecordReader
argument_list|(
name|reader
argument_list|,
name|conf
argument_list|,
name|fSplit
operator|.
name|getStart
argument_list|()
argument_list|,
name|fSplit
operator|.
name|getLength
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|validateInput
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
name|files
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isVectorMode
argument_list|(
name|conf
argument_list|)
condition|)
block|{
return|return
name|voif
operator|.
name|validateInput
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|files
argument_list|)
return|;
block|}
if|if
condition|(
name|files
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
try|try
block|{
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|boolean
name|isVectorMode
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|Utilities
operator|.
name|isVectorMode
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Get the list of input {@link Path}s for the map-reduce job.    *    * @param conf The configuration of the job    * @return the list of input {@link Path}s for the map-reduce job.    */
specifier|static
name|Path
index|[]
name|getInputPaths
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|dirs
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"mapred.input.dir"
argument_list|)
decl_stmt|;
if|if
condition|(
name|dirs
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Configuration mapred.input.dir is not defined."
argument_list|)
throw|;
block|}
name|String
index|[]
name|list
init|=
name|StringUtils
operator|.
name|split
argument_list|(
name|dirs
argument_list|)
decl_stmt|;
name|Path
index|[]
name|result
init|=
operator|new
name|Path
index|[
name|list
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|list
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
operator|new
name|Path
argument_list|(
name|StringUtils
operator|.
name|unEscapeString
argument_list|(
name|list
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * The global information about the split generation that we pass around to    * the different worker threads.    */
specifier|static
class|class
name|Context
block|{
specifier|static
class|class
name|FileSplitInfo
block|{
name|FileSplitInfo
parameter_list|(
name|Path
name|file
parameter_list|,
name|long
name|start
parameter_list|,
name|long
name|length
parameter_list|,
name|String
index|[]
name|hosts
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|)
block|{
name|this
operator|.
name|file
operator|=
name|file
expr_stmt|;
name|this
operator|.
name|start
operator|=
name|start
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|length
expr_stmt|;
name|this
operator|.
name|hosts
operator|=
name|hosts
expr_stmt|;
name|this
operator|.
name|fileMetaInfo
operator|=
name|fileMetaInfo
expr_stmt|;
block|}
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|file
return|;
block|}
name|long
name|getStart
parameter_list|()
block|{
return|return
name|start
return|;
block|}
name|long
name|getLength
parameter_list|()
block|{
return|return
name|length
return|;
block|}
name|String
index|[]
name|getLocations
parameter_list|()
block|{
return|return
name|hosts
return|;
block|}
name|FileMetaInfo
name|getFileMetaInfo
parameter_list|()
block|{
return|return
name|fileMetaInfo
return|;
block|}
specifier|private
name|Path
name|file
decl_stmt|;
specifier|private
name|long
name|start
decl_stmt|;
specifier|private
name|long
name|length
decl_stmt|;
specifier|private
name|String
index|[]
name|hosts
decl_stmt|;
name|FileMetaInfo
name|fileMetaInfo
decl_stmt|;
block|}
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|static
name|Cache
argument_list|<
name|Path
argument_list|,
name|FileInfo
argument_list|>
name|footerCache
decl_stmt|;
specifier|private
specifier|final
name|ExecutorService
name|threadPool
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|FileSplitInfo
argument_list|>
name|splits
init|=
operator|new
name|ArrayList
argument_list|<
name|FileSplitInfo
argument_list|>
argument_list|(
literal|10000
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|Throwable
argument_list|>
name|errors
init|=
operator|new
name|ArrayList
argument_list|<
name|Throwable
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|HadoopShims
name|shims
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxSize
decl_stmt|;
specifier|private
specifier|final
name|long
name|minSize
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|footerInSplits
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|cacheStripeDetails
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|cacheHitCounter
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|numFilesCounter
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
name|Throwable
name|fatalError
init|=
literal|null
decl_stmt|;
comment|/**      * A count of the number of threads that may create more work for the      * thread pool.      */
specifier|private
name|int
name|schedulers
init|=
literal|0
decl_stmt|;
name|Context
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|minSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MIN_SPLIT_SIZE
argument_list|,
name|DEFAULT_MIN_SPLIT_SIZE
argument_list|)
expr_stmt|;
name|maxSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MAX_SPLIT_SIZE
argument_list|,
name|DEFAULT_MAX_SPLIT_SIZE
argument_list|)
expr_stmt|;
name|footerInSplits
operator|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_INCLUDE_FILE_FOOTER_IN_SPLITS
argument_list|)
expr_stmt|;
name|int
name|cacheStripeDetailsSize
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_CACHE_STRIPE_DETAILS_SIZE
argument_list|)
decl_stmt|;
name|int
name|numThreads
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_COMPUTE_SPLITS_NUM_THREADS
argument_list|)
decl_stmt|;
name|cacheStripeDetails
operator|=
operator|(
name|cacheStripeDetailsSize
operator|>
literal|0
operator|)
expr_stmt|;
name|threadPool
operator|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|numThreads
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"ORC_GET_SPLITS #%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|Context
operator|.
name|class
init|)
block|{
if|if
condition|(
name|footerCache
operator|==
literal|null
operator|&&
name|cacheStripeDetails
condition|)
block|{
name|footerCache
operator|=
name|CacheBuilder
operator|.
name|newBuilder
argument_list|()
operator|.
name|concurrencyLevel
argument_list|(
name|numThreads
argument_list|)
operator|.
name|initialCapacity
argument_list|(
name|cacheStripeDetailsSize
argument_list|)
operator|.
name|softValues
argument_list|()
operator|.
name|build
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|int
name|getSchedulers
parameter_list|()
block|{
return|return
name|schedulers
return|;
block|}
comment|/**      * Get the Nth split.      * @param index if index>= 0, count from the front, otherwise count from      *     the back.      * @result the Nth file split      */
name|FileSplitInfo
name|getResult
parameter_list|(
name|int
name|index
parameter_list|)
block|{
if|if
condition|(
name|index
operator|>=
literal|0
condition|)
block|{
return|return
name|splits
operator|.
name|get
argument_list|(
name|index
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|splits
operator|.
name|get
argument_list|(
name|splits
operator|.
name|size
argument_list|()
operator|+
name|index
argument_list|)
return|;
block|}
block|}
name|List
argument_list|<
name|Throwable
argument_list|>
name|getErrors
parameter_list|()
block|{
return|return
name|errors
return|;
block|}
comment|/**      * Add a unit of work.      * @param runnable the object to run      */
specifier|synchronized
name|void
name|schedule
parameter_list|(
name|Runnable
name|runnable
parameter_list|)
block|{
if|if
condition|(
name|fatalError
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|runnable
operator|instanceof
name|FileGenerator
operator|||
name|runnable
operator|instanceof
name|SplitGenerator
condition|)
block|{
name|schedulers
operator|+=
literal|1
expr_stmt|;
block|}
name|threadPool
operator|.
name|execute
argument_list|(
name|runnable
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"serious problem"
argument_list|,
name|fatalError
argument_list|)
throw|;
block|}
block|}
comment|/**      * Mark a worker that may generate more work as done.      */
specifier|synchronized
name|void
name|decrementSchedulers
parameter_list|()
block|{
name|schedulers
operator|-=
literal|1
expr_stmt|;
if|if
condition|(
name|schedulers
operator|==
literal|0
condition|)
block|{
name|notify
argument_list|()
expr_stmt|;
block|}
block|}
specifier|synchronized
name|void
name|notifyOnNonIOException
parameter_list|(
name|Throwable
name|th
parameter_list|)
block|{
name|fatalError
operator|=
name|th
expr_stmt|;
name|notify
argument_list|()
expr_stmt|;
block|}
comment|/**      * Wait until all of the tasks are done. It waits until all of the      * threads that may create more work are done and then shuts down the      * thread pool and waits for the final threads to finish.      */
specifier|synchronized
name|void
name|waitForTasks
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
name|schedulers
operator|!=
literal|0
condition|)
block|{
name|wait
argument_list|()
expr_stmt|;
if|if
condition|(
name|fatalError
operator|!=
literal|null
condition|)
block|{
name|threadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"serious problem"
argument_list|,
name|fatalError
argument_list|)
throw|;
block|}
block|}
name|threadPool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|threadPool
operator|.
name|awaitTermination
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
name|TimeUnit
operator|.
name|DAYS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"interrupted"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Given a directory, get the list of files and blocks in those files.    * A thread is used for each directory.    */
specifier|static
specifier|final
class|class
name|FileGenerator
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
name|FileGenerator
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|)
block|{
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
block|}
comment|/**      * For each path, get the list of files and blocks that they consist of.      */
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|Iterator
argument_list|<
name|FileStatus
argument_list|>
name|itr
init|=
name|context
operator|.
name|shims
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
while|while
condition|(
name|itr
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FileStatus
name|file
init|=
name|itr
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|file
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|FileInfo
name|fileInfo
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|context
operator|.
name|cacheStripeDetails
condition|)
block|{
name|fileInfo
operator|=
name|verifyCachedFileInfo
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
name|SplitGenerator
name|spgen
init|=
operator|new
name|SplitGenerator
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|file
argument_list|,
name|fileInfo
argument_list|)
decl_stmt|;
name|spgen
operator|.
name|schedule
argument_list|()
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|th
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|th
operator|instanceof
name|IOException
operator|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unexpected Exception"
argument_list|,
name|th
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|context
operator|.
name|errors
init|)
block|{
name|context
operator|.
name|errors
operator|.
name|add
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
name|th
operator|instanceof
name|IOException
operator|)
condition|)
block|{
name|context
operator|.
name|notifyOnNonIOException
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|context
operator|.
name|decrementSchedulers
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|FileInfo
name|verifyCachedFileInfo
parameter_list|(
name|FileStatus
name|file
parameter_list|)
block|{
name|context
operator|.
name|numFilesCounter
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|FileInfo
name|fileInfo
init|=
name|Context
operator|.
name|footerCache
operator|.
name|getIfPresent
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileInfo
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Info cached for path: "
operator|+
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fileInfo
operator|.
name|modificationTime
operator|==
name|file
operator|.
name|getModificationTime
argument_list|()
operator|&&
name|fileInfo
operator|.
name|size
operator|==
name|file
operator|.
name|getLen
argument_list|()
condition|)
block|{
comment|// Cached copy is valid
name|context
operator|.
name|cacheHitCounter
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
return|return
name|fileInfo
return|;
block|}
else|else
block|{
comment|// Invalidate
name|Context
operator|.
name|footerCache
operator|.
name|invalidate
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Meta-Info for : "
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|" changed. CachedModificationTime: "
operator|+
name|fileInfo
operator|.
name|modificationTime
operator|+
literal|", CurrentModificationTime: "
operator|+
name|file
operator|.
name|getModificationTime
argument_list|()
operator|+
literal|", CachedLength: "
operator|+
name|fileInfo
operator|.
name|size
operator|+
literal|", CurrentLength: "
operator|+
name|file
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Info not cached for path: "
operator|+
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Split the stripes of a given file into input splits.    * A thread is used for each file.    */
specifier|static
specifier|final
class|class
name|SplitGenerator
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|FileStatus
name|file
decl_stmt|;
specifier|private
specifier|final
name|long
name|blockSize
decl_stmt|;
specifier|private
specifier|final
name|BlockLocation
index|[]
name|locations
decl_stmt|;
specifier|private
specifier|final
name|FileInfo
name|fileInfo
decl_stmt|;
specifier|private
name|Iterable
argument_list|<
name|StripeInformation
argument_list|>
name|stripes
decl_stmt|;
specifier|private
name|FileMetaInfo
name|fileMetaInfo
decl_stmt|;
specifier|private
name|Metadata
name|metadata
decl_stmt|;
specifier|private
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
decl_stmt|;
name|SplitGenerator
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|file
parameter_list|,
name|FileInfo
name|fileInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|file
operator|=
name|file
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
name|file
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|this
operator|.
name|fileInfo
operator|=
name|fileInfo
expr_stmt|;
name|locations
operator|=
name|context
operator|.
name|shims
operator|.
name|getLocations
argument_list|(
name|fs
argument_list|,
name|file
argument_list|)
expr_stmt|;
block|}
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|file
operator|.
name|getPath
argument_list|()
return|;
block|}
name|void
name|schedule
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|locations
operator|.
name|length
operator|==
literal|1
operator|&&
name|file
operator|.
name|getLen
argument_list|()
operator|<
name|context
operator|.
name|maxSize
condition|)
block|{
name|String
index|[]
name|hosts
init|=
name|locations
index|[
literal|0
index|]
operator|.
name|getHosts
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|context
operator|.
name|splits
init|)
block|{
name|context
operator|.
name|splits
operator|.
name|add
argument_list|(
operator|new
name|Context
operator|.
name|FileSplitInfo
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
literal|0
argument_list|,
name|file
operator|.
name|getLen
argument_list|()
argument_list|,
name|hosts
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// if it requires a compute task
name|context
operator|.
name|schedule
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"splitter("
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|")"
return|;
block|}
comment|/**      * Compute the number of bytes that overlap between the two ranges.      * @param offset1 start of range1      * @param length1 length of range1      * @param offset2 start of range2      * @param length2 length of range2      * @return the number of bytes in the overlap range      */
specifier|static
name|long
name|getOverlap
parameter_list|(
name|long
name|offset1
parameter_list|,
name|long
name|length1
parameter_list|,
name|long
name|offset2
parameter_list|,
name|long
name|length2
parameter_list|)
block|{
name|long
name|end1
init|=
name|offset1
operator|+
name|length1
decl_stmt|;
name|long
name|end2
init|=
name|offset2
operator|+
name|length2
decl_stmt|;
if|if
condition|(
name|end2
operator|<=
name|offset1
operator|||
name|end1
operator|<=
name|offset2
condition|)
block|{
return|return
literal|0
return|;
block|}
else|else
block|{
return|return
name|Math
operator|.
name|min
argument_list|(
name|end1
argument_list|,
name|end2
argument_list|)
operator|-
name|Math
operator|.
name|max
argument_list|(
name|offset1
argument_list|,
name|offset2
argument_list|)
return|;
block|}
block|}
comment|/**      * Create an input split over the given range of bytes. The location of the      * split is based on where the majority of the byte are coming from. ORC      * files are unlikely to have splits that cross between blocks because they      * are written with large block sizes.      * @param offset the start of the split      * @param length the length of the split      * @param fileMetaInfo file metadata from footer and postscript      * @throws IOException      */
name|void
name|createSplit
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|String
index|[]
name|hosts
decl_stmt|;
if|if
condition|(
operator|(
name|offset
operator|%
name|blockSize
operator|)
operator|+
name|length
operator|<=
name|blockSize
condition|)
block|{
comment|// handle the single block case
name|hosts
operator|=
name|locations
index|[
call|(
name|int
call|)
argument_list|(
name|offset
operator|/
name|blockSize
argument_list|)
index|]
operator|.
name|getHosts
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Calculate the number of bytes in the split that are local to each
comment|// host.
name|Map
argument_list|<
name|String
argument_list|,
name|LongWritable
argument_list|>
name|sizes
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LongWritable
argument_list|>
argument_list|()
decl_stmt|;
name|long
name|maxSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|BlockLocation
name|block
range|:
name|locations
control|)
block|{
name|long
name|overlap
init|=
name|getOverlap
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
name|block
operator|.
name|getOffset
argument_list|()
argument_list|,
name|block
operator|.
name|getLength
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|overlap
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|String
name|host
range|:
name|block
operator|.
name|getHosts
argument_list|()
control|)
block|{
name|LongWritable
name|val
init|=
name|sizes
operator|.
name|get
argument_list|(
name|host
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
operator|new
name|LongWritable
argument_list|()
expr_stmt|;
name|sizes
operator|.
name|put
argument_list|(
name|host
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
name|val
operator|.
name|set
argument_list|(
name|val
operator|.
name|get
argument_list|()
operator|+
name|overlap
argument_list|)
expr_stmt|;
name|maxSize
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxSize
argument_list|,
name|val
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// filter the list of locations to those that have at least 80% of the
comment|// max
name|long
name|threshold
init|=
call|(
name|long
call|)
argument_list|(
name|maxSize
operator|*
name|MIN_INCLUDED_LOCATION
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|hostList
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
comment|// build the locations in a predictable order to simplify testing
for|for
control|(
name|BlockLocation
name|block
range|:
name|locations
control|)
block|{
for|for
control|(
name|String
name|host
range|:
name|block
operator|.
name|getHosts
argument_list|()
control|)
block|{
if|if
condition|(
name|sizes
operator|.
name|containsKey
argument_list|(
name|host
argument_list|)
condition|)
block|{
if|if
condition|(
name|sizes
operator|.
name|get
argument_list|(
name|host
argument_list|)
operator|.
name|get
argument_list|()
operator|>=
name|threshold
condition|)
block|{
name|hostList
operator|.
name|add
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
name|sizes
operator|.
name|remove
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|hosts
operator|=
operator|new
name|String
index|[
name|hostList
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|hostList
operator|.
name|toArray
argument_list|(
name|hosts
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|context
operator|.
name|splits
init|)
block|{
name|context
operator|.
name|splits
operator|.
name|add
argument_list|(
operator|new
name|Context
operator|.
name|FileSplitInfo
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|hosts
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Divide the adjacent stripes in the file into input splits based on the      * block size and the configured minimum and maximum sizes.      */
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|populateAndCacheStripeDetails
argument_list|()
expr_stmt|;
name|Configuration
name|conf
init|=
name|context
operator|.
name|conf
decl_stmt|;
name|SearchArgument
name|sarg
init|=
name|createSarg
argument_list|(
name|types
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
init|=
literal|null
decl_stmt|;
name|int
index|[]
name|filterColumns
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|sarg
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|PredicateLeaf
argument_list|>
name|sargLeaves
init|=
literal|null
decl_stmt|;
name|String
index|[]
name|allColumns
init|=
name|conf
operator|.
name|get
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMNS
argument_list|)
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
name|String
index|[]
name|neededColumns
init|=
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_NAMES_CONF_STR
argument_list|)
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
name|sargLeaves
operator|=
name|sarg
operator|.
name|getLeaves
argument_list|()
expr_stmt|;
name|filterColumns
operator|=
operator|new
name|int
index|[
name|sargLeaves
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|filterColumns
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|String
name|colName
init|=
name|sargLeaves
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getColumnName
argument_list|()
decl_stmt|;
comment|// if needed columns does not contain the column specified in filter expression then
comment|// it must be partition column. There will not be columns within ORC file for partitioned
comment|// column, so we can ignore them
if|if
condition|(
name|containsColumn
argument_list|(
name|neededColumns
argument_list|,
name|colName
argument_list|)
condition|)
block|{
name|filterColumns
index|[
name|i
index|]
operator|=
name|RecordReaderImpl
operator|.
name|findColumns
argument_list|(
name|allColumns
argument_list|,
name|colName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|filterColumns
index|[
name|i
index|]
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
name|stripeStats
operator|=
name|metadata
operator|.
name|getStripeStatistics
argument_list|()
expr_stmt|;
block|}
name|long
name|currentOffset
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|currentLength
init|=
literal|0
decl_stmt|;
name|int
name|idx
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|StripeInformation
name|stripe
range|:
name|stripes
control|)
block|{
name|idx
operator|++
expr_stmt|;
comment|// eliminate stripes that doesn't satisfy the predicate condition
if|if
condition|(
name|sarg
operator|!=
literal|null
operator|&&
operator|!
name|isStripeSatisfyPredicate
argument_list|(
name|stripeStats
operator|.
name|get
argument_list|(
name|idx
argument_list|)
argument_list|,
name|sarg
argument_list|,
name|filterColumns
argument_list|)
condition|)
block|{
comment|// if a stripe doesn't satisfy predicate condition then skip it
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Eliminating ORC stripe-"
operator|+
name|idx
operator|+
literal|" of file '"
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|"'  as it did not satisfy predicate condition."
argument_list|)
expr_stmt|;
block|}
comment|// create split for the previous unfinished stripe
if|if
condition|(
name|currentOffset
operator|!=
operator|-
literal|1
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|,
name|fileMetaInfo
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
continue|continue;
block|}
comment|// if we are working on a stripe, over the min stripe size, and
comment|// crossed a block boundary, cut the input split here.
if|if
condition|(
name|currentOffset
operator|!=
operator|-
literal|1
operator|&&
name|currentLength
operator|>
name|context
operator|.
name|minSize
operator|&&
operator|(
name|currentOffset
operator|/
name|blockSize
operator|!=
name|stripe
operator|.
name|getOffset
argument_list|()
operator|/
name|blockSize
operator|)
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|,
name|fileMetaInfo
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// if we aren't building a split, start a new one.
if|if
condition|(
name|currentOffset
operator|==
operator|-
literal|1
condition|)
block|{
name|currentOffset
operator|=
name|stripe
operator|.
name|getOffset
argument_list|()
expr_stmt|;
name|currentLength
operator|=
name|stripe
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|currentLength
operator|+=
name|stripe
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|currentLength
operator|>=
name|context
operator|.
name|maxSize
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|,
name|fileMetaInfo
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
if|if
condition|(
name|currentOffset
operator|!=
operator|-
literal|1
condition|)
block|{
name|createSplit
argument_list|(
name|currentOffset
argument_list|,
name|currentLength
argument_list|,
name|fileMetaInfo
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|th
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|th
operator|instanceof
name|IOException
operator|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unexpected Exception"
argument_list|,
name|th
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|context
operator|.
name|errors
init|)
block|{
name|context
operator|.
name|errors
operator|.
name|add
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
name|th
operator|instanceof
name|IOException
operator|)
condition|)
block|{
name|context
operator|.
name|notifyOnNonIOException
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|context
operator|.
name|decrementSchedulers
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|populateAndCacheStripeDetails
parameter_list|()
block|{
try|try
block|{
name|Reader
name|orcReader
decl_stmt|;
name|boolean
name|found
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|fileInfo
operator|!=
literal|null
condition|)
block|{
name|found
operator|=
literal|true
expr_stmt|;
name|stripes
operator|=
name|fileInfo
operator|.
name|stripeInfos
expr_stmt|;
name|fileMetaInfo
operator|=
name|fileInfo
operator|.
name|fileMetaInfo
expr_stmt|;
name|metadata
operator|=
name|fileInfo
operator|.
name|metadata
expr_stmt|;
name|types
operator|=
name|fileInfo
operator|.
name|types
expr_stmt|;
comment|// For multiple runs, in case sendSplitsInFooter changes
if|if
condition|(
name|fileMetaInfo
operator|==
literal|null
operator|&&
name|context
operator|.
name|footerInSplits
condition|)
block|{
name|orcReader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|fileInfo
operator|.
name|fileMetaInfo
operator|=
name|orcReader
operator|.
name|getFileMetaInfo
argument_list|()
expr_stmt|;
name|fileInfo
operator|.
name|metadata
operator|=
name|orcReader
operator|.
name|getMetadata
argument_list|()
expr_stmt|;
name|fileInfo
operator|.
name|types
operator|=
name|orcReader
operator|.
name|getTypes
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|found
condition|)
block|{
name|orcReader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|stripes
operator|=
name|orcReader
operator|.
name|getStripes
argument_list|()
expr_stmt|;
name|metadata
operator|=
name|orcReader
operator|.
name|getMetadata
argument_list|()
expr_stmt|;
name|types
operator|=
name|orcReader
operator|.
name|getTypes
argument_list|()
expr_stmt|;
name|fileMetaInfo
operator|=
name|context
operator|.
name|footerInSplits
condition|?
name|orcReader
operator|.
name|getFileMetaInfo
argument_list|()
else|:
literal|null
expr_stmt|;
if|if
condition|(
name|context
operator|.
name|cacheStripeDetails
condition|)
block|{
comment|// Populate into cache.
name|Context
operator|.
name|footerCache
operator|.
name|put
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
operator|new
name|FileInfo
argument_list|(
name|file
operator|.
name|getModificationTime
argument_list|()
argument_list|,
name|file
operator|.
name|getLen
argument_list|()
argument_list|,
name|stripes
argument_list|,
name|metadata
argument_list|,
name|types
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|th
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|th
operator|instanceof
name|IOException
operator|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unexpected Exception"
argument_list|,
name|th
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|context
operator|.
name|errors
init|)
block|{
name|context
operator|.
name|errors
operator|.
name|add
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
name|th
operator|instanceof
name|IOException
operator|)
condition|)
block|{
name|context
operator|.
name|notifyOnNonIOException
argument_list|(
name|th
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|boolean
name|containsColumn
parameter_list|(
name|String
index|[]
name|neededColumns
parameter_list|,
name|String
name|colName
parameter_list|)
block|{
for|for
control|(
name|String
name|col
range|:
name|neededColumns
control|)
block|{
if|if
condition|(
name|colName
operator|.
name|equalsIgnoreCase
argument_list|(
name|col
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|boolean
name|isStripeSatisfyPredicate
parameter_list|(
name|StripeStatistics
name|stripeStatistics
parameter_list|,
name|SearchArgument
name|sarg
parameter_list|,
name|int
index|[]
name|filterColumns
parameter_list|)
block|{
if|if
condition|(
name|sarg
operator|!=
literal|null
operator|&&
name|filterColumns
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|PredicateLeaf
argument_list|>
name|predLeaves
init|=
name|sarg
operator|.
name|getLeaves
argument_list|()
decl_stmt|;
name|TruthValue
index|[]
name|truthValues
init|=
operator|new
name|TruthValue
index|[
name|predLeaves
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|pred
init|=
literal|0
init|;
name|pred
operator|<
name|truthValues
operator|.
name|length
condition|;
name|pred
operator|++
control|)
block|{
if|if
condition|(
name|filterColumns
index|[
name|pred
index|]
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// column statistics at index 0 contains only the number of rows
name|ColumnStatistics
name|stats
init|=
name|stripeStatistics
operator|.
name|getColumnStatistics
argument_list|()
index|[
name|filterColumns
index|[
name|pred
index|]
operator|+
literal|1
index|]
decl_stmt|;
name|Object
name|minValue
init|=
name|getMin
argument_list|(
name|stats
argument_list|)
decl_stmt|;
name|Object
name|maxValue
init|=
name|getMax
argument_list|(
name|stats
argument_list|)
decl_stmt|;
name|truthValues
index|[
name|pred
index|]
operator|=
name|RecordReaderImpl
operator|.
name|evaluatePredicateRange
argument_list|(
name|predLeaves
operator|.
name|get
argument_list|(
name|pred
argument_list|)
argument_list|,
name|minValue
argument_list|,
name|maxValue
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// parition column case.
comment|// partition filter will be evaluated by partition pruner so
comment|// we will not evaluate partition filter here.
name|truthValues
index|[
name|pred
index|]
operator|=
name|TruthValue
operator|.
name|YES_NO_NULL
expr_stmt|;
block|}
block|}
return|return
name|sarg
operator|.
name|evaluate
argument_list|(
name|truthValues
argument_list|)
operator|.
name|isNeeded
argument_list|()
return|;
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|Object
name|getMax
parameter_list|(
name|ColumnStatistics
name|index
parameter_list|)
block|{
if|if
condition|(
name|index
operator|instanceof
name|IntegerColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|IntegerColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMaximum
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|index
operator|instanceof
name|DoubleColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|DoubleColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMaximum
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|index
operator|instanceof
name|StringColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|StringColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMaximum
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|index
operator|instanceof
name|DateColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|DateColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMaximum
argument_list|()
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
specifier|private
name|Object
name|getMin
parameter_list|(
name|ColumnStatistics
name|index
parameter_list|)
block|{
if|if
condition|(
name|index
operator|instanceof
name|IntegerColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|IntegerColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMinimum
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|index
operator|instanceof
name|DoubleColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|DoubleColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMinimum
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|index
operator|instanceof
name|StringColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|StringColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMinimum
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|index
operator|instanceof
name|DateColumnStatistics
condition|)
block|{
return|return
operator|(
operator|(
name|DateColumnStatistics
operator|)
name|index
operator|)
operator|.
name|getMinimum
argument_list|()
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
block|}
specifier|static
name|List
argument_list|<
name|Context
operator|.
name|FileSplitInfo
argument_list|>
name|generateSplitsInfo
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// use threads to resolve directories into splits
name|Context
name|context
init|=
operator|new
name|Context
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|dir
range|:
name|getInputPaths
argument_list|(
name|conf
argument_list|)
control|)
block|{
name|FileSystem
name|fs
init|=
name|dir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|context
operator|.
name|schedule
argument_list|(
operator|new
name|FileGenerator
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|context
operator|.
name|waitForTasks
argument_list|()
expr_stmt|;
comment|// deal with exceptions
if|if
condition|(
operator|!
name|context
operator|.
name|errors
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|IOException
argument_list|>
name|errors
init|=
operator|new
name|ArrayList
argument_list|<
name|IOException
argument_list|>
argument_list|(
name|context
operator|.
name|errors
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Throwable
name|th
range|:
name|context
operator|.
name|errors
control|)
block|{
if|if
condition|(
name|th
operator|instanceof
name|IOException
condition|)
block|{
name|errors
operator|.
name|add
argument_list|(
operator|(
name|IOException
operator|)
name|th
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"serious problem"
argument_list|,
name|th
argument_list|)
throw|;
block|}
block|}
throw|throw
operator|new
name|InvalidInputException
argument_list|(
name|errors
argument_list|)
throw|;
block|}
if|if
condition|(
name|context
operator|.
name|cacheStripeDetails
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"FooterCacheHitRatio: "
operator|+
name|context
operator|.
name|cacheHitCounter
operator|.
name|get
argument_list|()
operator|+
literal|"/"
operator|+
name|context
operator|.
name|numFilesCounter
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|context
operator|.
name|splits
return|;
block|}
annotation|@
name|Override
specifier|public
name|InputSplit
index|[]
name|getSplits
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|int
name|numSplits
parameter_list|)
throws|throws
name|IOException
block|{
name|perfLogger
operator|.
name|PerfLogBegin
argument_list|(
name|CLASS_NAME
argument_list|,
name|PerfLogger
operator|.
name|ORC_GET_SPLITS
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|OrcInputFormat
operator|.
name|Context
operator|.
name|FileSplitInfo
argument_list|>
name|splits
init|=
name|OrcInputFormat
operator|.
name|generateSplitsInfo
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|InputSplit
index|[]
name|result
init|=
operator|new
name|InputSplit
index|[
name|splits
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|splits
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|OrcInputFormat
operator|.
name|Context
operator|.
name|FileSplitInfo
name|split
init|=
name|splits
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|result
index|[
name|i
index|]
operator|=
operator|new
name|OrcSplit
argument_list|(
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|split
operator|.
name|getStart
argument_list|()
argument_list|,
name|split
operator|.
name|getLength
argument_list|()
argument_list|,
name|split
operator|.
name|getLocations
argument_list|()
argument_list|,
name|split
operator|.
name|getFileMetaInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|perfLogger
operator|.
name|PerfLogEnd
argument_list|(
name|CLASS_NAME
argument_list|,
name|PerfLogger
operator|.
name|ORC_GET_SPLITS
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**    * FileInfo.    *    * Stores information relevant to split generation for an ORC File.    *    */
specifier|private
specifier|static
class|class
name|FileInfo
block|{
name|long
name|modificationTime
decl_stmt|;
name|long
name|size
decl_stmt|;
name|Iterable
argument_list|<
name|StripeInformation
argument_list|>
name|stripeInfos
decl_stmt|;
name|FileMetaInfo
name|fileMetaInfo
decl_stmt|;
name|Metadata
name|metadata
decl_stmt|;
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
decl_stmt|;
name|FileInfo
parameter_list|(
name|long
name|modificationTime
parameter_list|,
name|long
name|size
parameter_list|,
name|Iterable
argument_list|<
name|StripeInformation
argument_list|>
name|stripeInfos
parameter_list|,
name|Metadata
name|metadata
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|)
block|{
name|this
operator|.
name|modificationTime
operator|=
name|modificationTime
expr_stmt|;
name|this
operator|.
name|size
operator|=
name|size
expr_stmt|;
name|this
operator|.
name|stripeInfos
operator|=
name|stripeInfos
expr_stmt|;
name|this
operator|.
name|fileMetaInfo
operator|=
name|fileMetaInfo
expr_stmt|;
name|this
operator|.
name|metadata
operator|=
name|metadata
expr_stmt|;
name|this
operator|.
name|types
operator|=
name|types
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

