begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|InStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedExceptionAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorCompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|IOConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|BaseCharTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|DecimalTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|ListTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|MapTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|PrimitiveTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|StructTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|UnionTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|ColumnStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|FileMetaInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|StripeInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|StripeStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|TypeDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|BlockLocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidReadTxnList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidTxnList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Metastore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Metastore
operator|.
name|SplitInfos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|VectorizedInputFormatInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
operator|.
name|Directory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|CombineHiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|InputFormatChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|LlapWrappableInputFormatInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|RecordIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|SelfDescribingInputFormatInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|StatsProvidingRecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|ExternalCache
operator|.
name|ExternalFooterCachesByConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|SyntheticFileId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|ConvertAstToSearchArg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|PredicateLeaf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|SearchArgument
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|SearchArgument
operator|.
name|TruthValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|VirtualColumn
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|ColumnProjectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
operator|.
name|HdfsFileStatusWithId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|CodedInputStream
import|;
end_import

begin_comment
comment|/**  * A MapReduce/Hive input format for ORC files.  *<p>  * This class implements both the classic InputFormat, which stores the rows  * directly, and AcidInputFormat, which stores a series of events with the  * following schema:  *<pre>  *   class AcidEvent&lt;ROW&gt; {  *     enum ACTION {INSERT, UPDATE, DELETE}  *     ACTION operation;  *     long originalTransaction;  *     int bucket;  *     long rowId;  *     long currentTransaction;  *     ROW row;  *   }  *</pre>  * Each AcidEvent object corresponds to an update event. The  * originalTransaction, bucket, and rowId are the unique identifier for the row.  * The operation and currentTransaction are the operation and the transaction  * that added this event. Insert and update events include the entire row, while  * delete events have null for row.  */
end_comment

begin_class
specifier|public
class|class
name|OrcInputFormat
implements|implements
name|InputFormat
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
implements|,
name|InputFormatChecker
implements|,
name|VectorizedInputFormatInterface
implements|,
name|LlapWrappableInputFormatInterface
implements|,
name|SelfDescribingInputFormatInterface
implements|,
name|AcidInputFormat
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
implements|,
name|CombineHiveInputFormat
operator|.
name|AvoidSplitCombination
block|{
specifier|static
enum|enum
name|SplitStrategyKind
block|{
name|HYBRID
block|,
name|BI
block|,
name|ETL
block|}
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|OrcInputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
name|boolean
name|isDebugEnabled
init|=
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
decl_stmt|;
specifier|static
specifier|final
name|HadoopShims
name|SHIMS
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MIN_SPLIT_SIZE
init|=
literal|16
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MAX_SPLIT_SIZE
init|=
literal|256
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
comment|/**    * When picking the hosts for a split that crosses block boundaries,    * drop any host that has fewer than MIN_INCLUDED_LOCATION of the    * number of bytes available on the host with the most.    * If host1 has 10MB of the split, host2 has 20MB, and host3 has 18MB the    * split will contain host2 (100% of host2) and host3 (90% of host2). Host1    * with 50% will be dropped.    */
specifier|private
specifier|static
specifier|final
name|double
name|MIN_INCLUDED_LOCATION
init|=
literal|0.80
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|shouldSkipCombine
parameter_list|(
name|Path
name|path
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|(
name|conf
operator|.
name|get
argument_list|(
name|AcidUtils
operator|.
name|CONF_ACID_KEY
argument_list|)
operator|!=
literal|null
operator|)
operator|||
name|AcidUtils
operator|.
name|isAcid
argument_list|(
name|path
argument_list|,
name|conf
argument_list|)
return|;
block|}
comment|/**    * We can derive if a split is ACID or not from the flags encoded in OrcSplit.    * If the file split is not instance of OrcSplit then its definitely not ACID.    * If file split is instance of OrcSplit and the flags contain hasBase or deltas then it's    * definitely ACID.    * Else fallback to configuration object/table property.    * @param conf    * @param inputSplit    * @return    */
specifier|public
name|boolean
name|isAcidRead
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|InputSplit
name|inputSplit
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|inputSplit
operator|instanceof
name|OrcSplit
operator|)
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|/*      * If OrcSplit.isAcid returns true, we know for sure it is ACID.      */
comment|// if (((OrcSplit) inputSplit).isAcid()) {
comment|//   return true;
comment|// }
comment|/*      * Fallback for the case when OrcSplit flags do not contain hasBase and deltas      */
return|return
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
argument_list|)
return|;
block|}
specifier|private
specifier|static
class|class
name|OrcRecordReader
implements|implements
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
implements|,
name|StatsProvidingRecordReader
block|{
specifier|private
specifier|final
name|RecordReader
name|reader
decl_stmt|;
specifier|private
specifier|final
name|long
name|offset
decl_stmt|;
specifier|private
specifier|final
name|long
name|length
decl_stmt|;
specifier|private
specifier|final
name|int
name|numColumns
decl_stmt|;
specifier|private
name|float
name|progress
init|=
literal|0.0f
decl_stmt|;
specifier|private
specifier|final
name|Reader
name|file
decl_stmt|;
specifier|private
specifier|final
name|SerDeStats
name|stats
decl_stmt|;
name|OrcRecordReader
parameter_list|(
name|Reader
name|file
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|FileSplit
name|split
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
init|=
name|file
operator|.
name|getTypes
argument_list|()
decl_stmt|;
name|this
operator|.
name|file
operator|=
name|file
expr_stmt|;
name|numColumns
operator|=
operator|(
name|types
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|types
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getSubtypesCount
argument_list|()
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|split
operator|.
name|getStart
argument_list|()
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|split
operator|.
name|getLength
argument_list|()
expr_stmt|;
name|this
operator|.
name|reader
operator|=
name|createReaderFromFile
argument_list|(
name|file
argument_list|,
name|conf
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
expr_stmt|;
name|this
operator|.
name|stats
operator|=
operator|new
name|SerDeStats
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|NullWritable
name|key
parameter_list|,
name|OrcStruct
name|value
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|reader
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|reader
operator|.
name|next
argument_list|(
name|value
argument_list|)
expr_stmt|;
name|progress
operator|=
name|reader
operator|.
name|getProgress
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|NullWritable
name|createKey
parameter_list|()
block|{
return|return
name|NullWritable
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OrcStruct
name|createValue
parameter_list|()
block|{
return|return
operator|new
name|OrcStruct
argument_list|(
name|numColumns
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|offset
operator|+
call|(
name|long
call|)
argument_list|(
name|progress
operator|*
name|length
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|progress
return|;
block|}
annotation|@
name|Override
specifier|public
name|SerDeStats
name|getStats
parameter_list|()
block|{
name|stats
operator|.
name|setRawDataSize
argument_list|(
name|file
operator|.
name|getRawDataSize
argument_list|()
argument_list|)
expr_stmt|;
name|stats
operator|.
name|setRowCount
argument_list|(
name|file
operator|.
name|getNumberOfRows
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|stats
return|;
block|}
block|}
comment|/**    * Get the root column for the row. In ACID format files, it is offset by    * the extra metadata columns.    * @param isOriginal is the file in the original format?    * @return the column number for the root of row.    */
specifier|static
name|int
name|getRootColumn
parameter_list|(
name|boolean
name|isOriginal
parameter_list|)
block|{
return|return
name|isOriginal
condition|?
literal|0
else|:
operator|(
name|OrcRecordUpdater
operator|.
name|ROW
operator|+
literal|1
operator|)
return|;
block|}
specifier|public
specifier|static
name|void
name|raiseAcidTablesMustBeReadWithAcidReaderException
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|hiveInputFormat
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVEINPUTFORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|hiveInputFormat
operator|.
name|equals
argument_list|(
name|HiveInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|ACID_TABLES_MUST_BE_READ_WITH_ACID_READER
operator|.
name|getErrorCodedMsg
argument_list|()
argument_list|)
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|ACID_TABLES_MUST_BE_READ_WITH_HIVEINPUTFORMAT
operator|.
name|getErrorCodedMsg
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|RecordReader
name|createReaderFromFile
parameter_list|(
name|Reader
name|file
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|isTransactionalTableScan
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTransactionalTableScan
condition|)
block|{
name|raiseAcidTablesMustBeReadWithAcidReaderException
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**      * Do we have schema on read in the configuration variables?      */
name|TypeDescription
name|schema
init|=
name|getDesiredRowTypeDescr
argument_list|(
name|conf
argument_list|,
comment|/* isAcidRead */
literal|false
argument_list|)
decl_stmt|;
name|Reader
operator|.
name|Options
name|options
init|=
operator|new
name|Reader
operator|.
name|Options
argument_list|()
operator|.
name|range
argument_list|(
name|offset
argument_list|,
name|length
argument_list|)
decl_stmt|;
name|options
operator|.
name|schema
argument_list|(
name|schema
argument_list|)
expr_stmt|;
name|boolean
name|isOriginal
init|=
name|isOriginal
argument_list|(
name|file
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
init|=
name|file
operator|.
name|getTypes
argument_list|()
decl_stmt|;
name|options
operator|.
name|include
argument_list|(
name|genIncludedColumns
argument_list|(
name|types
argument_list|,
name|conf
argument_list|,
name|isOriginal
argument_list|)
argument_list|)
expr_stmt|;
name|setSearchArgument
argument_list|(
name|options
argument_list|,
name|types
argument_list|,
name|conf
argument_list|,
name|isOriginal
argument_list|)
expr_stmt|;
return|return
operator|(
name|RecordReader
operator|)
name|file
operator|.
name|rowsOptions
argument_list|(
name|options
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isOriginal
parameter_list|(
name|Reader
name|file
parameter_list|)
block|{
return|return
operator|!
name|file
operator|.
name|hasMetadataValue
argument_list|(
name|OrcRecordUpdater
operator|.
name|ACID_KEY_INDEX_NAME
argument_list|)
return|;
block|}
comment|/**    * Recurse down into a type subtree turning on all of the sub-columns.    * @param types the types of the file    * @param result the global view of columns that should be included    * @param typeId the root of tree to enable    * @param rootColumn the top column    */
specifier|private
specifier|static
name|void
name|includeColumnRecursive
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|boolean
index|[]
name|result
parameter_list|,
name|int
name|typeId
parameter_list|,
name|int
name|rootColumn
parameter_list|)
block|{
name|result
index|[
name|typeId
operator|-
name|rootColumn
index|]
operator|=
literal|true
expr_stmt|;
name|OrcProto
operator|.
name|Type
name|type
init|=
name|types
operator|.
name|get
argument_list|(
name|typeId
argument_list|)
decl_stmt|;
name|int
name|children
init|=
name|type
operator|.
name|getSubtypesCount
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|children
condition|;
operator|++
name|i
control|)
block|{
name|includeColumnRecursive
argument_list|(
name|types
argument_list|,
name|result
argument_list|,
name|type
operator|.
name|getSubtypes
argument_list|(
name|i
argument_list|)
argument_list|,
name|rootColumn
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|boolean
index|[]
name|genIncludedColumns
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|included
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
name|int
name|rootColumn
init|=
name|getRootColumn
argument_list|(
name|isOriginal
argument_list|)
decl_stmt|;
name|int
name|numColumns
init|=
name|types
operator|.
name|size
argument_list|()
operator|-
name|rootColumn
decl_stmt|;
name|boolean
index|[]
name|result
init|=
operator|new
name|boolean
index|[
name|numColumns
index|]
decl_stmt|;
name|result
index|[
literal|0
index|]
operator|=
literal|true
expr_stmt|;
name|OrcProto
operator|.
name|Type
name|root
init|=
name|types
operator|.
name|get
argument_list|(
name|rootColumn
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|root
operator|.
name|getSubtypesCount
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|included
operator|.
name|contains
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|includeColumnRecursive
argument_list|(
name|types
argument_list|,
name|result
argument_list|,
name|root
operator|.
name|getSubtypes
argument_list|(
name|i
argument_list|)
argument_list|,
name|rootColumn
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Take the configuration and figure out which columns we need to include.    * @param types the types for the file    * @param conf the configuration    * @param isOriginal is the file in the original format?    */
specifier|public
specifier|static
name|boolean
index|[]
name|genIncludedColumns
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ColumnProjectionUtils
operator|.
name|isReadAllColumns
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|List
argument_list|<
name|Integer
argument_list|>
name|included
init|=
name|ColumnProjectionUtils
operator|.
name|getReadColumnIDs
argument_list|(
name|conf
argument_list|)
decl_stmt|;
return|return
name|genIncludedColumns
argument_list|(
name|types
argument_list|,
name|included
argument_list|,
name|isOriginal
argument_list|)
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
specifier|public
specifier|static
name|String
index|[]
name|getSargColumnNames
parameter_list|(
name|String
index|[]
name|originalColumnNames
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|boolean
index|[]
name|includedColumns
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
name|int
name|rootColumn
init|=
name|getRootColumn
argument_list|(
name|isOriginal
argument_list|)
decl_stmt|;
name|String
index|[]
name|columnNames
init|=
operator|new
name|String
index|[
name|types
operator|.
name|size
argument_list|()
operator|-
name|rootColumn
index|]
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
comment|// The way this works is as such. originalColumnNames is the equivalent on getNeededColumns
comment|// from TSOP. They are assumed to be in the same order as the columns in ORC file, AND they are
comment|// assumed to be equivalent to the columns in includedColumns (because it was generated from
comment|// the same column list at some point in the past), minus the subtype columns. Therefore, when
comment|// we go thru all the top level ORC file columns that are included, in order, they match
comment|// originalColumnNames. This way, we do not depend on names stored inside ORC for SARG leaf
comment|// column name resolution (see mapSargColumns method).
for|for
control|(
name|int
name|columnId
range|:
name|types
operator|.
name|get
argument_list|(
name|rootColumn
argument_list|)
operator|.
name|getSubtypesList
argument_list|()
control|)
block|{
if|if
condition|(
name|includedColumns
operator|==
literal|null
operator|||
name|includedColumns
index|[
name|columnId
operator|-
name|rootColumn
index|]
condition|)
block|{
comment|// this is guaranteed to be positive because types only have children
comment|// ids greater than their own id.
name|columnNames
index|[
name|columnId
operator|-
name|rootColumn
index|]
operator|=
name|originalColumnNames
index|[
name|i
operator|++
index|]
expr_stmt|;
block|}
block|}
return|return
name|columnNames
return|;
block|}
specifier|static
name|void
name|setSearchArgument
parameter_list|(
name|Reader
operator|.
name|Options
name|options
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
name|String
name|neededColumnNames
init|=
name|getNeededColumnNamesString
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|neededColumnNames
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No ORC pushdown predicate - no column names"
argument_list|)
expr_stmt|;
name|options
operator|.
name|searchArgument
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return;
block|}
name|SearchArgument
name|sarg
init|=
name|ConvertAstToSearchArg
operator|.
name|createFromConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|sarg
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No ORC pushdown predicate"
argument_list|)
expr_stmt|;
name|options
operator|.
name|searchArgument
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"ORC pushdown predicate: "
operator|+
name|sarg
argument_list|)
expr_stmt|;
block|}
name|options
operator|.
name|searchArgument
argument_list|(
name|sarg
argument_list|,
name|getSargColumnNames
argument_list|(
name|neededColumnNames
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|,
name|types
argument_list|,
name|options
operator|.
name|getInclude
argument_list|()
argument_list|,
name|isOriginal
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|static
name|boolean
name|canCreateSargFromConf
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|getNeededColumnNamesString
argument_list|(
name|conf
argument_list|)
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No ORC pushdown predicate - no column names"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
operator|!
name|ConvertAstToSearchArg
operator|.
name|canCreateFromConf
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No ORC pushdown predicate"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
specifier|private
specifier|static
name|String
index|[]
name|extractNeededColNames
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
index|[]
name|include
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
name|String
name|colNames
init|=
name|getNeededColumnNamesString
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|colNames
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|extractNeededColNames
argument_list|(
name|types
argument_list|,
name|colNames
argument_list|,
name|include
argument_list|,
name|isOriginal
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
index|[]
name|extractNeededColNames
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|String
name|columnNamesString
parameter_list|,
name|boolean
index|[]
name|include
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
return|return
name|getSargColumnNames
argument_list|(
name|columnNamesString
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|,
name|types
argument_list|,
name|include
argument_list|,
name|isOriginal
argument_list|)
return|;
block|}
specifier|static
name|String
name|getNeededColumnNamesString
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_NAMES_CONF_STR
argument_list|)
return|;
block|}
specifier|static
name|String
name|getSargColumnIDsString
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getBoolean
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_ALL_COLUMNS
argument_list|,
literal|true
argument_list|)
condition|?
literal|null
else|:
name|conf
operator|.
name|get
argument_list|(
name|ColumnProjectionUtils
operator|.
name|READ_COLUMN_IDS_CONF_STR
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|validateInput
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|List
argument_list|<
name|FileStatus
argument_list|>
name|files
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|Utilities
operator|.
name|isVectorMode
argument_list|(
name|conf
argument_list|)
condition|)
block|{
return|return
operator|new
name|VectorizedOrcInputFormat
argument_list|()
operator|.
name|validateInput
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|files
argument_list|)
return|;
block|}
if|if
condition|(
name|files
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
comment|// 0 length files cannot be ORC files
if|if
condition|(
name|file
operator|.
name|getLen
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
try|try
block|{
name|OrcFile
operator|.
name|createReader
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|conf
argument_list|)
operator|.
name|filesystem
argument_list|(
name|fs
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Get the list of input {@link Path}s for the map-reduce job.    *    * @param conf The configuration of the job    * @return the list of input {@link Path}s for the map-reduce job.    */
specifier|static
name|Path
index|[]
name|getInputPaths
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|dirs
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"mapred.input.dir"
argument_list|)
decl_stmt|;
if|if
condition|(
name|dirs
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Configuration mapred.input.dir is not defined."
argument_list|)
throw|;
block|}
name|String
index|[]
name|list
init|=
name|StringUtils
operator|.
name|split
argument_list|(
name|dirs
argument_list|)
decl_stmt|;
name|Path
index|[]
name|result
init|=
operator|new
name|Path
index|[
name|list
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|list
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
operator|new
name|Path
argument_list|(
name|StringUtils
operator|.
name|unEscapeString
argument_list|(
name|list
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * The global information about the split generation that we pass around to    * the different worker threads.    */
specifier|static
class|class
name|Context
block|{
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
comment|// We store all caches in variables to change the main one based on config.
comment|// This is not thread safe between different split generations (and wasn't anyway).
specifier|private
name|FooterCache
name|footerCache
decl_stmt|;
specifier|private
specifier|static
name|LocalCache
name|localCache
decl_stmt|;
specifier|private
specifier|static
name|ExternalCache
name|metaCache
decl_stmt|;
specifier|static
name|ExecutorService
name|threadPool
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|int
name|numBuckets
decl_stmt|;
specifier|private
specifier|final
name|int
name|splitStrategyBatchMs
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxSize
decl_stmt|;
specifier|private
specifier|final
name|long
name|minSize
decl_stmt|;
specifier|private
specifier|final
name|int
name|minSplits
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|footerInSplits
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|cacheStripeDetails
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|forceThreadpool
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|cacheHitCounter
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|numFilesCounter
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|ValidTxnList
name|transactionList
decl_stmt|;
specifier|private
name|SplitStrategyKind
name|splitStrategyKind
decl_stmt|;
specifier|private
specifier|final
name|SearchArgument
name|sarg
decl_stmt|;
name|Context
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|this
argument_list|(
name|conf
argument_list|,
literal|1
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|Context
parameter_list|(
name|Configuration
name|conf
parameter_list|,
specifier|final
name|int
name|minSplits
parameter_list|)
block|{
name|this
argument_list|(
name|conf
argument_list|,
name|minSplits
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
name|Context
parameter_list|(
name|Configuration
name|conf
parameter_list|,
specifier|final
name|int
name|minSplits
parameter_list|,
name|ExternalFooterCachesByConf
name|efc
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|forceThreadpool
operator|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_IN_TEST
argument_list|)
expr_stmt|;
name|this
operator|.
name|sarg
operator|=
name|ConvertAstToSearchArg
operator|.
name|createFromConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|minSize
operator|=
name|HiveConf
operator|.
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZE
argument_list|,
name|DEFAULT_MIN_SPLIT_SIZE
argument_list|)
expr_stmt|;
name|maxSize
operator|=
name|HiveConf
operator|.
name|getLongVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|MAPREDMAXSPLITSIZE
argument_list|,
name|DEFAULT_MAX_SPLIT_SIZE
argument_list|)
expr_stmt|;
name|String
name|ss
init|=
name|conf
operator|.
name|get
argument_list|(
name|ConfVars
operator|.
name|HIVE_ORC_SPLIT_STRATEGY
operator|.
name|varname
argument_list|)
decl_stmt|;
if|if
condition|(
name|ss
operator|==
literal|null
operator|||
name|ss
operator|.
name|equals
argument_list|(
name|SplitStrategyKind
operator|.
name|HYBRID
operator|.
name|name
argument_list|()
argument_list|)
condition|)
block|{
name|splitStrategyKind
operator|=
name|SplitStrategyKind
operator|.
name|HYBRID
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Enforcing "
operator|+
name|ss
operator|+
literal|" ORC split strategy"
argument_list|)
expr_stmt|;
name|splitStrategyKind
operator|=
name|SplitStrategyKind
operator|.
name|valueOf
argument_list|(
name|ss
argument_list|)
expr_stmt|;
block|}
name|footerInSplits
operator|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_INCLUDE_FILE_FOOTER_IN_SPLITS
argument_list|)
expr_stmt|;
name|numBuckets
operator|=
name|Math
operator|.
name|max
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
literal|0
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|splitStrategyBatchMs
operator|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_SPLIT_DIRECTORY_BATCH_MS
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Number of buckets specified by conf file is "
operator|+
name|numBuckets
argument_list|)
expr_stmt|;
name|int
name|cacheStripeDetailsSize
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_CACHE_STRIPE_DETAILS_SIZE
argument_list|)
decl_stmt|;
name|int
name|numThreads
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_COMPUTE_SPLITS_NUM_THREADS
argument_list|)
decl_stmt|;
name|cacheStripeDetails
operator|=
operator|(
name|cacheStripeDetailsSize
operator|>
literal|0
operator|)
expr_stmt|;
name|this
operator|.
name|minSplits
operator|=
name|Math
operator|.
name|min
argument_list|(
name|cacheStripeDetailsSize
argument_list|,
name|minSplits
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|Context
operator|.
name|class
init|)
block|{
if|if
condition|(
name|threadPool
operator|==
literal|null
condition|)
block|{
name|threadPool
operator|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|numThreads
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"ORC_GET_SPLITS #%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// TODO: local cache is created once, so the configs for future queries will not be honored.
if|if
condition|(
name|cacheStripeDetails
condition|)
block|{
comment|// Note that there's no FS check here; we implicitly only use metastore cache for
comment|// HDFS, because only HDFS would return fileIds for us. If fileId is extended using
comment|// size/mod time/etc. for other FSes, we might need to check FSes explicitly because
comment|// using such an aggregate fileId cache is not bulletproof and should be disable-able.
name|boolean
name|useExternalCache
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_ORC_MS_FOOTER_CACHE_ENABLED
argument_list|)
decl_stmt|;
if|if
condition|(
name|localCache
operator|==
literal|null
condition|)
block|{
name|localCache
operator|=
operator|new
name|LocalCache
argument_list|(
name|numThreads
argument_list|,
name|cacheStripeDetailsSize
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|useExternalCache
condition|)
block|{
if|if
condition|(
name|metaCache
operator|==
literal|null
condition|)
block|{
name|metaCache
operator|=
operator|new
name|ExternalCache
argument_list|(
name|localCache
argument_list|,
name|efc
operator|==
literal|null
condition|?
operator|new
name|MetastoreExternalCachesByConf
argument_list|()
else|:
name|efc
argument_list|)
expr_stmt|;
block|}
assert|assert
name|conf
operator|instanceof
name|HiveConf
assert|;
name|metaCache
operator|.
name|configure
argument_list|(
operator|(
name|HiveConf
operator|)
name|conf
argument_list|)
expr_stmt|;
block|}
comment|// Set footer cache for current split generation. See field comment - not thread safe.
comment|// TODO: we should be able to enable caches separately
name|footerCache
operator|=
name|useExternalCache
condition|?
name|metaCache
else|:
name|localCache
expr_stmt|;
block|}
block|}
name|String
name|value
init|=
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|,
name|Long
operator|.
name|MAX_VALUE
operator|+
literal|":"
argument_list|)
decl_stmt|;
name|transactionList
operator|=
operator|new
name|ValidReadTxnList
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
specifier|static
name|int
name|getCurrentThreadPoolSize
parameter_list|()
block|{
synchronized|synchronized
init|(
name|Context
operator|.
name|class
init|)
block|{
return|return
operator|(
name|threadPool
operator|instanceof
name|ThreadPoolExecutor
operator|)
condition|?
operator|(
operator|(
name|ThreadPoolExecutor
operator|)
name|threadPool
operator|)
operator|.
name|getPoolSize
argument_list|()
else|:
operator|(
operator|(
name|threadPool
operator|==
literal|null
operator|)
condition|?
literal|0
else|:
operator|-
literal|1
operator|)
return|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|void
name|resetThreadPool
parameter_list|()
block|{
synchronized|synchronized
init|(
name|Context
operator|.
name|class
init|)
block|{
name|threadPool
operator|=
literal|null
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|void
name|clearLocalCache
parameter_list|()
block|{
if|if
condition|(
name|localCache
operator|==
literal|null
condition|)
return|return;
name|localCache
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * The full ACID directory information needed for splits; no more calls to HDFS needed.    * We could just live with AcidUtils.Directory but...    * 1) That doesn't have base files for the base-directory case.    * 2) We save fs for convenience to avoid getting it twice.    */
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
class|class
name|AcidDirInfo
block|{
specifier|public
name|AcidDirInfo
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|splitPath
parameter_list|,
name|Directory
name|acidInfo
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|baseOrOriginalFiles
parameter_list|)
block|{
name|this
operator|.
name|splitPath
operator|=
name|splitPath
expr_stmt|;
name|this
operator|.
name|acidInfo
operator|=
name|acidInfo
expr_stmt|;
name|this
operator|.
name|baseOrOriginalFiles
operator|=
name|baseOrOriginalFiles
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|final
name|Path
name|splitPath
decl_stmt|;
specifier|final
name|AcidUtils
operator|.
name|Directory
name|acidInfo
decl_stmt|;
specifier|final
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|baseOrOriginalFiles
decl_stmt|;
block|}
annotation|@
name|VisibleForTesting
interface|interface
name|SplitStrategy
parameter_list|<
name|T
parameter_list|>
block|{
name|List
argument_list|<
name|T
argument_list|>
name|getSplits
parameter_list|()
throws|throws
name|IOException
function_decl|;
block|}
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
class|class
name|SplitInfo
extends|extends
name|ACIDSplitStrategy
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|HdfsFileStatusWithId
name|fileWithId
decl_stmt|;
specifier|private
specifier|final
name|FileInfo
name|fileInfo
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isOriginal
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|hasBase
decl_stmt|;
specifier|private
specifier|final
name|ByteBuffer
name|ppdResult
decl_stmt|;
name|SplitInfo
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|HdfsFileStatusWithId
name|fileWithId
parameter_list|,
name|FileInfo
name|fileInfo
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|boolean
name|hasBase
parameter_list|,
name|Path
name|dir
parameter_list|,
name|boolean
index|[]
name|covered
parameter_list|,
name|ByteBuffer
name|ppdResult
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|dir
argument_list|,
name|context
operator|.
name|numBuckets
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|)
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|fileWithId
operator|=
name|fileWithId
expr_stmt|;
name|this
operator|.
name|fileInfo
operator|=
name|fileInfo
expr_stmt|;
name|this
operator|.
name|isOriginal
operator|=
name|isOriginal
expr_stmt|;
name|this
operator|.
name|deltas
operator|=
name|deltas
expr_stmt|;
name|this
operator|.
name|hasBase
operator|=
name|hasBase
expr_stmt|;
name|this
operator|.
name|ppdResult
operator|=
name|ppdResult
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|SplitInfo
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|fileStatus
parameter_list|,
name|FileInfo
name|fileInfo
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|ArrayList
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|boolean
name|hasBase
parameter_list|,
name|Path
name|dir
parameter_list|,
name|boolean
index|[]
name|covered
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|AcidUtils
operator|.
name|createOriginalObj
argument_list|(
literal|null
argument_list|,
name|fileStatus
argument_list|)
argument_list|,
name|fileInfo
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|hasBase
argument_list|,
name|dir
argument_list|,
name|covered
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * ETL strategy is used when spending little more time in split generation is acceptable    * (split generation reads and caches file footers).    */
specifier|static
specifier|final
class|class
name|ETLSplitStrategy
implements|implements
name|SplitStrategy
argument_list|<
name|SplitInfo
argument_list|>
implements|,
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|int
name|ETL_COMBINE_FILE_LIMIT
init|=
literal|500
decl_stmt|;
specifier|private
specifier|static
class|class
name|ETLDir
block|{
specifier|public
name|ETLDir
parameter_list|(
name|Path
name|dir
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|int
name|fileCount
parameter_list|)
block|{
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|fileCount
operator|=
name|fileCount
expr_stmt|;
block|}
specifier|private
specifier|final
name|int
name|fileCount
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
block|}
name|Context
name|context
decl_stmt|;
specifier|final
name|List
argument_list|<
name|ETLDir
argument_list|>
name|dirs
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|files
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
decl_stmt|;
specifier|private
specifier|final
name|boolean
index|[]
name|covered
decl_stmt|;
specifier|final
name|boolean
name|isOriginal
decl_stmt|;
comment|// References to external fields for async SplitInfo generation.
specifier|private
name|List
argument_list|<
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|>
name|splitFuturesRef
init|=
literal|null
decl_stmt|;
specifier|private
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splitsRef
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|UserGroupInformation
name|ugi
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|allowSyntheticFileIds
decl_stmt|;
specifier|public
name|ETLSplitStrategy
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|children
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|boolean
index|[]
name|covered
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|,
name|boolean
name|allowSyntheticFileIds
parameter_list|)
block|{
assert|assert
operator|!
name|children
operator|.
name|isEmpty
argument_list|()
assert|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|dirs
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
operator|new
name|ETLDir
argument_list|(
name|dir
argument_list|,
name|fs
argument_list|,
name|children
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|files
operator|=
name|children
expr_stmt|;
name|this
operator|.
name|isOriginal
operator|=
name|isOriginal
expr_stmt|;
name|this
operator|.
name|deltas
operator|=
name|deltas
expr_stmt|;
name|this
operator|.
name|covered
operator|=
name|covered
expr_stmt|;
name|this
operator|.
name|ugi
operator|=
name|ugi
expr_stmt|;
name|this
operator|.
name|allowSyntheticFileIds
operator|=
name|allowSyntheticFileIds
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|SplitInfo
argument_list|>
name|getSplits
parameter_list|()
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|SplitInfo
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|files
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Force local cache if we have deltas.
name|FooterCache
name|cache
init|=
name|context
operator|.
name|cacheStripeDetails
condition|?
operator|(
operator|(
name|deltas
operator|==
literal|null
operator|||
name|deltas
operator|.
name|isEmpty
argument_list|()
operator|)
condition|?
name|context
operator|.
name|footerCache
else|:
name|Context
operator|.
name|localCache
operator|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|cache
operator|!=
literal|null
condition|)
block|{
name|FileInfo
index|[]
name|infos
init|=
operator|new
name|FileInfo
index|[
name|files
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|ByteBuffer
index|[]
name|ppdResults
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|cache
operator|.
name|hasPpd
argument_list|()
condition|)
block|{
name|ppdResults
operator|=
operator|new
name|ByteBuffer
index|[
name|files
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
block|}
try|try
block|{
name|cache
operator|.
name|getAndValidate
argument_list|(
name|files
argument_list|,
name|isOriginal
argument_list|,
name|infos
argument_list|,
name|ppdResults
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|int
name|dirIx
init|=
operator|-
literal|1
decl_stmt|,
name|fileInDirIx
init|=
operator|-
literal|1
decl_stmt|,
name|filesInDirCount
init|=
literal|0
decl_stmt|;
name|ETLDir
name|dir
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|files
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
operator|(
operator|++
name|fileInDirIx
operator|)
operator|==
name|filesInDirCount
condition|)
block|{
name|dir
operator|=
name|dirs
operator|.
name|get
argument_list|(
operator|++
name|dirIx
argument_list|)
expr_stmt|;
name|filesInDirCount
operator|=
name|dir
operator|.
name|fileCount
expr_stmt|;
block|}
name|FileInfo
name|info
init|=
name|infos
index|[
name|i
index|]
decl_stmt|;
name|ByteBuffer
name|ppdResult
init|=
name|ppdResults
operator|==
literal|null
condition|?
literal|null
else|:
name|ppdResults
index|[
name|i
index|]
decl_stmt|;
name|HdfsFileStatusWithId
name|file
init|=
name|files
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|info
operator|!=
literal|null
condition|)
block|{
comment|// Cached copy is valid
name|context
operator|.
name|cacheHitCounter
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|// Ignore files eliminated by PPD, or of 0 length.
if|if
condition|(
name|ppdResult
operator|!=
name|FooterCache
operator|.
name|NO_SPLIT_AFTER_PPD
operator|&&
name|file
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
operator|new
name|SplitInfo
argument_list|(
name|context
argument_list|,
name|dir
operator|.
name|fs
argument_list|,
name|file
argument_list|,
name|info
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
literal|true
argument_list|,
name|dir
operator|.
name|dir
argument_list|,
name|covered
argument_list|,
name|ppdResult
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|int
name|dirIx
init|=
operator|-
literal|1
decl_stmt|,
name|fileInDirIx
init|=
operator|-
literal|1
decl_stmt|,
name|filesInDirCount
init|=
literal|0
decl_stmt|;
name|ETLDir
name|dir
init|=
literal|null
decl_stmt|;
for|for
control|(
name|HdfsFileStatusWithId
name|file
range|:
name|files
control|)
block|{
if|if
condition|(
operator|(
operator|++
name|fileInDirIx
operator|)
operator|==
name|filesInDirCount
condition|)
block|{
name|dir
operator|=
name|dirs
operator|.
name|get
argument_list|(
operator|++
name|dirIx
argument_list|)
expr_stmt|;
name|filesInDirCount
operator|=
name|dir
operator|.
name|fileCount
expr_stmt|;
block|}
comment|// ignore files of 0 length
if|if
condition|(
name|file
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
operator|new
name|SplitInfo
argument_list|(
name|context
argument_list|,
name|dir
operator|.
name|fs
argument_list|,
name|file
argument_list|,
literal|null
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
literal|true
argument_list|,
name|dir
operator|.
name|dir
argument_list|,
name|covered
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
if|if
condition|(
name|dirs
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
return|return
name|ETLSplitStrategy
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" strategy for "
operator|+
name|dirs
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|dir
return|;
block|}
else|else
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
name|ETLSplitStrategy
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" strategy for "
argument_list|)
decl_stmt|;
name|boolean
name|isFirst
init|=
literal|true
decl_stmt|;
for|for
control|(
name|ETLDir
name|dir
range|:
name|dirs
control|)
block|{
if|if
condition|(
operator|!
name|isFirst
condition|)
name|sb
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
name|isFirst
operator|=
literal|false
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|dir
operator|.
name|dir
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
enum|enum
name|CombineResult
block|{
name|YES
block|,
comment|// Combined, all good.
name|NO_AND_CONTINUE
block|,
comment|// Don't combine with that, but may combine with others.
name|NO_AND_SWAP
comment|// Don't combine with with that, and make that a base for new combines.
comment|// We may add NO_AND_STOP in future where combine is impossible and other should not be base.
block|}
specifier|public
name|CombineResult
name|combineWith
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|otherFiles
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
if|if
condition|(
operator|(
name|files
operator|.
name|size
argument_list|()
operator|+
name|otherFiles
operator|.
name|size
argument_list|()
operator|)
operator|>
name|ETL_COMBINE_FILE_LIMIT
operator|||
name|this
operator|.
name|isOriginal
operator|!=
name|isOriginal
condition|)
block|{
return|return
operator|(
name|files
operator|.
name|size
argument_list|()
operator|>
name|otherFiles
operator|.
name|size
argument_list|()
operator|)
condition|?
name|CombineResult
operator|.
name|NO_AND_SWAP
else|:
name|CombineResult
operator|.
name|NO_AND_CONTINUE
return|;
block|}
comment|// All good, combine the base/original only ETL strategies.
name|files
operator|.
name|addAll
argument_list|(
name|otherFiles
argument_list|)
expr_stmt|;
name|dirs
operator|.
name|add
argument_list|(
operator|new
name|ETLDir
argument_list|(
name|dir
argument_list|,
name|fs
argument_list|,
name|otherFiles
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|CombineResult
operator|.
name|YES
return|;
block|}
specifier|public
name|Future
argument_list|<
name|Void
argument_list|>
name|generateSplitWork
parameter_list|(
name|Context
name|context
parameter_list|,
name|List
argument_list|<
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|>
name|splitFutures
parameter_list|,
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|(
name|context
operator|.
name|cacheStripeDetails
operator|&&
name|context
operator|.
name|footerCache
operator|.
name|isBlocking
argument_list|()
operator|)
operator|||
name|context
operator|.
name|forceThreadpool
condition|)
block|{
name|this
operator|.
name|splitFuturesRef
operator|=
name|splitFutures
expr_stmt|;
name|this
operator|.
name|splitsRef
operator|=
name|splits
expr_stmt|;
return|return
name|Context
operator|.
name|threadPool
operator|.
name|submit
argument_list|(
name|this
argument_list|)
return|;
block|}
else|else
block|{
name|runGetSplitsSync
argument_list|(
name|splitFutures
argument_list|,
name|splits
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|runGetSplitsSync
argument_list|(
name|splitFuturesRef
argument_list|,
name|splitsRef
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
try|try
block|{
return|return
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|Exception
block|{
name|runGetSplitsSync
argument_list|(
name|splitFuturesRef
argument_list|,
name|splitsRef
argument_list|,
name|ugi
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|runGetSplitsSync
parameter_list|(
name|List
argument_list|<
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|>
name|splitFutures
parameter_list|,
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|)
throws|throws
name|IOException
block|{
name|UserGroupInformation
name|tpUgi
init|=
name|ugi
operator|==
literal|null
condition|?
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
else|:
name|ugi
decl_stmt|;
name|List
argument_list|<
name|SplitInfo
argument_list|>
name|splitInfos
init|=
name|getSplits
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|>
name|localListF
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|localListS
init|=
literal|null
decl_stmt|;
for|for
control|(
name|SplitInfo
name|splitInfo
range|:
name|splitInfos
control|)
block|{
name|SplitGenerator
name|sg
init|=
operator|new
name|SplitGenerator
argument_list|(
name|splitInfo
argument_list|,
name|tpUgi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|sg
operator|.
name|isBlocking
argument_list|()
condition|)
block|{
if|if
condition|(
name|localListS
operator|==
literal|null
condition|)
block|{
name|localListS
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|splits
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Already called in doAs, so no need to doAs here.
name|localListS
operator|.
name|addAll
argument_list|(
name|sg
operator|.
name|call
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|localListF
operator|==
literal|null
condition|)
block|{
name|localListF
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|splits
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|localListF
operator|.
name|add
argument_list|(
name|Context
operator|.
name|threadPool
operator|.
name|submit
argument_list|(
name|sg
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|localListS
operator|!=
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|splits
init|)
block|{
name|splits
operator|.
name|addAll
argument_list|(
name|localListS
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|localListF
operator|!=
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|splitFutures
init|)
block|{
name|splitFutures
operator|.
name|addAll
argument_list|(
name|localListF
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * BI strategy is used when the requirement is to spend less time in split generation    * as opposed to query execution (split generation does not read or cache file footers).    */
specifier|static
specifier|final
class|class
name|BISplitStrategy
extends|extends
name|ACIDSplitStrategy
block|{
specifier|private
specifier|final
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|fileStatuses
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isOriginal
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|allowSyntheticFileIds
decl_stmt|;
specifier|public
name|BISplitStrategy
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|fileStatuses
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|boolean
index|[]
name|covered
parameter_list|,
name|boolean
name|allowSyntheticFileIds
parameter_list|)
block|{
name|super
argument_list|(
name|dir
argument_list|,
name|context
operator|.
name|numBuckets
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|)
expr_stmt|;
name|this
operator|.
name|fileStatuses
operator|=
name|fileStatuses
expr_stmt|;
name|this
operator|.
name|isOriginal
operator|=
name|isOriginal
expr_stmt|;
name|this
operator|.
name|deltas
operator|=
name|deltas
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|allowSyntheticFileIds
operator|=
name|allowSyntheticFileIds
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|getSplits
parameter_list|()
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|HdfsFileStatusWithId
name|file
range|:
name|fileStatuses
control|)
block|{
name|FileStatus
name|fileStatus
init|=
name|file
operator|.
name|getFileStatus
argument_list|()
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|getLen
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|Object
name|fileKey
init|=
name|file
operator|.
name|getFileId
argument_list|()
decl_stmt|;
if|if
condition|(
name|fileKey
operator|==
literal|null
operator|&&
name|allowSyntheticFileIds
condition|)
block|{
name|fileKey
operator|=
operator|new
name|SyntheticFileId
argument_list|(
name|fileStatus
argument_list|)
expr_stmt|;
block|}
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|BlockLocation
argument_list|>
name|blockOffsets
init|=
name|SHIMS
operator|.
name|getLocationsWithOffset
argument_list|(
name|fs
argument_list|,
name|fileStatus
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|BlockLocation
argument_list|>
name|entry
range|:
name|blockOffsets
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|OrcSplit
name|orcSplit
init|=
operator|new
name|OrcSplit
argument_list|(
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|fileKey
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|getLength
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|getHosts
argument_list|()
argument_list|,
literal|null
argument_list|,
name|isOriginal
argument_list|,
literal|true
argument_list|,
name|deltas
argument_list|,
operator|-
literal|1
argument_list|)
decl_stmt|;
name|splits
operator|.
name|add
argument_list|(
name|orcSplit
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// add uncovered ACID delta splits
name|splits
operator|.
name|addAll
argument_list|(
name|super
operator|.
name|getSplits
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|splits
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|BISplitStrategy
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" strategy for "
operator|+
name|dir
return|;
block|}
block|}
comment|/**    * ACID split strategy is used when there is no base directory (when transactions are enabled).    */
specifier|static
class|class
name|ACIDSplitStrategy
implements|implements
name|SplitStrategy
argument_list|<
name|OrcSplit
argument_list|>
block|{
name|Path
name|dir
decl_stmt|;
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
decl_stmt|;
name|boolean
index|[]
name|covered
decl_stmt|;
name|int
name|numBuckets
decl_stmt|;
specifier|public
name|ACIDSplitStrategy
parameter_list|(
name|Path
name|dir
parameter_list|,
name|int
name|numBuckets
parameter_list|,
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|boolean
index|[]
name|covered
parameter_list|)
block|{
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|numBuckets
operator|=
name|numBuckets
expr_stmt|;
name|this
operator|.
name|deltas
operator|=
name|deltas
expr_stmt|;
name|this
operator|.
name|covered
operator|=
name|covered
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|getSplits
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Generate a split for any buckets that weren't covered.
comment|// This happens in the case where a bucket just has deltas and no
comment|// base.
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|deltas
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|int
name|b
init|=
literal|0
init|;
name|b
operator|<
name|numBuckets
condition|;
operator|++
name|b
control|)
block|{
if|if
condition|(
operator|!
name|covered
index|[
name|b
index|]
condition|)
block|{
name|splits
operator|.
name|add
argument_list|(
operator|new
name|OrcSplit
argument_list|(
name|dir
argument_list|,
literal|null
argument_list|,
name|b
argument_list|,
literal|0
argument_list|,
operator|new
name|String
index|[
literal|0
index|]
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
name|deltas
argument_list|,
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|splits
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|ACIDSplitStrategy
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" strategy for "
operator|+
name|dir
return|;
block|}
block|}
comment|/**    * Given a directory, get the list of files and blocks in those files.    * To parallelize file generator use "mapreduce.input.fileinputformat.list-status.num-threads"    */
specifier|static
specifier|final
class|class
name|FileGenerator
implements|implements
name|Callable
argument_list|<
name|AcidDirInfo
argument_list|>
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|useFileIds
decl_stmt|;
specifier|private
specifier|final
name|UserGroupInformation
name|ugi
decl_stmt|;
name|FileGenerator
parameter_list|(
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|boolean
name|useFileIds
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|)
block|{
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|useFileIds
operator|=
name|useFileIds
expr_stmt|;
name|this
operator|.
name|ugi
operator|=
name|ugi
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|AcidDirInfo
name|call
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
return|return
name|callInternal
argument_list|()
return|;
block|}
try|try
block|{
return|return
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|AcidDirInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|AcidDirInfo
name|run
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|callInternal
argument_list|()
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|AcidDirInfo
name|callInternal
parameter_list|()
throws|throws
name|IOException
block|{
name|AcidUtils
operator|.
name|Directory
name|dirInfo
init|=
name|AcidUtils
operator|.
name|getAcidState
argument_list|(
name|dir
argument_list|,
name|context
operator|.
name|conf
argument_list|,
name|context
operator|.
name|transactionList
argument_list|,
name|useFileIds
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|Path
name|base
init|=
name|dirInfo
operator|.
name|getBaseDirectory
argument_list|()
decl_stmt|;
comment|// find the base files (original or new style)
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|children
init|=
operator|(
name|base
operator|==
literal|null
operator|)
condition|?
name|dirInfo
operator|.
name|getOriginalFiles
argument_list|()
else|:
name|findBaseFiles
argument_list|(
name|base
argument_list|,
name|useFileIds
argument_list|)
decl_stmt|;
return|return
operator|new
name|AcidDirInfo
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|dirInfo
argument_list|,
name|children
argument_list|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|findBaseFiles
parameter_list|(
name|Path
name|base
parameter_list|,
name|boolean
name|useFileIds
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|useFileIds
condition|)
block|{
try|try
block|{
return|return
name|SHIMS
operator|.
name|listLocatedHdfsStatus
argument_list|(
name|fs
argument_list|,
name|base
argument_list|,
name|AcidUtils
operator|.
name|hiddenFileFilter
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get files with ID; using regular API: "
operator|+
name|t
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Fall back to regular API and create states without ID.
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|SHIMS
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|base
argument_list|,
name|AcidUtils
operator|.
name|hiddenFileFilter
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|children
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|result
operator|.
name|add
argument_list|(
name|AcidUtils
operator|.
name|createOriginalObj
argument_list|(
literal|null
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
block|}
comment|/**    * Split the stripes of a given file into input splits.    * A thread is used for each file.    */
specifier|static
specifier|final
class|class
name|SplitGenerator
implements|implements
name|Callable
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
block|{
specifier|private
specifier|final
name|Context
name|context
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|FileStatus
name|file
decl_stmt|;
specifier|private
specifier|final
name|Long
name|fsFileId
decl_stmt|;
specifier|private
specifier|final
name|long
name|blockSize
decl_stmt|;
specifier|private
specifier|final
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|BlockLocation
argument_list|>
name|locations
decl_stmt|;
specifier|private
specifier|final
name|FileInfo
name|fileInfo
decl_stmt|;
specifier|private
name|List
argument_list|<
name|StripeInformation
argument_list|>
name|stripes
decl_stmt|;
specifier|private
name|FileMetaInfo
name|fileMetaInfo
decl_stmt|;
specifier|private
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
decl_stmt|;
specifier|private
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
decl_stmt|;
specifier|private
name|boolean
index|[]
name|includedCols
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isOriginal
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|hasBase
decl_stmt|;
specifier|private
name|OrcFile
operator|.
name|WriterVersion
name|writerVersion
decl_stmt|;
specifier|private
name|long
name|projColsUncompressedSize
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|deltaSplits
decl_stmt|;
specifier|private
specifier|final
name|ByteBuffer
name|ppdResult
decl_stmt|;
specifier|private
specifier|final
name|UserGroupInformation
name|ugi
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|allowSyntheticFileIds
decl_stmt|;
specifier|public
name|SplitGenerator
parameter_list|(
name|SplitInfo
name|splitInfo
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|,
name|boolean
name|allowSyntheticFileIds
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|ugi
operator|=
name|ugi
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|splitInfo
operator|.
name|context
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|splitInfo
operator|.
name|fs
expr_stmt|;
name|this
operator|.
name|file
operator|=
name|splitInfo
operator|.
name|fileWithId
operator|.
name|getFileStatus
argument_list|()
expr_stmt|;
name|this
operator|.
name|fsFileId
operator|=
name|splitInfo
operator|.
name|fileWithId
operator|.
name|getFileId
argument_list|()
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
name|this
operator|.
name|file
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|this
operator|.
name|fileInfo
operator|=
name|splitInfo
operator|.
name|fileInfo
expr_stmt|;
comment|// TODO: potential DFS call
name|this
operator|.
name|locations
operator|=
name|SHIMS
operator|.
name|getLocationsWithOffset
argument_list|(
name|fs
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|this
operator|.
name|isOriginal
operator|=
name|splitInfo
operator|.
name|isOriginal
expr_stmt|;
name|this
operator|.
name|deltas
operator|=
name|splitInfo
operator|.
name|deltas
expr_stmt|;
name|this
operator|.
name|hasBase
operator|=
name|splitInfo
operator|.
name|hasBase
expr_stmt|;
name|this
operator|.
name|projColsUncompressedSize
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|deltaSplits
operator|=
name|splitInfo
operator|.
name|getSplits
argument_list|()
expr_stmt|;
name|this
operator|.
name|allowSyntheticFileIds
operator|=
name|allowSyntheticFileIds
expr_stmt|;
name|this
operator|.
name|ppdResult
operator|=
name|splitInfo
operator|.
name|ppdResult
expr_stmt|;
block|}
specifier|public
name|boolean
name|isBlocking
parameter_list|()
block|{
return|return
name|ppdResult
operator|!=
literal|null
return|;
block|}
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|file
operator|.
name|getPath
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"splitter("
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|")"
return|;
block|}
comment|/**      * Compute the number of bytes that overlap between the two ranges.      * @param offset1 start of range1      * @param length1 length of range1      * @param offset2 start of range2      * @param length2 length of range2      * @return the number of bytes in the overlap range      */
specifier|static
name|long
name|getOverlap
parameter_list|(
name|long
name|offset1
parameter_list|,
name|long
name|length1
parameter_list|,
name|long
name|offset2
parameter_list|,
name|long
name|length2
parameter_list|)
block|{
name|long
name|end1
init|=
name|offset1
operator|+
name|length1
decl_stmt|;
name|long
name|end2
init|=
name|offset2
operator|+
name|length2
decl_stmt|;
if|if
condition|(
name|end2
operator|<=
name|offset1
operator|||
name|end1
operator|<=
name|offset2
condition|)
block|{
return|return
literal|0
return|;
block|}
else|else
block|{
return|return
name|Math
operator|.
name|min
argument_list|(
name|end1
argument_list|,
name|end2
argument_list|)
operator|-
name|Math
operator|.
name|max
argument_list|(
name|offset1
argument_list|,
name|offset2
argument_list|)
return|;
block|}
block|}
comment|/**      * Create an input split over the given range of bytes. The location of the      * split is based on where the majority of the byte are coming from. ORC      * files are unlikely to have splits that cross between blocks because they      * are written with large block sizes.      * @param offset the start of the split      * @param length the length of the split      * @param fileMetaInfo file metadata from footer and postscript      * @throws IOException      */
name|OrcSplit
name|createSplit
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|String
index|[]
name|hosts
decl_stmt|;
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|BlockLocation
argument_list|>
name|startEntry
init|=
name|locations
operator|.
name|floorEntry
argument_list|(
name|offset
argument_list|)
decl_stmt|;
name|BlockLocation
name|start
init|=
name|startEntry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|offset
operator|+
name|length
operator|<=
name|start
operator|.
name|getOffset
argument_list|()
operator|+
name|start
operator|.
name|getLength
argument_list|()
condition|)
block|{
comment|// handle the single block case
name|hosts
operator|=
name|start
operator|.
name|getHosts
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|BlockLocation
argument_list|>
name|endEntry
init|=
name|locations
operator|.
name|floorEntry
argument_list|(
name|offset
operator|+
name|length
argument_list|)
decl_stmt|;
comment|//get the submap
name|NavigableMap
argument_list|<
name|Long
argument_list|,
name|BlockLocation
argument_list|>
name|navigableMap
init|=
name|locations
operator|.
name|subMap
argument_list|(
name|startEntry
operator|.
name|getKey
argument_list|()
argument_list|,
literal|true
argument_list|,
name|endEntry
operator|.
name|getKey
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// Calculate the number of bytes in the split that are local to each
comment|// host.
name|Map
argument_list|<
name|String
argument_list|,
name|LongWritable
argument_list|>
name|sizes
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LongWritable
argument_list|>
argument_list|()
decl_stmt|;
name|long
name|maxSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|BlockLocation
name|block
range|:
name|navigableMap
operator|.
name|values
argument_list|()
control|)
block|{
name|long
name|overlap
init|=
name|getOverlap
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
name|block
operator|.
name|getOffset
argument_list|()
argument_list|,
name|block
operator|.
name|getLength
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|overlap
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|String
name|host
range|:
name|block
operator|.
name|getHosts
argument_list|()
control|)
block|{
name|LongWritable
name|val
init|=
name|sizes
operator|.
name|get
argument_list|(
name|host
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
operator|new
name|LongWritable
argument_list|()
expr_stmt|;
name|sizes
operator|.
name|put
argument_list|(
name|host
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
name|val
operator|.
name|set
argument_list|(
name|val
operator|.
name|get
argument_list|()
operator|+
name|overlap
argument_list|)
expr_stmt|;
name|maxSize
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxSize
argument_list|,
name|val
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File "
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" should have had overlap on block starting at "
operator|+
name|block
operator|.
name|getOffset
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|// filter the list of locations to those that have at least 80% of the
comment|// max
name|long
name|threshold
init|=
call|(
name|long
call|)
argument_list|(
name|maxSize
operator|*
name|MIN_INCLUDED_LOCATION
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|hostList
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
comment|// build the locations in a predictable order to simplify testing
for|for
control|(
name|BlockLocation
name|block
range|:
name|navigableMap
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|String
name|host
range|:
name|block
operator|.
name|getHosts
argument_list|()
control|)
block|{
if|if
condition|(
name|sizes
operator|.
name|containsKey
argument_list|(
name|host
argument_list|)
condition|)
block|{
if|if
condition|(
name|sizes
operator|.
name|get
argument_list|(
name|host
argument_list|)
operator|.
name|get
argument_list|()
operator|>=
name|threshold
condition|)
block|{
name|hostList
operator|.
name|add
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
name|sizes
operator|.
name|remove
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|hosts
operator|=
operator|new
name|String
index|[
name|hostList
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|hostList
operator|.
name|toArray
argument_list|(
name|hosts
argument_list|)
expr_stmt|;
block|}
comment|// scale the raw data size to split level based on ratio of split wrt to file length
specifier|final
name|long
name|fileLen
init|=
name|file
operator|.
name|getLen
argument_list|()
decl_stmt|;
specifier|final
name|double
name|splitRatio
init|=
operator|(
name|double
operator|)
name|length
operator|/
operator|(
name|double
operator|)
name|fileLen
decl_stmt|;
specifier|final
name|long
name|scaledProjSize
init|=
name|projColsUncompressedSize
operator|>
literal|0
condition|?
call|(
name|long
call|)
argument_list|(
name|splitRatio
operator|*
name|projColsUncompressedSize
argument_list|)
else|:
name|fileLen
decl_stmt|;
name|Object
name|fileKey
init|=
name|fsFileId
decl_stmt|;
if|if
condition|(
name|fileKey
operator|==
literal|null
operator|&&
name|allowSyntheticFileIds
condition|)
block|{
name|fileKey
operator|=
operator|new
name|SyntheticFileId
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|OrcSplit
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|fileKey
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|hosts
argument_list|,
name|fileMetaInfo
argument_list|,
name|isOriginal
argument_list|,
name|hasBase
argument_list|,
name|deltas
argument_list|,
name|scaledProjSize
argument_list|)
return|;
block|}
specifier|private
specifier|static
specifier|final
class|class
name|OffsetAndLength
block|{
comment|// Java cruft; pair of long.
specifier|public
name|OffsetAndLength
parameter_list|()
block|{
name|this
operator|.
name|offset
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|length
operator|=
literal|0
expr_stmt|;
block|}
name|long
name|offset
decl_stmt|,
name|length
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"[offset="
operator|+
name|offset
operator|+
literal|", length="
operator|+
name|length
operator|+
literal|"]"
return|;
block|}
block|}
comment|/**      * Divide the adjacent stripes in the file into input splits based on the      * block size and the configured minimum and maximum sizes.      */
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|call
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
return|return
name|callInternal
argument_list|()
return|;
block|}
try|try
block|{
return|return
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|run
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|callInternal
argument_list|()
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|callInternal
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Figure out which stripes we need to read.
if|if
condition|(
name|ppdResult
operator|!=
literal|null
condition|)
block|{
assert|assert
name|deltaSplits
operator|.
name|isEmpty
argument_list|()
assert|;
assert|assert
name|ppdResult
operator|.
name|hasArray
argument_list|()
assert|;
comment|// TODO: when PB is upgraded to 2.6, newInstance(ByteBuffer) method should be used here.
name|CodedInputStream
name|cis
init|=
name|CodedInputStream
operator|.
name|newInstance
argument_list|(
name|ppdResult
operator|.
name|array
argument_list|()
argument_list|,
name|ppdResult
operator|.
name|arrayOffset
argument_list|()
argument_list|,
name|ppdResult
operator|.
name|remaining
argument_list|()
argument_list|)
decl_stmt|;
name|cis
operator|.
name|setSizeLimit
argument_list|(
name|InStream
operator|.
name|PROTOBUF_MESSAGE_MAX_LIMIT
argument_list|)
expr_stmt|;
return|return
name|generateSplitsFromPpd
argument_list|(
name|SplitInfos
operator|.
name|parseFrom
argument_list|(
name|cis
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
name|populateAndCacheStripeDetails
argument_list|()
expr_stmt|;
name|boolean
index|[]
name|includeStripe
init|=
literal|null
decl_stmt|;
comment|// We can't eliminate stripes if there are deltas because the
comment|// deltas may change the rows making them match the predicate.
if|if
condition|(
operator|(
name|deltas
operator|==
literal|null
operator|||
name|deltas
operator|.
name|isEmpty
argument_list|()
operator|)
operator|&&
name|context
operator|.
name|sarg
operator|!=
literal|null
condition|)
block|{
name|String
index|[]
name|colNames
init|=
name|extractNeededColNames
argument_list|(
name|types
argument_list|,
name|context
operator|.
name|conf
argument_list|,
name|includedCols
argument_list|,
name|isOriginal
argument_list|)
decl_stmt|;
if|if
condition|(
name|colNames
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Skipping split elimination for {} as column names is null"
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|includeStripe
operator|=
name|pickStripes
argument_list|(
name|context
operator|.
name|sarg
argument_list|,
name|colNames
argument_list|,
name|writerVersion
argument_list|,
name|isOriginal
argument_list|,
name|stripeStats
argument_list|,
name|stripes
operator|.
name|size
argument_list|()
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|generateSplitsFromStripes
argument_list|(
name|includeStripe
argument_list|)
return|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|generateSplitsFromPpd
parameter_list|(
name|SplitInfos
name|ppdResult
parameter_list|)
throws|throws
name|IOException
block|{
name|OffsetAndLength
name|current
init|=
operator|new
name|OffsetAndLength
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|ppdResult
operator|.
name|getInfosCount
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|lastIdx
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Metastore
operator|.
name|SplitInfo
name|si
range|:
name|ppdResult
operator|.
name|getInfosList
argument_list|()
control|)
block|{
name|int
name|index
init|=
name|si
operator|.
name|getIndex
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastIdx
operator|>=
literal|0
operator|&&
name|lastIdx
operator|+
literal|1
operator|!=
name|index
operator|&&
name|current
operator|.
name|offset
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// Create split for the previous unfinished stripe.
name|splits
operator|.
name|add
argument_list|(
name|createSplit
argument_list|(
name|current
operator|.
name|offset
argument_list|,
name|current
operator|.
name|length
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|current
operator|.
name|offset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
name|lastIdx
operator|=
name|index
expr_stmt|;
name|String
name|debugStr
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|debugStr
operator|=
name|current
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
name|current
operator|=
name|generateOrUpdateSplit
argument_list|(
name|splits
argument_list|,
name|current
argument_list|,
name|si
operator|.
name|getOffset
argument_list|()
argument_list|,
name|si
operator|.
name|getLength
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updated split from {"
operator|+
name|index
operator|+
literal|": "
operator|+
name|si
operator|.
name|getOffset
argument_list|()
operator|+
literal|", "
operator|+
name|si
operator|.
name|getLength
argument_list|()
operator|+
literal|"} and "
operator|+
name|debugStr
operator|+
literal|" to "
operator|+
name|current
argument_list|)
expr_stmt|;
block|}
block|}
name|generateLastSplit
argument_list|(
name|splits
argument_list|,
name|current
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|splits
return|;
block|}
specifier|private
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|generateSplitsFromStripes
parameter_list|(
name|boolean
index|[]
name|includeStripe
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|stripes
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// if we didn't have predicate pushdown, read everything
if|if
condition|(
name|includeStripe
operator|==
literal|null
condition|)
block|{
name|includeStripe
operator|=
operator|new
name|boolean
index|[
name|stripes
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|includeStripe
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|OffsetAndLength
name|current
init|=
operator|new
name|OffsetAndLength
argument_list|()
decl_stmt|;
name|int
name|idx
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|StripeInformation
name|stripe
range|:
name|stripes
control|)
block|{
name|idx
operator|++
expr_stmt|;
if|if
condition|(
operator|!
name|includeStripe
index|[
name|idx
index|]
condition|)
block|{
comment|// create split for the previous unfinished stripe
if|if
condition|(
name|current
operator|.
name|offset
operator|!=
operator|-
literal|1
condition|)
block|{
name|splits
operator|.
name|add
argument_list|(
name|createSplit
argument_list|(
name|current
operator|.
name|offset
argument_list|,
name|current
operator|.
name|length
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
name|current
operator|.
name|offset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
continue|continue;
block|}
name|current
operator|=
name|generateOrUpdateSplit
argument_list|(
name|splits
argument_list|,
name|current
argument_list|,
name|stripe
operator|.
name|getOffset
argument_list|()
argument_list|,
name|stripe
operator|.
name|getLength
argument_list|()
argument_list|,
name|fileMetaInfo
argument_list|)
expr_stmt|;
block|}
name|generateLastSplit
argument_list|(
name|splits
argument_list|,
name|current
argument_list|,
name|fileMetaInfo
argument_list|)
expr_stmt|;
comment|// Add uncovered ACID delta splits.
name|splits
operator|.
name|addAll
argument_list|(
name|deltaSplits
argument_list|)
expr_stmt|;
return|return
name|splits
return|;
block|}
specifier|private
name|OffsetAndLength
name|generateOrUpdateSplit
parameter_list|(
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
parameter_list|,
name|OffsetAndLength
name|current
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if we are working on a stripe, over the min stripe size, and
comment|// crossed a block boundary, cut the input split here.
if|if
condition|(
name|current
operator|.
name|offset
operator|!=
operator|-
literal|1
operator|&&
name|current
operator|.
name|length
operator|>
name|context
operator|.
name|minSize
operator|&&
operator|(
name|current
operator|.
name|offset
operator|/
name|blockSize
operator|!=
name|offset
operator|/
name|blockSize
operator|)
condition|)
block|{
name|splits
operator|.
name|add
argument_list|(
name|createSplit
argument_list|(
name|current
operator|.
name|offset
argument_list|,
name|current
operator|.
name|length
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
name|current
operator|.
name|offset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// if we aren't building a split, start a new one.
if|if
condition|(
name|current
operator|.
name|offset
operator|==
operator|-
literal|1
condition|)
block|{
name|current
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
name|current
operator|.
name|length
operator|=
name|length
expr_stmt|;
block|}
else|else
block|{
name|current
operator|.
name|length
operator|=
operator|(
name|offset
operator|+
name|length
operator|)
operator|-
name|current
operator|.
name|offset
expr_stmt|;
block|}
if|if
condition|(
name|current
operator|.
name|length
operator|>=
name|context
operator|.
name|maxSize
condition|)
block|{
name|splits
operator|.
name|add
argument_list|(
name|createSplit
argument_list|(
name|current
operator|.
name|offset
argument_list|,
name|current
operator|.
name|length
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
name|current
operator|.
name|offset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
return|return
name|current
return|;
block|}
specifier|private
name|void
name|generateLastSplit
parameter_list|(
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
parameter_list|,
name|OffsetAndLength
name|current
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|current
operator|.
name|offset
operator|==
operator|-
literal|1
condition|)
return|return;
name|splits
operator|.
name|add
argument_list|(
name|createSplit
argument_list|(
name|current
operator|.
name|offset
argument_list|,
name|current
operator|.
name|length
argument_list|,
name|fileMetaInfo
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|populateAndCacheStripeDetails
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Only create OrcReader if we are missing some information.
name|List
argument_list|<
name|OrcProto
operator|.
name|ColumnStatistics
argument_list|>
name|colStatsLocal
decl_stmt|;
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|typesLocal
decl_stmt|;
if|if
condition|(
name|fileInfo
operator|!=
literal|null
condition|)
block|{
name|stripes
operator|=
name|fileInfo
operator|.
name|stripeInfos
expr_stmt|;
name|stripeStats
operator|=
name|fileInfo
operator|.
name|stripeStats
expr_stmt|;
name|fileMetaInfo
operator|=
name|fileInfo
operator|.
name|fileMetaInfo
expr_stmt|;
name|typesLocal
operator|=
name|types
operator|=
name|fileInfo
operator|.
name|types
expr_stmt|;
name|colStatsLocal
operator|=
name|fileInfo
operator|.
name|fileStats
expr_stmt|;
name|writerVersion
operator|=
name|fileInfo
operator|.
name|writerVersion
expr_stmt|;
comment|// For multiple runs, in case sendSplitsInFooter changes
if|if
condition|(
name|fileMetaInfo
operator|==
literal|null
operator|&&
name|context
operator|.
name|footerInSplits
condition|)
block|{
name|Reader
name|orcReader
init|=
name|createOrcReader
argument_list|()
decl_stmt|;
name|fileInfo
operator|.
name|fileMetaInfo
operator|=
operator|(
operator|(
name|ReaderImpl
operator|)
name|orcReader
operator|)
operator|.
name|getFileMetaInfo
argument_list|()
expr_stmt|;
assert|assert
name|fileInfo
operator|.
name|stripeStats
operator|!=
literal|null
operator|&&
name|fileInfo
operator|.
name|types
operator|!=
literal|null
operator|&&
name|fileInfo
operator|.
name|writerVersion
operator|!=
literal|null
assert|;
comment|// We assume that if we needed to create a reader, we need to cache it to meta cache.
comment|// This will also needlessly overwrite it in local cache for now.
name|context
operator|.
name|footerCache
operator|.
name|put
argument_list|(
name|fsFileId
argument_list|,
name|file
argument_list|,
name|fileInfo
operator|.
name|fileMetaInfo
argument_list|,
name|orcReader
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|Reader
name|orcReader
init|=
name|createOrcReader
argument_list|()
decl_stmt|;
name|stripes
operator|=
name|orcReader
operator|.
name|getStripes
argument_list|()
expr_stmt|;
name|typesLocal
operator|=
name|types
operator|=
name|orcReader
operator|.
name|getTypes
argument_list|()
expr_stmt|;
name|colStatsLocal
operator|=
name|orcReader
operator|.
name|getOrcProtoFileStatistics
argument_list|()
expr_stmt|;
name|writerVersion
operator|=
name|orcReader
operator|.
name|getWriterVersion
argument_list|()
expr_stmt|;
name|stripeStats
operator|=
name|orcReader
operator|.
name|getStripeStatistics
argument_list|()
expr_stmt|;
name|fileMetaInfo
operator|=
name|context
operator|.
name|footerInSplits
condition|?
operator|(
operator|(
name|ReaderImpl
operator|)
name|orcReader
operator|)
operator|.
name|getFileMetaInfo
argument_list|()
else|:
literal|null
expr_stmt|;
if|if
condition|(
name|context
operator|.
name|cacheStripeDetails
condition|)
block|{
name|context
operator|.
name|footerCache
operator|.
name|put
argument_list|(
name|fsFileId
argument_list|,
name|file
argument_list|,
name|fileMetaInfo
argument_list|,
name|orcReader
argument_list|)
expr_stmt|;
block|}
block|}
name|includedCols
operator|=
name|genIncludedColumns
argument_list|(
name|types
argument_list|,
name|context
operator|.
name|conf
argument_list|,
name|isOriginal
argument_list|)
expr_stmt|;
name|projColsUncompressedSize
operator|=
name|computeProjectionSize
argument_list|(
name|typesLocal
argument_list|,
name|colStatsLocal
argument_list|,
name|includedCols
argument_list|,
name|isOriginal
argument_list|)
expr_stmt|;
block|}
specifier|private
name|Reader
name|createOrcReader
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|OrcFile
operator|.
name|createReader
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|context
operator|.
name|conf
argument_list|)
operator|.
name|filesystem
argument_list|(
name|fs
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|long
name|computeProjectionSize
parameter_list|(
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|ColumnStatistics
argument_list|>
name|stats
parameter_list|,
name|boolean
index|[]
name|includedCols
parameter_list|,
name|boolean
name|isOriginal
parameter_list|)
block|{
specifier|final
name|int
name|rootIdx
init|=
name|getRootColumn
argument_list|(
name|isOriginal
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|internalColIds
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
if|if
condition|(
name|includedCols
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|includedCols
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|includedCols
index|[
name|i
index|]
condition|)
block|{
name|internalColIds
operator|.
name|add
argument_list|(
name|rootIdx
operator|+
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|ReaderImpl
operator|.
name|getRawDataSizeFromColIndices
argument_list|(
name|internalColIds
argument_list|,
name|types
argument_list|,
name|stats
argument_list|)
return|;
block|}
block|}
comment|/** Class intended to update two values from methods... Java-related cruft. */
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
class|class
name|CombinedCtx
block|{
name|ETLSplitStrategy
name|combined
decl_stmt|;
name|long
name|combineStartUs
decl_stmt|;
block|}
specifier|static
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|generateSplitsInfo
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"ORC pushdown predicate: "
operator|+
name|context
operator|.
name|sarg
argument_list|)
expr_stmt|;
block|}
name|boolean
name|useFileIds
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_INCLUDE_FILE_ID_IN_SPLITS
argument_list|)
decl_stmt|;
name|boolean
name|allowSyntheticFileIds
init|=
name|useFileIds
operator|&&
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ORC_ALLOW_SYNTHETIC_FILE_ID_IN_SPLITS
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|AcidDirInfo
argument_list|>
argument_list|>
name|pathFutures
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|strategyFutures
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|>
name|splitFutures
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|UserGroupInformation
name|ugi
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
decl_stmt|;
comment|// multi-threaded file statuses and split strategy
name|Path
index|[]
name|paths
init|=
name|getInputPaths
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|AcidDirInfo
argument_list|>
name|ecs
init|=
operator|new
name|ExecutorCompletionService
argument_list|<>
argument_list|(
name|Context
operator|.
name|threadPool
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|dir
range|:
name|paths
control|)
block|{
name|FileSystem
name|fs
init|=
name|dir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileGenerator
name|fileGenerator
init|=
operator|new
name|FileGenerator
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|useFileIds
argument_list|,
name|ugi
argument_list|)
decl_stmt|;
name|pathFutures
operator|.
name|add
argument_list|(
name|ecs
operator|.
name|submit
argument_list|(
name|fileGenerator
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// complete path futures and schedule split generation
try|try
block|{
name|CombinedCtx
name|combinedCtx
init|=
operator|(
name|context
operator|.
name|splitStrategyBatchMs
operator|>
literal|0
operator|)
condition|?
operator|new
name|CombinedCtx
argument_list|()
else|:
literal|null
decl_stmt|;
name|long
name|maxWaitUs
init|=
name|context
operator|.
name|splitStrategyBatchMs
operator|*
literal|1000000
decl_stmt|;
name|int
name|resultsLeft
init|=
name|paths
operator|.
name|length
decl_stmt|;
while|while
condition|(
name|resultsLeft
operator|>
literal|0
condition|)
block|{
name|AcidDirInfo
name|adi
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|combinedCtx
operator|!=
literal|null
operator|&&
name|combinedCtx
operator|.
name|combined
operator|!=
literal|null
condition|)
block|{
name|long
name|waitTimeUs
init|=
name|combinedCtx
operator|.
name|combineStartUs
operator|+
name|maxWaitUs
operator|-
name|System
operator|.
name|nanoTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|waitTimeUs
operator|>=
literal|0
condition|)
block|{
name|Future
argument_list|<
name|AcidDirInfo
argument_list|>
name|f
init|=
name|ecs
operator|.
name|poll
argument_list|(
name|waitTimeUs
argument_list|,
name|TimeUnit
operator|.
name|NANOSECONDS
argument_list|)
decl_stmt|;
name|adi
operator|=
operator|(
name|f
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
name|f
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|adi
operator|=
name|ecs
operator|.
name|take
argument_list|()
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|adi
operator|==
literal|null
condition|)
block|{
comment|// We were combining SS-es and the time has expired.
assert|assert
name|combinedCtx
operator|.
name|combined
operator|!=
literal|null
assert|;
name|scheduleSplits
argument_list|(
name|combinedCtx
operator|.
name|combined
argument_list|,
name|context
argument_list|,
name|splitFutures
argument_list|,
name|strategyFutures
argument_list|,
name|splits
argument_list|)
expr_stmt|;
name|combinedCtx
operator|.
name|combined
operator|=
literal|null
expr_stmt|;
continue|continue;
block|}
comment|// We have received a new directory information, make a split strategy.
operator|--
name|resultsLeft
expr_stmt|;
name|SplitStrategy
argument_list|<
name|?
argument_list|>
name|splitStrategy
init|=
name|determineSplitStrategy
argument_list|(
name|combinedCtx
argument_list|,
name|context
argument_list|,
name|adi
operator|.
name|fs
argument_list|,
name|adi
operator|.
name|splitPath
argument_list|,
name|adi
operator|.
name|acidInfo
argument_list|,
name|adi
operator|.
name|baseOrOriginalFiles
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
decl_stmt|;
if|if
condition|(
name|splitStrategy
operator|==
literal|null
condition|)
continue|continue;
comment|// Combined.
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Split strategy: {}"
argument_list|,
name|splitStrategy
argument_list|)
expr_stmt|;
block|}
comment|// Hack note - different split strategies return differently typed lists, yay Java.
comment|// This works purely by magic, because we know which strategy produces which type.
if|if
condition|(
name|splitStrategy
operator|instanceof
name|ETLSplitStrategy
condition|)
block|{
name|scheduleSplits
argument_list|(
operator|(
name|ETLSplitStrategy
operator|)
name|splitStrategy
argument_list|,
name|context
argument_list|,
name|splitFutures
argument_list|,
name|strategyFutures
argument_list|,
name|splits
argument_list|)
expr_stmt|;
block|}
else|else
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|readySplits
init|=
operator|(
name|List
argument_list|<
name|OrcSplit
argument_list|>
operator|)
name|splitStrategy
operator|.
name|getSplits
argument_list|()
decl_stmt|;
name|splits
operator|.
name|addAll
argument_list|(
name|readySplits
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Run the last combined strategy, if any.
if|if
condition|(
name|combinedCtx
operator|!=
literal|null
operator|&&
name|combinedCtx
operator|.
name|combined
operator|!=
literal|null
condition|)
block|{
name|scheduleSplits
argument_list|(
name|combinedCtx
operator|.
name|combined
argument_list|,
name|context
argument_list|,
name|splitFutures
argument_list|,
name|strategyFutures
argument_list|,
name|splits
argument_list|)
expr_stmt|;
name|combinedCtx
operator|.
name|combined
operator|=
literal|null
expr_stmt|;
block|}
comment|// complete split futures
for|for
control|(
name|Future
argument_list|<
name|Void
argument_list|>
name|ssFuture
range|:
name|strategyFutures
control|)
block|{
name|ssFuture
operator|.
name|get
argument_list|()
expr_stmt|;
comment|// Make sure we get exceptions strategies might have thrown.
block|}
comment|// All the split strategies are done, so it must be safe to access splitFutures.
for|for
control|(
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
name|splitFuture
range|:
name|splitFutures
control|)
block|{
name|splits
operator|.
name|addAll
argument_list|(
name|splitFuture
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|cancelFutures
argument_list|(
name|pathFutures
argument_list|)
expr_stmt|;
name|cancelFutures
argument_list|(
name|strategyFutures
argument_list|)
expr_stmt|;
name|cancelFutures
argument_list|(
name|splitFutures
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"ORC split generation failed with exception: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|context
operator|.
name|cacheStripeDetails
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"FooterCacheHitRatio: "
operator|+
name|context
operator|.
name|cacheHitCounter
operator|.
name|get
argument_list|()
operator|+
literal|"/"
operator|+
name|context
operator|.
name|numFilesCounter
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
for|for
control|(
name|OrcSplit
name|split
range|:
name|splits
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|split
operator|+
literal|" projected_columns_uncompressed_size: "
operator|+
name|split
operator|.
name|getColumnarProjectionSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|splits
return|;
block|}
annotation|@
name|VisibleForTesting
comment|// We could have this as a protected method w/no class, but half of Hive is static, so there.
specifier|public
specifier|static
class|class
name|ContextFactory
block|{
specifier|public
name|Context
name|create
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|int
name|numSplits
parameter_list|)
block|{
return|return
operator|new
name|Context
argument_list|(
name|conf
argument_list|,
name|numSplits
argument_list|)
return|;
block|}
block|}
specifier|private
specifier|static
name|void
name|scheduleSplits
parameter_list|(
name|ETLSplitStrategy
name|splitStrategy
parameter_list|,
name|Context
name|context
parameter_list|,
name|List
argument_list|<
name|Future
argument_list|<
name|List
argument_list|<
name|OrcSplit
argument_list|>
argument_list|>
argument_list|>
name|splitFutures
parameter_list|,
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|strategyFutures
parameter_list|,
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|splits
parameter_list|)
throws|throws
name|IOException
block|{
name|Future
argument_list|<
name|Void
argument_list|>
name|ssFuture
init|=
name|splitStrategy
operator|.
name|generateSplitWork
argument_list|(
name|context
argument_list|,
name|splitFutures
argument_list|,
name|splits
argument_list|)
decl_stmt|;
if|if
condition|(
name|ssFuture
operator|==
literal|null
condition|)
return|return;
name|strategyFutures
operator|.
name|add
argument_list|(
name|ssFuture
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
parameter_list|<
name|T
parameter_list|>
name|void
name|cancelFutures
parameter_list|(
name|List
argument_list|<
name|Future
argument_list|<
name|T
argument_list|>
argument_list|>
name|futures
parameter_list|)
block|{
for|for
control|(
name|Future
argument_list|<
name|T
argument_list|>
name|future
range|:
name|futures
control|)
block|{
name|future
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|SplitStrategy
argument_list|<
name|?
argument_list|>
name|combineOrCreateETLStrategy
parameter_list|(
name|CombinedCtx
name|combinedCtx
parameter_list|,
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|files
parameter_list|,
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|boolean
index|[]
name|covered
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|,
name|boolean
name|allowSyntheticFileIds
parameter_list|)
block|{
if|if
condition|(
operator|!
name|deltas
operator|.
name|isEmpty
argument_list|()
operator|||
name|combinedCtx
operator|==
literal|null
condition|)
block|{
return|return
operator|new
name|ETLSplitStrategy
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|files
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|combinedCtx
operator|.
name|combined
operator|==
literal|null
condition|)
block|{
name|combinedCtx
operator|.
name|combined
operator|=
operator|new
name|ETLSplitStrategy
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|files
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
expr_stmt|;
name|combinedCtx
operator|.
name|combineStartUs
operator|=
name|System
operator|.
name|nanoTime
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
else|else
block|{
name|ETLSplitStrategy
operator|.
name|CombineResult
name|r
init|=
name|combinedCtx
operator|.
name|combined
operator|.
name|combineWith
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|files
argument_list|,
name|isOriginal
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|r
condition|)
block|{
case|case
name|YES
case|:
return|return
literal|null
return|;
case|case
name|NO_AND_CONTINUE
case|:
return|return
operator|new
name|ETLSplitStrategy
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|files
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
return|;
case|case
name|NO_AND_SWAP
case|:
block|{
name|ETLSplitStrategy
name|oldBase
init|=
name|combinedCtx
operator|.
name|combined
decl_stmt|;
name|combinedCtx
operator|.
name|combined
operator|=
operator|new
name|ETLSplitStrategy
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|files
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
expr_stmt|;
name|combinedCtx
operator|.
name|combineStartUs
operator|=
name|System
operator|.
name|nanoTime
argument_list|()
expr_stmt|;
return|return
name|oldBase
return|;
block|}
default|default:
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unknown result "
operator|+
name|r
argument_list|)
throw|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|InputSplit
index|[]
name|getSplits
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|int
name|numSplits
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"getSplits started"
argument_list|)
expr_stmt|;
block|}
name|Configuration
name|conf
init|=
name|job
decl_stmt|;
if|if
condition|(
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|job
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_ORC_MS_FOOTER_CACHE_ENABLED
argument_list|)
condition|)
block|{
comment|// Create HiveConf once, since this is expensive.
name|conf
operator|=
operator|new
name|HiveConf
argument_list|(
name|conf
argument_list|,
name|OrcInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|OrcSplit
argument_list|>
name|result
init|=
name|generateSplitsInfo
argument_list|(
name|conf
argument_list|,
operator|new
name|Context
argument_list|(
name|conf
argument_list|,
name|numSplits
argument_list|,
name|createExternalCaches
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"getSplits finished"
argument_list|)
expr_stmt|;
block|}
return|return
name|result
operator|.
name|toArray
argument_list|(
operator|new
name|InputSplit
index|[
name|result
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
comment|/**    * FileInfo.    *    * Stores information relevant to split generation for an ORC File.    *    */
specifier|static
class|class
name|FileInfo
block|{
specifier|final
name|long
name|modificationTime
decl_stmt|;
specifier|final
name|long
name|size
decl_stmt|;
specifier|final
name|Long
name|fileId
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|StripeInformation
argument_list|>
name|stripeInfos
decl_stmt|;
specifier|private
name|FileMetaInfo
name|fileMetaInfo
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|OrcProto
operator|.
name|ColumnStatistics
argument_list|>
name|fileStats
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
decl_stmt|;
specifier|private
specifier|final
name|OrcFile
operator|.
name|WriterVersion
name|writerVersion
decl_stmt|;
name|FileInfo
parameter_list|(
name|long
name|modificationTime
parameter_list|,
name|long
name|size
parameter_list|,
name|List
argument_list|<
name|StripeInformation
argument_list|>
name|stripeInfos
parameter_list|,
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|ColumnStatistics
argument_list|>
name|fileStats
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|,
name|OrcFile
operator|.
name|WriterVersion
name|writerVersion
parameter_list|,
name|Long
name|fileId
parameter_list|)
block|{
name|this
operator|.
name|modificationTime
operator|=
name|modificationTime
expr_stmt|;
name|this
operator|.
name|size
operator|=
name|size
expr_stmt|;
name|this
operator|.
name|fileId
operator|=
name|fileId
expr_stmt|;
name|this
operator|.
name|stripeInfos
operator|=
name|stripeInfos
expr_stmt|;
name|this
operator|.
name|fileMetaInfo
operator|=
name|fileMetaInfo
expr_stmt|;
name|this
operator|.
name|stripeStats
operator|=
name|stripeStats
expr_stmt|;
name|this
operator|.
name|types
operator|=
name|types
expr_stmt|;
name|this
operator|.
name|fileStats
operator|=
name|fileStats
expr_stmt|;
name|this
operator|.
name|writerVersion
operator|=
name|writerVersion
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
name|createVectorizedReader
parameter_list|(
name|InputSplit
name|split
parameter_list|,
name|JobConf
name|conf
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
operator|)
operator|new
name|VectorizedOrcInputFormat
argument_list|()
operator|.
name|getRecordReader
argument_list|(
name|split
argument_list|,
name|conf
argument_list|,
name|reporter
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
name|getRecordReader
parameter_list|(
name|InputSplit
name|inputSplit
parameter_list|,
name|JobConf
name|conf
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|vectorMode
init|=
name|Utilities
operator|.
name|isVectorMode
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|boolean
name|isAcidRead
init|=
name|isAcidRead
argument_list|(
name|conf
argument_list|,
name|inputSplit
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|isAcidRead
condition|)
block|{
if|if
condition|(
name|vectorMode
condition|)
block|{
return|return
name|createVectorizedReader
argument_list|(
name|inputSplit
argument_list|,
name|conf
argument_list|,
name|reporter
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|OrcRecordReader
argument_list|(
name|OrcFile
operator|.
name|createReader
argument_list|(
operator|(
operator|(
name|FileSplit
operator|)
name|inputSplit
operator|)
operator|.
name|getPath
argument_list|()
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|,
name|conf
argument_list|,
operator|(
name|FileSplit
operator|)
name|inputSplit
argument_list|)
return|;
block|}
block|}
name|OrcSplit
name|split
init|=
operator|(
name|OrcSplit
operator|)
name|inputSplit
decl_stmt|;
name|reporter
operator|.
name|setStatus
argument_list|(
name|inputSplit
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Options
name|options
init|=
operator|new
name|Options
argument_list|(
name|conf
argument_list|)
operator|.
name|reporter
argument_list|(
name|reporter
argument_list|)
decl_stmt|;
specifier|final
name|RowReader
argument_list|<
name|OrcStruct
argument_list|>
name|inner
init|=
name|getReader
argument_list|(
name|inputSplit
argument_list|,
name|options
argument_list|)
decl_stmt|;
if|if
condition|(
name|vectorMode
condition|)
block|{
return|return
operator|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
operator|)
operator|new
name|VectorizedOrcAcidRowReader
argument_list|(
name|inner
argument_list|,
name|conf
argument_list|,
name|Utilities
operator|.
name|getMapWork
argument_list|(
name|conf
argument_list|)
operator|.
name|getVectorizedRowBatchCtx
argument_list|()
argument_list|,
operator|(
name|FileSplit
operator|)
name|inputSplit
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|NullKeyRecordReader
argument_list|(
name|inner
argument_list|,
name|conf
argument_list|)
return|;
block|}
block|}
comment|/**    * Return a RecordReader that is compatible with the Hive 0.12 reader    * with NullWritable for the key instead of RecordIdentifier.    */
specifier|public
specifier|static
specifier|final
class|class
name|NullKeyRecordReader
implements|implements
name|AcidRecordReader
argument_list|<
name|NullWritable
argument_list|,
name|OrcStruct
argument_list|>
block|{
specifier|private
specifier|final
name|RecordIdentifier
name|id
decl_stmt|;
specifier|private
specifier|final
name|RowReader
argument_list|<
name|OrcStruct
argument_list|>
name|inner
decl_stmt|;
annotation|@
name|Override
specifier|public
name|RecordIdentifier
name|getRecordIdentifier
parameter_list|()
block|{
return|return
name|id
return|;
block|}
specifier|private
name|NullKeyRecordReader
parameter_list|(
name|RowReader
argument_list|<
name|OrcStruct
argument_list|>
name|inner
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|inner
operator|=
name|inner
expr_stmt|;
name|id
operator|=
name|inner
operator|.
name|createKey
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|NullWritable
name|nullWritable
parameter_list|,
name|OrcStruct
name|orcStruct
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|inner
operator|.
name|next
argument_list|(
name|id
argument_list|,
name|orcStruct
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|NullWritable
name|createKey
parameter_list|()
block|{
return|return
name|NullWritable
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OrcStruct
name|createValue
parameter_list|()
block|{
return|return
name|inner
operator|.
name|createValue
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|inner
operator|.
name|getPos
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|inner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|inner
operator|.
name|getProgress
argument_list|()
return|;
block|}
block|}
comment|// The schema type description does not include the ACID fields (i.e. it is the
comment|// non-ACID original schema).
specifier|private
specifier|static
name|boolean
name|SCHEMA_TYPES_IS_ORIGINAL
init|=
literal|true
decl_stmt|;
annotation|@
name|Override
specifier|public
name|RowReader
argument_list|<
name|OrcStruct
argument_list|>
name|getReader
parameter_list|(
name|InputSplit
name|inputSplit
parameter_list|,
name|Options
name|options
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|OrcSplit
name|split
init|=
operator|(
name|OrcSplit
operator|)
name|inputSplit
decl_stmt|;
specifier|final
name|Path
name|path
init|=
name|split
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|root
decl_stmt|;
if|if
condition|(
name|split
operator|.
name|hasBase
argument_list|()
condition|)
block|{
if|if
condition|(
name|split
operator|.
name|isOriginal
argument_list|()
condition|)
block|{
name|root
operator|=
name|path
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|root
operator|=
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|root
operator|=
name|path
expr_stmt|;
block|}
specifier|final
name|Path
index|[]
name|deltas
init|=
name|AcidUtils
operator|.
name|deserializeDeltas
argument_list|(
name|root
argument_list|,
name|split
operator|.
name|getDeltas
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|Configuration
name|conf
init|=
name|options
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
comment|/**      * Do we have schema on read in the configuration variables?      */
name|TypeDescription
name|schema
init|=
name|getDesiredRowTypeDescr
argument_list|(
name|conf
argument_list|,
comment|/* isAcidRead */
literal|true
argument_list|)
decl_stmt|;
specifier|final
name|Reader
name|reader
decl_stmt|;
specifier|final
name|int
name|bucket
decl_stmt|;
name|Reader
operator|.
name|Options
name|readOptions
init|=
operator|new
name|Reader
operator|.
name|Options
argument_list|()
operator|.
name|schema
argument_list|(
name|schema
argument_list|)
decl_stmt|;
name|readOptions
operator|.
name|range
argument_list|(
name|split
operator|.
name|getStart
argument_list|()
argument_list|,
name|split
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// TODO: Convert genIncludedColumns and setSearchArgument to use TypeDescription.
specifier|final
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|schemaTypes
init|=
name|OrcUtils
operator|.
name|getOrcTypes
argument_list|(
name|schema
argument_list|)
decl_stmt|;
name|readOptions
operator|.
name|include
argument_list|(
name|genIncludedColumns
argument_list|(
name|schemaTypes
argument_list|,
name|conf
argument_list|,
name|SCHEMA_TYPES_IS_ORIGINAL
argument_list|)
argument_list|)
expr_stmt|;
name|setSearchArgument
argument_list|(
name|readOptions
argument_list|,
name|schemaTypes
argument_list|,
name|conf
argument_list|,
name|SCHEMA_TYPES_IS_ORIGINAL
argument_list|)
expr_stmt|;
if|if
condition|(
name|split
operator|.
name|hasBase
argument_list|()
condition|)
block|{
name|bucket
operator|=
name|AcidUtils
operator|.
name|parseBaseBucketFilename
argument_list|(
name|split
operator|.
name|getPath
argument_list|()
argument_list|,
name|conf
argument_list|)
operator|.
name|getBucket
argument_list|()
expr_stmt|;
name|reader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|path
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bucket
operator|=
operator|(
name|int
operator|)
name|split
operator|.
name|getStart
argument_list|()
expr_stmt|;
name|reader
operator|=
literal|null
expr_stmt|;
block|}
name|String
name|txnString
init|=
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|,
name|Long
operator|.
name|MAX_VALUE
operator|+
literal|":"
argument_list|)
decl_stmt|;
name|ValidTxnList
name|validTxnList
init|=
operator|new
name|ValidReadTxnList
argument_list|(
name|txnString
argument_list|)
decl_stmt|;
specifier|final
name|OrcRawRecordMerger
name|records
init|=
operator|new
name|OrcRawRecordMerger
argument_list|(
name|conf
argument_list|,
literal|true
argument_list|,
name|reader
argument_list|,
name|split
operator|.
name|isOriginal
argument_list|()
argument_list|,
name|bucket
argument_list|,
name|validTxnList
argument_list|,
name|readOptions
argument_list|,
name|deltas
argument_list|)
decl_stmt|;
return|return
operator|new
name|RowReader
argument_list|<
name|OrcStruct
argument_list|>
argument_list|()
block|{
name|OrcStruct
name|innerRecord
init|=
name|records
operator|.
name|createValue
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|ObjectInspector
name|getObjectInspector
parameter_list|()
block|{
return|return
name|OrcStruct
operator|.
name|createObjectInspector
argument_list|(
literal|0
argument_list|,
name|schemaTypes
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|RecordIdentifier
name|recordIdentifier
parameter_list|,
name|OrcStruct
name|orcStruct
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|result
decl_stmt|;
comment|// filter out the deleted records
do|do
block|{
name|result
operator|=
name|records
operator|.
name|next
argument_list|(
name|recordIdentifier
argument_list|,
name|innerRecord
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|result
operator|&&
name|OrcRecordUpdater
operator|.
name|getOperation
argument_list|(
name|innerRecord
argument_list|)
operator|==
name|OrcRecordUpdater
operator|.
name|DELETE_OPERATION
condition|)
do|;
if|if
condition|(
name|result
condition|)
block|{
comment|// swap the fields with the passed in orcStruct
name|orcStruct
operator|.
name|linkFields
argument_list|(
name|OrcRecordUpdater
operator|.
name|getRow
argument_list|(
name|innerRecord
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|RecordIdentifier
name|createKey
parameter_list|()
block|{
return|return
name|records
operator|.
name|createKey
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OrcStruct
name|createValue
parameter_list|()
block|{
return|return
operator|new
name|OrcStruct
argument_list|(
name|records
operator|.
name|getColumns
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|records
operator|.
name|getPos
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|records
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|float
name|getProgress
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|records
operator|.
name|getProgress
argument_list|()
return|;
block|}
block|}
return|;
block|}
specifier|static
name|Path
name|findOriginalBucket
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|directory
parameter_list|,
name|int
name|bucket
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|FileStatus
name|stat
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|directory
argument_list|)
control|)
block|{
name|String
name|name
init|=
name|stat
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|String
name|numberPart
init|=
name|name
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|name
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isNumeric
argument_list|(
name|numberPart
argument_list|)
operator|&&
name|Integer
operator|.
name|parseInt
argument_list|(
name|numberPart
argument_list|)
operator|==
name|bucket
condition|)
block|{
return|return
name|stat
operator|.
name|getPath
argument_list|()
return|;
block|}
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Can't find bucket "
operator|+
name|bucket
operator|+
literal|" in "
operator|+
name|directory
argument_list|)
throw|;
block|}
specifier|public
specifier|static
name|boolean
index|[]
name|pickStripesViaTranslatedSarg
parameter_list|(
name|SearchArgument
name|sarg
parameter_list|,
name|OrcFile
operator|.
name|WriterVersion
name|writerVersion
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
parameter_list|,
name|int
name|stripeCount
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Translated ORC pushdown predicate: "
operator|+
name|sarg
argument_list|)
expr_stmt|;
assert|assert
name|sarg
operator|!=
literal|null
assert|;
if|if
condition|(
name|stripeStats
operator|==
literal|null
operator|||
name|writerVersion
operator|==
name|OrcFile
operator|.
name|WriterVersion
operator|.
name|ORIGINAL
condition|)
block|{
return|return
literal|null
return|;
comment|// only do split pruning if HIVE-8732 has been fixed in the writer
block|}
comment|// eliminate stripes that doesn't satisfy the predicate condition
name|List
argument_list|<
name|PredicateLeaf
argument_list|>
name|sargLeaves
init|=
name|sarg
operator|.
name|getLeaves
argument_list|()
decl_stmt|;
name|int
index|[]
name|filterColumns
init|=
name|RecordReaderImpl
operator|.
name|mapTranslatedSargColumns
argument_list|(
name|types
argument_list|,
name|sargLeaves
argument_list|)
decl_stmt|;
return|return
name|pickStripesInternal
argument_list|(
name|sarg
argument_list|,
name|filterColumns
argument_list|,
name|stripeStats
argument_list|,
name|stripeCount
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|boolean
index|[]
name|pickStripes
parameter_list|(
name|SearchArgument
name|sarg
parameter_list|,
name|String
index|[]
name|sargColNames
parameter_list|,
name|OrcFile
operator|.
name|WriterVersion
name|writerVersion
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
parameter_list|,
name|int
name|stripeCount
parameter_list|,
name|Path
name|filePath
parameter_list|)
block|{
if|if
condition|(
name|sarg
operator|==
literal|null
operator|||
name|stripeStats
operator|==
literal|null
operator|||
name|writerVersion
operator|==
name|OrcFile
operator|.
name|WriterVersion
operator|.
name|ORIGINAL
condition|)
block|{
return|return
literal|null
return|;
comment|// only do split pruning if HIVE-8732 has been fixed in the writer
block|}
comment|// eliminate stripes that doesn't satisfy the predicate condition
name|List
argument_list|<
name|PredicateLeaf
argument_list|>
name|sargLeaves
init|=
name|sarg
operator|.
name|getLeaves
argument_list|()
decl_stmt|;
name|int
index|[]
name|filterColumns
init|=
name|RecordReaderImpl
operator|.
name|mapSargColumnsToOrcInternalColIdx
argument_list|(
name|sargLeaves
argument_list|,
name|sargColNames
argument_list|,
name|getRootColumn
argument_list|(
name|isOriginal
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|pickStripesInternal
argument_list|(
name|sarg
argument_list|,
name|filterColumns
argument_list|,
name|stripeStats
argument_list|,
name|stripeCount
argument_list|,
name|filePath
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|boolean
index|[]
name|pickStripesInternal
parameter_list|(
name|SearchArgument
name|sarg
parameter_list|,
name|int
index|[]
name|filterColumns
parameter_list|,
name|List
argument_list|<
name|StripeStatistics
argument_list|>
name|stripeStats
parameter_list|,
name|int
name|stripeCount
parameter_list|,
name|Path
name|filePath
parameter_list|)
block|{
name|boolean
index|[]
name|includeStripe
init|=
operator|new
name|boolean
index|[
name|stripeCount
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|includeStripe
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|includeStripe
index|[
name|i
index|]
operator|=
operator|(
name|i
operator|>=
name|stripeStats
operator|.
name|size
argument_list|()
operator|)
operator|||
name|isStripeSatisfyPredicate
argument_list|(
name|stripeStats
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|sarg
argument_list|,
name|filterColumns
argument_list|)
expr_stmt|;
if|if
condition|(
name|isDebugEnabled
operator|&&
operator|!
name|includeStripe
index|[
name|i
index|]
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Eliminating ORC stripe-"
operator|+
name|i
operator|+
literal|" of file '"
operator|+
name|filePath
operator|+
literal|"'  as it did not satisfy predicate condition."
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|includeStripe
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isStripeSatisfyPredicate
parameter_list|(
name|StripeStatistics
name|stripeStatistics
parameter_list|,
name|SearchArgument
name|sarg
parameter_list|,
name|int
index|[]
name|filterColumns
parameter_list|)
block|{
name|List
argument_list|<
name|PredicateLeaf
argument_list|>
name|predLeaves
init|=
name|sarg
operator|.
name|getLeaves
argument_list|()
decl_stmt|;
name|TruthValue
index|[]
name|truthValues
init|=
operator|new
name|TruthValue
index|[
name|predLeaves
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|pred
init|=
literal|0
init|;
name|pred
operator|<
name|truthValues
operator|.
name|length
condition|;
name|pred
operator|++
control|)
block|{
if|if
condition|(
name|filterColumns
index|[
name|pred
index|]
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// column statistics at index 0 contains only the number of rows
name|ColumnStatistics
name|stats
init|=
name|stripeStatistics
operator|.
name|getColumnStatistics
argument_list|()
index|[
name|filterColumns
index|[
name|pred
index|]
index|]
decl_stmt|;
name|truthValues
index|[
name|pred
index|]
operator|=
name|RecordReaderImpl
operator|.
name|evaluatePredicate
argument_list|(
name|stats
argument_list|,
name|predLeaves
operator|.
name|get
argument_list|(
name|pred
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// parition column case.
comment|// partition filter will be evaluated by partition pruner so
comment|// we will not evaluate partition filter here.
name|truthValues
index|[
name|pred
index|]
operator|=
name|TruthValue
operator|.
name|YES_NO_NULL
expr_stmt|;
block|}
block|}
return|return
name|sarg
operator|.
name|evaluate
argument_list|(
name|truthValues
argument_list|)
operator|.
name|isNeeded
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|static
name|SplitStrategy
argument_list|<
name|?
argument_list|>
name|determineSplitStrategy
parameter_list|(
name|CombinedCtx
name|combinedCtx
parameter_list|,
name|Context
name|context
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|AcidUtils
operator|.
name|Directory
name|dirInfo
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|baseOrOriginalFiles
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|,
name|boolean
name|allowSyntheticFileIds
parameter_list|)
block|{
name|Path
name|base
init|=
name|dirInfo
operator|.
name|getBaseDirectory
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
init|=
name|dirInfo
operator|.
name|getOriginalFiles
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|DeltaMetaData
argument_list|>
name|deltas
init|=
name|AcidUtils
operator|.
name|serializeDeltas
argument_list|(
name|dirInfo
operator|.
name|getCurrentDirectories
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
index|[]
name|covered
init|=
operator|new
name|boolean
index|[
name|context
operator|.
name|numBuckets
index|]
decl_stmt|;
name|boolean
name|isOriginal
init|=
name|base
operator|==
literal|null
decl_stmt|;
comment|// if we have a base to work from
if|if
condition|(
name|base
operator|!=
literal|null
operator|||
operator|!
name|original
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|long
name|totalFileSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|baseOrOriginalFiles
control|)
block|{
name|totalFileSize
operator|+=
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getLen
argument_list|()
expr_stmt|;
name|AcidOutputFormat
operator|.
name|Options
name|opts
init|=
name|AcidUtils
operator|.
name|parseBaseBucketFilename
argument_list|(
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|,
name|context
operator|.
name|conf
argument_list|)
decl_stmt|;
name|int
name|b
init|=
name|opts
operator|.
name|getBucket
argument_list|()
decl_stmt|;
comment|// If the bucket is in the valid range, mark it as covered.
comment|// I wish Hive actually enforced bucketing all of the time.
if|if
condition|(
name|b
operator|>=
literal|0
operator|&&
name|b
operator|<
name|covered
operator|.
name|length
condition|)
block|{
name|covered
index|[
name|b
index|]
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|int
name|numFiles
init|=
name|baseOrOriginalFiles
operator|.
name|size
argument_list|()
decl_stmt|;
name|long
name|avgFileSize
init|=
name|totalFileSize
operator|/
name|numFiles
decl_stmt|;
name|int
name|totalFiles
init|=
name|context
operator|.
name|numFilesCounter
operator|.
name|addAndGet
argument_list|(
name|numFiles
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|context
operator|.
name|splitStrategyKind
condition|)
block|{
case|case
name|BI
case|:
comment|// BI strategy requested through config
return|return
operator|new
name|BISplitStrategy
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|baseOrOriginalFiles
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|allowSyntheticFileIds
argument_list|)
return|;
case|case
name|ETL
case|:
comment|// ETL strategy requested through config
return|return
name|combineOrCreateETLStrategy
argument_list|(
name|combinedCtx
argument_list|,
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|baseOrOriginalFiles
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|isOriginal
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
return|;
default|default:
comment|// HYBRID strategy
if|if
condition|(
name|avgFileSize
operator|>
name|context
operator|.
name|maxSize
operator|||
name|totalFiles
operator|<=
name|context
operator|.
name|minSplits
condition|)
block|{
return|return
name|combineOrCreateETLStrategy
argument_list|(
name|combinedCtx
argument_list|,
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|baseOrOriginalFiles
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|isOriginal
argument_list|,
name|ugi
argument_list|,
name|allowSyntheticFileIds
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|BISplitStrategy
argument_list|(
name|context
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|,
name|baseOrOriginalFiles
argument_list|,
name|isOriginal
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|,
name|allowSyntheticFileIds
argument_list|)
return|;
block|}
block|}
block|}
else|else
block|{
comment|// no base, only deltas
return|return
operator|new
name|ACIDSplitStrategy
argument_list|(
name|dir
argument_list|,
name|context
operator|.
name|numBuckets
argument_list|,
name|deltas
argument_list|,
name|covered
argument_list|)
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|RawReader
argument_list|<
name|OrcStruct
argument_list|>
name|getRawReader
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|collapseEvents
parameter_list|,
name|int
name|bucket
parameter_list|,
name|ValidTxnList
name|validTxnList
parameter_list|,
name|Path
name|baseDirectory
parameter_list|,
name|Path
index|[]
name|deltaDirectory
parameter_list|)
throws|throws
name|IOException
block|{
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
name|boolean
name|isOriginal
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|baseDirectory
operator|!=
literal|null
condition|)
block|{
name|Path
name|bucketFile
decl_stmt|;
if|if
condition|(
name|baseDirectory
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|AcidUtils
operator|.
name|BASE_PREFIX
argument_list|)
condition|)
block|{
name|bucketFile
operator|=
name|AcidUtils
operator|.
name|createBucketFile
argument_list|(
name|baseDirectory
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|isOriginal
operator|=
literal|true
expr_stmt|;
name|bucketFile
operator|=
name|findOriginalBucket
argument_list|(
name|baseDirectory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|baseDirectory
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
block|}
name|reader
operator|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|bucketFile
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|OrcRawRecordMerger
argument_list|(
name|conf
argument_list|,
name|collapseEvents
argument_list|,
name|reader
argument_list|,
name|isOriginal
argument_list|,
name|bucket
argument_list|,
name|validTxnList
argument_list|,
operator|new
name|Reader
operator|.
name|Options
argument_list|()
argument_list|,
name|deltaDirectory
argument_list|)
return|;
block|}
comment|/**    * Represents footer cache.    */
specifier|public
interface|interface
name|FooterCache
block|{
specifier|static
specifier|final
name|ByteBuffer
name|NO_SPLIT_AFTER_PPD
init|=
name|ByteBuffer
operator|.
name|wrap
argument_list|(
operator|new
name|byte
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|void
name|getAndValidate
parameter_list|(
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|files
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|FileInfo
index|[]
name|result
parameter_list|,
name|ByteBuffer
index|[]
name|ppdResult
parameter_list|)
throws|throws
name|IOException
throws|,
name|HiveException
function_decl|;
name|boolean
name|hasPpd
parameter_list|()
function_decl|;
name|boolean
name|isBlocking
parameter_list|()
function_decl|;
name|void
name|put
parameter_list|(
name|Long
name|fileId
parameter_list|,
name|FileStatus
name|file
parameter_list|,
name|FileMetaInfo
name|fileMetaInfo
parameter_list|,
name|Reader
name|orcReader
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/**    * Convert a Hive type property string that contains separated type names into a list of    * TypeDescription objects.    * @return the list of TypeDescription objects.    */
specifier|public
specifier|static
name|ArrayList
argument_list|<
name|TypeDescription
argument_list|>
name|typeDescriptionsFromHiveTypeProperty
parameter_list|(
name|String
name|hiveTypeProperty
parameter_list|)
block|{
comment|// CONSDIER: We need a type name parser for TypeDescription.
name|ArrayList
argument_list|<
name|TypeInfo
argument_list|>
name|typeInfoList
init|=
name|TypeInfoUtils
operator|.
name|getTypeInfosFromTypeString
argument_list|(
name|hiveTypeProperty
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|TypeDescription
argument_list|>
name|typeDescrList
init|=
operator|new
name|ArrayList
argument_list|<
name|TypeDescription
argument_list|>
argument_list|(
name|typeInfoList
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|TypeInfo
name|typeInfo
range|:
name|typeInfoList
control|)
block|{
name|typeDescrList
operator|.
name|add
argument_list|(
name|convertTypeInfo
argument_list|(
name|typeInfo
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|typeDescrList
return|;
block|}
specifier|public
specifier|static
name|TypeDescription
name|convertTypeInfo
parameter_list|(
name|TypeInfo
name|info
parameter_list|)
block|{
switch|switch
condition|(
name|info
operator|.
name|getCategory
argument_list|()
condition|)
block|{
case|case
name|PRIMITIVE
case|:
block|{
name|PrimitiveTypeInfo
name|pinfo
init|=
operator|(
name|PrimitiveTypeInfo
operator|)
name|info
decl_stmt|;
switch|switch
condition|(
name|pinfo
operator|.
name|getPrimitiveCategory
argument_list|()
condition|)
block|{
case|case
name|BOOLEAN
case|:
return|return
name|TypeDescription
operator|.
name|createBoolean
argument_list|()
return|;
case|case
name|BYTE
case|:
return|return
name|TypeDescription
operator|.
name|createByte
argument_list|()
return|;
case|case
name|SHORT
case|:
return|return
name|TypeDescription
operator|.
name|createShort
argument_list|()
return|;
case|case
name|INT
case|:
return|return
name|TypeDescription
operator|.
name|createInt
argument_list|()
return|;
case|case
name|LONG
case|:
return|return
name|TypeDescription
operator|.
name|createLong
argument_list|()
return|;
case|case
name|FLOAT
case|:
return|return
name|TypeDescription
operator|.
name|createFloat
argument_list|()
return|;
case|case
name|DOUBLE
case|:
return|return
name|TypeDescription
operator|.
name|createDouble
argument_list|()
return|;
case|case
name|STRING
case|:
return|return
name|TypeDescription
operator|.
name|createString
argument_list|()
return|;
case|case
name|DATE
case|:
return|return
name|TypeDescription
operator|.
name|createDate
argument_list|()
return|;
case|case
name|TIMESTAMP
case|:
return|return
name|TypeDescription
operator|.
name|createTimestamp
argument_list|()
return|;
case|case
name|BINARY
case|:
return|return
name|TypeDescription
operator|.
name|createBinary
argument_list|()
return|;
case|case
name|DECIMAL
case|:
block|{
name|DecimalTypeInfo
name|dinfo
init|=
operator|(
name|DecimalTypeInfo
operator|)
name|pinfo
decl_stmt|;
return|return
name|TypeDescription
operator|.
name|createDecimal
argument_list|()
operator|.
name|withScale
argument_list|(
name|dinfo
operator|.
name|getScale
argument_list|()
argument_list|)
operator|.
name|withPrecision
argument_list|(
name|dinfo
operator|.
name|getPrecision
argument_list|()
argument_list|)
return|;
block|}
case|case
name|VARCHAR
case|:
block|{
name|BaseCharTypeInfo
name|cinfo
init|=
operator|(
name|BaseCharTypeInfo
operator|)
name|pinfo
decl_stmt|;
return|return
name|TypeDescription
operator|.
name|createVarchar
argument_list|()
operator|.
name|withMaxLength
argument_list|(
name|cinfo
operator|.
name|getLength
argument_list|()
argument_list|)
return|;
block|}
case|case
name|CHAR
case|:
block|{
name|BaseCharTypeInfo
name|cinfo
init|=
operator|(
name|BaseCharTypeInfo
operator|)
name|pinfo
decl_stmt|;
return|return
name|TypeDescription
operator|.
name|createChar
argument_list|()
operator|.
name|withMaxLength
argument_list|(
name|cinfo
operator|.
name|getLength
argument_list|()
argument_list|)
return|;
block|}
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"ORC doesn't handle primitive"
operator|+
literal|" category "
operator|+
name|pinfo
operator|.
name|getPrimitiveCategory
argument_list|()
argument_list|)
throw|;
block|}
block|}
case|case
name|LIST
case|:
block|{
name|ListTypeInfo
name|linfo
init|=
operator|(
name|ListTypeInfo
operator|)
name|info
decl_stmt|;
return|return
name|TypeDescription
operator|.
name|createList
argument_list|(
name|convertTypeInfo
argument_list|(
name|linfo
operator|.
name|getListElementTypeInfo
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
case|case
name|MAP
case|:
block|{
name|MapTypeInfo
name|minfo
init|=
operator|(
name|MapTypeInfo
operator|)
name|info
decl_stmt|;
return|return
name|TypeDescription
operator|.
name|createMap
argument_list|(
name|convertTypeInfo
argument_list|(
name|minfo
operator|.
name|getMapKeyTypeInfo
argument_list|()
argument_list|)
argument_list|,
name|convertTypeInfo
argument_list|(
name|minfo
operator|.
name|getMapValueTypeInfo
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
case|case
name|UNION
case|:
block|{
name|UnionTypeInfo
name|minfo
init|=
operator|(
name|UnionTypeInfo
operator|)
name|info
decl_stmt|;
name|TypeDescription
name|result
init|=
name|TypeDescription
operator|.
name|createUnion
argument_list|()
decl_stmt|;
for|for
control|(
name|TypeInfo
name|child
range|:
name|minfo
operator|.
name|getAllUnionObjectTypeInfos
argument_list|()
control|)
block|{
name|result
operator|.
name|addUnionChild
argument_list|(
name|convertTypeInfo
argument_list|(
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
case|case
name|STRUCT
case|:
block|{
name|StructTypeInfo
name|sinfo
init|=
operator|(
name|StructTypeInfo
operator|)
name|info
decl_stmt|;
name|TypeDescription
name|result
init|=
name|TypeDescription
operator|.
name|createStruct
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|fieldName
range|:
name|sinfo
operator|.
name|getAllStructFieldNames
argument_list|()
control|)
block|{
name|result
operator|.
name|addField
argument_list|(
name|fieldName
argument_list|,
name|convertTypeInfo
argument_list|(
name|sinfo
operator|.
name|getStructFieldTypeInfo
argument_list|(
name|fieldName
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"ORC doesn't handle "
operator|+
name|info
operator|.
name|getCategory
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|TypeDescription
name|getDesiredRowTypeDescr
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|isAcidRead
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|columnNameProperty
init|=
literal|null
decl_stmt|;
name|String
name|columnTypeProperty
init|=
literal|null
decl_stmt|;
name|ArrayList
argument_list|<
name|String
argument_list|>
name|schemaEvolutionColumnNames
init|=
literal|null
decl_stmt|;
name|ArrayList
argument_list|<
name|TypeDescription
argument_list|>
name|schemaEvolutionTypeDescrs
init|=
literal|null
decl_stmt|;
name|boolean
name|haveSchemaEvolutionProperties
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|isAcidRead
operator|||
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_SCHEMA_EVOLUTION
argument_list|)
condition|)
block|{
name|columnNameProperty
operator|=
name|conf
operator|.
name|get
argument_list|(
name|IOConstants
operator|.
name|SCHEMA_EVOLUTION_COLUMNS
argument_list|)
expr_stmt|;
name|columnTypeProperty
operator|=
name|conf
operator|.
name|get
argument_list|(
name|IOConstants
operator|.
name|SCHEMA_EVOLUTION_COLUMNS_TYPES
argument_list|)
expr_stmt|;
name|haveSchemaEvolutionProperties
operator|=
operator|(
name|columnNameProperty
operator|!=
literal|null
operator|&&
name|columnTypeProperty
operator|!=
literal|null
operator|)
expr_stmt|;
if|if
condition|(
name|haveSchemaEvolutionProperties
condition|)
block|{
name|schemaEvolutionColumnNames
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|columnNameProperty
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|schemaEvolutionColumnNames
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|haveSchemaEvolutionProperties
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|schemaEvolutionTypeDescrs
operator|=
name|typeDescriptionsFromHiveTypeProperty
argument_list|(
name|columnTypeProperty
argument_list|)
expr_stmt|;
if|if
condition|(
name|schemaEvolutionTypeDescrs
operator|.
name|size
argument_list|()
operator|!=
name|schemaEvolutionColumnNames
operator|.
name|size
argument_list|()
condition|)
block|{
name|haveSchemaEvolutionProperties
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|isAcidRead
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|SCHEMA_REQUIRED_TO_READ_ACID_TABLES
operator|.
name|getErrorCodedMsg
argument_list|()
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|haveSchemaEvolutionProperties
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Using schema evolution configuration variables schema.evolution.columns "
operator|+
name|schemaEvolutionColumnNames
operator|.
name|toString
argument_list|()
operator|+
literal|" / schema.evolution.columns.types "
operator|+
name|schemaEvolutionTypeDescrs
operator|.
name|toString
argument_list|()
operator|+
literal|" (isAcidRead "
operator|+
name|isAcidRead
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Try regular properties;
name|columnNameProperty
operator|=
name|conf
operator|.
name|get
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMNS
argument_list|)
expr_stmt|;
name|columnTypeProperty
operator|=
name|conf
operator|.
name|get
argument_list|(
name|serdeConstants
operator|.
name|LIST_COLUMN_TYPES
argument_list|)
expr_stmt|;
if|if
condition|(
name|columnTypeProperty
operator|==
literal|null
operator|||
name|columnNameProperty
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|schemaEvolutionColumnNames
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|columnNameProperty
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|schemaEvolutionColumnNames
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
name|schemaEvolutionTypeDescrs
operator|=
name|typeDescriptionsFromHiveTypeProperty
argument_list|(
name|columnTypeProperty
argument_list|)
expr_stmt|;
if|if
condition|(
name|schemaEvolutionTypeDescrs
operator|.
name|size
argument_list|()
operator|!=
name|schemaEvolutionColumnNames
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Find first virtual column and clip them off.
name|int
name|virtualColumnClipNum
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|columnNum
init|=
literal|0
decl_stmt|;
for|for
control|(
name|String
name|columnName
range|:
name|schemaEvolutionColumnNames
control|)
block|{
if|if
condition|(
name|VirtualColumn
operator|.
name|VIRTUAL_COLUMN_NAMES
operator|.
name|contains
argument_list|(
name|columnName
argument_list|)
condition|)
block|{
name|virtualColumnClipNum
operator|=
name|columnNum
expr_stmt|;
break|break;
block|}
name|columnNum
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|virtualColumnClipNum
operator|!=
operator|-
literal|1
condition|)
block|{
name|schemaEvolutionColumnNames
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|schemaEvolutionColumnNames
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|virtualColumnClipNum
argument_list|)
argument_list|)
expr_stmt|;
name|schemaEvolutionTypeDescrs
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|schemaEvolutionTypeDescrs
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|virtualColumnClipNum
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Using column configuration variables columns "
operator|+
name|schemaEvolutionColumnNames
operator|.
name|toString
argument_list|()
operator|+
literal|" / columns.types "
operator|+
name|schemaEvolutionTypeDescrs
operator|.
name|toString
argument_list|()
operator|+
literal|" (isAcidRead "
operator|+
name|isAcidRead
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Desired schema does not include virtual columns or partition columns.
name|TypeDescription
name|result
init|=
name|TypeDescription
operator|.
name|createStruct
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|schemaEvolutionColumnNames
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|result
operator|.
name|addField
argument_list|(
name|schemaEvolutionColumnNames
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|schemaEvolutionTypeDescrs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|protected
name|ExternalFooterCachesByConf
name|createExternalCaches
parameter_list|()
block|{
return|return
literal|null
return|;
comment|// The default ones are created in case of null; tests override this.
block|}
block|}
end_class

end_unit

