begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Field
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|IdentityHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|Pool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|Pool
operator|.
name|PoolObjectHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|Allocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DataCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DiskRange
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DiskRangeList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DataCache
operator|.
name|BooleanRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DataCache
operator|.
name|DiskRangeListFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DiskRangeList
operator|.
name|CreateHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|DiskRangeList
operator|.
name|MutateHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|encoded
operator|.
name|EncodedColumnBatch
operator|.
name|ColumnStreamData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|io
operator|.
name|encoded
operator|.
name|MemoryBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionKind
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|DataReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcFile
operator|.
name|WriterVersion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
operator|.
name|ColumnEncoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
operator|.
name|Stream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|TypeDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|InStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OrcCodecPool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OrcIndex
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OutStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|RecordReaderUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|StreamName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|RecordReaderImpl
operator|.
name|SargApplier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|StreamName
operator|.
name|Area
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|WriterImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|StripeInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|BufferChunk
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|IoTrace
operator|.
name|RangesSrc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|Reader
operator|.
name|OrcEncodedColumnBatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|encoded
operator|.
name|Reader
operator|.
name|PoolFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|zlib
operator|.
name|ZlibDecompressor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|zlib
operator|.
name|ZlibDecompressor
operator|.
name|ZlibDirectDecompressor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|CodedInputStream
import|;
end_import

begin_import
import|import
name|sun
operator|.
name|misc
operator|.
name|Cleaner
import|;
end_import

begin_comment
comment|/**  * Encoded reader implementation.  *  * Note about refcounts on cache blocks.  * When we get or put blocks into cache, they are "locked" (refcount++), so they cannot be evicted.  * We send the MemoryBuffer-s to caller as part of RG data; one MemoryBuffer can be used for many  * RGs (e.g. a dictionary, or multiple RGs per block). Also, we want to "unlock" MemoryBuffer-s in  * cache as soon as possible. This is how we deal with this:  *  * For dictionary case:  * 1) There's a separate refcount on the ColumnStreamData object we send to the caller. In the  *    dictionary case, it's increased per RG, and callers don't release MBs if the containing  *    ColumnStreamData is not ready to be released. This is done because dictionary can have many  *    buffers; decrefing all of them for all RGs is more expensive; plus, decrefing in cache  *    may be more expensive due to cache policy/etc.  *  * For non-dictionary case:  * 1) All the ColumnStreamData-s for normal data always have refcount 1; we return them once.  * 2) At all times, every MB in such cases has +1 refcount for each time we return it as part of CSD.  * 3) When caller is done, it therefore decrefs SB to 0, and decrefs all the MBs involved.  * 4) Additionally, we keep an extra +1 refcount "for the fetching thread". That way, if we return  *    the MB to caller, and he decrefs it, the MB can't be evicted and will be there if we want to  *    reuse it for some other RG.  * 5) As we read (we always read RGs in order and forward in each stream; we assume they are stored  *    physically in order in the file; AND that CBs are not shared between streams), we note which  *    MBs cannot possibly be reused anymore (next RG starts in the next CB). We decref the refcount  *    from (4) in such case.  * 6) Given that RG end boundaries in ORC are estimates, we can request data from cache and then  *    not use it; thus, at the end we go thru all the MBs, and release those not released by (5).  */
end_comment

begin_comment
comment|// Note: this thing should know nothing about ACID or schema. It reads physical columns by index;
end_comment

begin_comment
comment|//       schema evolution/ACID schema considerations should be on higher level.
end_comment

begin_class
class|class
name|EncodedReaderImpl
implements|implements
name|EncodedReader
block|{
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|EncodedReaderImpl
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
name|Field
name|cleanerField
decl_stmt|;
static|static
block|{
try|try
block|{
comment|// TODO: To make it work for JDK9 use CleanerUtil from https://issues.apache.org/jira/browse/HADOOP-12760
specifier|final
name|Class
argument_list|<
name|?
argument_list|>
name|dbClazz
init|=
name|Class
operator|.
name|forName
argument_list|(
literal|"java.nio.DirectByteBuffer"
argument_list|)
decl_stmt|;
name|cleanerField
operator|=
name|dbClazz
operator|.
name|getDeclaredField
argument_list|(
literal|"cleaner"
argument_list|)
expr_stmt|;
name|cleanerField
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|cleanerField
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
specifier|final
name|Object
name|POOLS_CREATION_LOCK
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
specifier|static
name|Pools
name|POOLS
decl_stmt|;
specifier|private
specifier|static
class|class
name|Pools
block|{
name|Pool
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
name|ecbPool
decl_stmt|;
name|Pool
argument_list|<
name|ColumnStreamData
argument_list|>
name|csdPool
decl_stmt|;
block|}
specifier|private
specifier|final
specifier|static
name|DiskRangeListFactory
name|CC_FACTORY
init|=
operator|new
name|DiskRangeListFactory
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DiskRangeList
name|createCacheChunk
parameter_list|(
name|MemoryBuffer
name|buffer
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|end
parameter_list|)
block|{
return|return
operator|new
name|CacheChunk
argument_list|(
name|buffer
argument_list|,
name|offset
argument_list|,
name|end
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|private
specifier|final
name|Object
name|fileKey
decl_stmt|;
specifier|private
specifier|final
name|DataReader
name|dataReader
decl_stmt|;
specifier|private
name|boolean
name|isDataReaderOpen
init|=
literal|false
decl_stmt|;
specifier|private
name|CompressionCodec
name|codec
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isCodecFromPool
decl_stmt|;
specifier|private
name|boolean
name|isCodecFailure
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isCompressed
decl_stmt|;
specifier|private
specifier|final
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionKind
name|compressionKind
decl_stmt|;
specifier|private
specifier|final
name|int
name|bufferSize
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
decl_stmt|;
specifier|private
specifier|final
name|long
name|rowIndexStride
decl_stmt|;
specifier|private
specifier|final
name|DataCache
name|cacheWrapper
decl_stmt|;
specifier|private
name|boolean
name|isTracingEnabled
decl_stmt|;
specifier|private
specifier|final
name|IoTrace
name|trace
decl_stmt|;
specifier|private
specifier|final
name|TypeDescription
name|fileSchema
decl_stmt|;
specifier|private
specifier|final
name|WriterVersion
name|version
decl_stmt|;
specifier|private
specifier|final
name|String
name|tag
decl_stmt|;
specifier|private
name|AtomicBoolean
name|isStopped
decl_stmt|;
specifier|private
name|StoppableAllocator
name|allocator
decl_stmt|;
specifier|public
name|EncodedReaderImpl
parameter_list|(
name|Object
name|fileKey
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Type
argument_list|>
name|types
parameter_list|,
name|TypeDescription
name|fileSchema
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionKind
name|kind
parameter_list|,
name|WriterVersion
name|version
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|long
name|strideRate
parameter_list|,
name|DataCache
name|cacheWrapper
parameter_list|,
name|DataReader
name|dataReader
parameter_list|,
name|PoolFactory
name|pf
parameter_list|,
name|IoTrace
name|trace
parameter_list|,
name|boolean
name|useCodecPool
parameter_list|,
name|String
name|tag
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fileKey
operator|=
name|fileKey
expr_stmt|;
name|this
operator|.
name|compressionKind
operator|=
name|kind
expr_stmt|;
name|this
operator|.
name|isCompressed
operator|=
name|kind
operator|!=
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|CompressionKind
operator|.
name|NONE
expr_stmt|;
name|this
operator|.
name|isCodecFromPool
operator|=
name|useCodecPool
expr_stmt|;
name|this
operator|.
name|codec
operator|=
name|useCodecPool
condition|?
name|OrcCodecPool
operator|.
name|getCodec
argument_list|(
name|kind
argument_list|)
else|:
name|WriterImpl
operator|.
name|createCodec
argument_list|(
name|kind
argument_list|)
expr_stmt|;
name|this
operator|.
name|types
operator|=
name|types
expr_stmt|;
name|this
operator|.
name|fileSchema
operator|=
name|fileSchema
expr_stmt|;
comment|// Note: this is redundant with types
name|this
operator|.
name|version
operator|=
name|version
expr_stmt|;
name|this
operator|.
name|bufferSize
operator|=
name|bufferSize
expr_stmt|;
name|this
operator|.
name|rowIndexStride
operator|=
name|strideRate
expr_stmt|;
name|this
operator|.
name|cacheWrapper
operator|=
name|cacheWrapper
expr_stmt|;
name|Allocator
name|alloc
init|=
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
decl_stmt|;
name|this
operator|.
name|allocator
operator|=
name|alloc
operator|instanceof
name|StoppableAllocator
condition|?
operator|(
name|StoppableAllocator
operator|)
name|alloc
else|:
literal|null
expr_stmt|;
name|this
operator|.
name|dataReader
operator|=
name|dataReader
expr_stmt|;
name|this
operator|.
name|trace
operator|=
name|trace
expr_stmt|;
name|this
operator|.
name|tag
operator|=
name|tag
expr_stmt|;
if|if
condition|(
name|POOLS
operator|!=
literal|null
condition|)
return|return;
if|if
condition|(
name|pf
operator|==
literal|null
condition|)
block|{
name|pf
operator|=
operator|new
name|NoopPoolFactory
argument_list|()
expr_stmt|;
block|}
name|Pools
name|pools
init|=
name|createPools
argument_list|(
name|pf
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|POOLS_CREATION_LOCK
init|)
block|{
if|if
condition|(
name|POOLS
operator|!=
literal|null
condition|)
return|return;
name|POOLS
operator|=
name|pools
expr_stmt|;
block|}
block|}
comment|/** Helper context for each column being read */
specifier|private
specifier|static
specifier|final
class|class
name|ColumnReadContext
extends|extends
name|ReadContext
block|{
specifier|public
name|ColumnReadContext
parameter_list|(
name|int
name|colIx
parameter_list|,
name|OrcProto
operator|.
name|ColumnEncoding
name|encoding
parameter_list|,
name|OrcProto
operator|.
name|RowIndex
name|rowIndex
parameter_list|,
name|int
name|colRgIx
parameter_list|)
block|{
name|super
argument_list|(
name|colIx
argument_list|,
name|colRgIx
argument_list|,
name|MAX_STREAMS
argument_list|)
expr_stmt|;
name|this
operator|.
name|encoding
operator|=
name|encoding
expr_stmt|;
name|this
operator|.
name|rowIndex
operator|=
name|rowIndex
expr_stmt|;
block|}
specifier|public
specifier|static
specifier|final
name|int
name|MAX_STREAMS
init|=
name|countMaxStreams
argument_list|(
name|Area
operator|.
name|DATA
argument_list|)
decl_stmt|;
comment|/** Column encoding. */
name|OrcProto
operator|.
name|ColumnEncoding
name|encoding
decl_stmt|;
comment|/** Column rowindex. */
name|OrcProto
operator|.
name|RowIndex
name|rowIndex
decl_stmt|;
specifier|public
name|void
name|addStream
parameter_list|(
name|long
name|offset
parameter_list|,
name|OrcProto
operator|.
name|Stream
name|stream
parameter_list|,
name|int
name|indexIx
parameter_list|)
block|{
name|streams
index|[
name|streamCount
operator|++
index|]
operator|=
operator|new
name|StreamContext
argument_list|(
name|stream
argument_list|,
name|offset
argument_list|,
name|indexIx
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" column_index: "
argument_list|)
operator|.
name|append
argument_list|(
name|colIx
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" included_index: "
argument_list|)
operator|.
name|append
argument_list|(
name|includedIx
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" encoding: "
argument_list|)
operator|.
name|append
argument_list|(
name|encoding
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" stream_count: "
argument_list|)
operator|.
name|append
argument_list|(
name|streamCount
argument_list|)
expr_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StreamContext
name|sc
range|:
name|streams
control|)
block|{
if|if
condition|(
name|sc
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|" stream_"
argument_list|)
operator|.
name|append
argument_list|(
name|i
argument_list|)
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
operator|.
name|append
argument_list|(
name|sc
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|i
operator|++
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|/** Helper context for each column for which the index is being read */
specifier|private
specifier|static
class|class
name|ReadContext
block|{
specifier|protected
name|ReadContext
parameter_list|(
name|int
name|colIx
parameter_list|,
name|int
name|colRgIx
parameter_list|,
name|int
name|maxStreams
parameter_list|)
block|{
name|this
operator|.
name|colIx
operator|=
name|colIx
expr_stmt|;
name|this
operator|.
name|includedIx
operator|=
name|colRgIx
expr_stmt|;
name|streamCount
operator|=
literal|0
expr_stmt|;
name|streams
operator|=
operator|new
name|StreamContext
index|[
name|maxStreams
index|]
expr_stmt|;
block|}
specifier|public
name|ReadContext
parameter_list|(
name|int
name|colIx
parameter_list|,
name|int
name|colRgIx
parameter_list|)
block|{
name|this
argument_list|(
name|colIx
argument_list|,
name|colRgIx
argument_list|,
name|MAX_STREAMS
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
specifier|final
name|int
name|MAX_STREAMS
init|=
name|countMaxStreams
argument_list|(
name|Area
operator|.
name|INDEX
argument_list|)
decl_stmt|;
comment|/** The number of streams that are part of this column. */
name|int
name|streamCount
init|=
literal|0
decl_stmt|;
specifier|final
name|StreamContext
index|[]
name|streams
decl_stmt|;
comment|/** Column index in the file. */
name|int
name|colIx
decl_stmt|;
comment|/** Column index in the included columns only (for RG masks). */
name|int
name|includedIx
decl_stmt|;
specifier|public
name|void
name|addStream
parameter_list|(
name|long
name|offset
parameter_list|,
name|OrcProto
operator|.
name|Stream
name|stream
parameter_list|,
name|int
name|indexIx
parameter_list|)
block|{
name|streams
index|[
name|streamCount
operator|++
index|]
operator|=
operator|new
name|StreamContext
argument_list|(
name|stream
argument_list|,
name|offset
argument_list|,
name|indexIx
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" column_index: "
argument_list|)
operator|.
name|append
argument_list|(
name|colIx
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" included_index: "
argument_list|)
operator|.
name|append
argument_list|(
name|includedIx
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" stream_count: "
argument_list|)
operator|.
name|append
argument_list|(
name|streamCount
argument_list|)
expr_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StreamContext
name|sc
range|:
name|streams
control|)
block|{
if|if
condition|(
name|sc
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|" stream_"
argument_list|)
operator|.
name|append
argument_list|(
name|i
argument_list|)
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
operator|.
name|append
argument_list|(
name|sc
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|i
operator|++
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
specifier|final
class|class
name|StreamContext
block|{
specifier|public
name|StreamContext
parameter_list|(
name|OrcProto
operator|.
name|Stream
name|stream
parameter_list|,
name|long
name|streamOffset
parameter_list|,
name|int
name|streamIndexOffset
parameter_list|)
block|{
name|this
operator|.
name|kind
operator|=
name|stream
operator|.
name|getKind
argument_list|()
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|stream
operator|.
name|getLength
argument_list|()
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|streamOffset
expr_stmt|;
name|this
operator|.
name|streamIndexOffset
operator|=
name|streamIndexOffset
expr_stmt|;
block|}
comment|/** Offsets of each stream in the column. */
specifier|public
name|long
name|offset
decl_stmt|,
name|length
decl_stmt|;
specifier|public
name|int
name|streamIndexOffset
decl_stmt|;
specifier|public
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
name|kind
decl_stmt|;
comment|/** Iterators for the buffers; used to maintain position in per-rg reading. */
name|DiskRangeList
name|bufferIter
decl_stmt|;
comment|/** Saved stripe-level stream, to reuse for each RG (e.g. dictionaries). */
name|ColumnStreamData
name|stripeLevelStream
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" kind: "
argument_list|)
operator|.
name|append
argument_list|(
name|kind
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" offset: "
argument_list|)
operator|.
name|append
argument_list|(
name|offset
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" length: "
argument_list|)
operator|.
name|append
argument_list|(
name|length
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" index_offset: "
argument_list|)
operator|.
name|append
argument_list|(
name|streamIndexOffset
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|readEncodedColumns
parameter_list|(
name|int
name|stripeIx
parameter_list|,
name|StripeInformation
name|stripe
parameter_list|,
name|OrcProto
operator|.
name|RowIndex
index|[]
name|indexes
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|ColumnEncoding
argument_list|>
name|encodings
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Stream
argument_list|>
name|streamList
parameter_list|,
name|boolean
index|[]
name|physicalFileIncludes
parameter_list|,
name|boolean
index|[]
name|rgs
parameter_list|,
name|Consumer
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
name|consumer
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Note: for now we don't have to setError here, caller will setError if we throw.
comment|// We are also not supposed to call setDone, since we are only part of the operation.
name|long
name|stripeOffset
init|=
name|stripe
operator|.
name|getOffset
argument_list|()
decl_stmt|;
comment|// 1. Figure out what we have to read.
name|long
name|offset
init|=
literal|0
decl_stmt|;
comment|// Stream offset in relation to the stripe.
comment|// 1.1. Figure out which columns have a present stream
name|boolean
index|[]
name|hasNull
init|=
name|RecordReaderUtils
operator|.
name|findPresentStreamsByColumn
argument_list|(
name|streamList
argument_list|,
name|types
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"The following columns have PRESENT streams: "
operator|+
name|arrayToString
argument_list|(
name|hasNull
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// We assume stream list is sorted by column and that non-data
comment|// streams do not interleave data streams for the same column.
comment|// 1.2. With that in mind, determine disk ranges to read/get from cache (not by stream).
name|ColumnReadContext
index|[]
name|colCtxs
init|=
operator|new
name|ColumnReadContext
index|[
name|physicalFileIncludes
operator|.
name|length
index|]
decl_stmt|;
name|int
name|colRgIx
init|=
operator|-
literal|1
decl_stmt|;
comment|// Don't create context for the 0-s column.
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|physicalFileIncludes
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
operator|!
name|physicalFileIncludes
index|[
name|i
index|]
condition|)
continue|continue;
name|ColumnEncoding
name|enc
init|=
name|encodings
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|colCtxs
index|[
name|i
index|]
operator|=
operator|new
name|ColumnReadContext
argument_list|(
name|i
argument_list|,
name|enc
argument_list|,
name|indexes
index|[
name|i
index|]
argument_list|,
operator|++
name|colRgIx
argument_list|)
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Creating context: "
operator|+
name|colCtxs
index|[
name|i
index|]
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logColumnRead
argument_list|(
name|i
argument_list|,
name|colRgIx
argument_list|,
name|enc
operator|.
name|getKind
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|CreateHelper
name|listToRead
init|=
operator|new
name|CreateHelper
argument_list|()
decl_stmt|;
name|boolean
name|hasIndexOnlyCols
init|=
literal|false
decl_stmt|,
name|hasAnyNonData
init|=
literal|false
decl_stmt|;
for|for
control|(
name|OrcProto
operator|.
name|Stream
name|stream
range|:
name|streamList
control|)
block|{
name|long
name|length
init|=
name|stream
operator|.
name|getLength
argument_list|()
decl_stmt|;
name|int
name|colIx
init|=
name|stream
operator|.
name|getColumn
argument_list|()
decl_stmt|;
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
name|streamKind
init|=
name|stream
operator|.
name|getKind
argument_list|()
decl_stmt|;
name|boolean
name|isIndexCol
init|=
name|StreamName
operator|.
name|getArea
argument_list|(
name|streamKind
argument_list|)
operator|!=
name|StreamName
operator|.
name|Area
operator|.
name|DATA
decl_stmt|;
name|hasAnyNonData
operator|=
name|hasAnyNonData
operator|||
name|isIndexCol
expr_stmt|;
comment|// We have a stream for included column, but in future it might have no data streams.
comment|// It's more like "has at least one column included that has an index stream".
name|hasIndexOnlyCols
operator|=
name|hasIndexOnlyCols
operator|||
operator|(
name|isIndexCol
operator|&&
name|physicalFileIncludes
index|[
name|colIx
index|]
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|physicalFileIncludes
index|[
name|colIx
index|]
operator|||
name|isIndexCol
condition|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Skipping stream for column "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|streamKind
operator|+
literal|" at "
operator|+
name|offset
operator|+
literal|", "
operator|+
name|length
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logSkipStream
argument_list|(
name|colIx
argument_list|,
name|streamKind
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
expr_stmt|;
name|offset
operator|+=
name|length
expr_stmt|;
continue|continue;
block|}
name|ColumnReadContext
name|ctx
init|=
name|colCtxs
index|[
name|colIx
index|]
decl_stmt|;
assert|assert
name|ctx
operator|!=
literal|null
assert|;
name|int
name|indexIx
init|=
name|RecordReaderUtils
operator|.
name|getIndexPosition
argument_list|(
name|ctx
operator|.
name|encoding
operator|.
name|getKind
argument_list|()
argument_list|,
name|types
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
operator|.
name|getKind
argument_list|()
argument_list|,
name|streamKind
argument_list|,
name|isCompressed
argument_list|,
name|hasNull
index|[
name|colIx
index|]
argument_list|)
decl_stmt|;
name|ctx
operator|.
name|addStream
argument_list|(
name|offset
argument_list|,
name|stream
argument_list|,
name|indexIx
argument_list|)
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Adding stream for column "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|streamKind
operator|+
literal|" at "
operator|+
name|offset
operator|+
literal|", "
operator|+
name|length
operator|+
literal|", index position "
operator|+
name|indexIx
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rgs
operator|==
literal|null
operator|||
name|RecordReaderUtils
operator|.
name|isDictionary
argument_list|(
name|streamKind
argument_list|,
name|encodings
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
argument_list|)
condition|)
block|{
name|trace
operator|.
name|logAddStream
argument_list|(
name|colIx
argument_list|,
name|streamKind
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|indexIx
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|RecordReaderUtils
operator|.
name|addEntireStreamToRanges
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
name|listToRead
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Will read whole stream "
operator|+
name|streamKind
operator|+
literal|"; added to "
operator|+
name|listToRead
operator|.
name|getTail
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|trace
operator|.
name|logAddStream
argument_list|(
name|colIx
argument_list|,
name|streamKind
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|indexIx
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|RecordReaderUtils
operator|.
name|addRgFilteredStreamToRanges
argument_list|(
name|stream
argument_list|,
name|rgs
argument_list|,
name|isCompressed
argument_list|,
name|indexes
index|[
name|colIx
index|]
argument_list|,
name|encodings
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
argument_list|,
name|types
operator|.
name|get
argument_list|(
name|colIx
argument_list|)
argument_list|,
name|bufferSize
argument_list|,
name|hasNull
index|[
name|colIx
index|]
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|listToRead
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|offset
operator|+=
name|length
expr_stmt|;
block|}
name|boolean
name|hasFileId
init|=
name|this
operator|.
name|fileKey
operator|!=
literal|null
decl_stmt|;
if|if
condition|(
name|listToRead
operator|.
name|get
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// No data to read for this stripe. Check if we have some included index-only columns.
comment|// For example, count(1) would have the root column, that has no data stream, included.
comment|// It may also happen that we have a column included with no streams whatsoever. That
comment|// should only be possible if the file has no index streams.
name|boolean
name|hasAnyIncludes
init|=
literal|false
decl_stmt|;
if|if
condition|(
operator|!
name|hasIndexOnlyCols
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|physicalFileIncludes
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
operator|!
name|physicalFileIncludes
index|[
name|i
index|]
condition|)
continue|continue;
name|hasAnyIncludes
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
name|boolean
name|nonProjectionRead
init|=
name|hasIndexOnlyCols
operator|||
operator|(
operator|!
name|hasAnyNonData
operator|&&
name|hasAnyIncludes
operator|)
decl_stmt|;
comment|// TODO: Could there be partial RG filtering w/no projection?
comment|//       We should probably just disable filtering for such cases if they exist.
if|if
condition|(
name|nonProjectionRead
operator|&&
operator|(
name|rgs
operator|==
name|SargApplier
operator|.
name|READ_ALL_RGS
operator|)
condition|)
block|{
name|OrcEncodedColumnBatch
name|ecb
init|=
name|POOLS
operator|.
name|ecbPool
operator|.
name|take
argument_list|()
decl_stmt|;
name|ecb
operator|.
name|init
argument_list|(
name|fileKey
argument_list|,
name|stripeIx
argument_list|,
name|OrcEncodedColumnBatch
operator|.
name|ALL_RGS
argument_list|,
name|physicalFileIncludes
operator|.
name|length
argument_list|)
expr_stmt|;
try|try
block|{
name|consumer
operator|.
name|consumeData
argument_list|(
name|ecb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"IO thread interrupted while queueing data"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Nothing to read for stripe ["
operator|+
name|stripe
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
comment|// 2. Now, read all of the ranges from cache or disk.
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
init|=
operator|new
name|IdentityHashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|MutateHelper
name|toRead
init|=
name|getDataFromCacheAndDisk
argument_list|(
name|listToRead
operator|.
name|get
argument_list|()
argument_list|,
name|stripeOffset
argument_list|,
name|hasFileId
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
comment|// 3. For uncompressed case, we need some special processing before read.
comment|//    Basically, we are trying to create artificial, consistent ranges to cache, as there are
comment|//    no CBs in an uncompressed file. At the end of this processing, the list would contain
comment|//    either cache buffers, or buffers allocated by us and not cached (if we are only reading
comment|//    parts of the data for some ranges and don't want to cache it). Both are represented by
comment|//    CacheChunks, so the list is just CacheChunk-s from that point on.
name|DiskRangeList
name|iter
init|=
name|preReadUncompressedStreams
argument_list|(
name|stripeOffset
argument_list|,
name|colCtxs
argument_list|,
name|toRead
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
comment|// 4. Finally, decompress data, map per RG, and return to caller.
comment|// We go by RG and not by column because that is how data is processed.
name|boolean
name|hasError
init|=
literal|true
decl_stmt|;
try|try
block|{
name|int
name|rgCount
init|=
name|rowIndexStride
operator|==
literal|0
condition|?
literal|1
else|:
operator|(
name|int
operator|)
name|Math
operator|.
name|ceil
argument_list|(
operator|(
name|double
operator|)
name|stripe
operator|.
name|getNumberOfRows
argument_list|()
operator|/
name|rowIndexStride
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|rgIx
init|=
literal|0
init|;
name|rgIx
operator|<
name|rgCount
condition|;
operator|++
name|rgIx
control|)
block|{
if|if
condition|(
name|rgs
operator|!=
literal|null
operator|&&
operator|!
name|rgs
index|[
name|rgIx
index|]
condition|)
block|{
continue|continue;
comment|// RG filtered.
block|}
name|boolean
name|isLastRg
init|=
name|rgIx
operator|==
name|rgCount
operator|-
literal|1
decl_stmt|;
comment|// Create the batch we will use to return data for this RG.
name|OrcEncodedColumnBatch
name|ecb
init|=
name|POOLS
operator|.
name|ecbPool
operator|.
name|take
argument_list|()
decl_stmt|;
name|trace
operator|.
name|logStartRg
argument_list|(
name|rgIx
argument_list|)
expr_stmt|;
name|boolean
name|hasErrorForEcb
init|=
literal|true
decl_stmt|;
try|try
block|{
name|ecb
operator|.
name|init
argument_list|(
name|fileKey
argument_list|,
name|stripeIx
argument_list|,
name|rgIx
argument_list|,
name|physicalFileIncludes
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|colCtxs
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
name|ColumnReadContext
name|ctx
init|=
name|colCtxs
index|[
name|colIx
index|]
decl_stmt|;
if|if
condition|(
name|ctx
operator|==
literal|null
condition|)
continue|continue;
comment|// This column is not included
name|OrcProto
operator|.
name|RowIndexEntry
name|index
decl_stmt|;
name|OrcProto
operator|.
name|RowIndexEntry
name|nextIndex
decl_stmt|;
comment|// index is disabled
if|if
condition|(
name|ctx
operator|.
name|rowIndex
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Row index is null. Likely reading a file with indexes disabled."
argument_list|)
expr_stmt|;
block|}
name|index
operator|=
literal|null
expr_stmt|;
name|nextIndex
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|index
operator|=
name|ctx
operator|.
name|rowIndex
operator|.
name|getEntry
argument_list|(
name|rgIx
argument_list|)
expr_stmt|;
name|nextIndex
operator|=
name|isLastRg
condition|?
literal|null
else|:
name|ctx
operator|.
name|rowIndex
operator|.
name|getEntry
argument_list|(
name|rgIx
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"ctx: {} rgIx: {} isLastRg: {} rgCount: {}"
argument_list|,
name|ctx
argument_list|,
name|rgIx
argument_list|,
name|isLastRg
argument_list|,
name|rgCount
argument_list|)
expr_stmt|;
block|}
name|ecb
operator|.
name|initOrcColumn
argument_list|(
name|ctx
operator|.
name|colIx
argument_list|)
expr_stmt|;
name|trace
operator|.
name|logStartCol
argument_list|(
name|ctx
operator|.
name|colIx
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|streamIx
init|=
literal|0
init|;
name|streamIx
operator|<
name|ctx
operator|.
name|streamCount
condition|;
operator|++
name|streamIx
control|)
block|{
name|StreamContext
name|sctx
init|=
name|ctx
operator|.
name|streams
index|[
name|streamIx
index|]
decl_stmt|;
name|ColumnStreamData
name|cb
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|RecordReaderUtils
operator|.
name|isDictionary
argument_list|(
name|sctx
operator|.
name|kind
argument_list|,
name|ctx
operator|.
name|encoding
argument_list|)
operator|||
name|index
operator|==
literal|null
condition|)
block|{
comment|// This stream is for entire stripe and needed for every RG; uncompress once and reuse.
if|if
condition|(
name|sctx
operator|.
name|stripeLevelStream
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Getting stripe-level stream ["
operator|+
name|sctx
operator|.
name|kind
operator|+
literal|", "
operator|+
name|ctx
operator|.
name|encoding
operator|+
literal|"] for"
operator|+
literal|" column "
operator|+
name|ctx
operator|.
name|colIx
operator|+
literal|" RG "
operator|+
name|rgIx
operator|+
literal|" at "
operator|+
name|sctx
operator|.
name|offset
operator|+
literal|", "
operator|+
name|sctx
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logStartStripeStream
argument_list|(
name|sctx
operator|.
name|kind
argument_list|)
expr_stmt|;
name|sctx
operator|.
name|stripeLevelStream
operator|=
name|POOLS
operator|.
name|csdPool
operator|.
name|take
argument_list|()
expr_stmt|;
comment|// We will be using this for each RG while also sending RGs to processing.
comment|// To avoid buffers being unlocked, run refcount one ahead; so each RG
comment|// processing will decref once, and the last one will unlock the buffers.
name|sctx
operator|.
name|stripeLevelStream
operator|.
name|incRef
argument_list|()
expr_stmt|;
comment|// For stripe-level streams we don't need the extra refcount on the block.
comment|// See class comment about refcounts.
name|long
name|unlockUntilCOffset
init|=
name|sctx
operator|.
name|offset
operator|+
name|sctx
operator|.
name|length
decl_stmt|;
name|DiskRangeList
name|lastCached
init|=
name|readEncodedStream
argument_list|(
name|stripeOffset
argument_list|,
name|iter
argument_list|,
name|sctx
operator|.
name|offset
argument_list|,
name|sctx
operator|.
name|offset
operator|+
name|sctx
operator|.
name|length
argument_list|,
name|sctx
operator|.
name|stripeLevelStream
argument_list|,
name|unlockUntilCOffset
argument_list|,
name|sctx
operator|.
name|offset
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
if|if
condition|(
name|lastCached
operator|!=
literal|null
condition|)
block|{
name|iter
operator|=
name|lastCached
expr_stmt|;
block|}
block|}
name|sctx
operator|.
name|stripeLevelStream
operator|.
name|incRef
argument_list|()
expr_stmt|;
name|cb
operator|=
name|sctx
operator|.
name|stripeLevelStream
expr_stmt|;
block|}
else|else
block|{
comment|// This stream can be separated by RG using index. Let's do that.
comment|// Offset to where this RG begins.
name|long
name|cOffset
init|=
name|sctx
operator|.
name|offset
operator|+
name|index
operator|.
name|getPositions
argument_list|(
name|sctx
operator|.
name|streamIndexOffset
argument_list|)
decl_stmt|;
comment|// Offset relative to the beginning of the stream of where this RG ends.
name|long
name|nextCOffsetRel
init|=
name|isLastRg
condition|?
name|sctx
operator|.
name|length
else|:
name|nextIndex
operator|.
name|getPositions
argument_list|(
name|sctx
operator|.
name|streamIndexOffset
argument_list|)
decl_stmt|;
comment|// Offset before which this RG is guaranteed to end. Can only be estimated.
comment|// We estimate the same way for compressed and uncompressed for now.
name|long
name|endCOffset
init|=
name|sctx
operator|.
name|offset
operator|+
name|RecordReaderUtils
operator|.
name|estimateRgEndOffset
argument_list|(
name|isCompressed
argument_list|,
name|isLastRg
argument_list|,
name|nextCOffsetRel
argument_list|,
name|sctx
operator|.
name|length
argument_list|,
name|bufferSize
argument_list|)
decl_stmt|;
comment|// As we read, we can unlock initial refcounts for the buffers that end before
comment|// the data that we need for this RG.
name|long
name|unlockUntilCOffset
init|=
name|sctx
operator|.
name|offset
operator|+
name|nextCOffsetRel
decl_stmt|;
name|cb
operator|=
name|createRgColumnStreamData
argument_list|(
name|rgIx
argument_list|,
name|isLastRg
argument_list|,
name|ctx
operator|.
name|colIx
argument_list|,
name|sctx
argument_list|,
name|cOffset
argument_list|,
name|endCOffset
argument_list|,
name|isCompressed
argument_list|,
name|unlockUntilCOffset
argument_list|)
expr_stmt|;
name|boolean
name|isStartOfStream
init|=
name|sctx
operator|.
name|bufferIter
operator|==
literal|null
decl_stmt|;
name|DiskRangeList
name|lastCached
init|=
name|readEncodedStream
argument_list|(
name|stripeOffset
argument_list|,
operator|(
name|isStartOfStream
condition|?
name|iter
else|:
name|sctx
operator|.
name|bufferIter
operator|)
argument_list|,
name|cOffset
argument_list|,
name|endCOffset
argument_list|,
name|cb
argument_list|,
name|unlockUntilCOffset
argument_list|,
name|sctx
operator|.
name|offset
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
if|if
condition|(
name|lastCached
operator|!=
literal|null
condition|)
block|{
name|sctx
operator|.
name|bufferIter
operator|=
name|iter
operator|=
name|lastCached
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|DiskRangeList
name|drl
init|=
name|toRead
operator|==
literal|null
condition|?
literal|null
else|:
name|toRead
operator|.
name|next
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Error getting stream ["
operator|+
name|sctx
operator|.
name|kind
operator|+
literal|", "
operator|+
name|ctx
operator|.
name|encoding
operator|+
literal|"] for"
operator|+
literal|" column "
operator|+
name|ctx
operator|.
name|colIx
operator|+
literal|" RG "
operator|+
name|rgIx
operator|+
literal|" at "
operator|+
name|sctx
operator|.
name|offset
operator|+
literal|", "
operator|+
name|sctx
operator|.
name|length
operator|+
literal|"; toRead "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|drl
argument_list|)
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|(
name|ex
operator|instanceof
name|IOException
operator|)
condition|?
operator|(
name|IOException
operator|)
name|ex
else|:
operator|new
name|IOException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
finally|finally
block|{
comment|// Always add stream data to ecb; releaseEcbRefCountsOnError relies on it.
comment|// Otherwise, we won't release consumer refcounts for a partially read stream.
if|if
condition|(
name|cb
operator|!=
literal|null
condition|)
block|{
name|ecb
operator|.
name|setStreamData
argument_list|(
name|ctx
operator|.
name|colIx
argument_list|,
name|sctx
operator|.
name|kind
operator|.
name|getNumber
argument_list|()
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|hasErrorForEcb
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|hasErrorForEcb
condition|)
block|{
name|releaseEcbRefCountsOnError
argument_list|(
name|ecb
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|consumer
operator|.
name|consumeData
argument_list|(
name|ecb
argument_list|)
expr_stmt|;
comment|// After this, the non-initial refcounts are the responsibility of the consumer.
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"IO thread interrupted while queueing data"
argument_list|)
expr_stmt|;
name|releaseEcbRefCountsOnError
argument_list|(
name|ecb
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Disk ranges after preparing all the data "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logRanges
argument_list|(
name|fileKey
argument_list|,
name|stripeOffset
argument_list|,
name|toRead
operator|.
name|next
argument_list|,
name|RangesSrc
operator|.
name|PREREAD
argument_list|)
expr_stmt|;
name|hasError
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
try|try
block|{
comment|// Release the unreleased stripe-level buffers. See class comment about refcounts.
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|colCtxs
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
name|ColumnReadContext
name|ctx
init|=
name|colCtxs
index|[
name|colIx
index|]
decl_stmt|;
if|if
condition|(
name|ctx
operator|==
literal|null
condition|)
continue|continue;
comment|// This column is not included.
for|for
control|(
name|int
name|streamIx
init|=
literal|0
init|;
name|streamIx
operator|<
name|ctx
operator|.
name|streamCount
condition|;
operator|++
name|streamIx
control|)
block|{
name|StreamContext
name|sctx
init|=
name|ctx
operator|.
name|streams
index|[
name|streamIx
index|]
decl_stmt|;
if|if
condition|(
name|sctx
operator|==
literal|null
operator|||
name|sctx
operator|.
name|stripeLevelStream
operator|==
literal|null
condition|)
continue|continue;
if|if
condition|(
literal|0
operator|!=
name|sctx
operator|.
name|stripeLevelStream
operator|.
name|decRef
argument_list|()
condition|)
continue|continue;
comment|// Note - this is a little bit confusing; the special treatment of stripe-level buffers
comment|// is because we run the ColumnStreamData refcount one ahead (as specified above). It
comment|// may look like this would release the buffers too many times (one release from the
comment|// consumer, one from releaseInitialRefcounts below, and one here); however, this is
comment|// merely handling a special case where all the batches that are sharing the stripe-
comment|// level stream have been processed before we got here; they have all decRef-ed the CSD,
comment|// but have not released the buffers because of that extra refCount. So, this is
comment|// essentially the "consumer" refcount being released here.
for|for
control|(
name|MemoryBuffer
name|buf
range|:
name|sctx
operator|.
name|stripeLevelStream
operator|.
name|getCacheBuffers
argument_list|()
control|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Unlocking {} at the end of processing"
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
name|cacheWrapper
operator|.
name|releaseBuffer
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|releaseInitialRefcounts
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
expr_stmt|;
comment|// Release buffers as we are done with all the streams... also see toRelease comment.
name|releaseBuffers
argument_list|(
name|toRelease
operator|.
name|keySet
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
if|if
condition|(
operator|!
name|hasError
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
throw|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Error during the cleanup after another error; ignoring"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|int
name|countMaxStreams
parameter_list|(
name|Area
name|area
parameter_list|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Stream
operator|.
name|Kind
name|sk
range|:
name|Stream
operator|.
name|Kind
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|StreamName
operator|.
name|getArea
argument_list|(
name|sk
argument_list|)
operator|==
name|area
condition|)
block|{
operator|++
name|count
expr_stmt|;
block|}
block|}
return|return
name|count
return|;
block|}
specifier|private
name|DiskRangeList
operator|.
name|MutateHelper
name|getDataFromCacheAndDisk
parameter_list|(
name|DiskRangeList
name|listToRead
parameter_list|,
name|long
name|stripeOffset
parameter_list|,
name|boolean
name|hasFileId
parameter_list|,
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
parameter_list|)
throws|throws
name|IOException
block|{
name|DiskRangeList
operator|.
name|MutateHelper
name|toRead
init|=
operator|new
name|DiskRangeList
operator|.
name|MutateHelper
argument_list|(
name|listToRead
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Resulting disk ranges to read (file "
operator|+
name|fileKey
operator|+
literal|"): "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|BooleanRef
name|isAllInCache
init|=
operator|new
name|BooleanRef
argument_list|()
decl_stmt|;
if|if
condition|(
name|hasFileId
condition|)
block|{
name|cacheWrapper
operator|.
name|getFileData
argument_list|(
name|fileKey
argument_list|,
name|toRead
operator|.
name|next
argument_list|,
name|stripeOffset
argument_list|,
name|CC_FACTORY
argument_list|,
name|isAllInCache
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Disk ranges after cache (found everything "
operator|+
name|isAllInCache
operator|.
name|value
operator|+
literal|"; file "
operator|+
name|fileKey
operator|+
literal|", base offset "
operator|+
name|stripeOffset
operator|+
literal|"): "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logRanges
argument_list|(
name|fileKey
argument_list|,
name|stripeOffset
argument_list|,
name|toRead
operator|.
name|next
argument_list|,
name|RangesSrc
operator|.
name|CACHE
argument_list|)
expr_stmt|;
block|}
comment|// TODO: the memory release could be optimized - we could release original buffers after we
comment|//       are fully done with each original buffer from disk. For now release all at the end;
comment|//       it doesn't increase the total amount of memory we hold, just the duration a bit.
comment|//       This is much simpler - we can just remember original ranges after reading them, and
comment|//       release them at the end. In a few cases where it's easy to determine that a buffer
comment|//       can be freed in advance, we remove it from the map.
if|if
condition|(
operator|!
name|isAllInCache
operator|.
name|value
condition|)
block|{
name|boolean
name|hasError
init|=
literal|true
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|isDataReaderOpen
condition|)
block|{
name|this
operator|.
name|dataReader
operator|.
name|open
argument_list|()
expr_stmt|;
name|isDataReaderOpen
operator|=
literal|true
expr_stmt|;
block|}
name|dataReader
operator|.
name|readFileData
argument_list|(
name|toRead
operator|.
name|next
argument_list|,
name|stripeOffset
argument_list|,
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
operator|.
name|isDirectAlloc
argument_list|()
argument_list|)
expr_stmt|;
name|toRelease
operator|=
operator|new
name|IdentityHashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|DiskRangeList
name|drl
init|=
name|toRead
operator|.
name|next
decl_stmt|;
while|while
condition|(
name|drl
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|drl
operator|instanceof
name|BufferChunk
condition|)
block|{
name|toRelease
operator|.
name|put
argument_list|(
name|drl
operator|.
name|getData
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|drl
operator|=
name|drl
operator|.
name|next
expr_stmt|;
block|}
name|hasError
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
comment|// The FS can be closed from under us if the task is interrupted. Release cache buffers.
comment|// We are assuming here that toRelease will not be present in such cases.
if|if
condition|(
name|hasError
condition|)
block|{
name|releaseInitialRefcounts
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|toRead
return|;
block|}
specifier|private
name|void
name|releaseEcbRefCountsOnError
parameter_list|(
name|OrcEncodedColumnBatch
name|ecb
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Unlocking the batch not sent to consumer, on error"
argument_list|)
expr_stmt|;
block|}
comment|// We cannot send the ecb to consumer. Discard whatever is already there.
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|ecb
operator|.
name|getTotalColCount
argument_list|()
condition|;
operator|++
name|colIx
control|)
block|{
if|if
condition|(
operator|!
name|ecb
operator|.
name|hasData
argument_list|(
name|colIx
argument_list|)
condition|)
continue|continue;
name|ColumnStreamData
index|[]
name|datas
init|=
name|ecb
operator|.
name|getColumnData
argument_list|(
name|colIx
argument_list|)
decl_stmt|;
for|for
control|(
name|ColumnStreamData
name|data
range|:
name|datas
control|)
block|{
if|if
condition|(
name|data
operator|==
literal|null
operator|||
name|data
operator|.
name|decRef
argument_list|()
operator|!=
literal|0
condition|)
continue|continue;
for|for
control|(
name|MemoryBuffer
name|buf
range|:
name|data
operator|.
name|getCacheBuffers
argument_list|()
control|)
block|{
if|if
condition|(
name|buf
operator|==
literal|null
condition|)
continue|continue;
name|cacheWrapper
operator|.
name|releaseBuffer
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error during the cleanup of an error; ignoring"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|String
name|arrayToString
parameter_list|(
name|boolean
index|[]
name|a
parameter_list|)
block|{
name|StringBuilder
name|b
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|b
operator|.
name|append
argument_list|(
literal|'['
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|a
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|b
operator|.
name|append
argument_list|(
name|a
index|[
name|i
index|]
condition|?
literal|"1"
else|:
literal|"0"
argument_list|)
expr_stmt|;
block|}
name|b
operator|.
name|append
argument_list|(
literal|']'
argument_list|)
expr_stmt|;
return|return
name|b
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
name|ColumnStreamData
name|createRgColumnStreamData
parameter_list|(
name|int
name|rgIx
parameter_list|,
name|boolean
name|isLastRg
parameter_list|,
name|int
name|colIx
parameter_list|,
name|StreamContext
name|sctx
parameter_list|,
name|long
name|cOffset
parameter_list|,
name|long
name|endCOffset
parameter_list|,
name|boolean
name|isCompressed
parameter_list|,
name|long
name|unlockUntilCOffset
parameter_list|)
block|{
name|ColumnStreamData
name|cb
init|=
name|POOLS
operator|.
name|csdPool
operator|.
name|take
argument_list|()
decl_stmt|;
name|cb
operator|.
name|incRef
argument_list|()
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Getting data for column "
operator|+
name|colIx
operator|+
literal|" "
operator|+
operator|(
name|isLastRg
condition|?
literal|"last "
else|:
literal|""
operator|)
operator|+
literal|"RG "
operator|+
name|rgIx
operator|+
literal|" stream "
operator|+
name|sctx
operator|.
name|kind
operator|+
literal|" at "
operator|+
name|sctx
operator|.
name|offset
operator|+
literal|", "
operator|+
name|sctx
operator|.
name|length
operator|+
literal|" index position "
operator|+
name|sctx
operator|.
name|streamIndexOffset
operator|+
literal|": "
operator|+
operator|(
name|isCompressed
condition|?
literal|""
else|:
literal|"un"
operator|)
operator|+
literal|"compressed ["
operator|+
name|cOffset
operator|+
literal|", "
operator|+
name|endCOffset
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logStartStream
argument_list|(
name|sctx
operator|.
name|kind
argument_list|,
name|cOffset
argument_list|,
name|endCOffset
argument_list|,
name|unlockUntilCOffset
argument_list|)
expr_stmt|;
return|return
name|cb
return|;
block|}
specifier|private
name|void
name|releaseInitialRefcounts
parameter_list|(
name|DiskRangeList
name|current
parameter_list|)
block|{
while|while
condition|(
name|current
operator|!=
literal|null
condition|)
block|{
name|DiskRangeList
name|toFree
init|=
name|current
decl_stmt|;
name|current
operator|=
name|current
operator|.
name|next
expr_stmt|;
if|if
condition|(
name|toFree
operator|instanceof
name|ProcCacheChunk
condition|)
block|{
name|ProcCacheChunk
name|pcc
init|=
operator|(
name|ProcCacheChunk
operator|)
name|toFree
decl_stmt|;
if|if
condition|(
name|pcc
operator|.
name|originalData
operator|!=
literal|null
condition|)
block|{
comment|// TODO: can this still happen? we now clean these up explicitly to avoid other issues.
comment|// This can only happen in case of failure - we read some data, but didn't decompress
comment|// it. Deallocate the buffer directly, do not decref.
if|if
condition|(
name|pcc
operator|.
name|getBuffer
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
operator|.
name|deallocate
argument_list|(
name|pcc
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
block|}
if|if
condition|(
operator|!
operator|(
name|toFree
operator|instanceof
name|CacheChunk
operator|)
condition|)
continue|continue;
name|CacheChunk
name|cc
init|=
operator|(
name|CacheChunk
operator|)
name|toFree
decl_stmt|;
if|if
condition|(
name|cc
operator|.
name|getBuffer
argument_list|()
operator|==
literal|null
condition|)
continue|continue;
name|MemoryBuffer
name|buffer
init|=
name|cc
operator|.
name|getBuffer
argument_list|()
decl_stmt|;
name|cacheWrapper
operator|.
name|releaseBuffer
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|cc
operator|.
name|setBuffer
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|setTracing
parameter_list|(
name|boolean
name|isEnabled
parameter_list|)
block|{
name|this
operator|.
name|isTracingEnabled
operator|=
name|isEnabled
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|codec
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|isCodecFromPool
operator|&&
operator|!
name|isCodecFailure
condition|)
block|{
name|OrcCodecPool
operator|.
name|returnCodec
argument_list|(
name|compressionKind
argument_list|,
name|codec
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|codec
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|codec
operator|=
literal|null
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Ignoring error from codec"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|dataReader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Fake cache chunk used for uncompressed data. Used in preRead for uncompressed files.    * Makes assumptions about preRead code; for example, we add chunks here when they are    * already in the linked list, without unlinking. So, we record the start position in the    * original list, and then, when someone adds the next element, we merely increase the number    * of elements one has to traverse from that position to get the whole list.    */
specifier|private
specifier|static
class|class
name|UncompressedCacheChunk
extends|extends
name|CacheChunk
block|{
specifier|private
name|BufferChunk
name|chunk
decl_stmt|;
specifier|private
name|int
name|count
decl_stmt|;
specifier|public
name|UncompressedCacheChunk
parameter_list|(
name|BufferChunk
name|bc
parameter_list|)
block|{
name|super
argument_list|(
literal|null
argument_list|,
name|bc
operator|.
name|getOffset
argument_list|()
argument_list|,
name|bc
operator|.
name|getEnd
argument_list|()
argument_list|)
expr_stmt|;
name|chunk
operator|=
name|bc
expr_stmt|;
name|count
operator|=
literal|1
expr_stmt|;
block|}
specifier|public
name|void
name|addChunk
parameter_list|(
name|BufferChunk
name|bc
parameter_list|)
block|{
assert|assert
name|bc
operator|.
name|getOffset
argument_list|()
operator|==
name|this
operator|.
name|getEnd
argument_list|()
assert|;
name|this
operator|.
name|end
operator|=
name|bc
operator|.
name|getEnd
argument_list|()
expr_stmt|;
operator|++
name|count
expr_stmt|;
block|}
specifier|public
name|BufferChunk
name|getChunk
parameter_list|()
block|{
return|return
name|chunk
return|;
block|}
specifier|public
name|int
name|getCount
parameter_list|()
block|{
return|return
name|count
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleCacheCollision
parameter_list|(
name|DataCache
name|cacheWrapper
parameter_list|,
name|MemoryBuffer
name|replacementBuffer
parameter_list|,
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|cacheBuffers
parameter_list|)
block|{
assert|assert
name|cacheBuffers
operator|==
literal|null
assert|;
comment|// This is done at pre-read stage where there's nothing special w/refcounts. Just release.
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
operator|.
name|deallocate
argument_list|(
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
comment|// Replace the buffer in our big range list, as well as in current results.
name|this
operator|.
name|setBuffer
argument_list|(
name|replacementBuffer
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|clear
parameter_list|()
block|{
name|this
operator|.
name|chunk
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|count
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
comment|/**    * CacheChunk that is pre-created for new cache data; initially, it contains an original disk    * buffer and an unallocated MemoryBuffer object. Before we expose it, the MB is allocated,    * the data is decompressed, and original compressed data is discarded. The chunk lives on in    * the DiskRange list created for the request, and everyone treats it like regular CacheChunk.    */
specifier|private
specifier|static
class|class
name|ProcCacheChunk
extends|extends
name|CacheChunk
block|{
specifier|public
name|ProcCacheChunk
parameter_list|(
name|long
name|cbStartOffset
parameter_list|,
name|long
name|cbEndOffset
parameter_list|,
name|boolean
name|isCompressed
parameter_list|,
name|ByteBuffer
name|originalData
parameter_list|,
name|MemoryBuffer
name|targetBuffer
parameter_list|,
name|int
name|originalCbIndex
parameter_list|)
block|{
name|super
argument_list|(
name|targetBuffer
argument_list|,
name|cbStartOffset
argument_list|,
name|cbEndOffset
argument_list|)
expr_stmt|;
name|this
operator|.
name|isOriginalDataCompressed
operator|=
name|isCompressed
expr_stmt|;
name|this
operator|.
name|originalData
operator|=
name|originalData
expr_stmt|;
name|this
operator|.
name|originalCbIndex
operator|=
name|originalCbIndex
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|super
operator|.
name|toString
argument_list|()
operator|+
literal|", original is set "
operator|+
operator|(
name|this
operator|.
name|originalData
operator|!=
literal|null
operator|)
operator|+
literal|", buffer was replaced "
operator|+
operator|(
name|originalCbIndex
operator|==
operator|-
literal|1
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleCacheCollision
parameter_list|(
name|DataCache
name|cacheWrapper
parameter_list|,
name|MemoryBuffer
name|replacementBuffer
parameter_list|,
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|cacheBuffers
parameter_list|)
block|{
assert|assert
name|originalCbIndex
operator|>=
literal|0
assert|;
comment|// Had the put succeeded for our new buffer, it would have refcount of 2 - 1 from put,
comment|// and 1 from notifyReused call above. "Old" buffer now has the 1 from put; new buffer
comment|// is not in cache. releaseBuffer will decref the buffer, and also deallocate.
name|cacheWrapper
operator|.
name|releaseBuffer
argument_list|(
name|this
operator|.
name|buffer
argument_list|)
expr_stmt|;
name|cacheWrapper
operator|.
name|reuseBuffer
argument_list|(
name|replacementBuffer
argument_list|)
expr_stmt|;
comment|// Replace the buffer in our big range list, as well as in current results.
name|this
operator|.
name|buffer
operator|=
name|replacementBuffer
expr_stmt|;
name|cacheBuffers
operator|.
name|set
argument_list|(
name|originalCbIndex
argument_list|,
name|replacementBuffer
argument_list|)
expr_stmt|;
name|originalCbIndex
operator|=
operator|-
literal|1
expr_stmt|;
comment|// This can only happen once at decompress time.
block|}
comment|/** Original data that will be turned into encoded cache data in this.buffer and reset. */
specifier|private
name|ByteBuffer
name|originalData
init|=
literal|null
decl_stmt|;
comment|/** Whether originalData is compressed. */
specifier|private
name|boolean
name|isOriginalDataCompressed
decl_stmt|;
comment|/** Index of the MemoryBuffer corresponding to this object inside the result list. If we      * hit a cache collision, we will replace this memory buffer with the one from cache at      * this index, without having to look for it. */
specifier|private
name|int
name|originalCbIndex
decl_stmt|;
block|}
comment|/**    * Uncompresses part of the stream. RGs can overlap, so we cannot just go and decompress    * and remove what we have returned. We will keep iterator as a "hint" point.    * @param baseOffset Absolute offset of boundaries and ranges relative to file, for cache keys.    * @param start Ordered ranges containing file data. Helpful if they point close to cOffset.    * @param cOffset Start offset to decompress.    * @param endCOffset End offset to decompress; estimate, partial CBs will be ignored.    * @param csd Stream data, to add the results.    * @param unlockUntilCOffset The offset until which the buffers can be unlocked in cache, as    *                           they will not be used in future calls (see the class comment in    *                           EncodedReaderImpl about refcounts).    * @return Last buffer cached during decompression. Cache buffers are never removed from    *         the master list, so they are safe to keep as iterators for various streams.    */
specifier|public
name|DiskRangeList
name|readEncodedStream
parameter_list|(
name|long
name|baseOffset
parameter_list|,
name|DiskRangeList
name|start
parameter_list|,
name|long
name|cOffset
parameter_list|,
name|long
name|endCOffset
parameter_list|,
name|ColumnStreamData
name|csd
parameter_list|,
name|long
name|unlockUntilCOffset
parameter_list|,
name|long
name|streamOffset
parameter_list|,
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|csd
operator|.
name|getCacheBuffers
argument_list|()
operator|==
literal|null
condition|)
block|{
name|csd
operator|.
name|setCacheBuffers
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|MemoryBuffer
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|csd
operator|.
name|getCacheBuffers
argument_list|()
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|cOffset
operator|==
name|endCOffset
condition|)
return|return
literal|null
return|;
name|List
argument_list|<
name|ProcCacheChunk
argument_list|>
name|toDecompress
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|IncompleteCb
argument_list|>
name|badEstimates
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|ByteBuffer
argument_list|>
name|toReleaseCopies
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isCompressed
condition|)
block|{
name|toReleaseCopies
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|toDecompress
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|badEstimates
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
comment|// 1. Find our bearings in the stream. Normally, iter will already point either to where we
comment|// want to be, or just before. However, RGs can overlap due to encoding, so we may have
comment|// to return to a previous block.
name|DiskRangeList
name|current
init|=
name|findExactPosition
argument_list|(
name|start
argument_list|,
name|cOffset
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Starting read for ["
operator|+
name|cOffset
operator|+
literal|","
operator|+
name|endCOffset
operator|+
literal|") at "
operator|+
name|current
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logStartRead
argument_list|(
name|current
argument_list|)
expr_stmt|;
name|CacheChunk
name|lastUncompressed
init|=
literal|null
decl_stmt|;
comment|// 2. Go thru the blocks; add stuff to results and prepare the decompression work (see below).
try|try
block|{
name|lastUncompressed
operator|=
name|isCompressed
condition|?
name|prepareRangesForCompressedRead
argument_list|(
name|cOffset
argument_list|,
name|endCOffset
argument_list|,
name|streamOffset
argument_list|,
name|unlockUntilCOffset
argument_list|,
name|current
argument_list|,
name|csd
argument_list|,
name|toRelease
argument_list|,
name|toReleaseCopies
argument_list|,
name|toDecompress
argument_list|,
name|badEstimates
argument_list|)
else|:
name|prepareRangesForUncompressedRead
argument_list|(
name|cOffset
argument_list|,
name|endCOffset
argument_list|,
name|streamOffset
argument_list|,
name|unlockUntilCOffset
argument_list|,
name|current
argument_list|,
name|csd
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed "
operator|+
operator|(
name|isCompressed
condition|?
literal|""
else|:
literal|"un"
operator|)
operator|+
literal|"compressed read; cOffset "
operator|+
name|cOffset
operator|+
literal|", endCOffset "
operator|+
name|endCOffset
operator|+
literal|", streamOffset "
operator|+
name|streamOffset
operator|+
literal|", unlockUntilCOffset "
operator|+
name|unlockUntilCOffset
operator|+
literal|"; ranges passed in "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|start
argument_list|)
operator|+
literal|"; ranges passed to prepare "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|current
argument_list|)
argument_list|)
expr_stmt|;
comment|// Don't log exception here.
throw|throw
operator|(
name|ex
operator|instanceof
name|IOException
operator|)
condition|?
operator|(
name|IOException
operator|)
name|ex
else|:
operator|new
name|IOException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
comment|// 2.5. Remember the bad estimates for future reference.
if|if
condition|(
name|badEstimates
operator|!=
literal|null
operator|&&
operator|!
name|badEstimates
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Relies on the fact that cache does not actually store these.
name|DiskRange
index|[]
name|cacheKeys
init|=
name|badEstimates
operator|.
name|toArray
argument_list|(
operator|new
name|DiskRange
index|[
name|badEstimates
operator|.
name|size
argument_list|()
index|]
argument_list|)
decl_stmt|;
name|long
index|[]
name|result
init|=
name|cacheWrapper
operator|.
name|putFileData
argument_list|(
name|fileKey
argument_list|,
name|cacheKeys
argument_list|,
literal|null
argument_list|,
name|baseOffset
argument_list|,
name|tag
argument_list|)
decl_stmt|;
assert|assert
name|result
operator|==
literal|null
assert|;
comment|// We don't expect conflicts from bad estimates.
block|}
if|if
condition|(
name|toDecompress
operator|==
literal|null
operator|||
name|toDecompress
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|releaseBuffers
argument_list|(
name|toReleaseCopies
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
name|lastUncompressed
return|;
comment|// Nothing to do.
block|}
comment|// 3. Allocate the buffers, prepare cache keys.
comment|// At this point, we have read all the CBs we need to read. cacheBuffers contains some cache
comment|// data and some unallocated membufs for decompression. toDecompress contains all the work we
comment|// need to do, and each item points to one of the membufs in cacheBuffers as target. The iter
comment|// has also been adjusted to point to these buffers instead of compressed data for the ranges.
name|MemoryBuffer
index|[]
name|targetBuffers
init|=
operator|new
name|MemoryBuffer
index|[
name|toDecompress
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|DiskRange
index|[]
name|cacheKeys
init|=
operator|new
name|DiskRange
index|[
name|toDecompress
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|ix
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ProcCacheChunk
name|chunk
range|:
name|toDecompress
control|)
block|{
name|cacheKeys
index|[
name|ix
index|]
operator|=
name|chunk
expr_stmt|;
comment|// Relies on the fact that cache does not actually store these.
name|targetBuffers
index|[
name|ix
index|]
operator|=
name|chunk
operator|.
name|getBuffer
argument_list|()
expr_stmt|;
operator|++
name|ix
expr_stmt|;
block|}
name|boolean
name|isAllocated
init|=
literal|false
decl_stmt|;
try|try
block|{
name|allocateMultiple
argument_list|(
name|targetBuffers
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
name|isAllocated
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
comment|// toDecompress/targetBuffers contents are actually already added to some structures that
comment|// will be cleaned up on error. Remove the unallocated buffers; keep the cached buffers in.
if|if
condition|(
operator|!
name|isAllocated
condition|)
block|{
comment|// Inefficient - this only happens during cleanup on errors.
for|for
control|(
name|MemoryBuffer
name|buf
range|:
name|targetBuffers
control|)
block|{
name|csd
operator|.
name|getCacheBuffers
argument_list|()
operator|.
name|remove
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ProcCacheChunk
name|chunk
range|:
name|toDecompress
control|)
block|{
name|chunk
operator|.
name|buffer
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|// 4. Now decompress (or copy) the data into cache buffers.
name|int
name|decompressedIx
init|=
literal|0
decl_stmt|;
try|try
block|{
while|while
condition|(
name|decompressedIx
operator|<
name|toDecompress
operator|.
name|size
argument_list|()
condition|)
block|{
name|ProcCacheChunk
name|chunk
init|=
name|toDecompress
operator|.
name|get
argument_list|(
name|decompressedIx
argument_list|)
decl_stmt|;
name|ByteBuffer
name|dest
init|=
name|chunk
operator|.
name|getBuffer
argument_list|()
operator|.
name|getByteBufferRaw
argument_list|()
decl_stmt|;
if|if
condition|(
name|chunk
operator|.
name|isOriginalDataCompressed
condition|)
block|{
name|boolean
name|isOk
init|=
literal|false
decl_stmt|;
try|try
block|{
name|decompressChunk
argument_list|(
name|chunk
operator|.
name|originalData
argument_list|,
name|codec
argument_list|,
name|dest
argument_list|)
expr_stmt|;
name|isOk
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|isOk
condition|)
block|{
name|isCodecFailure
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|copyUncompressedChunk
argument_list|(
name|chunk
operator|.
name|originalData
argument_list|,
name|dest
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Locking "
operator|+
name|chunk
operator|.
name|getBuffer
argument_list|()
operator|+
literal|" due to reuse (after decompression)"
argument_list|)
expr_stmt|;
block|}
comment|// After we set originalData to null, we incref the buffer and the cleanup would decref it.
comment|// Note that this assumes the failure during incref means incref didn't occur.
try|try
block|{
name|cacheWrapper
operator|.
name|reuseBuffer
argument_list|(
name|chunk
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|chunk
operator|.
name|originalData
operator|=
literal|null
expr_stmt|;
block|}
operator|++
name|decompressedIx
expr_stmt|;
block|}
block|}
finally|finally
block|{
comment|// This will only execute on error. Deallocate the remaining allocated buffers explicitly.
comment|// The ones that were already incref-ed will be cleaned up with the regular cache buffers.
while|while
condition|(
name|decompressedIx
operator|<
name|toDecompress
operator|.
name|size
argument_list|()
condition|)
block|{
name|ProcCacheChunk
name|chunk
init|=
name|toDecompress
operator|.
name|get
argument_list|(
name|decompressedIx
argument_list|)
decl_stmt|;
name|csd
operator|.
name|getCacheBuffers
argument_list|()
operator|.
name|remove
argument_list|(
name|chunk
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
operator|.
name|deallocate
argument_list|(
name|chunk
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Ignoring the cleanup error after another error"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
name|chunk
operator|.
name|setBuffer
argument_list|(
literal|null
argument_list|)
expr_stmt|;
operator|++
name|decompressedIx
expr_stmt|;
block|}
block|}
comment|// 5. Release the copies we made directly to the cleaner.
name|releaseBuffers
argument_list|(
name|toReleaseCopies
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// 6. Finally, put uncompressed data to cache.
if|if
condition|(
name|fileKey
operator|!=
literal|null
condition|)
block|{
name|long
index|[]
name|collisionMask
init|=
name|cacheWrapper
operator|.
name|putFileData
argument_list|(
name|fileKey
argument_list|,
name|cacheKeys
argument_list|,
name|targetBuffers
argument_list|,
name|baseOffset
argument_list|,
name|tag
argument_list|)
decl_stmt|;
name|processCacheCollisions
argument_list|(
name|collisionMask
argument_list|,
name|toDecompress
argument_list|,
name|targetBuffers
argument_list|,
name|csd
operator|.
name|getCacheBuffers
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// 7. It may happen that we know we won't use some cache buffers anymore (the alternative
comment|//    is that we will use the same buffers for other streams in separate calls).
comment|//    Release initial refcounts.
for|for
control|(
name|ProcCacheChunk
name|chunk
range|:
name|toDecompress
control|)
block|{
name|ponderReleaseInitialRefcount
argument_list|(
name|unlockUntilCOffset
argument_list|,
name|streamOffset
argument_list|,
name|chunk
argument_list|)
expr_stmt|;
block|}
return|return
name|lastUncompressed
return|;
block|}
comment|/** Subset of readEncodedStream specific to compressed streams, separate to avoid long methods. */
specifier|private
name|CacheChunk
name|prepareRangesForCompressedRead
parameter_list|(
name|long
name|cOffset
parameter_list|,
name|long
name|endCOffset
parameter_list|,
name|long
name|streamOffset
parameter_list|,
name|long
name|unlockUntilCOffset
parameter_list|,
name|DiskRangeList
name|current
parameter_list|,
name|ColumnStreamData
name|columnStreamData
parameter_list|,
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
parameter_list|,
name|List
argument_list|<
name|ByteBuffer
argument_list|>
name|toReleaseCopies
parameter_list|,
name|List
argument_list|<
name|ProcCacheChunk
argument_list|>
name|toDecompress
parameter_list|,
name|List
argument_list|<
name|IncompleteCb
argument_list|>
name|badEstimates
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|cOffset
operator|>
name|current
operator|.
name|getOffset
argument_list|()
condition|)
block|{
comment|// Target compression block is in the middle of the range; slice the range in two.
name|current
operator|=
name|current
operator|.
name|split
argument_list|(
name|cOffset
argument_list|)
operator|.
name|next
expr_stmt|;
block|}
name|long
name|currentOffset
init|=
name|cOffset
decl_stmt|;
name|CacheChunk
name|lastUncompressed
init|=
literal|null
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|DiskRangeList
name|next
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|current
operator|instanceof
name|CacheChunk
condition|)
block|{
comment|// 2a. This is a decoded compression buffer, add as is.
name|CacheChunk
name|cc
init|=
operator|(
name|CacheChunk
operator|)
name|current
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Locking "
operator|+
name|cc
operator|.
name|getBuffer
argument_list|()
operator|+
literal|" due to reuse"
argument_list|)
expr_stmt|;
block|}
name|cacheWrapper
operator|.
name|reuseBuffer
argument_list|(
name|cc
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
name|columnStreamData
operator|.
name|getCacheBuffers
argument_list|()
operator|.
name|add
argument_list|(
name|cc
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
name|cc
operator|.
name|getEnd
argument_list|()
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Adding an already-uncompressed buffer "
operator|+
name|cc
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ponderReleaseInitialRefcount
argument_list|(
name|unlockUntilCOffset
argument_list|,
name|streamOffset
argument_list|,
name|cc
argument_list|)
expr_stmt|;
name|lastUncompressed
operator|=
name|cc
expr_stmt|;
name|next
operator|=
name|current
operator|.
name|next
expr_stmt|;
if|if
condition|(
name|next
operator|!=
literal|null
operator|&&
operator|(
name|endCOffset
operator|>=
literal|0
operator|&&
name|currentOffset
operator|<
name|endCOffset
operator|)
operator|&&
name|next
operator|.
name|getOffset
argument_list|()
operator|>=
name|endCOffset
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expected data at "
operator|+
name|currentOffset
operator|+
literal|" (reading until "
operator|+
name|endCOffset
operator|+
literal|"), but the next buffer starts at "
operator|+
name|next
operator|.
name|getOffset
argument_list|()
argument_list|)
throw|;
block|}
block|}
elseif|else
if|if
condition|(
name|current
operator|instanceof
name|IncompleteCb
condition|)
block|{
comment|// 2b. This is a known incomplete CB caused by ORC CB end boundaries being estimates.
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Cannot read "
operator|+
name|current
argument_list|)
expr_stmt|;
block|}
name|next
operator|=
literal|null
expr_stmt|;
name|currentOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
comment|// 2c. This is a compressed buffer. We need to uncompress it; the buffer can comprise
comment|// several disk ranges, so we might need to combine them.
if|if
condition|(
operator|!
operator|(
name|current
operator|instanceof
name|BufferChunk
operator|)
condition|)
block|{
name|String
name|msg
init|=
literal|"Found an unexpected "
operator|+
name|current
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|": "
operator|+
name|current
operator|+
literal|" while looking at "
operator|+
name|currentOffset
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
name|BufferChunk
name|bc
init|=
operator|(
name|BufferChunk
operator|)
name|current
decl_stmt|;
name|ProcCacheChunk
name|newCached
init|=
name|addOneCompressionBuffer
argument_list|(
name|bc
argument_list|,
name|columnStreamData
operator|.
name|getCacheBuffers
argument_list|()
argument_list|,
name|toDecompress
argument_list|,
name|toRelease
argument_list|,
name|toReleaseCopies
argument_list|,
name|badEstimates
argument_list|)
decl_stmt|;
name|lastUncompressed
operator|=
operator|(
name|newCached
operator|==
literal|null
operator|)
condition|?
name|lastUncompressed
else|:
name|newCached
expr_stmt|;
name|next
operator|=
operator|(
name|newCached
operator|!=
literal|null
operator|)
condition|?
name|newCached
operator|.
name|next
else|:
literal|null
expr_stmt|;
name|currentOffset
operator|=
operator|(
name|next
operator|!=
literal|null
operator|)
condition|?
name|next
operator|.
name|getOffset
argument_list|()
else|:
operator|-
literal|1
expr_stmt|;
block|}
if|if
condition|(
name|next
operator|==
literal|null
operator|||
operator|(
name|endCOffset
operator|>=
literal|0
operator|&&
name|currentOffset
operator|>=
name|endCOffset
operator|)
condition|)
block|{
break|break;
block|}
name|current
operator|=
name|next
expr_stmt|;
block|}
return|return
name|lastUncompressed
return|;
block|}
comment|/** Subset of readEncodedStream specific to uncompressed streams, separate to avoid long methods. */
specifier|private
name|CacheChunk
name|prepareRangesForUncompressedRead
parameter_list|(
name|long
name|cOffset
parameter_list|,
name|long
name|endCOffset
parameter_list|,
name|long
name|streamOffset
parameter_list|,
name|long
name|unlockUntilCOffset
parameter_list|,
name|DiskRangeList
name|current
parameter_list|,
name|ColumnStreamData
name|columnStreamData
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Note: we are called after preReadUncompressedStream, so it doesn't have to do nearly as much
comment|//       as prepareRangesForCompressedRead does; e.g. every buffer is already a CacheChunk.
name|long
name|currentOffset
init|=
name|cOffset
decl_stmt|;
name|CacheChunk
name|lastUncompressed
init|=
literal|null
decl_stmt|;
name|boolean
name|isFirst
init|=
literal|true
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|DiskRangeList
name|next
init|=
literal|null
decl_stmt|;
assert|assert
name|current
operator|instanceof
name|CacheChunk
assert|;
name|lastUncompressed
operator|=
operator|(
name|CacheChunk
operator|)
name|current
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Locking "
operator|+
name|lastUncompressed
operator|.
name|getBuffer
argument_list|()
operator|+
literal|" due to reuse"
argument_list|)
expr_stmt|;
block|}
name|cacheWrapper
operator|.
name|reuseBuffer
argument_list|(
name|lastUncompressed
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isFirst
condition|)
block|{
name|columnStreamData
operator|.
name|setIndexBaseOffset
argument_list|(
call|(
name|int
call|)
argument_list|(
name|lastUncompressed
operator|.
name|getOffset
argument_list|()
operator|-
name|streamOffset
argument_list|)
argument_list|)
expr_stmt|;
name|isFirst
operator|=
literal|false
expr_stmt|;
block|}
name|columnStreamData
operator|.
name|getCacheBuffers
argument_list|()
operator|.
name|add
argument_list|(
name|lastUncompressed
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
name|currentOffset
operator|=
name|lastUncompressed
operator|.
name|getEnd
argument_list|()
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Adding an uncompressed buffer "
operator|+
name|lastUncompressed
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ponderReleaseInitialRefcount
argument_list|(
name|unlockUntilCOffset
argument_list|,
name|streamOffset
argument_list|,
name|lastUncompressed
argument_list|)
expr_stmt|;
name|next
operator|=
name|current
operator|.
name|next
expr_stmt|;
if|if
condition|(
name|next
operator|==
literal|null
operator|||
operator|(
name|endCOffset
operator|>=
literal|0
operator|&&
name|currentOffset
operator|>=
name|endCOffset
operator|)
condition|)
block|{
break|break;
block|}
name|current
operator|=
name|next
expr_stmt|;
block|}
return|return
name|lastUncompressed
return|;
block|}
comment|/**    * To achieve some sort of consistent cache boundaries, we will cache streams deterministically;    * in segments starting w/stream start, and going for either stream size or some fixed size.    * If we are not reading the entire segment's worth of data, then we will not cache the partial    * RGs; the breakage of cache assumptions (no interleaving blocks, etc.) is way too much PITA    * to handle just for this case.    * We could avoid copy in non-zcr case and manage the buffer that was not allocated by our    * allocator. Uncompressed case is not mainline though so let's not complicate it.    * @param kind    */
specifier|private
name|DiskRangeList
name|preReadUncompressedStream
parameter_list|(
name|long
name|baseOffset
parameter_list|,
name|DiskRangeList
name|start
parameter_list|,
name|long
name|streamOffset
parameter_list|,
name|long
name|streamEnd
parameter_list|,
name|Kind
name|kind
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|streamOffset
operator|==
name|streamEnd
condition|)
return|return
literal|null
return|;
name|List
argument_list|<
name|UncompressedCacheChunk
argument_list|>
name|toCache
init|=
literal|null
decl_stmt|;
comment|// 1. Find our bearings in the stream.
name|DiskRangeList
name|current
init|=
name|findIntersectingPosition
argument_list|(
name|start
argument_list|,
name|streamOffset
argument_list|,
name|streamEnd
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Starting pre-read for ["
operator|+
name|streamOffset
operator|+
literal|","
operator|+
name|streamEnd
operator|+
literal|") at "
operator|+
name|current
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logStartStream
argument_list|(
name|kind
argument_list|,
name|streamOffset
argument_list|,
name|streamEnd
argument_list|,
name|streamOffset
argument_list|)
expr_stmt|;
name|trace
operator|.
name|logStartRead
argument_list|(
name|current
argument_list|)
expr_stmt|;
if|if
condition|(
name|streamOffset
operator|>
name|current
operator|.
name|getOffset
argument_list|()
condition|)
block|{
comment|// Target compression block is in the middle of the range; slice the range in two.
name|current
operator|=
name|current
operator|.
name|split
argument_list|(
name|streamOffset
argument_list|)
operator|.
name|next
expr_stmt|;
block|}
comment|// Account for maximum cache buffer size.
name|long
name|streamLen
init|=
name|streamEnd
operator|-
name|streamOffset
decl_stmt|;
name|int
name|partSize
init|=
name|determineUncompressedPartSize
argument_list|()
decl_stmt|,
name|partCount
init|=
call|(
name|int
call|)
argument_list|(
name|streamLen
operator|/
name|partSize
argument_list|)
operator|+
operator|(
operator|(
operator|(
name|streamLen
operator|%
name|partSize
operator|)
operator|!=
literal|0
operator|)
condition|?
literal|1
else|:
literal|0
operator|)
decl_stmt|;
name|CacheChunk
name|lastUncompressed
init|=
literal|null
decl_stmt|;
name|MemoryBuffer
index|[]
name|singleAlloc
init|=
operator|new
name|MemoryBuffer
index|[
literal|1
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partCount
condition|;
operator|++
name|i
control|)
block|{
name|long
name|partOffset
init|=
name|streamOffset
operator|+
operator|(
name|i
operator|*
name|partSize
operator|)
decl_stmt|,
name|partEnd
init|=
name|Math
operator|.
name|min
argument_list|(
name|partOffset
operator|+
name|partSize
argument_list|,
name|streamEnd
argument_list|)
decl_stmt|;
name|long
name|hasEntirePartTo
init|=
name|partOffset
decl_stmt|;
comment|// We have 0 bytes of data for this part, for now.
if|if
condition|(
name|current
operator|==
literal|null
condition|)
block|{
break|break;
comment|// We have no data from this point on (could be unneeded), skip.
block|}
assert|assert
name|partOffset
operator|<=
name|current
operator|.
name|getOffset
argument_list|()
assert|;
if|if
condition|(
name|partOffset
operator|==
name|current
operator|.
name|getOffset
argument_list|()
operator|&&
name|current
operator|instanceof
name|CacheChunk
condition|)
block|{
comment|// We assume cache chunks would always match the way we read, so check and skip it.
assert|assert
name|current
operator|.
name|getOffset
argument_list|()
operator|==
name|partOffset
operator|&&
name|current
operator|.
name|getEnd
argument_list|()
operator|==
name|partEnd
assert|;
name|lastUncompressed
operator|=
operator|(
name|CacheChunk
operator|)
name|current
expr_stmt|;
name|current
operator|=
name|current
operator|.
name|next
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|current
operator|.
name|getOffset
argument_list|()
operator|>=
name|partEnd
condition|)
block|{
continue|continue;
comment|// We have no data at all for this part of the stream (could be unneeded), skip.
block|}
comment|// We have some disk buffers... see if we have entire part, etc.
name|UncompressedCacheChunk
name|candidateCached
init|=
literal|null
decl_stmt|;
comment|// We will cache if we have the entire part.
name|DiskRangeList
name|next
init|=
name|current
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|boolean
name|noMoreDataForPart
init|=
operator|(
name|next
operator|==
literal|null
operator|||
name|next
operator|.
name|getOffset
argument_list|()
operator|>=
name|partEnd
operator|)
decl_stmt|;
if|if
condition|(
name|noMoreDataForPart
operator|&&
name|hasEntirePartTo
operator|<
name|partEnd
operator|&&
name|candidateCached
operator|!=
literal|null
condition|)
block|{
comment|// We are missing a section at the end of the part... copy the start to non-cached.
name|lastUncompressed
operator|=
name|copyAndReplaceCandidateToNonCached
argument_list|(
name|candidateCached
argument_list|,
name|partOffset
argument_list|,
name|hasEntirePartTo
argument_list|,
name|cacheWrapper
argument_list|,
name|singleAlloc
argument_list|)
expr_stmt|;
name|candidateCached
operator|=
literal|null
expr_stmt|;
block|}
name|current
operator|=
name|next
expr_stmt|;
if|if
condition|(
name|noMoreDataForPart
condition|)
break|break;
comment|// Done with this part.
if|if
condition|(
name|current
operator|.
name|getEnd
argument_list|()
operator|>
name|partEnd
condition|)
block|{
comment|// If the current buffer contains multiple parts, split it.
name|current
operator|=
name|current
operator|.
name|split
argument_list|(
name|partEnd
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Processing uncompressed file data at ["
operator|+
name|current
operator|.
name|getOffset
argument_list|()
operator|+
literal|", "
operator|+
name|current
operator|.
name|getEnd
argument_list|()
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logUncompressedData
argument_list|(
name|current
operator|.
name|getOffset
argument_list|()
argument_list|,
name|current
operator|.
name|getEnd
argument_list|()
argument_list|)
expr_stmt|;
name|BufferChunk
name|curBc
init|=
operator|(
name|BufferChunk
operator|)
name|current
decl_stmt|;
comment|// Track if we still have the entire part.
name|long
name|hadEntirePartTo
init|=
name|hasEntirePartTo
decl_stmt|;
comment|// We have data until the end of current block if we had it until the beginning.
name|hasEntirePartTo
operator|=
operator|(
name|hasEntirePartTo
operator|==
name|current
operator|.
name|getOffset
argument_list|()
operator|)
condition|?
name|current
operator|.
name|getEnd
argument_list|()
else|:
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|hasEntirePartTo
operator|==
operator|-
literal|1
condition|)
block|{
comment|// We don't have the entire part; copy both whatever we intended to cache, and the rest,
comment|// to an allocated buffer. We could try to optimize a bit if we have contiguous buffers
comment|// with gaps, but it's probably not needed.
if|if
condition|(
name|candidateCached
operator|!=
literal|null
condition|)
block|{
assert|assert
name|hadEntirePartTo
operator|!=
operator|-
literal|1
assert|;
name|copyAndReplaceCandidateToNonCached
argument_list|(
name|candidateCached
argument_list|,
name|partOffset
argument_list|,
name|hadEntirePartTo
argument_list|,
name|cacheWrapper
argument_list|,
name|singleAlloc
argument_list|)
expr_stmt|;
name|candidateCached
operator|=
literal|null
expr_stmt|;
block|}
name|lastUncompressed
operator|=
name|copyAndReplaceUncompressedToNonCached
argument_list|(
name|curBc
argument_list|,
name|cacheWrapper
argument_list|,
name|singleAlloc
argument_list|)
expr_stmt|;
name|next
operator|=
name|lastUncompressed
operator|.
name|next
expr_stmt|;
comment|// There may be more data after the gap.
block|}
else|else
block|{
comment|// So far we have all the data from the beginning of the part.
if|if
condition|(
name|candidateCached
operator|==
literal|null
condition|)
block|{
name|candidateCached
operator|=
operator|new
name|UncompressedCacheChunk
argument_list|(
name|curBc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|candidateCached
operator|.
name|addChunk
argument_list|(
name|curBc
argument_list|)
expr_stmt|;
block|}
name|next
operator|=
name|current
operator|.
name|next
expr_stmt|;
block|}
block|}
if|if
condition|(
name|candidateCached
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|toCache
operator|==
literal|null
condition|)
block|{
name|toCache
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partCount
operator|-
name|i
argument_list|)
expr_stmt|;
block|}
name|toCache
operator|.
name|add
argument_list|(
name|candidateCached
argument_list|)
expr_stmt|;
block|}
block|}
comment|// 3. Allocate the buffers, prepare cache keys.
if|if
condition|(
name|toCache
operator|==
literal|null
condition|)
return|return
name|lastUncompressed
return|;
comment|// Nothing to copy and cache.
name|MemoryBuffer
index|[]
name|targetBuffers
init|=
name|toCache
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|?
name|singleAlloc
else|:
operator|new
name|MemoryBuffer
index|[
name|toCache
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|targetBuffers
index|[
literal|0
index|]
operator|=
literal|null
expr_stmt|;
name|DiskRange
index|[]
name|cacheKeys
init|=
operator|new
name|DiskRange
index|[
name|toCache
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|ix
init|=
literal|0
decl_stmt|;
for|for
control|(
name|UncompressedCacheChunk
name|chunk
range|:
name|toCache
control|)
block|{
name|cacheKeys
index|[
name|ix
index|]
operator|=
name|chunk
expr_stmt|;
comment|// Relies on the fact that cache does not actually store these.
operator|++
name|ix
expr_stmt|;
block|}
name|allocateMultiple
argument_list|(
name|targetBuffers
argument_list|,
call|(
name|int
call|)
argument_list|(
name|partCount
operator|==
literal|1
condition|?
name|streamLen
else|:
name|partSize
argument_list|)
argument_list|)
expr_stmt|;
comment|// 4. Now copy the data into cache buffers.
name|ix
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|UncompressedCacheChunk
name|candidateCached
range|:
name|toCache
control|)
block|{
name|candidateCached
operator|.
name|setBuffer
argument_list|(
name|targetBuffers
index|[
name|ix
index|]
argument_list|)
expr_stmt|;
name|ByteBuffer
name|dest
init|=
name|candidateCached
operator|.
name|getBuffer
argument_list|()
operator|.
name|getByteBufferRaw
argument_list|()
decl_stmt|;
name|copyAndReplaceUncompressedChunks
argument_list|(
name|candidateCached
argument_list|,
name|dest
argument_list|,
name|candidateCached
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|candidateCached
operator|.
name|clear
argument_list|()
expr_stmt|;
name|lastUncompressed
operator|=
name|candidateCached
expr_stmt|;
operator|++
name|ix
expr_stmt|;
block|}
comment|// 5. Put uncompressed data to cache.
if|if
condition|(
name|fileKey
operator|!=
literal|null
condition|)
block|{
name|long
index|[]
name|collisionMask
init|=
name|cacheWrapper
operator|.
name|putFileData
argument_list|(
name|fileKey
argument_list|,
name|cacheKeys
argument_list|,
name|targetBuffers
argument_list|,
name|baseOffset
argument_list|,
name|tag
argument_list|)
decl_stmt|;
name|processCacheCollisions
argument_list|(
name|collisionMask
argument_list|,
name|toCache
argument_list|,
name|targetBuffers
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
return|return
name|lastUncompressed
return|;
block|}
specifier|private
name|int
name|determineUncompressedPartSize
parameter_list|()
block|{
comment|// We will break the uncompressed data in the cache in the chunks that are the size
comment|// of the prevalent ORC compression buffer (the default), or maximum allocation (since we
comment|// cannot allocate bigger chunks), whichever is less.
name|long
name|orcCbSizeDefault
init|=
operator|(
operator|(
name|Number
operator|)
name|OrcConf
operator|.
name|BUFFER_SIZE
operator|.
name|getDefaultValue
argument_list|()
operator|)
operator|.
name|longValue
argument_list|()
decl_stmt|;
name|int
name|maxAllocSize
init|=
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
operator|.
name|getMaxAllocation
argument_list|()
decl_stmt|;
return|return
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|maxAllocSize
argument_list|,
name|orcCbSizeDefault
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|void
name|copyUncompressedChunk
parameter_list|(
name|ByteBuffer
name|src
parameter_list|,
name|ByteBuffer
name|dest
parameter_list|)
block|{
name|int
name|startPos
init|=
name|dest
operator|.
name|position
argument_list|()
decl_stmt|,
name|startLim
init|=
name|dest
operator|.
name|limit
argument_list|()
decl_stmt|;
name|dest
operator|.
name|put
argument_list|(
name|src
argument_list|)
expr_stmt|;
comment|// Copy uncompressed data to cache.
comment|// Put call moves position forward by the size of the data.
name|int
name|newPos
init|=
name|dest
operator|.
name|position
argument_list|()
decl_stmt|;
if|if
condition|(
name|newPos
operator|>
name|startLim
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"After copying, buffer ["
operator|+
name|startPos
operator|+
literal|", "
operator|+
name|startLim
operator|+
literal|") became ["
operator|+
name|newPos
operator|+
literal|", "
operator|+
name|dest
operator|.
name|limit
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
name|dest
operator|.
name|position
argument_list|(
name|startPos
argument_list|)
expr_stmt|;
name|dest
operator|.
name|limit
argument_list|(
name|newPos
argument_list|)
expr_stmt|;
block|}
specifier|private
name|CacheChunk
name|copyAndReplaceCandidateToNonCached
parameter_list|(
name|UncompressedCacheChunk
name|candidateCached
parameter_list|,
name|long
name|partOffset
parameter_list|,
name|long
name|candidateEnd
parameter_list|,
name|DataCache
name|cacheWrapper
parameter_list|,
name|MemoryBuffer
index|[]
name|singleAlloc
parameter_list|)
block|{
comment|// We thought we had the entire part to cache, but we don't; convert start to
comment|// non-cached. Since we are at the first gap, the previous stuff must be contiguous.
name|singleAlloc
index|[
literal|0
index|]
operator|=
literal|null
expr_stmt|;
name|trace
operator|.
name|logPartialUncompressedData
argument_list|(
name|partOffset
argument_list|,
name|candidateEnd
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|allocateMultiple
argument_list|(
name|singleAlloc
argument_list|,
call|(
name|int
call|)
argument_list|(
name|candidateEnd
operator|-
name|partOffset
argument_list|)
argument_list|)
expr_stmt|;
name|MemoryBuffer
name|buffer
init|=
name|singleAlloc
index|[
literal|0
index|]
decl_stmt|;
name|cacheWrapper
operator|.
name|reuseBuffer
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|ByteBuffer
name|dest
init|=
name|buffer
operator|.
name|getByteBufferRaw
argument_list|()
decl_stmt|;
name|CacheChunk
name|tcc
init|=
operator|new
name|CacheChunk
argument_list|(
name|buffer
argument_list|,
name|partOffset
argument_list|,
name|candidateEnd
argument_list|)
decl_stmt|;
name|copyAndReplaceUncompressedChunks
argument_list|(
name|candidateCached
argument_list|,
name|dest
argument_list|,
name|tcc
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
name|tcc
return|;
block|}
specifier|private
name|void
name|allocateMultiple
parameter_list|(
name|MemoryBuffer
index|[]
name|dest
parameter_list|,
name|int
name|size
parameter_list|)
block|{
if|if
condition|(
name|allocator
operator|!=
literal|null
condition|)
block|{
name|allocator
operator|.
name|allocateMultiple
argument_list|(
name|dest
argument_list|,
name|size
argument_list|,
name|cacheWrapper
operator|.
name|getDataBufferFactory
argument_list|()
argument_list|,
name|isStopped
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|cacheWrapper
operator|.
name|getAllocator
argument_list|()
operator|.
name|allocateMultiple
argument_list|(
name|dest
argument_list|,
name|size
argument_list|,
name|cacheWrapper
operator|.
name|getDataBufferFactory
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|CacheChunk
name|copyAndReplaceUncompressedToNonCached
parameter_list|(
name|BufferChunk
name|bc
parameter_list|,
name|DataCache
name|cacheWrapper
parameter_list|,
name|MemoryBuffer
index|[]
name|singleAlloc
parameter_list|)
block|{
name|singleAlloc
index|[
literal|0
index|]
operator|=
literal|null
expr_stmt|;
name|trace
operator|.
name|logPartialUncompressedData
argument_list|(
name|bc
operator|.
name|getOffset
argument_list|()
argument_list|,
name|bc
operator|.
name|getEnd
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|allocateMultiple
argument_list|(
name|singleAlloc
argument_list|,
name|bc
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
name|MemoryBuffer
name|buffer
init|=
name|singleAlloc
index|[
literal|0
index|]
decl_stmt|;
name|cacheWrapper
operator|.
name|reuseBuffer
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|ByteBuffer
name|dest
init|=
name|buffer
operator|.
name|getByteBufferRaw
argument_list|()
decl_stmt|;
name|CacheChunk
name|tcc
init|=
operator|new
name|CacheChunk
argument_list|(
name|buffer
argument_list|,
name|bc
operator|.
name|getOffset
argument_list|()
argument_list|,
name|bc
operator|.
name|getEnd
argument_list|()
argument_list|)
decl_stmt|;
name|copyUncompressedChunk
argument_list|(
name|bc
operator|.
name|getChunk
argument_list|()
argument_list|,
name|dest
argument_list|)
expr_stmt|;
name|bc
operator|.
name|replaceSelfWith
argument_list|(
name|tcc
argument_list|)
expr_stmt|;
return|return
name|tcc
return|;
block|}
specifier|private
name|void
name|copyAndReplaceUncompressedChunks
parameter_list|(
name|UncompressedCacheChunk
name|candidateCached
parameter_list|,
name|ByteBuffer
name|dest
parameter_list|,
name|CacheChunk
name|tcc
parameter_list|,
name|boolean
name|isValid
parameter_list|)
block|{
name|int
name|startPos
init|=
name|dest
operator|.
name|position
argument_list|()
decl_stmt|,
name|startLim
init|=
name|dest
operator|.
name|limit
argument_list|()
decl_stmt|;
name|DiskRangeList
name|next
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|candidateCached
operator|.
name|getCount
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|BufferChunk
name|chunk
init|=
operator|(
name|i
operator|==
literal|0
operator|)
condition|?
name|candidateCached
operator|.
name|getChunk
argument_list|()
else|:
operator|(
name|BufferChunk
operator|)
name|next
decl_stmt|;
name|dest
operator|.
name|put
argument_list|(
name|chunk
operator|.
name|getData
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isValid
condition|)
block|{
name|trace
operator|.
name|logValidUncompresseedChunk
argument_list|(
name|startLim
operator|-
name|startPos
argument_list|,
name|chunk
argument_list|)
expr_stmt|;
block|}
name|next
operator|=
name|chunk
operator|.
name|next
expr_stmt|;
if|if
condition|(
name|i
operator|==
literal|0
condition|)
block|{
name|chunk
operator|.
name|replaceSelfWith
argument_list|(
name|tcc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|chunk
operator|.
name|removeSelf
argument_list|()
expr_stmt|;
block|}
block|}
name|int
name|newPos
init|=
name|dest
operator|.
name|position
argument_list|()
decl_stmt|;
if|if
condition|(
name|newPos
operator|>
name|startLim
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"After copying, buffer ["
operator|+
name|startPos
operator|+
literal|", "
operator|+
name|startLim
operator|+
literal|") became ["
operator|+
name|newPos
operator|+
literal|", "
operator|+
name|dest
operator|.
name|limit
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
name|dest
operator|.
name|position
argument_list|(
name|startPos
argument_list|)
expr_stmt|;
name|dest
operator|.
name|limit
argument_list|(
name|newPos
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|decompressChunk
parameter_list|(
name|ByteBuffer
name|src
parameter_list|,
name|CompressionCodec
name|codec
parameter_list|,
name|ByteBuffer
name|dest
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|startPos
init|=
name|dest
operator|.
name|position
argument_list|()
decl_stmt|,
name|startLim
init|=
name|dest
operator|.
name|limit
argument_list|()
decl_stmt|;
name|int
name|startSrcPos
init|=
name|src
operator|.
name|position
argument_list|()
decl_stmt|,
name|startSrcLim
init|=
name|src
operator|.
name|limit
argument_list|()
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Decompressing "
operator|+
name|src
operator|.
name|remaining
argument_list|()
operator|+
literal|" bytes to dest buffer pos "
operator|+
name|dest
operator|.
name|position
argument_list|()
operator|+
literal|", limit "
operator|+
name|dest
operator|.
name|limit
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|codec
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// We always need to call reset on the codec.
name|codec
operator|.
name|decompress
argument_list|(
name|src
argument_list|,
name|dest
argument_list|)
expr_stmt|;
name|dest
operator|.
name|position
argument_list|(
name|startPos
argument_list|)
expr_stmt|;
name|int
name|newLim
init|=
name|dest
operator|.
name|limit
argument_list|()
decl_stmt|;
if|if
condition|(
name|newLim
operator|>
name|startLim
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"After codec, buffer ["
operator|+
name|startPos
operator|+
literal|", "
operator|+
name|startLim
operator|+
literal|") became ["
operator|+
name|dest
operator|.
name|position
argument_list|()
operator|+
literal|", "
operator|+
name|newLim
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dest
operator|.
name|remaining
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The codec has produced 0 bytes for {"
operator|+
name|src
operator|.
name|isDirect
argument_list|()
operator|+
literal|", "
operator|+
name|src
operator|.
name|position
argument_list|()
operator|+
literal|", "
operator|+
name|src
operator|.
name|remaining
argument_list|()
operator|+
literal|"} into {"
operator|+
name|dest
operator|.
name|isDirect
argument_list|()
operator|+
literal|", "
operator|+
name|dest
operator|.
name|position
argument_list|()
operator|+
literal|", "
operator|+
name|dest
operator|.
name|remaining
argument_list|()
operator|+
literal|"}"
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|ponderReleaseInitialRefcount
parameter_list|(
name|long
name|unlockUntilCOffset
parameter_list|,
name|long
name|streamStartOffset
parameter_list|,
name|CacheChunk
name|cc
parameter_list|)
block|{
comment|// Don't release if the buffer contains any data beyond the acceptable boundary.
if|if
condition|(
name|cc
operator|.
name|getEnd
argument_list|()
operator|>
name|unlockUntilCOffset
condition|)
return|return;
assert|assert
name|cc
operator|.
name|getBuffer
argument_list|()
operator|!=
literal|null
assert|;
try|try
block|{
name|releaseInitialRefcount
argument_list|(
name|cc
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AssertionError
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"BUG: releasing initial refcount; stream start "
operator|+
name|streamStartOffset
operator|+
literal|", "
operator|+
literal|"unlocking until "
operator|+
name|unlockUntilCOffset
operator|+
literal|" from ["
operator|+
name|cc
operator|+
literal|"]: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
comment|// Release all the previous buffers that we may not have been able to release due to reuse,
comment|// as long as they are still in the same stream and are not already released.
name|DiskRangeList
name|prev
init|=
name|cc
operator|.
name|prev
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
comment|// Do not release beyond current stream (we don't know which RGs that buffer is for).
if|if
condition|(
operator|(
name|prev
operator|==
literal|null
operator|)
operator|||
operator|(
name|prev
operator|.
name|getEnd
argument_list|()
operator|<=
name|streamStartOffset
operator|)
condition|)
break|break;
comment|// Only release cache chunks; do not release ProcCacheChunks - they may not yet have data.
if|if
condition|(
name|prev
operator|.
name|getClass
argument_list|()
operator|!=
name|CacheChunk
operator|.
name|class
condition|)
break|break;
name|CacheChunk
name|prevCc
init|=
operator|(
name|CacheChunk
operator|)
name|prev
decl_stmt|;
if|if
condition|(
name|prevCc
operator|.
name|buffer
operator|==
literal|null
condition|)
break|break;
try|try
block|{
name|releaseInitialRefcount
argument_list|(
name|prevCc
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AssertionError
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"BUG: releasing initial refcount; stream start "
operator|+
name|streamStartOffset
operator|+
literal|", "
operator|+
literal|"unlocking until "
operator|+
name|unlockUntilCOffset
operator|+
literal|" from ["
operator|+
name|cc
operator|+
literal|"] and backtracked to ["
operator|+
name|prevCc
operator|+
literal|"]: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|prev
operator|=
name|prev
operator|.
name|prev
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|releaseInitialRefcount
parameter_list|(
name|CacheChunk
name|cc
parameter_list|,
name|boolean
name|isBacktracking
parameter_list|)
block|{
comment|// This is the last RG for which this buffer will be used. Remove the initial refcount
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Unlocking "
operator|+
name|cc
operator|.
name|getBuffer
argument_list|()
operator|+
literal|" for the fetching thread"
operator|+
operator|(
name|isBacktracking
condition|?
literal|"; backtracking"
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
block|}
name|cacheWrapper
operator|.
name|releaseBuffer
argument_list|(
name|cc
operator|.
name|getBuffer
argument_list|()
argument_list|)
expr_stmt|;
name|cc
operator|.
name|setBuffer
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|processCacheCollisions
parameter_list|(
name|long
index|[]
name|collisionMask
parameter_list|,
name|List
argument_list|<
name|?
extends|extends
name|CacheChunk
argument_list|>
name|toDecompress
parameter_list|,
name|MemoryBuffer
index|[]
name|targetBuffers
parameter_list|,
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|cacheBuffers
parameter_list|)
block|{
if|if
condition|(
name|collisionMask
operator|==
literal|null
condition|)
return|return;
assert|assert
name|collisionMask
operator|.
name|length
operator|>=
operator|(
name|toDecompress
operator|.
name|size
argument_list|()
operator|>>>
literal|6
operator|)
assert|;
comment|// There are some elements that were cached in parallel, take care of them.
name|long
name|maskVal
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|toDecompress
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
operator|(
name|i
operator|&
literal|63
operator|)
operator|==
literal|0
condition|)
block|{
name|maskVal
operator|=
name|collisionMask
index|[
name|i
operator|>>>
literal|6
index|]
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|maskVal
operator|&
literal|1
operator|)
operator|==
literal|1
condition|)
block|{
comment|// Cache has found an old buffer for the key and put it into array instead of our new one.
name|CacheChunk
name|replacedChunk
init|=
name|toDecompress
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|MemoryBuffer
name|replacementBuffer
init|=
name|targetBuffers
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Discarding data due to cache collision: "
operator|+
name|replacedChunk
operator|.
name|getBuffer
argument_list|()
operator|+
literal|" replaced with "
operator|+
name|replacementBuffer
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logCacheCollision
argument_list|(
name|replacedChunk
argument_list|,
name|replacementBuffer
argument_list|)
expr_stmt|;
assert|assert
name|replacedChunk
operator|.
name|getBuffer
argument_list|()
operator|!=
name|replacementBuffer
operator|:
name|i
operator|+
literal|" was not replaced in the results "
operator|+
literal|"even though mask is ["
operator|+
name|Long
operator|.
name|toBinaryString
argument_list|(
name|maskVal
argument_list|)
operator|+
literal|"]"
assert|;
name|replacedChunk
operator|.
name|handleCacheCollision
argument_list|(
name|cacheWrapper
argument_list|,
name|replacementBuffer
argument_list|,
name|cacheBuffers
argument_list|)
expr_stmt|;
block|}
name|maskVal
operator|>>=
literal|1
expr_stmt|;
block|}
block|}
comment|/** Finds compressed offset in a stream and makes sure iter points to its position.      This may be necessary for obscure combinations of compression and encoding boundaries. */
specifier|private
specifier|static
name|DiskRangeList
name|findExactPosition
parameter_list|(
name|DiskRangeList
name|ranges
parameter_list|,
name|long
name|offset
parameter_list|)
block|{
if|if
condition|(
name|offset
operator|<
literal|0
condition|)
return|return
name|ranges
return|;
name|ranges
operator|=
name|findUpperBound
argument_list|(
name|ranges
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|ranges
operator|=
name|findLowerBound
argument_list|(
name|ranges
argument_list|,
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|offset
operator|<
name|ranges
operator|.
name|getOffset
argument_list|()
operator|||
name|offset
operator|>=
name|ranges
operator|.
name|getEnd
argument_list|()
condition|)
block|{
name|throwRangesError
argument_list|(
name|ranges
argument_list|,
name|offset
argument_list|,
name|offset
argument_list|)
expr_stmt|;
block|}
return|return
name|ranges
return|;
block|}
specifier|private
specifier|static
name|DiskRangeList
name|findIntersectingPosition
parameter_list|(
name|DiskRangeList
name|ranges
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|end
parameter_list|)
block|{
if|if
condition|(
name|offset
operator|<
literal|0
condition|)
return|return
name|ranges
return|;
name|ranges
operator|=
name|findUpperBound
argument_list|(
name|ranges
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|ranges
operator|=
name|findLowerBound
argument_list|(
name|ranges
argument_list|,
name|end
argument_list|)
expr_stmt|;
comment|// We are now on some intersecting buffer, find the first intersecting buffer.
while|while
condition|(
name|ranges
operator|.
name|prev
operator|!=
literal|null
operator|&&
name|ranges
operator|.
name|prev
operator|.
name|getEnd
argument_list|()
operator|>
name|offset
condition|)
block|{
if|if
condition|(
name|ranges
operator|.
name|prev
operator|.
name|getEnd
argument_list|()
operator|>
name|ranges
operator|.
name|getOffset
argument_list|()
condition|)
block|{
name|throwRangesError
argument_list|(
name|ranges
argument_list|,
name|offset
argument_list|,
name|end
argument_list|)
expr_stmt|;
block|}
name|ranges
operator|=
name|ranges
operator|.
name|prev
expr_stmt|;
block|}
return|return
name|ranges
return|;
block|}
specifier|public
specifier|static
name|DiskRangeList
name|findLowerBound
parameter_list|(
name|DiskRangeList
name|ranges
parameter_list|,
name|long
name|end
parameter_list|)
block|{
while|while
condition|(
name|ranges
operator|.
name|getOffset
argument_list|()
operator|>
name|end
condition|)
block|{
if|if
condition|(
name|ranges
operator|.
name|prev
operator|.
name|getEnd
argument_list|()
operator|>
name|ranges
operator|.
name|getOffset
argument_list|()
condition|)
block|{
name|throwRangesError
argument_list|(
name|ranges
argument_list|,
name|end
argument_list|,
name|end
argument_list|)
expr_stmt|;
block|}
name|ranges
operator|=
name|ranges
operator|.
name|prev
expr_stmt|;
block|}
return|return
name|ranges
return|;
block|}
specifier|public
specifier|static
name|DiskRangeList
name|findUpperBound
parameter_list|(
name|DiskRangeList
name|ranges
parameter_list|,
name|long
name|offset
parameter_list|)
block|{
while|while
condition|(
name|ranges
operator|.
name|getEnd
argument_list|()
operator|<=
name|offset
condition|)
block|{
if|if
condition|(
name|ranges
operator|.
name|next
operator|.
name|getOffset
argument_list|()
operator|<
name|ranges
operator|.
name|getEnd
argument_list|()
condition|)
block|{
name|throwRangesError
argument_list|(
name|ranges
argument_list|,
name|offset
argument_list|,
name|offset
argument_list|)
expr_stmt|;
block|}
name|ranges
operator|=
name|ranges
operator|.
name|next
expr_stmt|;
block|}
return|return
name|ranges
return|;
block|}
specifier|private
specifier|static
name|void
name|throwRangesError
parameter_list|(
name|DiskRangeList
name|ranges
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|end
parameter_list|)
block|{
comment|// We are going to fail, so it is ok to do expensive stuff. Ranges are broken, play it safe.
name|IdentityHashMap
argument_list|<
name|DiskRangeList
argument_list|,
name|Boolean
argument_list|>
name|seen
init|=
operator|new
name|IdentityHashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|seen
operator|.
name|put
argument_list|(
name|ranges
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|StringBuilder
name|errors
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
while|while
condition|(
name|ranges
operator|.
name|prev
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|ranges
operator|.
name|prev
operator|.
name|next
operator|!=
name|ranges
condition|)
block|{
name|errors
operator|.
name|append
argument_list|(
literal|"inconsistent list going back: ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
argument_list|)
operator|.
name|append
argument_list|(
literal|"].prev = ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
operator|.
name|prev
argument_list|)
operator|.
name|append
argument_list|(
literal|"]; prev.next = ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
operator|.
name|prev
operator|.
name|next
argument_list|)
operator|.
name|append
argument_list|(
literal|"]; "
argument_list|)
expr_stmt|;
comment|// Stop, as we won't be able to go forward.
break|break;
block|}
if|if
condition|(
name|seen
operator|.
name|containsKey
argument_list|(
name|ranges
operator|.
name|prev
argument_list|)
condition|)
block|{
name|errors
operator|.
name|append
argument_list|(
literal|"loop: ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
argument_list|)
operator|.
name|append
argument_list|(
literal|"].prev = ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
operator|.
name|prev
argument_list|)
operator|.
name|append
argument_list|(
literal|"]; "
argument_list|)
expr_stmt|;
break|break;
block|}
name|ranges
operator|=
name|ranges
operator|.
name|prev
expr_stmt|;
name|seen
operator|.
name|put
argument_list|(
name|ranges
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|seen
operator|.
name|clear
argument_list|()
expr_stmt|;
name|seen
operator|.
name|put
argument_list|(
name|ranges
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"Incorrect ranges detected while looking for "
argument_list|)
decl_stmt|;
if|if
condition|(
name|offset
operator|==
name|end
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|offset
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"["
argument_list|)
operator|.
name|append
argument_list|(
name|offset
argument_list|)
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
operator|.
name|append
argument_list|(
name|end
argument_list|)
operator|.
name|append
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|": ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
argument_list|)
operator|.
name|append
argument_list|(
literal|"], "
argument_list|)
expr_stmt|;
while|while
condition|(
name|ranges
operator|.
name|next
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|ranges
operator|.
name|next
operator|.
name|prev
operator|!=
name|ranges
condition|)
block|{
name|errors
operator|.
name|append
argument_list|(
literal|"inconsistent list going forward: ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
argument_list|)
operator|.
name|append
argument_list|(
literal|"].next.prev = ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
operator|.
name|next
operator|.
name|prev
argument_list|)
operator|.
name|append
argument_list|(
literal|"]; "
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|seen
operator|.
name|containsKey
argument_list|(
name|ranges
operator|.
name|next
argument_list|)
condition|)
block|{
name|errors
operator|.
name|append
argument_list|(
literal|"loop: ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
argument_list|)
operator|.
name|append
argument_list|(
literal|"].next = ["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
operator|.
name|next
argument_list|)
operator|.
name|append
argument_list|(
literal|"]; "
argument_list|)
expr_stmt|;
break|break;
block|}
name|ranges
operator|=
name|ranges
operator|.
name|next
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"["
argument_list|)
operator|.
name|append
argument_list|(
name|ranges
argument_list|)
operator|.
name|append
argument_list|(
literal|"], "
argument_list|)
expr_stmt|;
name|seen
operator|.
name|put
argument_list|(
name|ranges
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"; "
argument_list|)
operator|.
name|append
argument_list|(
name|errors
argument_list|)
expr_stmt|;
name|String
name|error
init|=
name|sb
operator|.
name|toString
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|error
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|error
argument_list|)
throw|;
block|}
comment|/**    * Reads one compression block from the source; handles compression blocks read from    * multiple ranges (usually, that would only happen with zcr).    * Adds stuff to cachedBuffers, toDecompress and toRelease (see below what each does).    * @param current BufferChunk where compression block starts.    * @param cacheBuffers The result buffer array to add pre-allocated target cache buffer.    * @param toDecompress The list of work to decompress - pairs of compressed buffers and the    *                     target buffers (same as the ones added to cacheBuffers).    * @param toRelease The list of buffers to release to zcr because they are no longer in use.    * @param badEstimates The list of bad estimates that cannot be decompressed.    * @return The resulting cache chunk.    */
specifier|private
name|ProcCacheChunk
name|addOneCompressionBuffer
parameter_list|(
name|BufferChunk
name|current
parameter_list|,
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|cacheBuffers
parameter_list|,
name|List
argument_list|<
name|ProcCacheChunk
argument_list|>
name|toDecompress
parameter_list|,
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
parameter_list|,
name|List
argument_list|<
name|ByteBuffer
argument_list|>
name|toReleaseCopies
parameter_list|,
name|List
argument_list|<
name|IncompleteCb
argument_list|>
name|badEstimates
parameter_list|)
throws|throws
name|IOException
block|{
name|ByteBuffer
name|slice
init|=
literal|null
decl_stmt|;
name|ByteBuffer
name|compressed
init|=
name|current
operator|.
name|getChunk
argument_list|()
decl_stmt|;
name|long
name|cbStartOffset
init|=
name|current
operator|.
name|getOffset
argument_list|()
decl_stmt|;
name|int
name|b0
init|=
operator|-
literal|1
decl_stmt|,
name|b1
init|=
operator|-
literal|1
decl_stmt|,
name|b2
init|=
operator|-
literal|1
decl_stmt|;
comment|// First, read the CB header. Due to ORC estimates, ZCR, etc. this can be complex.
if|if
condition|(
name|compressed
operator|.
name|remaining
argument_list|()
operator|>=
literal|3
condition|)
block|{
comment|// The overwhelming majority of cases will go here. Read 3 bytes. Tada!
name|b0
operator|=
name|compressed
operator|.
name|get
argument_list|()
operator|&
literal|0xff
expr_stmt|;
name|b1
operator|=
name|compressed
operator|.
name|get
argument_list|()
operator|&
literal|0xff
expr_stmt|;
name|b2
operator|=
name|compressed
operator|.
name|get
argument_list|()
operator|&
literal|0xff
expr_stmt|;
block|}
else|else
block|{
comment|// Bad luck! Handle the corner cases where 3 bytes are in multiple blocks.
name|int
index|[]
name|bytes
init|=
operator|new
name|int
index|[
literal|3
index|]
decl_stmt|;
name|current
operator|=
name|readLengthBytesFromSmallBuffers
argument_list|(
name|current
argument_list|,
name|cbStartOffset
argument_list|,
name|bytes
argument_list|,
name|badEstimates
argument_list|,
name|isTracingEnabled
argument_list|,
name|trace
argument_list|)
expr_stmt|;
if|if
condition|(
name|current
operator|==
literal|null
condition|)
return|return
literal|null
return|;
name|compressed
operator|=
name|current
operator|.
name|getChunk
argument_list|()
expr_stmt|;
name|b0
operator|=
name|bytes
index|[
literal|0
index|]
expr_stmt|;
name|b1
operator|=
name|bytes
index|[
literal|1
index|]
expr_stmt|;
name|b2
operator|=
name|bytes
index|[
literal|2
index|]
expr_stmt|;
block|}
name|int
name|chunkLength
init|=
operator|(
name|b2
operator|<<
literal|15
operator|)
operator||
operator|(
name|b1
operator|<<
literal|7
operator|)
operator||
operator|(
name|b0
operator|>>
literal|1
operator|)
decl_stmt|;
if|if
condition|(
name|chunkLength
operator|>
name|bufferSize
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Buffer size too small. size = "
operator|+
name|bufferSize
operator|+
literal|" needed = "
operator|+
name|chunkLength
argument_list|)
throw|;
block|}
name|int
name|consumedLength
init|=
name|chunkLength
operator|+
name|OutStream
operator|.
name|HEADER_SIZE
decl_stmt|;
name|long
name|cbEndOffset
init|=
name|cbStartOffset
operator|+
name|consumedLength
decl_stmt|;
name|boolean
name|isUncompressed
init|=
operator|(
operator|(
name|b0
operator|&
literal|0x01
operator|)
operator|==
literal|1
operator|)
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Found CB at "
operator|+
name|cbStartOffset
operator|+
literal|", chunk length "
operator|+
name|chunkLength
operator|+
literal|", total "
operator|+
name|consumedLength
operator|+
literal|", "
operator|+
operator|(
name|isUncompressed
condition|?
literal|"not "
else|:
literal|""
operator|)
operator|+
literal|"compressed"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logOrcCb
argument_list|(
name|cbStartOffset
argument_list|,
name|chunkLength
argument_list|,
name|isUncompressed
argument_list|)
expr_stmt|;
if|if
condition|(
name|compressed
operator|.
name|remaining
argument_list|()
operator|>=
name|chunkLength
condition|)
block|{
comment|// Simple case - CB fits entirely in the disk range.
name|slice
operator|=
name|compressed
operator|.
name|slice
argument_list|()
expr_stmt|;
name|slice
operator|.
name|limit
argument_list|(
name|chunkLength
argument_list|)
expr_stmt|;
return|return
name|addOneCompressionBlockByteBuffer
argument_list|(
name|slice
argument_list|,
name|isUncompressed
argument_list|,
name|cbStartOffset
argument_list|,
name|cbEndOffset
argument_list|,
name|chunkLength
argument_list|,
name|current
argument_list|,
name|toDecompress
argument_list|,
name|cacheBuffers
argument_list|,
literal|false
argument_list|)
return|;
block|}
if|if
condition|(
name|current
operator|.
name|getEnd
argument_list|()
operator|<
name|cbEndOffset
operator|&&
operator|!
name|current
operator|.
name|hasContiguousNext
argument_list|()
condition|)
block|{
name|badEstimates
operator|.
name|add
argument_list|(
name|addIncompleteCompressionBuffer
argument_list|(
name|cbStartOffset
argument_list|,
name|current
argument_list|,
literal|0
argument_list|,
name|isTracingEnabled
argument_list|,
name|trace
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
comment|// This is impossible to read from this chunk.
block|}
comment|// TODO: we could remove extra copy for isUncompressed case by copying directly to cache.
comment|// We need to consolidate 2 or more buffers into one to decompress.
name|ByteBuffer
name|copy
init|=
name|allocateBuffer
argument_list|(
name|chunkLength
argument_list|,
name|compressed
operator|.
name|isDirect
argument_list|()
argument_list|)
decl_stmt|;
name|toReleaseCopies
operator|.
name|add
argument_list|(
name|copy
argument_list|)
expr_stmt|;
comment|// We will always release copies at the end.
name|int
name|remaining
init|=
name|chunkLength
operator|-
name|compressed
operator|.
name|remaining
argument_list|()
decl_stmt|;
name|int
name|originalPos
init|=
name|compressed
operator|.
name|position
argument_list|()
decl_stmt|;
name|copy
operator|.
name|put
argument_list|(
name|compressed
argument_list|)
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removing partial CB "
operator|+
name|current
operator|+
literal|" from ranges after copying its contents"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logPartialCb
argument_list|(
name|current
argument_list|)
expr_stmt|;
name|DiskRangeList
name|next
init|=
name|current
operator|.
name|next
decl_stmt|;
name|current
operator|.
name|removeSelf
argument_list|()
expr_stmt|;
if|if
condition|(
name|originalPos
operator|==
literal|0
operator|&&
name|toRelease
operator|.
name|remove
argument_list|(
name|compressed
argument_list|)
condition|)
block|{
name|releaseBuffer
argument_list|(
name|compressed
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|int
name|extraChunkCount
init|=
literal|0
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
operator|!
operator|(
name|next
operator|instanceof
name|BufferChunk
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Trying to extend compressed block into uncompressed block "
operator|+
name|next
argument_list|)
throw|;
block|}
name|compressed
operator|=
name|next
operator|.
name|getData
argument_list|()
expr_stmt|;
operator|++
name|extraChunkCount
expr_stmt|;
if|if
condition|(
name|compressed
operator|.
name|remaining
argument_list|()
operator|>=
name|remaining
condition|)
block|{
comment|// This is the last range for this compression block. Yay!
name|slice
operator|=
name|compressed
operator|.
name|slice
argument_list|()
expr_stmt|;
name|slice
operator|.
name|limit
argument_list|(
name|remaining
argument_list|)
expr_stmt|;
name|copy
operator|.
name|put
argument_list|(
name|slice
argument_list|)
expr_stmt|;
name|ProcCacheChunk
name|cc
init|=
name|addOneCompressionBlockByteBuffer
argument_list|(
name|copy
argument_list|,
name|isUncompressed
argument_list|,
name|cbStartOffset
argument_list|,
name|cbEndOffset
argument_list|,
name|remaining
argument_list|,
operator|(
name|BufferChunk
operator|)
name|next
argument_list|,
name|toDecompress
argument_list|,
name|cacheBuffers
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|compressed
operator|.
name|remaining
argument_list|()
operator|<=
literal|0
operator|&&
name|toRelease
operator|.
name|remove
argument_list|(
name|compressed
argument_list|)
condition|)
block|{
name|releaseBuffer
argument_list|(
name|compressed
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// We copied the entire buffer.
block|}
comment|// else there's more data to process; will be handled in next call.
return|return
name|cc
return|;
block|}
name|remaining
operator|-=
name|compressed
operator|.
name|remaining
argument_list|()
expr_stmt|;
name|copy
operator|.
name|put
argument_list|(
name|compressed
argument_list|)
expr_stmt|;
comment|// TODO: move into the if below; account for release call
if|if
condition|(
name|toRelease
operator|.
name|remove
argument_list|(
name|compressed
argument_list|)
condition|)
block|{
name|releaseBuffer
argument_list|(
name|compressed
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// We copied the entire buffer.
block|}
name|DiskRangeList
name|tmp
init|=
name|next
decl_stmt|;
name|next
operator|=
name|next
operator|.
name|hasContiguousNext
argument_list|()
condition|?
name|next
operator|.
name|next
else|:
literal|null
expr_stmt|;
if|if
condition|(
name|next
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removing partial CB "
operator|+
name|tmp
operator|+
literal|" from ranges after copying its contents"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logPartialCb
argument_list|(
name|tmp
argument_list|)
expr_stmt|;
name|tmp
operator|.
name|removeSelf
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|badEstimates
operator|.
name|add
argument_list|(
name|addIncompleteCompressionBuffer
argument_list|(
name|cbStartOffset
argument_list|,
name|tmp
argument_list|,
name|extraChunkCount
argument_list|,
name|isTracingEnabled
argument_list|,
name|trace
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
comment|// This is impossible to read from this chunk.
block|}
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|static
name|BufferChunk
name|readLengthBytesFromSmallBuffers
parameter_list|(
name|BufferChunk
name|first
parameter_list|,
name|long
name|cbStartOffset
parameter_list|,
name|int
index|[]
name|result
parameter_list|,
name|List
argument_list|<
name|IncompleteCb
argument_list|>
name|badEstimates
parameter_list|,
name|boolean
name|isTracingEnabled
parameter_list|,
name|IoTrace
name|trace
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|first
operator|.
name|hasContiguousNext
argument_list|()
condition|)
block|{
name|badEstimates
operator|.
name|add
argument_list|(
name|addIncompleteCompressionBuffer
argument_list|(
name|cbStartOffset
argument_list|,
name|first
argument_list|,
literal|0
argument_list|,
name|isTracingEnabled
argument_list|,
name|trace
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
comment|// This is impossible to read from this chunk.
block|}
name|int
name|ix
init|=
name|readLengthBytes
argument_list|(
name|first
operator|.
name|getChunk
argument_list|()
argument_list|,
name|result
argument_list|,
literal|0
argument_list|)
decl_stmt|;
assert|assert
name|ix
operator|<
literal|3
assert|;
comment|// Otherwise we wouldn't be here.
name|DiskRangeList
name|current
init|=
name|first
operator|.
name|next
decl_stmt|;
name|first
operator|.
name|removeSelf
argument_list|()
expr_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
operator|!
operator|(
name|current
operator|instanceof
name|BufferChunk
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Trying to extend compressed block into uncompressed block "
operator|+
name|current
argument_list|)
throw|;
block|}
name|BufferChunk
name|currentBc
init|=
operator|(
name|BufferChunk
operator|)
name|current
decl_stmt|;
name|ix
operator|=
name|readLengthBytes
argument_list|(
name|currentBc
operator|.
name|getChunk
argument_list|()
argument_list|,
name|result
argument_list|,
name|ix
argument_list|)
expr_stmt|;
if|if
condition|(
name|ix
operator|==
literal|3
condition|)
return|return
name|currentBc
return|;
comment|// Done, we have 3 bytes. Continue reading this buffer.
name|DiskRangeList
name|tmp
init|=
name|current
decl_stmt|;
name|current
operator|=
name|current
operator|.
name|hasContiguousNext
argument_list|()
condition|?
name|current
operator|.
name|next
else|:
literal|null
expr_stmt|;
if|if
condition|(
name|current
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removing partial CB "
operator|+
name|tmp
operator|+
literal|" from ranges after copying its contents"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logPartialCb
argument_list|(
name|tmp
argument_list|)
expr_stmt|;
name|tmp
operator|.
name|removeSelf
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|badEstimates
operator|.
name|add
argument_list|(
name|addIncompleteCompressionBuffer
argument_list|(
name|cbStartOffset
argument_list|,
name|tmp
argument_list|,
operator|-
literal|1
argument_list|,
name|isTracingEnabled
argument_list|,
name|trace
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
comment|// This is impossible to read from this chunk.
block|}
block|}
block|}
specifier|private
specifier|static
name|int
name|readLengthBytes
parameter_list|(
name|ByteBuffer
name|compressed
parameter_list|,
name|int
index|[]
name|bytes
parameter_list|,
name|int
name|ix
parameter_list|)
block|{
name|int
name|byteCount
init|=
name|compressed
operator|.
name|remaining
argument_list|()
decl_stmt|;
while|while
condition|(
name|byteCount
operator|>
literal|0
operator|&&
name|ix
operator|<
literal|3
condition|)
block|{
name|bytes
index|[
name|ix
operator|++
index|]
operator|=
name|compressed
operator|.
name|get
argument_list|()
operator|&
literal|0xff
expr_stmt|;
operator|--
name|byteCount
expr_stmt|;
block|}
return|return
name|ix
return|;
block|}
specifier|private
name|void
name|releaseBuffers
parameter_list|(
name|Collection
argument_list|<
name|ByteBuffer
argument_list|>
name|toRelease
parameter_list|,
name|boolean
name|isFromDataReader
parameter_list|)
block|{
if|if
condition|(
name|toRelease
operator|==
literal|null
condition|)
return|return;
for|for
control|(
name|ByteBuffer
name|buf
range|:
name|toRelease
control|)
block|{
name|releaseBuffer
argument_list|(
name|buf
argument_list|,
name|isFromDataReader
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|releaseBuffer
parameter_list|(
name|ByteBuffer
name|bb
parameter_list|,
name|boolean
name|isFromDataReader
parameter_list|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Releasing the buffer "
operator|+
name|System
operator|.
name|identityHashCode
argument_list|(
name|bb
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isFromDataReader
operator|&&
name|dataReader
operator|.
name|isTrackingDiskRanges
argument_list|()
condition|)
block|{
name|dataReader
operator|.
name|releaseBuffer
argument_list|(
name|bb
argument_list|)
expr_stmt|;
return|return;
block|}
name|Field
name|localCf
init|=
name|cleanerField
decl_stmt|;
if|if
condition|(
operator|!
name|bb
operator|.
name|isDirect
argument_list|()
operator|||
name|localCf
operator|==
literal|null
condition|)
return|return;
try|try
block|{
name|Cleaner
name|cleaner
init|=
operator|(
name|Cleaner
operator|)
name|localCf
operator|.
name|get
argument_list|(
name|bb
argument_list|)
decl_stmt|;
if|if
condition|(
name|cleaner
operator|!=
literal|null
condition|)
block|{
name|cleaner
operator|.
name|clean
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Unable to clean a buffer using cleaner - no cleaner"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// leave it for GC to clean up
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to clean direct buffers using Cleaner."
argument_list|)
expr_stmt|;
name|cleanerField
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|IncompleteCb
name|addIncompleteCompressionBuffer
parameter_list|(
name|long
name|cbStartOffset
parameter_list|,
name|DiskRangeList
name|target
parameter_list|,
name|int
name|extraChunkCountToLog
parameter_list|,
name|boolean
name|isTracingEnabled
parameter_list|,
name|IoTrace
name|trace
parameter_list|)
block|{
name|IncompleteCb
name|icb
init|=
operator|new
name|IncompleteCb
argument_list|(
name|cbStartOffset
argument_list|,
name|target
operator|.
name|getEnd
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Replacing "
operator|+
name|target
operator|+
literal|" (and "
operator|+
name|extraChunkCountToLog
operator|+
literal|" previous chunks) with "
operator|+
name|icb
operator|+
literal|" in the buffers"
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logInvalidOrcCb
argument_list|(
name|cbStartOffset
argument_list|,
name|target
operator|.
name|getEnd
argument_list|()
argument_list|)
expr_stmt|;
name|target
operator|.
name|replaceSelfWith
argument_list|(
name|icb
argument_list|)
expr_stmt|;
return|return
name|icb
return|;
block|}
comment|/**    * Add one buffer with compressed data the results for addOneCompressionBuffer (see javadoc).    * @param fullCompressionBlock (fCB) Entire compression block, sliced or copied from disk data.    * @param isUncompressed Whether the data in the block is uncompressed.    * @param cbStartOffset Compressed start offset of the fCB.    * @param cbEndOffset Compressed end offset of the fCB.    * @param lastChunkLength The number of compressed bytes consumed from last *chunk* into fullCompressionBlock.    * @param lastChunk    * @param toDecompress See addOneCompressionBuffer.    * @param cacheBuffers See addOneCompressionBuffer.    * @return New cache buffer.    */
specifier|private
name|ProcCacheChunk
name|addOneCompressionBlockByteBuffer
parameter_list|(
name|ByteBuffer
name|fullCompressionBlock
parameter_list|,
name|boolean
name|isUncompressed
parameter_list|,
name|long
name|cbStartOffset
parameter_list|,
name|long
name|cbEndOffset
parameter_list|,
name|int
name|lastChunkLength
parameter_list|,
name|BufferChunk
name|lastChunk
parameter_list|,
name|List
argument_list|<
name|ProcCacheChunk
argument_list|>
name|toDecompress
parameter_list|,
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|cacheBuffers
parameter_list|,
name|boolean
name|doTrace
parameter_list|)
block|{
comment|// Prepare future cache buffer.
name|MemoryBuffer
name|futureAlloc
init|=
name|cacheWrapper
operator|.
name|getDataBufferFactory
argument_list|()
operator|.
name|create
argument_list|()
decl_stmt|;
comment|// Add it to result in order we are processing.
name|cacheBuffers
operator|.
name|add
argument_list|(
name|futureAlloc
argument_list|)
expr_stmt|;
comment|// Add it to the list of work to decompress.
name|ProcCacheChunk
name|cc
init|=
operator|new
name|ProcCacheChunk
argument_list|(
name|cbStartOffset
argument_list|,
name|cbEndOffset
argument_list|,
operator|!
name|isUncompressed
argument_list|,
name|fullCompressionBlock
argument_list|,
name|futureAlloc
argument_list|,
name|cacheBuffers
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|toDecompress
operator|.
name|add
argument_list|(
name|cc
argument_list|)
expr_stmt|;
comment|// Adjust the compression block position.
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Adjusting "
operator|+
name|lastChunk
operator|+
literal|" to consume "
operator|+
name|lastChunkLength
operator|+
literal|" compressed bytes"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|doTrace
condition|)
block|{
name|trace
operator|.
name|logCompositeOrcCb
argument_list|(
name|lastChunkLength
argument_list|,
name|lastChunk
operator|.
name|getChunk
argument_list|()
operator|.
name|remaining
argument_list|()
argument_list|,
name|cc
argument_list|)
expr_stmt|;
block|}
name|lastChunk
operator|.
name|getChunk
argument_list|()
operator|.
name|position
argument_list|(
name|lastChunk
operator|.
name|getChunk
argument_list|()
operator|.
name|position
argument_list|()
operator|+
name|lastChunkLength
argument_list|)
expr_stmt|;
comment|// Finally, put it in the ranges list for future use (if shared between RGs).
comment|// Before anyone else accesses it, it would have been allocated and decompressed locally.
if|if
condition|(
name|lastChunk
operator|.
name|getChunk
argument_list|()
operator|.
name|remaining
argument_list|()
operator|<=
literal|0
condition|)
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Replacing "
operator|+
name|lastChunk
operator|+
literal|" with "
operator|+
name|cc
operator|+
literal|" in the buffers"
argument_list|)
expr_stmt|;
block|}
name|lastChunk
operator|.
name|replaceSelfWith
argument_list|(
name|cc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Adding "
operator|+
name|cc
operator|+
literal|" before "
operator|+
name|lastChunk
operator|+
literal|" in the buffers"
argument_list|)
expr_stmt|;
block|}
name|lastChunk
operator|.
name|insertPartBefore
argument_list|(
name|cc
argument_list|)
expr_stmt|;
block|}
return|return
name|cc
return|;
block|}
specifier|private
specifier|static
name|ByteBuffer
name|allocateBuffer
parameter_list|(
name|int
name|size
parameter_list|,
name|boolean
name|isDirect
parameter_list|)
block|{
return|return
name|isDirect
condition|?
name|ByteBuffer
operator|.
name|allocateDirect
argument_list|(
name|size
argument_list|)
else|:
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|size
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|Pools
name|createPools
parameter_list|(
name|PoolFactory
name|pf
parameter_list|)
block|{
name|Pools
name|pools
init|=
operator|new
name|Pools
argument_list|()
decl_stmt|;
name|pools
operator|.
name|ecbPool
operator|=
name|pf
operator|.
name|createEncodedColumnBatchPool
argument_list|()
expr_stmt|;
name|pools
operator|.
name|csdPool
operator|=
name|pf
operator|.
name|createColumnStreamDataPool
argument_list|()
expr_stmt|;
return|return
name|pools
return|;
block|}
comment|/** Pool factory that is used if another one isn't specified - just creates the objects. */
specifier|private
specifier|static
class|class
name|NoopPoolFactory
implements|implements
name|PoolFactory
block|{
specifier|private
parameter_list|<
name|T
parameter_list|>
name|Pool
argument_list|<
name|T
argument_list|>
name|createPool
parameter_list|(
specifier|final
name|int
name|size
parameter_list|,
specifier|final
name|PoolObjectHelper
argument_list|<
name|T
argument_list|>
name|helper
parameter_list|)
block|{
return|return
operator|new
name|Pool
argument_list|<
name|T
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|offer
parameter_list|(
name|T
name|t
parameter_list|)
block|{         }
annotation|@
name|Override
specifier|public
name|int
name|size
parameter_list|()
block|{
return|return
name|size
return|;
block|}
specifier|public
name|T
name|take
parameter_list|()
block|{
return|return
name|helper
operator|.
name|create
argument_list|()
return|;
block|}
block|}
return|;
block|}
annotation|@
name|Override
specifier|public
name|Pool
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
name|createEncodedColumnBatchPool
parameter_list|()
block|{
return|return
name|createPool
argument_list|(
literal|0
argument_list|,
operator|new
name|PoolObjectHelper
argument_list|<
name|OrcEncodedColumnBatch
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|OrcEncodedColumnBatch
name|create
parameter_list|()
block|{
return|return
operator|new
name|OrcEncodedColumnBatch
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|resetBeforeOffer
parameter_list|(
name|OrcEncodedColumnBatch
name|t
parameter_list|)
block|{         }
block|}
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Pool
argument_list|<
name|ColumnStreamData
argument_list|>
name|createColumnStreamDataPool
parameter_list|()
block|{
return|return
name|createPool
argument_list|(
literal|0
argument_list|,
operator|new
name|PoolObjectHelper
argument_list|<
name|ColumnStreamData
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|ColumnStreamData
name|create
parameter_list|()
block|{
return|return
operator|new
name|ColumnStreamData
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|resetBeforeOffer
parameter_list|(
name|ColumnStreamData
name|t
parameter_list|)
block|{         }
block|}
argument_list|)
return|;
block|}
block|}
comment|// TODO: perhaps move to Orc InStream?
specifier|private
specifier|static
class|class
name|IndexStream
extends|extends
name|InputStream
block|{
specifier|private
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|ranges
decl_stmt|;
specifier|private
name|long
name|currentOffset
init|=
literal|0
decl_stmt|,
name|length
decl_stmt|;
specifier|private
name|ByteBuffer
name|range
decl_stmt|;
specifier|private
name|int
name|rangeIx
init|=
operator|-
literal|1
decl_stmt|;
specifier|public
name|IndexStream
parameter_list|(
name|List
argument_list|<
name|MemoryBuffer
argument_list|>
name|input
parameter_list|,
name|long
name|length
parameter_list|)
block|{
name|this
operator|.
name|ranges
operator|=
name|input
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|length
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|()
block|{
if|if
condition|(
operator|!
name|ensureRangeWithData
argument_list|()
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
name|currentOffset
operator|+=
literal|1
expr_stmt|;
return|return
literal|0xff
operator|&
name|range
operator|.
name|get
argument_list|()
return|;
block|}
specifier|private
name|boolean
name|ensureRangeWithData
parameter_list|()
block|{
while|while
condition|(
name|range
operator|==
literal|null
operator|||
name|range
operator|.
name|remaining
argument_list|()
operator|<=
literal|0
condition|)
block|{
operator|++
name|rangeIx
expr_stmt|;
if|if
condition|(
name|rangeIx
operator|==
name|ranges
operator|.
name|size
argument_list|()
condition|)
return|return
literal|false
return|;
name|range
operator|=
name|ranges
operator|.
name|get
argument_list|(
name|rangeIx
argument_list|)
operator|.
name|getByteBufferDup
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|(
name|byte
index|[]
name|data
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ensureRangeWithData
argument_list|()
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
name|int
name|actualLength
init|=
name|Math
operator|.
name|min
argument_list|(
name|length
argument_list|,
name|range
operator|.
name|remaining
argument_list|()
argument_list|)
decl_stmt|;
name|range
operator|.
name|get
argument_list|(
name|data
argument_list|,
name|offset
argument_list|,
name|actualLength
argument_list|)
expr_stmt|;
name|currentOffset
operator|+=
name|actualLength
expr_stmt|;
return|return
name|actualLength
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|available
parameter_list|()
block|{
if|if
condition|(
name|range
operator|!=
literal|null
operator|&&
name|range
operator|.
name|remaining
argument_list|()
operator|>
literal|0
condition|)
block|{
return|return
name|range
operator|.
name|remaining
argument_list|()
return|;
block|}
return|return
call|(
name|int
call|)
argument_list|(
name|length
operator|-
name|currentOffset
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
block|{
name|rangeIx
operator|=
name|ranges
operator|.
name|size
argument_list|()
expr_stmt|;
name|currentOffset
operator|=
name|length
expr_stmt|;
name|ranges
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"position: "
operator|+
name|currentOffset
operator|+
literal|" length: "
operator|+
name|length
operator|+
literal|" range: "
operator|+
name|rangeIx
operator|+
literal|" offset: "
operator|+
operator|(
name|range
operator|==
literal|null
condition|?
literal|0
else|:
name|range
operator|.
name|position
argument_list|()
operator|)
operator|+
literal|" limit: "
operator|+
operator|(
name|range
operator|==
literal|null
condition|?
literal|0
else|:
name|range
operator|.
name|limit
argument_list|()
operator|)
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|readIndexStreams
parameter_list|(
name|OrcIndex
name|index
parameter_list|,
name|StripeInformation
name|stripe
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Stream
argument_list|>
name|streams
parameter_list|,
name|boolean
index|[]
name|physicalFileIncludes
parameter_list|,
name|boolean
index|[]
name|sargColumns
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|stripeOffset
init|=
name|stripe
operator|.
name|getOffset
argument_list|()
decl_stmt|;
name|DiskRangeList
name|indexRanges
init|=
name|planIndexReading
argument_list|(
name|fileSchema
argument_list|,
name|streams
argument_list|,
literal|true
argument_list|,
name|physicalFileIncludes
argument_list|,
name|sargColumns
argument_list|,
name|version
argument_list|,
name|index
operator|.
name|getBloomFilterKinds
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexRanges
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Nothing to read for stripe ["
operator|+
name|stripe
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|ReadContext
index|[]
name|colCtxs
init|=
operator|new
name|ReadContext
index|[
name|physicalFileIncludes
operator|.
name|length
index|]
decl_stmt|;
name|int
name|colRgIx
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|physicalFileIncludes
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
operator|!
name|physicalFileIncludes
index|[
name|i
index|]
operator|&&
operator|(
name|sargColumns
operator|==
literal|null
operator|||
operator|!
name|sargColumns
index|[
name|i
index|]
operator|)
condition|)
continue|continue;
name|colCtxs
index|[
name|i
index|]
operator|=
operator|new
name|ReadContext
argument_list|(
name|i
argument_list|,
operator|++
name|colRgIx
argument_list|)
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Creating context: "
operator|+
name|colCtxs
index|[
name|i
index|]
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|trace
operator|.
name|logColumnRead
argument_list|(
name|i
argument_list|,
name|colRgIx
argument_list|,
name|ColumnEncoding
operator|.
name|Kind
operator|.
name|DIRECT
argument_list|)
expr_stmt|;
comment|// Bogus encoding.
block|}
name|long
name|offset
init|=
literal|0
decl_stmt|;
for|for
control|(
name|OrcProto
operator|.
name|Stream
name|stream
range|:
name|streams
control|)
block|{
name|long
name|length
init|=
name|stream
operator|.
name|getLength
argument_list|()
decl_stmt|;
name|int
name|colIx
init|=
name|stream
operator|.
name|getColumn
argument_list|()
decl_stmt|;
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
name|streamKind
init|=
name|stream
operator|.
name|getKind
argument_list|()
decl_stmt|;
comment|// See planIndexReading - only read non-row-index streams if involved in SARGs.
if|if
condition|(
operator|(
name|StreamName
operator|.
name|getArea
argument_list|(
name|streamKind
argument_list|)
operator|==
name|StreamName
operator|.
name|Area
operator|.
name|INDEX
operator|)
operator|&&
operator|(
operator|(
name|sargColumns
operator|!=
literal|null
operator|&&
name|sargColumns
index|[
name|colIx
index|]
operator|)
operator|||
operator|(
name|physicalFileIncludes
index|[
name|colIx
index|]
operator|&&
name|streamKind
operator|==
name|Kind
operator|.
name|ROW_INDEX
operator|)
operator|)
condition|)
block|{
name|trace
operator|.
name|logAddStream
argument_list|(
name|colIx
argument_list|,
name|streamKind
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
operator|-
literal|1
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|colCtxs
index|[
name|colIx
index|]
operator|.
name|addStream
argument_list|(
name|offset
argument_list|,
name|stream
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Adding stream for column "
operator|+
name|colIx
operator|+
literal|": "
operator|+
name|streamKind
operator|+
literal|" at "
operator|+
name|offset
operator|+
literal|", "
operator|+
name|length
argument_list|)
expr_stmt|;
block|}
block|}
name|offset
operator|+=
name|length
expr_stmt|;
block|}
name|boolean
name|hasFileId
init|=
name|this
operator|.
name|fileKey
operator|!=
literal|null
decl_stmt|;
comment|// 2. Now, read all of the ranges from cache or disk.
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
init|=
operator|new
name|IdentityHashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|MutateHelper
name|toRead
init|=
name|getDataFromCacheAndDisk
argument_list|(
name|indexRanges
argument_list|,
name|stripeOffset
argument_list|,
name|hasFileId
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
comment|// 3. For uncompressed case, we need some special processing before read.
name|DiskRangeList
name|iter
init|=
name|preReadUncompressedStreams
argument_list|(
name|stripeOffset
argument_list|,
name|colCtxs
argument_list|,
name|toRead
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
comment|// 4. Decompress the data.
name|boolean
name|hasError
init|=
literal|true
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|colCtxs
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
name|ReadContext
name|ctx
init|=
name|colCtxs
index|[
name|colIx
index|]
decl_stmt|;
if|if
condition|(
name|ctx
operator|==
literal|null
condition|)
continue|continue;
comment|// This column is not included.
for|for
control|(
name|int
name|streamIx
init|=
literal|0
init|;
name|streamIx
operator|<
name|ctx
operator|.
name|streamCount
condition|;
operator|++
name|streamIx
control|)
block|{
name|StreamContext
name|sctx
init|=
name|ctx
operator|.
name|streams
index|[
name|streamIx
index|]
decl_stmt|;
try|try
block|{
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Getting index stream "
operator|+
name|sctx
operator|.
name|kind
operator|+
literal|" for column "
operator|+
name|ctx
operator|.
name|colIx
operator|+
literal|" at "
operator|+
name|sctx
operator|.
name|offset
operator|+
literal|", "
operator|+
name|sctx
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
name|ColumnStreamData
name|csd
init|=
name|POOLS
operator|.
name|csdPool
operator|.
name|take
argument_list|()
decl_stmt|;
name|long
name|endCOffset
init|=
name|sctx
operator|.
name|offset
operator|+
name|sctx
operator|.
name|length
decl_stmt|;
name|DiskRangeList
name|lastCached
init|=
name|readEncodedStream
argument_list|(
name|stripeOffset
argument_list|,
name|iter
argument_list|,
name|sctx
operator|.
name|offset
argument_list|,
name|endCOffset
argument_list|,
name|csd
argument_list|,
name|endCOffset
argument_list|,
name|sctx
operator|.
name|offset
argument_list|,
name|toRelease
argument_list|)
decl_stmt|;
if|if
condition|(
name|lastCached
operator|!=
literal|null
condition|)
block|{
name|iter
operator|=
name|lastCached
expr_stmt|;
block|}
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|traceLogBuffersUsedToParse
argument_list|(
name|csd
argument_list|)
expr_stmt|;
block|}
name|CodedInputStream
name|cis
init|=
name|CodedInputStream
operator|.
name|newInstance
argument_list|(
operator|new
name|IndexStream
argument_list|(
name|csd
operator|.
name|getCacheBuffers
argument_list|()
argument_list|,
name|sctx
operator|.
name|length
argument_list|)
argument_list|)
decl_stmt|;
name|cis
operator|.
name|setSizeLimit
argument_list|(
name|InStream
operator|.
name|PROTOBUF_MESSAGE_MAX_LIMIT
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|sctx
operator|.
name|kind
condition|)
block|{
case|case
name|ROW_INDEX
case|:
name|OrcProto
operator|.
name|RowIndex
name|tmp
init|=
name|index
operator|.
name|getRowGroupIndex
argument_list|()
index|[
name|colIx
index|]
operator|=
name|OrcProto
operator|.
name|RowIndex
operator|.
name|parseFrom
argument_list|(
name|cis
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Index is "
operator|+
name|tmp
operator|.
name|toString
argument_list|()
operator|.
name|replace
argument_list|(
literal|'\n'
argument_list|,
literal|' '
argument_list|)
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|BLOOM_FILTER
case|:
case|case
name|BLOOM_FILTER_UTF8
case|:
name|index
operator|.
name|getBloomFilterIndex
argument_list|()
index|[
name|colIx
index|]
operator|=
name|OrcProto
operator|.
name|BloomFilterIndex
operator|.
name|parseFrom
argument_list|(
name|cis
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unexpected index stream type "
operator|+
name|sctx
operator|.
name|kind
argument_list|)
throw|;
block|}
comment|// We are done with the buffers; unlike data blocks, we are also the consumer. Release.
for|for
control|(
name|MemoryBuffer
name|buf
range|:
name|csd
operator|.
name|getCacheBuffers
argument_list|()
control|)
block|{
if|if
condition|(
name|buf
operator|==
literal|null
condition|)
continue|continue;
name|cacheWrapper
operator|.
name|releaseBuffer
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|DiskRangeList
name|drl
init|=
name|toRead
operator|==
literal|null
condition|?
literal|null
else|:
name|toRead
operator|.
name|next
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Error getting stream "
operator|+
name|sctx
operator|.
name|kind
operator|+
literal|" for column "
operator|+
name|ctx
operator|.
name|colIx
operator|+
literal|" at "
operator|+
name|sctx
operator|.
name|offset
operator|+
literal|", "
operator|+
name|sctx
operator|.
name|length
operator|+
literal|"; toRead "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|drl
argument_list|)
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|(
name|ex
operator|instanceof
name|IOException
operator|)
condition|?
operator|(
name|IOException
operator|)
name|ex
else|:
operator|new
name|IOException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|isTracingEnabled
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Disk ranges after preparing all the data "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|hasError
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
comment|// Release the unreleased buffers. See class comment about refcounts.
try|try
block|{
if|if
condition|(
name|toRead
operator|!=
literal|null
condition|)
block|{
name|releaseInitialRefcounts
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
expr_stmt|;
block|}
name|releaseBuffers
argument_list|(
name|toRelease
operator|.
name|keySet
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
if|if
condition|(
operator|!
name|hasError
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
throw|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Error during the cleanup after another error; ignoring"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|traceLogBuffersUsedToParse
parameter_list|(
name|ColumnStreamData
name|csd
parameter_list|)
block|{
name|String
name|s
init|=
literal|"Buffers "
decl_stmt|;
if|if
condition|(
name|csd
operator|.
name|getCacheBuffers
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|MemoryBuffer
name|buf
range|:
name|csd
operator|.
name|getCacheBuffers
argument_list|()
control|)
block|{
name|ByteBuffer
name|bb
init|=
name|buf
operator|.
name|getByteBufferDup
argument_list|()
decl_stmt|;
name|s
operator|+=
literal|"{"
operator|+
name|buf
operator|+
literal|", "
operator|+
name|bb
operator|.
name|remaining
argument_list|()
operator|+
comment|/* " => " + bb.hashCode() + */
literal|"}, "
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|trace
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
specifier|private
name|DiskRangeList
name|preReadUncompressedStreams
parameter_list|(
name|long
name|stripeOffset
parameter_list|,
name|ReadContext
index|[]
name|colCtxs
parameter_list|,
name|MutateHelper
name|toRead
parameter_list|,
name|IdentityHashMap
argument_list|<
name|ByteBuffer
argument_list|,
name|Boolean
argument_list|>
name|toRelease
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isCompressed
condition|)
return|return
name|toRead
operator|.
name|next
return|;
name|DiskRangeList
name|iter
init|=
name|toRead
operator|.
name|next
decl_stmt|;
comment|// Keep "toRead" list for future use, don't extract().
name|boolean
name|hasError
init|=
literal|true
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|colIx
init|=
literal|0
init|;
name|colIx
operator|<
name|colCtxs
operator|.
name|length
condition|;
operator|++
name|colIx
control|)
block|{
name|ReadContext
name|ctx
init|=
name|colCtxs
index|[
name|colIx
index|]
decl_stmt|;
if|if
condition|(
name|ctx
operator|==
literal|null
condition|)
continue|continue;
comment|// This column is not included.
for|for
control|(
name|int
name|streamIx
init|=
literal|0
init|;
name|streamIx
operator|<
name|ctx
operator|.
name|streamCount
condition|;
operator|++
name|streamIx
control|)
block|{
name|StreamContext
name|sctx
init|=
name|ctx
operator|.
name|streams
index|[
name|streamIx
index|]
decl_stmt|;
name|DiskRangeList
name|newIter
init|=
name|preReadUncompressedStream
argument_list|(
name|stripeOffset
argument_list|,
name|iter
argument_list|,
name|sctx
operator|.
name|offset
argument_list|,
name|sctx
operator|.
name|offset
operator|+
name|sctx
operator|.
name|length
argument_list|,
name|sctx
operator|.
name|kind
argument_list|)
decl_stmt|;
if|if
condition|(
name|newIter
operator|!=
literal|null
condition|)
block|{
name|iter
operator|=
name|newIter
expr_stmt|;
block|}
block|}
block|}
comment|// Release buffers as we are done with all the streams... also see toRelease comment.\
comment|// With uncompressed streams, we know we are done earlier.
if|if
condition|(
name|toRelease
operator|!=
literal|null
condition|)
block|{
name|releaseBuffers
argument_list|(
name|toRelease
operator|.
name|keySet
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|toRelease
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Disk ranges after pre-read (file "
operator|+
name|fileKey
operator|+
literal|", base offset "
operator|+
name|stripeOffset
operator|+
literal|"): "
operator|+
name|RecordReaderUtils
operator|.
name|stringifyDiskRanges
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|iter
operator|=
name|toRead
operator|.
name|next
expr_stmt|;
comment|// Reset the iter to start.
name|hasError
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
comment|// At this point, everything in the list is going to have a refcount of one. Unless it
comment|// failed between the allocation and the incref for a single item, we should be ok.
if|if
condition|(
name|hasError
condition|)
block|{
try|try
block|{
name|releaseInitialRefcounts
argument_list|(
name|toRead
operator|.
name|next
argument_list|)
expr_stmt|;
if|if
condition|(
name|toRelease
operator|!=
literal|null
condition|)
block|{
name|releaseBuffers
argument_list|(
name|toRelease
operator|.
name|keySet
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|toRelease
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error during the cleanup after another error; ignoring"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|toRead
operator|.
name|next
return|;
comment|// Reset the iter to start.
block|}
comment|// TODO: temporary, need to expose from ORC utils (note the difference in null checks)
specifier|static
name|DiskRangeList
name|planIndexReading
parameter_list|(
name|TypeDescription
name|fileSchema
parameter_list|,
name|List
argument_list|<
name|OrcProto
operator|.
name|Stream
argument_list|>
name|streams
parameter_list|,
name|boolean
name|ignoreNonUtf8BloomFilter
parameter_list|,
name|boolean
index|[]
name|fileIncluded
parameter_list|,
name|boolean
index|[]
name|sargColumns
parameter_list|,
name|WriterVersion
name|version
parameter_list|,
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
index|[]
name|bloomFilterKinds
parameter_list|)
block|{
name|DiskRangeList
operator|.
name|CreateHelper
name|result
init|=
operator|new
name|DiskRangeList
operator|.
name|CreateHelper
argument_list|()
decl_stmt|;
comment|// figure out which kind of bloom filter we want for each column
comment|// picks bloom_filter_utf8 if its available, otherwise bloom_filter
if|if
condition|(
name|sargColumns
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|OrcProto
operator|.
name|Stream
name|stream
range|:
name|streams
control|)
block|{
if|if
condition|(
name|stream
operator|.
name|hasKind
argument_list|()
operator|&&
name|stream
operator|.
name|hasColumn
argument_list|()
condition|)
block|{
name|int
name|column
init|=
name|stream
operator|.
name|getColumn
argument_list|()
decl_stmt|;
if|if
condition|(
name|sargColumns
index|[
name|column
index|]
condition|)
block|{
switch|switch
condition|(
name|stream
operator|.
name|getKind
argument_list|()
condition|)
block|{
case|case
name|BLOOM_FILTER
case|:
if|if
condition|(
name|bloomFilterKinds
index|[
name|column
index|]
operator|==
literal|null
operator|&&
operator|!
operator|(
name|ignoreNonUtf8BloomFilter
operator|&&
name|hadBadBloomFilters
argument_list|(
name|fileSchema
operator|.
name|findSubtype
argument_list|(
name|column
argument_list|)
operator|.
name|getCategory
argument_list|()
argument_list|,
name|version
argument_list|)
operator|)
condition|)
block|{
name|bloomFilterKinds
index|[
name|column
index|]
operator|=
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
operator|.
name|BLOOM_FILTER
expr_stmt|;
block|}
break|break;
case|case
name|BLOOM_FILTER_UTF8
case|:
name|bloomFilterKinds
index|[
name|column
index|]
operator|=
name|OrcProto
operator|.
name|Stream
operator|.
name|Kind
operator|.
name|BLOOM_FILTER_UTF8
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
block|}
block|}
block|}
name|long
name|offset
init|=
literal|0
decl_stmt|;
for|for
control|(
name|OrcProto
operator|.
name|Stream
name|stream
range|:
name|streams
control|)
block|{
if|if
condition|(
name|stream
operator|.
name|hasKind
argument_list|()
operator|&&
name|stream
operator|.
name|hasColumn
argument_list|()
condition|)
block|{
name|int
name|column
init|=
name|stream
operator|.
name|getColumn
argument_list|()
decl_stmt|;
if|if
condition|(
name|fileIncluded
operator|==
literal|null
operator|||
name|fileIncluded
index|[
name|column
index|]
condition|)
block|{
name|boolean
name|needStream
init|=
literal|false
decl_stmt|;
switch|switch
condition|(
name|stream
operator|.
name|getKind
argument_list|()
condition|)
block|{
case|case
name|ROW_INDEX
case|:
name|needStream
operator|=
literal|true
expr_stmt|;
break|break;
case|case
name|BLOOM_FILTER
case|:
case|case
name|BLOOM_FILTER_UTF8
case|:
name|needStream
operator|=
operator|(
name|sargColumns
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|bloomFilterKinds
index|[
name|column
index|]
operator|==
name|stream
operator|.
name|getKind
argument_list|()
operator|)
expr_stmt|;
break|break;
default|default:
comment|// PASS
break|break;
block|}
if|if
condition|(
name|needStream
condition|)
block|{
name|result
operator|.
name|addOrMerge
argument_list|(
name|offset
argument_list|,
name|offset
operator|+
name|stream
operator|.
name|getLength
argument_list|()
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|offset
operator|+=
name|stream
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
return|return
name|result
operator|.
name|get
argument_list|()
return|;
block|}
comment|// TODO: see planIndexReading; this is not needed here.
specifier|private
specifier|static
name|boolean
name|hadBadBloomFilters
parameter_list|(
name|TypeDescription
operator|.
name|Category
name|category
parameter_list|,
name|WriterVersion
name|version
parameter_list|)
block|{
switch|switch
condition|(
name|category
condition|)
block|{
case|case
name|STRING
case|:
case|case
name|CHAR
case|:
case|case
name|VARCHAR
case|:
return|return
operator|!
name|version
operator|.
name|includes
argument_list|(
name|WriterVersion
operator|.
name|HIVE_12055
argument_list|)
return|;
case|case
name|DECIMAL
case|:
return|return
literal|true
return|;
default|default:
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|setStopped
parameter_list|(
name|AtomicBoolean
name|isStopped
parameter_list|)
block|{
name|this
operator|.
name|isStopped
operator|=
name|isStopped
expr_stmt|;
block|}
block|}
end_class

end_unit

