begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|CompilationOpContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|AbstractMapOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TableScanOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecMapperContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcSerde
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcStruct
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|VectorPartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|VectorPartitionDesc
operator|.
name|VectorMapOperatorReadType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|api
operator|.
name|OperatorType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|ColumnProjectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|fast
operator|.
name|DeserializeRead
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySerDeParameters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|fast
operator|.
name|LazySimpleDeserializeRead
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazybinary
operator|.
name|fast
operator|.
name|LazyBinaryDeserializeRead
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StandardStructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
operator|.
name|ObjectInspectorCopyOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BinaryComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_comment
comment|/*  *  * The vectorized MapOperator.  *  * There are 3 modes of reading for vectorization:  *  *   1) One for the Vectorized Input File Format which returns VectorizedRowBatch as the row.  *  *   2) One for using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch.  *      Currently, these Input File Formats:  *        TEXTFILE  *        SEQUENCEFILE  *  *   3) And one using the regular partition deserializer to get the row object and assigning  *      the row object into the VectorizedRowBatch with VectorAssignRow.  *      This picks up Input File Format not supported by the other two.  */
end_comment

begin_class
specifier|public
class|class
name|VectorMapOperator
extends|extends
name|AbstractMapOperator
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
comment|/*    * Overall information on this vectorized Map operation.    */
specifier|private
specifier|transient
name|HashMap
argument_list|<
name|String
argument_list|,
name|VectorPartitionContext
argument_list|>
name|fileToPartitionContextMap
decl_stmt|;
specifier|private
specifier|transient
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|oneRootOperator
decl_stmt|;
specifier|private
specifier|transient
name|TypeInfo
name|tableStructTypeInfo
decl_stmt|;
specifier|private
specifier|transient
name|StandardStructObjectInspector
name|tableStandardStructObjectInspector
decl_stmt|;
specifier|private
specifier|transient
name|TypeInfo
index|[]
name|tableRowTypeInfos
decl_stmt|;
specifier|private
specifier|transient
name|int
index|[]
name|dataColumnNums
decl_stmt|;
specifier|private
specifier|transient
name|StandardStructObjectInspector
name|neededStandardStructObjectInspector
decl_stmt|;
specifier|private
specifier|transient
name|VectorizedRowBatchCtx
name|batchContext
decl_stmt|;
comment|// The context for creating the VectorizedRowBatch for this Map node that
comment|// the Vectorizer class determined.
comment|/*    * A different batch for vectorized Input File Format readers so they can do their work    * overlapped with work of the row collection that vector/row deserialization does.  This allows    * the partitions to mix modes (e.g. for us to flush the previously batched rows on file change).    */
specifier|private
specifier|transient
name|VectorizedRowBatch
name|vectorizedInputFileFormatBatch
decl_stmt|;
comment|/*    * This batch is only used by vector/row deserializer readers.    */
specifier|private
specifier|transient
name|VectorizedRowBatch
name|deserializerBatch
decl_stmt|;
specifier|private
specifier|transient
name|long
name|batchCounter
decl_stmt|;
specifier|private
specifier|transient
name|int
name|dataColumnCount
decl_stmt|;
specifier|private
specifier|transient
name|int
name|partitionColumnCount
decl_stmt|;
specifier|private
specifier|transient
name|Object
index|[]
name|partitionValues
decl_stmt|;
specifier|private
specifier|transient
name|boolean
index|[]
name|dataColumnsToIncludeTruncated
decl_stmt|;
comment|/*    * The following members have context information for the current partition file being read.    */
specifier|private
specifier|transient
name|VectorMapOperatorReadType
name|currentReadType
decl_stmt|;
specifier|private
specifier|transient
name|VectorPartitionContext
name|currentVectorPartContext
decl_stmt|;
comment|// Current vector map operator read type and context.
specifier|private
specifier|transient
name|int
name|currentDataColumnCount
decl_stmt|;
comment|// The number of data columns that the current reader will return.
comment|// Only applicable for vector/row deserialization.
specifier|private
specifier|transient
name|DeserializeRead
name|currentDeserializeRead
decl_stmt|;
specifier|private
specifier|transient
name|VectorDeserializeRow
name|currentVectorDeserializeRow
decl_stmt|;
comment|// When we are doing vector deserialization, these are the fast deserializer and
comment|// the vector row deserializer.
specifier|private
name|Deserializer
name|currentPartDeserializer
decl_stmt|;
specifier|private
name|StructObjectInspector
name|currentPartRawRowObjectInspector
decl_stmt|;
specifier|private
name|VectorAssignRow
name|currentVectorAssign
decl_stmt|;
comment|// When we are doing row deserialization, these are the regular deserializer,
comment|// partition object inspector, and vector row assigner.
comment|/*    * The abstract context for the 3 kinds of vectorized reading.    */
specifier|protected
specifier|abstract
class|class
name|VectorPartitionContext
block|{
specifier|protected
specifier|final
name|PartitionDesc
name|partDesc
decl_stmt|;
name|String
name|tableName
decl_stmt|;
name|String
name|partName
decl_stmt|;
comment|/*      * Initialization here is adapted from MapOperator.MapOpCtx.initObjectInspector method.      */
specifier|private
name|VectorPartitionContext
parameter_list|(
name|PartitionDesc
name|partDesc
parameter_list|)
block|{
name|this
operator|.
name|partDesc
operator|=
name|partDesc
expr_stmt|;
name|TableDesc
name|td
init|=
name|partDesc
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
comment|// Use table properties in case of unpartitioned tables,
comment|// and the union of table properties and partition properties, with partition
comment|// taking precedence, in the case of partitioned tables
name|Properties
name|overlayedProps
init|=
name|SerDeUtils
operator|.
name|createOverlayedProperties
argument_list|(
name|td
operator|.
name|getProperties
argument_list|()
argument_list|,
name|partDesc
operator|.
name|getProperties
argument_list|()
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|partDesc
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
name|tableName
operator|=
name|String
operator|.
name|valueOf
argument_list|(
name|overlayedProps
operator|.
name|getProperty
argument_list|(
literal|"name"
argument_list|)
argument_list|)
expr_stmt|;
name|partName
operator|=
name|String
operator|.
name|valueOf
argument_list|(
name|partSpec
argument_list|)
expr_stmt|;
block|}
specifier|public
name|PartitionDesc
name|getPartDesc
parameter_list|()
block|{
return|return
name|partDesc
return|;
block|}
comment|/*      * Override this for concrete initialization.      */
specifier|public
specifier|abstract
name|void
name|init
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|Exception
function_decl|;
comment|/*      * How many data columns is the partition reader actually supplying?      */
specifier|public
specifier|abstract
name|int
name|getReaderDataColumnCount
parameter_list|()
function_decl|;
block|}
comment|/*    * Context for reading a Vectorized Input File Format.    */
specifier|protected
class|class
name|VectorizedInputFileFormatPartitionContext
extends|extends
name|VectorPartitionContext
block|{
specifier|private
name|VectorizedInputFileFormatPartitionContext
parameter_list|(
name|PartitionDesc
name|partDesc
parameter_list|)
block|{
name|super
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|init
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
block|{     }
annotation|@
name|Override
specifier|public
name|int
name|getReaderDataColumnCount
parameter_list|()
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Not applicable"
argument_list|)
throw|;
block|}
block|}
comment|/*    * Context for using VectorDeserializeRow to deserialize each row from the Input File Format    * into the VectorizedRowBatch.    */
specifier|protected
class|class
name|VectorDeserializePartitionContext
extends|extends
name|VectorPartitionContext
block|{
comment|// This helper object deserializes known deserialization / input file format combination into
comment|// columns of a row in a vectorized row batch.
specifier|private
name|VectorDeserializeRow
name|vectorDeserializeRow
decl_stmt|;
specifier|private
name|DeserializeRead
name|deserializeRead
decl_stmt|;
specifier|private
name|int
name|readerColumnCount
decl_stmt|;
specifier|private
name|VectorDeserializePartitionContext
parameter_list|(
name|PartitionDesc
name|partDesc
parameter_list|)
block|{
name|super
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
block|}
specifier|public
name|VectorDeserializeRow
name|getVectorDeserializeRow
parameter_list|()
block|{
return|return
name|vectorDeserializeRow
return|;
block|}
name|DeserializeRead
name|getDeserializeRead
parameter_list|()
block|{
return|return
name|deserializeRead
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getReaderDataColumnCount
parameter_list|()
block|{
return|return
name|readerColumnCount
return|;
block|}
specifier|public
name|void
name|init
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|HiveException
block|{
name|VectorPartitionDesc
name|vectorPartDesc
init|=
name|partDesc
operator|.
name|getVectorPartitionDesc
argument_list|()
decl_stmt|;
comment|// This type information specifies the data types the partition needs to read.
name|TypeInfo
index|[]
name|dataTypeInfos
init|=
name|vectorPartDesc
operator|.
name|getDataTypeInfos
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|vectorPartDesc
operator|.
name|getVectorDeserializeType
argument_list|()
condition|)
block|{
case|case
name|LAZY_SIMPLE
case|:
block|{
name|LazySerDeParameters
name|simpleSerdeParams
init|=
operator|new
name|LazySerDeParameters
argument_list|(
name|hconf
argument_list|,
name|partDesc
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getProperties
argument_list|()
argument_list|,
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|LazySimpleDeserializeRead
name|lazySimpleDeserializeRead
init|=
operator|new
name|LazySimpleDeserializeRead
argument_list|(
name|dataTypeInfos
argument_list|,
name|simpleSerdeParams
argument_list|)
decl_stmt|;
name|vectorDeserializeRow
operator|=
operator|new
name|VectorDeserializeRow
argument_list|<
name|LazySimpleDeserializeRead
argument_list|>
argument_list|(
name|lazySimpleDeserializeRead
argument_list|)
expr_stmt|;
comment|// Initialize with data row type conversion parameters.
name|readerColumnCount
operator|=
name|vectorDeserializeRow
operator|.
name|initConversion
argument_list|(
name|tableRowTypeInfos
argument_list|,
name|dataColumnsToIncludeTruncated
argument_list|)
expr_stmt|;
name|deserializeRead
operator|=
name|lazySimpleDeserializeRead
expr_stmt|;
block|}
break|break;
case|case
name|LAZY_BINARY
case|:
block|{
name|LazyBinaryDeserializeRead
name|lazyBinaryDeserializeRead
init|=
operator|new
name|LazyBinaryDeserializeRead
argument_list|(
name|dataTypeInfos
argument_list|)
decl_stmt|;
name|vectorDeserializeRow
operator|=
operator|new
name|VectorDeserializeRow
argument_list|<
name|LazyBinaryDeserializeRead
argument_list|>
argument_list|(
name|lazyBinaryDeserializeRead
argument_list|)
expr_stmt|;
comment|// Initialize with data row type conversion parameters.
name|readerColumnCount
operator|=
name|vectorDeserializeRow
operator|.
name|initConversion
argument_list|(
name|tableRowTypeInfos
argument_list|,
name|dataColumnsToIncludeTruncated
argument_list|)
expr_stmt|;
name|deserializeRead
operator|=
name|lazyBinaryDeserializeRead
expr_stmt|;
block|}
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected vector deserialize row type "
operator|+
name|vectorPartDesc
operator|.
name|getVectorDeserializeType
argument_list|()
operator|.
name|name
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
comment|/*    * Context for reading using the regular partition deserializer to get the row object and    * assigning the row object into the VectorizedRowBatch with VectorAssignRow    */
specifier|protected
class|class
name|RowDeserializePartitionContext
extends|extends
name|VectorPartitionContext
block|{
specifier|private
name|Deserializer
name|partDeserializer
decl_stmt|;
specifier|private
name|StructObjectInspector
name|partRawRowObjectInspector
decl_stmt|;
specifier|private
name|VectorAssignRow
name|vectorAssign
decl_stmt|;
specifier|private
name|int
name|readerColumnCount
decl_stmt|;
specifier|private
name|RowDeserializePartitionContext
parameter_list|(
name|PartitionDesc
name|partDesc
parameter_list|)
block|{
name|super
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
block|}
specifier|public
name|Deserializer
name|getPartDeserializer
parameter_list|()
block|{
return|return
name|partDeserializer
return|;
block|}
specifier|public
name|StructObjectInspector
name|getPartRawRowObjectInspector
parameter_list|()
block|{
return|return
name|partRawRowObjectInspector
return|;
block|}
specifier|public
name|VectorAssignRow
name|getVectorAssign
parameter_list|()
block|{
return|return
name|vectorAssign
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getReaderDataColumnCount
parameter_list|()
block|{
return|return
name|readerColumnCount
return|;
block|}
specifier|public
name|void
name|init
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|Exception
block|{
name|VectorPartitionDesc
name|vectorPartDesc
init|=
name|partDesc
operator|.
name|getVectorPartitionDesc
argument_list|()
decl_stmt|;
name|partDeserializer
operator|=
name|partDesc
operator|.
name|getDeserializer
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
if|if
condition|(
name|partDeserializer
operator|instanceof
name|OrcSerde
condition|)
block|{
comment|// UNDONE: We need to get the table schema inspector from self-describing Input File
comment|//         Formats like ORC.  Modify the ORC serde instead?  For now, this works.
name|partRawRowObjectInspector
operator|=
operator|(
name|StructObjectInspector
operator|)
name|OrcStruct
operator|.
name|createObjectInspector
argument_list|(
name|tableStructTypeInfo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partRawRowObjectInspector
operator|=
operator|(
name|StructObjectInspector
operator|)
name|partDeserializer
operator|.
name|getObjectInspector
argument_list|()
expr_stmt|;
block|}
name|TypeInfo
index|[]
name|dataTypeInfos
init|=
name|vectorPartDesc
operator|.
name|getDataTypeInfos
argument_list|()
decl_stmt|;
name|vectorAssign
operator|=
operator|new
name|VectorAssignRow
argument_list|()
expr_stmt|;
comment|// Initialize with data type conversion parameters.
name|readerColumnCount
operator|=
name|vectorAssign
operator|.
name|initConversion
argument_list|(
name|dataTypeInfos
argument_list|,
name|tableRowTypeInfos
argument_list|,
name|dataColumnsToIncludeTruncated
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|VectorPartitionContext
name|createAndInitPartitionContext
parameter_list|(
name|PartitionDesc
name|partDesc
parameter_list|,
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|Exception
block|{
name|VectorPartitionDesc
name|vectorPartDesc
init|=
name|partDesc
operator|.
name|getVectorPartitionDesc
argument_list|()
decl_stmt|;
name|VectorPartitionContext
name|vectorPartitionContext
decl_stmt|;
name|VectorMapOperatorReadType
name|vectorMapOperatorReadType
init|=
name|vectorPartDesc
operator|.
name|getVectorMapOperatorReadType
argument_list|()
decl_stmt|;
if|if
condition|(
name|vectorMapOperatorReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|VECTOR_DESERIALIZE
operator|||
name|vectorMapOperatorReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|ROW_DESERIALIZE
condition|)
block|{
comment|// Verify hive.exec.schema.evolution is true or we have an ACID table so we are producing
comment|// the table schema from ORC.  The Vectorizer class assures this.
name|boolean
name|isAcid
init|=
name|AcidUtils
operator|.
name|isTablePropertyTransactional
argument_list|(
name|partDesc
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getProperties
argument_list|()
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|Utilities
operator|.
name|isSchemaEvolutionEnabled
argument_list|(
name|hconf
argument_list|,
name|isAcid
argument_list|)
argument_list|)
expr_stmt|;
block|}
switch|switch
condition|(
name|vectorMapOperatorReadType
condition|)
block|{
case|case
name|VECTORIZED_INPUT_FILE_FORMAT
case|:
name|vectorPartitionContext
operator|=
operator|new
name|VectorizedInputFileFormatPartitionContext
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
break|break;
case|case
name|VECTOR_DESERIALIZE
case|:
name|vectorPartitionContext
operator|=
operator|new
name|VectorDeserializePartitionContext
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
break|break;
case|case
name|ROW_DESERIALIZE
case|:
name|vectorPartitionContext
operator|=
operator|new
name|RowDeserializePartitionContext
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected vector MapOperator read type "
operator|+
name|vectorMapOperatorReadType
operator|.
name|name
argument_list|()
argument_list|)
throw|;
block|}
name|vectorPartitionContext
operator|.
name|init
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
return|return
name|vectorPartitionContext
return|;
block|}
specifier|private
name|void
name|determineDataColumnsToIncludeTruncated
parameter_list|()
block|{
name|Preconditions
operator|.
name|checkState
argument_list|(
name|batchContext
operator|!=
literal|null
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|dataColumnNums
operator|!=
literal|null
argument_list|)
expr_stmt|;
name|boolean
index|[]
name|columnsToInclude
init|=
operator|new
name|boolean
index|[
name|dataColumnCount
index|]
decl_stmt|;
empty_stmt|;
specifier|final
name|int
name|count
init|=
name|dataColumnNums
operator|.
name|length
decl_stmt|;
name|int
name|columnNum
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|columnNum
operator|=
name|dataColumnNums
index|[
name|i
index|]
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|columnNum
operator|<
name|dataColumnCount
argument_list|)
expr_stmt|;
name|columnsToInclude
index|[
name|columnNum
index|]
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|columnNum
operator|==
operator|-
literal|1
condition|)
block|{
name|dataColumnsToIncludeTruncated
operator|=
operator|new
name|boolean
index|[
literal|0
index|]
expr_stmt|;
block|}
else|else
block|{
name|dataColumnsToIncludeTruncated
operator|=
name|Arrays
operator|.
name|copyOf
argument_list|(
name|columnsToInclude
argument_list|,
name|columnNum
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Kryo ctor. */
specifier|public
name|VectorMapOperator
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
block|}
specifier|public
name|VectorMapOperator
parameter_list|(
name|CompilationOpContext
name|ctx
parameter_list|)
block|{
name|super
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
block|}
comment|/*    * This is the same as the setChildren method below but for empty tables.    */
annotation|@
name|Override
specifier|public
name|void
name|initEmptyInputChildren
parameter_list|(
name|List
argument_list|<
name|Operator
argument_list|<
name|?
argument_list|>
argument_list|>
name|children
parameter_list|,
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|Exception
block|{
comment|// Get the single TableScanOperator.  Vectorization only supports one input tree.
name|Preconditions
operator|.
name|checkState
argument_list|(
name|children
operator|.
name|size
argument_list|()
operator|==
literal|1
argument_list|)
expr_stmt|;
name|oneRootOperator
operator|=
name|children
operator|.
name|get
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|internalSetChildren
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setChildren
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|Exception
block|{
comment|// Get the single TableScanOperator.  Vectorization only supports one input tree.
name|Iterator
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|aliasToWorkIterator
init|=
name|conf
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|values
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|oneRootOperator
operator|=
name|aliasToWorkIterator
operator|.
name|next
argument_list|()
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
operator|!
name|aliasToWorkIterator
operator|.
name|hasNext
argument_list|()
argument_list|)
expr_stmt|;
name|internalSetChildren
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
block|}
comment|/*    * Create information for vector map operator.    * The member oneRootOperator has been set.    */
specifier|private
name|void
name|internalSetChildren
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|Exception
block|{
comment|// The setupPartitionContextVars uses the prior read type to flush the prior deserializerBatch,
comment|// so set it here to none.
name|currentReadType
operator|=
name|VectorMapOperatorReadType
operator|.
name|NONE
expr_stmt|;
name|batchContext
operator|=
name|conf
operator|.
name|getVectorizedRowBatchCtx
argument_list|()
expr_stmt|;
comment|/*      * Use a different batch for vectorized Input File Format readers so they can do their work      * overlapped with work of the row collection that vector/row deserialization does.  This allows      * the partitions to mix modes (e.g. for us to flush the previously batched rows on file change).      */
name|vectorizedInputFileFormatBatch
operator|=
name|batchContext
operator|.
name|createVectorizedRowBatch
argument_list|()
expr_stmt|;
name|conf
operator|.
name|setVectorizedRowBatch
argument_list|(
name|vectorizedInputFileFormatBatch
argument_list|)
expr_stmt|;
comment|/*      * This batch is used by vector/row deserializer readers.      */
name|deserializerBatch
operator|=
name|batchContext
operator|.
name|createVectorizedRowBatch
argument_list|()
expr_stmt|;
name|batchCounter
operator|=
literal|0
expr_stmt|;
name|dataColumnCount
operator|=
name|batchContext
operator|.
name|getDataColumnCount
argument_list|()
expr_stmt|;
name|partitionColumnCount
operator|=
name|batchContext
operator|.
name|getPartitionColumnCount
argument_list|()
expr_stmt|;
name|partitionValues
operator|=
operator|new
name|Object
index|[
name|partitionColumnCount
index|]
expr_stmt|;
name|dataColumnNums
operator|=
name|batchContext
operator|.
name|getDataColumnNums
argument_list|()
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|dataColumnNums
operator|!=
literal|null
argument_list|)
expr_stmt|;
comment|// Form a truncated boolean include array for our vector/row deserializers.
name|determineDataColumnsToIncludeTruncated
argument_list|()
expr_stmt|;
comment|/*      * Create table related objects      */
specifier|final
name|String
index|[]
name|rowColumnNames
init|=
name|batchContext
operator|.
name|getRowColumnNames
argument_list|()
decl_stmt|;
specifier|final
name|TypeInfo
index|[]
name|rowColumnTypeInfos
init|=
name|batchContext
operator|.
name|getRowColumnTypeInfos
argument_list|()
decl_stmt|;
name|tableStructTypeInfo
operator|=
name|TypeInfoFactory
operator|.
name|getStructTypeInfo
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|rowColumnNames
argument_list|)
argument_list|,
name|Arrays
operator|.
name|asList
argument_list|(
name|rowColumnTypeInfos
argument_list|)
argument_list|)
expr_stmt|;
name|tableStandardStructObjectInspector
operator|=
operator|(
name|StandardStructObjectInspector
operator|)
name|TypeInfoUtils
operator|.
name|getStandardWritableObjectInspectorFromTypeInfo
argument_list|(
name|tableStructTypeInfo
argument_list|)
expr_stmt|;
name|tableRowTypeInfos
operator|=
name|batchContext
operator|.
name|getRowColumnTypeInfos
argument_list|()
expr_stmt|;
comment|/*      * NOTE: We do not alter the projectedColumns / projectionSize of the batches to just be      * the included columns (+ partition columns).      *      * For now, we need to model the object inspector rows because there are still several      * vectorized operators that use them.      *      * We need to continue to model the Object[] as having null objects for not included columns      * until the following has been fixed:      *    o When we have to output a STRUCT for AVG we switch to row GroupBy operators.      *    o Some variations of VectorMapOperator, VectorReduceSinkOperator, VectorFileSinkOperator      *      use the row super class to process rows.      */
comment|/*      * The Vectorizer class enforces that there is only one TableScanOperator, so      * we don't need the more complicated multiple root operator mapping that MapOperator has.      */
name|fileToPartitionContextMap
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|VectorPartitionContext
argument_list|>
argument_list|()
expr_stmt|;
comment|// Temporary map so we only create one partition context entry.
name|HashMap
argument_list|<
name|PartitionDesc
argument_list|,
name|VectorPartitionContext
argument_list|>
name|partitionContextMap
init|=
operator|new
name|HashMap
argument_list|<
name|PartitionDesc
argument_list|,
name|VectorPartitionContext
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Path
argument_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|>
name|entry
range|:
name|conf
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Path
name|path
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|PartitionDesc
name|partDesc
init|=
name|conf
operator|.
name|getPathToPartitionInfo
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|String
argument_list|>
name|aliases
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|VectorPartitionDesc
name|vectorPartDesc
init|=
name|partDesc
operator|.
name|getVectorPartitionDesc
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"VectorMapOperator path: "
operator|+
name|path
operator|+
literal|", read type "
operator|+
name|vectorPartDesc
operator|.
name|getVectorMapOperatorReadType
argument_list|()
operator|.
name|name
argument_list|()
operator|+
literal|", vector deserialize type "
operator|+
name|vectorPartDesc
operator|.
name|getVectorDeserializeType
argument_list|()
operator|.
name|name
argument_list|()
operator|+
literal|", aliases "
operator|+
name|aliases
argument_list|)
expr_stmt|;
name|VectorPartitionContext
name|vectorPartitionContext
decl_stmt|;
if|if
condition|(
operator|!
name|partitionContextMap
operator|.
name|containsKey
argument_list|(
name|partDesc
argument_list|)
condition|)
block|{
name|vectorPartitionContext
operator|=
name|createAndInitPartitionContext
argument_list|(
name|partDesc
argument_list|,
name|hconf
argument_list|)
expr_stmt|;
name|partitionContextMap
operator|.
name|put
argument_list|(
name|partDesc
argument_list|,
name|vectorPartitionContext
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vectorPartitionContext
operator|=
name|partitionContextMap
operator|.
name|get
argument_list|(
name|partDesc
argument_list|)
expr_stmt|;
block|}
name|fileToPartitionContextMap
operator|.
name|put
argument_list|(
name|path
operator|.
name|toString
argument_list|()
argument_list|,
name|vectorPartitionContext
argument_list|)
expr_stmt|;
block|}
comment|// Create list of one.
name|List
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
name|children
init|=
operator|new
name|ArrayList
argument_list|<
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|children
operator|.
name|add
argument_list|(
name|oneRootOperator
argument_list|)
expr_stmt|;
name|setChildOperators
argument_list|(
name|children
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|initializeMapOperator
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|HiveException
block|{
name|super
operator|.
name|initializeMapOperator
argument_list|(
name|hconf
argument_list|)
expr_stmt|;
name|oneRootOperator
operator|.
name|initialize
argument_list|(
name|hconf
argument_list|,
operator|new
name|ObjectInspector
index|[]
block|{
name|tableStandardStructObjectInspector
block|}
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|initializeContexts
parameter_list|()
throws|throws
name|HiveException
block|{
name|Path
name|fpath
init|=
name|getExecContext
argument_list|()
operator|.
name|getCurrentInputPath
argument_list|()
decl_stmt|;
name|String
name|nominalPath
init|=
name|getNominalPath
argument_list|(
name|fpath
argument_list|)
decl_stmt|;
name|setupPartitionContextVars
argument_list|(
name|nominalPath
argument_list|)
expr_stmt|;
block|}
comment|// Find context for current input file
annotation|@
name|Override
specifier|public
name|void
name|cleanUpInputFileChangedOp
parameter_list|()
throws|throws
name|HiveException
block|{
name|super
operator|.
name|cleanUpInputFileChangedOp
argument_list|()
expr_stmt|;
name|Path
name|fpath
init|=
name|getExecContext
argument_list|()
operator|.
name|getCurrentInputPath
argument_list|()
decl_stmt|;
name|String
name|nominalPath
init|=
name|getNominalPath
argument_list|(
name|fpath
argument_list|)
decl_stmt|;
name|setupPartitionContextVars
argument_list|(
name|nominalPath
argument_list|)
expr_stmt|;
comment|// Add alias, table name, and partitions to hadoop conf so that their
comment|// children will inherit these
name|oneRootOperator
operator|.
name|setInputContext
argument_list|(
name|currentVectorPartContext
operator|.
name|tableName
argument_list|,
name|currentVectorPartContext
operator|.
name|partName
argument_list|)
expr_stmt|;
block|}
comment|/*    * Setup the context for reading from the next partition file.    */
specifier|private
name|void
name|setupPartitionContextVars
parameter_list|(
name|String
name|nominalPath
parameter_list|)
throws|throws
name|HiveException
block|{
name|currentVectorPartContext
operator|=
name|fileToPartitionContextMap
operator|.
name|get
argument_list|(
name|nominalPath
argument_list|)
expr_stmt|;
name|PartitionDesc
name|partDesc
init|=
name|currentVectorPartContext
operator|.
name|getPartDesc
argument_list|()
decl_stmt|;
name|VectorPartitionDesc
name|vectorPartDesc
init|=
name|partDesc
operator|.
name|getVectorPartitionDesc
argument_list|()
decl_stmt|;
name|currentReadType
operator|=
name|vectorPartDesc
operator|.
name|getVectorMapOperatorReadType
argument_list|()
expr_stmt|;
comment|/*      * Setup for 3 different kinds of vectorized reading supported:      *      *   1) Read the Vectorized Input File Format which returns VectorizedRowBatch as the row.      *      *   2) Read using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch.      *      *   3) And read using the regular partition deserializer to get the row object and assigning      *      the row object into the VectorizedRowBatch with VectorAssignRow.      */
if|if
condition|(
name|currentReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|VECTORIZED_INPUT_FILE_FORMAT
condition|)
block|{
comment|/*        * The Vectorized Input File Format reader is responsible for setting the partition column        * values, resetting and filling in the batch, etc.        */
comment|/*        * Clear all the reading variables.        */
name|currentDataColumnCount
operator|=
literal|0
expr_stmt|;
name|currentDeserializeRead
operator|=
literal|null
expr_stmt|;
name|currentVectorDeserializeRow
operator|=
literal|null
expr_stmt|;
name|currentPartDeserializer
operator|=
literal|null
expr_stmt|;
name|currentPartRawRowObjectInspector
operator|=
literal|null
expr_stmt|;
name|currentVectorAssign
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
comment|/*        * We will get "regular" single rows from the Input File Format reader that we will need        * to {vector|row} deserialize.        */
name|Preconditions
operator|.
name|checkState
argument_list|(
name|currentReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|VECTOR_DESERIALIZE
operator|||
name|currentReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|ROW_DESERIALIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|deserializerBatch
operator|.
name|size
operator|>
literal|0
condition|)
block|{
comment|/*          * Clear out any rows in the batch from previous partition since we are going to change          * the repeating partition column values.          */
name|batchCounter
operator|++
expr_stmt|;
name|oneRootOperator
operator|.
name|process
argument_list|(
name|deserializerBatch
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|deserializerBatch
operator|.
name|reset
argument_list|()
expr_stmt|;
if|if
condition|(
name|oneRootOperator
operator|.
name|getDone
argument_list|()
condition|)
block|{
name|setDone
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
comment|/*        * For this particular file, how many columns will we actually read?        */
name|currentDataColumnCount
operator|=
name|currentVectorPartContext
operator|.
name|getReaderDataColumnCount
argument_list|()
expr_stmt|;
if|if
condition|(
name|currentDataColumnCount
operator|<
name|dataColumnCount
condition|)
block|{
comment|/*          * Default any additional data columns to NULL once for the file (if they are present).          */
for|for
control|(
name|int
name|i
init|=
name|currentDataColumnCount
init|;
name|i
operator|<
name|dataColumnCount
condition|;
name|i
operator|++
control|)
block|{
name|ColumnVector
name|colVector
init|=
name|deserializerBatch
operator|.
name|cols
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|colVector
operator|!=
literal|null
condition|)
block|{
name|colVector
operator|.
name|isNull
index|[
literal|0
index|]
operator|=
literal|true
expr_stmt|;
name|colVector
operator|.
name|noNulls
operator|=
literal|false
expr_stmt|;
name|colVector
operator|.
name|isRepeating
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|batchContext
operator|.
name|getPartitionColumnCount
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|/*          * The partition columns are set once for the partition and are marked repeating.          */
name|VectorizedRowBatchCtx
operator|.
name|getPartitionValues
argument_list|(
name|batchContext
argument_list|,
name|partDesc
argument_list|,
name|partitionValues
argument_list|)
expr_stmt|;
name|batchContext
operator|.
name|addPartitionColsToBatch
argument_list|(
name|deserializerBatch
argument_list|,
name|partitionValues
argument_list|)
expr_stmt|;
block|}
comment|/*        * Set or clear the rest of the reading variables based on {vector|row} deserialization.        */
switch|switch
condition|(
name|currentReadType
condition|)
block|{
case|case
name|VECTOR_DESERIALIZE
case|:
block|{
name|VectorDeserializePartitionContext
name|vectorDeserPartContext
init|=
operator|(
name|VectorDeserializePartitionContext
operator|)
name|currentVectorPartContext
decl_stmt|;
comment|// Set ours.
name|currentDeserializeRead
operator|=
name|vectorDeserPartContext
operator|.
name|getDeserializeRead
argument_list|()
expr_stmt|;
name|currentVectorDeserializeRow
operator|=
name|vectorDeserPartContext
operator|.
name|getVectorDeserializeRow
argument_list|()
expr_stmt|;
comment|// Clear the other ones.
name|currentPartDeserializer
operator|=
literal|null
expr_stmt|;
name|currentPartRawRowObjectInspector
operator|=
literal|null
expr_stmt|;
name|currentVectorAssign
operator|=
literal|null
expr_stmt|;
block|}
break|break;
case|case
name|ROW_DESERIALIZE
case|:
block|{
name|RowDeserializePartitionContext
name|rowDeserPartContext
init|=
operator|(
name|RowDeserializePartitionContext
operator|)
name|currentVectorPartContext
decl_stmt|;
comment|// Clear the other ones.
name|currentDeserializeRead
operator|=
literal|null
expr_stmt|;
name|currentVectorDeserializeRow
operator|=
literal|null
expr_stmt|;
comment|// Set ours.
name|currentPartDeserializer
operator|=
name|rowDeserPartContext
operator|.
name|getPartDeserializer
argument_list|()
expr_stmt|;
name|currentPartRawRowObjectInspector
operator|=
name|rowDeserPartContext
operator|.
name|getPartRawRowObjectInspector
argument_list|()
expr_stmt|;
name|currentVectorAssign
operator|=
name|rowDeserPartContext
operator|.
name|getVectorAssign
argument_list|()
expr_stmt|;
block|}
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected VectorMapOperator read type "
operator|+
name|currentReadType
operator|.
name|name
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|Deserializer
name|getCurrentDeserializer
parameter_list|()
block|{
comment|// Not applicable.
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|process
parameter_list|(
name|Writable
name|value
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// A mapper can span multiple files/partitions.
comment|// The VectorPartitionContext need to be changed if the input file changed
name|ExecMapperContext
name|context
init|=
name|getExecContext
argument_list|()
decl_stmt|;
if|if
condition|(
name|context
operator|!=
literal|null
operator|&&
name|context
operator|.
name|inputFileChanged
argument_list|()
condition|)
block|{
comment|// The child operators cleanup if input file has changed
name|cleanUpInputFileChanged
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|oneRootOperator
operator|.
name|getDone
argument_list|()
condition|)
block|{
comment|/*        * 3 different kinds of vectorized reading supported:        *        *   1) Read the Vectorized Input File Format which returns VectorizedRowBatch as the row.        *        *   2) Read using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch.        *        *   3) And read using the regular partition deserializer to get the row object and assigning        *      the row object into the VectorizedRowBatch with VectorAssignRow.        */
try|try
block|{
if|if
condition|(
name|currentReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|VECTORIZED_INPUT_FILE_FORMAT
condition|)
block|{
comment|/*            * The Vectorized Input File Format reader has already set the partition column            * values, reset and filled in the batch, etc.            *            * We pass the VectorizedRowBatch through here.            */
name|batchCounter
operator|++
expr_stmt|;
if|if
condition|(
name|value
operator|!=
literal|null
condition|)
block|{
name|numRows
operator|+=
operator|(
operator|(
name|VectorizedRowBatch
operator|)
name|value
operator|)
operator|.
name|size
expr_stmt|;
block|}
name|oneRootOperator
operator|.
name|process
argument_list|(
name|value
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|oneRootOperator
operator|.
name|getDone
argument_list|()
condition|)
block|{
name|setDone
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
else|else
block|{
comment|/*            * We have a "regular" single rows from the Input File Format reader that we will need            * to deserialize.            */
name|Preconditions
operator|.
name|checkState
argument_list|(
name|currentReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|VECTOR_DESERIALIZE
operator|||
name|currentReadType
operator|==
name|VectorMapOperatorReadType
operator|.
name|ROW_DESERIALIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|deserializerBatch
operator|.
name|size
operator|==
name|deserializerBatch
operator|.
name|DEFAULT_SIZE
condition|)
block|{
name|numRows
operator|+=
name|deserializerBatch
operator|.
name|size
expr_stmt|;
comment|/*              * Feed current full batch to operator tree.              */
name|batchCounter
operator|++
expr_stmt|;
name|oneRootOperator
operator|.
name|process
argument_list|(
name|deserializerBatch
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/**              * Only reset the current data columns.  Not any data columns defaulted to NULL              * because they are not present in the partition, and not partition columns.              */
for|for
control|(
name|int
name|c
init|=
literal|0
init|;
name|c
operator|<
name|currentDataColumnCount
condition|;
name|c
operator|++
control|)
block|{
name|ColumnVector
name|colVector
init|=
name|deserializerBatch
operator|.
name|cols
index|[
name|c
index|]
decl_stmt|;
if|if
condition|(
name|colVector
operator|!=
literal|null
condition|)
block|{
name|colVector
operator|.
name|reset
argument_list|()
expr_stmt|;
name|colVector
operator|.
name|init
argument_list|()
expr_stmt|;
block|}
block|}
name|deserializerBatch
operator|.
name|selectedInUse
operator|=
literal|false
expr_stmt|;
name|deserializerBatch
operator|.
name|size
operator|=
literal|0
expr_stmt|;
name|deserializerBatch
operator|.
name|endOfFile
operator|=
literal|false
expr_stmt|;
if|if
condition|(
name|oneRootOperator
operator|.
name|getDone
argument_list|()
condition|)
block|{
name|setDone
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
comment|/*            * Do the {vector|row} deserialization of the one row into the VectorizedRowBatch.            */
switch|switch
condition|(
name|currentReadType
condition|)
block|{
case|case
name|VECTOR_DESERIALIZE
case|:
block|{
name|BinaryComparable
name|binComp
init|=
operator|(
name|BinaryComparable
operator|)
name|value
decl_stmt|;
name|currentDeserializeRead
operator|.
name|set
argument_list|(
name|binComp
operator|.
name|getBytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|binComp
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// Deserialize and append new row using the current batch size as the index.
name|currentVectorDeserializeRow
operator|.
name|deserialize
argument_list|(
name|deserializerBatch
argument_list|,
name|deserializerBatch
operator|.
name|size
operator|++
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|ROW_DESERIALIZE
case|:
block|{
name|Object
name|deserialized
init|=
name|currentPartDeserializer
operator|.
name|deserialize
argument_list|(
name|value
argument_list|)
decl_stmt|;
comment|// Note: Regardless of what the Input File Format returns, we have determined
comment|// with VectorAppendRow.initConversion that only currentDataColumnCount columns
comment|// have values we want.
comment|//
comment|// Any extra columns needed by the table schema were set to repeating null
comment|// in the batch by setupPartitionContextVars.
comment|// Convert input row to standard objects.
name|List
argument_list|<
name|Object
argument_list|>
name|standardObjects
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|()
decl_stmt|;
name|ObjectInspectorUtils
operator|.
name|copyToStandardObject
argument_list|(
name|standardObjects
argument_list|,
name|deserialized
argument_list|,
name|currentPartRawRowObjectInspector
argument_list|,
name|ObjectInspectorCopyOption
operator|.
name|WRITABLE
argument_list|)
expr_stmt|;
if|if
condition|(
name|standardObjects
operator|.
name|size
argument_list|()
operator|<
name|currentDataColumnCount
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Input File Format returned row with too few columns"
argument_list|)
throw|;
block|}
comment|// Append the deserialized standard object row using the current batch size
comment|// as the index.
name|currentVectorAssign
operator|.
name|assignRow
argument_list|(
name|deserializerBatch
argument_list|,
name|deserializerBatch
operator|.
name|size
operator|++
argument_list|,
name|standardObjects
argument_list|,
name|currentDataColumnCount
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected vector MapOperator read type "
operator|+
name|currentReadType
operator|.
name|name
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Hive Runtime Error while processing row "
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|process
parameter_list|(
name|Object
name|row
parameter_list|,
name|int
name|tag
parameter_list|)
throws|throws
name|HiveException
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Hive 2 Internal error: should not be called!"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeOp
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|abort
operator|&&
name|oneRootOperator
operator|!=
literal|null
operator|&&
operator|!
name|oneRootOperator
operator|.
name|getDone
argument_list|()
operator|&&
name|currentReadType
operator|!=
name|VectorMapOperatorReadType
operator|.
name|VECTORIZED_INPUT_FILE_FORMAT
condition|)
block|{
if|if
condition|(
name|deserializerBatch
operator|.
name|size
operator|>
literal|0
condition|)
block|{
name|numRows
operator|+=
name|deserializerBatch
operator|.
name|size
expr_stmt|;
name|batchCounter
operator|++
expr_stmt|;
name|oneRootOperator
operator|.
name|process
argument_list|(
name|deserializerBatch
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|deserializerBatch
operator|.
name|size
operator|=
literal|0
expr_stmt|;
block|}
block|}
name|super
operator|.
name|closeOp
argument_list|(
name|abort
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
name|getOperatorName
argument_list|()
return|;
block|}
specifier|static
specifier|public
name|String
name|getOperatorName
parameter_list|()
block|{
return|return
literal|"MAP"
return|;
block|}
annotation|@
name|Override
specifier|public
name|OperatorType
name|getType
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
block|}
end_class

end_unit

