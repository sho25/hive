begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|ColumnarSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|LlapAwareSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|SyntheticFileId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|OrcProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OrcTail
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * OrcFileSplit. Holds file meta info  *  */
end_comment

begin_class
specifier|public
class|class
name|OrcSplit
extends|extends
name|FileSplit
implements|implements
name|ColumnarSplit
implements|,
name|LlapAwareSplit
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|OrcSplit
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|OrcTail
name|orcTail
decl_stmt|;
specifier|private
name|boolean
name|hasFooter
decl_stmt|;
comment|/**    * This means {@link AcidUtils.AcidBaseFileType#ORIGINAL_BASE}    */
specifier|private
name|boolean
name|isOriginal
decl_stmt|;
specifier|private
name|boolean
name|hasBase
decl_stmt|;
comment|//partition root
specifier|private
name|Path
name|rootDir
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|deltas
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
name|long
name|projColsUncompressedSize
decl_stmt|;
specifier|private
specifier|transient
name|Object
name|fileKey
decl_stmt|;
specifier|private
name|long
name|fileLen
decl_stmt|;
specifier|static
specifier|final
name|int
name|HAS_SYNTHETIC_FILEID_FLAG
init|=
literal|16
decl_stmt|;
specifier|static
specifier|final
name|int
name|HAS_LONG_FILEID_FLAG
init|=
literal|8
decl_stmt|;
specifier|static
specifier|final
name|int
name|BASE_FLAG
init|=
literal|4
decl_stmt|;
specifier|static
specifier|final
name|int
name|ORIGINAL_FLAG
init|=
literal|2
decl_stmt|;
specifier|static
specifier|final
name|int
name|FOOTER_FLAG
init|=
literal|1
decl_stmt|;
specifier|protected
name|OrcSplit
parameter_list|()
block|{
comment|//The FileSplit() constructor in hadoop 0.20 and 1.x is package private so can't use it.
comment|//This constructor is used to create the object and then call readFields()
comment|// so just pass nulls to this super constructor.
name|super
argument_list|(
literal|null
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
operator|(
name|String
index|[]
operator|)
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
name|OrcSplit
parameter_list|(
name|Path
name|path
parameter_list|,
name|Object
name|fileId
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|,
name|String
index|[]
name|hosts
parameter_list|,
name|OrcTail
name|orcTail
parameter_list|,
name|boolean
name|isOriginal
parameter_list|,
name|boolean
name|hasBase
parameter_list|,
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|,
name|long
name|projectedDataSize
parameter_list|,
name|long
name|fileLen
parameter_list|,
name|Path
name|rootDir
parameter_list|)
block|{
name|super
argument_list|(
name|path
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|hosts
argument_list|)
expr_stmt|;
comment|// For HDFS, we could avoid serializing file ID and just replace the path with inode-based
comment|// path. However, that breaks bunch of stuff because Hive later looks up things by split path.
name|this
operator|.
name|fileKey
operator|=
name|fileId
expr_stmt|;
name|this
operator|.
name|orcTail
operator|=
name|orcTail
expr_stmt|;
name|hasFooter
operator|=
name|this
operator|.
name|orcTail
operator|!=
literal|null
expr_stmt|;
name|this
operator|.
name|isOriginal
operator|=
name|isOriginal
expr_stmt|;
name|this
operator|.
name|hasBase
operator|=
name|hasBase
expr_stmt|;
name|this
operator|.
name|rootDir
operator|=
name|rootDir
expr_stmt|;
name|this
operator|.
name|deltas
operator|.
name|addAll
argument_list|(
name|deltas
argument_list|)
expr_stmt|;
name|this
operator|.
name|projColsUncompressedSize
operator|=
name|projectedDataSize
operator|<=
literal|0
condition|?
name|length
else|:
name|projectedDataSize
expr_stmt|;
comment|// setting file length to Long.MAX_VALUE will let orc reader read file length from file system
name|this
operator|.
name|fileLen
operator|=
name|fileLen
operator|<=
literal|0
condition|?
name|Long
operator|.
name|MAX_VALUE
else|:
name|fileLen
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|ByteArrayOutputStream
name|bos
init|=
operator|new
name|ByteArrayOutputStream
argument_list|()
decl_stmt|;
name|DataOutputStream
name|dos
init|=
operator|new
name|DataOutputStream
argument_list|(
name|bos
argument_list|)
decl_stmt|;
comment|// serialize path, offset, length using FileSplit
name|super
operator|.
name|write
argument_list|(
name|dos
argument_list|)
expr_stmt|;
name|int
name|required
init|=
name|bos
operator|.
name|size
argument_list|()
decl_stmt|;
comment|// write addition payload required for orc
name|writeAdditionalPayload
argument_list|(
name|dos
argument_list|)
expr_stmt|;
name|int
name|additional
init|=
name|bos
operator|.
name|size
argument_list|()
operator|-
name|required
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
name|bos
operator|.
name|toByteArray
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Writing additional {} bytes to OrcSplit as payload. Required {} bytes."
argument_list|,
name|additional
argument_list|,
name|required
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|writeAdditionalPayload
parameter_list|(
specifier|final
name|DataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|isFileIdLong
init|=
name|fileKey
operator|instanceof
name|Long
decl_stmt|,
name|isFileIdWritable
init|=
name|fileKey
operator|instanceof
name|Writable
decl_stmt|;
name|int
name|flags
init|=
operator|(
name|hasBase
condition|?
name|BASE_FLAG
else|:
literal|0
operator|)
operator||
operator|(
name|isOriginal
condition|?
name|ORIGINAL_FLAG
else|:
literal|0
operator|)
operator||
operator|(
name|hasFooter
condition|?
name|FOOTER_FLAG
else|:
literal|0
operator|)
operator||
operator|(
name|isFileIdLong
condition|?
name|HAS_LONG_FILEID_FLAG
else|:
literal|0
operator|)
operator||
operator|(
name|isFileIdWritable
condition|?
name|HAS_SYNTHETIC_FILEID_FLAG
else|:
literal|0
operator|)
decl_stmt|;
name|out
operator|.
name|writeByte
argument_list|(
name|flags
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeInt
argument_list|(
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|delta
range|:
name|deltas
control|)
block|{
name|delta
operator|.
name|write
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hasFooter
condition|)
block|{
name|OrcProto
operator|.
name|FileTail
name|fileTail
init|=
name|orcTail
operator|.
name|getMinimalFileTail
argument_list|()
decl_stmt|;
name|byte
index|[]
name|tailBuffer
init|=
name|fileTail
operator|.
name|toByteArray
argument_list|()
decl_stmt|;
name|int
name|tailLen
init|=
name|tailBuffer
operator|.
name|length
decl_stmt|;
name|WritableUtils
operator|.
name|writeVInt
argument_list|(
name|out
argument_list|,
name|tailLen
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
name|tailBuffer
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isFileIdLong
condition|)
block|{
name|out
operator|.
name|writeLong
argument_list|(
operator|(
operator|(
name|Long
operator|)
name|fileKey
operator|)
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|isFileIdWritable
condition|)
block|{
operator|(
operator|(
name|Writable
operator|)
name|fileKey
operator|)
operator|.
name|write
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
name|out
operator|.
name|writeLong
argument_list|(
name|fileLen
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeUTF
argument_list|(
name|rootDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|readFields
parameter_list|(
name|DataInput
name|in
parameter_list|)
throws|throws
name|IOException
block|{
comment|//deserialize path, offset, length using FileSplit
name|super
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|byte
name|flags
init|=
name|in
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|hasFooter
operator|=
operator|(
name|FOOTER_FLAG
operator|&
name|flags
operator|)
operator|!=
literal|0
expr_stmt|;
name|isOriginal
operator|=
operator|(
name|ORIGINAL_FLAG
operator|&
name|flags
operator|)
operator|!=
literal|0
expr_stmt|;
name|hasBase
operator|=
operator|(
name|BASE_FLAG
operator|&
name|flags
operator|)
operator|!=
literal|0
expr_stmt|;
name|boolean
name|hasLongFileId
init|=
operator|(
name|HAS_LONG_FILEID_FLAG
operator|&
name|flags
operator|)
operator|!=
literal|0
decl_stmt|,
name|hasWritableFileId
init|=
operator|(
name|HAS_SYNTHETIC_FILEID_FLAG
operator|&
name|flags
operator|)
operator|!=
literal|0
decl_stmt|;
if|if
condition|(
name|hasLongFileId
operator|&&
name|hasWritableFileId
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid split - both file ID types present"
argument_list|)
throw|;
block|}
name|deltas
operator|.
name|clear
argument_list|()
expr_stmt|;
name|int
name|numDeltas
init|=
name|in
operator|.
name|readInt
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numDeltas
condition|;
name|i
operator|++
control|)
block|{
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|dmd
init|=
operator|new
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|()
decl_stmt|;
name|dmd
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|deltas
operator|.
name|add
argument_list|(
name|dmd
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hasFooter
condition|)
block|{
name|int
name|tailLen
init|=
name|WritableUtils
operator|.
name|readVInt
argument_list|(
name|in
argument_list|)
decl_stmt|;
name|byte
index|[]
name|tailBuffer
init|=
operator|new
name|byte
index|[
name|tailLen
index|]
decl_stmt|;
name|in
operator|.
name|readFully
argument_list|(
name|tailBuffer
argument_list|)
expr_stmt|;
name|OrcProto
operator|.
name|FileTail
name|fileTail
init|=
name|OrcProto
operator|.
name|FileTail
operator|.
name|parseFrom
argument_list|(
name|tailBuffer
argument_list|)
decl_stmt|;
name|orcTail
operator|=
operator|new
name|OrcTail
argument_list|(
name|fileTail
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hasLongFileId
condition|)
block|{
name|fileKey
operator|=
name|in
operator|.
name|readLong
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hasWritableFileId
condition|)
block|{
name|SyntheticFileId
name|fileId
init|=
operator|new
name|SyntheticFileId
argument_list|()
decl_stmt|;
name|fileId
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|this
operator|.
name|fileKey
operator|=
name|fileId
expr_stmt|;
block|}
name|fileLen
operator|=
name|in
operator|.
name|readLong
argument_list|()
expr_stmt|;
name|rootDir
operator|=
operator|new
name|Path
argument_list|(
name|in
operator|.
name|readUTF
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|OrcTail
name|getOrcTail
parameter_list|()
block|{
return|return
name|orcTail
return|;
block|}
specifier|public
name|boolean
name|hasFooter
parameter_list|()
block|{
return|return
name|hasFooter
return|;
block|}
specifier|public
name|boolean
name|isOriginal
parameter_list|()
block|{
return|return
name|isOriginal
return|;
block|}
specifier|public
name|boolean
name|hasBase
parameter_list|()
block|{
return|return
name|hasBase
return|;
block|}
specifier|public
name|Path
name|getRootDir
parameter_list|()
block|{
return|return
name|rootDir
return|;
block|}
specifier|public
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|getDeltas
parameter_list|()
block|{
return|return
name|deltas
return|;
block|}
specifier|public
name|long
name|getFileLength
parameter_list|()
block|{
return|return
name|fileLen
return|;
block|}
comment|/**    * If this method returns true, then for sure it is ACID.    * However, if it returns false.. it could be ACID or non-ACID.    * @return    */
specifier|public
name|boolean
name|isAcid
parameter_list|()
block|{
return|return
name|hasBase
operator|||
name|deltas
operator|.
name|size
argument_list|()
operator|>
literal|0
return|;
block|}
specifier|public
name|long
name|getProjectedColumnsUncompressedSize
parameter_list|()
block|{
return|return
name|projColsUncompressedSize
return|;
block|}
specifier|public
name|Object
name|getFileKey
parameter_list|()
block|{
return|return
name|fileKey
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getColumnarProjectionSize
parameter_list|()
block|{
return|return
name|projColsUncompressedSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|canUseLlapIo
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
specifier|final
name|boolean
name|hasDelta
init|=
name|deltas
operator|!=
literal|null
operator|&&
operator|!
name|deltas
operator|.
name|isEmpty
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|isAcidRead
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_ACID_TABLE_SCAN
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|isVectorized
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_VECTORIZATION_ENABLED
argument_list|)
decl_stmt|;
specifier|final
name|AcidUtils
operator|.
name|AcidOperationalProperties
name|acidOperationalProperties
init|=
name|AcidUtils
operator|.
name|getAcidOperationalProperties
argument_list|(
name|conf
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|isSplitUpdate
init|=
name|acidOperationalProperties
operator|.
name|isSplitUpdate
argument_list|()
decl_stmt|;
assert|assert
name|isSplitUpdate
operator|:
literal|"should be true in Hive 3.0"
assert|;
if|if
condition|(
name|isOriginal
condition|)
block|{
if|if
condition|(
operator|!
name|isAcidRead
operator|&&
operator|!
name|hasDelta
condition|)
block|{
comment|// Original scan only
return|return
literal|true
return|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|isAcidRead
operator|&&
name|hasBase
operator|&&
name|isVectorized
condition|)
block|{
if|if
condition|(
name|hasDelta
condition|)
block|{
if|if
condition|(
name|isSplitUpdate
condition|)
block|{
comment|// Base with delete deltas
return|return
literal|true
return|;
block|}
block|}
else|else
block|{
comment|// Base scan only
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"OrcSplit ["
operator|+
name|getPath
argument_list|()
operator|+
literal|", start="
operator|+
name|getStart
argument_list|()
operator|+
literal|", length="
operator|+
name|getLength
argument_list|()
operator|+
literal|", isOriginal="
operator|+
name|isOriginal
operator|+
literal|", fileLength="
operator|+
name|fileLen
operator|+
literal|", hasFooter="
operator|+
name|hasFooter
operator|+
literal|", hasBase="
operator|+
name|hasBase
operator|+
literal|", deltas="
operator|+
operator|(
name|deltas
operator|==
literal|null
condition|?
literal|0
else|:
name|deltas
operator|.
name|size
argument_list|()
operator|)
operator|+
literal|"]"
return|;
block|}
block|}
end_class

end_unit

