begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidTxnList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
operator|.
name|HdfsFileStatusWithId
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_comment
comment|/**  * Utilities that are shared by all of the ACID input and output formats. They  * are used by the compactor and cleaner and thus must be format agnostic.  */
end_comment

begin_class
specifier|public
class|class
name|AcidUtils
block|{
comment|// This key will be put in the conf file when planning an acid operation
specifier|public
specifier|static
specifier|final
name|String
name|CONF_ACID_KEY
init|=
literal|"hive.doing.acid"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BASE_PREFIX
init|=
literal|"base_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|baseFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_PREFIX
init|=
literal|"delta_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_SIDE_FILE_SUFFIX
init|=
literal|"_flush_length"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|deltaFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BUCKET_PREFIX
init|=
literal|"bucket_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|bucketFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
operator|&&
operator|!
name|path
operator|.
name|getName
argument_list|()
operator|.
name|endsWith
argument_list|(
name|DELTA_SIDE_FILE_SUFFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BUCKET_DIGITS
init|=
literal|"%05d"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_DIGITS
init|=
literal|"%07d"
decl_stmt|;
comment|/**    * 10K statements per tx.  Probably overkill ... since that many delta files    * would not be good for performance    */
specifier|public
specifier|static
specifier|final
name|String
name|STATEMENT_DIGITS
init|=
literal|"%04d"
decl_stmt|;
comment|/**    * This must be in sync with {@link #STATEMENT_DIGITS}    */
specifier|public
specifier|static
specifier|final
name|int
name|MAX_STATEMENTS_PER_TXN
init|=
literal|10000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|BUCKET_DIGIT_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]{5}$"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|LEGACY_BUCKET_DIGIT_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^[0-9]{5}"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|originalBucketFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|path
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|matches
argument_list|()
return|;
block|}
block|}
decl_stmt|;
specifier|private
name|AcidUtils
parameter_list|()
block|{
comment|// NOT USED
block|}
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|AcidUtils
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Pattern
name|ORIGINAL_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]+_[0-9]+"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|hiddenFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
name|name
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|HadoopShims
name|SHIMS
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
comment|/**    * Create the bucket filename.    * @param subdir the subdirectory for the bucket.    * @param bucket the bucket number    * @return the filename    */
specifier|public
specifier|static
name|Path
name|createBucketFile
parameter_list|(
name|Path
name|subdir
parameter_list|,
name|int
name|bucket
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|subdir
argument_list|,
name|BUCKET_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|BUCKET_DIGITS
argument_list|,
name|bucket
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * This is format of delta dir name prior to Hive 1.3.x    */
specifier|public
specifier|static
name|String
name|deltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|)
block|{
return|return
name|DELTA_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|min
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|max
argument_list|)
return|;
block|}
comment|/**    * Each write statement in a transaction creates its own delta dir.    * @since 1.3.x    */
specifier|public
specifier|static
name|String
name|deltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
return|return
name|deltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|STATEMENT_DIGITS
argument_list|,
name|statementId
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|baseDir
parameter_list|(
name|long
name|txnId
parameter_list|)
block|{
return|return
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|txnId
argument_list|)
return|;
block|}
comment|/**    * Create a filename for a bucket file.    * @param directory the partition directory    * @param options the options for writing the bucket    * @return the filename that should store the bucket    */
specifier|public
specifier|static
name|Path
name|createFilename
parameter_list|(
name|Path
name|directory
parameter_list|,
name|AcidOutputFormat
operator|.
name|Options
name|options
parameter_list|)
block|{
name|String
name|subdir
decl_stmt|;
if|if
condition|(
name|options
operator|.
name|getOldStyle
argument_list|()
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|directory
argument_list|,
name|String
operator|.
name|format
argument_list|(
name|BUCKET_DIGITS
argument_list|,
name|options
operator|.
name|getBucket
argument_list|()
argument_list|)
operator|+
literal|"_0"
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|options
operator|.
name|isWritingBase
argument_list|()
condition|)
block|{
name|subdir
operator|=
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|options
operator|.
name|getStatementId
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
comment|//when minor compaction runs, we collapse per statement delta files inside a single
comment|//transaction so we no longer need a statementId in the file name
name|subdir
operator|=
name|deltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|subdir
operator|=
name|deltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|createBucketFile
argument_list|(
operator|new
name|Path
argument_list|(
name|directory
argument_list|,
name|subdir
argument_list|)
argument_list|,
name|options
operator|.
name|getBucket
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get the transaction id from a base directory name.    * @param path the base directory name    * @return the maximum transaction id that is included    */
specifier|static
name|long
name|parseBase
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|String
name|filename
init|=
name|path
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|BASE_PREFIX
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|filename
operator|+
literal|" does not start with "
operator|+
name|BASE_PREFIX
argument_list|)
throw|;
block|}
comment|/**    * Parse a bucket filename back into the options that would have created    * the file.    * @param bucketFile the path to a bucket file    * @param conf the configuration    * @return the options used to create that filename    */
specifier|public
specifier|static
name|AcidOutputFormat
operator|.
name|Options
name|parseBaseBucketFilename
parameter_list|(
name|Path
name|bucketFile
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|AcidOutputFormat
operator|.
name|Options
name|result
init|=
operator|new
name|AcidOutputFormat
operator|.
name|Options
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|filename
init|=
name|bucketFile
operator|.
name|getName
argument_list|()
decl_stmt|;
name|result
operator|.
name|writingBase
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
name|int
name|bucket
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
condition|)
block|{
name|int
name|bucket
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
name|parseBase
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|)
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|bucket
argument_list|(
operator|-
literal|1
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
specifier|public
enum|enum
name|Operation
block|{
name|NOT_ACID
block|,
name|INSERT
block|,
name|UPDATE
block|,
name|DELETE
block|}
specifier|public
specifier|static
interface|interface
name|Directory
block|{
comment|/**      * Get the base directory.      * @return the base directory to read      */
name|Path
name|getBaseDirectory
parameter_list|()
function_decl|;
comment|/**      * Get the list of original files.  Not {@code null}.      * @return the list of original files (eg. 000000_0)      */
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|getOriginalFiles
parameter_list|()
function_decl|;
comment|/**      * Get the list of base and delta directories that are valid and not      * obsolete.  Not {@code null}.  List must be sorted in a specific way.      * See {@link org.apache.hadoop.hive.ql.io.AcidUtils.ParsedDelta#compareTo(org.apache.hadoop.hive.ql.io.AcidUtils.ParsedDelta)}      * for details.      * @return the minimal list of current directories      */
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|getCurrentDirectories
parameter_list|()
function_decl|;
comment|/**      * Get the list of obsolete directories. After filtering out bases and      * deltas that are not selected by the valid transaction list, return the      * list of original files, bases, and deltas that have been replaced by      * more up to date ones.  Not {@code null}.      */
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getObsolete
parameter_list|()
function_decl|;
block|}
specifier|public
specifier|static
class|class
name|ParsedDelta
implements|implements
name|Comparable
argument_list|<
name|ParsedDelta
argument_list|>
block|{
specifier|private
specifier|final
name|long
name|minTransaction
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxTransaction
decl_stmt|;
specifier|private
specifier|final
name|FileStatus
name|path
decl_stmt|;
comment|//-1 is for internal (getAcidState()) purposes and means the delta dir
comment|//had no statement ID
specifier|private
specifier|final
name|int
name|statementId
decl_stmt|;
comment|/**      * for pre 1.3.x delta files      */
name|ParsedDelta
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|FileStatus
name|path
parameter_list|)
block|{
name|this
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
name|path
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|ParsedDelta
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|FileStatus
name|path
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
name|this
operator|.
name|minTransaction
operator|=
name|min
expr_stmt|;
name|this
operator|.
name|maxTransaction
operator|=
name|max
expr_stmt|;
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
name|this
operator|.
name|statementId
operator|=
name|statementId
expr_stmt|;
block|}
specifier|public
name|long
name|getMinTransaction
parameter_list|()
block|{
return|return
name|minTransaction
return|;
block|}
specifier|public
name|long
name|getMaxTransaction
parameter_list|()
block|{
return|return
name|maxTransaction
return|;
block|}
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|path
operator|.
name|getPath
argument_list|()
return|;
block|}
specifier|public
name|int
name|getStatementId
parameter_list|()
block|{
return|return
name|statementId
operator|==
operator|-
literal|1
condition|?
literal|0
else|:
name|statementId
return|;
block|}
comment|/**      * Compactions (Major/Minor) merge deltas/bases but delete of old files      * happens in a different process; thus it's possible to have bases/deltas with      * overlapping txnId boundaries.  The sort order helps figure out the "best" set of files      * to use to get data.      * This sorts "wider" delta before "narrower" i.e. delta_5_20 sorts before delta_5_10 (and delta_11_20)      */
annotation|@
name|Override
specifier|public
name|int
name|compareTo
parameter_list|(
name|ParsedDelta
name|parsedDelta
parameter_list|)
block|{
if|if
condition|(
name|minTransaction
operator|!=
name|parsedDelta
operator|.
name|minTransaction
condition|)
block|{
if|if
condition|(
name|minTransaction
operator|<
name|parsedDelta
operator|.
name|minTransaction
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
literal|1
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|maxTransaction
operator|!=
name|parsedDelta
operator|.
name|maxTransaction
condition|)
block|{
if|if
condition|(
name|maxTransaction
operator|<
name|parsedDelta
operator|.
name|maxTransaction
condition|)
block|{
return|return
literal|1
return|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|statementId
operator|!=
name|parsedDelta
operator|.
name|statementId
condition|)
block|{
comment|/**          * We want deltas after minor compaction (w/o statementId) to sort          * earlier so that getAcidState() considers compacted files (into larger ones) obsolete          * Before compaction, include deltas with all statementIds for a given txnId          * in a {@link org.apache.hadoop.hive.ql.io.AcidUtils.Directory}          */
if|if
condition|(
name|statementId
operator|<
name|parsedDelta
operator|.
name|statementId
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
literal|1
return|;
block|}
block|}
else|else
block|{
return|return
name|path
operator|.
name|compareTo
argument_list|(
name|parsedDelta
operator|.
name|path
argument_list|)
return|;
block|}
block|}
block|}
comment|/**    * Convert a list of deltas to a list of delta directories.    * @param deltas the list of deltas out of a Directory object.    * @return a list of delta directory paths that need to be read    */
specifier|public
specifier|static
name|Path
index|[]
name|getPaths
parameter_list|(
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|)
block|{
name|Path
index|[]
name|result
init|=
operator|new
name|Path
index|[
name|deltas
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|result
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
name|deltas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getPath
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * Convert the list of deltas into an equivalent list of begin/end    * transaction id pairs.  Assumes {@code deltas} is sorted.    * @param deltas    * @return the list of transaction ids to serialize    */
specifier|public
specifier|static
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|serializeDeltas
parameter_list|(
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|)
block|{
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|last
init|=
literal|null
decl_stmt|;
for|for
control|(
name|ParsedDelta
name|parsedDelta
range|:
name|deltas
control|)
block|{
if|if
condition|(
name|last
operator|!=
literal|null
operator|&&
name|last
operator|.
name|getMinTxnId
argument_list|()
operator|==
name|parsedDelta
operator|.
name|getMinTransaction
argument_list|()
operator|&&
name|last
operator|.
name|getMaxTxnId
argument_list|()
operator|==
name|parsedDelta
operator|.
name|getMaxTransaction
argument_list|()
condition|)
block|{
name|last
operator|.
name|getStmtIds
argument_list|()
operator|.
name|add
argument_list|(
name|parsedDelta
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|last
operator|=
operator|new
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|(
name|parsedDelta
operator|.
name|getMinTransaction
argument_list|()
argument_list|,
name|parsedDelta
operator|.
name|getMaxTransaction
argument_list|()
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|last
argument_list|)
expr_stmt|;
if|if
condition|(
name|parsedDelta
operator|.
name|statementId
operator|>=
literal|0
condition|)
block|{
name|last
operator|.
name|getStmtIds
argument_list|()
operator|.
name|add
argument_list|(
name|parsedDelta
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Convert the list of begin/end transaction id pairs to a list of delta    * directories.  Note that there may be multiple delta files for the exact same txn range starting    * with 1.3.x;    * see {@link org.apache.hadoop.hive.ql.io.AcidUtils#deltaSubdir(long, long, int)}    * @param root the root directory    * @param deltas list of begin/end transaction id pairs    * @return the list of delta paths    */
specifier|public
specifier|static
name|Path
index|[]
name|deserializeDeltas
parameter_list|(
name|Path
name|root
parameter_list|,
specifier|final
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|deltas
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|dmd
range|:
name|deltas
control|)
block|{
if|if
condition|(
name|dmd
operator|.
name|getStmtIds
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Path
argument_list|(
name|root
argument_list|,
name|deltaSubdir
argument_list|(
name|dmd
operator|.
name|getMinTxnId
argument_list|()
argument_list|,
name|dmd
operator|.
name|getMaxTxnId
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
for|for
control|(
name|Integer
name|stmtId
range|:
name|dmd
operator|.
name|getStmtIds
argument_list|()
control|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Path
argument_list|(
name|root
argument_list|,
name|deltaSubdir
argument_list|(
name|dmd
operator|.
name|getMinTxnId
argument_list|()
argument_list|,
name|dmd
operator|.
name|getMaxTxnId
argument_list|()
argument_list|,
name|stmtId
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|results
operator|.
name|toArray
argument_list|(
operator|new
name|Path
index|[
name|results
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|ParsedDelta
name|parseDelta
parameter_list|(
name|FileStatus
name|path
parameter_list|)
block|{
name|ParsedDelta
name|p
init|=
name|parsedDelta
argument_list|(
name|path
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDelta
argument_list|(
name|p
operator|.
name|getMinTransaction
argument_list|()
argument_list|,
name|p
operator|.
name|getMaxTransaction
argument_list|()
argument_list|,
name|path
argument_list|,
name|p
operator|.
name|statementId
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|ParsedDelta
name|parsedDelta
parameter_list|(
name|Path
name|deltaDir
parameter_list|)
block|{
name|String
name|filename
init|=
name|deltaDir
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
condition|)
block|{
name|String
name|rest
init|=
name|filename
operator|.
name|substring
argument_list|(
name|DELTA_PREFIX
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|split
init|=
name|rest
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
decl_stmt|;
name|int
name|split2
init|=
name|rest
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|,
name|split
operator|+
literal|1
argument_list|)
decl_stmt|;
comment|//may be -1 if no statementId
name|long
name|min
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|split
argument_list|)
argument_list|)
decl_stmt|;
name|long
name|max
init|=
name|split2
operator|==
operator|-
literal|1
condition|?
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split
operator|+
literal|1
argument_list|)
argument_list|)
else|:
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split
operator|+
literal|1
argument_list|,
name|split2
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|split2
operator|==
operator|-
literal|1
condition|)
block|{
return|return
operator|new
name|ParsedDelta
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
literal|null
argument_list|)
return|;
block|}
name|int
name|statementId
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split2
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDelta
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
literal|null
argument_list|,
name|statementId
argument_list|)
return|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|deltaDir
operator|+
literal|" does not start with "
operator|+
name|DELTA_PREFIX
argument_list|)
throw|;
block|}
comment|/**    * Is the given directory in ACID format?    * @param directory the partition directory to check    * @param conf the query configuration    * @return true, if it is an ACID directory    * @throws IOException    */
specifier|public
specifier|static
name|boolean
name|isAcid
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|directory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|directory
argument_list|)
control|)
block|{
name|String
name|filename
init|=
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|||
name|filename
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
condition|)
block|{
if|if
condition|(
name|file
operator|.
name|isDir
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
name|directory
argument_list|,
name|conf
argument_list|,
name|txnList
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/** State class for getChildState; cannot modify 2 things in a method. */
specifier|private
specifier|static
class|class
name|TxnBase
block|{
specifier|private
name|FileStatus
name|status
decl_stmt|;
specifier|private
name|long
name|txn
decl_stmt|;
block|}
comment|/**    * Get the ACID state of the given directory. It finds the minimal set of    * base and diff directories. Note that because major compactions don't    * preserve the history, we can't use a base directory that includes a    * transaction id that we must exclude.    * @param directory the partition directory to analyze    * @param conf the configuration    * @param txnList the list of transactions that we are reading    * @return the state of the directory    * @throws IOException    */
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|,
name|boolean
name|useFileIds
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|directory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
init|=
operator|new
name|ArrayList
argument_list|<
name|ParsedDelta
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|working
init|=
operator|new
name|ArrayList
argument_list|<
name|ParsedDelta
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|originalDirectories
init|=
operator|new
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|FileStatus
argument_list|>
name|obsolete
init|=
operator|new
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|useFileIds
condition|)
block|{
try|try
block|{
name|childrenWithId
operator|=
name|SHIMS
operator|.
name|listLocatedHdfsStatus
argument_list|(
name|fs
argument_list|,
name|directory
argument_list|,
name|hiddenFileFilter
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get files with ID; using regular API"
argument_list|,
name|t
argument_list|)
expr_stmt|;
name|useFileIds
operator|=
literal|false
expr_stmt|;
block|}
block|}
name|TxnBase
name|bestBase
init|=
operator|new
name|TxnBase
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|childrenWithId
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|childrenWithId
control|)
block|{
name|getChildState
argument_list|(
name|child
operator|.
name|getFileStatus
argument_list|()
argument_list|,
name|child
argument_list|,
name|txnList
argument_list|,
name|working
argument_list|,
name|originalDirectories
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|bestBase
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|SHIMS
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|directory
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|getChildState
argument_list|(
name|child
argument_list|,
literal|null
argument_list|,
name|txnList
argument_list|,
name|working
argument_list|,
name|originalDirectories
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|bestBase
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we have a base, the original files are obsolete.
if|if
condition|(
name|bestBase
operator|.
name|status
operator|!=
literal|null
condition|)
block|{
comment|// remove the entries so we don't get confused later and think we should
comment|// use them.
name|original
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Okay, we're going to need these originals.  Recurse through them and figure out what we
comment|// really need.
for|for
control|(
name|FileStatus
name|origDir
range|:
name|originalDirectories
control|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|origDir
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|)
expr_stmt|;
block|}
block|}
name|Collections
operator|.
name|sort
argument_list|(
name|working
argument_list|)
expr_stmt|;
comment|//so now, 'working' should be sorted like delta_5_20 delta_5_10 delta_11_20 delta_51_60 for example
comment|//and we want to end up with the best set containing all relevant data: delta_5_20 delta_51_60,
comment|//subject to list of 'exceptions' in 'txnList' (not show in above example).
name|long
name|current
init|=
name|bestBase
operator|.
name|txn
decl_stmt|;
name|int
name|lastStmtId
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|ParsedDelta
name|next
range|:
name|working
control|)
block|{
if|if
condition|(
name|next
operator|.
name|maxTransaction
operator|>
name|current
condition|)
block|{
comment|// are any of the new transactions ones that we care about?
if|if
condition|(
name|txnList
operator|.
name|isTxnRangeValid
argument_list|(
name|current
operator|+
literal|1
argument_list|,
name|next
operator|.
name|maxTransaction
argument_list|)
operator|!=
name|ValidTxnList
operator|.
name|RangeResponse
operator|.
name|NONE
condition|)
block|{
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|current
operator|=
name|next
operator|.
name|maxTransaction
expr_stmt|;
name|lastStmtId
operator|=
name|next
operator|.
name|statementId
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|next
operator|.
name|maxTransaction
operator|==
name|current
operator|&&
name|lastStmtId
operator|>=
literal|0
condition|)
block|{
comment|//make sure to get all deltas within a single transaction;  multi-statement txn
comment|//generate multiple delta files with the same txnId range
comment|//of course, if maxTransaction has already been minor compacted, all per statement deltas are obsolete
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|next
operator|.
name|path
argument_list|)
expr_stmt|;
block|}
block|}
specifier|final
name|Path
name|base
init|=
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|?
literal|null
else|:
name|bestBase
operator|.
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"in directory "
operator|+
name|directory
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" base = "
operator|+
name|base
operator|+
literal|" deltas = "
operator|+
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|Directory
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Path
name|getBaseDirectory
parameter_list|()
block|{
return|return
name|base
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|getOriginalFiles
parameter_list|()
block|{
return|return
name|original
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|getCurrentDirectories
parameter_list|()
block|{
return|return
name|deltas
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getObsolete
parameter_list|()
block|{
return|return
name|obsolete
return|;
block|}
block|}
return|;
block|}
specifier|private
specifier|static
name|void
name|getChildState
parameter_list|(
name|FileStatus
name|child
parameter_list|,
name|HdfsFileStatusWithId
name|childWithId
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|,
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|working
parameter_list|,
name|List
argument_list|<
name|FileStatus
argument_list|>
name|originalDirectories
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|List
argument_list|<
name|FileStatus
argument_list|>
name|obsolete
parameter_list|,
name|TxnBase
name|bestBase
parameter_list|)
block|{
name|Path
name|p
init|=
name|child
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|String
name|fn
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|fn
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|&&
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|long
name|txn
init|=
name|parseBase
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|)
block|{
name|bestBase
operator|.
name|status
operator|=
name|child
expr_stmt|;
name|bestBase
operator|.
name|txn
operator|=
name|txn
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bestBase
operator|.
name|txn
operator|<
name|txn
condition|)
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|bestBase
operator|.
name|status
argument_list|)
expr_stmt|;
name|bestBase
operator|.
name|status
operator|=
name|child
expr_stmt|;
name|bestBase
operator|.
name|txn
operator|=
name|txn
expr_stmt|;
block|}
else|else
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|fn
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|&&
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|ParsedDelta
name|delta
init|=
name|parseDelta
argument_list|(
name|child
argument_list|)
decl_stmt|;
if|if
condition|(
name|txnList
operator|.
name|isTxnRangeValid
argument_list|(
name|delta
operator|.
name|minTransaction
argument_list|,
name|delta
operator|.
name|maxTransaction
argument_list|)
operator|!=
name|ValidTxnList
operator|.
name|RangeResponse
operator|.
name|NONE
condition|)
block|{
name|working
operator|.
name|add
argument_list|(
name|delta
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
comment|// This is just the directory.  We need to recurse and find the actual files.  But don't
comment|// do this until we have determined there is no base.  This saves time.  Plus,
comment|// it is possible that the cleaner is running and removing these original files,
comment|// in which case recursing through them could cause us to get an error.
name|originalDirectories
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|original
operator|.
name|add
argument_list|(
name|createOriginalObj
argument_list|(
name|childWithId
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|HdfsFileStatusWithId
name|createOriginalObj
parameter_list|(
name|HdfsFileStatusWithId
name|childWithId
parameter_list|,
name|FileStatus
name|child
parameter_list|)
block|{
return|return
name|childWithId
operator|!=
literal|null
condition|?
name|childWithId
else|:
operator|new
name|HdfsFileStatusWithoutId
argument_list|(
name|child
argument_list|)
return|;
block|}
specifier|private
specifier|static
class|class
name|HdfsFileStatusWithoutId
implements|implements
name|HdfsFileStatusWithId
block|{
specifier|private
name|FileStatus
name|fs
decl_stmt|;
specifier|public
name|HdfsFileStatusWithoutId
parameter_list|(
name|FileStatus
name|fs
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|FileStatus
name|getFileStatus
parameter_list|()
block|{
return|return
name|fs
return|;
block|}
annotation|@
name|Override
specifier|public
name|Long
name|getFileId
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Find the original files (non-ACID layout) recursively under the partition directory.    * @param fs the file system    * @param stat the directory to add    * @param original the list of original files    * @throws IOException    */
specifier|private
specifier|static
name|void
name|findOriginals
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|stat
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|boolean
name|useFileIds
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|stat
operator|.
name|isDir
argument_list|()
assert|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|useFileIds
condition|)
block|{
try|try
block|{
name|childrenWithId
operator|=
name|SHIMS
operator|.
name|listLocatedHdfsStatus
argument_list|(
name|fs
argument_list|,
name|stat
operator|.
name|getPath
argument_list|()
argument_list|,
name|hiddenFileFilter
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get files with ID; using regular API"
argument_list|,
name|t
argument_list|)
expr_stmt|;
name|useFileIds
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
name|childrenWithId
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|childrenWithId
control|)
block|{
if|if
condition|(
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|child
operator|.
name|getFileStatus
argument_list|()
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|original
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|SHIMS
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|stat
operator|.
name|getPath
argument_list|()
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
if|if
condition|(
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|child
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|original
operator|.
name|add
argument_list|(
name|createOriginalObj
argument_list|(
literal|null
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
end_class

end_unit

