begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidTxnList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|DataOperationType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TransactionalValidationListener
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcRecordUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateTableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
operator|.
name|HdfsFileStatusWithId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|Ref
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|FileFormatException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OrcAcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|map
operator|.
name|ObjectMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
operator|.
name|COPY_KEYWORD
import|;
end_import

begin_comment
comment|/**  * Utilities that are shared by all of the ACID input and output formats. They  * are used by the compactor and cleaner and thus must be format agnostic.  */
end_comment

begin_class
specifier|public
class|class
name|AcidUtils
block|{
comment|// This key will be put in the conf file when planning an acid operation
specifier|public
specifier|static
specifier|final
name|String
name|CONF_ACID_KEY
init|=
literal|"hive.doing.acid"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BASE_PREFIX
init|=
literal|"base_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|baseFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_PREFIX
init|=
literal|"delta_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELETE_DELTA_PREFIX
init|=
literal|"delete_delta_"
decl_stmt|;
comment|/**    * Acid Streaming Ingest writes multiple transactions to the same file.  It also maintains a    * {@link org.apache.orc.impl.OrcAcidUtils#getSideFile(Path)} side file which stores the length of    * the primary file as of the last commit ({@link OrcRecordUpdater#flush()}).  That is the 'logical length'.    * Once the primary is closed, the side file is deleted (logical length = actual length) but if    * the writer dies or the primary file is being read while its still being written to, anything    * past the logical length should be ignored.    *    * @see org.apache.orc.impl.OrcAcidUtils#DELTA_SIDE_FILE_SUFFIX    * @see org.apache.orc.impl.OrcAcidUtils#getLastFlushLength(FileSystem, Path)    * @see #getLogicalLength(FileSystem, FileStatus)    */
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_SIDE_FILE_SUFFIX
init|=
literal|"_flush_length"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|deltaFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|deleteEventDeltaDirFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BUCKET_PREFIX
init|=
literal|"bucket_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|bucketFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
operator|&&
operator|!
name|path
operator|.
name|getName
argument_list|()
operator|.
name|endsWith
argument_list|(
name|DELTA_SIDE_FILE_SUFFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BUCKET_DIGITS
init|=
literal|"%05d"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|LEGACY_FILE_BUCKET_DIGITS
init|=
literal|"%06d"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_DIGITS
init|=
literal|"%07d"
decl_stmt|;
comment|/**    * 10K statements per tx.  Probably overkill ... since that many delta files    * would not be good for performance    */
specifier|public
specifier|static
specifier|final
name|String
name|STATEMENT_DIGITS
init|=
literal|"%04d"
decl_stmt|;
comment|/**    * This must be in sync with {@link #STATEMENT_DIGITS}    */
specifier|public
specifier|static
specifier|final
name|int
name|MAX_STATEMENTS_PER_TXN
init|=
literal|10000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|BUCKET_DIGIT_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]{5}$"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|LEGACY_BUCKET_DIGIT_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^[0-9]{6}"
argument_list|)
decl_stmt|;
comment|/**    * A write into a non-aicd table produces files like 0000_0 or 0000_0_copy_1    * (Unless via Load Data statement)    */
specifier|public
specifier|static
specifier|final
name|PathFilter
name|originalBucketFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|path
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|matches
argument_list|()
operator|||
name|ORIGINAL_PATTERN_COPY
operator|.
name|matcher
argument_list|(
name|path
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|matches
argument_list|()
return|;
block|}
block|}
decl_stmt|;
specifier|private
name|AcidUtils
parameter_list|()
block|{
comment|// NOT USED
block|}
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AcidUtils
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|BUCKET_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
name|BUCKET_PREFIX
operator|+
literal|"_[0-9]{5}$"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|ORIGINAL_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]+_[0-9]+"
argument_list|)
decl_stmt|;
comment|/**    * @see org.apache.hadoop.hive.ql.exec.Utilities#COPY_KEYWORD    */
specifier|public
specifier|static
specifier|final
name|Pattern
name|ORIGINAL_PATTERN_COPY
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]+_[0-9]+"
operator|+
name|COPY_KEYWORD
operator|+
literal|"[0-9]+"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|hiddenFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
name|name
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|HadoopShims
name|SHIMS
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
comment|/**    * Create the bucket filename in Acid format    * @param subdir the subdirectory for the bucket.    * @param bucket the bucket number    * @return the filename    */
specifier|public
specifier|static
name|Path
name|createBucketFile
parameter_list|(
name|Path
name|subdir
parameter_list|,
name|int
name|bucket
parameter_list|)
block|{
return|return
name|createBucketFile
argument_list|(
name|subdir
argument_list|,
name|bucket
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Create acid or original bucket name    * @param subdir the subdirectory for the bucket.    * @param bucket the bucket number    * @return the filename    */
specifier|private
specifier|static
name|Path
name|createBucketFile
parameter_list|(
name|Path
name|subdir
parameter_list|,
name|int
name|bucket
parameter_list|,
name|boolean
name|isAcidSchema
parameter_list|)
block|{
if|if
condition|(
name|isAcidSchema
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|subdir
argument_list|,
name|BUCKET_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|BUCKET_DIGITS
argument_list|,
name|bucket
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|Path
argument_list|(
name|subdir
argument_list|,
name|String
operator|.
name|format
argument_list|(
name|BUCKET_DIGITS
argument_list|,
name|bucket
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**    * This is format of delta dir name prior to Hive 1.3.x    */
specifier|public
specifier|static
name|String
name|deltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|)
block|{
return|return
name|DELTA_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|min
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|max
argument_list|)
return|;
block|}
comment|/**    * Each write statement in a transaction creates its own delta dir.    * @since 1.3.x    */
specifier|public
specifier|static
name|String
name|deltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
return|return
name|deltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|STATEMENT_DIGITS
argument_list|,
name|statementId
argument_list|)
return|;
block|}
comment|/**    * This is format of delete delta dir name prior to Hive 2.2.x    */
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|String
name|deleteDeltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|)
block|{
return|return
name|DELETE_DELTA_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|min
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|max
argument_list|)
return|;
block|}
comment|/**    * Each write statement in a transaction creates its own delete delta dir,    * when split-update acid operational property is turned on.    * @since 2.2.x    */
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|String
name|deleteDeltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
return|return
name|deleteDeltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|STATEMENT_DIGITS
argument_list|,
name|statementId
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|baseDir
parameter_list|(
name|long
name|txnId
parameter_list|)
block|{
return|return
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|txnId
argument_list|)
return|;
block|}
comment|/**    * Return a base or delta directory string    * according to the given "baseDirRequired".    */
specifier|public
specifier|static
name|String
name|baseOrDeltaSubdir
parameter_list|(
name|boolean
name|baseDirRequired
parameter_list|,
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
if|if
condition|(
operator|!
name|baseDirRequired
condition|)
block|{
return|return
name|deltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
name|statementId
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|baseDir
argument_list|(
name|min
argument_list|)
return|;
block|}
block|}
comment|/**    * Create a filename for a bucket file.    * @param directory the partition directory    * @param options the options for writing the bucket    * @return the filename that should store the bucket    */
specifier|public
specifier|static
name|Path
name|createFilename
parameter_list|(
name|Path
name|directory
parameter_list|,
name|AcidOutputFormat
operator|.
name|Options
name|options
parameter_list|)
block|{
name|String
name|subdir
decl_stmt|;
if|if
condition|(
name|options
operator|.
name|getOldStyle
argument_list|()
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|directory
argument_list|,
name|String
operator|.
name|format
argument_list|(
name|LEGACY_FILE_BUCKET_DIGITS
argument_list|,
name|options
operator|.
name|getBucketId
argument_list|()
argument_list|)
operator|+
literal|"_0"
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|options
operator|.
name|isWritingBase
argument_list|()
condition|)
block|{
name|subdir
operator|=
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|options
operator|.
name|getStatementId
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
comment|//when minor compaction runs, we collapse per statement delta files inside a single
comment|//transaction so we no longer need a statementId in the file name
name|subdir
operator|=
name|options
operator|.
name|isWritingDeleteDelta
argument_list|()
condition|?
name|deleteDeltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|)
else|:
name|deltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|subdir
operator|=
name|options
operator|.
name|isWritingDeleteDelta
argument_list|()
condition|?
name|deleteDeltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getStatementId
argument_list|()
argument_list|)
else|:
name|deltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumTransactionId
argument_list|()
argument_list|,
name|options
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|createBucketFile
argument_list|(
operator|new
name|Path
argument_list|(
name|directory
argument_list|,
name|subdir
argument_list|)
argument_list|,
name|options
operator|.
name|getBucketId
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get the transaction id from a base directory name.    * @param path the base directory name    * @return the maximum transaction id that is included    */
specifier|public
specifier|static
name|long
name|parseBase
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|String
name|filename
init|=
name|path
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|BASE_PREFIX
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|filename
operator|+
literal|" does not start with "
operator|+
name|BASE_PREFIX
argument_list|)
throw|;
block|}
comment|/**    * Parse a bucket filename back into the options that would have created    * the file.    * @param bucketFile the path to a bucket file    * @param conf the configuration    * @return the options used to create that filename    */
specifier|public
specifier|static
name|AcidOutputFormat
operator|.
name|Options
name|parseBaseOrDeltaBucketFilename
parameter_list|(
name|Path
name|bucketFile
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|AcidOutputFormat
operator|.
name|Options
name|result
init|=
operator|new
name|AcidOutputFormat
operator|.
name|Options
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|filename
init|=
name|bucketFile
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
name|int
name|bucket
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|writingBase
argument_list|(
operator|!
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ORIGINAL_PATTERN_COPY
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
comment|//todo: define groups in regex and use parseInt(Matcher.group(2))....
name|int
name|bucket
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|copyNumber
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|filename
operator|.
name|lastIndexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|copyNumber
argument_list|(
name|copyNumber
argument_list|)
operator|.
name|writingBase
argument_list|(
operator|!
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
condition|)
block|{
name|int
name|bucket
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
name|parseBase
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|)
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|writingBase
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
condition|)
block|{
name|ParsedDelta
name|parsedDelta
init|=
name|parsedDelta
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|,
name|DELTA_PREFIX
argument_list|,
name|bucketFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
name|parsedDelta
operator|.
name|minTransaction
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
name|parsedDelta
operator|.
name|maxTransaction
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
name|ParsedDelta
name|parsedDelta
init|=
name|parsedDelta
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|,
name|DELETE_DELTA_PREFIX
argument_list|,
name|bucketFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
name|parsedDelta
operator|.
name|minTransaction
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
name|parsedDelta
operator|.
name|maxTransaction
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|bucket
argument_list|(
operator|-
literal|1
argument_list|)
operator|.
name|minimumTransactionId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumTransactionId
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|//This is used for (full) Acid tables.  InsertOnly use NOT_ACID
specifier|public
enum|enum
name|Operation
implements|implements
name|Serializable
block|{
name|NOT_ACID
block|,
name|INSERT
block|,
name|UPDATE
block|,
name|DELETE
block|;   }
comment|/**    * Logically this should have been defined in Operation but that causes a dependency    * on metastore package from exec jar (from the cluster) which is not allowed.    * This method should only be called from client side where metastore.* classes are present.    * Not following this will not be caught by unit tests since they have all the jar loaded.    */
specifier|public
specifier|static
name|DataOperationType
name|toDataOperationType
parameter_list|(
name|Operation
name|op
parameter_list|)
block|{
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|NOT_ACID
case|:
return|return
name|DataOperationType
operator|.
name|UNSET
return|;
case|case
name|INSERT
case|:
return|return
name|DataOperationType
operator|.
name|INSERT
return|;
case|case
name|UPDATE
case|:
return|return
name|DataOperationType
operator|.
name|UPDATE
return|;
case|case
name|DELETE
case|:
return|return
name|DataOperationType
operator|.
name|DELETE
return|;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected Operation: "
operator|+
name|op
argument_list|)
throw|;
block|}
block|}
specifier|public
enum|enum
name|AcidBaseFileType
block|{
comment|/**    * File w/o Acid meta columns.  This this would be the case for files that were added to the table    * before it was converted to Acid but not yet major compacted.  May also be the the result of    * Load Data statement on an acid table.    */
name|ORIGINAL_BASE
block|,
comment|/**    * File that has Acid metadata columns embedded in it.  Found in base_x/ or delta_x_y/.    */
name|ACID_SCHEMA
block|,   }
comment|/**    * A simple wrapper class that stores the information about a base file and its type.    * Orc splits can be generated on three kinds of base files: an original file (non-acid converted    * files), a regular base file (created by major compaction) or an insert delta (which can be    * treated as a base when split-update is enabled for acid).    */
specifier|public
specifier|static
class|class
name|AcidBaseFileInfo
block|{
specifier|final
specifier|private
name|HdfsFileStatusWithId
name|fileId
decl_stmt|;
specifier|final
specifier|private
name|AcidBaseFileType
name|acidBaseFileType
decl_stmt|;
specifier|public
name|AcidBaseFileInfo
parameter_list|(
name|HdfsFileStatusWithId
name|fileId
parameter_list|,
name|AcidBaseFileType
name|acidBaseFileType
parameter_list|)
block|{
name|this
operator|.
name|fileId
operator|=
name|fileId
expr_stmt|;
name|this
operator|.
name|acidBaseFileType
operator|=
name|acidBaseFileType
expr_stmt|;
block|}
specifier|public
name|boolean
name|isOriginal
parameter_list|()
block|{
return|return
name|this
operator|.
name|acidBaseFileType
operator|==
name|AcidBaseFileType
operator|.
name|ORIGINAL_BASE
return|;
block|}
specifier|public
name|boolean
name|isAcidSchema
parameter_list|()
block|{
return|return
name|this
operator|.
name|acidBaseFileType
operator|==
name|AcidBaseFileType
operator|.
name|ACID_SCHEMA
return|;
block|}
specifier|public
name|HdfsFileStatusWithId
name|getHdfsFileStatusWithId
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileId
return|;
block|}
block|}
comment|/**    * Current syntax for creating full acid transactional tables is any one of following 3 ways:    * create table T (a int, b int) stored as orc tblproperties('transactional'='true').    * create table T (a int, b int) stored as orc tblproperties('transactional'='true',    * 'transactional_properties'='default').    * create table T (a int, b int) stored as orc tblproperties('transactional'='true',    * 'transactional_properties'='split_update').    * These are all identical and create a table capable of insert/update/delete/merge operations    * with full ACID semantics at Snapshot Isolation.  These tables require ORC input/output format.    *    * To create a 1/4 acid, aka Micro Managed table:    * create table T (a int, b int) stored as orc tblproperties('transactional'='true',    * 'transactional_properties'='insert_only').    * These tables only support insert operation (also with full ACID semantics at SI).    *    */
specifier|public
specifier|static
class|class
name|AcidOperationalProperties
block|{
specifier|private
name|int
name|description
init|=
literal|0x00
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|SPLIT_UPDATE_BIT
init|=
literal|0x01
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|SPLIT_UPDATE_STRING
init|=
literal|"split_update"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|HASH_BASED_MERGE_BIT
init|=
literal|0x02
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|HASH_BASED_MERGE_STRING
init|=
literal|"hash_merge"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|INSERT_ONLY_BIT
init|=
literal|0x04
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|INSERT_ONLY_STRING
init|=
literal|"insert_only"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_VALUE_STRING
init|=
name|TransactionalValidationListener
operator|.
name|DEFAULT_TRANSACTIONAL_PROPERTY
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|INSERTONLY_VALUE_STRING
init|=
name|TransactionalValidationListener
operator|.
name|INSERTONLY_TRANSACTIONAL_PROPERTY
decl_stmt|;
specifier|private
name|AcidOperationalProperties
parameter_list|()
block|{     }
comment|/**      * Returns an acidOperationalProperties object that represents default ACID behavior for tables      * that do no explicitly specify/override the default behavior.      * @return the acidOperationalProperties object.      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getDefault
parameter_list|()
block|{
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
name|obj
operator|.
name|setSplitUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|obj
operator|.
name|setHashBasedMerge
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|obj
operator|.
name|setInsertOnly
argument_list|(
literal|false
argument_list|)
expr_stmt|;
return|return
name|obj
return|;
block|}
comment|/**      * Returns an acidOperationalProperties object for tables that uses ACID framework but only      * supports INSERT operation and does not require ORC or bucketing      * @return the acidOperationalProperties object      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getInsertOnly
parameter_list|()
block|{
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
name|obj
operator|.
name|setInsertOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|obj
return|;
block|}
comment|/**      * Returns an acidOperationalProperties object that is represented by an encoded string.      * @param propertiesStr an encoded string representing the acidOperationalProperties.      * @return the acidOperationalProperties object.      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|parseString
parameter_list|(
name|String
name|propertiesStr
parameter_list|)
block|{
if|if
condition|(
name|propertiesStr
operator|==
literal|null
condition|)
block|{
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
if|if
condition|(
name|propertiesStr
operator|.
name|equalsIgnoreCase
argument_list|(
name|DEFAULT_VALUE_STRING
argument_list|)
condition|)
block|{
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
if|if
condition|(
name|propertiesStr
operator|.
name|equalsIgnoreCase
argument_list|(
name|INSERTONLY_VALUE_STRING
argument_list|)
condition|)
block|{
return|return
name|AcidOperationalProperties
operator|.
name|getInsertOnly
argument_list|()
return|;
block|}
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
name|String
index|[]
name|options
init|=
name|propertiesStr
operator|.
name|split
argument_list|(
literal|"\\|"
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|option
range|:
name|options
control|)
block|{
if|if
condition|(
name|option
operator|.
name|trim
argument_list|()
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
continue|continue;
comment|// ignore empty strings
switch|switch
condition|(
name|option
condition|)
block|{
case|case
name|SPLIT_UPDATE_STRING
case|:
name|obj
operator|.
name|setSplitUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
break|break;
case|case
name|HASH_BASED_MERGE_STRING
case|:
name|obj
operator|.
name|setHashBasedMerge
argument_list|(
literal|true
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected value "
operator|+
name|option
operator|+
literal|" for ACID operational properties!"
argument_list|)
throw|;
block|}
block|}
return|return
name|obj
return|;
block|}
comment|/**      * Returns an acidOperationalProperties object that is represented by an encoded 32-bit integer.      * @param properties an encoded 32-bit representing the acidOperationalProperties.      * @return the acidOperationalProperties object.      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|parseInt
parameter_list|(
name|int
name|properties
parameter_list|)
block|{
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|properties
operator|&
name|SPLIT_UPDATE_BIT
operator|)
operator|>
literal|0
condition|)
block|{
name|obj
operator|.
name|setSplitUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|properties
operator|&
name|HASH_BASED_MERGE_BIT
operator|)
operator|>
literal|0
condition|)
block|{
name|obj
operator|.
name|setHashBasedMerge
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|properties
operator|&
name|INSERT_ONLY_BIT
operator|)
operator|>
literal|0
condition|)
block|{
name|obj
operator|.
name|setInsertOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
return|return
name|obj
return|;
block|}
comment|/**      * Sets the split update property for ACID operations based on the boolean argument.      * When split update is turned on, an update ACID event is interpreted as a combination of      * delete event followed by an update event.      * @param isSplitUpdate a boolean property that turns on split update when true.      * @return the acidOperationalProperties object.      */
specifier|public
name|AcidOperationalProperties
name|setSplitUpdate
parameter_list|(
name|boolean
name|isSplitUpdate
parameter_list|)
block|{
name|description
operator|=
operator|(
name|isSplitUpdate
condition|?
operator|(
name|description
operator||
name|SPLIT_UPDATE_BIT
operator|)
else|:
operator|(
name|description
operator|&
operator|~
name|SPLIT_UPDATE_BIT
operator|)
operator|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Sets the hash-based merge property for ACID operations that combines delta files using      * GRACE hash join based approach, when turned on. (Currently unimplemented!)      * @param isHashBasedMerge a boolean property that turns on hash-based merge when true.      * @return the acidOperationalProperties object.      */
specifier|public
name|AcidOperationalProperties
name|setHashBasedMerge
parameter_list|(
name|boolean
name|isHashBasedMerge
parameter_list|)
block|{
name|description
operator|=
operator|(
name|isHashBasedMerge
condition|?
operator|(
name|description
operator||
name|HASH_BASED_MERGE_BIT
operator|)
else|:
operator|(
name|description
operator|&
operator|~
name|HASH_BASED_MERGE_BIT
operator|)
operator|)
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|AcidOperationalProperties
name|setInsertOnly
parameter_list|(
name|boolean
name|isInsertOnly
parameter_list|)
block|{
name|description
operator|=
operator|(
name|isInsertOnly
condition|?
operator|(
name|description
operator||
name|INSERT_ONLY_BIT
operator|)
else|:
operator|(
name|description
operator|&
operator|~
name|INSERT_ONLY_BIT
operator|)
operator|)
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|boolean
name|isSplitUpdate
parameter_list|()
block|{
return|return
operator|(
name|description
operator|&
name|SPLIT_UPDATE_BIT
operator|)
operator|>
literal|0
return|;
block|}
specifier|public
name|boolean
name|isHashBasedMerge
parameter_list|()
block|{
return|return
operator|(
name|description
operator|&
name|HASH_BASED_MERGE_BIT
operator|)
operator|>
literal|0
return|;
block|}
specifier|public
name|boolean
name|isInsertOnly
parameter_list|()
block|{
return|return
operator|(
name|description
operator|&
name|INSERT_ONLY_BIT
operator|)
operator|>
literal|0
return|;
block|}
specifier|public
name|int
name|toInt
parameter_list|()
block|{
return|return
name|description
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|str
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
if|if
condition|(
name|isSplitUpdate
argument_list|()
condition|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|"|"
operator|+
name|SPLIT_UPDATE_STRING
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isHashBasedMerge
argument_list|()
condition|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|"|"
operator|+
name|HASH_BASED_MERGE_STRING
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isInsertOnly
argument_list|()
condition|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|"|"
operator|+
name|INSERT_ONLY_STRING
argument_list|)
expr_stmt|;
block|}
return|return
name|str
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
specifier|public
specifier|static
interface|interface
name|Directory
block|{
comment|/**      * Get the base directory.      * @return the base directory to read      */
name|Path
name|getBaseDirectory
parameter_list|()
function_decl|;
name|boolean
name|isBaseInRawFormat
parameter_list|()
function_decl|;
comment|/**      * Get the list of original files.  Not {@code null}.  Must be sorted.      * @return the list of original files (eg. 000000_0)      */
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|getOriginalFiles
parameter_list|()
function_decl|;
comment|/**      * Get the list of base and delta directories that are valid and not      * obsolete.  Not {@code null}.  List must be sorted in a specific way.      * See {@link org.apache.hadoop.hive.ql.io.AcidUtils.ParsedDelta#compareTo(org.apache.hadoop.hive.ql.io.AcidUtils.ParsedDelta)}      * for details.      * @return the minimal list of current directories      */
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|getCurrentDirectories
parameter_list|()
function_decl|;
comment|/**      * Get the list of obsolete directories. After filtering out bases and      * deltas that are not selected by the valid transaction list, return the      * list of original files, bases, and deltas that have been replaced by      * more up to date ones.  Not {@code null}.      */
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getObsolete
parameter_list|()
function_decl|;
comment|/**      * Get the list of directories that has nothing but aborted transactions.      * @return the list of aborted directories      */
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getAbortedDirectories
parameter_list|()
function_decl|;
block|}
comment|/**    * Immutable    */
specifier|public
specifier|static
specifier|final
class|class
name|ParsedDelta
implements|implements
name|Comparable
argument_list|<
name|ParsedDelta
argument_list|>
block|{
specifier|private
specifier|final
name|long
name|minTransaction
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxTransaction
decl_stmt|;
specifier|private
specifier|final
name|FileStatus
name|path
decl_stmt|;
comment|//-1 is for internal (getAcidState()) purposes and means the delta dir
comment|//had no statement ID
specifier|private
specifier|final
name|int
name|statementId
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isDeleteDelta
decl_stmt|;
comment|// records whether delta dir is of type 'delete_delta_x_y...'
specifier|private
specifier|final
name|boolean
name|isRawFormat
decl_stmt|;
comment|/**      * for pre 1.3.x delta files      */
specifier|private
name|ParsedDelta
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|FileStatus
name|path
parameter_list|,
name|boolean
name|isDeleteDelta
parameter_list|,
name|boolean
name|isRawFormat
parameter_list|)
block|{
name|this
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
name|path
argument_list|,
operator|-
literal|1
argument_list|,
name|isDeleteDelta
argument_list|,
name|isRawFormat
argument_list|)
expr_stmt|;
block|}
specifier|private
name|ParsedDelta
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|FileStatus
name|path
parameter_list|,
name|int
name|statementId
parameter_list|,
name|boolean
name|isDeleteDelta
parameter_list|,
name|boolean
name|isRawFormat
parameter_list|)
block|{
name|this
operator|.
name|minTransaction
operator|=
name|min
expr_stmt|;
name|this
operator|.
name|maxTransaction
operator|=
name|max
expr_stmt|;
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
name|this
operator|.
name|statementId
operator|=
name|statementId
expr_stmt|;
name|this
operator|.
name|isDeleteDelta
operator|=
name|isDeleteDelta
expr_stmt|;
name|this
operator|.
name|isRawFormat
operator|=
name|isRawFormat
expr_stmt|;
assert|assert
operator|!
name|isDeleteDelta
operator|||
operator|!
name|isRawFormat
operator|:
literal|" deleteDelta should not be raw format"
assert|;
block|}
specifier|public
name|long
name|getMinTransaction
parameter_list|()
block|{
return|return
name|minTransaction
return|;
block|}
specifier|public
name|long
name|getMaxTransaction
parameter_list|()
block|{
return|return
name|maxTransaction
return|;
block|}
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|path
operator|.
name|getPath
argument_list|()
return|;
block|}
specifier|public
name|int
name|getStatementId
parameter_list|()
block|{
return|return
name|statementId
operator|==
operator|-
literal|1
condition|?
literal|0
else|:
name|statementId
return|;
block|}
specifier|public
name|boolean
name|isDeleteDelta
parameter_list|()
block|{
return|return
name|isDeleteDelta
return|;
block|}
comment|/**      * Files w/o Acid meta columns embedded in the file. See {@link AcidBaseFileType#ORIGINAL_BASE}      */
specifier|public
name|boolean
name|isRawFormat
parameter_list|()
block|{
return|return
name|isRawFormat
return|;
block|}
comment|/**      * Compactions (Major/Minor) merge deltas/bases but delete of old files      * happens in a different process; thus it's possible to have bases/deltas with      * overlapping txnId boundaries.  The sort order helps figure out the "best" set of files      * to use to get data.      * This sorts "wider" delta before "narrower" i.e. delta_5_20 sorts before delta_5_10 (and delta_11_20)      */
annotation|@
name|Override
specifier|public
name|int
name|compareTo
parameter_list|(
name|ParsedDelta
name|parsedDelta
parameter_list|)
block|{
if|if
condition|(
name|minTransaction
operator|!=
name|parsedDelta
operator|.
name|minTransaction
condition|)
block|{
if|if
condition|(
name|minTransaction
operator|<
name|parsedDelta
operator|.
name|minTransaction
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
literal|1
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|maxTransaction
operator|!=
name|parsedDelta
operator|.
name|maxTransaction
condition|)
block|{
if|if
condition|(
name|maxTransaction
operator|<
name|parsedDelta
operator|.
name|maxTransaction
condition|)
block|{
return|return
literal|1
return|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|statementId
operator|!=
name|parsedDelta
operator|.
name|statementId
condition|)
block|{
comment|/**          * We want deltas after minor compaction (w/o statementId) to sort          * earlier so that getAcidState() considers compacted files (into larger ones) obsolete          * Before compaction, include deltas with all statementIds for a given txnId          * in a {@link org.apache.hadoop.hive.ql.io.AcidUtils.Directory}          */
if|if
condition|(
name|statementId
operator|<
name|parsedDelta
operator|.
name|statementId
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
literal|1
return|;
block|}
block|}
else|else
block|{
return|return
name|path
operator|.
name|compareTo
argument_list|(
name|parsedDelta
operator|.
name|path
argument_list|)
return|;
block|}
block|}
block|}
comment|/**    * Convert a list of deltas to a list of delta directories.    * @param deltas the list of deltas out of a Directory object.    * @return a list of delta directory paths that need to be read    */
specifier|public
specifier|static
name|Path
index|[]
name|getPaths
parameter_list|(
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|)
block|{
name|Path
index|[]
name|result
init|=
operator|new
name|Path
index|[
name|deltas
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|result
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
name|deltas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getPath
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * Convert the list of deltas into an equivalent list of begin/end    * transaction id pairs.  Assumes {@code deltas} is sorted.    * @param deltas    * @return the list of transaction ids to serialize    */
specifier|public
specifier|static
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|serializeDeltas
parameter_list|(
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|)
block|{
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|last
init|=
literal|null
decl_stmt|;
for|for
control|(
name|ParsedDelta
name|parsedDelta
range|:
name|deltas
control|)
block|{
if|if
condition|(
name|last
operator|!=
literal|null
operator|&&
name|last
operator|.
name|getMinTxnId
argument_list|()
operator|==
name|parsedDelta
operator|.
name|getMinTransaction
argument_list|()
operator|&&
name|last
operator|.
name|getMaxTxnId
argument_list|()
operator|==
name|parsedDelta
operator|.
name|getMaxTransaction
argument_list|()
condition|)
block|{
name|last
operator|.
name|getStmtIds
argument_list|()
operator|.
name|add
argument_list|(
name|parsedDelta
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|last
operator|=
operator|new
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|(
name|parsedDelta
operator|.
name|getMinTransaction
argument_list|()
argument_list|,
name|parsedDelta
operator|.
name|getMaxTransaction
argument_list|()
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|last
argument_list|)
expr_stmt|;
if|if
condition|(
name|parsedDelta
operator|.
name|statementId
operator|>=
literal|0
condition|)
block|{
name|last
operator|.
name|getStmtIds
argument_list|()
operator|.
name|add
argument_list|(
name|parsedDelta
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Convert the list of begin/end transaction id pairs to a list of delete delta    * directories.  Note that there may be multiple delete_delta files for the exact same txn range starting    * with 2.2.x;    * see {@link org.apache.hadoop.hive.ql.io.AcidUtils#deltaSubdir(long, long, int)}    * @param root the root directory    * @param deleteDeltas list of begin/end transaction id pairs    * @return the list of delta paths    */
specifier|public
specifier|static
name|Path
index|[]
name|deserializeDeleteDeltas
parameter_list|(
name|Path
name|root
parameter_list|,
specifier|final
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|deleteDeltas
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|deleteDeltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|dmd
range|:
name|deleteDeltas
control|)
block|{
if|if
condition|(
name|dmd
operator|.
name|getStmtIds
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Path
argument_list|(
name|root
argument_list|,
name|deleteDeltaSubdir
argument_list|(
name|dmd
operator|.
name|getMinTxnId
argument_list|()
argument_list|,
name|dmd
operator|.
name|getMaxTxnId
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
for|for
control|(
name|Integer
name|stmtId
range|:
name|dmd
operator|.
name|getStmtIds
argument_list|()
control|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Path
argument_list|(
name|root
argument_list|,
name|deleteDeltaSubdir
argument_list|(
name|dmd
operator|.
name|getMinTxnId
argument_list|()
argument_list|,
name|dmd
operator|.
name|getMaxTxnId
argument_list|()
argument_list|,
name|stmtId
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|results
operator|.
name|toArray
argument_list|(
operator|new
name|Path
index|[
name|results
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|ParsedDelta
name|parsedDelta
parameter_list|(
name|Path
name|deltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|deltaDirName
init|=
name|deltaDir
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|deltaDirName
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
return|return
name|parsedDelta
argument_list|(
name|deltaDir
argument_list|,
name|DELETE_DELTA_PREFIX
argument_list|,
name|fs
argument_list|)
return|;
block|}
return|return
name|parsedDelta
argument_list|(
name|deltaDir
argument_list|,
name|DELTA_PREFIX
argument_list|,
name|fs
argument_list|)
return|;
comment|// default prefix is delta_prefix
block|}
specifier|private
specifier|static
name|ParsedDelta
name|parseDelta
parameter_list|(
name|FileStatus
name|path
parameter_list|,
name|String
name|deltaPrefix
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|ParsedDelta
name|p
init|=
name|parsedDelta
argument_list|(
name|path
operator|.
name|getPath
argument_list|()
argument_list|,
name|deltaPrefix
argument_list|,
name|fs
argument_list|)
decl_stmt|;
name|boolean
name|isDeleteDelta
init|=
name|deltaPrefix
operator|.
name|equals
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDelta
argument_list|(
name|p
operator|.
name|getMinTransaction
argument_list|()
argument_list|,
name|p
operator|.
name|getMaxTransaction
argument_list|()
argument_list|,
name|path
argument_list|,
name|p
operator|.
name|statementId
argument_list|,
name|isDeleteDelta
argument_list|,
name|p
operator|.
name|isRawFormat
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|ParsedDelta
name|parsedDelta
parameter_list|(
name|Path
name|deltaDir
parameter_list|,
name|String
name|deltaPrefix
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|filename
init|=
name|deltaDir
operator|.
name|getName
argument_list|()
decl_stmt|;
name|boolean
name|isDeleteDelta
init|=
name|deltaPrefix
operator|.
name|equals
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|deltaPrefix
argument_list|)
condition|)
block|{
comment|//small optimization - delete delta can't be in raw format
name|boolean
name|isRawFormat
init|=
operator|!
name|isDeleteDelta
operator|&&
name|MetaDataFile
operator|.
name|isRawFormat
argument_list|(
name|deltaDir
argument_list|,
name|fs
argument_list|)
decl_stmt|;
name|String
name|rest
init|=
name|filename
operator|.
name|substring
argument_list|(
name|deltaPrefix
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|split
init|=
name|rest
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
decl_stmt|;
name|int
name|split2
init|=
name|rest
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|,
name|split
operator|+
literal|1
argument_list|)
decl_stmt|;
comment|//may be -1 if no statementId
name|long
name|min
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|split
argument_list|)
argument_list|)
decl_stmt|;
name|long
name|max
init|=
name|split2
operator|==
operator|-
literal|1
condition|?
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split
operator|+
literal|1
argument_list|)
argument_list|)
else|:
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split
operator|+
literal|1
argument_list|,
name|split2
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|split2
operator|==
operator|-
literal|1
condition|)
block|{
return|return
operator|new
name|ParsedDelta
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
literal|null
argument_list|,
name|isDeleteDelta
argument_list|,
name|isRawFormat
argument_list|)
return|;
block|}
name|int
name|statementId
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split2
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDelta
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
literal|null
argument_list|,
name|statementId
argument_list|,
name|isDeleteDelta
argument_list|,
name|isRawFormat
argument_list|)
return|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|deltaDir
operator|+
literal|" does not start with "
operator|+
name|deltaPrefix
argument_list|)
throw|;
block|}
comment|/**    * Is the given directory in ACID format?    * @param directory the partition directory to check    * @param conf the query configuration    * @return true, if it is an ACID directory    * @throws IOException    */
specifier|public
specifier|static
name|boolean
name|isAcid
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|directory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|directory
argument_list|)
control|)
block|{
name|String
name|filename
init|=
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|||
name|filename
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|||
name|filename
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
if|if
condition|(
name|file
operator|.
name|isDir
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
name|directory
argument_list|,
name|conf
argument_list|,
name|txnList
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/** State class for getChildState; cannot modify 2 things in a method. */
specifier|private
specifier|static
class|class
name|TxnBase
block|{
specifier|private
name|FileStatus
name|status
decl_stmt|;
specifier|private
name|long
name|txn
init|=
literal|0
decl_stmt|;
specifier|private
name|long
name|oldestBaseTxnId
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
specifier|private
name|Path
name|oldestBase
init|=
literal|null
decl_stmt|;
block|}
comment|/**    * Get the ACID state of the given directory. It finds the minimal set of    * base and diff directories. Note that because major compactions don't    * preserve the history, we can't use a base directory that includes a    * transaction id that we must exclude.    * @param directory the partition directory to analyze    * @param conf the configuration    * @param txnList the list of transactions that we are reading    * @return the state of the directory    * @throws IOException    */
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|,
name|boolean
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
name|directory
argument_list|,
name|conf
argument_list|,
name|txnList
argument_list|,
name|Ref
operator|.
name|from
argument_list|(
name|useFileIds
argument_list|)
argument_list|,
name|ignoreEmptyFiles
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|,
name|Ref
argument_list|<
name|Boolean
argument_list|>
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|directory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|// The following 'deltas' includes all kinds of delta files including insert& delete deltas.
specifier|final
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
init|=
operator|new
name|ArrayList
argument_list|<
name|ParsedDelta
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|working
init|=
operator|new
name|ArrayList
argument_list|<
name|ParsedDelta
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|originalDirectories
init|=
operator|new
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|FileStatus
argument_list|>
name|obsolete
init|=
operator|new
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|FileStatus
argument_list|>
name|abortedDirectories
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
literal|null
decl_stmt|;
name|Boolean
name|val
init|=
name|useFileIds
operator|.
name|value
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
name|val
condition|)
block|{
try|try
block|{
name|childrenWithId
operator|=
name|SHIMS
operator|.
name|listLocatedHdfsStatus
argument_list|(
name|fs
argument_list|,
name|directory
argument_list|,
name|hiddenFileFilter
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|useFileIds
operator|.
name|value
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get files with ID; using regular API: "
operator|+
name|t
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|&&
name|t
operator|instanceof
name|UnsupportedOperationException
condition|)
block|{
name|useFileIds
operator|.
name|value
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
name|TxnBase
name|bestBase
init|=
operator|new
name|TxnBase
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|childrenWithId
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|childrenWithId
control|)
block|{
name|getChildState
argument_list|(
name|child
operator|.
name|getFileStatus
argument_list|()
argument_list|,
name|child
argument_list|,
name|txnList
argument_list|,
name|working
argument_list|,
name|originalDirectories
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|bestBase
argument_list|,
name|ignoreEmptyFiles
argument_list|,
name|abortedDirectories
argument_list|,
name|tblproperties
argument_list|,
name|fs
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|HdfsUtils
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|directory
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|getChildState
argument_list|(
name|child
argument_list|,
literal|null
argument_list|,
name|txnList
argument_list|,
name|working
argument_list|,
name|originalDirectories
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|bestBase
argument_list|,
name|ignoreEmptyFiles
argument_list|,
name|abortedDirectories
argument_list|,
name|tblproperties
argument_list|,
name|fs
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we have a base, the original files are obsolete.
if|if
condition|(
name|bestBase
operator|.
name|status
operator|!=
literal|null
condition|)
block|{
comment|// Add original files to obsolete list if any
for|for
control|(
name|HdfsFileStatusWithId
name|fswid
range|:
name|original
control|)
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|fswid
operator|.
name|getFileStatus
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Add original direcotries to obsolete list if any
name|obsolete
operator|.
name|addAll
argument_list|(
name|originalDirectories
argument_list|)
expr_stmt|;
comment|// remove the entries so we don't get confused later and think we should
comment|// use them.
name|original
operator|.
name|clear
argument_list|()
expr_stmt|;
name|originalDirectories
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Okay, we're going to need these originals.  Recurse through them and figure out what we
comment|// really need.
for|for
control|(
name|FileStatus
name|origDir
range|:
name|originalDirectories
control|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|origDir
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|)
expr_stmt|;
block|}
block|}
name|Collections
operator|.
name|sort
argument_list|(
name|working
argument_list|)
expr_stmt|;
comment|//so now, 'working' should be sorted like delta_5_20 delta_5_10 delta_11_20 delta_51_60 for example
comment|//and we want to end up with the best set containing all relevant data: delta_5_20 delta_51_60,
comment|//subject to list of 'exceptions' in 'txnList' (not show in above example).
name|long
name|current
init|=
name|bestBase
operator|.
name|txn
decl_stmt|;
name|int
name|lastStmtId
init|=
operator|-
literal|1
decl_stmt|;
name|ParsedDelta
name|prev
init|=
literal|null
decl_stmt|;
for|for
control|(
name|ParsedDelta
name|next
range|:
name|working
control|)
block|{
if|if
condition|(
name|next
operator|.
name|maxTransaction
operator|>
name|current
condition|)
block|{
comment|// are any of the new transactions ones that we care about?
if|if
condition|(
name|txnList
operator|.
name|isTxnRangeValid
argument_list|(
name|current
operator|+
literal|1
argument_list|,
name|next
operator|.
name|maxTransaction
argument_list|)
operator|!=
name|ValidTxnList
operator|.
name|RangeResponse
operator|.
name|NONE
condition|)
block|{
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|current
operator|=
name|next
operator|.
name|maxTransaction
expr_stmt|;
name|lastStmtId
operator|=
name|next
operator|.
name|statementId
expr_stmt|;
name|prev
operator|=
name|next
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|next
operator|.
name|maxTransaction
operator|==
name|current
operator|&&
name|lastStmtId
operator|>=
literal|0
condition|)
block|{
comment|//make sure to get all deltas within a single transaction;  multi-statement txn
comment|//generate multiple delta files with the same txnId range
comment|//of course, if maxTransaction has already been minor compacted, all per statement deltas are obsolete
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|prev
operator|=
name|next
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|prev
operator|!=
literal|null
operator|&&
name|next
operator|.
name|maxTransaction
operator|==
name|prev
operator|.
name|maxTransaction
operator|&&
name|next
operator|.
name|minTransaction
operator|==
name|prev
operator|.
name|minTransaction
operator|&&
name|next
operator|.
name|statementId
operator|==
name|prev
operator|.
name|statementId
condition|)
block|{
comment|// The 'next' parsedDelta may have everything equal to the 'prev' parsedDelta, except
comment|// the path. This may happen when we have split update and we have two types of delta
comment|// directories- 'delta_x_y' and 'delete_delta_x_y' for the SAME txn range.
comment|// Also note that any delete_deltas in between a given delta_x_y range would be made
comment|// obsolete. For example, a delta_30_50 would make delete_delta_40_40 obsolete.
comment|// This is valid because minor compaction always compacts the normal deltas and the delete
comment|// deltas for the same range. That is, if we had 3 directories, delta_30_30,
comment|// delete_delta_40_40 and delta_50_50, then running minor compaction would produce
comment|// delta_30_50 and delete_delta_30_50.
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|prev
operator|=
name|next
expr_stmt|;
block|}
else|else
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|next
operator|.
name|path
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|bestBase
operator|.
name|oldestBase
operator|!=
literal|null
operator|&&
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|)
block|{
comment|/**        * If here, it means there was a base_x (> 1 perhaps) but none were suitable for given        * {@link txnList}.  Note that 'original' files are logically a base_Long.MIN_VALUE and thus        * cannot have any data for an open txn.  We could check {@link deltas} has files to cover        * [1,n] w/o gaps but this would almost never happen...*/
name|long
index|[]
name|exceptions
init|=
name|txnList
operator|.
name|getInvalidTransactions
argument_list|()
decl_stmt|;
name|String
name|minOpenTxn
init|=
name|exceptions
operator|!=
literal|null
operator|&&
name|exceptions
operator|.
name|length
operator|>
literal|0
condition|?
name|Long
operator|.
name|toString
argument_list|(
name|exceptions
index|[
literal|0
index|]
argument_list|)
else|:
literal|"x"
decl_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|ACID_NOT_ENOUGH_HISTORY
operator|.
name|format
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|txnList
operator|.
name|getHighWatermark
argument_list|()
argument_list|)
argument_list|,
name|minOpenTxn
argument_list|,
name|bestBase
operator|.
name|oldestBase
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|base
init|=
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|?
literal|null
else|:
name|bestBase
operator|.
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"in directory "
operator|+
name|directory
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" base = "
operator|+
name|base
operator|+
literal|" deltas = "
operator|+
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|/**      * If this sort order is changed and there are tables that have been converted to transactional      * and have had any update/delete/merge operations performed but not yet MAJOR compacted, it      * may result in data loss since it may change how      * {@link org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.OriginalReaderPair} assigns       * {@link RecordIdentifier#rowId} for read (that have happened) and compaction (yet to happen).      */
name|Collections
operator|.
name|sort
argument_list|(
name|original
argument_list|,
parameter_list|(
name|HdfsFileStatusWithId
name|o1
parameter_list|,
name|HdfsFileStatusWithId
name|o2
parameter_list|)
lambda|->
block|{
comment|//this does "Path.uri.compareTo(that.uri)"
return|return
name|o1
operator|.
name|getFileStatus
argument_list|()
operator|.
name|compareTo
argument_list|(
name|o2
operator|.
name|getFileStatus
argument_list|()
argument_list|)
return|;
block|}
argument_list|)
expr_stmt|;
specifier|final
name|boolean
name|isBaseInRawFormat
init|=
name|base
operator|!=
literal|null
operator|&&
name|MetaDataFile
operator|.
name|isRawFormat
argument_list|(
name|base
argument_list|,
name|fs
argument_list|)
decl_stmt|;
return|return
operator|new
name|Directory
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Path
name|getBaseDirectory
parameter_list|()
block|{
return|return
name|base
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isBaseInRawFormat
parameter_list|()
block|{
return|return
name|isBaseInRawFormat
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|getOriginalFiles
parameter_list|()
block|{
return|return
name|original
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|getCurrentDirectories
parameter_list|()
block|{
return|return
name|deltas
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getObsolete
parameter_list|()
block|{
return|return
name|obsolete
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getAbortedDirectories
parameter_list|()
block|{
return|return
name|abortedDirectories
return|;
block|}
block|}
return|;
block|}
comment|/**    * We can only use a 'base' if it doesn't have an open txn (from specific reader's point of view)    * A 'base' with open txn in its range doesn't have 'enough history' info to produce a correct    * snapshot for this reader.    * Note that such base is NOT obsolete.  Obsolete files are those that are "covered" by other    * files within the snapshot.    */
specifier|private
specifier|static
name|boolean
name|isValidBase
parameter_list|(
name|long
name|baseTxnId
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|)
block|{
if|if
condition|(
name|baseTxnId
operator|==
name|Long
operator|.
name|MIN_VALUE
condition|)
block|{
comment|//such base is created by 1st compaction in case of non-acid to acid table conversion
comment|//By definition there are no open txns with id< 1.
return|return
literal|true
return|;
block|}
return|return
name|txnList
operator|.
name|isValidBase
argument_list|(
name|baseTxnId
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|void
name|getChildState
parameter_list|(
name|FileStatus
name|child
parameter_list|,
name|HdfsFileStatusWithId
name|childWithId
parameter_list|,
name|ValidTxnList
name|txnList
parameter_list|,
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|working
parameter_list|,
name|List
argument_list|<
name|FileStatus
argument_list|>
name|originalDirectories
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|List
argument_list|<
name|FileStatus
argument_list|>
name|obsolete
parameter_list|,
name|TxnBase
name|bestBase
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|,
name|List
argument_list|<
name|FileStatus
argument_list|>
name|aborted
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|child
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|String
name|fn
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|fn
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|&&
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|long
name|txn
init|=
name|parseBase
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|bestBase
operator|.
name|oldestBaseTxnId
operator|>
name|txn
condition|)
block|{
comment|//keep track for error reporting
name|bestBase
operator|.
name|oldestBase
operator|=
name|p
expr_stmt|;
name|bestBase
operator|.
name|oldestBaseTxnId
operator|=
name|txn
expr_stmt|;
block|}
if|if
condition|(
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|isValidBase
argument_list|(
name|txn
argument_list|,
name|txnList
argument_list|)
condition|)
block|{
name|bestBase
operator|.
name|status
operator|=
name|child
expr_stmt|;
name|bestBase
operator|.
name|txn
operator|=
name|txn
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|bestBase
operator|.
name|txn
operator|<
name|txn
condition|)
block|{
if|if
condition|(
name|isValidBase
argument_list|(
name|txn
argument_list|,
name|txnList
argument_list|)
condition|)
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|bestBase
operator|.
name|status
argument_list|)
expr_stmt|;
name|bestBase
operator|.
name|status
operator|=
name|child
expr_stmt|;
name|bestBase
operator|.
name|txn
operator|=
name|txn
expr_stmt|;
block|}
block|}
else|else
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|(
name|fn
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|||
name|fn
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
operator|)
operator|&&
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|String
name|deltaPrefix
init|=
operator|(
name|fn
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|)
condition|?
name|DELTA_PREFIX
else|:
name|DELETE_DELTA_PREFIX
decl_stmt|;
name|ParsedDelta
name|delta
init|=
name|parseDelta
argument_list|(
name|child
argument_list|,
name|deltaPrefix
argument_list|,
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblproperties
operator|!=
literal|null
operator|&&
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|tblproperties
argument_list|)
operator|&&
name|ValidTxnList
operator|.
name|RangeResponse
operator|.
name|ALL
operator|==
name|txnList
operator|.
name|isTxnRangeAborted
argument_list|(
name|delta
operator|.
name|minTransaction
argument_list|,
name|delta
operator|.
name|maxTransaction
argument_list|)
condition|)
block|{
name|aborted
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|txnList
operator|.
name|isTxnRangeValid
argument_list|(
name|delta
operator|.
name|minTransaction
argument_list|,
name|delta
operator|.
name|maxTransaction
argument_list|)
operator|!=
name|ValidTxnList
operator|.
name|RangeResponse
operator|.
name|NONE
condition|)
block|{
name|working
operator|.
name|add
argument_list|(
name|delta
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
comment|// This is just the directory.  We need to recurse and find the actual files.  But don't
comment|// do this until we have determined there is no base.  This saves time.  Plus,
comment|// it is possible that the cleaner is running and removing these original files,
comment|// in which case recursing through them could cause us to get an error.
name|originalDirectories
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|ignoreEmptyFiles
operator|||
name|child
operator|.
name|getLen
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|original
operator|.
name|add
argument_list|(
name|createOriginalObj
argument_list|(
name|childWithId
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|HdfsFileStatusWithId
name|createOriginalObj
parameter_list|(
name|HdfsFileStatusWithId
name|childWithId
parameter_list|,
name|FileStatus
name|child
parameter_list|)
block|{
return|return
name|childWithId
operator|!=
literal|null
condition|?
name|childWithId
else|:
operator|new
name|HdfsFileStatusWithoutId
argument_list|(
name|child
argument_list|)
return|;
block|}
specifier|private
specifier|static
class|class
name|HdfsFileStatusWithoutId
implements|implements
name|HdfsFileStatusWithId
block|{
specifier|private
specifier|final
name|FileStatus
name|fs
decl_stmt|;
specifier|public
name|HdfsFileStatusWithoutId
parameter_list|(
name|FileStatus
name|fs
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|FileStatus
name|getFileStatus
parameter_list|()
block|{
return|return
name|fs
return|;
block|}
annotation|@
name|Override
specifier|public
name|Long
name|getFileId
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Find the original files (non-ACID layout) recursively under the partition directory.    * @param fs the file system    * @param stat the directory to add    * @param original the list of original files    * @throws IOException    */
specifier|private
specifier|static
name|void
name|findOriginals
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|stat
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|Ref
argument_list|<
name|Boolean
argument_list|>
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|stat
operator|.
name|isDir
argument_list|()
assert|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
literal|null
decl_stmt|;
name|Boolean
name|val
init|=
name|useFileIds
operator|.
name|value
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
name|val
condition|)
block|{
try|try
block|{
name|childrenWithId
operator|=
name|SHIMS
operator|.
name|listLocatedHdfsStatus
argument_list|(
name|fs
argument_list|,
name|stat
operator|.
name|getPath
argument_list|()
argument_list|,
name|hiddenFileFilter
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|useFileIds
operator|.
name|value
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get files with ID; using regular API: "
operator|+
name|t
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|&&
name|t
operator|instanceof
name|UnsupportedOperationException
condition|)
block|{
name|useFileIds
operator|.
name|value
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|childrenWithId
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|childrenWithId
control|)
block|{
if|if
condition|(
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|child
operator|.
name|getFileStatus
argument_list|()
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|ignoreEmptyFiles
operator|||
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|original
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|HdfsUtils
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|stat
operator|.
name|getPath
argument_list|()
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
if|if
condition|(
name|child
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|child
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|ignoreEmptyFiles
operator|||
name|child
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|original
operator|.
name|add
argument_list|(
name|createOriginalObj
argument_list|(
literal|null
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
specifier|public
specifier|static
name|boolean
name|isTablePropertyTransactional
parameter_list|(
name|Properties
name|props
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|props
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
name|resultStr
operator|=
name|props
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|resultStr
operator|!=
literal|null
operator|&&
name|resultStr
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTablePropertyTransactional
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|parameters
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
name|resultStr
operator|=
name|parameters
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|resultStr
operator|!=
literal|null
operator|&&
name|resultStr
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTablePropertyTransactional
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|conf
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
name|resultStr
operator|=
name|conf
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|resultStr
operator|!=
literal|null
operator|&&
name|resultStr
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
comment|/**    * Means it's a full acid table    */
specifier|public
specifier|static
name|void
name|setAcidTableScan
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|boolean
name|isAcidTable
parameter_list|)
block|{
name|parameters
operator|.
name|put
argument_list|(
name|ConfVars
operator|.
name|HIVE_ACID_TABLE_SCAN
operator|.
name|varname
argument_list|,
name|Boolean
operator|.
name|toString
argument_list|(
name|isAcidTable
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Means it's a full acid table    */
specifier|public
specifier|static
name|void
name|setAcidTableScan
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|isFullAcidTable
parameter_list|)
block|{
name|HiveConf
operator|.
name|setBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_ACID_TABLE_SCAN
argument_list|,
name|isFullAcidTable
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param p - not null    */
specifier|public
specifier|static
name|boolean
name|isDeleteDelta
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
return|return
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
return|;
block|}
comment|/**    * Should produce the same result as    * {@link org.apache.hadoop.hive.metastore.txn.TxnUtils#isTransactionalTable(org.apache.hadoop.hive.metastore.api.Table)}    */
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|String
name|tableIsTransactional
init|=
name|table
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableIsTransactional
operator|==
literal|null
condition|)
block|{
name|tableIsTransactional
operator|=
name|table
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|tableIsTransactional
operator|!=
literal|null
operator|&&
name|tableIsTransactional
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|CreateTableDesc
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
operator|||
name|table
operator|.
name|getTblProps
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|String
name|tableIsTransactional
init|=
name|table
operator|.
name|getTblProps
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableIsTransactional
operator|==
literal|null
condition|)
block|{
name|tableIsTransactional
operator|=
name|table
operator|.
name|getTblProps
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|tableIsTransactional
operator|!=
literal|null
operator|&&
name|tableIsTransactional
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
comment|/**    * Should produce the same result as    * {@link org.apache.hadoop.hive.metastore.txn.TxnUtils#isAcidTable(org.apache.hadoop.hive.metastore.api.Table)}    */
specifier|public
specifier|static
name|boolean
name|isAcidTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
return|return
name|isAcidTable
argument_list|(
name|table
operator|==
literal|null
condition|?
literal|null
else|:
name|table
operator|.
name|getTTable
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Should produce the same result as    * {@link org.apache.hadoop.hive.metastore.txn.TxnUtils#isAcidTable(org.apache.hadoop.hive.metastore.api.Table)}    */
specifier|public
specifier|static
name|boolean
name|isAcidTable
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|table
operator|!=
literal|null
operator|&&
name|table
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
operator|&&
name|isTablePropertyTransactional
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
operator|&&
operator|!
name|isInsertOnlyTable
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isAcidTable
parameter_list|(
name|CreateTableDesc
name|td
parameter_list|)
block|{
if|if
condition|(
name|td
operator|==
literal|null
operator|||
name|td
operator|.
name|getTblProps
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|String
name|tableIsTransactional
init|=
name|td
operator|.
name|getTblProps
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableIsTransactional
operator|==
literal|null
condition|)
block|{
name|tableIsTransactional
operator|=
name|td
operator|.
name|getTblProps
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|tableIsTransactional
operator|!=
literal|null
operator|&&
name|tableIsTransactional
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
operator|&&
operator|!
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|td
operator|.
name|getTblProps
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Sets the acidOperationalProperties in the configuration object argument.    * @param conf Mutable configuration object    * @param properties An acidOperationalProperties object to initialize from.    */
specifier|public
specifier|static
name|void
name|setAcidOperationalProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|AcidOperationalProperties
name|properties
parameter_list|)
block|{
if|if
condition|(
name|properties
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
argument_list|,
name|properties
operator|.
name|toInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Sets the acidOperationalProperties in the map object argument.    * @param parameters Mutable map object    * @param properties An acidOperationalProperties object to initialize from.    */
specifier|public
specifier|static
name|void
name|setAcidOperationalProperties
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|AcidOperationalProperties
name|properties
parameter_list|)
block|{
if|if
condition|(
name|properties
operator|!=
literal|null
condition|)
block|{
name|parameters
operator|.
name|put
argument_list|(
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
operator|.
name|varname
argument_list|,
name|properties
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Returns the acidOperationalProperties for a given table.    * @param table A table object    * @return the acidOperationalProperties object for the corresponding table.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
name|String
name|transactionalProperties
init|=
name|table
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactionalProperties
operator|==
literal|null
condition|)
block|{
comment|// If the table does not define any transactional properties, we return a default type.
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
return|return
name|AcidOperationalProperties
operator|.
name|parseString
argument_list|(
name|transactionalProperties
argument_list|)
return|;
block|}
comment|/**    * Returns the acidOperationalProperties for a given configuration.    * @param conf A configuration object    * @return the acidOperationalProperties object for the corresponding configuration.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
comment|// If the conf does not define any transactional properties, the parseInt() should receive
comment|// a value of 1, which will set AcidOperationalProperties to a default type and return that.
return|return
name|AcidOperationalProperties
operator|.
name|parseInt
argument_list|(
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns the acidOperationalProperties for a given set of properties.    * @param props A properties object    * @return the acidOperationalProperties object for the corresponding properties.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Properties
name|props
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|props
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
comment|// If the properties does not define any transactional properties, we return a default type.
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
return|return
name|AcidOperationalProperties
operator|.
name|parseString
argument_list|(
name|resultStr
argument_list|)
return|;
block|}
comment|/**    * Returns the acidOperationalProperties for a given map.    * @param parameters A parameters object    * @return the acidOperationalProperties object for the corresponding map.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|parameters
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
comment|// If the parameters does not define any transactional properties, we return a default type.
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
return|return
name|AcidOperationalProperties
operator|.
name|parseString
argument_list|(
name|resultStr
argument_list|)
return|;
block|}
comment|/**    * See comments at {@link AcidUtils#DELTA_SIDE_FILE_SUFFIX}.    *    * Returns the logical end of file for an acid data file.    *    * This relies on the fact that if delta_x_y has no committed transactions it wil be filtered out    * by {@link #getAcidState(Path, Configuration, ValidTxnList)} and so won't be read at all.    * @param file - data file to read/compute splits on    */
specifier|public
specifier|static
name|long
name|getLogicalLength
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|file
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|lengths
init|=
name|OrcAcidUtils
operator|.
name|getSideFile
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|lengths
argument_list|)
condition|)
block|{
comment|/**        * if here for delta_x_y that means txn y is resolved and all files in this delta are closed so        * they should all have a valid ORC footer and info from NameNode about length is good        */
return|return
name|file
operator|.
name|getLen
argument_list|()
return|;
block|}
name|long
name|len
init|=
name|OrcAcidUtils
operator|.
name|getLastFlushLength
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|len
operator|>=
literal|0
condition|)
block|{
comment|/**        * if here something is still writing to delta_x_y so  read only as far as the last commit,        * i.e. where last footer was written.  The file may contain more data after 'len' position        * belonging to an open txn.        */
return|return
name|len
return|;
block|}
comment|/**      * if here, side file is there but we couldn't read it.  We want to avoid a read where      * (file.getLen()< 'value from side file' which may happen if file is not closed) because this      * means some committed data from 'file' would be skipped.      * This should be very unusual.      */
throw|throw
operator|new
name|IOException
argument_list|(
name|lengths
operator|+
literal|" found but is not readable.  Consider waiting or orcfiledump --recover"
argument_list|)
throw|;
block|}
comment|/**    * Checks if a table is a transactional table that only supports INSERT, but not UPDATE/DELETE    * @param params table properties    * @return true if table is an INSERT_ONLY table, false otherwise    */
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
return|return
name|isInsertOnlyTable
argument_list|(
name|params
argument_list|,
literal|false
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
return|return
name|isTransactionalTable
argument_list|(
name|table
argument_list|)
operator|&&
name|getAcidOperationalProperties
argument_list|(
name|table
argument_list|)
operator|.
name|isInsertOnly
argument_list|()
return|;
block|}
comment|// TODO [MM gap]: CTAS may currently be broken. It used to work. See the old code, and why isCtas isn't used?
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|,
name|boolean
name|isCtas
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Properties
name|params
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
comment|/**     * The method for altering table props; may set the table to MM, non-MM, or not affect MM.     * todo: All such validation logic should be TransactionValidationListener     * @param tbl object image before alter table command     * @param props prop values set in this alter table command     */
specifier|public
specifier|static
name|Boolean
name|isToInsertOnlyTable
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
parameter_list|)
block|{
comment|// Note: Setting these separately is a very hairy issue in certain combinations, since we
comment|//       cannot decide what type of table this becomes without taking both into account, and
comment|//       in many cases the conversion might be illegal.
comment|//       The only thing we allow is tx = true w/o tx-props, for backward compat.
name|String
name|transactional
init|=
name|props
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
name|String
name|transactionalProp
init|=
name|props
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactional
operator|==
literal|null
operator|&&
name|transactionalProp
operator|==
literal|null
condition|)
block|{
comment|// Not affected or the op is not about transactional.
return|return
literal|null
return|;
block|}
if|if
condition|(
name|transactional
operator|==
literal|null
condition|)
block|{
name|transactional
operator|=
name|tbl
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
expr_stmt|;
block|}
name|boolean
name|isSetToTxn
init|=
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactional
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactionalProp
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|isSetToTxn
condition|)
return|return
literal|false
return|;
comment|// Assume the full ACID table.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cannot change '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|+
literal|"' without '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
condition|)
return|return
literal|false
return|;
comment|// Not MM.
if|if
condition|(
operator|!
name|isSetToTxn
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cannot set '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
operator|+
literal|"' to 'insert_only' without "
operator|+
literal|"setting '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|+
literal|"' to 'true'"
argument_list|)
throw|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isRemovedInsertOnlyTable
parameter_list|(
name|Set
argument_list|<
name|String
argument_list|>
name|removedSet
parameter_list|)
block|{
name|boolean
name|hasTxn
init|=
name|removedSet
operator|.
name|contains
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|,
name|hasProps
init|=
name|removedSet
operator|.
name|contains
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
name|hasTxn
operator|||
name|hasProps
return|;
block|}
comment|/**    * Load Data commands against Acid tables write {@link AcidBaseFileType#ORIGINAL_BASE} type files    * into delta_x_x/ (or base_x in case there is Overwrite clause).  {@link MetaDataFile} is a    * small JSON file in this directory that indicates that these files don't have Acid metadata    * columns and so the values for these columns need to be assigned at read time/compaction.    */
specifier|public
specifier|static
class|class
name|MetaDataFile
block|{
comment|//export command uses _metadata....
specifier|private
specifier|static
specifier|final
name|String
name|METADATA_FILE
init|=
literal|"_metadata_acid"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|CURRENT_VERSION
init|=
literal|"0"
decl_stmt|;
comment|//todo: enums? that have both field name and value list
specifier|private
interface|interface
name|Field
block|{
name|String
name|VERSION
init|=
literal|"thisFileVersion"
decl_stmt|;
name|String
name|DATA_FORMAT
init|=
literal|"dataFormat"
decl_stmt|;
block|}
specifier|private
interface|interface
name|Value
block|{
comment|//plain ORC file
name|String
name|RAW
init|=
literal|"raw"
decl_stmt|;
comment|//result of acid write, i.e. decorated with ROW__ID info
name|String
name|NATIVE
init|=
literal|"native"
decl_stmt|;
block|}
comment|/**      * @param baseOrDeltaDir detla or base dir, must exist      */
specifier|public
specifier|static
name|void
name|createMetaFile
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|boolean
name|isRawFormat
parameter_list|)
throws|throws
name|IOException
block|{
comment|/**        * create _meta_data json file in baseOrDeltaDir        * write thisFileVersion, dataFormat        *        * on read if the file is not there, assume version 0 and dataFormat=acid        */
name|Path
name|formatFile
init|=
operator|new
name|Path
argument_list|(
name|baseOrDeltaDir
argument_list|,
name|METADATA_FILE
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metaData
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|metaData
operator|.
name|put
argument_list|(
name|Field
operator|.
name|VERSION
argument_list|,
name|CURRENT_VERSION
argument_list|)
expr_stmt|;
name|metaData
operator|.
name|put
argument_list|(
name|Field
operator|.
name|DATA_FORMAT
argument_list|,
name|isRawFormat
condition|?
name|Value
operator|.
name|RAW
else|:
name|Value
operator|.
name|NATIVE
argument_list|)
expr_stmt|;
try|try
init|(
name|FSDataOutputStream
name|strm
init|=
name|fs
operator|.
name|create
argument_list|(
name|formatFile
argument_list|,
literal|false
argument_list|)
init|)
block|{
operator|new
name|ObjectMapper
argument_list|()
operator|.
name|writeValue
argument_list|(
name|strm
argument_list|,
name|metaData
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Failed to create "
operator|+
name|baseOrDeltaDir
operator|+
literal|"/"
operator|+
name|METADATA_FILE
operator|+
literal|": "
operator|+
name|ioe
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
comment|//should be useful for import/export
specifier|public
specifier|static
name|boolean
name|isImport
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|formatFile
init|=
operator|new
name|Path
argument_list|(
name|baseOrDeltaDir
argument_list|,
name|METADATA_FILE
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|formatFile
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
try|try
init|(
name|FSDataInputStream
name|strm
init|=
name|fs
operator|.
name|open
argument_list|(
name|formatFile
argument_list|)
init|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metaData
init|=
operator|new
name|ObjectMapper
argument_list|()
operator|.
name|readValue
argument_list|(
name|strm
argument_list|,
name|Map
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|CURRENT_VERSION
operator|.
name|equalsIgnoreCase
argument_list|(
name|metaData
operator|.
name|get
argument_list|(
name|Field
operator|.
name|VERSION
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Unexpected Meta Data version: "
operator|+
name|metaData
operator|.
name|get
argument_list|(
name|Field
operator|.
name|VERSION
argument_list|)
argument_list|)
throw|;
block|}
name|String
name|dataFormat
init|=
name|metaData
operator|.
name|getOrDefault
argument_list|(
name|Field
operator|.
name|DATA_FORMAT
argument_list|,
literal|"null"
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|dataFormat
condition|)
block|{
case|case
name|Value
operator|.
name|NATIVE
case|:
return|return
literal|false
return|;
case|case
name|Value
operator|.
name|RAW
case|:
return|return
literal|true
return|;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected value for "
operator|+
name|Field
operator|.
name|DATA_FORMAT
operator|+
literal|": "
operator|+
name|dataFormat
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Failed to read "
operator|+
name|baseOrDeltaDir
operator|+
literal|"/"
operator|+
name|METADATA_FILE
operator|+
literal|": "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**      * Chooses 1 representantive file from {@code baseOrDeltaDir}      * This assumes that all files in the dir are of the same type: either written by an acid      * write or Load Data.  This should always be the case for an Acid table.      */
specifier|private
specifier|static
name|Path
name|chooseFile
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
operator|(
name|baseOrDeltaDir
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|||
name|baseOrDeltaDir
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|baseOrDeltaDir
operator|+
literal|" is not a base/delta"
argument_list|)
throw|;
block|}
name|FileStatus
index|[]
name|dataFiles
init|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
index|[]
block|{
name|baseOrDeltaDir
block|}
argument_list|,
name|originalBucketFilter
argument_list|)
decl_stmt|;
return|return
name|dataFiles
operator|!=
literal|null
operator|&&
name|dataFiles
operator|.
name|length
operator|>
literal|0
condition|?
name|dataFiles
index|[
literal|0
index|]
operator|.
name|getPath
argument_list|()
else|:
literal|null
return|;
block|}
comment|/**      * Checks if the files in base/delta dir are a result of Load Data statement and thus do not      * have ROW_IDs embedded in the data.      * @param baseOrDeltaDir base or delta file.      */
specifier|public
specifier|static
name|boolean
name|isRawFormat
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|dataFile
init|=
name|chooseFile
argument_list|(
name|baseOrDeltaDir
argument_list|,
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
name|dataFile
operator|==
literal|null
condition|)
block|{
comment|//directory is empty or doesn't have any that could have been produced by load data
return|return
literal|false
return|;
block|}
try|try
block|{
name|Reader
name|reader
init|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|dataFile
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
comment|/*           acid file would have schema like<op, otid, writerId, rowid, ctid,<f1, ... fn>> so could           check it this way once/if OrcRecordUpdater.ACID_KEY_INDEX_NAME is removed           TypeDescription schema = reader.getSchema();           List<String> columns = schema.getFieldNames();          */
return|return
name|OrcInputFormat
operator|.
name|isOriginal
argument_list|(
name|reader
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|FileFormatException
name|ex
parameter_list|)
block|{
comment|//We may be parsing a delta for Insert-only table which may not even be an ORC file so
comment|//cannot have ROW_IDs in it.
name|LOG
operator|.
name|debug
argument_list|(
literal|"isRawFormat() called on "
operator|+
name|dataFile
operator|+
literal|" which is not an ORC file: "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
end_class

end_unit

