begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
operator|.
name|COPY_KEYWORD
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|LockComponentBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TransactionalValidationListener
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|DataOperationType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockComponent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|MetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ddl
operator|.
name|table
operator|.
name|creation
operator|.
name|CreateTableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|Entity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|ReadEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|WriteEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|OrcRecordUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|orc
operator|.
name|Writer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|HiveTxnManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|LockException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveStorageHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|LoadSemanticAnalyzer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableScanDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
operator|.
name|HdfsFileStatusWithId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|Ref
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|FileFormatException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|orc
operator|.
name|impl
operator|.
name|OrcAcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|map
operator|.
name|ObjectMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|concurrent
operator|.
name|Immutable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|Charset
import|;
end_import

begin_comment
comment|/**  * Utilities that are shared by all of the ACID input and output formats. They  * are used by the compactor and cleaner and thus must be format agnostic.  */
end_comment

begin_class
specifier|public
class|class
name|AcidUtils
block|{
comment|// This key will be put in the conf file when planning an acid operation
specifier|public
specifier|static
specifier|final
name|String
name|CONF_ACID_KEY
init|=
literal|"hive.doing.acid"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BASE_PREFIX
init|=
literal|"base_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|baseFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_PREFIX
init|=
literal|"delta_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELETE_DELTA_PREFIX
init|=
literal|"delete_delta_"
decl_stmt|;
comment|/**    * Acid Streaming Ingest writes multiple transactions to the same file.  It also maintains a    * {@link org.apache.orc.impl.OrcAcidUtils#getSideFile(Path)} side file which stores the length of    * the primary file as of the last commit ({@link OrcRecordUpdater#flush()}).  That is the 'logical length'.    * Once the primary is closed, the side file is deleted (logical length = actual length) but if    * the writer dies or the primary file is being read while its still being written to, anything    * past the logical length should be ignored.    *    * @see org.apache.orc.impl.OrcAcidUtils#DELTA_SIDE_FILE_SUFFIX    * @see org.apache.orc.impl.OrcAcidUtils#getLastFlushLength(FileSystem, Path)    * @see #getLogicalLength(FileSystem, FileStatus)    */
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_SIDE_FILE_SUFFIX
init|=
literal|"_flush_length"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|deltaFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|deleteEventDeltaDirFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BUCKET_PREFIX
init|=
literal|"bucket_"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|bucketFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
operator|&&
operator|!
name|path
operator|.
name|getName
argument_list|()
operator|.
name|endsWith
argument_list|(
name|DELTA_SIDE_FILE_SUFFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BUCKET_DIGITS
init|=
literal|"%05d"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|LEGACY_FILE_BUCKET_DIGITS
init|=
literal|"%06d"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DELTA_DIGITS
init|=
literal|"%07d"
decl_stmt|;
comment|/**    * 10K statements per tx.  Probably overkill ... since that many delta files    * would not be good for performance    */
specifier|public
specifier|static
specifier|final
name|String
name|STATEMENT_DIGITS
init|=
literal|"%04d"
decl_stmt|;
comment|/**    * This must be in sync with {@link #STATEMENT_DIGITS}    */
specifier|public
specifier|static
specifier|final
name|int
name|MAX_STATEMENTS_PER_TXN
init|=
literal|10000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|BUCKET_DIGIT_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]{5}$"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|LEGACY_BUCKET_DIGIT_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^[0-9]{6}"
argument_list|)
decl_stmt|;
comment|/**    * A write into a non-aicd table produces files like 0000_0 or 0000_0_copy_1    * (Unless via Load Data statement)    */
specifier|public
specifier|static
specifier|final
name|PathFilter
name|originalBucketFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|path
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|matches
argument_list|()
operator|||
name|ORIGINAL_PATTERN_COPY
operator|.
name|matcher
argument_list|(
name|path
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|matches
argument_list|()
return|;
block|}
block|}
decl_stmt|;
specifier|private
name|AcidUtils
parameter_list|()
block|{
comment|// NOT USED
block|}
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AcidUtils
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|BUCKET_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
name|BUCKET_PREFIX
operator|+
literal|"_[0-9]{5}$"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|ORIGINAL_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]+_[0-9]+"
argument_list|)
decl_stmt|;
comment|/**    * @see org.apache.hadoop.hive.ql.exec.Utilities#COPY_KEYWORD    */
specifier|public
specifier|static
specifier|final
name|Pattern
name|ORIGINAL_PATTERN_COPY
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[0-9]+_[0-9]+"
operator|+
name|COPY_KEYWORD
operator|+
literal|"[0-9]+"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|PathFilter
name|hiddenFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
name|name
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|VISIBILITY_PREFIX
init|=
literal|"_v"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Pattern
name|VISIBILITY_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
name|VISIBILITY_PREFIX
operator|+
literal|"\\d+"
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|HadoopShims
name|SHIMS
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
comment|/**    * Create the bucket filename in Acid format    * @param subdir the subdirectory for the bucket.    * @param bucket the bucket number    * @return the filename    */
specifier|public
specifier|static
name|Path
name|createBucketFile
parameter_list|(
name|Path
name|subdir
parameter_list|,
name|int
name|bucket
parameter_list|)
block|{
return|return
name|createBucketFile
argument_list|(
name|subdir
argument_list|,
name|bucket
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Create acid or original bucket name    * @param subdir the subdirectory for the bucket.    * @param bucket the bucket number    * @return the filename    */
specifier|private
specifier|static
name|Path
name|createBucketFile
parameter_list|(
name|Path
name|subdir
parameter_list|,
name|int
name|bucket
parameter_list|,
name|boolean
name|isAcidSchema
parameter_list|)
block|{
if|if
condition|(
name|isAcidSchema
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|subdir
argument_list|,
name|BUCKET_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|BUCKET_DIGITS
argument_list|,
name|bucket
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|Path
argument_list|(
name|subdir
argument_list|,
name|String
operator|.
name|format
argument_list|(
name|BUCKET_DIGITS
argument_list|,
name|bucket
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**    * This is format of delta dir name prior to Hive 1.3.x    */
specifier|public
specifier|static
name|String
name|deltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|)
block|{
return|return
name|DELTA_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|min
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|max
argument_list|)
return|;
block|}
comment|/**    * Each write statement in a transaction creates its own delta dir.    * @since 1.3.x    */
specifier|public
specifier|static
name|String
name|deltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
return|return
name|deltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|STATEMENT_DIGITS
argument_list|,
name|statementId
argument_list|)
return|;
block|}
comment|/**    * This is format of delete delta dir name prior to Hive 2.2.x    */
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|String
name|deleteDeltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|)
block|{
return|return
name|DELETE_DELTA_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|min
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|max
argument_list|)
return|;
block|}
comment|/**    * Each write statement in a transaction creates its own delete delta dir,    * when split-update acid operational property is turned on.    * @since 2.2.x    */
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|String
name|deleteDeltaSubdir
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
return|return
name|deleteDeltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|STATEMENT_DIGITS
argument_list|,
name|statementId
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|baseDir
parameter_list|(
name|long
name|writeId
parameter_list|)
block|{
return|return
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|writeId
argument_list|)
return|;
block|}
comment|/**    * Return a base or delta directory string    * according to the given "baseDirRequired".    */
specifier|public
specifier|static
name|String
name|baseOrDeltaSubdir
parameter_list|(
name|boolean
name|baseDirRequired
parameter_list|,
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|int
name|statementId
parameter_list|)
block|{
if|if
condition|(
operator|!
name|baseDirRequired
condition|)
block|{
return|return
name|deltaSubdir
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
name|statementId
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|baseDir
argument_list|(
name|min
argument_list|)
return|;
block|}
block|}
comment|/**    * Return a base or delta directory path according to the given "options".    */
specifier|public
specifier|static
name|Path
name|baseOrDeltaSubdirPath
parameter_list|(
name|Path
name|directory
parameter_list|,
name|AcidOutputFormat
operator|.
name|Options
name|options
parameter_list|)
block|{
name|String
name|subdir
decl_stmt|;
if|if
condition|(
name|options
operator|.
name|isWritingBase
argument_list|()
condition|)
block|{
name|subdir
operator|=
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|options
operator|.
name|getMaximumWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|options
operator|.
name|getStatementId
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
comment|//when minor compaction runs, we collapse per statement delta files inside a single
comment|//transaction so we no longer need a statementId in the file name
name|subdir
operator|=
name|options
operator|.
name|isWritingDeleteDelta
argument_list|()
condition|?
name|deleteDeltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumWriteId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumWriteId
argument_list|()
argument_list|)
else|:
name|deltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumWriteId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|subdir
operator|=
name|options
operator|.
name|isWritingDeleteDelta
argument_list|()
condition|?
name|deleteDeltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumWriteId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumWriteId
argument_list|()
argument_list|,
name|options
operator|.
name|getStatementId
argument_list|()
argument_list|)
else|:
name|deltaSubdir
argument_list|(
name|options
operator|.
name|getMinimumWriteId
argument_list|()
argument_list|,
name|options
operator|.
name|getMaximumWriteId
argument_list|()
argument_list|,
name|options
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|subdir
operator|=
name|addVisibilitySuffix
argument_list|(
name|subdir
argument_list|,
name|options
operator|.
name|getVisibilityTxnId
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|Path
argument_list|(
name|directory
argument_list|,
name|subdir
argument_list|)
return|;
block|}
comment|/**    * Create a filename for a bucket file.    * @param directory the partition directory    * @param options the options for writing the bucket    * @return the filename that should store the bucket    */
specifier|public
specifier|static
name|Path
name|createFilename
parameter_list|(
name|Path
name|directory
parameter_list|,
name|AcidOutputFormat
operator|.
name|Options
name|options
parameter_list|)
block|{
if|if
condition|(
name|options
operator|.
name|getOldStyle
argument_list|()
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|directory
argument_list|,
name|String
operator|.
name|format
argument_list|(
name|LEGACY_FILE_BUCKET_DIGITS
argument_list|,
name|options
operator|.
name|getBucketId
argument_list|()
argument_list|)
operator|+
literal|"_0"
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|createBucketFile
argument_list|(
name|baseOrDeltaSubdirPath
argument_list|(
name|directory
argument_list|,
name|options
argument_list|)
argument_list|,
name|options
operator|.
name|getBucketId
argument_list|()
argument_list|)
return|;
block|}
block|}
comment|/**    * Since Hive 4.0, compactor produces directories with {@link #VISIBILITY_PATTERN} suffix.    * _v0 is equivalent to no suffix, for backwards compatibility.    */
specifier|static
name|String
name|addVisibilitySuffix
parameter_list|(
name|String
name|baseOrDeltaDir
parameter_list|,
name|long
name|visibilityTxnId
parameter_list|)
block|{
if|if
condition|(
name|visibilityTxnId
operator|==
literal|0
condition|)
block|{
return|return
name|baseOrDeltaDir
return|;
block|}
return|return
name|baseOrDeltaDir
operator|+
name|VISIBILITY_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|visibilityTxnId
argument_list|)
return|;
block|}
comment|/**    * Represents bucketId and copy_N suffix    */
specifier|public
specifier|static
specifier|final
class|class
name|BucketMetaData
block|{
specifier|private
specifier|static
specifier|final
name|BucketMetaData
name|INVALID
init|=
operator|new
name|BucketMetaData
argument_list|(
operator|-
literal|1
argument_list|,
literal|0
argument_list|)
decl_stmt|;
comment|/**      * @param bucketFileName {@link #ORIGINAL_PATTERN} or {@link #ORIGINAL_PATTERN_COPY}      */
specifier|public
specifier|static
name|BucketMetaData
name|parse
parameter_list|(
name|String
name|bucketFileName
parameter_list|)
block|{
if|if
condition|(
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|bucketFileName
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
name|int
name|bucketId
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|bucketFileName
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|bucketFileName
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|BucketMetaData
argument_list|(
name|bucketId
argument_list|,
literal|0
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|ORIGINAL_PATTERN_COPY
operator|.
name|matcher
argument_list|(
name|bucketFileName
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
name|int
name|copyNumber
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|bucketFileName
operator|.
name|substring
argument_list|(
name|bucketFileName
operator|.
name|lastIndexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|bucketId
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|bucketFileName
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|bucketFileName
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|BucketMetaData
argument_list|(
name|bucketId
argument_list|,
name|copyNumber
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|bucketFileName
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
condition|)
block|{
return|return
operator|new
name|BucketMetaData
argument_list|(
name|Integer
operator|.
name|parseInt
argument_list|(
name|bucketFileName
operator|.
name|substring
argument_list|(
name|bucketFileName
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
argument_list|,
literal|0
argument_list|)
return|;
block|}
return|return
name|INVALID
return|;
block|}
specifier|public
specifier|static
name|BucketMetaData
name|parse
parameter_list|(
name|Path
name|bucketFile
parameter_list|)
block|{
return|return
name|parse
argument_list|(
name|bucketFile
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
comment|/**      * -1 if non-standard file name      */
specifier|public
specifier|final
name|int
name|bucketId
decl_stmt|;
comment|/**      * 0 means no copy_N suffix      */
specifier|public
specifier|final
name|int
name|copyNumber
decl_stmt|;
specifier|private
name|BucketMetaData
parameter_list|(
name|int
name|bucketId
parameter_list|,
name|int
name|copyNumber
parameter_list|)
block|{
name|this
operator|.
name|bucketId
operator|=
name|bucketId
expr_stmt|;
name|this
operator|.
name|copyNumber
operator|=
name|copyNumber
expr_stmt|;
block|}
block|}
comment|/**    * Get the bucket id from the file path    * @param bucketFile - bucket file path    * @return - bucket id    */
specifier|public
specifier|static
name|int
name|parseBucketId
parameter_list|(
name|Path
name|bucketFile
parameter_list|)
block|{
name|String
name|filename
init|=
name|bucketFile
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
operator|||
name|ORIGINAL_PATTERN_COPY
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
condition|)
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|filename
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
return|;
block|}
return|return
operator|-
literal|1
return|;
block|}
comment|/**    * Parse a bucket filename back into the options that would have created    * the file.    * @param bucketFile the path to a bucket file    * @param conf the configuration    * @return the options used to create that filename    */
specifier|public
specifier|static
name|AcidOutputFormat
operator|.
name|Options
name|parseBaseOrDeltaBucketFilename
parameter_list|(
name|Path
name|bucketFile
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|AcidOutputFormat
operator|.
name|Options
name|result
init|=
operator|new
name|AcidOutputFormat
operator|.
name|Options
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|filename
init|=
name|bucketFile
operator|.
name|getName
argument_list|()
decl_stmt|;
name|int
name|bucket
init|=
name|parseBucketId
argument_list|(
name|bucketFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|ORIGINAL_PATTERN
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
literal|0
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|writingBase
argument_list|(
operator|!
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ORIGINAL_PATTERN_COPY
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
comment|//todo: define groups in regex and use parseInt(Matcher.group(2))....
name|int
name|copyNumber
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|filename
operator|.
name|lastIndexOf
argument_list|(
literal|'_'
argument_list|)
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
literal|0
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|copyNumber
argument_list|(
name|copyNumber
argument_list|)
operator|.
name|writingBase
argument_list|(
operator|!
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BUCKET_PREFIX
argument_list|)
condition|)
block|{
if|if
condition|(
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
name|ParsedBase
operator|.
name|parseBase
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|)
operator|.
name|getWriteId
argument_list|()
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|writingBase
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
condition|)
block|{
name|ParsedDelta
name|parsedDelta
init|=
name|parsedDelta
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|,
name|DELTA_PREFIX
argument_list|,
name|bucketFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
name|parsedDelta
operator|.
name|minWriteId
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
name|parsedDelta
operator|.
name|maxWriteId
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bucketFile
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
name|ParsedDelta
name|parsedDelta
init|=
name|parsedDelta
argument_list|(
name|bucketFile
operator|.
name|getParent
argument_list|()
argument_list|,
name|DELETE_DELTA_PREFIX
argument_list|,
name|bucketFile
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|.
name|setOldStyle
argument_list|(
literal|false
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
name|parsedDelta
operator|.
name|minWriteId
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
name|parsedDelta
operator|.
name|maxWriteId
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|result
operator|.
name|setOldStyle
argument_list|(
literal|true
argument_list|)
operator|.
name|bucket
argument_list|(
name|bucket
argument_list|)
operator|.
name|minimumWriteId
argument_list|(
literal|0
argument_list|)
operator|.
name|maximumWriteId
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
specifier|public
specifier|static
specifier|final
class|class
name|DirectoryImpl
implements|implements
name|Directory
block|{
specifier|private
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|abortedDirectories
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isBaseInRawFormat
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|obsolete
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
decl_stmt|;
specifier|private
specifier|final
name|Path
name|base
decl_stmt|;
specifier|public
name|DirectoryImpl
parameter_list|(
name|List
argument_list|<
name|Path
argument_list|>
name|abortedDirectories
parameter_list|,
name|boolean
name|isBaseInRawFormat
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|obsolete
parameter_list|,
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|,
name|Path
name|base
parameter_list|)
block|{
name|this
operator|.
name|abortedDirectories
operator|=
name|abortedDirectories
operator|==
literal|null
condition|?
name|Collections
operator|.
name|emptyList
argument_list|()
else|:
name|abortedDirectories
expr_stmt|;
name|this
operator|.
name|isBaseInRawFormat
operator|=
name|isBaseInRawFormat
expr_stmt|;
name|this
operator|.
name|original
operator|=
name|original
operator|==
literal|null
condition|?
name|Collections
operator|.
name|emptyList
argument_list|()
else|:
name|original
expr_stmt|;
name|this
operator|.
name|obsolete
operator|=
name|obsolete
operator|==
literal|null
condition|?
name|Collections
operator|.
name|emptyList
argument_list|()
else|:
name|obsolete
expr_stmt|;
name|this
operator|.
name|deltas
operator|=
name|deltas
operator|==
literal|null
condition|?
name|Collections
operator|.
name|emptyList
argument_list|()
else|:
name|deltas
expr_stmt|;
name|this
operator|.
name|base
operator|=
name|base
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Path
name|getBaseDirectory
parameter_list|()
block|{
return|return
name|base
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isBaseInRawFormat
parameter_list|()
block|{
return|return
name|isBaseInRawFormat
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|getOriginalFiles
parameter_list|()
block|{
return|return
name|original
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|getCurrentDirectories
parameter_list|()
block|{
return|return
name|deltas
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Path
argument_list|>
name|getObsolete
parameter_list|()
block|{
return|return
name|obsolete
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Path
argument_list|>
name|getAbortedDirectories
parameter_list|()
block|{
return|return
name|abortedDirectories
return|;
block|}
block|}
comment|//This is used for (full) Acid tables.  InsertOnly use NOT_ACID
specifier|public
enum|enum
name|Operation
implements|implements
name|Serializable
block|{
name|NOT_ACID
block|,
name|INSERT
block|,
name|UPDATE
block|,
name|DELETE
block|;   }
comment|/**    * Logically this should have been defined in Operation but that causes a dependency    * on metastore package from exec jar (from the cluster) which is not allowed.    * This method should only be called from client side where metastore.* classes are present.    * Not following this will not be caught by unit tests since they have all the jar loaded.    */
specifier|public
specifier|static
name|DataOperationType
name|toDataOperationType
parameter_list|(
name|Operation
name|op
parameter_list|)
block|{
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|NOT_ACID
case|:
return|return
name|DataOperationType
operator|.
name|UNSET
return|;
case|case
name|INSERT
case|:
return|return
name|DataOperationType
operator|.
name|INSERT
return|;
case|case
name|UPDATE
case|:
return|return
name|DataOperationType
operator|.
name|UPDATE
return|;
case|case
name|DELETE
case|:
return|return
name|DataOperationType
operator|.
name|DELETE
return|;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected Operation: "
operator|+
name|op
argument_list|)
throw|;
block|}
block|}
specifier|public
enum|enum
name|AcidBaseFileType
block|{
comment|/**    * File w/o Acid meta columns.  This this would be the case for files that were added to the table    * before it was converted to Acid but not yet major compacted.  May also be the the result of    * Load Data statement on an acid table.    */
name|ORIGINAL_BASE
block|,
comment|/**    * File that has Acid metadata columns embedded in it.  Found in base_x/ or delta_x_y/.    */
name|ACID_SCHEMA
block|,   }
comment|/**    * A simple wrapper class that stores the information about a base file and its type.    * Orc splits can be generated on three kinds of base files: an original file (non-acid converted    * files), a regular base file (created by major compaction) or an insert delta (which can be    * treated as a base when split-update is enabled for acid).    */
specifier|public
specifier|static
class|class
name|AcidBaseFileInfo
block|{
specifier|final
specifier|private
name|HdfsFileStatusWithId
name|fileId
decl_stmt|;
specifier|final
specifier|private
name|AcidBaseFileType
name|acidBaseFileType
decl_stmt|;
specifier|public
name|AcidBaseFileInfo
parameter_list|(
name|HdfsFileStatusWithId
name|fileId
parameter_list|,
name|AcidBaseFileType
name|acidBaseFileType
parameter_list|)
block|{
name|this
operator|.
name|fileId
operator|=
name|fileId
expr_stmt|;
name|this
operator|.
name|acidBaseFileType
operator|=
name|acidBaseFileType
expr_stmt|;
block|}
specifier|public
name|boolean
name|isOriginal
parameter_list|()
block|{
return|return
name|this
operator|.
name|acidBaseFileType
operator|==
name|AcidBaseFileType
operator|.
name|ORIGINAL_BASE
return|;
block|}
specifier|public
name|boolean
name|isAcidSchema
parameter_list|()
block|{
return|return
name|this
operator|.
name|acidBaseFileType
operator|==
name|AcidBaseFileType
operator|.
name|ACID_SCHEMA
return|;
block|}
specifier|public
name|HdfsFileStatusWithId
name|getHdfsFileStatusWithId
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileId
return|;
block|}
block|}
comment|/**    * Current syntax for creating full acid transactional tables is any one of following 3 ways:    * create table T (a int, b int) stored as orc tblproperties('transactional'='true').    * create table T (a int, b int) stored as orc tblproperties('transactional'='true',    * 'transactional_properties'='default').    * create table T (a int, b int) stored as orc tblproperties('transactional'='true',    * 'transactional_properties'='split_update').    * These are all identical and create a table capable of insert/update/delete/merge operations    * with full ACID semantics at Snapshot Isolation.  These tables require ORC input/output format.    *    * To create a 1/4 acid, aka Micro Managed table:    * create table T (a int, b int) stored as orc tblproperties('transactional'='true',    * 'transactional_properties'='insert_only').    * These tables only support insert operation (also with full ACID semantics at SI).    *    */
specifier|public
specifier|static
class|class
name|AcidOperationalProperties
block|{
specifier|private
name|int
name|description
init|=
literal|0x00
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|SPLIT_UPDATE_BIT
init|=
literal|0x01
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|SPLIT_UPDATE_STRING
init|=
literal|"split_update"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|HASH_BASED_MERGE_BIT
init|=
literal|0x02
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|HASH_BASED_MERGE_STRING
init|=
literal|"hash_merge"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|INSERT_ONLY_BIT
init|=
literal|0x04
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|INSERT_ONLY_STRING
init|=
literal|"insert_only"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_VALUE_STRING
init|=
name|TransactionalValidationListener
operator|.
name|DEFAULT_TRANSACTIONAL_PROPERTY
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|INSERTONLY_VALUE_STRING
init|=
name|TransactionalValidationListener
operator|.
name|INSERTONLY_TRANSACTIONAL_PROPERTY
decl_stmt|;
specifier|private
name|AcidOperationalProperties
parameter_list|()
block|{     }
comment|/**      * Returns an acidOperationalProperties object that represents default ACID behavior for tables      * that do no explicitly specify/override the default behavior.      * @return the acidOperationalProperties object.      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getDefault
parameter_list|()
block|{
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
name|obj
operator|.
name|setSplitUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|obj
operator|.
name|setHashBasedMerge
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|obj
operator|.
name|setInsertOnly
argument_list|(
literal|false
argument_list|)
expr_stmt|;
return|return
name|obj
return|;
block|}
comment|/**      * Returns an acidOperationalProperties object for tables that uses ACID framework but only      * supports INSERT operation and does not require ORC or bucketing      * @return the acidOperationalProperties object      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getInsertOnly
parameter_list|()
block|{
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
name|obj
operator|.
name|setInsertOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|obj
return|;
block|}
comment|/**      * Returns an acidOperationalProperties object that is represented by an encoded string.      * @param propertiesStr an encoded string representing the acidOperationalProperties.      * @return the acidOperationalProperties object.      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|parseString
parameter_list|(
name|String
name|propertiesStr
parameter_list|)
block|{
if|if
condition|(
name|propertiesStr
operator|==
literal|null
condition|)
block|{
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
if|if
condition|(
name|propertiesStr
operator|.
name|equalsIgnoreCase
argument_list|(
name|DEFAULT_VALUE_STRING
argument_list|)
condition|)
block|{
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
if|if
condition|(
name|propertiesStr
operator|.
name|equalsIgnoreCase
argument_list|(
name|INSERTONLY_VALUE_STRING
argument_list|)
condition|)
block|{
return|return
name|AcidOperationalProperties
operator|.
name|getInsertOnly
argument_list|()
return|;
block|}
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
name|String
index|[]
name|options
init|=
name|propertiesStr
operator|.
name|split
argument_list|(
literal|"\\|"
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|option
range|:
name|options
control|)
block|{
if|if
condition|(
name|option
operator|.
name|trim
argument_list|()
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
continue|continue;
comment|// ignore empty strings
switch|switch
condition|(
name|option
condition|)
block|{
case|case
name|SPLIT_UPDATE_STRING
case|:
name|obj
operator|.
name|setSplitUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
break|break;
case|case
name|HASH_BASED_MERGE_STRING
case|:
name|obj
operator|.
name|setHashBasedMerge
argument_list|(
literal|true
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected value "
operator|+
name|option
operator|+
literal|" for ACID operational properties!"
argument_list|)
throw|;
block|}
block|}
return|return
name|obj
return|;
block|}
comment|/**      * Returns an acidOperationalProperties object that is represented by an encoded 32-bit integer.      * @param properties an encoded 32-bit representing the acidOperationalProperties.      * @return the acidOperationalProperties object.      */
specifier|public
specifier|static
name|AcidOperationalProperties
name|parseInt
parameter_list|(
name|int
name|properties
parameter_list|)
block|{
name|AcidOperationalProperties
name|obj
init|=
operator|new
name|AcidOperationalProperties
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|properties
operator|&
name|SPLIT_UPDATE_BIT
operator|)
operator|>
literal|0
condition|)
block|{
name|obj
operator|.
name|setSplitUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|properties
operator|&
name|HASH_BASED_MERGE_BIT
operator|)
operator|>
literal|0
condition|)
block|{
name|obj
operator|.
name|setHashBasedMerge
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|properties
operator|&
name|INSERT_ONLY_BIT
operator|)
operator|>
literal|0
condition|)
block|{
name|obj
operator|.
name|setInsertOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
return|return
name|obj
return|;
block|}
comment|/**      * Sets the split update property for ACID operations based on the boolean argument.      * When split update is turned on, an update ACID event is interpreted as a combination of      * delete event followed by an update event.      * @param isSplitUpdate a boolean property that turns on split update when true.      * @return the acidOperationalProperties object.      */
specifier|public
name|AcidOperationalProperties
name|setSplitUpdate
parameter_list|(
name|boolean
name|isSplitUpdate
parameter_list|)
block|{
name|description
operator|=
operator|(
name|isSplitUpdate
condition|?
operator|(
name|description
operator||
name|SPLIT_UPDATE_BIT
operator|)
else|:
operator|(
name|description
operator|&
operator|~
name|SPLIT_UPDATE_BIT
operator|)
operator|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Sets the hash-based merge property for ACID operations that combines delta files using      * GRACE hash join based approach, when turned on. (Currently unimplemented!)      * @param isHashBasedMerge a boolean property that turns on hash-based merge when true.      * @return the acidOperationalProperties object.      */
specifier|public
name|AcidOperationalProperties
name|setHashBasedMerge
parameter_list|(
name|boolean
name|isHashBasedMerge
parameter_list|)
block|{
name|description
operator|=
operator|(
name|isHashBasedMerge
condition|?
operator|(
name|description
operator||
name|HASH_BASED_MERGE_BIT
operator|)
else|:
operator|(
name|description
operator|&
operator|~
name|HASH_BASED_MERGE_BIT
operator|)
operator|)
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|AcidOperationalProperties
name|setInsertOnly
parameter_list|(
name|boolean
name|isInsertOnly
parameter_list|)
block|{
name|description
operator|=
operator|(
name|isInsertOnly
condition|?
operator|(
name|description
operator||
name|INSERT_ONLY_BIT
operator|)
else|:
operator|(
name|description
operator|&
operator|~
name|INSERT_ONLY_BIT
operator|)
operator|)
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|boolean
name|isSplitUpdate
parameter_list|()
block|{
return|return
operator|(
name|description
operator|&
name|SPLIT_UPDATE_BIT
operator|)
operator|>
literal|0
return|;
block|}
specifier|public
name|boolean
name|isHashBasedMerge
parameter_list|()
block|{
return|return
operator|(
name|description
operator|&
name|HASH_BASED_MERGE_BIT
operator|)
operator|>
literal|0
return|;
block|}
specifier|public
name|boolean
name|isInsertOnly
parameter_list|()
block|{
return|return
operator|(
name|description
operator|&
name|INSERT_ONLY_BIT
operator|)
operator|>
literal|0
return|;
block|}
specifier|public
name|int
name|toInt
parameter_list|()
block|{
return|return
name|description
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|str
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
if|if
condition|(
name|isSplitUpdate
argument_list|()
condition|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|"|"
operator|+
name|SPLIT_UPDATE_STRING
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isHashBasedMerge
argument_list|()
condition|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|"|"
operator|+
name|HASH_BASED_MERGE_STRING
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isInsertOnly
argument_list|()
condition|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|"|"
operator|+
name|INSERT_ONLY_STRING
argument_list|)
expr_stmt|;
block|}
return|return
name|str
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|/**    * Interface used to provide ACID directory information.    */
specifier|public
interface|interface
name|Directory
block|{
comment|/**      * Get the base directory.      * @return the base directory to read      */
name|Path
name|getBaseDirectory
parameter_list|()
function_decl|;
name|boolean
name|isBaseInRawFormat
parameter_list|()
function_decl|;
comment|/**      * Get the list of original files.  Not {@code null}.  Must be sorted.      * @return the list of original files (eg. 000000_0)      */
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|getOriginalFiles
parameter_list|()
function_decl|;
comment|/**      * Get the list of base and delta directories that are valid and not      * obsolete.  Not {@code null}.  List must be sorted in a specific way.      * See {@link org.apache.hadoop.hive.ql.io.AcidUtils.ParsedDeltaLight#compareTo(org.apache.hadoop.hive.ql.io.AcidUtils.ParsedDeltaLight)}      * for details.      * @return the minimal list of current directories      */
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|getCurrentDirectories
parameter_list|()
function_decl|;
comment|/**      * Get the list of obsolete directories. After filtering out bases and      * deltas that are not selected by the valid transaction/write ids list, return the      * list of original files, bases, and deltas that have been replaced by      * more up to date ones.  Not {@code null}.      */
name|List
argument_list|<
name|Path
argument_list|>
name|getObsolete
parameter_list|()
function_decl|;
comment|/**      * Get the list of directories that has nothing but aborted transactions.      * @return the list of aborted directories      */
name|List
argument_list|<
name|Path
argument_list|>
name|getAbortedDirectories
parameter_list|()
function_decl|;
block|}
comment|/**    * Since version 3 but prior to version 4, format of a base is "base_X" where X is a writeId.    * If this base was produced by a compactor, X is the highest writeId that the compactor included.    * If this base is produced by Insert Overwrite stmt, X is a writeId of the transaction that    * executed the insert.    * Since Hive Version 4.0, the format of a base produced by a compactor is    * base_X_vY.  X is like before, i.e. the highest writeId compactor included and Y is the    * visibilityTxnId of the transaction in which the compactor ran.    * (v(isibility) is a literal to help parsing).    */
specifier|public
specifier|static
specifier|final
class|class
name|ParsedBase
block|{
specifier|private
specifier|final
name|long
name|writeId
decl_stmt|;
specifier|private
specifier|final
name|long
name|visibilityTxnId
decl_stmt|;
specifier|private
specifier|final
name|Path
name|baseDirPath
decl_stmt|;
name|ParsedBase
parameter_list|(
name|long
name|writeId
parameter_list|,
name|Path
name|baseDirPath
parameter_list|)
block|{
name|this
argument_list|(
name|writeId
argument_list|,
literal|0
argument_list|,
name|baseDirPath
argument_list|)
expr_stmt|;
block|}
name|ParsedBase
parameter_list|(
name|long
name|writeId
parameter_list|,
name|long
name|visibilityTxnId
parameter_list|,
name|Path
name|baseDirPath
parameter_list|)
block|{
name|this
operator|.
name|writeId
operator|=
name|writeId
expr_stmt|;
name|this
operator|.
name|visibilityTxnId
operator|=
name|visibilityTxnId
expr_stmt|;
name|this
operator|.
name|baseDirPath
operator|=
name|baseDirPath
expr_stmt|;
block|}
specifier|public
name|long
name|getWriteId
parameter_list|()
block|{
return|return
name|writeId
return|;
block|}
specifier|public
name|long
name|getVisibilityTxnId
parameter_list|()
block|{
return|return
name|visibilityTxnId
return|;
block|}
specifier|public
name|Path
name|getBaseDirPath
parameter_list|()
block|{
return|return
name|baseDirPath
return|;
block|}
specifier|public
specifier|static
name|ParsedBase
name|parseBase
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|String
name|filename
init|=
name|path
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|filename
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|filename
operator|+
literal|" does not start with "
operator|+
name|BASE_PREFIX
argument_list|)
throw|;
block|}
name|int
name|idxOfv
init|=
name|filename
operator|.
name|indexOf
argument_list|(
name|VISIBILITY_PREFIX
argument_list|)
decl_stmt|;
if|if
condition|(
name|idxOfv
operator|<
literal|0
condition|)
block|{
return|return
operator|new
name|ParsedBase
argument_list|(
name|Long
operator|.
name|parseLong
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|BASE_PREFIX
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|path
argument_list|)
return|;
block|}
return|return
operator|new
name|ParsedBase
argument_list|(
name|Long
operator|.
name|parseLong
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|BASE_PREFIX
operator|.
name|length
argument_list|()
argument_list|,
name|idxOfv
argument_list|)
argument_list|)
argument_list|,
name|Long
operator|.
name|parseLong
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|idxOfv
operator|+
name|VISIBILITY_PREFIX
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|path
argument_list|)
return|;
block|}
block|}
comment|/**    * In addition to {@link ParsedDeltaLight} this knows if the data is in raw format, i.e. doesn't    * have acid metadata columns embedded in the files.  To determine this in some cases    * requires looking at the footer of the data file which can be expensive so if this info is    * not needed {@link ParsedDeltaLight} should be used.    */
annotation|@
name|Immutable
specifier|public
specifier|static
specifier|final
class|class
name|ParsedDelta
extends|extends
name|ParsedDeltaLight
block|{
specifier|private
specifier|final
name|boolean
name|isRawFormat
decl_stmt|;
comment|/**      * for pre 1.3.x delta files      */
specifier|private
name|ParsedDelta
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|Path
name|path
parameter_list|,
name|boolean
name|isDeleteDelta
parameter_list|,
name|boolean
name|isRawFormat
parameter_list|,
name|long
name|visibilityTxnId
parameter_list|)
block|{
name|this
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
name|path
argument_list|,
operator|-
literal|1
argument_list|,
name|isDeleteDelta
argument_list|,
name|isRawFormat
argument_list|,
name|visibilityTxnId
argument_list|)
expr_stmt|;
block|}
specifier|private
name|ParsedDelta
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|Path
name|path
parameter_list|,
name|int
name|statementId
parameter_list|,
name|boolean
name|isDeleteDelta
parameter_list|,
name|boolean
name|isRawFormat
parameter_list|,
name|long
name|visibilityTxnId
parameter_list|)
block|{
name|super
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
name|path
argument_list|,
name|statementId
argument_list|,
name|isDeleteDelta
argument_list|,
name|visibilityTxnId
argument_list|)
expr_stmt|;
name|this
operator|.
name|isRawFormat
operator|=
name|isRawFormat
expr_stmt|;
block|}
comment|/**      * Files w/o Acid meta columns embedded in the file. See {@link AcidBaseFileType#ORIGINAL_BASE}      */
specifier|public
name|boolean
name|isRawFormat
parameter_list|()
block|{
return|return
name|isRawFormat
return|;
block|}
block|}
comment|/**    * This encapsulates info obtained form the file path.    * See also {@link ParsedDelta}.    */
annotation|@
name|Immutable
specifier|public
specifier|static
class|class
name|ParsedDeltaLight
implements|implements
name|Comparable
argument_list|<
name|ParsedDeltaLight
argument_list|>
block|{
specifier|final
name|long
name|minWriteId
decl_stmt|;
specifier|final
name|long
name|maxWriteId
decl_stmt|;
specifier|final
name|Path
name|path
decl_stmt|;
comment|//-1 is for internal (getAcidState()) purposes and means the delta dir
comment|//had no statement ID
specifier|final
name|int
name|statementId
decl_stmt|;
specifier|final
name|boolean
name|isDeleteDelta
decl_stmt|;
comment|// records whether delta dir is of type 'delete_delta_x_y...'
comment|/**      * transaction Id of txn which created this delta.  This dir should be considered      * invisible unless this txn is committed      *      * TODO: define TransactionallyVisible interface - add getVisibilityTxnId() etc and all comments      * use in {@link ParsedBase}, {@link ParsedDelta}, {@link AcidInputFormat.Options}, AcidInputFormat.DeltaMetaData etc      */
specifier|final
name|long
name|visibilityTxnId
decl_stmt|;
specifier|public
specifier|static
name|ParsedDeltaLight
name|parse
parameter_list|(
name|Path
name|deltaDir
parameter_list|)
block|{
comment|//passing isRawFormat=false is bogus.  This is just to parse the file name.
name|ParsedDelta
name|pd
init|=
name|parsedDelta
argument_list|(
name|deltaDir
argument_list|,
literal|false
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDeltaLight
argument_list|(
name|pd
operator|.
name|getMinWriteId
argument_list|()
argument_list|,
name|pd
operator|.
name|getMaxWriteId
argument_list|()
argument_list|,
name|deltaDir
argument_list|,
name|pd
operator|.
name|getStatementId
argument_list|()
argument_list|,
name|pd
operator|.
name|isDeleteDelta
argument_list|()
argument_list|,
name|pd
operator|.
name|getVisibilityTxnId
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|ParsedDeltaLight
parameter_list|(
name|long
name|min
parameter_list|,
name|long
name|max
parameter_list|,
name|Path
name|path
parameter_list|,
name|int
name|statementId
parameter_list|,
name|boolean
name|isDeleteDelta
parameter_list|,
name|long
name|visibilityTxnId
parameter_list|)
block|{
name|this
operator|.
name|minWriteId
operator|=
name|min
expr_stmt|;
name|this
operator|.
name|maxWriteId
operator|=
name|max
expr_stmt|;
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
name|this
operator|.
name|statementId
operator|=
name|statementId
expr_stmt|;
name|this
operator|.
name|isDeleteDelta
operator|=
name|isDeleteDelta
expr_stmt|;
name|this
operator|.
name|visibilityTxnId
operator|=
name|visibilityTxnId
expr_stmt|;
block|}
specifier|public
name|long
name|getMinWriteId
parameter_list|()
block|{
return|return
name|minWriteId
return|;
block|}
specifier|public
name|long
name|getMaxWriteId
parameter_list|()
block|{
return|return
name|maxWriteId
return|;
block|}
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|path
return|;
block|}
specifier|public
name|int
name|getStatementId
parameter_list|()
block|{
return|return
name|statementId
operator|==
operator|-
literal|1
condition|?
literal|0
else|:
name|statementId
return|;
block|}
specifier|public
name|boolean
name|isDeleteDelta
parameter_list|()
block|{
return|return
name|isDeleteDelta
return|;
block|}
specifier|public
name|long
name|getVisibilityTxnId
parameter_list|()
block|{
return|return
name|visibilityTxnId
return|;
block|}
comment|/**      * Only un-compacted delta_x_y (x != y) (created by streaming ingest with batch size> 1)      * may contain a {@link OrcAcidUtils#getSideFile(Path)}.      * @return      */
name|boolean
name|mayContainSideFile
parameter_list|()
block|{
return|return
operator|!
name|isDeleteDelta
argument_list|()
operator|&&
name|getMinWriteId
argument_list|()
operator|!=
name|getMaxWriteId
argument_list|()
operator|&&
name|getVisibilityTxnId
argument_list|()
operator|<=
literal|0
return|;
block|}
comment|/**      * Compactions (Major/Minor) merge deltas/bases but delete of old files      * happens in a different process; thus it's possible to have bases/deltas with      * overlapping writeId boundaries.  The sort order helps figure out the "best" set of files      * to use to get data.      * This sorts "wider" delta before "narrower" i.e. delta_5_20 sorts before delta_5_10 (and delta_11_20)      */
annotation|@
name|Override
specifier|public
name|int
name|compareTo
parameter_list|(
name|ParsedDeltaLight
name|parsedDelta
parameter_list|)
block|{
if|if
condition|(
name|minWriteId
operator|!=
name|parsedDelta
operator|.
name|minWriteId
condition|)
block|{
if|if
condition|(
name|minWriteId
operator|<
name|parsedDelta
operator|.
name|minWriteId
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
literal|1
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|maxWriteId
operator|!=
name|parsedDelta
operator|.
name|maxWriteId
condition|)
block|{
if|if
condition|(
name|maxWriteId
operator|<
name|parsedDelta
operator|.
name|maxWriteId
condition|)
block|{
return|return
literal|1
return|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|statementId
operator|!=
name|parsedDelta
operator|.
name|statementId
condition|)
block|{
comment|/**          * We want deltas after minor compaction (w/o statementId) to sort          * earlier so that getAcidState() considers compacted files (into larger ones) obsolete          * Before compaction, include deltas with all statementIds for a given writeId          * in a {@link org.apache.hadoop.hive.ql.io.AcidUtils.Directory}          */
if|if
condition|(
name|statementId
operator|<
name|parsedDelta
operator|.
name|statementId
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
return|return
literal|1
return|;
block|}
block|}
else|else
block|{
return|return
name|path
operator|.
name|compareTo
argument_list|(
name|parsedDelta
operator|.
name|path
argument_list|)
return|;
block|}
block|}
block|}
comment|/**    * Convert a list of deltas to a list of delta directories.    * @param deltas the list of deltas out of a Directory object.    * @return a list of delta directory paths that need to be read    */
specifier|public
specifier|static
name|Path
index|[]
name|getPaths
parameter_list|(
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|)
block|{
name|Path
index|[]
name|result
init|=
operator|new
name|Path
index|[
name|deltas
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|result
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
name|deltas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getPath
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * todo: rename serializeDeleteDelta()?    * Convert the list of deltas into an equivalent list of begin/end    * write id pairs.  Assumes {@code deltas} is sorted.    * @param deltas    * @return the list of write ids to serialize    */
specifier|public
specifier|static
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|serializeDeltas
parameter_list|(
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
parameter_list|)
block|{
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|last
init|=
literal|null
decl_stmt|;
for|for
control|(
name|ParsedDelta
name|parsedDelta
range|:
name|deltas
control|)
block|{
assert|assert
name|parsedDelta
operator|.
name|isDeleteDelta
argument_list|()
operator|:
literal|"expected delete_delta, got "
operator|+
name|parsedDelta
operator|.
name|getPath
argument_list|()
assert|;
if|if
condition|(
operator|(
name|last
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|last
operator|.
name|getMinWriteId
argument_list|()
operator|==
name|parsedDelta
operator|.
name|getMinWriteId
argument_list|()
operator|)
operator|&&
operator|(
name|last
operator|.
name|getMaxWriteId
argument_list|()
operator|==
name|parsedDelta
operator|.
name|getMaxWriteId
argument_list|()
operator|)
condition|)
block|{
name|last
operator|.
name|getStmtIds
argument_list|()
operator|.
name|add
argument_list|(
name|parsedDelta
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|last
operator|=
operator|new
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|(
name|parsedDelta
operator|.
name|getMinWriteId
argument_list|()
argument_list|,
name|parsedDelta
operator|.
name|getMaxWriteId
argument_list|()
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|()
argument_list|,
name|parsedDelta
operator|.
name|getVisibilityTxnId
argument_list|()
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|last
argument_list|)
expr_stmt|;
if|if
condition|(
name|parsedDelta
operator|.
name|statementId
operator|>=
literal|0
condition|)
block|{
name|last
operator|.
name|getStmtIds
argument_list|()
operator|.
name|add
argument_list|(
name|parsedDelta
operator|.
name|getStatementId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Convert the list of begin/end write id pairs to a list of delete delta    * directories.  Note that there may be multiple delete_delta files for the exact same txn range starting    * with 2.2.x;    * see {@link org.apache.hadoop.hive.ql.io.AcidUtils#deltaSubdir(long, long, int)}    * @param root the root directory    * @param deleteDeltas list of begin/end write id pairs    * @return the list of delta paths    */
specifier|public
specifier|static
name|Path
index|[]
name|deserializeDeleteDeltas
parameter_list|(
name|Path
name|root
parameter_list|,
specifier|final
name|List
argument_list|<
name|AcidInputFormat
operator|.
name|DeltaMetaData
argument_list|>
name|deleteDeltas
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|deleteDeltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|AcidInputFormat
operator|.
name|DeltaMetaData
name|dmd
range|:
name|deleteDeltas
control|)
block|{
if|if
condition|(
name|dmd
operator|.
name|getStmtIds
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Path
argument_list|(
name|root
argument_list|,
name|dmd
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
for|for
control|(
name|Integer
name|stmtId
range|:
name|dmd
operator|.
name|getStmtIds
argument_list|()
control|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Path
argument_list|(
name|root
argument_list|,
name|dmd
operator|.
name|getName
argument_list|(
name|stmtId
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|results
operator|.
name|toArray
argument_list|(
operator|new
name|Path
index|[
name|results
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
comment|/**    * This will look at a footer of one of the files in the delta to see if the    * file is in Acid format, i.e. has acid metadata columns.  The assumption is    * that for any dir, either all files are acid or all are not.    */
specifier|public
specifier|static
name|ParsedDelta
name|parsedDelta
parameter_list|(
name|Path
name|deltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|deltaDirName
init|=
name|deltaDir
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|deltaDirName
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
return|return
name|parsedDelta
argument_list|(
name|deltaDir
argument_list|,
name|DELETE_DELTA_PREFIX
argument_list|,
name|fs
argument_list|)
return|;
block|}
return|return
name|parsedDelta
argument_list|(
name|deltaDir
argument_list|,
name|DELTA_PREFIX
argument_list|,
name|fs
argument_list|)
return|;
comment|// default prefix is delta_prefix
block|}
specifier|private
specifier|static
name|ParsedDelta
name|parseDelta
parameter_list|(
name|Path
name|path
parameter_list|,
name|String
name|deltaPrefix
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|ParsedDelta
name|p
init|=
name|parsedDelta
argument_list|(
name|path
argument_list|,
name|deltaPrefix
argument_list|,
name|fs
argument_list|)
decl_stmt|;
name|boolean
name|isDeleteDelta
init|=
name|deltaPrefix
operator|.
name|equals
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDelta
argument_list|(
name|p
operator|.
name|getMinWriteId
argument_list|()
argument_list|,
name|p
operator|.
name|getMaxWriteId
argument_list|()
argument_list|,
name|path
argument_list|,
name|p
operator|.
name|statementId
argument_list|,
name|isDeleteDelta
argument_list|,
name|p
operator|.
name|isRawFormat
argument_list|()
argument_list|,
name|p
operator|.
name|visibilityTxnId
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|ParsedDelta
name|parsedDelta
parameter_list|(
name|Path
name|deltaDir
parameter_list|,
name|String
name|deltaPrefix
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|filename
init|=
name|deltaDir
operator|.
name|getName
argument_list|()
decl_stmt|;
name|boolean
name|isDeleteDelta
init|=
name|deltaPrefix
operator|.
name|equals
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|deltaPrefix
argument_list|)
condition|)
block|{
comment|//small optimization - delete delta can't be in raw format
name|boolean
name|isRawFormat
init|=
operator|!
name|isDeleteDelta
operator|&&
name|MetaDataFile
operator|.
name|isRawFormat
argument_list|(
name|deltaDir
argument_list|,
name|fs
argument_list|)
decl_stmt|;
return|return
name|parsedDelta
argument_list|(
name|deltaDir
argument_list|,
name|isRawFormat
argument_list|)
return|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|deltaDir
operator|+
literal|" does not start with "
operator|+
name|deltaPrefix
argument_list|)
throw|;
block|}
comment|/**    * This method just parses the file name.  It relies on caller to figure if    * the file is in Acid format (i.e. has acid metadata columns) or not.    * {@link #parsedDelta(Path, FileSystem)}    */
specifier|public
specifier|static
name|ParsedDelta
name|parsedDelta
parameter_list|(
name|Path
name|deltaDir
parameter_list|,
name|boolean
name|isRawFormat
parameter_list|)
block|{
name|String
name|filename
init|=
name|deltaDir
operator|.
name|getName
argument_list|()
decl_stmt|;
name|int
name|idxOfVis
init|=
name|filename
operator|.
name|indexOf
argument_list|(
name|VISIBILITY_PREFIX
argument_list|)
decl_stmt|;
name|long
name|visibilityTxnId
init|=
literal|0
decl_stmt|;
comment|//visibilityTxnId:0 is always visible
if|if
condition|(
name|idxOfVis
operator|>=
literal|0
condition|)
block|{
name|visibilityTxnId
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|filename
operator|.
name|substring
argument_list|(
name|idxOfVis
operator|+
name|VISIBILITY_PREFIX
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|filename
operator|=
name|filename
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|idxOfVis
argument_list|)
expr_stmt|;
block|}
name|boolean
name|isDeleteDelta
init|=
name|filename
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
decl_stmt|;
comment|//make sure it's null for delete delta no matter what was passed in - this
comment|//doesn't apply to delete deltas
name|isRawFormat
operator|=
name|isDeleteDelta
condition|?
literal|false
else|:
name|isRawFormat
expr_stmt|;
name|String
name|rest
init|=
name|filename
operator|.
name|substring
argument_list|(
operator|(
name|isDeleteDelta
condition|?
name|DELETE_DELTA_PREFIX
else|:
name|DELTA_PREFIX
operator|)
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|split
init|=
name|rest
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|)
decl_stmt|;
comment|//split2 may be -1 if no statementId
name|int
name|split2
init|=
name|rest
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|,
name|split
operator|+
literal|1
argument_list|)
decl_stmt|;
name|long
name|min
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|split
argument_list|)
argument_list|)
decl_stmt|;
name|long
name|max
init|=
name|split2
operator|==
operator|-
literal|1
condition|?
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split
operator|+
literal|1
argument_list|)
argument_list|)
else|:
name|Long
operator|.
name|parseLong
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split
operator|+
literal|1
argument_list|,
name|split2
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|split2
operator|==
operator|-
literal|1
condition|)
block|{
return|return
operator|new
name|ParsedDelta
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
literal|null
argument_list|,
name|isDeleteDelta
argument_list|,
name|isRawFormat
argument_list|,
name|visibilityTxnId
argument_list|)
return|;
block|}
name|int
name|statementId
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|rest
operator|.
name|substring
argument_list|(
name|split2
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|ParsedDelta
argument_list|(
name|min
argument_list|,
name|max
argument_list|,
literal|null
argument_list|,
name|statementId
argument_list|,
name|isDeleteDelta
argument_list|,
name|isRawFormat
argument_list|,
name|visibilityTxnId
argument_list|)
return|;
block|}
comment|/**    * Is the given directory in ACID format?    * @param directory the partition directory to check    * @param conf the query configuration    * @return true, if it is an ACID directory    * @throws IOException    */
specifier|public
specifier|static
name|boolean
name|isAcid
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|isAcid
argument_list|(
literal|null
argument_list|,
name|directory
argument_list|,
name|conf
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isAcid
parameter_list|(
name|FileSystem
name|fileSystem
parameter_list|,
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|fileSystem
operator|==
literal|null
condition|?
name|directory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
else|:
name|fileSystem
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|directory
argument_list|)
control|)
block|{
name|String
name|filename
init|=
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|filename
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|||
name|filename
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|||
name|filename
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
if|if
condition|(
name|file
operator|.
name|isDir
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
name|directory
argument_list|,
name|conf
argument_list|,
name|writeIdList
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/** State class for getChildState; cannot modify 2 things in a method. */
specifier|private
specifier|static
class|class
name|TxnBase
block|{
specifier|private
name|FileStatus
name|status
decl_stmt|;
specifier|private
name|long
name|writeId
init|=
literal|0
decl_stmt|;
specifier|private
name|long
name|oldestBaseWriteId
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
specifier|private
name|Path
name|oldestBase
init|=
literal|null
decl_stmt|;
block|}
comment|/**    * Get the ACID state of the given directory. It finds the minimal set of    * base and diff directories. Note that because major compactions don't    * preserve the history, we can't use a base directory that includes a    * write id that we must exclude.    * @param directory the partition directory to analyze    * @param conf the configuration    * @param writeIdList the list of write ids that we are reading    * @return the state of the directory    * @throws IOException    */
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|,
name|boolean
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
name|directory
argument_list|,
name|conf
argument_list|,
name|writeIdList
argument_list|,
name|Ref
operator|.
name|from
argument_list|(
name|useFileIds
argument_list|)
argument_list|,
name|ignoreEmptyFiles
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|FileSystem
name|fileSystem
parameter_list|,
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|,
name|boolean
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
name|fileSystem
argument_list|,
name|directory
argument_list|,
name|conf
argument_list|,
name|writeIdList
argument_list|,
name|Ref
operator|.
name|from
argument_list|(
name|useFileIds
argument_list|)
argument_list|,
name|ignoreEmptyFiles
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|,
name|Ref
argument_list|<
name|Boolean
argument_list|>
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getAcidState
argument_list|(
literal|null
argument_list|,
name|directory
argument_list|,
name|conf
argument_list|,
name|writeIdList
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|,
name|tblproperties
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Directory
name|getAcidState
parameter_list|(
name|FileSystem
name|fileSystem
parameter_list|,
name|Path
name|directory
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|,
name|Ref
argument_list|<
name|Boolean
argument_list|>
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|)
throws|throws
name|IOException
block|{
name|ValidTxnList
name|validTxnList
init|=
literal|null
decl_stmt|;
name|String
name|s
init|=
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|Strings
operator|.
name|isNullOrEmpty
argument_list|(
name|s
argument_list|)
condition|)
block|{
comment|/**        * getAcidState() is sometimes called on non-transactional tables, e.g.        * OrcInputFileFormat.FileGenerator.callInternal().  e.g. orc_merge3.q In that case        * writeIdList is bogus - doesn't even have a table name.        * see https://issues.apache.org/jira/browse/HIVE-20856.        *        * For now, assert that ValidTxnList.VALID_TXNS_KEY is set only if this is really a read        * of a transactional table.        * see {@link #getChildState(FileStatus, HdfsFileStatusWithId, ValidWriteIdList, List, List, List, List, TxnBase, boolean, List, Map, FileSystem, ValidTxnList)}        */
name|validTxnList
operator|=
operator|new
name|ValidReadTxnList
argument_list|()
expr_stmt|;
name|validTxnList
operator|.
name|readFromString
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|FileSystem
name|fs
init|=
name|fileSystem
operator|==
literal|null
condition|?
name|directory
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
else|:
name|fileSystem
decl_stmt|;
comment|// The following 'deltas' includes all kinds of delta files including insert& delete deltas.
specifier|final
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|deltas
init|=
operator|new
name|ArrayList
argument_list|<
name|ParsedDelta
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|working
init|=
operator|new
name|ArrayList
argument_list|<
name|ParsedDelta
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|originalDirectories
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|obsolete
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|abortedDirectories
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
name|tryListLocatedHdfsStatus
argument_list|(
name|useFileIds
argument_list|,
name|fs
argument_list|,
name|directory
argument_list|)
decl_stmt|;
name|TxnBase
name|bestBase
init|=
operator|new
name|TxnBase
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|childrenWithId
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|childrenWithId
control|)
block|{
name|getChildState
argument_list|(
name|child
operator|.
name|getFileStatus
argument_list|()
argument_list|,
name|child
argument_list|,
name|writeIdList
argument_list|,
name|working
argument_list|,
name|originalDirectories
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|bestBase
argument_list|,
name|ignoreEmptyFiles
argument_list|,
name|abortedDirectories
argument_list|,
name|tblproperties
argument_list|,
name|fs
argument_list|,
name|validTxnList
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|HdfsUtils
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|directory
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|getChildState
argument_list|(
name|child
argument_list|,
literal|null
argument_list|,
name|writeIdList
argument_list|,
name|working
argument_list|,
name|originalDirectories
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|bestBase
argument_list|,
name|ignoreEmptyFiles
argument_list|,
name|abortedDirectories
argument_list|,
name|tblproperties
argument_list|,
name|fs
argument_list|,
name|validTxnList
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we have a base, the original files are obsolete.
if|if
condition|(
name|bestBase
operator|.
name|status
operator|!=
literal|null
condition|)
block|{
comment|// Add original files to obsolete list if any
for|for
control|(
name|HdfsFileStatusWithId
name|fswid
range|:
name|original
control|)
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|fswid
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Add original directories to obsolete list if any
name|obsolete
operator|.
name|addAll
argument_list|(
name|originalDirectories
argument_list|)
expr_stmt|;
comment|// remove the entries so we don't get confused later and think we should
comment|// use them.
name|original
operator|.
name|clear
argument_list|()
expr_stmt|;
name|originalDirectories
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Okay, we're going to need these originals.  Recurse through them and figure out what we
comment|// really need.
for|for
control|(
name|Path
name|origDir
range|:
name|originalDirectories
control|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|origDir
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
name|Collections
operator|.
name|sort
argument_list|(
name|working
argument_list|)
expr_stmt|;
comment|//so now, 'working' should be sorted like delta_5_20 delta_5_10 delta_11_20 delta_51_60 for example
comment|//and we want to end up with the best set containing all relevant data: delta_5_20 delta_51_60,
comment|//subject to list of 'exceptions' in 'writeIdList' (not show in above example).
name|long
name|current
init|=
name|bestBase
operator|.
name|writeId
decl_stmt|;
name|int
name|lastStmtId
init|=
operator|-
literal|1
decl_stmt|;
name|ParsedDelta
name|prev
init|=
literal|null
decl_stmt|;
for|for
control|(
name|ParsedDelta
name|next
range|:
name|working
control|)
block|{
if|if
condition|(
name|next
operator|.
name|maxWriteId
operator|>
name|current
condition|)
block|{
comment|// are any of the new transactions ones that we care about?
if|if
condition|(
name|writeIdList
operator|.
name|isWriteIdRangeValid
argument_list|(
name|current
operator|+
literal|1
argument_list|,
name|next
operator|.
name|maxWriteId
argument_list|)
operator|!=
name|ValidWriteIdList
operator|.
name|RangeResponse
operator|.
name|NONE
condition|)
block|{
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|current
operator|=
name|next
operator|.
name|maxWriteId
expr_stmt|;
name|lastStmtId
operator|=
name|next
operator|.
name|statementId
expr_stmt|;
name|prev
operator|=
name|next
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|next
operator|.
name|maxWriteId
operator|==
name|current
operator|&&
name|lastStmtId
operator|>=
literal|0
condition|)
block|{
comment|//make sure to get all deltas within a single transaction;  multi-statement txn
comment|//generate multiple delta files with the same txnId range
comment|//of course, if maxWriteId has already been minor compacted, all per statement deltas are obsolete
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|prev
operator|=
name|next
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|prev
operator|!=
literal|null
operator|&&
name|next
operator|.
name|maxWriteId
operator|==
name|prev
operator|.
name|maxWriteId
operator|&&
name|next
operator|.
name|minWriteId
operator|==
name|prev
operator|.
name|minWriteId
operator|&&
name|next
operator|.
name|statementId
operator|==
name|prev
operator|.
name|statementId
condition|)
block|{
comment|// The 'next' parsedDelta may have everything equal to the 'prev' parsedDelta, except
comment|// the path. This may happen when we have split update and we have two types of delta
comment|// directories- 'delta_x_y' and 'delete_delta_x_y' for the SAME txn range.
comment|// Also note that any delete_deltas in between a given delta_x_y range would be made
comment|// obsolete. For example, a delta_30_50 would make delete_delta_40_40 obsolete.
comment|// This is valid because minor compaction always compacts the normal deltas and the delete
comment|// deltas for the same range. That is, if we had 3 directories, delta_30_30,
comment|// delete_delta_40_40 and delta_50_50, then running minor compaction would produce
comment|// delta_30_50 and delete_delta_30_50.
name|deltas
operator|.
name|add
argument_list|(
name|next
argument_list|)
expr_stmt|;
name|prev
operator|=
name|next
expr_stmt|;
block|}
else|else
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|next
operator|.
name|path
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|bestBase
operator|.
name|oldestBase
operator|!=
literal|null
operator|&&
name|bestBase
operator|.
name|status
operator|==
literal|null
operator|&&
name|isCompactedBase
argument_list|(
name|ParsedBase
operator|.
name|parseBase
argument_list|(
name|bestBase
operator|.
name|oldestBase
argument_list|)
argument_list|,
name|fs
argument_list|)
condition|)
block|{
comment|/**        * If here, it means there was a base_x (> 1 perhaps) but none were suitable for given        * {@link writeIdList}.  Note that 'original' files are logically a base_Long.MIN_VALUE and thus        * cannot have any data for an open txn.  We could check {@link deltas} has files to cover        * [1,n] w/o gaps but this would almost never happen...        *        * We only throw for base_x produced by Compactor since that base erases all history and        * cannot be used for a client that has a snapshot in which something inside this base is        * open.  (Nor can we ignore this base of course)  But base_x which is a result of IOW,        * contains all history so we treat it just like delta wrt visibility.  Imagine, IOW which        * aborts. It creates a base_x, which can and should just be ignored.*/
name|long
index|[]
name|exceptions
init|=
name|writeIdList
operator|.
name|getInvalidWriteIds
argument_list|()
decl_stmt|;
name|String
name|minOpenWriteId
init|=
name|exceptions
operator|!=
literal|null
operator|&&
name|exceptions
operator|.
name|length
operator|>
literal|0
condition|?
name|Long
operator|.
name|toString
argument_list|(
name|exceptions
index|[
literal|0
index|]
argument_list|)
else|:
literal|"x"
decl_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|ACID_NOT_ENOUGH_HISTORY
operator|.
name|format
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|writeIdList
operator|.
name|getHighWatermark
argument_list|()
argument_list|)
argument_list|,
name|minOpenWriteId
argument_list|,
name|bestBase
operator|.
name|oldestBase
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|base
init|=
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|?
literal|null
else|:
name|bestBase
operator|.
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"in directory "
operator|+
name|directory
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" base = "
operator|+
name|base
operator|+
literal|" deltas = "
operator|+
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|/**      * If this sort order is changed and there are tables that have been converted to transactional      * and have had any update/delete/merge operations performed but not yet MAJOR compacted, it      * may result in data loss since it may change how      * {@link org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.OriginalReaderPair} assigns      * {@link RecordIdentifier#rowId} for read (that have happened) and compaction (yet to happen).      */
name|Collections
operator|.
name|sort
argument_list|(
name|original
argument_list|,
parameter_list|(
name|HdfsFileStatusWithId
name|o1
parameter_list|,
name|HdfsFileStatusWithId
name|o2
parameter_list|)
lambda|->
block|{
comment|//this does "Path.uri.compareTo(that.uri)"
return|return
name|o1
operator|.
name|getFileStatus
argument_list|()
operator|.
name|compareTo
argument_list|(
name|o2
operator|.
name|getFileStatus
argument_list|()
argument_list|)
return|;
block|}
argument_list|)
expr_stmt|;
comment|// Note: isRawFormat is invalid for non-ORC tables. It will always return true, so we're good.
specifier|final
name|boolean
name|isBaseInRawFormat
init|=
name|base
operator|!=
literal|null
operator|&&
name|MetaDataFile
operator|.
name|isRawFormat
argument_list|(
name|base
argument_list|,
name|fs
argument_list|)
decl_stmt|;
return|return
operator|new
name|DirectoryImpl
argument_list|(
name|abortedDirectories
argument_list|,
name|isBaseInRawFormat
argument_list|,
name|original
argument_list|,
name|obsolete
argument_list|,
name|deltas
argument_list|,
name|base
argument_list|)
return|;
block|}
comment|/**    * We can only use a 'base' if it doesn't have an open txn (from specific reader's point of view)    * A 'base' with open txn in its range doesn't have 'enough history' info to produce a correct    * snapshot for this reader.    * Note that such base is NOT obsolete.  Obsolete files are those that are "covered" by other    * files within the snapshot.    * A base produced by Insert Overwrite is different.  Logically it's a delta file but one that    * causes anything written previously to be ignored (hence the overwrite).  In this case, base_x    * is visible if writeid:x is committed for current reader.    */
specifier|private
specifier|static
name|boolean
name|isValidBase
parameter_list|(
name|ParsedBase
name|parsedBase
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|parsedBase
operator|.
name|getWriteId
argument_list|()
operator|==
name|Long
operator|.
name|MIN_VALUE
condition|)
block|{
comment|//such base is created by 1st compaction in case of non-acid to acid table conversion
comment|//By definition there are no open txns with id< 1.
return|return
literal|true
return|;
block|}
if|if
condition|(
name|isCompactedBase
argument_list|(
name|parsedBase
argument_list|,
name|fs
argument_list|)
condition|)
block|{
return|return
name|writeIdList
operator|.
name|isValidBase
argument_list|(
name|parsedBase
operator|.
name|getWriteId
argument_list|()
argument_list|)
return|;
block|}
comment|//if here, it's a result of IOW
return|return
name|writeIdList
operator|.
name|isWriteIdValid
argument_list|(
name|parsedBase
operator|.
name|getWriteId
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Returns {@code true} if {@code parsedBase} was created by compaction.    * As of Hive 4.0 we can tell if a directory is a result of compaction based on the    * presence of {@link AcidUtils#VISIBILITY_PATTERN} suffix.  Base directories written prior to    * that, have to rely on the {@link MetaDataFile} in the directory. So look at the filename first    * since that is the cheaper test.*/
specifier|private
specifier|static
name|boolean
name|isCompactedBase
parameter_list|(
name|ParsedBase
name|parsedBase
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|parsedBase
operator|.
name|getVisibilityTxnId
argument_list|()
operator|>
literal|0
operator|||
name|MetaDataFile
operator|.
name|isCompacted
argument_list|(
name|parsedBase
operator|.
name|getBaseDirPath
argument_list|()
argument_list|,
name|fs
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|void
name|getChildState
parameter_list|(
name|FileStatus
name|child
parameter_list|,
name|HdfsFileStatusWithId
name|childWithId
parameter_list|,
name|ValidWriteIdList
name|writeIdList
parameter_list|,
name|List
argument_list|<
name|ParsedDelta
argument_list|>
name|working
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|originalDirectories
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|obsolete
parameter_list|,
name|TxnBase
name|bestBase
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|aborted
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|ValidTxnList
name|validTxnList
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|child
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|String
name|fn
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|child
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|ignoreEmptyFiles
operator|||
name|child
operator|.
name|getLen
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|original
operator|.
name|add
argument_list|(
name|createOriginalObj
argument_list|(
name|childWithId
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
if|if
condition|(
name|fn
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
name|ParsedBase
name|parsedBase
init|=
name|ParsedBase
operator|.
name|parseBase
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|isDirUsable
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|,
name|parsedBase
operator|.
name|getVisibilityTxnId
argument_list|()
argument_list|,
name|aborted
argument_list|,
name|validTxnList
argument_list|)
condition|)
block|{
return|return;
block|}
specifier|final
name|long
name|writeId
init|=
name|parsedBase
operator|.
name|getWriteId
argument_list|()
decl_stmt|;
if|if
condition|(
name|bestBase
operator|.
name|oldestBaseWriteId
operator|>
name|writeId
condition|)
block|{
comment|//keep track for error reporting
name|bestBase
operator|.
name|oldestBase
operator|=
name|p
expr_stmt|;
name|bestBase
operator|.
name|oldestBaseWriteId
operator|=
name|writeId
expr_stmt|;
block|}
if|if
condition|(
name|bestBase
operator|.
name|status
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|isValidBase
argument_list|(
name|parsedBase
argument_list|,
name|writeIdList
argument_list|,
name|fs
argument_list|)
condition|)
block|{
name|bestBase
operator|.
name|status
operator|=
name|child
expr_stmt|;
name|bestBase
operator|.
name|writeId
operator|=
name|writeId
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|bestBase
operator|.
name|writeId
operator|<
name|writeId
condition|)
block|{
if|if
condition|(
name|isValidBase
argument_list|(
name|parsedBase
argument_list|,
name|writeIdList
argument_list|,
name|fs
argument_list|)
condition|)
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|bestBase
operator|.
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|bestBase
operator|.
name|status
operator|=
name|child
expr_stmt|;
name|bestBase
operator|.
name|writeId
operator|=
name|writeId
expr_stmt|;
block|}
block|}
else|else
block|{
name|obsolete
operator|.
name|add
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|fn
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|||
name|fn
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
name|String
name|deltaPrefix
init|=
name|fn
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
condition|?
name|DELTA_PREFIX
else|:
name|DELETE_DELTA_PREFIX
decl_stmt|;
name|ParsedDelta
name|delta
init|=
name|parseDelta
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|,
name|deltaPrefix
argument_list|,
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|isDirUsable
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|,
name|delta
operator|.
name|getVisibilityTxnId
argument_list|()
argument_list|,
name|aborted
argument_list|,
name|validTxnList
argument_list|)
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|ValidWriteIdList
operator|.
name|RangeResponse
operator|.
name|ALL
operator|==
name|writeIdList
operator|.
name|isWriteIdRangeAborted
argument_list|(
name|delta
operator|.
name|minWriteId
argument_list|,
name|delta
operator|.
name|maxWriteId
argument_list|)
condition|)
block|{
name|aborted
operator|.
name|add
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|writeIdList
operator|.
name|isWriteIdRangeValid
argument_list|(
name|delta
operator|.
name|minWriteId
argument_list|,
name|delta
operator|.
name|maxWriteId
argument_list|)
operator|!=
name|ValidWriteIdList
operator|.
name|RangeResponse
operator|.
name|NONE
condition|)
block|{
name|working
operator|.
name|add
argument_list|(
name|delta
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// This is just the directory.  We need to recurse and find the actual files.  But don't
comment|// do this until we have determined there is no base.  This saves time.  Plus,
comment|// it is possible that the cleaner is running and removing these original files,
comment|// in which case recursing through them could cause us to get an error.
name|originalDirectories
operator|.
name|add
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * checks {@code visibilityTxnId} to see if {@code child} is committed in current snapshot    */
specifier|private
specifier|static
name|boolean
name|isDirUsable
parameter_list|(
name|Path
name|child
parameter_list|,
name|long
name|visibilityTxnId
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|aborted
parameter_list|,
name|ValidTxnList
name|validTxnList
parameter_list|)
block|{
if|if
condition|(
name|validTxnList
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"No ValidTxnList for "
operator|+
name|child
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|validTxnList
operator|.
name|isTxnValid
argument_list|(
name|visibilityTxnId
argument_list|)
condition|)
block|{
name|boolean
name|isAborted
init|=
name|validTxnList
operator|.
name|isTxnAborted
argument_list|(
name|visibilityTxnId
argument_list|)
decl_stmt|;
if|if
condition|(
name|isAborted
condition|)
block|{
name|aborted
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
comment|//so we can clean it up
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"getChildState() ignoring("
operator|+
name|aborted
operator|+
literal|") "
operator|+
name|child
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|HdfsFileStatusWithId
name|createOriginalObj
parameter_list|(
name|HdfsFileStatusWithId
name|childWithId
parameter_list|,
name|FileStatus
name|child
parameter_list|)
block|{
return|return
name|childWithId
operator|!=
literal|null
condition|?
name|childWithId
else|:
operator|new
name|HdfsFileStatusWithoutId
argument_list|(
name|child
argument_list|)
return|;
block|}
specifier|private
specifier|static
class|class
name|HdfsFileStatusWithoutId
implements|implements
name|HdfsFileStatusWithId
block|{
specifier|private
specifier|final
name|FileStatus
name|fs
decl_stmt|;
specifier|public
name|HdfsFileStatusWithoutId
parameter_list|(
name|FileStatus
name|fs
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|FileStatus
name|getFileStatus
parameter_list|()
block|{
return|return
name|fs
return|;
block|}
annotation|@
name|Override
specifier|public
name|Long
name|getFileId
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Find the original files (non-ACID layout) recursively under the partition directory.    * @param fs the file system    * @param dir the directory to add    * @param original the list of original files    * @throws IOException    */
specifier|public
specifier|static
name|void
name|findOriginals
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|original
parameter_list|,
name|Ref
argument_list|<
name|Boolean
argument_list|>
name|useFileIds
parameter_list|,
name|boolean
name|ignoreEmptyFiles
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
name|tryListLocatedHdfsStatus
argument_list|(
name|useFileIds
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|childrenWithId
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HdfsFileStatusWithId
name|child
range|:
name|childrenWithId
control|)
block|{
if|if
condition|(
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|recursive
condition|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|ignoreEmptyFiles
operator|||
name|child
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|original
operator|.
name|add
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
else|else
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|children
init|=
name|HdfsUtils
operator|.
name|listLocatedStatus
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
if|if
condition|(
name|child
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|recursive
condition|)
block|{
name|findOriginals
argument_list|(
name|fs
argument_list|,
name|child
operator|.
name|getPath
argument_list|()
argument_list|,
name|original
argument_list|,
name|useFileIds
argument_list|,
name|ignoreEmptyFiles
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|ignoreEmptyFiles
operator|||
name|child
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|original
operator|.
name|add
argument_list|(
name|createOriginalObj
argument_list|(
literal|null
argument_list|,
name|child
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
specifier|private
specifier|static
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|tryListLocatedHdfsStatus
parameter_list|(
name|Ref
argument_list|<
name|Boolean
argument_list|>
name|useFileIds
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|directory
parameter_list|)
block|{
name|Boolean
name|val
init|=
name|useFileIds
operator|.
name|value
decl_stmt|;
name|List
argument_list|<
name|HdfsFileStatusWithId
argument_list|>
name|childrenWithId
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
name|val
condition|)
block|{
try|try
block|{
name|childrenWithId
operator|=
name|SHIMS
operator|.
name|listLocatedHdfsStatus
argument_list|(
name|fs
argument_list|,
name|directory
argument_list|,
name|hiddenFileFilter
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|useFileIds
operator|.
name|value
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get files with ID; using regular API: "
operator|+
name|t
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|&&
name|t
operator|instanceof
name|UnsupportedOperationException
condition|)
block|{
name|useFileIds
operator|.
name|value
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
return|return
name|childrenWithId
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTablePropertyTransactional
parameter_list|(
name|Properties
name|props
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|props
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
name|resultStr
operator|=
name|props
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|resultStr
operator|!=
literal|null
operator|&&
name|resultStr
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTablePropertyTransactional
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|parameters
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
name|resultStr
operator|=
name|parameters
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|resultStr
operator|!=
literal|null
operator|&&
name|resultStr
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTablePropertyTransactional
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|conf
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
name|resultStr
operator|=
name|conf
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|resultStr
operator|!=
literal|null
operator|&&
name|resultStr
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
comment|/**    * @param p - not null    */
specifier|public
specifier|static
name|boolean
name|isDeleteDelta
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
return|return
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELETE_DELTA_PREFIX
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isInsertDelta
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
return|return
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|CreateTableDesc
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
operator|||
name|table
operator|.
name|getTblProps
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|isTransactionalTable
argument_list|(
name|table
operator|.
name|getTblProps
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
parameter_list|)
block|{
name|String
name|tableIsTransactional
init|=
name|props
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableIsTransactional
operator|==
literal|null
condition|)
block|{
name|tableIsTransactional
operator|=
name|props
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|tableIsTransactional
operator|!=
literal|null
operator|&&
name|tableIsTransactional
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
comment|/**    * Should produce the same result as    * {@link org.apache.hadoop.hive.metastore.txn.TxnUtils#isAcidTable(org.apache.hadoop.hive.metastore.api.Table)}    */
specifier|public
specifier|static
name|boolean
name|isFullAcidTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
return|return
name|isFullAcidTable
argument_list|(
name|table
operator|==
literal|null
condition|?
literal|null
else|:
name|table
operator|.
name|getTTable
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
return|return
name|isTransactionalTable
argument_list|(
name|table
operator|==
literal|null
condition|?
literal|null
else|:
name|table
operator|.
name|getTTable
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Should produce the same result as    * {@link org.apache.hadoop.hive.metastore.txn.TxnUtils#isAcidTable(org.apache.hadoop.hive.metastore.api.Table)}    */
specifier|public
specifier|static
name|boolean
name|isFullAcidTable
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|isTransactionalTable
argument_list|(
name|table
argument_list|)
operator|&&
operator|!
name|isInsertOnlyTable
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isFullAcidTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
return|return
name|isTransactionalTable
argument_list|(
name|params
argument_list|)
operator|&&
operator|!
name|isInsertOnlyTable
argument_list|(
name|params
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isTransactionalTable
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|table
operator|!=
literal|null
operator|&&
name|table
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
operator|&&
name|isTablePropertyTransactional
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isFullAcidTable
parameter_list|(
name|CreateTableDesc
name|td
parameter_list|)
block|{
if|if
condition|(
name|td
operator|==
literal|null
operator|||
name|td
operator|.
name|getTblProps
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|String
name|tableIsTransactional
init|=
name|td
operator|.
name|getTblProps
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableIsTransactional
operator|==
literal|null
condition|)
block|{
name|tableIsTransactional
operator|=
name|td
operator|.
name|getTblProps
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|tableIsTransactional
operator|!=
literal|null
operator|&&
name|tableIsTransactional
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
operator|&&
operator|!
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|td
operator|.
name|getTblProps
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isFullAcidScan
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
name|int
name|propInt
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
operator|.
name|varname
argument_list|,
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|propInt
operator|==
operator|-
literal|1
condition|)
block|{
return|return
literal|true
return|;
block|}
name|AcidOperationalProperties
name|props
init|=
name|AcidOperationalProperties
operator|.
name|parseInt
argument_list|(
name|propInt
argument_list|)
decl_stmt|;
return|return
operator|!
name|props
operator|.
name|isInsertOnly
argument_list|()
return|;
block|}
comment|/**    * Sets the acidOperationalProperties in the configuration object argument.    * @param conf Mutable configuration object    * @param properties An acidOperationalProperties object to initialize from. If this is null,    *                   we assume this is a full transactional table.    */
specifier|public
specifier|static
name|void
name|setAcidOperationalProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|isTxnTable
parameter_list|,
name|AcidOperationalProperties
name|properties
parameter_list|)
block|{
if|if
condition|(
name|isTxnTable
condition|)
block|{
name|HiveConf
operator|.
name|setBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
argument_list|,
name|isTxnTable
argument_list|)
expr_stmt|;
if|if
condition|(
name|properties
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
argument_list|,
name|properties
operator|.
name|toInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|conf
operator|.
name|unset
argument_list|(
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
operator|.
name|varname
argument_list|)
expr_stmt|;
name|conf
operator|.
name|unset
argument_list|(
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
operator|.
name|varname
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Sets the acidOperationalProperties in the map object argument.    * @param parameters Mutable map object    * @param properties An acidOperationalProperties object to initialize from.    */
specifier|public
specifier|static
name|void
name|setAcidOperationalProperties
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|boolean
name|isTxnTable
parameter_list|,
name|AcidOperationalProperties
name|properties
parameter_list|)
block|{
name|parameters
operator|.
name|put
argument_list|(
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
operator|.
name|varname
argument_list|,
name|Boolean
operator|.
name|toString
argument_list|(
name|isTxnTable
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|properties
operator|!=
literal|null
condition|)
block|{
name|parameters
operator|.
name|put
argument_list|(
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
operator|.
name|varname
argument_list|,
name|properties
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Returns the acidOperationalProperties for a given table.    * @param table A table object    * @return the acidOperationalProperties object for the corresponding table.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
name|String
name|transactionalProperties
init|=
name|table
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactionalProperties
operator|==
literal|null
condition|)
block|{
comment|// If the table does not define any transactional properties, we return a default type.
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
return|return
name|AcidOperationalProperties
operator|.
name|parseString
argument_list|(
name|transactionalProperties
argument_list|)
return|;
block|}
comment|/**    * Returns the acidOperationalProperties for a given configuration.    * @param conf A configuration object    * @return the acidOperationalProperties object for the corresponding configuration.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
comment|// If the conf does not define any transactional properties, the parseInt() should receive
comment|// a value of 1, which will set AcidOperationalProperties to a default type and return that.
return|return
name|AcidOperationalProperties
operator|.
name|parseInt
argument_list|(
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TXN_OPERATIONAL_PROPERTIES
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns the acidOperationalProperties for a given set of properties.    * @param props A properties object    * @return the acidOperationalProperties object for the corresponding properties.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Properties
name|props
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|props
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
comment|// If the properties does not define any transactional properties, we return a default type.
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
return|return
name|AcidOperationalProperties
operator|.
name|parseString
argument_list|(
name|resultStr
argument_list|)
return|;
block|}
comment|/**    * Returns the acidOperationalProperties for a given map.    * @param parameters A parameters object    * @return the acidOperationalProperties object for the corresponding map.    */
specifier|public
specifier|static
name|AcidOperationalProperties
name|getAcidOperationalProperties
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
block|{
name|String
name|resultStr
init|=
name|parameters
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|resultStr
operator|==
literal|null
condition|)
block|{
comment|// If the parameters does not define any transactional properties, we return a default type.
return|return
name|AcidOperationalProperties
operator|.
name|getDefault
argument_list|()
return|;
block|}
return|return
name|AcidOperationalProperties
operator|.
name|parseString
argument_list|(
name|resultStr
argument_list|)
return|;
block|}
comment|/**    * See comments at {@link AcidUtils#DELTA_SIDE_FILE_SUFFIX}.    *    * Returns the logical end of file for an acid data file.    *    * This relies on the fact that if delta_x_y has no committed transactions it wil be filtered out    * by {@link #getAcidState(Path, Configuration, ValidWriteIdList)} and so won't be read at all.    * @param file - data file to read/compute splits on    */
specifier|public
specifier|static
name|long
name|getLogicalLength
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|file
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|acidDir
init|=
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getParent
argument_list|()
decl_stmt|;
comment|//should be base_x or delta_x_y_
if|if
condition|(
name|AcidUtils
operator|.
name|isInsertDelta
argument_list|(
name|acidDir
argument_list|)
condition|)
block|{
name|ParsedDeltaLight
name|pd
init|=
name|ParsedDeltaLight
operator|.
name|parse
argument_list|(
name|acidDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|pd
operator|.
name|mayContainSideFile
argument_list|()
condition|)
block|{
return|return
name|file
operator|.
name|getLen
argument_list|()
return|;
block|}
block|}
else|else
block|{
return|return
name|file
operator|.
name|getLen
argument_list|()
return|;
block|}
name|Path
name|lengths
init|=
name|OrcAcidUtils
operator|.
name|getSideFile
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|lengths
argument_list|)
condition|)
block|{
comment|/**        * if here for delta_x_y that means txn y is resolved and all files in this delta are closed so        * they should all have a valid ORC footer and info from NameNode about length is good        */
return|return
name|file
operator|.
name|getLen
argument_list|()
return|;
block|}
name|long
name|len
init|=
name|OrcAcidUtils
operator|.
name|getLastFlushLength
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|len
operator|>=
literal|0
condition|)
block|{
comment|/**        * if here something is still writing to delta_x_y so  read only as far as the last commit,        * i.e. where last footer was written.  The file may contain more data after 'len' position        * belonging to an open txn.        */
return|return
name|len
return|;
block|}
comment|/**      * if here, side file is there but we couldn't read it.  We want to avoid a read where      * (file.getLen()< 'value from side file' which may happen if file is not closed) because this      * means some committed data from 'file' would be skipped.      * This should be very unusual.      */
throw|throw
operator|new
name|IOException
argument_list|(
name|lengths
operator|+
literal|" found but is not readable.  Consider waiting or orcfiledump --recover"
argument_list|)
throw|;
block|}
comment|/**    * Checks if a table is a transactional table that only supports INSERT, but not UPDATE/DELETE    * @param params table properties    * @return true if table is an INSERT_ONLY table, false otherwise    */
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
return|return
name|isInsertOnlyTable
argument_list|(
name|params
argument_list|,
literal|false
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
return|return
name|isTransactionalTable
argument_list|(
name|table
argument_list|)
operator|&&
name|getAcidOperationalProperties
argument_list|(
name|table
argument_list|)
operator|.
name|isInsertOnly
argument_list|()
return|;
block|}
comment|// TODO [MM gap]: CTAS may currently be broken. It used to work. See the old code, and why isCtas isn't used?
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|,
name|boolean
name|isCtas
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isInsertOnlyTable
parameter_list|(
name|Properties
name|params
parameter_list|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|getProperty
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
operator|(
name|transactionalProp
operator|!=
literal|null
operator|&&
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
operator|)
return|;
block|}
comment|/**     * The method for altering table props; may set the table to MM, non-MM, or not affect MM.     * todo: All such validation logic should be TransactionValidationListener     * @param tbl object image before alter table command (or null if not retrieved yet).     * @param props prop values set in this alter table command     */
specifier|public
specifier|static
name|Boolean
name|isToInsertOnlyTable
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
parameter_list|)
block|{
comment|// Note: Setting these separately is a very hairy issue in certain combinations, since we
comment|//       cannot decide what type of table this becomes without taking both into account, and
comment|//       in many cases the conversion might be illegal.
comment|//       The only thing we allow is tx = true w/o tx-props, for backward compat.
name|String
name|transactional
init|=
name|props
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|;
name|String
name|transactionalProp
init|=
name|props
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactional
operator|==
literal|null
operator|&&
name|transactionalProp
operator|==
literal|null
condition|)
block|{
comment|// Not affected or the op is not about transactional.
return|return
literal|null
return|;
block|}
if|if
condition|(
name|transactional
operator|==
literal|null
operator|&&
name|tbl
operator|!=
literal|null
condition|)
block|{
name|transactional
operator|=
name|tbl
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
expr_stmt|;
block|}
name|boolean
name|isSetToTxn
init|=
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactional
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactionalProp
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|isSetToTxn
operator|||
name|tbl
operator|==
literal|null
condition|)
return|return
literal|false
return|;
comment|// Assume the full ACID table.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cannot change '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|+
literal|"' without '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
literal|"insert_only"
operator|.
name|equalsIgnoreCase
argument_list|(
name|transactionalProp
argument_list|)
condition|)
return|return
literal|false
return|;
comment|// Not MM.
if|if
condition|(
operator|!
name|isSetToTxn
condition|)
block|{
if|if
condition|(
name|tbl
operator|==
literal|null
condition|)
return|return
literal|true
return|;
comment|// No table information yet; looks like it could be valid.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cannot set '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
operator|+
literal|"' to 'insert_only' without "
operator|+
literal|"setting '"
operator|+
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
operator|+
literal|"' to 'true'"
argument_list|)
throw|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isRemovedInsertOnlyTable
parameter_list|(
name|Set
argument_list|<
name|String
argument_list|>
name|removedSet
parameter_list|)
block|{
name|boolean
name|hasTxn
init|=
name|removedSet
operator|.
name|contains
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|)
decl_stmt|,
name|hasProps
init|=
name|removedSet
operator|.
name|contains
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
decl_stmt|;
return|return
name|hasTxn
operator|||
name|hasProps
return|;
block|}
comment|/**    * Get the ValidTxnWriteIdList saved in the configuration.    */
specifier|public
specifier|static
name|ValidTxnWriteIdList
name|getValidTxnWriteIdList
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|txnString
init|=
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnWriteIdList
operator|.
name|VALID_TABLES_WRITEIDS_KEY
argument_list|)
decl_stmt|;
name|ValidTxnWriteIdList
name|validTxnList
init|=
operator|new
name|ValidTxnWriteIdList
argument_list|(
name|txnString
argument_list|)
decl_stmt|;
return|return
name|validTxnList
return|;
block|}
comment|/**    * Extract the ValidWriteIdList for the given table from the list of tables' ValidWriteIdList.    */
specifier|public
specifier|static
name|ValidWriteIdList
name|getTableValidWriteIdList
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|String
name|fullTableName
parameter_list|)
block|{
name|ValidTxnWriteIdList
name|validTxnList
init|=
name|getValidTxnWriteIdList
argument_list|(
name|conf
argument_list|)
decl_stmt|;
return|return
name|validTxnList
operator|.
name|getTableValidWriteIdList
argument_list|(
name|fullTableName
argument_list|)
return|;
block|}
comment|/**    * Set the valid write id list for the current table scan.    */
specifier|public
specifier|static
name|void
name|setValidWriteIdList
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ValidWriteIdList
name|validWriteIds
parameter_list|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|ValidWriteIdList
operator|.
name|VALID_WRITEIDS_KEY
argument_list|,
name|validWriteIds
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting ValidWriteIdList: "
operator|+
name|validWriteIds
operator|.
name|toString
argument_list|()
operator|+
literal|" isAcidTable: "
operator|+
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_TRANSACTIONAL_TABLE_SCAN
argument_list|,
literal|false
argument_list|)
operator|+
literal|" acidProperty: "
operator|+
name|getAcidOperationalProperties
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the valid write id list for the current table scan.    */
specifier|public
specifier|static
name|void
name|setValidWriteIdList
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|TableScanDesc
name|tsDesc
parameter_list|)
block|{
if|if
condition|(
name|tsDesc
operator|.
name|isTranscationalTable
argument_list|()
condition|)
block|{
name|String
name|dbName
init|=
name|tsDesc
operator|.
name|getDatabaseName
argument_list|()
decl_stmt|;
name|String
name|tableName
init|=
name|tsDesc
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|ValidWriteIdList
name|validWriteIdList
init|=
name|getTableValidWriteIdList
argument_list|(
name|conf
argument_list|,
name|AcidUtils
operator|.
name|getFullTableName
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|validWriteIdList
operator|!=
literal|null
condition|)
block|{
name|setValidWriteIdList
argument_list|(
name|conf
argument_list|,
name|validWriteIdList
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Log error if the acid table is missing from the ValidWriteIdList conf
name|LOG
operator|.
name|error
argument_list|(
literal|"setValidWriteIdList on table: "
operator|+
name|AcidUtils
operator|.
name|getFullTableName
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
operator|+
literal|" isAcidTable: "
operator|+
literal|true
operator|+
literal|" acidProperty: "
operator|+
name|getAcidOperationalProperties
argument_list|(
name|conf
argument_list|)
operator|+
literal|" couldn't find the ValidWriteId list from ValidTxnWriteIdList: "
operator|+
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnWriteIdList
operator|.
name|VALID_TABLES_WRITEIDS_KEY
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"ACID table: "
operator|+
name|AcidUtils
operator|.
name|getFullTableName
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
operator|+
literal|" is missing from the ValidWriteIdList config: "
operator|+
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnWriteIdList
operator|.
name|VALID_TABLES_WRITEIDS_KEY
argument_list|)
argument_list|)
throw|;
block|}
block|}
block|}
specifier|public
specifier|static
class|class
name|TableSnapshot
block|{
specifier|private
name|long
name|writeId
decl_stmt|;
specifier|private
name|String
name|validWriteIdList
decl_stmt|;
specifier|public
name|TableSnapshot
parameter_list|()
block|{     }
specifier|public
name|TableSnapshot
parameter_list|(
name|long
name|writeId
parameter_list|,
name|String
name|validWriteIdList
parameter_list|)
block|{
name|this
operator|.
name|writeId
operator|=
name|writeId
expr_stmt|;
name|this
operator|.
name|validWriteIdList
operator|=
name|validWriteIdList
expr_stmt|;
block|}
specifier|public
name|String
name|getValidWriteIdList
parameter_list|()
block|{
return|return
name|validWriteIdList
return|;
block|}
specifier|public
name|long
name|getWriteId
parameter_list|()
block|{
return|return
name|writeId
return|;
block|}
specifier|public
name|void
name|setWriteId
parameter_list|(
name|long
name|writeId
parameter_list|)
block|{
name|this
operator|.
name|writeId
operator|=
name|writeId
expr_stmt|;
block|}
specifier|public
name|void
name|setValidWriteIdList
parameter_list|(
name|String
name|validWriteIdList
parameter_list|)
block|{
name|this
operator|.
name|validWriteIdList
operator|=
name|validWriteIdList
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"[validWriteIdList="
operator|+
name|validWriteIdList
operator|+
literal|", writeId="
operator|+
name|writeId
operator|+
literal|"]"
return|;
block|}
block|}
specifier|public
specifier|static
name|TableSnapshot
name|getTableSnapshot
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Table
name|tbl
parameter_list|)
throws|throws
name|LockException
block|{
return|return
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/** Note: this is generally called in Hive.java; so, the callers of Hive.java make sure    *        to set up the acid state during compile, and Hive.java retrieves it if needed. */
specifier|public
specifier|static
name|TableSnapshot
name|getTableSnapshot
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|boolean
name|isStatsUpdater
parameter_list|)
throws|throws
name|LockException
block|{
return|return
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|,
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|isStatsUpdater
argument_list|)
return|;
block|}
comment|/** Note: this is generally called in Hive.java; so, the callers of Hive.java make sure    *        to set up the acid state during compile, and Hive.java retrieves it if needed. */
specifier|public
specifier|static
name|TableSnapshot
name|getTableSnapshot
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|boolean
name|isStatsUpdater
parameter_list|)
throws|throws
name|LockException
throws|,
name|AssertionError
block|{
if|if
condition|(
operator|!
name|isTransactionalTable
argument_list|(
name|tbl
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|dbName
operator|==
literal|null
condition|)
block|{
name|dbName
operator|=
name|tbl
operator|.
name|getDbName
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|tblName
operator|==
literal|null
condition|)
block|{
name|tblName
operator|=
name|tbl
operator|.
name|getTableName
argument_list|()
expr_stmt|;
block|}
name|long
name|writeId
init|=
operator|-
literal|1
decl_stmt|;
name|ValidWriteIdList
name|validWriteIdList
init|=
literal|null
decl_stmt|;
name|HiveTxnManager
name|sessionTxnMgr
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
decl_stmt|;
name|String
name|fullTableName
init|=
name|getFullTableName
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
if|if
condition|(
name|sessionTxnMgr
operator|!=
literal|null
operator|&&
name|sessionTxnMgr
operator|.
name|getCurrentTxnId
argument_list|()
operator|>
literal|0
condition|)
block|{
name|validWriteIdList
operator|=
name|getTableValidWriteIdList
argument_list|(
name|conf
argument_list|,
name|fullTableName
argument_list|)
expr_stmt|;
if|if
condition|(
name|isStatsUpdater
condition|)
block|{
name|writeId
operator|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|!=
literal|null
condition|?
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|.
name|getAllocatedTableWriteId
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
else|:
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|writeId
operator|<
literal|1
condition|)
block|{
comment|// TODO: this is not ideal... stats updater that doesn't have write ID is currently
comment|//       "create table"; writeId would be 0/-1 here. No need to call this w/true.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Stats updater for {}.{} doesn't have a write ID ({})"
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_IN_TEST
argument_list|)
operator|&&
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|)
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|validWriteIdList
operator|==
literal|null
condition|)
block|{
name|validWriteIdList
operator|=
name|getTableValidWriteIdListWithTxnList
argument_list|(
name|conf
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|validWriteIdList
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Cannot find valid write ID list for "
operator|+
name|tblName
argument_list|)
throw|;
block|}
block|}
return|return
operator|new
name|TableSnapshot
argument_list|(
name|writeId
argument_list|,
name|validWriteIdList
operator|!=
literal|null
condition|?
name|validWriteIdList
operator|.
name|toString
argument_list|()
else|:
literal|null
argument_list|)
return|;
block|}
comment|/**    * Returns ValidWriteIdList for the table with the given "dbName" and "tableName".    * This is called when HiveConf has no list for the table.    * Otherwise use getTableSnapshot().    * @param conf       Configuration    * @param dbName    * @param tableName    * @return ValidWriteIdList on success, null on failure to get a list.    * @throws LockException    */
specifier|public
specifier|static
name|ValidWriteIdList
name|getTableValidWriteIdListWithTxnList
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|)
throws|throws
name|LockException
block|{
name|HiveTxnManager
name|sessionTxnMgr
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
decl_stmt|;
if|if
condition|(
name|sessionTxnMgr
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|ValidWriteIdList
name|validWriteIdList
init|=
literal|null
decl_stmt|;
name|ValidTxnWriteIdList
name|validTxnWriteIdList
init|=
literal|null
decl_stmt|;
name|String
name|validTxnList
init|=
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|tablesInput
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|String
name|fullTableName
init|=
name|getFullTableName
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|tablesInput
operator|.
name|add
argument_list|(
name|fullTableName
argument_list|)
expr_stmt|;
name|validTxnWriteIdList
operator|=
name|sessionTxnMgr
operator|.
name|getValidWriteIds
argument_list|(
name|tablesInput
argument_list|,
name|validTxnList
argument_list|)
expr_stmt|;
return|return
name|validTxnWriteIdList
operator|!=
literal|null
condition|?
name|validTxnWriteIdList
operator|.
name|getTableValidWriteIdList
argument_list|(
name|fullTableName
argument_list|)
else|:
literal|null
return|;
block|}
specifier|public
specifier|static
name|String
name|getFullTableName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|)
block|{
return|return
name|TableName
operator|.
name|getDbTable
argument_list|(
name|dbName
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|tableName
operator|.
name|toLowerCase
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * General facility to place a metadta file into a dir created by acid/compactor write.    *    * Load Data commands against Acid tables write {@link AcidBaseFileType#ORIGINAL_BASE} type files    * into delta_x_x/ (or base_x in case there is Overwrite clause).  {@link MetaDataFile} is a    * small JSON file in this directory that indicates that these files don't have Acid metadata    * columns and so the values for these columns need to be assigned at read time/compaction.    */
specifier|public
specifier|static
class|class
name|MetaDataFile
block|{
comment|//export command uses _metadata....
specifier|private
specifier|static
specifier|final
name|String
name|METADATA_FILE
init|=
literal|"_metadata_acid"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|CURRENT_VERSION
init|=
literal|"0"
decl_stmt|;
comment|//todo: enums? that have both field name and value list
specifier|private
interface|interface
name|Field
block|{
name|String
name|VERSION
init|=
literal|"thisFileVersion"
decl_stmt|;
name|String
name|DATA_FORMAT
init|=
literal|"dataFormat"
decl_stmt|;
block|}
specifier|private
interface|interface
name|Value
block|{
comment|//written by Major compaction
name|String
name|COMPACTED
init|=
literal|"compacted"
decl_stmt|;
block|}
specifier|static
name|boolean
name|isCompacted
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
comment|/**        * this file was written by Hive versions before 4.0 into a base_x/ dir        * created by compactor so that it can be distinguished from the one        * created by Insert Overwrite        */
name|Path
name|formatFile
init|=
operator|new
name|Path
argument_list|(
name|baseOrDeltaDir
argument_list|,
name|METADATA_FILE
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|formatFile
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
try|try
init|(
name|FSDataInputStream
name|strm
init|=
name|fs
operator|.
name|open
argument_list|(
name|formatFile
argument_list|)
init|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metaData
init|=
operator|new
name|ObjectMapper
argument_list|()
operator|.
name|readValue
argument_list|(
name|strm
argument_list|,
name|Map
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|CURRENT_VERSION
operator|.
name|equalsIgnoreCase
argument_list|(
name|metaData
operator|.
name|get
argument_list|(
name|Field
operator|.
name|VERSION
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Unexpected Meta Data version: "
operator|+
name|metaData
operator|.
name|get
argument_list|(
name|Field
operator|.
name|VERSION
argument_list|)
argument_list|)
throw|;
block|}
name|String
name|dataFormat
init|=
name|metaData
operator|.
name|getOrDefault
argument_list|(
name|Field
operator|.
name|DATA_FORMAT
argument_list|,
literal|"null"
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|dataFormat
condition|)
block|{
case|case
name|Value
operator|.
name|COMPACTED
case|:
return|return
literal|true
return|;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected value for "
operator|+
name|Field
operator|.
name|DATA_FORMAT
operator|+
literal|": "
operator|+
name|dataFormat
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Failed to read "
operator|+
name|baseOrDeltaDir
operator|+
literal|"/"
operator|+
name|METADATA_FILE
operator|+
literal|": "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**      * Chooses 1 representative file from {@code baseOrDeltaDir}      * This assumes that all files in the dir are of the same type: either written by an acid      * write or Load Data.  This should always be the case for an Acid table.      */
specifier|private
specifier|static
name|Path
name|chooseFile
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
operator|(
name|baseOrDeltaDir
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
operator|||
name|baseOrDeltaDir
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|baseOrDeltaDir
operator|+
literal|" is not a base/delta"
argument_list|)
throw|;
block|}
name|FileStatus
index|[]
name|dataFiles
init|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
index|[]
block|{
name|baseOrDeltaDir
block|}
argument_list|,
name|originalBucketFilter
argument_list|)
decl_stmt|;
return|return
name|dataFiles
operator|!=
literal|null
operator|&&
name|dataFiles
operator|.
name|length
operator|>
literal|0
condition|?
name|dataFiles
index|[
literal|0
index|]
operator|.
name|getPath
argument_list|()
else|:
literal|null
return|;
block|}
comment|/**      * Checks if the files in base/delta dir are a result of Load Data/Add Partition statement      * and thus do not have ROW_IDs embedded in the data.      * This is only meaningful for full CRUD tables - Insert-only tables have all their data      * in raw format by definition.      * @param baseOrDeltaDir base or delta file.      */
specifier|public
specifier|static
name|boolean
name|isRawFormat
parameter_list|(
name|Path
name|baseOrDeltaDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
comment|//todo: this could be optimized - for full CRUD table only base_x and delta_x_x could have
comment|// files in raw format delta_x_y (x != y) whether from streaming ingested or compaction
comment|// must be native Acid format by definition
if|if
condition|(
name|isDeleteDelta
argument_list|(
name|baseOrDeltaDir
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|isInsertDelta
argument_list|(
name|baseOrDeltaDir
argument_list|)
condition|)
block|{
name|ParsedDeltaLight
name|pd
init|=
name|ParsedDeltaLight
operator|.
name|parse
argument_list|(
name|baseOrDeltaDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|pd
operator|.
name|getMinWriteId
argument_list|()
operator|!=
name|pd
operator|.
name|getMaxWriteId
argument_list|()
condition|)
block|{
comment|//must be either result of streaming or compaction
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
comment|//must be base_x
if|if
condition|(
name|isCompactedBase
argument_list|(
name|ParsedBase
operator|.
name|parseBase
argument_list|(
name|baseOrDeltaDir
argument_list|)
argument_list|,
name|fs
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
comment|//if here, have to check the files
name|Path
name|dataFile
init|=
name|chooseFile
argument_list|(
name|baseOrDeltaDir
argument_list|,
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
name|dataFile
operator|==
literal|null
condition|)
block|{
comment|//directory is empty or doesn't have any that could have been produced by load data
return|return
literal|false
return|;
block|}
return|return
name|isRawFormatFile
argument_list|(
name|dataFile
argument_list|,
name|fs
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isRawFormatFile
parameter_list|(
name|Path
name|dataFile
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|Reader
name|reader
init|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|dataFile
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
comment|/*           acid file would have schema like<op, owid, writerId, rowid, cwid,<f1, ... fn>> so could           check it this way once/if OrcRecordUpdater.ACID_KEY_INDEX_NAME is removed           TypeDescription schema = reader.getSchema();           List<String> columns = schema.getFieldNames();          */
return|return
name|OrcInputFormat
operator|.
name|isOriginal
argument_list|(
name|reader
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|FileFormatException
name|ex
parameter_list|)
block|{
comment|//We may be parsing a delta for Insert-only table which may not even be an ORC file so
comment|//cannot have ROW_IDs in it.
name|LOG
operator|.
name|debug
argument_list|(
literal|"isRawFormat() called on "
operator|+
name|dataFile
operator|+
literal|" which is not an ORC file: "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
comment|/**    * Logic related to versioning acid data format.  An {@code ACID_FORMAT} file is written to each    * base/delta/delete_delta dir written by a full acid write or compaction.  This is the primary    * mechanism for versioning acid data.    *    * Each individual ORC file written stores the current version as a user property in ORC footer.    * All data files produced by Acid write should have this (starting with Hive 3.0), including    * those written by compactor.  This is more for sanity checking in case someone moved the files    * around or something like that.    */
specifier|public
specifier|static
specifier|final
class|class
name|OrcAcidVersion
block|{
specifier|private
specifier|static
specifier|final
name|String
name|ACID_VERSION_KEY
init|=
literal|"hive.acid.version"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|ACID_FORMAT
init|=
literal|"_orc_acid_version"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Charset
name|UTF8
init|=
name|Charset
operator|.
name|forName
argument_list|(
literal|"UTF-8"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|ORC_ACID_VERSION_DEFAULT
init|=
literal|0
decl_stmt|;
comment|/**      * 2 is the version of Acid released in Hive 3.0.      */
specifier|public
specifier|static
specifier|final
name|int
name|ORC_ACID_VERSION
init|=
literal|2
decl_stmt|;
comment|/**      * Inlucde current acid version in file footer.      * @param writer - file written      */
specifier|public
specifier|static
name|void
name|setAcidVersionInDataFile
parameter_list|(
name|Writer
name|writer
parameter_list|)
block|{
comment|//so that we know which version wrote the file
name|writer
operator|.
name|addUserMetadata
argument_list|(
name|ACID_VERSION_KEY
argument_list|,
name|UTF8
operator|.
name|encode
argument_list|(
name|String
operator|.
name|valueOf
argument_list|(
name|ORC_ACID_VERSION
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**      * This is smart enough to handle streaming ingest where there could be a      * {@link OrcAcidUtils#DELTA_SIDE_FILE_SUFFIX} side file.      * @param dataFile - ORC acid data file      * @return version property from file if there,      *          {@link #ORC_ACID_VERSION_DEFAULT} otherwise      */
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|int
name|getAcidVersionFromDataFile
parameter_list|(
name|Path
name|dataFile
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|fileStatus
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dataFile
argument_list|)
decl_stmt|;
name|Reader
name|orcReader
init|=
name|OrcFile
operator|.
name|createReader
argument_list|(
name|dataFile
argument_list|,
name|OrcFile
operator|.
name|readerOptions
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|)
operator|.
name|filesystem
argument_list|(
name|fs
argument_list|)
comment|//make sure to check for side file in case streaming ingest died
operator|.
name|maxLength
argument_list|(
name|getLogicalLength
argument_list|(
name|fs
argument_list|,
name|fileStatus
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|orcReader
operator|.
name|hasMetadataValue
argument_list|(
name|ACID_VERSION_KEY
argument_list|)
condition|)
block|{
name|char
index|[]
name|versionChar
init|=
name|UTF8
operator|.
name|decode
argument_list|(
name|orcReader
operator|.
name|getMetadataValue
argument_list|(
name|ACID_VERSION_KEY
argument_list|)
argument_list|)
operator|.
name|array
argument_list|()
decl_stmt|;
name|String
name|version
init|=
operator|new
name|String
argument_list|(
name|versionChar
argument_list|)
decl_stmt|;
return|return
name|Integer
operator|.
name|valueOf
argument_list|(
name|version
argument_list|)
return|;
block|}
return|return
name|ORC_ACID_VERSION_DEFAULT
return|;
block|}
comment|/**      * This creates a version file in {@code deltaOrBaseDir}      * @param deltaOrBaseDir - where to create the version file      */
specifier|public
specifier|static
name|void
name|writeVersionFile
parameter_list|(
name|Path
name|deltaOrBaseDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|formatFile
init|=
name|getVersionFilePath
argument_list|(
name|deltaOrBaseDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|formatFile
argument_list|)
condition|)
block|{
try|try
init|(
name|FSDataOutputStream
name|strm
init|=
name|fs
operator|.
name|create
argument_list|(
name|formatFile
argument_list|,
literal|false
argument_list|)
init|)
block|{
name|strm
operator|.
name|write
argument_list|(
name|UTF8
operator|.
name|encode
argument_list|(
name|String
operator|.
name|valueOf
argument_list|(
name|ORC_ACID_VERSION
argument_list|)
argument_list|)
operator|.
name|array
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to create "
operator|+
name|formatFile
operator|+
literal|" due to: "
operator|+
name|ioe
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
block|}
specifier|public
specifier|static
name|Path
name|getVersionFilePath
parameter_list|(
name|Path
name|deltaOrBase
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|deltaOrBase
argument_list|,
name|ACID_FORMAT
argument_list|)
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|int
name|getAcidVersionFromMetaFile
parameter_list|(
name|Path
name|deltaOrBaseDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|formatFile
init|=
name|getVersionFilePath
argument_list|(
name|deltaOrBaseDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|formatFile
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|formatFile
operator|+
literal|" not found, returning default: "
operator|+
name|ORC_ACID_VERSION_DEFAULT
argument_list|)
expr_stmt|;
return|return
name|ORC_ACID_VERSION_DEFAULT
return|;
block|}
try|try
init|(
name|FSDataInputStream
name|inputStream
init|=
name|fs
operator|.
name|open
argument_list|(
name|formatFile
argument_list|)
init|)
block|{
name|byte
index|[]
name|bytes
init|=
operator|new
name|byte
index|[
literal|1
index|]
decl_stmt|;
name|int
name|read
init|=
name|inputStream
operator|.
name|read
argument_list|(
name|bytes
argument_list|)
decl_stmt|;
if|if
condition|(
name|read
operator|!=
operator|-
literal|1
condition|)
block|{
name|String
name|version
init|=
operator|new
name|String
argument_list|(
name|bytes
argument_list|,
name|UTF8
argument_list|)
decl_stmt|;
return|return
name|Integer
operator|.
name|valueOf
argument_list|(
name|version
argument_list|)
return|;
block|}
return|return
name|ORC_ACID_VERSION_DEFAULT
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|formatFile
operator|+
literal|" is unreadable due to: "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|FileStatus
argument_list|>
name|getAcidFilesForStats
parameter_list|(
name|Table
name|table
parameter_list|,
name|Path
name|dir
parameter_list|,
name|Configuration
name|jc
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|fileList
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|ValidWriteIdList
name|idList
init|=
name|AcidUtils
operator|.
name|getTableValidWriteIdList
argument_list|(
name|jc
argument_list|,
name|AcidUtils
operator|.
name|getFullTableName
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|idList
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot get ACID state for "
operator|+
name|table
operator|.
name|getDbName
argument_list|()
operator|+
literal|"."
operator|+
name|table
operator|.
name|getTableName
argument_list|()
operator|+
literal|" from "
operator|+
name|jc
operator|.
name|get
argument_list|(
name|ValidTxnWriteIdList
operator|.
name|VALID_TABLES_WRITEIDS_KEY
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|Directory
name|acidInfo
init|=
name|AcidUtils
operator|.
name|getAcidState
argument_list|(
name|dir
argument_list|,
name|jc
argument_list|,
name|idList
argument_list|)
decl_stmt|;
comment|// Assume that for an MM table, or if there's only the base directory, we are good.
if|if
condition|(
operator|!
name|acidInfo
operator|.
name|getCurrentDirectories
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|&&
name|AcidUtils
operator|.
name|isFullAcidTable
argument_list|(
name|table
argument_list|)
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|warn
argument_list|(
literal|"Computing stats for an ACID table; stats may be inaccurate"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|==
literal|null
condition|)
block|{
name|fs
operator|=
name|dir
operator|.
name|getFileSystem
argument_list|(
name|jc
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|HdfsFileStatusWithId
name|hfs
range|:
name|acidInfo
operator|.
name|getOriginalFiles
argument_list|()
control|)
block|{
name|fileList
operator|.
name|add
argument_list|(
name|hfs
operator|.
name|getFileStatus
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ParsedDelta
name|delta
range|:
name|acidInfo
operator|.
name|getCurrentDirectories
argument_list|()
control|)
block|{
for|for
control|(
name|FileStatus
name|f
range|:
name|HiveStatsUtils
operator|.
name|getFileStatusRecurse
argument_list|(
name|delta
operator|.
name|getPath
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
name|fs
argument_list|)
control|)
block|{
name|fileList
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|acidInfo
operator|.
name|getBaseDirectory
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FileStatus
name|f
range|:
name|HiveStatsUtils
operator|.
name|getFileStatusRecurse
argument_list|(
name|acidInfo
operator|.
name|getBaseDirectory
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
name|fs
argument_list|)
control|)
block|{
name|fileList
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|fileList
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|Path
argument_list|>
name|getValidDataPaths
parameter_list|(
name|Path
name|dataPath
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|String
name|validWriteIdStr
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|pathList
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|validWriteIdStr
operator|==
literal|null
operator|)
operator|||
name|validWriteIdStr
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// If Non-Acid case, then all files would be in the base data path. So, just return it.
name|pathList
operator|.
name|add
argument_list|(
name|dataPath
argument_list|)
expr_stmt|;
return|return
name|pathList
return|;
block|}
comment|// If ACID/MM tables, then need to find the valid state wrt to given ValidWriteIdList.
name|ValidWriteIdList
name|validWriteIdList
init|=
operator|new
name|ValidReaderWriteIdList
argument_list|(
name|validWriteIdStr
argument_list|)
decl_stmt|;
name|Directory
name|acidInfo
init|=
name|AcidUtils
operator|.
name|getAcidState
argument_list|(
name|dataPath
argument_list|,
name|conf
argument_list|,
name|validWriteIdList
argument_list|)
decl_stmt|;
for|for
control|(
name|HdfsFileStatusWithId
name|hfs
range|:
name|acidInfo
operator|.
name|getOriginalFiles
argument_list|()
control|)
block|{
name|pathList
operator|.
name|add
argument_list|(
name|hfs
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ParsedDelta
name|delta
range|:
name|acidInfo
operator|.
name|getCurrentDirectories
argument_list|()
control|)
block|{
name|pathList
operator|.
name|add
argument_list|(
name|delta
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|acidInfo
operator|.
name|getBaseDirectory
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|pathList
operator|.
name|add
argument_list|(
name|acidInfo
operator|.
name|getBaseDirectory
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|pathList
return|;
block|}
specifier|public
specifier|static
name|String
name|getAcidSubDir
parameter_list|(
name|Path
name|dataPath
parameter_list|)
block|{
name|String
name|dataDir
init|=
name|dataPath
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|dataDir
operator|.
name|startsWith
argument_list|(
name|AcidUtils
operator|.
name|BASE_PREFIX
argument_list|)
operator|||
name|dataDir
operator|.
name|startsWith
argument_list|(
name|AcidUtils
operator|.
name|DELTA_PREFIX
argument_list|)
operator|||
name|dataDir
operator|.
name|startsWith
argument_list|(
name|AcidUtils
operator|.
name|DELETE_DELTA_PREFIX
argument_list|)
condition|)
block|{
return|return
name|dataDir
return|;
block|}
return|return
literal|null
return|;
block|}
comment|//Get the first level acid directory (if any) from a given path
specifier|public
specifier|static
name|String
name|getFirstLevelAcidDirPath
parameter_list|(
name|Path
name|dataPath
parameter_list|,
name|FileSystem
name|fileSystem
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|dataPath
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|String
name|firstLevelAcidDir
init|=
name|getAcidSubDir
argument_list|(
name|dataPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|firstLevelAcidDir
operator|!=
literal|null
condition|)
block|{
return|return
name|firstLevelAcidDir
return|;
block|}
name|String
name|acidDirPath
init|=
name|getFirstLevelAcidDirPath
argument_list|(
name|dataPath
operator|.
name|getParent
argument_list|()
argument_list|,
name|fileSystem
argument_list|)
decl_stmt|;
if|if
condition|(
name|acidDirPath
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// We need the path for directory so no need to append file name
if|if
condition|(
name|fileSystem
operator|.
name|isDirectory
argument_list|(
name|dataPath
argument_list|)
condition|)
block|{
return|return
name|acidDirPath
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|dataPath
operator|.
name|getName
argument_list|()
return|;
block|}
return|return
name|acidDirPath
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isAcidEnabled
parameter_list|(
name|HiveConf
name|hiveConf
parameter_list|)
block|{
name|String
name|txnMgr
init|=
name|hiveConf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_TXN_MANAGER
argument_list|)
decl_stmt|;
name|boolean
name|concurrency
init|=
name|hiveConf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_SUPPORT_CONCURRENCY
argument_list|)
decl_stmt|;
name|String
name|dbTxnMgr
init|=
literal|"org.apache.hadoop.hive.ql.lockmgr.DbTxnManager"
decl_stmt|;
if|if
condition|(
name|txnMgr
operator|.
name|equals
argument_list|(
name|dbTxnMgr
argument_list|)
operator|&&
name|concurrency
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
specifier|static
class|class
name|AnyIdDirFilter
implements|implements
name|PathFilter
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|extractWriteId
argument_list|(
name|path
argument_list|)
operator|!=
literal|null
return|;
block|}
block|}
specifier|public
specifier|static
class|class
name|IdPathFilter
implements|implements
name|PathFilter
block|{
specifier|private
name|String
name|baseDirName
decl_stmt|,
name|deltaDirName
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isDeltaPrefix
decl_stmt|;
specifier|public
name|IdPathFilter
parameter_list|(
name|long
name|writeId
parameter_list|,
name|int
name|stmtId
parameter_list|)
block|{
name|String
name|deltaDirName
init|=
literal|null
decl_stmt|;
name|deltaDirName
operator|=
name|DELTA_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|writeId
argument_list|)
operator|+
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
name|isDeltaPrefix
operator|=
operator|(
name|stmtId
operator|<
literal|0
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|isDeltaPrefix
condition|)
block|{
name|deltaDirName
operator|+=
literal|"_"
operator|+
name|String
operator|.
name|format
argument_list|(
name|STATEMENT_DIGITS
argument_list|,
name|stmtId
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|baseDirName
operator|=
name|BASE_PREFIX
operator|+
name|String
operator|.
name|format
argument_list|(
name|DELTA_DIGITS
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
name|this
operator|.
name|deltaDirName
operator|=
name|deltaDirName
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|String
name|name
init|=
name|path
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
name|name
operator|.
name|equals
argument_list|(
name|baseDirName
argument_list|)
operator|||
operator|(
name|isDeltaPrefix
operator|&&
name|name
operator|.
name|startsWith
argument_list|(
name|deltaDirName
argument_list|)
operator|)
operator|||
operator|(
operator|!
name|isDeltaPrefix
operator|&&
name|name
operator|.
name|equals
argument_list|(
name|deltaDirName
argument_list|)
operator|)
return|;
block|}
block|}
specifier|public
specifier|static
name|Long
name|extractWriteId
parameter_list|(
name|Path
name|file
parameter_list|)
block|{
name|String
name|fileName
init|=
name|file
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fileName
operator|.
name|startsWith
argument_list|(
name|DELTA_PREFIX
argument_list|)
operator|&&
operator|!
name|fileName
operator|.
name|startsWith
argument_list|(
name|BASE_PREFIX
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Cannot extract write ID for a MM table: {}"
argument_list|,
name|file
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|String
index|[]
name|parts
init|=
name|fileName
operator|.
name|split
argument_list|(
literal|"_"
argument_list|,
literal|4
argument_list|)
decl_stmt|;
comment|// e.g. delta_0000001_0000001_0000 or base_0000022
if|if
condition|(
name|parts
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cannot extract write ID for a MM table: "
operator|+
name|file
operator|+
literal|" ("
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|parts
argument_list|)
operator|+
literal|")"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|long
name|writeId
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|writeId
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|parts
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cannot extract write ID for a MM table: "
operator|+
name|file
operator|+
literal|"; parsing "
operator|+
name|parts
index|[
literal|1
index|]
operator|+
literal|" got "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
return|return
name|writeId
return|;
block|}
specifier|public
specifier|static
name|void
name|setNonTransactional
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblProps
parameter_list|)
block|{
name|tblProps
operator|.
name|put
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_TRANSACTIONAL
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|tblProps
operator|.
name|remove
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_TRANSACTIONAL_PROPERTIES
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|boolean
name|needsLock
parameter_list|(
name|Entity
name|entity
parameter_list|)
block|{
switch|switch
condition|(
name|entity
operator|.
name|getType
argument_list|()
condition|)
block|{
case|case
name|TABLE
case|:
return|return
name|isLockableTable
argument_list|(
name|entity
operator|.
name|getTable
argument_list|()
argument_list|)
return|;
case|case
name|PARTITION
case|:
return|return
name|isLockableTable
argument_list|(
name|entity
operator|.
name|getPartition
argument_list|()
operator|.
name|getTable
argument_list|()
argument_list|)
return|;
default|default:
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|static
name|Table
name|getTable
parameter_list|(
name|WriteEntity
name|we
parameter_list|)
block|{
name|Table
name|t
init|=
name|we
operator|.
name|getTable
argument_list|()
decl_stmt|;
if|if
condition|(
name|t
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"No table info for "
operator|+
name|we
argument_list|)
throw|;
block|}
return|return
name|t
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isLockableTable
parameter_list|(
name|Table
name|t
parameter_list|)
block|{
if|if
condition|(
name|t
operator|.
name|isTemporary
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
switch|switch
condition|(
name|t
operator|.
name|getTableType
argument_list|()
condition|)
block|{
case|case
name|MANAGED_TABLE
case|:
case|case
name|MATERIALIZED_VIEW
case|:
return|return
literal|true
return|;
default|default:
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Create lock components from write/read entities.    * @param outputs write entities    * @param inputs read entities    * @param conf    * @return list with lock components    */
specifier|public
specifier|static
name|List
argument_list|<
name|LockComponent
argument_list|>
name|makeLockComponents
parameter_list|(
name|Set
argument_list|<
name|WriteEntity
argument_list|>
name|outputs
parameter_list|,
name|Set
argument_list|<
name|ReadEntity
argument_list|>
name|inputs
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
block|{
name|List
argument_list|<
name|LockComponent
argument_list|>
name|lockComponents
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// For each source to read, get a shared lock
for|for
control|(
name|ReadEntity
name|input
range|:
name|inputs
control|)
block|{
if|if
condition|(
operator|!
name|input
operator|.
name|needsLock
argument_list|()
operator|||
name|input
operator|.
name|isUpdateOrDelete
argument_list|()
operator|||
operator|!
name|AcidUtils
operator|.
name|needsLock
argument_list|(
name|input
argument_list|)
condition|)
block|{
comment|// We don't want to acquire read locks during update or delete as we'll be acquiring write
comment|// locks instead. Also, there's no need to lock temp tables since they're session wide
continue|continue;
block|}
name|LockComponentBuilder
name|compBuilder
init|=
operator|new
name|LockComponentBuilder
argument_list|()
decl_stmt|;
name|compBuilder
operator|.
name|setShared
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|SELECT
argument_list|)
expr_stmt|;
name|Table
name|t
init|=
literal|null
decl_stmt|;
switch|switch
condition|(
name|input
operator|.
name|getType
argument_list|()
condition|)
block|{
case|case
name|DATABASE
case|:
name|compBuilder
operator|.
name|setDbName
argument_list|(
name|input
operator|.
name|getDatabase
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|TABLE
case|:
name|t
operator|=
name|input
operator|.
name|getTable
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setDbName
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|)
expr_stmt|;
name|compBuilder
operator|.
name|setTableName
argument_list|(
name|t
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|PARTITION
case|:
case|case
name|DUMMYPARTITION
case|:
name|compBuilder
operator|.
name|setPartitionName
argument_list|(
name|input
operator|.
name|getPartition
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|t
operator|=
name|input
operator|.
name|getPartition
argument_list|()
operator|.
name|getTable
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setDbName
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|)
expr_stmt|;
name|compBuilder
operator|.
name|setTableName
argument_list|(
name|t
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
comment|// This is a file or something we don't hold locks for.
continue|continue;
block|}
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|compBuilder
operator|.
name|setIsTransactional
argument_list|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|t
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LockComponent
name|comp
init|=
name|compBuilder
operator|.
name|build
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding lock component to lock request "
operator|+
name|comp
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|lockComponents
operator|.
name|add
argument_list|(
name|comp
argument_list|)
expr_stmt|;
block|}
comment|// For each source to write to, get the appropriate lock type.  If it's
comment|// an OVERWRITE, we need to get an exclusive lock.  If it's an insert (no
comment|// overwrite) than we need a shared.  If it's update or delete then we
comment|// need a SEMI-SHARED.
for|for
control|(
name|WriteEntity
name|output
range|:
name|outputs
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"output is null "
operator|+
operator|(
name|output
operator|==
literal|null
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|output
operator|.
name|getType
argument_list|()
operator|==
name|Entity
operator|.
name|Type
operator|.
name|DFS_DIR
operator|||
name|output
operator|.
name|getType
argument_list|()
operator|==
name|Entity
operator|.
name|Type
operator|.
name|LOCAL_DIR
operator|||
operator|!
name|AcidUtils
operator|.
name|needsLock
argument_list|(
name|output
argument_list|)
condition|)
block|{
comment|// We don't lock files or directories. We also skip locking temp tables.
continue|continue;
block|}
name|LockComponentBuilder
name|compBuilder
init|=
operator|new
name|LockComponentBuilder
argument_list|()
decl_stmt|;
name|Table
name|t
init|=
literal|null
decl_stmt|;
switch|switch
condition|(
name|output
operator|.
name|getType
argument_list|()
condition|)
block|{
case|case
name|DATABASE
case|:
name|compBuilder
operator|.
name|setDbName
argument_list|(
name|output
operator|.
name|getDatabase
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|TABLE
case|:
case|case
name|DUMMYPARTITION
case|:
comment|// in case of dynamic partitioning lock the table
name|t
operator|=
name|output
operator|.
name|getTable
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setDbName
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|)
expr_stmt|;
name|compBuilder
operator|.
name|setTableName
argument_list|(
name|t
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|PARTITION
case|:
name|compBuilder
operator|.
name|setPartitionName
argument_list|(
name|output
operator|.
name|getPartition
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|t
operator|=
name|output
operator|.
name|getPartition
argument_list|()
operator|.
name|getTable
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setDbName
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|)
expr_stmt|;
name|compBuilder
operator|.
name|setTableName
argument_list|(
name|t
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
comment|// This is a file or something we don't hold locks for.
continue|continue;
block|}
switch|switch
condition|(
name|output
operator|.
name|getWriteType
argument_list|()
condition|)
block|{
comment|/* base this on HiveOperation instead?  this and DDL_NO_LOCK is peppered all over the code...          Seems much cleaner if each stmt is identified as a particular HiveOperation (which I'd think          makes sense everywhere).  This however would be problematic for merge...*/
case|case
name|DDL_EXCLUSIVE
case|:
name|compBuilder
operator|.
name|setExclusive
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|NO_TXN
argument_list|)
expr_stmt|;
break|break;
case|case
name|INSERT_OVERWRITE
case|:
name|t
operator|=
name|AcidUtils
operator|.
name|getTable
argument_list|(
name|output
argument_list|)
expr_stmt|;
if|if
condition|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|t
argument_list|)
condition|)
block|{
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|TXN_OVERWRITE_X_LOCK
argument_list|)
condition|)
block|{
name|compBuilder
operator|.
name|setExclusive
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|compBuilder
operator|.
name|setSemiShared
argument_list|()
expr_stmt|;
block|}
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|UPDATE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|compBuilder
operator|.
name|setExclusive
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|NO_TXN
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|INSERT
case|:
assert|assert
name|t
operator|!=
literal|null
assert|;
if|if
condition|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|t
argument_list|)
condition|)
block|{
name|compBuilder
operator|.
name|setShared
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|MetaStoreUtils
operator|.
name|isNonNativeTable
argument_list|(
name|t
operator|.
name|getTTable
argument_list|()
argument_list|)
condition|)
block|{
specifier|final
name|HiveStorageHandler
name|storageHandler
init|=
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|t
operator|.
name|getStorageHandler
argument_list|()
argument_list|,
literal|"Thought all the non native tables have an instance of storage handler"
argument_list|)
decl_stmt|;
name|LockType
name|lockType
init|=
name|storageHandler
operator|.
name|getLockType
argument_list|(
name|output
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|LockType
operator|.
name|findByValue
argument_list|(
name|lockType
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Lock type [%s] for Database.Table [%s.%s] is unknown"
argument_list|,
name|lockType
argument_list|,
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|compBuilder
operator|.
name|setLock
argument_list|(
name|lockType
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_TXN_STRICT_LOCKING_MODE
argument_list|)
condition|)
block|{
name|compBuilder
operator|.
name|setExclusive
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// this is backward compatible for non-ACID resources, w/o ACID semantics
name|compBuilder
operator|.
name|setShared
argument_list|()
expr_stmt|;
block|}
block|}
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|INSERT
argument_list|)
expr_stmt|;
break|break;
case|case
name|DDL_SHARED
case|:
name|compBuilder
operator|.
name|setShared
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|output
operator|.
name|isTxnAnalyze
argument_list|()
condition|)
block|{
comment|// Analyze needs txn components to be present, otherwise an aborted analyze write ID
comment|// might be rolled under the watermark by compactor while stats written by it are
comment|// still present.
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|NO_TXN
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|UPDATE
case|:
name|compBuilder
operator|.
name|setSemiShared
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|UPDATE
argument_list|)
expr_stmt|;
break|break;
case|case
name|DELETE
case|:
name|compBuilder
operator|.
name|setSemiShared
argument_list|()
expr_stmt|;
name|compBuilder
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|DELETE
argument_list|)
expr_stmt|;
break|break;
case|case
name|DDL_NO_LOCK
case|:
continue|continue;
comment|// No lock required here
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown write type "
operator|+
name|output
operator|.
name|getWriteType
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|compBuilder
operator|.
name|setIsTransactional
argument_list|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|t
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|compBuilder
operator|.
name|setIsDynamicPartitionWrite
argument_list|(
name|output
operator|.
name|isDynamicPartitionWrite
argument_list|()
argument_list|)
expr_stmt|;
name|LockComponent
name|comp
init|=
name|compBuilder
operator|.
name|build
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding lock component to lock request "
operator|+
name|comp
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|lockComponents
operator|.
name|add
argument_list|(
name|comp
argument_list|)
expr_stmt|;
block|}
return|return
name|lockComponents
return|;
block|}
comment|/**    * Safety check to make sure a file take from one acid table is not added into another acid table    * since the ROW__IDs embedded as part a write to one table won't make sense in different    * table/cluster.    */
specifier|public
specifier|static
name|void
name|validateAcidFiles
parameter_list|(
name|Table
name|table
parameter_list|,
name|FileStatus
index|[]
name|srcs
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|SemanticException
block|{
if|if
condition|(
operator|!
name|AcidUtils
operator|.
name|isFullAcidTable
argument_list|(
name|table
argument_list|)
condition|)
block|{
return|return;
block|}
name|validateAcidFiles
argument_list|(
name|srcs
argument_list|,
name|fs
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|validateAcidFiles
parameter_list|(
name|FileStatus
index|[]
name|srcs
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|SemanticException
block|{
try|try
block|{
if|if
condition|(
name|srcs
operator|==
literal|null
condition|)
block|{
return|return;
block|}
for|for
control|(
name|FileStatus
name|oneSrc
range|:
name|srcs
control|)
block|{
if|if
condition|(
operator|!
name|AcidUtils
operator|.
name|MetaDataFile
operator|.
name|isRawFormatFile
argument_list|(
name|oneSrc
operator|.
name|getPath
argument_list|()
argument_list|,
name|fs
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|LOAD_DATA_ACID_FILE
argument_list|,
name|oneSrc
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
comment|/**    * Safety check to make sure the given location is not the location of acid table and    * all it's files  will be not added into another acid table    */
specifier|public
specifier|static
name|void
name|validateAcidPartitionLocation
parameter_list|(
name|String
name|location
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|SemanticException
block|{
try|try
block|{
name|URI
name|uri
init|=
operator|new
name|URI
argument_list|(
name|location
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|uri
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|fileStatuses
init|=
name|LoadSemanticAnalyzer
operator|.
name|matchFilesOrDir
argument_list|(
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|uri
argument_list|)
argument_list|)
decl_stmt|;
name|validateAcidFiles
argument_list|(
name|fileStatuses
argument_list|,
name|fs
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|URISyntaxException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PATH
operator|.
name|getMsg
argument_list|(
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

