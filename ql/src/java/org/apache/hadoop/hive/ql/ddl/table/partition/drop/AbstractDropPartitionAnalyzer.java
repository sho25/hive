begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ddl
operator|.
name|table
operator|.
name|partition
operator|.
name|drop
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|antlr
operator|.
name|runtime
operator|.
name|tree
operator|.
name|CommonTree
import|;
end_import

begin_import
import|import
name|org
operator|.
name|antlr
operator|.
name|runtime
operator|.
name|tree
operator|.
name|Tree
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|QueryState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ddl
operator|.
name|DDLWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ddl
operator|.
name|table
operator|.
name|AbstractAlterTableAnalyzer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ddl
operator|.
name|table
operator|.
name|AlterTableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ddl
operator|.
name|table
operator|.
name|partition
operator|.
name|PartitionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FunctionRegistry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TaskFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|ReadEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|WriteEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|InvalidTableException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ASTNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ReplicationSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|TypeCheckCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|TypeCheckProcFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeColumnDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeConstantDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeGenericFuncDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDF
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorConverters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorConverters
operator|.
name|Converter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|PrimitiveTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_comment
comment|/**  * Analyzer for drop partition commands.  */
end_comment

begin_class
specifier|abstract
class|class
name|AbstractDropPartitionAnalyzer
extends|extends
name|AbstractAlterTableAnalyzer
block|{
name|AbstractDropPartitionAnalyzer
parameter_list|(
name|QueryState
name|queryState
parameter_list|)
throws|throws
name|SemanticException
block|{
name|super
argument_list|(
name|queryState
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|analyzeCommand
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionSpec
parameter_list|,
name|ASTNode
name|command
parameter_list|)
throws|throws
name|SemanticException
block|{
name|boolean
name|ifExists
init|=
operator|(
name|command
operator|.
name|getFirstChildWithType
argument_list|(
name|HiveParser
operator|.
name|TOK_IFEXISTS
argument_list|)
operator|!=
literal|null
operator|)
operator|||
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|DROP_IGNORES_NON_EXISTENT
argument_list|)
decl_stmt|;
comment|// If the drop has to fail on non-existent partitions, we cannot batch expressions.
comment|// That is because we actually have to check each separate expression for existence.
comment|// We could do a small optimization for the case where expr has all columns and all
comment|// operators are equality, if we assume those would always match one partition (which
comment|// may not be true with legacy, non-normalized column values). This is probably a
comment|// popular case but that's kinda hacky. Let's not do it for now.
name|boolean
name|canGroupExprs
init|=
name|ifExists
decl_stmt|;
name|boolean
name|mustPurge
init|=
operator|(
name|command
operator|.
name|getFirstChildWithType
argument_list|(
name|HiveParser
operator|.
name|KW_PURGE
argument_list|)
operator|!=
literal|null
operator|)
decl_stmt|;
name|ReplicationSpec
name|replicationSpec
init|=
operator|new
name|ReplicationSpec
argument_list|(
name|command
argument_list|)
decl_stmt|;
name|Table
name|table
init|=
literal|null
decl_stmt|;
try|try
block|{
name|table
operator|=
name|getTable
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SemanticException
name|se
parameter_list|)
block|{
if|if
condition|(
name|replicationSpec
operator|.
name|isInReplicationScope
argument_list|()
operator|&&
operator|(
operator|(
name|se
operator|.
name|getCause
argument_list|()
operator|instanceof
name|InvalidTableException
operator|)
operator|||
operator|(
name|se
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_TABLE
operator|.
name|getMsg
argument_list|()
argument_list|)
operator|)
operator|)
condition|)
block|{
comment|// If we're inside a replication scope, then the table not existing is not an error.
comment|// We just return in that case, no drop needed.
return|return;
comment|// TODO : the contains message check is fragile, we should refactor SemanticException to be
comment|// queriable for error code, and not simply have a message
comment|// NOTE : IF_EXISTS might also want to invoke this, but there's a good possibility
comment|// that IF_EXISTS is stricter about table existence, and applies only to the ptn.
comment|// Therefore, ignoring IF_EXISTS here.
block|}
else|else
block|{
throw|throw
name|se
throw|;
block|}
block|}
name|Map
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|ExprNodeGenericFuncDesc
argument_list|>
argument_list|>
name|partitionSpecs
init|=
name|getFullPartitionSpecs
argument_list|(
name|command
argument_list|,
name|table
argument_list|,
name|canGroupExprs
argument_list|)
decl_stmt|;
if|if
condition|(
name|partitionSpecs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// nothing to do
return|return;
block|}
name|validateAlterTableType
argument_list|(
name|table
argument_list|,
name|AlterTableType
operator|.
name|DROPPARTITION
argument_list|,
name|expectView
argument_list|()
argument_list|)
expr_stmt|;
name|ReadEntity
name|re
init|=
operator|new
name|ReadEntity
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|re
operator|.
name|noLockNeeded
argument_list|()
expr_stmt|;
name|inputs
operator|.
name|add
argument_list|(
name|re
argument_list|)
expr_stmt|;
name|addTableDropPartsOutputs
argument_list|(
name|table
argument_list|,
name|partitionSpecs
operator|.
name|values
argument_list|()
argument_list|,
operator|!
name|ifExists
argument_list|)
expr_stmt|;
name|AlterTableDropPartitionDesc
name|desc
init|=
operator|new
name|AlterTableDropPartitionDesc
argument_list|(
name|tableName
argument_list|,
name|partitionSpecs
argument_list|,
name|mustPurge
argument_list|,
name|replicationSpec
argument_list|)
decl_stmt|;
name|rootTasks
operator|.
name|add
argument_list|(
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DDLWork
argument_list|(
name|getInputs
argument_list|()
argument_list|,
name|getOutputs
argument_list|()
argument_list|,
name|desc
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the partition specs from the tree. This stores the full specification    * with the comparator operator into the output list.    *    * @return Map of partitions by prefix length. Most of the time prefix length will    *         be the same for all partition specs, so we can just OR the expressions.    */
specifier|private
name|Map
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|ExprNodeGenericFuncDesc
argument_list|>
argument_list|>
name|getFullPartitionSpecs
parameter_list|(
name|CommonTree
name|ast
parameter_list|,
name|Table
name|table
parameter_list|,
name|boolean
name|canGroupExprs
parameter_list|)
throws|throws
name|SemanticException
block|{
name|String
name|defaultPartitionName
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DEFAULTPARTITIONNAME
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|colTypes
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fs
range|:
name|table
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
name|colTypes
operator|.
name|put
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|fs
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Map
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|ExprNodeGenericFuncDesc
argument_list|>
argument_list|>
name|result
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|childIndex
init|=
literal|0
init|;
name|childIndex
operator|<
name|ast
operator|.
name|getChildCount
argument_list|()
condition|;
name|childIndex
operator|++
control|)
block|{
name|Tree
name|partSpecTree
init|=
name|ast
operator|.
name|getChild
argument_list|(
name|childIndex
argument_list|)
decl_stmt|;
if|if
condition|(
name|partSpecTree
operator|.
name|getType
argument_list|()
operator|!=
name|HiveParser
operator|.
name|TOK_PARTSPEC
condition|)
block|{
continue|continue;
block|}
name|ExprNodeGenericFuncDesc
name|expr
init|=
literal|null
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|names
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|partSpecTree
operator|.
name|getChildCount
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partSpecTree
operator|.
name|getChildCount
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|CommonTree
name|partSpecSingleKey
init|=
operator|(
name|CommonTree
operator|)
name|partSpecTree
operator|.
name|getChild
argument_list|(
name|i
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|partSpecSingleKey
operator|.
name|getType
argument_list|()
operator|==
name|HiveParser
operator|.
name|TOK_PARTVAL
operator|)
assert|;
name|String
name|key
init|=
name|stripIdentifierQuotes
argument_list|(
name|partSpecSingleKey
operator|.
name|getChild
argument_list|(
literal|0
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
operator|.
name|toLowerCase
argument_list|()
decl_stmt|;
name|String
name|operator
init|=
name|partSpecSingleKey
operator|.
name|getChild
argument_list|(
literal|1
argument_list|)
operator|.
name|getText
argument_list|()
decl_stmt|;
name|ASTNode
name|partValNode
init|=
operator|(
name|ASTNode
operator|)
name|partSpecSingleKey
operator|.
name|getChild
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|TypeCheckCtx
name|typeCheckCtx
init|=
operator|new
name|TypeCheckCtx
argument_list|(
literal|null
argument_list|)
decl_stmt|;
name|ExprNodeConstantDesc
name|valExpr
init|=
operator|(
name|ExprNodeConstantDesc
operator|)
name|TypeCheckProcFactory
operator|.
name|genExprNode
argument_list|(
name|partValNode
argument_list|,
name|typeCheckCtx
argument_list|)
operator|.
name|get
argument_list|(
name|partValNode
argument_list|)
decl_stmt|;
name|Object
name|val
init|=
name|valExpr
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|boolean
name|isDefaultPartitionName
init|=
name|val
operator|.
name|equals
argument_list|(
name|defaultPartitionName
argument_list|)
decl_stmt|;
name|String
name|type
init|=
name|colTypes
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|PrimitiveTypeInfo
name|pti
init|=
name|TypeInfoFactory
operator|.
name|getPrimitiveTypeInfo
argument_list|(
name|type
argument_list|)
decl_stmt|;
if|if
condition|(
name|type
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Column "
operator|+
name|key
operator|+
literal|" not found"
argument_list|)
throw|;
block|}
comment|// Create the corresponding hive expression to filter on partition columns.
if|if
condition|(
operator|!
name|isDefaultPartitionName
condition|)
block|{
if|if
condition|(
operator|!
name|valExpr
operator|.
name|getTypeString
argument_list|()
operator|.
name|equals
argument_list|(
name|type
argument_list|)
condition|)
block|{
name|Converter
name|converter
init|=
name|ObjectInspectorConverters
operator|.
name|getConverter
argument_list|(
name|TypeInfoUtils
operator|.
name|getStandardJavaObjectInspectorFromTypeInfo
argument_list|(
name|valExpr
operator|.
name|getTypeInfo
argument_list|()
argument_list|)
argument_list|,
name|TypeInfoUtils
operator|.
name|getStandardJavaObjectInspectorFromTypeInfo
argument_list|(
name|pti
argument_list|)
argument_list|)
decl_stmt|;
name|val
operator|=
name|converter
operator|.
name|convert
argument_list|(
name|valExpr
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|ExprNodeColumnDesc
name|column
init|=
operator|new
name|ExprNodeColumnDesc
argument_list|(
name|pti
argument_list|,
name|key
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|ExprNodeGenericFuncDesc
name|op
decl_stmt|;
if|if
condition|(
operator|!
name|isDefaultPartitionName
condition|)
block|{
name|op
operator|=
name|PartitionUtils
operator|.
name|makeBinaryPredicate
argument_list|(
name|operator
argument_list|,
name|column
argument_list|,
operator|new
name|ExprNodeConstantDesc
argument_list|(
name|pti
argument_list|,
name|val
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|GenericUDF
name|originalOp
init|=
name|FunctionRegistry
operator|.
name|getFunctionInfo
argument_list|(
name|operator
argument_list|)
operator|.
name|getGenericUDF
argument_list|()
decl_stmt|;
name|String
name|fnName
decl_stmt|;
if|if
condition|(
name|FunctionRegistry
operator|.
name|isEq
argument_list|(
name|originalOp
argument_list|)
condition|)
block|{
name|fnName
operator|=
literal|"isnull"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|FunctionRegistry
operator|.
name|isNeq
argument_list|(
name|originalOp
argument_list|)
condition|)
block|{
name|fnName
operator|=
literal|"isnotnull"
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Cannot use "
operator|+
name|operator
operator|+
literal|" in a default partition spec; only '=' and '!=' are allowed."
argument_list|)
throw|;
block|}
name|op
operator|=
name|PartitionUtils
operator|.
name|makeUnaryPredicate
argument_list|(
name|fnName
argument_list|,
name|column
argument_list|)
expr_stmt|;
block|}
comment|// If it's multi-expr filter (e.g. a='5', b='2012-01-02'), AND with previous exprs.
name|expr
operator|=
operator|(
name|expr
operator|==
literal|null
operator|)
condition|?
name|op
else|:
name|PartitionUtils
operator|.
name|makeBinaryPredicate
argument_list|(
literal|"and"
argument_list|,
name|expr
argument_list|,
name|op
argument_list|)
expr_stmt|;
name|names
operator|.
name|add
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|expr
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// We got the expr for one full partition spec. Determine the prefix length.
name|int
name|prefixLength
init|=
name|calculatePartPrefix
argument_list|(
name|table
argument_list|,
name|names
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|ExprNodeGenericFuncDesc
argument_list|>
name|orExpr
init|=
name|result
operator|.
name|get
argument_list|(
name|prefixLength
argument_list|)
decl_stmt|;
comment|// We have to tell apart partitions resulting from spec with different prefix lengths.
comment|// So, if we already have smth for the same prefix length, we can OR the two.
comment|// If we don't, create a new separate filter. In most cases there will only be one.
if|if
condition|(
name|orExpr
operator|==
literal|null
condition|)
block|{
name|result
operator|.
name|put
argument_list|(
name|prefixLength
argument_list|,
name|Lists
operator|.
name|newArrayList
argument_list|(
name|expr
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|canGroupExprs
condition|)
block|{
name|orExpr
operator|.
name|set
argument_list|(
literal|0
argument_list|,
name|PartitionUtils
operator|.
name|makeBinaryPredicate
argument_list|(
literal|"or"
argument_list|,
name|expr
argument_list|,
name|orExpr
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|orExpr
operator|.
name|add
argument_list|(
name|expr
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Calculates the partition prefix length based on the drop spec.    * This is used to avoid deleting archived partitions with lower level.    * For example, if, for A and B key cols, drop spec is A=5, B=6, we shouldn't drop    * archived A=5/, because it can contain B-s other than 6.    */
specifier|private
name|int
name|calculatePartPrefix
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Set
argument_list|<
name|String
argument_list|>
name|partSpecKeys
parameter_list|)
block|{
name|int
name|partPrefixToDrop
init|=
literal|0
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fs
range|:
name|tbl
operator|.
name|getPartCols
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|partSpecKeys
operator|.
name|contains
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
break|break;
block|}
operator|++
name|partPrefixToDrop
expr_stmt|;
block|}
return|return
name|partPrefixToDrop
return|;
block|}
specifier|protected
specifier|abstract
name|boolean
name|expectView
parameter_list|()
function_decl|;
comment|/**    * Add the table partitions to be modified in the output, so that it is available for the    * pre-execution hook. If the partition does not exist, throw an error if    * throwIfNonExistent is true, otherwise ignore it.    */
specifier|private
name|void
name|addTableDropPartsOutputs
parameter_list|(
name|Table
name|tab
parameter_list|,
name|Collection
argument_list|<
name|List
argument_list|<
name|ExprNodeGenericFuncDesc
argument_list|>
argument_list|>
name|partitionSpecs
parameter_list|,
name|boolean
name|throwIfNonExistent
parameter_list|)
throws|throws
name|SemanticException
block|{
for|for
control|(
name|List
argument_list|<
name|ExprNodeGenericFuncDesc
argument_list|>
name|specs
range|:
name|partitionSpecs
control|)
block|{
for|for
control|(
name|ExprNodeGenericFuncDesc
name|partitionSpec
range|:
name|specs
control|)
block|{
name|List
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|boolean
name|hasUnknown
init|=
literal|false
decl_stmt|;
try|try
block|{
name|hasUnknown
operator|=
name|db
operator|.
name|getPartitionsByExpr
argument_list|(
name|tab
argument_list|,
name|partitionSpec
argument_list|,
name|conf
argument_list|,
name|parts
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PARTITION
operator|.
name|getMsg
argument_list|(
name|partitionSpec
operator|.
name|getExprString
argument_list|()
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|hasUnknown
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Unexpected unknown partitions for "
operator|+
name|partitionSpec
operator|.
name|getExprString
argument_list|()
argument_list|)
throw|;
block|}
comment|// TODO: ifExists could be moved to metastore. In fact it already supports that. Check it
comment|//       for now since we get parts for output anyway, so we can get the error message
comment|//       earlier... If we get rid of output, we can get rid of this.
if|if
condition|(
name|parts
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|throwIfNonExistent
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PARTITION
operator|.
name|getMsg
argument_list|(
name|partitionSpec
operator|.
name|getExprString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
block|}
for|for
control|(
name|Partition
name|p
range|:
name|parts
control|)
block|{
name|outputs
operator|.
name|add
argument_list|(
operator|new
name|WriteEntity
argument_list|(
name|p
argument_list|,
name|WriteEntity
operator|.
name|WriteType
operator|.
name|DDL_EXCLUSIVE
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
end_class

end_unit

