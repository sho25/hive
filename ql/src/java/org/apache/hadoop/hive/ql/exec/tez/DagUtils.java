begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|security
operator|.
name|auth
operator|.
name|login
operator|.
name|LoginException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FilenameUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DistributedFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Context
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecReducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|BucketizedHiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveOutputFormatImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|BaseWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|Hadoop20Shims
operator|.
name|NullOutputCommitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|OutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|LocalResource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|LocalResourceType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|LocalResourceVisibility
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|util
operator|.
name|ConverterUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|util
operator|.
name|Records
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|Edge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeProperty
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeProperty
operator|.
name|ConnectionPattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeProperty
operator|.
name|SourceType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|InputDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|OutputDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|ProcessorDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|Vertex
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|engine
operator|.
name|lib
operator|.
name|input
operator|.
name|ShuffledMergedInput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|engine
operator|.
name|lib
operator|.
name|output
operator|.
name|OnFileSortedOutput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|InputSplitInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MRHelpers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MultiStageMRConfToTezTranslator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|processor
operator|.
name|map
operator|.
name|MapProcessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|processor
operator|.
name|reduce
operator|.
name|ReduceProcessor
import|;
end_import

begin_comment
comment|/**  * DagUtils. DagUtils is a collection of helper methods to convert  * map and reduce work to tez vertices and edges. It handles configuration  * objects, file localization and vertex/edge creation.  */
end_comment

begin_class
specifier|public
class|class
name|DagUtils
block|{
comment|/*    * Creates the configuration object necessary to run a specific vertex from    * map work. This includes input formats, input processor, etc. =  */
specifier|private
specifier|static
name|JobConf
name|initializeVertexConf
parameter_list|(
name|JobConf
name|baseConf
parameter_list|,
name|MapWork
name|mapWork
parameter_list|)
block|{
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|(
name|baseConf
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapWork
operator|.
name|getNumMapTasks
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|setInt
argument_list|(
name|MRJobConfig
operator|.
name|NUM_MAPS
argument_list|,
name|mapWork
operator|.
name|getNumMapTasks
argument_list|()
operator|.
name|intValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMaxSplitSize
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMAXSPLITSIZE
argument_list|,
name|mapWork
operator|.
name|getMaxSplitSize
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMinSplitSize
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZE
argument_list|,
name|mapWork
operator|.
name|getMinSplitSize
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMinSplitSizePerNode
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZEPERNODE
argument_list|,
name|mapWork
operator|.
name|getMinSplitSizePerNode
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMinSplitSizePerRack
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZEPERRACK
argument_list|,
name|mapWork
operator|.
name|getMinSplitSizePerRack
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Utilities
operator|.
name|setInputAttributes
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|)
expr_stmt|;
name|String
name|inpFormat
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEINPUTFORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|inpFormat
operator|==
literal|null
operator|)
operator|||
operator|(
operator|!
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|inpFormat
argument_list|)
operator|)
condition|)
block|{
name|inpFormat
operator|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getInputFormatClassName
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|isUseBucketizedHiveInputFormat
argument_list|()
condition|)
block|{
name|inpFormat
operator|=
name|BucketizedHiveInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|MAP_CLASS_ATTR
argument_list|,
name|ExecMapper
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|INPUT_FORMAT_CLASS_ATTR
argument_list|,
name|inpFormat
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
comment|/**    * Given two vertices and their respective configuration objects createEdge    * will create an Edge object that connects the two. Currently the edge will    * always be a stable bi-partite edge.    *    * @param vConf JobConf of the first vertex    * @param v The first vertex (source)    * @param wConf JobConf of the second vertex    * @param w The second vertex (sink)    * @return    */
specifier|public
specifier|static
name|Edge
name|createEdge
parameter_list|(
name|JobConf
name|vConf
parameter_list|,
name|Vertex
name|v
parameter_list|,
name|JobConf
name|wConf
parameter_list|,
name|Vertex
name|w
parameter_list|)
block|{
comment|// Tez needs to setup output subsequent input pairs correctly
name|MultiStageMRConfToTezTranslator
operator|.
name|translateVertexConfToTez
argument_list|(
name|wConf
argument_list|,
name|vConf
argument_list|)
expr_stmt|;
comment|// all edges are of the same type right now
name|EdgeProperty
name|edgeProperty
init|=
operator|new
name|EdgeProperty
argument_list|(
name|ConnectionPattern
operator|.
name|BIPARTITE
argument_list|,
name|SourceType
operator|.
name|STABLE
argument_list|,
operator|new
name|OutputDescriptor
argument_list|(
name|OnFileSortedOutput
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|,
operator|new
name|InputDescriptor
argument_list|(
name|ShuffledMergedInput
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|Edge
argument_list|(
name|v
argument_list|,
name|w
argument_list|,
name|edgeProperty
argument_list|)
return|;
block|}
comment|/*    * Helper function to create Vertex from MapWork.    */
specifier|private
specifier|static
name|Vertex
name|createVertex
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|MapWork
name|mapWork
parameter_list|,
name|int
name|seqNo
parameter_list|,
name|LocalResource
name|appJarLr
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|additionalLr
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|mrScratchDir
parameter_list|,
name|Context
name|ctx
parameter_list|)
throws|throws
name|Exception
block|{
comment|// map work can contain localwork, i.e: hashtables for map-side joins
name|Path
name|hashTableArchive
init|=
name|createHashTables
argument_list|(
name|mapWork
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|LocalResource
name|localWorkLr
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hashTableArchive
operator|!=
literal|null
condition|)
block|{
name|localWorkLr
operator|=
name|createLocalResource
argument_list|(
name|fs
argument_list|,
name|hashTableArchive
argument_list|,
name|LocalResourceType
operator|.
name|ARCHIVE
argument_list|,
name|LocalResourceVisibility
operator|.
name|APPLICATION
argument_list|)
expr_stmt|;
block|}
comment|// write out the operator plan
name|Path
name|planPath
init|=
name|Utilities
operator|.
name|setMapWork
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|,
name|mrScratchDir
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|LocalResource
name|planLr
init|=
name|createLocalResource
argument_list|(
name|fs
argument_list|,
name|planPath
argument_list|,
name|LocalResourceType
operator|.
name|FILE
argument_list|,
name|LocalResourceVisibility
operator|.
name|APPLICATION
argument_list|)
decl_stmt|;
comment|// setup input paths and split info
name|List
argument_list|<
name|Path
argument_list|>
name|inputPaths
init|=
name|Utilities
operator|.
name|getInputPaths
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|,
name|mrScratchDir
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|ctx
argument_list|)
decl_stmt|;
name|Utilities
operator|.
name|setInputPaths
argument_list|(
name|conf
argument_list|,
name|inputPaths
argument_list|)
expr_stmt|;
name|InputSplitInfo
name|inputSplitInfo
init|=
name|MRHelpers
operator|.
name|generateInputSplits
argument_list|(
name|conf
argument_list|,
name|mrScratchDir
argument_list|)
decl_stmt|;
name|MultiStageMRConfToTezTranslator
operator|.
name|translateVertexConfToTez
argument_list|(
name|conf
argument_list|,
name|conf
argument_list|)
expr_stmt|;
comment|// finally create the vertex
name|Vertex
name|map
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|inputSplitInfo
operator|.
name|getNumTasks
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|map
operator|=
operator|new
name|Vertex
argument_list|(
literal|"Map "
operator|+
name|seqNo
argument_list|,
operator|new
name|ProcessorDescriptor
argument_list|(
name|MapProcessor
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|MRHelpers
operator|.
name|createUserPayloadFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|,
name|inputSplitInfo
operator|.
name|getNumTasks
argument_list|()
argument_list|,
name|MRHelpers
operator|.
name|getMapResource
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|environment
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|MRHelpers
operator|.
name|updateEnvironmentForMRTasks
argument_list|(
name|conf
argument_list|,
name|environment
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|map
operator|.
name|setTaskEnvironment
argument_list|(
name|environment
argument_list|)
expr_stmt|;
name|map
operator|.
name|setJavaOpts
argument_list|(
name|MRHelpers
operator|.
name|getMapJavaOpts
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|map
operator|.
name|setTaskLocationsHint
argument_list|(
name|inputSplitInfo
operator|.
name|getTaskLocationHints
argument_list|()
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
name|localResources
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|localWorkLr
operator|!=
literal|null
condition|)
block|{
name|localResources
operator|.
name|put
argument_list|(
name|hashTableArchive
operator|.
name|getName
argument_list|()
argument_list|,
name|localWorkLr
argument_list|)
expr_stmt|;
block|}
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|appJarLr
argument_list|)
argument_list|,
name|appJarLr
argument_list|)
expr_stmt|;
for|for
control|(
name|LocalResource
name|lr
range|:
name|additionalLr
control|)
block|{
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|lr
argument_list|)
argument_list|,
name|lr
argument_list|)
expr_stmt|;
block|}
name|localResources
operator|.
name|put
argument_list|(
name|FilenameUtils
operator|.
name|getName
argument_list|(
name|planPath
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|planLr
argument_list|)
expr_stmt|;
name|MRHelpers
operator|.
name|updateLocalResourcesForInputSplits
argument_list|(
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
argument_list|,
name|inputSplitInfo
argument_list|,
name|localResources
argument_list|)
expr_stmt|;
name|map
operator|.
name|setTaskLocalResources
argument_list|(
name|localResources
argument_list|)
expr_stmt|;
block|}
return|return
name|map
return|;
block|}
comment|/*    * If the given MapWork has local work embedded we need to generate the corresponding    * hash tables and localize them. These tables will be used by the map work to do    * map-side joins.    */
specifier|private
specifier|static
name|Path
name|createHashTables
parameter_list|(
name|MapWork
name|mapWork
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
comment|/*    * Helper function to create JobConf for specific ReduceWork.    */
specifier|private
specifier|static
name|JobConf
name|initializeVertexConf
parameter_list|(
name|JobConf
name|baseConf
parameter_list|,
name|ReduceWork
name|reduceWork
parameter_list|)
block|{
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|(
name|baseConf
argument_list|)
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|REDUCE_CLASS_ATTR
argument_list|,
name|ExecReducer
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|boolean
name|useSpeculativeExecReducers
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESPECULATIVEEXECREDUCERS
argument_list|)
decl_stmt|;
name|HiveConf
operator|.
name|setBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPSPECULATIVEEXECREDUCERS
argument_list|,
name|useSpeculativeExecReducers
argument_list|)
expr_stmt|;
comment|// reducers should have been set at planning stage
comment|// job.setNumberOfReducers(rWork.getNumberOfReducers())
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|NUM_REDUCES
argument_list|,
name|reduceWork
operator|.
name|getNumReduceTasks
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
comment|/*    * Helper function to create Vertex for given ReduceWork.    */
specifier|private
specifier|static
name|Vertex
name|createVertex
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|ReduceWork
name|reduceWork
parameter_list|,
name|int
name|seqNo
parameter_list|,
name|LocalResource
name|appJarLr
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|additionalLr
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|mrScratchDir
parameter_list|,
name|Context
name|ctx
parameter_list|)
throws|throws
name|Exception
block|{
comment|// write out the operator plan
name|Path
name|planPath
init|=
name|Utilities
operator|.
name|setReduceWork
argument_list|(
name|conf
argument_list|,
name|reduceWork
argument_list|,
name|mrScratchDir
operator|.
name|getName
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|LocalResource
name|planLr
init|=
name|createLocalResource
argument_list|(
name|fs
argument_list|,
name|planPath
argument_list|,
name|LocalResourceType
operator|.
name|FILE
argument_list|,
name|LocalResourceVisibility
operator|.
name|APPLICATION
argument_list|)
decl_stmt|;
comment|// create the vertex
name|Vertex
name|reducer
init|=
operator|new
name|Vertex
argument_list|(
literal|"Reducer "
operator|+
name|seqNo
argument_list|,
operator|new
name|ProcessorDescriptor
argument_list|(
name|ReduceProcessor
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|MRHelpers
operator|.
name|createUserPayloadFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|,
name|reduceWork
operator|.
name|getNumReduceTasks
argument_list|()
argument_list|,
name|MRHelpers
operator|.
name|getReduceResource
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|environment
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|MRHelpers
operator|.
name|updateEnvironmentForMRTasks
argument_list|(
name|conf
argument_list|,
name|environment
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|reducer
operator|.
name|setTaskEnvironment
argument_list|(
name|environment
argument_list|)
expr_stmt|;
name|reducer
operator|.
name|setJavaOpts
argument_list|(
name|MRHelpers
operator|.
name|getReduceJavaOpts
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
name|localResources
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|appJarLr
argument_list|)
argument_list|,
name|appJarLr
argument_list|)
expr_stmt|;
for|for
control|(
name|LocalResource
name|lr
range|:
name|additionalLr
control|)
block|{
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|lr
argument_list|)
argument_list|,
name|lr
argument_list|)
expr_stmt|;
block|}
name|localResources
operator|.
name|put
argument_list|(
name|FilenameUtils
operator|.
name|getName
argument_list|(
name|planPath
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|planLr
argument_list|)
expr_stmt|;
name|reducer
operator|.
name|setTaskLocalResources
argument_list|(
name|localResources
argument_list|)
expr_stmt|;
return|return
name|reducer
return|;
block|}
comment|/*    * Helper method to create a yarn local resource.    */
specifier|private
specifier|static
name|LocalResource
name|createLocalResource
parameter_list|(
name|FileSystem
name|remoteFs
parameter_list|,
name|Path
name|file
parameter_list|,
name|LocalResourceType
name|type
parameter_list|,
name|LocalResourceVisibility
name|visibility
parameter_list|)
block|{
name|FileStatus
name|fstat
init|=
literal|null
decl_stmt|;
try|try
block|{
name|fstat
operator|=
name|remoteFs
operator|.
name|getFileStatus
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
name|URL
name|resourceURL
init|=
name|ConverterUtils
operator|.
name|getYarnUrlFromPath
argument_list|(
name|file
argument_list|)
decl_stmt|;
name|long
name|resourceSize
init|=
name|fstat
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|long
name|resourceModificationTime
init|=
name|fstat
operator|.
name|getModificationTime
argument_list|()
decl_stmt|;
name|LocalResource
name|lr
init|=
name|Records
operator|.
name|newRecord
argument_list|(
name|LocalResource
operator|.
name|class
argument_list|)
decl_stmt|;
name|lr
operator|.
name|setResource
argument_list|(
name|resourceURL
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setType
argument_list|(
name|type
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setSize
argument_list|(
name|resourceSize
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setVisibility
argument_list|(
name|visibility
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setTimestamp
argument_list|(
name|resourceModificationTime
argument_list|)
expr_stmt|;
return|return
name|lr
return|;
block|}
comment|/**    * @param conf    * @return path to destination directory on hdfs    * @throws LoginException if we are unable to figure user information    * @throws IOException when any dfs operation fails.    */
specifier|private
specifier|static
name|Path
name|getDefaultDestDir
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|LoginException
throws|,
name|IOException
block|{
name|UserGroupInformation
name|ugi
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getUGIForConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|userName
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getShortUserName
argument_list|(
name|ugi
argument_list|)
decl_stmt|;
name|String
name|userPathStr
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_USER_INSTALL_DIR
argument_list|)
decl_stmt|;
name|Path
name|userPath
init|=
operator|new
name|Path
argument_list|(
name|userPathStr
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|userPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|fs
operator|instanceof
name|DistributedFileSystem
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_HDFS_URI
operator|.
name|format
argument_list|(
name|userPathStr
argument_list|)
argument_list|)
throw|;
block|}
name|String
name|jarPathStr
init|=
name|userPathStr
operator|+
literal|"/"
operator|+
name|userName
decl_stmt|;
name|String
name|hdfsDirPathStr
init|=
name|jarPathStr
decl_stmt|;
name|Path
name|hdfsDirPath
init|=
operator|new
name|Path
argument_list|(
name|hdfsDirPathStr
argument_list|)
decl_stmt|;
name|FileStatus
name|fstatus
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|hdfsDirPath
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fstatus
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_DIR
operator|.
name|format
argument_list|(
name|hdfsDirPath
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|Path
name|retPath
init|=
operator|new
name|Path
argument_list|(
name|hdfsDirPath
operator|.
name|toString
argument_list|()
operator|+
literal|"/.hiveJars"
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|retPath
argument_list|)
expr_stmt|;
return|return
name|retPath
return|;
block|}
comment|/**    * Localizes files, archives and jars the user has instructed us    * to provide on the cluster as resources for execution.    *    * @param conf    * @return List<LocalResource> local resources to add to execution    * @throws IOException when hdfs operation fails    * @throws LoginException when getDefaultDestDir fails with the same exception    */
specifier|public
specifier|static
name|List
argument_list|<
name|LocalResource
argument_list|>
name|localizeTempFiles
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|LoginException
block|{
name|List
argument_list|<
name|LocalResource
argument_list|>
name|tmpResources
init|=
operator|new
name|ArrayList
argument_list|<
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|auxJars
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEAUXJARS
argument_list|)
decl_stmt|;
name|String
name|addedJars
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEADDEDJARS
argument_list|)
decl_stmt|;
name|String
name|addedFiles
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEADDEDFILES
argument_list|)
decl_stmt|;
name|String
name|addedArchives
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEADDEDARCHIVES
argument_list|)
decl_stmt|;
comment|// need to localize the additional jars and files
comment|// we need the directory on hdfs to which we shall put all these files
name|String
name|hdfsDirPathStr
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_JAR_DIRECTORY
argument_list|)
decl_stmt|;
name|Path
name|hdfsDirPath
init|=
operator|new
name|Path
argument_list|(
name|hdfsDirPathStr
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|hdfsDirPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|fs
operator|instanceof
name|DistributedFileSystem
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_HDFS_URI
operator|.
name|format
argument_list|(
name|hdfsDirPathStr
argument_list|)
argument_list|)
throw|;
block|}
name|FileStatus
name|fstatus
init|=
literal|null
decl_stmt|;
try|try
block|{
name|fstatus
operator|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|hdfsDirPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fe
parameter_list|)
block|{
comment|// do nothing
block|}
if|if
condition|(
operator|(
name|fstatus
operator|==
literal|null
operator|)
operator|||
operator|(
operator|!
name|fstatus
operator|.
name|isDir
argument_list|()
operator|)
condition|)
block|{
name|Path
name|destDir
init|=
name|getDefaultDestDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|hdfsDirPathStr
operator|=
name|destDir
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
name|String
name|allFiles
init|=
name|auxJars
operator|+
literal|","
operator|+
name|addedJars
operator|+
literal|","
operator|+
name|addedFiles
operator|+
literal|","
operator|+
name|addedArchives
decl_stmt|;
name|String
index|[]
name|allFilesArr
init|=
name|allFiles
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|file
range|:
name|allFilesArr
control|)
block|{
name|String
name|hdfsFilePathStr
init|=
name|hdfsDirPathStr
operator|+
literal|"/"
operator|+
name|getResourceBaseName
argument_list|(
name|file
argument_list|)
decl_stmt|;
name|LocalResource
name|localResource
init|=
name|localizeResource
argument_list|(
operator|new
name|Path
argument_list|(
name|file
argument_list|)
argument_list|,
operator|new
name|Path
argument_list|(
name|hdfsFilePathStr
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|tmpResources
operator|.
name|add
argument_list|(
name|localResource
argument_list|)
expr_stmt|;
block|}
return|return
name|tmpResources
return|;
block|}
comment|// the api that finds the jar being used by this class on disk
specifier|private
specifier|static
name|String
name|getExecJarPathLocal
parameter_list|()
throws|throws
name|URISyntaxException
block|{
comment|// returns the location on disc of the jar of this class.
return|return
name|DagUtils
operator|.
name|class
operator|.
name|getProtectionDomain
argument_list|()
operator|.
name|getCodeSource
argument_list|()
operator|.
name|getLocation
argument_list|()
operator|.
name|toURI
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/*    * Helper function to retrieve the basename of a local resource    */
specifier|public
specifier|static
name|String
name|getBaseName
parameter_list|(
name|LocalResource
name|lr
parameter_list|)
block|{
return|return
name|FilenameUtils
operator|.
name|getName
argument_list|(
name|lr
operator|.
name|getResource
argument_list|()
operator|.
name|getFile
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param pathStr - the string from which we try to determine the resource base name    * @return the name of the resource from a given path string.    */
specifier|private
specifier|static
name|String
name|getResourceBaseName
parameter_list|(
name|String
name|pathStr
parameter_list|)
block|{
name|String
index|[]
name|splits
init|=
name|pathStr
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
return|return
name|splits
index|[
name|splits
operator|.
name|length
operator|-
literal|1
index|]
return|;
block|}
comment|/**    * @param src the source file.    * @param dest the destination file.    * @param conf the configuration    * @return true if the file names match else returns false.    * @throws IOException when any file system related call fails    */
specifier|private
specifier|static
name|boolean
name|checkPreExisting
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dest
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|destFS
init|=
name|dest
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|destFS
operator|.
name|exists
argument_list|(
name|dest
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
name|FileStatus
name|destStatus
init|=
name|destFS
operator|.
name|getFileStatus
argument_list|(
name|dest
argument_list|)
decl_stmt|;
if|if
condition|(
name|destStatus
operator|.
name|isDir
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|String
name|srcName
init|=
name|getResourceBaseName
argument_list|(
name|src
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|destName
init|=
name|getResourceBaseName
argument_list|(
name|dest
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcName
operator|.
name|equals
argument_list|(
name|destName
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * @param src path to the source for the resource    * @param dest path in hdfs for the resource    * @param conf    * @return localresource from tez localization.    * @throws IOException when any file system related calls fails.    */
specifier|private
specifier|static
name|LocalResource
name|localizeResource
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dest
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|destFS
init|=
name|dest
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|destFS
operator|instanceof
name|DistributedFileSystem
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_HDFS_URI
operator|.
name|format
argument_list|(
name|dest
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|src
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|checkPreExisting
argument_list|(
name|src
argument_list|,
name|dest
argument_list|,
name|conf
argument_list|)
condition|)
block|{
comment|// copy the src to the destination and create local resource.
comment|// overwrite even if file already exists.
name|destFS
operator|.
name|copyFromLocalFile
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|,
name|src
argument_list|,
name|dest
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|createLocalResource
argument_list|(
name|destFS
argument_list|,
name|dest
argument_list|,
name|LocalResourceType
operator|.
name|FILE
argument_list|,
name|LocalResourceVisibility
operator|.
name|APPLICATION
argument_list|)
return|;
block|}
comment|/**    * Returns a local resource representing the hive-exec jar. This resource will    * be used to execute the plan on the cluster.    * @param conf    * @return LocalResource corresponding to the localized hive exec resource.    * @throws IOException when any file system related call fails.    * @throws LoginException when we are unable to determine the user.    * @throws URISyntaxException when current jar location cannot be determined.    */
specifier|public
specifier|static
name|LocalResource
name|createHiveExecLocalResource
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|LoginException
throws|,
name|URISyntaxException
block|{
name|String
name|hiveJarDir
init|=
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_JAR_DIRECTORY
argument_list|)
decl_stmt|;
name|String
name|currentVersionPathStr
init|=
name|getExecJarPathLocal
argument_list|()
decl_stmt|;
name|String
name|currentJarName
init|=
name|getResourceBaseName
argument_list|(
name|currentVersionPathStr
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
name|Path
name|jarPath
init|=
literal|null
decl_stmt|;
name|FileStatus
name|dirStatus
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hiveJarDir
operator|!=
literal|null
condition|)
block|{
comment|// check if it is a valid directory in HDFS
name|Path
name|hiveJarDirPath
init|=
operator|new
name|Path
argument_list|(
name|hiveJarDir
argument_list|)
decl_stmt|;
name|fs
operator|=
name|hiveJarDirPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|fs
operator|instanceof
name|DistributedFileSystem
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_HDFS_URI
operator|.
name|format
argument_list|(
name|hiveJarDir
argument_list|)
argument_list|)
throw|;
block|}
try|try
block|{
name|dirStatus
operator|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|hiveJarDirPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fe
parameter_list|)
block|{
comment|// do nothing
block|}
if|if
condition|(
operator|(
name|dirStatus
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|dirStatus
operator|.
name|isDir
argument_list|()
operator|)
condition|)
block|{
name|FileStatus
index|[]
name|listFileStatus
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|hiveJarDirPath
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|fstatus
range|:
name|listFileStatus
control|)
block|{
name|String
name|jarName
init|=
name|getResourceBaseName
argument_list|(
name|fstatus
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|jarName
operator|.
name|equals
argument_list|(
name|currentJarName
argument_list|)
condition|)
block|{
comment|// we have found the jar we need.
name|jarPath
operator|=
name|fstatus
operator|.
name|getPath
argument_list|()
expr_stmt|;
return|return
name|localizeResource
argument_list|(
literal|null
argument_list|,
name|jarPath
argument_list|,
name|conf
argument_list|)
return|;
block|}
block|}
comment|// jar wasn't in the directory, copy the one in current use
if|if
condition|(
name|jarPath
operator|==
literal|null
condition|)
block|{
return|return
name|localizeResource
argument_list|(
operator|new
name|Path
argument_list|(
name|currentVersionPathStr
argument_list|)
argument_list|,
name|hiveJarDirPath
argument_list|,
name|conf
argument_list|)
return|;
block|}
block|}
block|}
comment|/*      * specified location does not exist or is not a directory      * try to push the jar to the hdfs location pointed by      * config variable HIVE_INSTALL_DIR. Path will be      * HIVE_INSTALL_DIR/{username}/.hiveJars/      */
if|if
condition|(
operator|(
name|hiveJarDir
operator|==
literal|null
operator|)
operator|||
operator|(
name|dirStatus
operator|==
literal|null
operator|)
operator|||
operator|(
operator|(
name|dirStatus
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|dirStatus
operator|.
name|isDir
argument_list|()
operator|)
operator|)
condition|)
block|{
name|Path
name|dest
init|=
name|getDefaultDestDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|destPathStr
init|=
name|dest
operator|.
name|toString
argument_list|()
decl_stmt|;
name|String
name|jarPathStr
init|=
name|destPathStr
operator|+
literal|"/"
operator|+
name|currentJarName
decl_stmt|;
name|dirStatus
operator|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dest
argument_list|)
expr_stmt|;
if|if
condition|(
name|dirStatus
operator|.
name|isDir
argument_list|()
condition|)
block|{
return|return
name|localizeResource
argument_list|(
operator|new
name|Path
argument_list|(
name|currentVersionPathStr
argument_list|)
argument_list|,
operator|new
name|Path
argument_list|(
name|jarPathStr
argument_list|)
argument_list|,
name|conf
argument_list|)
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_DIR
operator|.
name|format
argument_list|(
name|dest
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
block|}
comment|// we couldn't find any valid locations. Throw exception
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|NO_VALID_LOCATIONS
operator|.
name|getMsg
argument_list|()
argument_list|)
throw|;
block|}
comment|/**    * Creates and initializes a JobConf object that can be used to execute    * the DAG. The configuration object will contain configurations from mapred-site    * overlaid with key/value pairs from the hiveConf object. Finally it will also    * contain some hive specific configurations that do not change from DAG to DAG.    *    * @param hiveConf Current hiveConf for the execution    * @return JobConf base configuration for job execution    * @throws IOException    */
specifier|public
specifier|static
name|JobConf
name|createConfiguration
parameter_list|(
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|IOException
block|{
name|hiveConf
operator|.
name|setBoolean
argument_list|(
literal|"mapred.mapper.new-api"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|JobConf
name|conf
init|=
operator|(
name|JobConf
operator|)
name|MRHelpers
operator|.
name|getBaseMRConfiguration
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|entry
range|:
name|hiveConf
control|)
block|{
if|if
condition|(
name|conf
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
operator|==
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|conf
operator|.
name|set
argument_list|(
literal|"mapreduce.framework.name"
argument_list|,
literal|"yarn-tez"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapreduce.job.output.committer.class"
argument_list|,
name|NullOutputCommitter
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|MRJobConfig
operator|.
name|SETUP_CLEANUP_NEEDED
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|MRJobConfig
operator|.
name|TASK_CLEANUP_NEEDED
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setClass
argument_list|(
name|MRJobConfig
operator|.
name|OUTPUT_FORMAT_CLASS_ATTR
argument_list|,
name|HiveOutputFormatImpl
operator|.
name|class
argument_list|,
name|OutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|MAP_CLASS_ATTR
argument_list|,
name|ExecMapper
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|OUTPUT_KEY_CLASS
argument_list|,
name|HiveKey
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|OUTPUT_VALUE_CLASS
argument_list|,
name|BytesWritable
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|PARTITIONER_CLASS_ATTR
argument_list|,
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEPARTITIONER
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
comment|/**    * Creates and initializes the JobConf object for a given BaseWork object.    *    * @param conf Any configurations in conf will be copied to the resulting new JobConf object.    * @param work BaseWork will be used to populate the configuration object.    * @return JobConf new configuration object    */
specifier|public
specifier|static
name|JobConf
name|initializeVertexConf
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|BaseWork
name|work
parameter_list|)
block|{
comment|// simply dispatch the call to the right method for the actual (sub-) type of
comment|// BaseWork.
if|if
condition|(
name|work
operator|instanceof
name|MapWork
condition|)
block|{
return|return
name|initializeVertexConf
argument_list|(
name|conf
argument_list|,
operator|(
name|MapWork
operator|)
name|work
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|work
operator|instanceof
name|ReduceWork
condition|)
block|{
return|return
name|initializeVertexConf
argument_list|(
name|conf
argument_list|,
operator|(
name|ReduceWork
operator|)
name|work
argument_list|)
return|;
block|}
else|else
block|{
assert|assert
literal|false
assert|;
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Create a vertex from a given work object.    *    * @param conf JobConf to be used to this execution unit    * @param work The instance of BaseWork representing the actual work to be performed    * by this vertex.    * @param scratchDir HDFS scratch dir for this execution unit.    * @param seqNo Unique number for this DAG. Used to name the vertex.    * @param appJarLr Local resource for hive-exec.    * @param additionalLr    * @param fileSystem FS corresponding to scratchDir and LocalResources    * @param ctx This query's context    * @return Vertex    */
specifier|public
specifier|static
name|Vertex
name|createVertex
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|BaseWork
name|work
parameter_list|,
name|Path
name|scratchDir
parameter_list|,
name|int
name|seqNo
parameter_list|,
name|LocalResource
name|appJarLr
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|additionalLr
parameter_list|,
name|FileSystem
name|fileSystem
parameter_list|,
name|Context
name|ctx
parameter_list|)
throws|throws
name|Exception
block|{
comment|// simply dispatch the call to the right method for the actual (sub-) type of
comment|// BaseWork.
if|if
condition|(
name|work
operator|instanceof
name|MapWork
condition|)
block|{
return|return
name|createVertex
argument_list|(
name|conf
argument_list|,
operator|(
name|MapWork
operator|)
name|work
argument_list|,
name|seqNo
argument_list|,
name|appJarLr
argument_list|,
name|additionalLr
argument_list|,
name|fileSystem
argument_list|,
name|scratchDir
argument_list|,
name|ctx
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|work
operator|instanceof
name|ReduceWork
condition|)
block|{
return|return
name|createVertex
argument_list|(
name|conf
argument_list|,
operator|(
name|ReduceWork
operator|)
name|work
argument_list|,
name|seqNo
argument_list|,
name|appJarLr
argument_list|,
name|additionalLr
argument_list|,
name|fileSystem
argument_list|,
name|scratchDir
argument_list|,
name|ctx
argument_list|)
return|;
block|}
else|else
block|{
assert|assert
literal|false
assert|;
return|return
literal|null
return|;
block|}
block|}
specifier|private
name|DagUtils
parameter_list|()
block|{
comment|// don't instantiate
block|}
block|}
end_class

end_unit

