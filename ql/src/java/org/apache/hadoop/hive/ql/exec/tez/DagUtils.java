begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterators
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FilenameUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Context
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecReducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|tez
operator|.
name|tools
operator|.
name|TezMergedLogicalInput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|BucketizedHiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|CombineHiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveOutputFormatImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|merge
operator|.
name|MergeFileMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|merge
operator|.
name|MergeFileOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|merge
operator|.
name|MergeFileWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|BaseWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezEdgeProperty
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezEdgeProperty
operator|.
name|EdgeType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TezWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|stats
operator|.
name|StatsFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|stats
operator|.
name|StatsPublisher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShimsSecure
operator|.
name|NullOutputCommitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|DataOutputBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|OutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|LocalResource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|LocalResourceType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|LocalResourceVisibility
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|Resource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|util
operator|.
name|ConverterUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|util
operator|.
name|Records
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|common
operator|.
name|TezUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|DAG
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|DataSinkDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|DataSourceDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|Edge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeManagerPluginDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|EdgeProperty
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|GroupInputEdge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|InputDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|InputInitializerDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|OutputDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|PreWarmVertex
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|ProcessorDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|TezConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|TezException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|UserPayload
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|Vertex
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|VertexGroup
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|api
operator|.
name|VertexManagerPluginDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|dag
operator|.
name|library
operator|.
name|vertexmanager
operator|.
name|ShuffleVertexManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MRHelpers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MRInputHelpers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|hadoop
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|input
operator|.
name|MRInputLegacy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|output
operator|.
name|MROutput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|mapreduce
operator|.
name|partition
operator|.
name|MRPartitioner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|api
operator|.
name|TezRuntimeConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|common
operator|.
name|comparator
operator|.
name|TezBytesComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|common
operator|.
name|serializer
operator|.
name|TezBytesWritableSerialization
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|conf
operator|.
name|OrderedPartitionedKVEdgeConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|conf
operator|.
name|UnorderedKVEdgeConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|conf
operator|.
name|UnorderedPartitionedKVEdgeConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|tez
operator|.
name|runtime
operator|.
name|library
operator|.
name|input
operator|.
name|ConcatenatedMergedKeyValueInput
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|security
operator|.
name|auth
operator|.
name|login
operator|.
name|LoginException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_comment
comment|/**  * DagUtils. DagUtils is a collection of helper methods to convert  * map and reduce work to tez vertices and edges. It handles configuration  * objects, file localization and vertex/edge creation.  */
end_comment

begin_class
specifier|public
class|class
name|DagUtils
block|{
specifier|public
specifier|static
specifier|final
name|String
name|TEZ_TMP_DIR_KEY
init|=
literal|"_hive_tez_tmp_dir"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|DagUtils
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|TEZ_DIR
init|=
literal|"_tez_scratch_dir"
decl_stmt|;
specifier|private
specifier|static
name|DagUtils
name|instance
decl_stmt|;
specifier|private
name|void
name|addCredentials
parameter_list|(
name|MapWork
name|mapWork
parameter_list|,
name|DAG
name|dag
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|paths
init|=
name|mapWork
operator|.
name|getPathToAliases
argument_list|()
operator|.
name|keySet
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|paths
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Iterator
argument_list|<
name|URI
argument_list|>
name|pathIterator
init|=
name|Iterators
operator|.
name|transform
argument_list|(
name|paths
operator|.
name|iterator
argument_list|()
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|URI
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|URI
name|apply
parameter_list|(
name|String
name|input
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|input
argument_list|)
operator|.
name|toUri
argument_list|()
return|;
block|}
block|}
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|URI
argument_list|>
name|uris
init|=
operator|new
name|HashSet
argument_list|<
name|URI
argument_list|>
argument_list|()
decl_stmt|;
name|Iterators
operator|.
name|addAll
argument_list|(
name|uris
argument_list|,
name|pathIterator
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
for|for
control|(
name|URI
name|uri
range|:
name|uris
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Marking URI as needing credentials: "
operator|+
name|uri
argument_list|)
expr_stmt|;
block|}
block|}
name|dag
operator|.
name|addURIsForCredentials
argument_list|(
name|uris
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|addCredentials
parameter_list|(
name|ReduceWork
name|reduceWork
parameter_list|,
name|DAG
name|dag
parameter_list|)
block|{
comment|// nothing at the moment
block|}
comment|/*    * Creates the configuration object necessary to run a specific vertex from    * map work. This includes input formats, input processor, etc.    */
specifier|private
name|JobConf
name|initializeVertexConf
parameter_list|(
name|JobConf
name|baseConf
parameter_list|,
name|Context
name|context
parameter_list|,
name|MapWork
name|mapWork
parameter_list|)
block|{
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|(
name|baseConf
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapWork
operator|.
name|getNumMapTasks
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// Is this required ?
name|conf
operator|.
name|setInt
argument_list|(
name|MRJobConfig
operator|.
name|NUM_MAPS
argument_list|,
name|mapWork
operator|.
name|getNumMapTasks
argument_list|()
operator|.
name|intValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMaxSplitSize
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMAXSPLITSIZE
argument_list|,
name|mapWork
operator|.
name|getMaxSplitSize
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMinSplitSize
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZE
argument_list|,
name|mapWork
operator|.
name|getMinSplitSize
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMinSplitSizePerNode
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZEPERNODE
argument_list|,
name|mapWork
operator|.
name|getMinSplitSizePerNode
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getMinSplitSizePerRack
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HiveConf
operator|.
name|setLongVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|MAPREDMINSPLITSIZEPERRACK
argument_list|,
name|mapWork
operator|.
name|getMinSplitSizePerRack
argument_list|()
operator|.
name|longValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Utilities
operator|.
name|setInputAttributes
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|)
expr_stmt|;
name|String
name|inpFormat
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVETEZINPUTFORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|inpFormat
operator|==
literal|null
operator|)
operator|||
operator|(
operator|!
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|inpFormat
argument_list|)
operator|)
condition|)
block|{
name|inpFormat
operator|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getInputFormatClassName
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|isUseBucketizedHiveInputFormat
argument_list|()
condition|)
block|{
name|inpFormat
operator|=
name|BucketizedHiveInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|isUseOneNullRowInputFormat
argument_list|()
condition|)
block|{
name|inpFormat
operator|=
name|CombineHiveInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|mapWork
operator|.
name|getDummyTableScan
argument_list|()
condition|)
block|{
comment|// hive input format doesn't handle the special condition of no paths + 1
comment|// split correctly.
name|inpFormat
operator|=
name|CombineHiveInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
name|TEZ_TMP_DIR_KEY
argument_list|,
name|context
operator|.
name|getMRTmpPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.mapper.class"
argument_list|,
name|ExecMapper
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.input.format.class"
argument_list|,
name|inpFormat
argument_list|)
expr_stmt|;
if|if
condition|(
name|mapWork
operator|instanceof
name|MergeFileWork
condition|)
block|{
name|MergeFileWork
name|mfWork
init|=
operator|(
name|MergeFileWork
operator|)
name|mapWork
decl_stmt|;
comment|// This mapper class is used for serializaiton/deserializaiton of merge
comment|// file work.
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.mapper.class"
argument_list|,
name|MergeFileMapper
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.input.format.class"
argument_list|,
name|mfWork
operator|.
name|getInputformat
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setClass
argument_list|(
literal|"mapred.output.format.class"
argument_list|,
name|MergeFileOutputFormat
operator|.
name|class
argument_list|,
name|FileOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
return|return
name|conf
return|;
block|}
comment|/**    * Given a Vertex group and a vertex createEdge will create an    * Edge between them.    *    * @param group The parent VertexGroup    * @param vConf The job conf of one of the parrent (grouped) vertices    * @param w The child vertex    * @param edgeProp the edge property of connection between the two    * endpoints.    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"rawtypes"
argument_list|)
specifier|public
name|GroupInputEdge
name|createEdge
parameter_list|(
name|VertexGroup
name|group
parameter_list|,
name|JobConf
name|vConf
parameter_list|,
name|Vertex
name|w
parameter_list|,
name|TezEdgeProperty
name|edgeProp
parameter_list|)
throws|throws
name|IOException
block|{
name|Class
name|mergeInputClass
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating Edge between "
operator|+
name|group
operator|.
name|getGroupName
argument_list|()
operator|+
literal|" and "
operator|+
name|w
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|EdgeType
name|edgeType
init|=
name|edgeProp
operator|.
name|getEdgeType
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|edgeType
condition|)
block|{
case|case
name|BROADCAST_EDGE
case|:
name|mergeInputClass
operator|=
name|ConcatenatedMergedKeyValueInput
operator|.
name|class
expr_stmt|;
break|break;
case|case
name|CUSTOM_EDGE
case|:
block|{
name|mergeInputClass
operator|=
name|ConcatenatedMergedKeyValueInput
operator|.
name|class
expr_stmt|;
name|int
name|numBuckets
init|=
name|edgeProp
operator|.
name|getNumBuckets
argument_list|()
decl_stmt|;
name|VertexManagerPluginDescriptor
name|desc
init|=
name|VertexManagerPluginDescriptor
operator|.
name|create
argument_list|(
name|CustomPartitionVertex
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|ByteBuffer
name|userPayload
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
literal|4
argument_list|)
operator|.
name|putInt
argument_list|(
name|numBuckets
argument_list|)
decl_stmt|;
name|userPayload
operator|.
name|flip
argument_list|()
expr_stmt|;
name|desc
operator|.
name|setUserPayload
argument_list|(
name|UserPayload
operator|.
name|create
argument_list|(
name|userPayload
argument_list|)
argument_list|)
expr_stmt|;
name|w
operator|.
name|setVertexManagerPlugin
argument_list|(
name|desc
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|CUSTOM_SIMPLE_EDGE
case|:
name|mergeInputClass
operator|=
name|ConcatenatedMergedKeyValueInput
operator|.
name|class
expr_stmt|;
break|break;
case|case
name|SIMPLE_EDGE
case|:
name|setupAutoReducerParallelism
argument_list|(
name|edgeProp
argument_list|,
name|w
argument_list|)
expr_stmt|;
comment|// fall through
default|default:
name|mergeInputClass
operator|=
name|TezMergedLogicalInput
operator|.
name|class
expr_stmt|;
break|break;
block|}
return|return
name|GroupInputEdge
operator|.
name|create
argument_list|(
name|group
argument_list|,
name|w
argument_list|,
name|createEdgeProperty
argument_list|(
name|edgeProp
argument_list|,
name|vConf
argument_list|)
argument_list|,
name|InputDescriptor
operator|.
name|create
argument_list|(
name|mergeInputClass
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Given two vertices and the configuration for the source vertex, createEdge    * will create an Edge object that connects the two.    *    * @param vConf JobConf of the first (source) vertex    * @param v The first vertex (source)    * @param w The second vertex (sink)    * @return    */
specifier|public
name|Edge
name|createEdge
parameter_list|(
name|JobConf
name|vConf
parameter_list|,
name|Vertex
name|v
parameter_list|,
name|Vertex
name|w
parameter_list|,
name|TezEdgeProperty
name|edgeProp
parameter_list|)
throws|throws
name|IOException
block|{
switch|switch
condition|(
name|edgeProp
operator|.
name|getEdgeType
argument_list|()
condition|)
block|{
case|case
name|CUSTOM_EDGE
case|:
block|{
name|int
name|numBuckets
init|=
name|edgeProp
operator|.
name|getNumBuckets
argument_list|()
decl_stmt|;
name|ByteBuffer
name|userPayload
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
literal|4
argument_list|)
operator|.
name|putInt
argument_list|(
name|numBuckets
argument_list|)
decl_stmt|;
name|userPayload
operator|.
name|flip
argument_list|()
expr_stmt|;
name|VertexManagerPluginDescriptor
name|desc
init|=
name|VertexManagerPluginDescriptor
operator|.
name|create
argument_list|(
name|CustomPartitionVertex
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|desc
operator|.
name|setUserPayload
argument_list|(
name|UserPayload
operator|.
name|create
argument_list|(
name|userPayload
argument_list|)
argument_list|)
expr_stmt|;
name|w
operator|.
name|setVertexManagerPlugin
argument_list|(
name|desc
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|SIMPLE_EDGE
case|:
block|{
name|setupAutoReducerParallelism
argument_list|(
name|edgeProp
argument_list|,
name|w
argument_list|)
expr_stmt|;
break|break;
block|}
default|default:
comment|// nothing
block|}
return|return
name|Edge
operator|.
name|create
argument_list|(
name|v
argument_list|,
name|w
argument_list|,
name|createEdgeProperty
argument_list|(
name|edgeProp
argument_list|,
name|vConf
argument_list|)
argument_list|)
return|;
block|}
comment|/*    * Helper function to create an edge property from an edge type.    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"rawtypes"
argument_list|)
specifier|private
name|EdgeProperty
name|createEdgeProperty
parameter_list|(
name|TezEdgeProperty
name|edgeProp
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|MRHelpers
operator|.
name|translateMRConfToTez
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|String
name|keyClass
init|=
name|conf
operator|.
name|get
argument_list|(
name|TezRuntimeConfiguration
operator|.
name|TEZ_RUNTIME_KEY_CLASS
argument_list|)
decl_stmt|;
name|String
name|valClass
init|=
name|conf
operator|.
name|get
argument_list|(
name|TezRuntimeConfiguration
operator|.
name|TEZ_RUNTIME_VALUE_CLASS
argument_list|)
decl_stmt|;
name|String
name|partitionerClassName
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"mapred.partitioner.class"
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionerConf
decl_stmt|;
name|EdgeType
name|edgeType
init|=
name|edgeProp
operator|.
name|getEdgeType
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|edgeType
condition|)
block|{
case|case
name|BROADCAST_EDGE
case|:
name|UnorderedKVEdgeConfig
name|et1Conf
init|=
name|UnorderedKVEdgeConfig
operator|.
name|newBuilder
argument_list|(
name|keyClass
argument_list|,
name|valClass
argument_list|)
operator|.
name|setFromConfiguration
argument_list|(
name|conf
argument_list|)
operator|.
name|setKeySerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|setValueSerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
name|et1Conf
operator|.
name|createDefaultBroadcastEdgeProperty
argument_list|()
return|;
case|case
name|CUSTOM_EDGE
case|:
assert|assert
name|partitionerClassName
operator|!=
literal|null
assert|;
name|partitionerConf
operator|=
name|createPartitionerConf
argument_list|(
name|partitionerClassName
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|UnorderedPartitionedKVEdgeConfig
name|et2Conf
init|=
name|UnorderedPartitionedKVEdgeConfig
operator|.
name|newBuilder
argument_list|(
name|keyClass
argument_list|,
name|valClass
argument_list|,
name|MRPartitioner
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|partitionerConf
argument_list|)
operator|.
name|setFromConfiguration
argument_list|(
name|conf
argument_list|)
operator|.
name|setKeySerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|setValueSerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|EdgeManagerPluginDescriptor
name|edgeDesc
init|=
name|EdgeManagerPluginDescriptor
operator|.
name|create
argument_list|(
name|CustomPartitionEdge
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|CustomEdgeConfiguration
name|edgeConf
init|=
operator|new
name|CustomEdgeConfiguration
argument_list|(
name|edgeProp
operator|.
name|getNumBuckets
argument_list|()
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|DataOutputBuffer
name|dob
init|=
operator|new
name|DataOutputBuffer
argument_list|()
decl_stmt|;
name|edgeConf
operator|.
name|write
argument_list|(
name|dob
argument_list|)
expr_stmt|;
name|byte
index|[]
name|userPayload
init|=
name|dob
operator|.
name|getData
argument_list|()
decl_stmt|;
name|edgeDesc
operator|.
name|setUserPayload
argument_list|(
name|UserPayload
operator|.
name|create
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|userPayload
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|et2Conf
operator|.
name|createDefaultCustomEdgeProperty
argument_list|(
name|edgeDesc
argument_list|)
return|;
case|case
name|CUSTOM_SIMPLE_EDGE
case|:
assert|assert
name|partitionerClassName
operator|!=
literal|null
assert|;
name|partitionerConf
operator|=
name|createPartitionerConf
argument_list|(
name|partitionerClassName
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|UnorderedPartitionedKVEdgeConfig
name|et3Conf
init|=
name|UnorderedPartitionedKVEdgeConfig
operator|.
name|newBuilder
argument_list|(
name|keyClass
argument_list|,
name|valClass
argument_list|,
name|MRPartitioner
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|partitionerConf
argument_list|)
operator|.
name|setFromConfiguration
argument_list|(
name|conf
argument_list|)
operator|.
name|setKeySerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|setValueSerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
name|et3Conf
operator|.
name|createDefaultEdgeProperty
argument_list|()
return|;
case|case
name|SIMPLE_EDGE
case|:
default|default:
assert|assert
name|partitionerClassName
operator|!=
literal|null
assert|;
name|partitionerConf
operator|=
name|createPartitionerConf
argument_list|(
name|partitionerClassName
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|OrderedPartitionedKVEdgeConfig
name|et4Conf
init|=
name|OrderedPartitionedKVEdgeConfig
operator|.
name|newBuilder
argument_list|(
name|keyClass
argument_list|,
name|valClass
argument_list|,
name|MRPartitioner
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|partitionerConf
argument_list|)
operator|.
name|setFromConfiguration
argument_list|(
name|conf
argument_list|)
operator|.
name|setKeySerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|TezBytesComparator
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|setValueSerializationClass
argument_list|(
name|TezBytesWritableSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
name|et4Conf
operator|.
name|createDefaultEdgeProperty
argument_list|()
return|;
block|}
block|}
comment|/**    * Utility method to create a stripped down configuration for the MR partitioner.    *    * @param partitionerClassName    *          the real MR partitioner class name    * @param baseConf    *          a base configuration to extract relevant properties    * @return    */
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|createPartitionerConf
parameter_list|(
name|String
name|partitionerClassName
parameter_list|,
name|Configuration
name|baseConf
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionerConf
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|partitionerConf
operator|.
name|put
argument_list|(
literal|"mapred.partitioner.class"
argument_list|,
name|partitionerClassName
argument_list|)
expr_stmt|;
if|if
condition|(
name|baseConf
operator|.
name|get
argument_list|(
literal|"mapreduce.totalorderpartitioner.path"
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|partitionerConf
operator|.
name|put
argument_list|(
literal|"mapreduce.totalorderpartitioner.path"
argument_list|,
name|baseConf
operator|.
name|get
argument_list|(
literal|"mapreduce.totalorderpartitioner.path"
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|partitionerConf
return|;
block|}
comment|/*    * Helper to determine the size of the container requested    * from yarn. Falls back to Map-reduce's map size if tez    * container size isn't set.    */
specifier|private
name|Resource
name|getContainerResource
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|int
name|memory
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVETEZCONTAINERSIZE
argument_list|)
operator|>
literal|0
condition|?
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVETEZCONTAINERSIZE
argument_list|)
else|:
name|conf
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|MAP_MEMORY_MB
argument_list|,
name|MRJobConfig
operator|.
name|DEFAULT_MAP_MEMORY_MB
argument_list|)
decl_stmt|;
name|int
name|cpus
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|MAP_CPU_VCORES
argument_list|,
name|MRJobConfig
operator|.
name|DEFAULT_MAP_CPU_VCORES
argument_list|)
decl_stmt|;
return|return
name|Resource
operator|.
name|newInstance
argument_list|(
name|memory
argument_list|,
name|cpus
argument_list|)
return|;
block|}
comment|/*    * Helper to setup default environment for a task in YARN.    */
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getContainerEnvironment
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|boolean
name|isMap
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|environment
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|MRHelpers
operator|.
name|updateEnvBasedOnMRTaskEnv
argument_list|(
name|conf
argument_list|,
name|environment
argument_list|,
name|isMap
argument_list|)
expr_stmt|;
return|return
name|environment
return|;
block|}
comment|/*    * Helper to determine what java options to use for the containers    * Falls back to Map-reduces map java opts if no tez specific options    * are set    */
specifier|private
name|String
name|getContainerJavaOpts
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|javaOpts
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVETEZJAVAOPTS
argument_list|)
decl_stmt|;
if|if
condition|(
name|javaOpts
operator|!=
literal|null
operator|&&
operator|!
name|javaOpts
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
name|logLevel
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVETEZLOGLEVEL
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|logProps
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|TezUtils
operator|.
name|addLog4jSystemProperties
argument_list|(
name|logLevel
argument_list|,
name|logProps
argument_list|)
expr_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|str
range|:
name|logProps
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|str
argument_list|)
operator|.
name|append
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
block|}
return|return
name|javaOpts
operator|+
literal|" "
operator|+
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
return|return
name|MRHelpers
operator|.
name|getJavaOptsForMRMapper
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/*    * Helper function to create Vertex from MapWork.    */
specifier|private
name|Vertex
name|createVertex
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|MapWork
name|mapWork
parameter_list|,
name|LocalResource
name|appJarLr
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|additionalLr
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|mrScratchDir
parameter_list|,
name|Context
name|ctx
parameter_list|,
name|TezWork
name|tezWork
parameter_list|)
throws|throws
name|Exception
block|{
name|Path
name|tezDir
init|=
name|getTezDir
argument_list|(
name|mrScratchDir
argument_list|)
decl_stmt|;
comment|// set up the operator plan
name|Utilities
operator|.
name|cacheMapWork
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|,
name|mrScratchDir
argument_list|)
expr_stmt|;
comment|// create the directories FileSinkOperators need
name|Utilities
operator|.
name|createTmpDirs
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|)
expr_stmt|;
comment|// finally create the vertex
name|Vertex
name|map
init|=
literal|null
decl_stmt|;
comment|// use tez to combine splits
name|boolean
name|groupSplitsInInputInitializer
decl_stmt|;
name|DataSourceDescriptor
name|dataSource
decl_stmt|;
name|int
name|numTasks
init|=
operator|-
literal|1
decl_stmt|;
name|Class
name|inputFormatClass
init|=
name|conf
operator|.
name|getClass
argument_list|(
literal|"mapred.input.format.class"
argument_list|,
name|InputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
name|boolean
name|vertexHasCustomInput
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|tezWork
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|BaseWork
name|baseWork
range|:
name|tezWork
operator|.
name|getParents
argument_list|(
name|mapWork
argument_list|)
control|)
block|{
if|if
condition|(
name|tezWork
operator|.
name|getEdgeType
argument_list|(
name|baseWork
argument_list|,
name|mapWork
argument_list|)
operator|==
name|EdgeType
operator|.
name|CUSTOM_EDGE
condition|)
block|{
name|vertexHasCustomInput
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|vertexHasCustomInput
condition|)
block|{
name|groupSplitsInInputInitializer
operator|=
literal|false
expr_stmt|;
comment|// grouping happens in execution phase. The input payload should not enable grouping here,
comment|// it will be enabled in the CustomVertex.
name|inputFormatClass
operator|=
name|HiveInputFormat
operator|.
name|class
expr_stmt|;
name|conf
operator|.
name|setClass
argument_list|(
literal|"mapred.input.format.class"
argument_list|,
name|HiveInputFormat
operator|.
name|class
argument_list|,
name|InputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
comment|// mapreduce.tez.input.initializer.serialize.event.payload should be set to false when using
comment|// this plug-in to avoid getting a serialized event at run-time.
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"mapreduce.tez.input.initializer.serialize.event.payload"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// we'll set up tez to combine spits for us iff the input format
comment|// is HiveInputFormat
if|if
condition|(
name|inputFormatClass
operator|==
name|HiveInputFormat
operator|.
name|class
condition|)
block|{
name|groupSplitsInInputInitializer
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|groupSplitsInInputInitializer
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
name|mapWork
operator|instanceof
name|MergeFileWork
condition|)
block|{
name|Path
name|outputPath
init|=
operator|(
operator|(
name|MergeFileWork
operator|)
name|mapWork
operator|)
operator|.
name|getOutputDir
argument_list|()
decl_stmt|;
comment|// prepare the tmp output directory. The output tmp directory should
comment|// exist before jobClose (before renaming after job completion)
name|Path
name|tempOutPath
init|=
name|Utilities
operator|.
name|toTempPath
argument_list|(
name|outputPath
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|tempOutPath
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|tempOutPath
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Can't make path "
operator|+
name|outputPath
operator|+
literal|" : "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_AM_SPLIT_GENERATION
argument_list|)
operator|&&
operator|!
name|mapWork
operator|.
name|isUseOneNullRowInputFormat
argument_list|()
condition|)
block|{
comment|// set up the operator plan. (before setting up splits on the AM)
name|Utilities
operator|.
name|setMapWork
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|,
name|mrScratchDir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// if we're generating the splits in the AM, we just need to set
comment|// the correct plugin.
if|if
condition|(
name|groupSplitsInInputInitializer
condition|)
block|{
comment|// Not setting a payload, since the MRInput payload is the same and can be accessed.
name|InputInitializerDescriptor
name|descriptor
init|=
name|InputInitializerDescriptor
operator|.
name|create
argument_list|(
name|HiveSplitGenerator
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|dataSource
operator|=
name|MRInputLegacy
operator|.
name|createConfigBuilder
argument_list|(
name|conf
argument_list|,
name|inputFormatClass
argument_list|)
operator|.
name|groupSplits
argument_list|(
literal|true
argument_list|)
operator|.
name|setCustomInitializerDescriptor
argument_list|(
name|descriptor
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Not HiveInputFormat, or a custom VertexManager will take care of grouping splits
name|dataSource
operator|=
name|MRInputLegacy
operator|.
name|createConfigBuilder
argument_list|(
name|conf
argument_list|,
name|inputFormatClass
argument_list|)
operator|.
name|groupSplits
argument_list|(
literal|false
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Setup client side split generation.
name|dataSource
operator|=
name|MRInputHelpers
operator|.
name|configureMRInputWithLegacySplitGeneration
argument_list|(
name|conf
argument_list|,
operator|new
name|Path
argument_list|(
name|tezDir
argument_list|,
literal|"split_"
operator|+
name|mapWork
operator|.
name|getName
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|" "
argument_list|,
literal|"_"
argument_list|)
argument_list|)
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|numTasks
operator|=
name|dataSource
operator|.
name|getNumberOfShards
argument_list|()
expr_stmt|;
comment|// set up the operator plan. (after generating splits - that changes configs)
name|Utilities
operator|.
name|setMapWork
argument_list|(
name|conf
argument_list|,
name|mapWork
argument_list|,
name|mrScratchDir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|UserPayload
name|serializedConf
init|=
name|TezUtils
operator|.
name|createUserPayloadFromConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|procClassName
init|=
name|MapTezProcessor
operator|.
name|class
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|mapWork
operator|instanceof
name|MergeFileWork
condition|)
block|{
name|procClassName
operator|=
name|MergeFileTezProcessor
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|map
operator|=
name|Vertex
operator|.
name|create
argument_list|(
name|mapWork
operator|.
name|getName
argument_list|()
argument_list|,
name|ProcessorDescriptor
operator|.
name|create
argument_list|(
name|procClassName
argument_list|)
operator|.
name|setUserPayload
argument_list|(
name|serializedConf
argument_list|)
argument_list|,
name|numTasks
argument_list|,
name|getContainerResource
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|map
operator|.
name|setTaskEnvironment
argument_list|(
name|getContainerEnvironment
argument_list|(
name|conf
argument_list|,
literal|true
argument_list|)
argument_list|)
expr_stmt|;
name|map
operator|.
name|setTaskLaunchCmdOpts
argument_list|(
name|getContainerJavaOpts
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
assert|assert
name|mapWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|1
assert|;
comment|// Add the actual source input
name|String
name|alias
init|=
name|mapWork
operator|.
name|getAliasToWork
argument_list|()
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|map
operator|.
name|addDataSource
argument_list|(
name|alias
argument_list|,
name|dataSource
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
name|localResources
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|appJarLr
argument_list|)
argument_list|,
name|appJarLr
argument_list|)
expr_stmt|;
for|for
control|(
name|LocalResource
name|lr
range|:
name|additionalLr
control|)
block|{
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|lr
argument_list|)
argument_list|,
name|lr
argument_list|)
expr_stmt|;
block|}
name|map
operator|.
name|addTaskLocalFiles
argument_list|(
name|localResources
argument_list|)
expr_stmt|;
return|return
name|map
return|;
block|}
comment|/*    * Helper function to create JobConf for specific ReduceWork.    */
specifier|private
name|JobConf
name|initializeVertexConf
parameter_list|(
name|JobConf
name|baseConf
parameter_list|,
name|Context
name|context
parameter_list|,
name|ReduceWork
name|reduceWork
parameter_list|)
block|{
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|(
name|baseConf
argument_list|)
decl_stmt|;
comment|// Is this required ?
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.reducer.class"
argument_list|,
name|ExecReducer
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|boolean
name|useSpeculativeExecReducers
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESPECULATIVEEXECREDUCERS
argument_list|)
decl_stmt|;
name|HiveConf
operator|.
name|setBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HADOOPSPECULATIVEEXECREDUCERS
argument_list|,
name|useSpeculativeExecReducers
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
comment|/*    * Helper function to create Vertex for given ReduceWork.    */
specifier|private
name|Vertex
name|createVertex
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|ReduceWork
name|reduceWork
parameter_list|,
name|LocalResource
name|appJarLr
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|additionalLr
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|mrScratchDir
parameter_list|,
name|Context
name|ctx
parameter_list|)
throws|throws
name|Exception
block|{
comment|// set up operator plan
name|Utilities
operator|.
name|setReduceWork
argument_list|(
name|conf
argument_list|,
name|reduceWork
argument_list|,
name|mrScratchDir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// create the directories FileSinkOperators need
name|Utilities
operator|.
name|createTmpDirs
argument_list|(
name|conf
argument_list|,
name|reduceWork
argument_list|)
expr_stmt|;
comment|// create the vertex
name|Vertex
name|reducer
init|=
name|Vertex
operator|.
name|create
argument_list|(
name|reduceWork
operator|.
name|getName
argument_list|()
argument_list|,
name|ProcessorDescriptor
operator|.
name|create
argument_list|(
name|ReduceTezProcessor
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|setUserPayload
argument_list|(
name|TezUtils
operator|.
name|createUserPayloadFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|,
name|reduceWork
operator|.
name|isAutoReduceParallelism
argument_list|()
condition|?
name|reduceWork
operator|.
name|getMaxReduceTasks
argument_list|()
else|:
name|reduceWork
operator|.
name|getNumReduceTasks
argument_list|()
argument_list|,
name|getContainerResource
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|reducer
operator|.
name|setTaskEnvironment
argument_list|(
name|getContainerEnvironment
argument_list|(
name|conf
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|reducer
operator|.
name|setTaskLaunchCmdOpts
argument_list|(
name|getContainerJavaOpts
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
name|localResources
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|appJarLr
argument_list|)
argument_list|,
name|appJarLr
argument_list|)
expr_stmt|;
for|for
control|(
name|LocalResource
name|lr
range|:
name|additionalLr
control|)
block|{
name|localResources
operator|.
name|put
argument_list|(
name|getBaseName
argument_list|(
name|lr
argument_list|)
argument_list|,
name|lr
argument_list|)
expr_stmt|;
block|}
name|reducer
operator|.
name|addTaskLocalFiles
argument_list|(
name|localResources
argument_list|)
expr_stmt|;
return|return
name|reducer
return|;
block|}
comment|/*    * Helper method to create a yarn local resource.    */
specifier|private
name|LocalResource
name|createLocalResource
parameter_list|(
name|FileSystem
name|remoteFs
parameter_list|,
name|Path
name|file
parameter_list|,
name|LocalResourceType
name|type
parameter_list|,
name|LocalResourceVisibility
name|visibility
parameter_list|)
block|{
name|FileStatus
name|fstat
init|=
literal|null
decl_stmt|;
try|try
block|{
name|fstat
operator|=
name|remoteFs
operator|.
name|getFileStatus
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
name|URL
name|resourceURL
init|=
name|ConverterUtils
operator|.
name|getYarnUrlFromPath
argument_list|(
name|file
argument_list|)
decl_stmt|;
name|long
name|resourceSize
init|=
name|fstat
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|long
name|resourceModificationTime
init|=
name|fstat
operator|.
name|getModificationTime
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Resource modification time: "
operator|+
name|resourceModificationTime
argument_list|)
expr_stmt|;
name|LocalResource
name|lr
init|=
name|Records
operator|.
name|newRecord
argument_list|(
name|LocalResource
operator|.
name|class
argument_list|)
decl_stmt|;
name|lr
operator|.
name|setResource
argument_list|(
name|resourceURL
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setType
argument_list|(
name|type
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setSize
argument_list|(
name|resourceSize
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setVisibility
argument_list|(
name|visibility
argument_list|)
expr_stmt|;
name|lr
operator|.
name|setTimestamp
argument_list|(
name|resourceModificationTime
argument_list|)
expr_stmt|;
return|return
name|lr
return|;
block|}
comment|/**    * @param numContainers number of containers to pre-warm    * @param localResources additional resources to pre-warm with    * @return prewarm vertex to run    */
specifier|public
name|PreWarmVertex
name|createPreWarmVertex
parameter_list|(
name|TezConfiguration
name|conf
parameter_list|,
name|int
name|numContainers
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
name|localResources
parameter_list|)
throws|throws
name|IOException
throws|,
name|TezException
block|{
name|ProcessorDescriptor
name|prewarmProcDescriptor
init|=
name|ProcessorDescriptor
operator|.
name|create
argument_list|(
name|HivePreWarmProcessor
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|prewarmProcDescriptor
operator|.
name|setUserPayload
argument_list|(
name|TezUtils
operator|.
name|createUserPayloadFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|PreWarmVertex
name|prewarmVertex
init|=
name|PreWarmVertex
operator|.
name|create
argument_list|(
literal|"prewarm"
argument_list|,
name|prewarmProcDescriptor
argument_list|,
name|numContainers
argument_list|,
name|getContainerResource
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
name|combinedResources
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|localResources
operator|!=
literal|null
condition|)
block|{
name|combinedResources
operator|.
name|putAll
argument_list|(
name|localResources
argument_list|)
expr_stmt|;
block|}
name|prewarmVertex
operator|.
name|addTaskLocalFiles
argument_list|(
name|localResources
argument_list|)
expr_stmt|;
name|prewarmVertex
operator|.
name|setTaskLaunchCmdOpts
argument_list|(
name|getContainerJavaOpts
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|prewarmVertex
operator|.
name|setTaskEnvironment
argument_list|(
name|getContainerEnvironment
argument_list|(
name|conf
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|prewarmVertex
return|;
block|}
comment|/**    * @param conf    * @return path to destination directory on hdfs    * @throws LoginException if we are unable to figure user information    * @throws IOException when any dfs operation fails.    */
specifier|public
name|Path
name|getDefaultDestDir
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|LoginException
throws|,
name|IOException
block|{
name|UserGroupInformation
name|ugi
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getUGIForConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|userName
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getShortUserName
argument_list|(
name|ugi
argument_list|)
decl_stmt|;
name|String
name|userPathStr
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_USER_INSTALL_DIR
argument_list|)
decl_stmt|;
name|Path
name|userPath
init|=
operator|new
name|Path
argument_list|(
name|userPathStr
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|userPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|jarPathStr
init|=
name|userPathStr
operator|+
literal|"/"
operator|+
name|userName
decl_stmt|;
name|String
name|hdfsDirPathStr
init|=
name|jarPathStr
decl_stmt|;
name|Path
name|hdfsDirPath
init|=
operator|new
name|Path
argument_list|(
name|hdfsDirPathStr
argument_list|)
decl_stmt|;
name|FileStatus
name|fstatus
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|hdfsDirPath
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fstatus
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_DIR
operator|.
name|format
argument_list|(
name|hdfsDirPath
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|Path
name|retPath
init|=
operator|new
name|Path
argument_list|(
name|hdfsDirPath
operator|.
name|toString
argument_list|()
operator|+
literal|"/.hiveJars"
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|retPath
argument_list|)
expr_stmt|;
return|return
name|retPath
return|;
block|}
comment|/**    * Localizes files, archives and jars the user has instructed us    * to provide on the cluster as resources for execution.    *    * @param conf    * @return List<LocalResource> local resources to add to execution    * @throws IOException when hdfs operation fails    * @throws LoginException when getDefaultDestDir fails with the same exception    */
specifier|public
name|List
argument_list|<
name|LocalResource
argument_list|>
name|localizeTempFilesFromConf
parameter_list|(
name|String
name|hdfsDirPathStr
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|LoginException
block|{
name|List
argument_list|<
name|LocalResource
argument_list|>
name|tmpResources
init|=
operator|new
name|ArrayList
argument_list|<
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
name|addTempFiles
argument_list|(
name|conf
argument_list|,
name|tmpResources
argument_list|,
name|hdfsDirPathStr
argument_list|,
name|getTempFilesFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|tmpResources
return|;
block|}
specifier|public
specifier|static
name|String
index|[]
name|getTempFilesFromConf
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|addedFiles
init|=
name|Utilities
operator|.
name|getResourceFiles
argument_list|(
name|conf
argument_list|,
name|SessionState
operator|.
name|ResourceType
operator|.
name|FILE
argument_list|)
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|addedFiles
argument_list|)
condition|)
block|{
name|HiveConf
operator|.
name|setVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVEADDEDFILES
argument_list|,
name|addedFiles
argument_list|)
expr_stmt|;
block|}
name|String
name|addedJars
init|=
name|Utilities
operator|.
name|getResourceFiles
argument_list|(
name|conf
argument_list|,
name|SessionState
operator|.
name|ResourceType
operator|.
name|JAR
argument_list|)
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|addedJars
argument_list|)
condition|)
block|{
name|HiveConf
operator|.
name|setVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVEADDEDJARS
argument_list|,
name|addedJars
argument_list|)
expr_stmt|;
block|}
name|String
name|addedArchives
init|=
name|Utilities
operator|.
name|getResourceFiles
argument_list|(
name|conf
argument_list|,
name|SessionState
operator|.
name|ResourceType
operator|.
name|ARCHIVE
argument_list|)
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|addedArchives
argument_list|)
condition|)
block|{
name|HiveConf
operator|.
name|setVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVEADDEDARCHIVES
argument_list|,
name|addedArchives
argument_list|)
expr_stmt|;
block|}
name|String
name|auxJars
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEAUXJARS
argument_list|)
decl_stmt|;
comment|// need to localize the additional jars and files
comment|// we need the directory on hdfs to which we shall put all these files
name|String
name|allFiles
init|=
name|auxJars
operator|+
literal|","
operator|+
name|addedJars
operator|+
literal|","
operator|+
name|addedFiles
operator|+
literal|","
operator|+
name|addedArchives
decl_stmt|;
return|return
name|allFiles
operator|.
name|split
argument_list|(
literal|","
argument_list|)
return|;
block|}
comment|/**    * Localizes files, archives and jars from a provided array of names.    * @param hdfsDirPathStr Destination directory in HDFS.    * @param conf Configuration.    * @param inputOutputJars The file names to localize.    * @return List<LocalResource> local resources to add to execution    * @throws IOException when hdfs operation fails.    * @throws LoginException when getDefaultDestDir fails with the same exception    */
specifier|public
name|List
argument_list|<
name|LocalResource
argument_list|>
name|localizeTempFiles
parameter_list|(
name|String
name|hdfsDirPathStr
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|String
index|[]
name|inputOutputJars
parameter_list|)
throws|throws
name|IOException
throws|,
name|LoginException
block|{
if|if
condition|(
name|inputOutputJars
operator|==
literal|null
condition|)
return|return
literal|null
return|;
name|List
argument_list|<
name|LocalResource
argument_list|>
name|tmpResources
init|=
operator|new
name|ArrayList
argument_list|<
name|LocalResource
argument_list|>
argument_list|()
decl_stmt|;
name|addTempFiles
argument_list|(
name|conf
argument_list|,
name|tmpResources
argument_list|,
name|hdfsDirPathStr
argument_list|,
name|inputOutputJars
argument_list|)
expr_stmt|;
return|return
name|tmpResources
return|;
block|}
specifier|private
name|void
name|addTempFiles
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|tmpResources
parameter_list|,
name|String
name|hdfsDirPathStr
parameter_list|,
name|String
index|[]
name|files
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|String
name|file
range|:
name|files
control|)
block|{
if|if
condition|(
operator|!
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|file
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|Path
name|hdfsFilePath
init|=
operator|new
name|Path
argument_list|(
name|hdfsDirPathStr
argument_list|,
name|getResourceBaseName
argument_list|(
operator|new
name|Path
argument_list|(
name|file
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|LocalResource
name|localResource
init|=
name|localizeResource
argument_list|(
operator|new
name|Path
argument_list|(
name|file
argument_list|)
argument_list|,
name|hdfsFilePath
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|tmpResources
operator|.
name|add
argument_list|(
name|localResource
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|FileStatus
name|getHiveJarDirectory
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|LoginException
block|{
name|FileStatus
name|fstatus
init|=
literal|null
decl_stmt|;
name|String
name|hdfsDirPathStr
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_JAR_DIRECTORY
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|hdfsDirPathStr
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Hive jar directory is "
operator|+
name|hdfsDirPathStr
argument_list|)
expr_stmt|;
name|fstatus
operator|=
name|validateTargetDir
argument_list|(
operator|new
name|Path
argument_list|(
name|hdfsDirPathStr
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fstatus
operator|==
literal|null
condition|)
block|{
name|Path
name|destDir
init|=
name|getDefaultDestDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Jar dir is null/directory doesn't exist. Choosing HIVE_INSTALL_DIR - "
operator|+
name|destDir
argument_list|)
expr_stmt|;
name|fstatus
operator|=
name|validateTargetDir
argument_list|(
name|destDir
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fstatus
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ErrorMsg
operator|.
name|NO_VALID_LOCATIONS
operator|.
name|getMsg
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|fstatus
return|;
block|}
specifier|public
specifier|static
name|FileStatus
name|validateTargetDir
parameter_list|(
name|Path
name|path
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileStatus
name|fstatus
init|=
literal|null
decl_stmt|;
try|try
block|{
name|fstatus
operator|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fe
parameter_list|)
block|{
comment|// do nothing
block|}
return|return
operator|(
name|fstatus
operator|!=
literal|null
operator|&&
name|fstatus
operator|.
name|isDir
argument_list|()
operator|)
condition|?
name|fstatus
else|:
literal|null
return|;
block|}
comment|// the api that finds the jar being used by this class on disk
specifier|public
name|String
name|getExecJarPathLocal
parameter_list|()
throws|throws
name|URISyntaxException
block|{
comment|// returns the location on disc of the jar of this class.
return|return
name|DagUtils
operator|.
name|class
operator|.
name|getProtectionDomain
argument_list|()
operator|.
name|getCodeSource
argument_list|()
operator|.
name|getLocation
argument_list|()
operator|.
name|toURI
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/*    * Helper function to retrieve the basename of a local resource    */
specifier|public
name|String
name|getBaseName
parameter_list|(
name|LocalResource
name|lr
parameter_list|)
block|{
return|return
name|FilenameUtils
operator|.
name|getName
argument_list|(
name|lr
operator|.
name|getResource
argument_list|()
operator|.
name|getFile
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param path - the string from which we try to determine the resource base name    * @return the name of the resource from a given path string.    */
specifier|public
name|String
name|getResourceBaseName
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|getName
argument_list|()
return|;
block|}
comment|/**    * @param src the source file.    * @param dest the destination file.    * @param conf the configuration    * @return true if the file names match else returns false.    * @throws IOException when any file system related call fails    */
specifier|private
name|boolean
name|checkPreExisting
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dest
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|destFS
init|=
name|dest
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileSystem
name|sourceFS
init|=
name|src
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|destFS
operator|.
name|exists
argument_list|(
name|dest
argument_list|)
condition|)
block|{
return|return
operator|(
name|sourceFS
operator|.
name|getFileStatus
argument_list|(
name|src
argument_list|)
operator|.
name|getLen
argument_list|()
operator|==
name|destFS
operator|.
name|getFileStatus
argument_list|(
name|dest
argument_list|)
operator|.
name|getLen
argument_list|()
operator|)
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * @param src path to the source for the resource    * @param dest path in hdfs for the resource    * @param conf    * @return localresource from tez localization.    * @throws IOException when any file system related calls fails.    */
specifier|public
name|LocalResource
name|localizeResource
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dest
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|destFS
init|=
name|dest
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|src
operator|!=
literal|null
condition|)
block|{
comment|// copy the src to the destination and create local resource.
comment|// do not overwrite.
name|LOG
operator|.
name|info
argument_list|(
literal|"Localizing resource because it does not exist: "
operator|+
name|src
operator|+
literal|" to dest: "
operator|+
name|dest
argument_list|)
expr_stmt|;
try|try
block|{
name|destFS
operator|.
name|copyFromLocalFile
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|,
name|src
argument_list|,
name|dest
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Looks like another thread is writing the same file will wait."
argument_list|)
expr_stmt|;
name|int
name|waitAttempts
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_LOCALIZE_RESOURCE_NUM_WAIT_ATTEMPTS
operator|.
name|varname
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_LOCALIZE_RESOURCE_NUM_WAIT_ATTEMPTS
operator|.
name|defaultIntVal
argument_list|)
decl_stmt|;
name|long
name|sleepInterval
init|=
name|HiveConf
operator|.
name|getTimeVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_LOCALIZE_RESOURCE_WAIT_INTERVAL
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Number of wait attempts: "
operator|+
name|waitAttempts
operator|+
literal|". Wait interval: "
operator|+
name|sleepInterval
argument_list|)
expr_stmt|;
name|boolean
name|found
init|=
literal|false
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|waitAttempts
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|checkPreExisting
argument_list|(
name|src
argument_list|,
name|dest
argument_list|,
name|conf
argument_list|)
condition|)
block|{
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|sleepInterval
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|interruptedException
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|interruptedException
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|found
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|found
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not find the jar that was being uploaded"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Previous writer likely failed to write "
operator|+
name|dest
operator|+
literal|". Failing because I am unlikely to write too."
argument_list|)
throw|;
block|}
block|}
block|}
return|return
name|createLocalResource
argument_list|(
name|destFS
argument_list|,
name|dest
argument_list|,
name|LocalResourceType
operator|.
name|FILE
argument_list|,
name|LocalResourceVisibility
operator|.
name|PRIVATE
argument_list|)
return|;
block|}
comment|/**    * Creates and initializes a JobConf object that can be used to execute    * the DAG. The configuration object will contain configurations from mapred-site    * overlaid with key/value pairs from the hiveConf object. Finally it will also    * contain some hive specific configurations that do not change from DAG to DAG.    *    * @param hiveConf Current hiveConf for the execution    * @return JobConf base configuration for job execution    * @throws IOException    */
specifier|public
name|JobConf
name|createConfiguration
parameter_list|(
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|IOException
block|{
name|hiveConf
operator|.
name|setBoolean
argument_list|(
literal|"mapred.mapper.new-api"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.output.committer.class"
argument_list|,
name|NullOutputCommitter
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"mapred.committer.job.setup.cleanup.needed"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"mapred.committer.job.task.cleanup.needed"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setClass
argument_list|(
literal|"mapred.output.format.class"
argument_list|,
name|HiveOutputFormatImpl
operator|.
name|class
argument_list|,
name|OutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|OUTPUT_KEY_CLASS
argument_list|,
name|HiveKey
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|OUTPUT_VALUE_CLASS
argument_list|,
name|BytesWritable
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.partitioner.class"
argument_list|,
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEPARTITIONER
argument_list|)
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"tez.runtime.partitioner.class"
argument_list|,
name|MRPartitioner
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
comment|/**    * Creates and initializes the JobConf object for a given BaseWork object.    *    * @param conf Any configurations in conf will be copied to the resulting new JobConf object.    * @param work BaseWork will be used to populate the configuration object.    * @return JobConf new configuration object    */
specifier|public
name|JobConf
name|initializeVertexConf
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|Context
name|context
parameter_list|,
name|BaseWork
name|work
parameter_list|)
block|{
comment|// simply dispatch the call to the right method for the actual (sub-) type of
comment|// BaseWork.
if|if
condition|(
name|work
operator|instanceof
name|MapWork
condition|)
block|{
return|return
name|initializeVertexConf
argument_list|(
name|conf
argument_list|,
name|context
argument_list|,
operator|(
name|MapWork
operator|)
name|work
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|work
operator|instanceof
name|ReduceWork
condition|)
block|{
return|return
name|initializeVertexConf
argument_list|(
name|conf
argument_list|,
name|context
argument_list|,
operator|(
name|ReduceWork
operator|)
name|work
argument_list|)
return|;
block|}
else|else
block|{
assert|assert
literal|false
assert|;
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Create a vertex from a given work object.    *    * @param conf JobConf to be used to this execution unit    * @param work The instance of BaseWork representing the actual work to be performed    * by this vertex.    * @param scratchDir HDFS scratch dir for this execution unit.    * @param appJarLr Local resource for hive-exec.    * @param additionalLr    * @param fileSystem FS corresponding to scratchDir and LocalResources    * @param ctx This query's context    * @return Vertex    */
specifier|public
name|Vertex
name|createVertex
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|BaseWork
name|work
parameter_list|,
name|Path
name|scratchDir
parameter_list|,
name|LocalResource
name|appJarLr
parameter_list|,
name|List
argument_list|<
name|LocalResource
argument_list|>
name|additionalLr
parameter_list|,
name|FileSystem
name|fileSystem
parameter_list|,
name|Context
name|ctx
parameter_list|,
name|boolean
name|hasChildren
parameter_list|,
name|TezWork
name|tezWork
parameter_list|)
throws|throws
name|Exception
block|{
name|Vertex
name|v
init|=
literal|null
decl_stmt|;
comment|// simply dispatch the call to the right method for the actual (sub-) type of
comment|// BaseWork.
if|if
condition|(
name|work
operator|instanceof
name|MapWork
condition|)
block|{
name|v
operator|=
name|createVertex
argument_list|(
name|conf
argument_list|,
operator|(
name|MapWork
operator|)
name|work
argument_list|,
name|appJarLr
argument_list|,
name|additionalLr
argument_list|,
name|fileSystem
argument_list|,
name|scratchDir
argument_list|,
name|ctx
argument_list|,
name|tezWork
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|work
operator|instanceof
name|ReduceWork
condition|)
block|{
name|v
operator|=
name|createVertex
argument_list|(
name|conf
argument_list|,
operator|(
name|ReduceWork
operator|)
name|work
argument_list|,
name|appJarLr
argument_list|,
name|additionalLr
argument_list|,
name|fileSystem
argument_list|,
name|scratchDir
argument_list|,
name|ctx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// something is seriously wrong if this is happening
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|GENERIC_ERROR
operator|.
name|getErrorCodedMsg
argument_list|()
argument_list|)
throw|;
block|}
comment|// initialize stats publisher if necessary
if|if
condition|(
name|work
operator|.
name|isGatheringStats
argument_list|()
condition|)
block|{
name|StatsPublisher
name|statsPublisher
decl_stmt|;
name|StatsFactory
name|factory
init|=
name|StatsFactory
operator|.
name|newFactory
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|factory
operator|!=
literal|null
condition|)
block|{
name|statsPublisher
operator|=
name|factory
operator|.
name|getStatsPublisher
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|statsPublisher
operator|.
name|init
argument_list|(
name|conf
argument_list|)
condition|)
block|{
comment|// creating stats table if not exists
if|if
condition|(
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_STATS_RELIABLE
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|STATSPUBLISHER_INITIALIZATION_ERROR
operator|.
name|getErrorCodedMsg
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|// final vertices need to have at least one output
if|if
condition|(
operator|!
name|hasChildren
condition|)
block|{
name|v
operator|.
name|addDataSink
argument_list|(
literal|"out_"
operator|+
name|work
operator|.
name|getName
argument_list|()
argument_list|,
operator|new
name|DataSinkDescriptor
argument_list|(
name|OutputDescriptor
operator|.
name|create
argument_list|(
name|MROutput
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|setUserPayload
argument_list|(
name|TezUtils
operator|.
name|createUserPayloadFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|v
return|;
block|}
comment|/**    * Set up credentials for the base work on secure clusters    */
specifier|public
name|void
name|addCredentials
parameter_list|(
name|BaseWork
name|work
parameter_list|,
name|DAG
name|dag
parameter_list|)
block|{
if|if
condition|(
name|work
operator|instanceof
name|MapWork
condition|)
block|{
name|addCredentials
argument_list|(
operator|(
name|MapWork
operator|)
name|work
argument_list|,
name|dag
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|work
operator|instanceof
name|ReduceWork
condition|)
block|{
name|addCredentials
argument_list|(
operator|(
name|ReduceWork
operator|)
name|work
argument_list|,
name|dag
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * createTezDir creates a temporary directory in the scratchDir folder to    * be used with Tez. Assumes scratchDir exists.    */
specifier|public
name|Path
name|createTezDir
parameter_list|(
name|Path
name|scratchDir
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|UserGroupInformation
name|ugi
decl_stmt|;
name|String
name|userName
init|=
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
decl_stmt|;
try|try
block|{
name|ugi
operator|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getUGIForConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|userName
operator|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getShortUserName
argument_list|(
name|ugi
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LoginException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|scratchDir
operator|=
operator|new
name|Path
argument_list|(
name|scratchDir
argument_list|,
name|userName
argument_list|)
expr_stmt|;
name|Path
name|tezDir
init|=
name|getTezDir
argument_list|(
name|scratchDir
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|tezDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"TezDir path set "
operator|+
name|tezDir
operator|+
literal|" for user: "
operator|+
name|userName
argument_list|)
expr_stmt|;
comment|// since we are adding the user name to the scratch dir, we do not
comment|// need to give more permissions here
name|fs
operator|.
name|mkdirs
argument_list|(
name|tezDir
argument_list|)
expr_stmt|;
return|return
name|tezDir
return|;
block|}
comment|/**    * Gets the tez dir that belongs to the hive scratch dir    */
specifier|public
name|Path
name|getTezDir
parameter_list|(
name|Path
name|scratchDir
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|scratchDir
argument_list|,
name|TEZ_DIR
argument_list|)
return|;
block|}
comment|/**    * Singleton    * @return instance of this class    */
specifier|public
specifier|static
name|DagUtils
name|getInstance
parameter_list|()
block|{
if|if
condition|(
name|instance
operator|==
literal|null
condition|)
block|{
name|instance
operator|=
operator|new
name|DagUtils
argument_list|()
expr_stmt|;
block|}
return|return
name|instance
return|;
block|}
specifier|private
name|void
name|setupAutoReducerParallelism
parameter_list|(
name|TezEdgeProperty
name|edgeProp
parameter_list|,
name|Vertex
name|v
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|edgeProp
operator|.
name|isAutoReduce
argument_list|()
condition|)
block|{
name|Configuration
name|pluginConf
init|=
operator|new
name|Configuration
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|VertexManagerPluginDescriptor
name|desc
init|=
name|VertexManagerPluginDescriptor
operator|.
name|create
argument_list|(
name|ShuffleVertexManager
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|pluginConf
operator|.
name|setBoolean
argument_list|(
name|ShuffleVertexManager
operator|.
name|TEZ_SHUFFLE_VERTEX_MANAGER_ENABLE_AUTO_PARALLEL
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|pluginConf
operator|.
name|setInt
argument_list|(
name|ShuffleVertexManager
operator|.
name|TEZ_SHUFFLE_VERTEX_MANAGER_MIN_TASK_PARALLELISM
argument_list|,
name|edgeProp
operator|.
name|getMinReducer
argument_list|()
argument_list|)
expr_stmt|;
name|pluginConf
operator|.
name|setLong
argument_list|(
name|ShuffleVertexManager
operator|.
name|TEZ_SHUFFLE_VERTEX_MANAGER_DESIRED_TASK_INPUT_SIZE
argument_list|,
name|edgeProp
operator|.
name|getInputSizePerReducer
argument_list|()
argument_list|)
expr_stmt|;
name|UserPayload
name|payload
init|=
name|TezUtils
operator|.
name|createUserPayloadFromConf
argument_list|(
name|pluginConf
argument_list|)
decl_stmt|;
name|desc
operator|.
name|setUserPayload
argument_list|(
name|payload
argument_list|)
expr_stmt|;
name|v
operator|.
name|setVertexManagerPlugin
argument_list|(
name|desc
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|DagUtils
parameter_list|()
block|{
comment|// don't instantiate
block|}
block|}
end_class

end_unit

