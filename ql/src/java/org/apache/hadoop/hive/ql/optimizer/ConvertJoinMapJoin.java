begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Stack
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|GroupByOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|JoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MapJoinOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|MuxOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ReduceSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|NodeProcessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|NodeProcessorCtx
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|OptimizeTezProcContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|ParseContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeColumnDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|MapJoinDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OpTraits
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|Statistics
import|;
end_import

begin_comment
comment|/**  * ConvertJoinMapJoin is an optimization that replaces a common join  * (aka shuffle join) with a map join (aka broadcast or fragment replicate  * join when possible. Map joins have restrictions on which joins can be  * converted (e.g.: full outer joins cannot be handled as map joins) as well  * as memory restrictions (one side of the join has to fit into memory).  */
end_comment

begin_class
specifier|public
class|class
name|ConvertJoinMapJoin
implements|implements
name|NodeProcessor
block|{
specifier|static
specifier|final
specifier|private
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|ConvertJoinMapJoin
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
annotation|@
name|Override
comment|/*      * (non-Javadoc)      * we should ideally not modify the tree we traverse.      * However, since we need to walk the tree at any time when we modify the      * operator, we might as well do it here.      */
specifier|public
name|Object
name|process
parameter_list|(
name|Node
name|nd
parameter_list|,
name|Stack
argument_list|<
name|Node
argument_list|>
name|stack
parameter_list|,
name|NodeProcessorCtx
name|procCtx
parameter_list|,
name|Object
modifier|...
name|nodeOutputs
parameter_list|)
throws|throws
name|SemanticException
block|{
name|OptimizeTezProcContext
name|context
init|=
operator|(
name|OptimizeTezProcContext
operator|)
name|procCtx
decl_stmt|;
if|if
condition|(
operator|!
name|context
operator|.
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOIN
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|JoinOperator
name|joinOp
init|=
operator|(
name|JoinOperator
operator|)
name|nd
decl_stmt|;
comment|// if we have traits, and table info is present in the traits, we know the
comment|// exact number of buckets. Else choose the largest number of estimated
comment|// reducers from the parent operators.
name|int
name|numBuckets
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|estimatedBuckets
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parentOp
range|:
name|joinOp
operator|.
name|getParentOperators
argument_list|()
control|)
block|{
if|if
condition|(
name|parentOp
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
operator|>
literal|0
condition|)
block|{
name|numBuckets
operator|=
operator|(
name|numBuckets
operator|<
name|parentOp
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
operator|)
condition|?
name|parentOp
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
else|:
name|numBuckets
expr_stmt|;
block|}
name|ReduceSinkOperator
name|rs
init|=
operator|(
name|ReduceSinkOperator
operator|)
name|parentOp
decl_stmt|;
name|estimatedBuckets
operator|=
operator|(
name|estimatedBuckets
operator|<
name|rs
operator|.
name|getConf
argument_list|()
operator|.
name|getNumReducers
argument_list|()
operator|)
condition|?
name|rs
operator|.
name|getConf
argument_list|()
operator|.
name|getNumReducers
argument_list|()
else|:
name|estimatedBuckets
expr_stmt|;
block|}
if|if
condition|(
name|numBuckets
operator|<=
literal|0
condition|)
block|{
name|numBuckets
operator|=
name|estimatedBuckets
expr_stmt|;
if|if
condition|(
name|numBuckets
operator|<=
literal|0
condition|)
block|{
name|numBuckets
operator|=
literal|1
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Estimated number of buckets "
operator|+
name|numBuckets
argument_list|)
expr_stmt|;
name|int
name|mapJoinConversionPos
init|=
name|mapJoinConversionPos
argument_list|(
name|joinOp
argument_list|,
name|context
argument_list|,
name|numBuckets
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapJoinConversionPos
operator|<
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|context
operator|.
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_CONVERT_JOIN_BUCKET_MAPJOIN_TEZ
argument_list|)
condition|)
block|{
if|if
condition|(
name|convertJoinBucketMapJoin
argument_list|(
name|joinOp
argument_list|,
name|context
argument_list|,
name|mapJoinConversionPos
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Convert to non-bucketed map join"
argument_list|)
expr_stmt|;
name|MapJoinOperator
name|mapJoinOp
init|=
name|convertJoinMapJoin
argument_list|(
name|joinOp
argument_list|,
name|context
argument_list|,
name|mapJoinConversionPos
argument_list|)
decl_stmt|;
comment|// map join operator by default has no bucket cols
name|mapJoinOp
operator|.
name|setOpTraits
argument_list|(
operator|new
name|OpTraits
argument_list|(
literal|null
argument_list|,
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
comment|// propagate this change till the next RS
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|childOp
range|:
name|mapJoinOp
operator|.
name|getChildOperators
argument_list|()
control|)
block|{
name|setAllChildrenTraitsToNull
argument_list|(
name|childOp
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
specifier|private
name|void
name|setAllChildrenTraitsToNull
parameter_list|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|currentOp
parameter_list|)
block|{
if|if
condition|(
name|currentOp
operator|instanceof
name|ReduceSinkOperator
condition|)
block|{
return|return;
block|}
name|currentOp
operator|.
name|setOpTraits
argument_list|(
operator|new
name|OpTraits
argument_list|(
literal|null
argument_list|,
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|childOp
range|:
name|currentOp
operator|.
name|getChildOperators
argument_list|()
control|)
block|{
if|if
condition|(
operator|(
name|childOp
operator|instanceof
name|ReduceSinkOperator
operator|)
operator|||
operator|(
name|childOp
operator|instanceof
name|GroupByOperator
operator|)
condition|)
block|{
break|break;
block|}
name|setAllChildrenTraitsToNull
argument_list|(
name|childOp
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|boolean
name|convertJoinBucketMapJoin
parameter_list|(
name|JoinOperator
name|joinOp
parameter_list|,
name|OptimizeTezProcContext
name|context
parameter_list|,
name|int
name|bigTablePosition
parameter_list|)
throws|throws
name|SemanticException
block|{
name|TezBucketJoinProcCtx
name|tezBucketJoinProcCtx
init|=
operator|new
name|TezBucketJoinProcCtx
argument_list|(
name|context
operator|.
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|checkConvertJoinBucketMapJoin
argument_list|(
name|joinOp
argument_list|,
name|context
argument_list|,
name|bigTablePosition
argument_list|,
name|tezBucketJoinProcCtx
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Check conversion to bucket map join failed."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|MapJoinOperator
name|mapJoinOp
init|=
name|convertJoinMapJoin
argument_list|(
name|joinOp
argument_list|,
name|context
argument_list|,
name|bigTablePosition
argument_list|)
decl_stmt|;
name|MapJoinDesc
name|joinDesc
init|=
name|mapJoinOp
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|joinDesc
operator|.
name|setBucketMapJoin
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// we can set the traits for this join operator
name|OpTraits
name|opTraits
init|=
operator|new
name|OpTraits
argument_list|(
name|joinOp
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getBucketColNames
argument_list|()
argument_list|,
name|tezBucketJoinProcCtx
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
decl_stmt|;
name|mapJoinOp
operator|.
name|setOpTraits
argument_list|(
name|opTraits
argument_list|)
expr_stmt|;
name|setNumberOfBucketsOnChildren
argument_list|(
name|mapJoinOp
argument_list|)
expr_stmt|;
comment|// Once the conversion is done, we can set the partitioner to bucket cols on the small table
name|Map
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
name|bigTableBucketNumMapping
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
name|bigTableBucketNumMapping
operator|.
name|put
argument_list|(
name|joinDesc
operator|.
name|getBigTableAlias
argument_list|()
argument_list|,
name|tezBucketJoinProcCtx
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
expr_stmt|;
name|joinDesc
operator|.
name|setBigTableBucketNumMapping
argument_list|(
name|bigTableBucketNumMapping
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting legacy map join to "
operator|+
operator|(
operator|!
name|tezBucketJoinProcCtx
operator|.
name|isSubQuery
argument_list|()
operator|)
argument_list|)
expr_stmt|;
name|joinDesc
operator|.
name|setCustomBucketMapJoin
argument_list|(
operator|!
name|tezBucketJoinProcCtx
operator|.
name|isSubQuery
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|private
name|void
name|setNumberOfBucketsOnChildren
parameter_list|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|currentOp
parameter_list|)
block|{
name|int
name|numBuckets
init|=
name|currentOp
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
decl_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|op
range|:
name|currentOp
operator|.
name|getChildOperators
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
operator|(
name|op
operator|instanceof
name|ReduceSinkOperator
operator|)
operator|&&
operator|!
operator|(
name|op
operator|instanceof
name|GroupByOperator
operator|)
condition|)
block|{
name|op
operator|.
name|getOpTraits
argument_list|()
operator|.
name|setNumBuckets
argument_list|(
name|numBuckets
argument_list|)
expr_stmt|;
name|setNumberOfBucketsOnChildren
argument_list|(
name|op
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/*    *  We perform the following checks to see if we can convert to a bucket map join    *  1. If the parent reduce sink of the big table side has the same emit key cols as     *  its parent, we can create a bucket map join eliminating the reduce sink.    *  2. If we have the table information, we can check the same way as in Mapreduce to     *  determine if we can perform a Bucket Map Join.    */
specifier|private
name|boolean
name|checkConvertJoinBucketMapJoin
parameter_list|(
name|JoinOperator
name|joinOp
parameter_list|,
name|OptimizeTezProcContext
name|context
parameter_list|,
name|int
name|bigTablePosition
parameter_list|,
name|TezBucketJoinProcCtx
name|tezBucketJoinProcCtx
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// bail on mux-operator because mux operator masks the emit keys of the
comment|// constituent reduce sinks
if|if
condition|(
operator|!
operator|(
name|joinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|instanceof
name|ReduceSinkOperator
operator|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Operator is "
operator|+
name|joinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getName
argument_list|()
operator|+
literal|". Cannot convert to bucket map join"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|ReduceSinkOperator
name|rs
init|=
operator|(
name|ReduceSinkOperator
operator|)
name|joinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
name|bigTablePosition
argument_list|)
decl_stmt|;
comment|/*      * this is the case when the big table is a sub-query and is probably      * already bucketed by the join column in say a group by operation       */
name|List
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|colNames
init|=
name|rs
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getBucketColNames
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|colNames
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|colNames
operator|.
name|isEmpty
argument_list|()
operator|==
literal|false
operator|)
condition|)
block|{
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parentOfParent
init|=
name|rs
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|String
argument_list|>
name|listBucketCols
range|:
name|parentOfParent
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getBucketColNames
argument_list|()
control|)
block|{
comment|// can happen if this operator does not carry forward the previous bucketing columns
comment|// for e.g. another join operator which does not carry one of the sides' key columns
if|if
condition|(
name|listBucketCols
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|int
name|colCount
init|=
literal|0
decl_stmt|;
comment|// parent op is guaranteed to have a single list because it is a reduce sink
for|for
control|(
name|String
name|colName
range|:
name|rs
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getBucketColNames
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
control|)
block|{
comment|// all columns need to be at least a subset of the parentOfParent's bucket cols
name|ExprNodeDesc
name|exprNodeDesc
init|=
name|rs
operator|.
name|getColumnExprMap
argument_list|()
operator|.
name|get
argument_list|(
name|colName
argument_list|)
decl_stmt|;
if|if
condition|(
name|exprNodeDesc
operator|instanceof
name|ExprNodeColumnDesc
condition|)
block|{
if|if
condition|(
operator|(
operator|(
name|ExprNodeColumnDesc
operator|)
name|exprNodeDesc
operator|)
operator|.
name|getColumn
argument_list|()
operator|.
name|equals
argument_list|(
name|listBucketCols
operator|.
name|get
argument_list|(
name|colCount
argument_list|)
argument_list|)
condition|)
block|{
name|colCount
operator|++
expr_stmt|;
block|}
else|else
block|{
break|break;
block|}
block|}
if|if
condition|(
name|colCount
operator|==
name|rs
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getBucketColNames
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|size
argument_list|()
condition|)
block|{
comment|// all keys matched.
name|int
name|numBuckets
init|=
name|parentOfParent
operator|.
name|getOpTraits
argument_list|()
operator|.
name|getNumBuckets
argument_list|()
decl_stmt|;
name|boolean
name|isSubQuery
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|numBuckets
operator|<
literal|0
condition|)
block|{
name|isSubQuery
operator|=
literal|true
expr_stmt|;
name|numBuckets
operator|=
name|rs
operator|.
name|getConf
argument_list|()
operator|.
name|getNumReducers
argument_list|()
expr_stmt|;
block|}
name|tezBucketJoinProcCtx
operator|.
name|setNumBuckets
argument_list|(
name|numBuckets
argument_list|)
expr_stmt|;
name|tezBucketJoinProcCtx
operator|.
name|setIsSubQuery
argument_list|(
name|isSubQuery
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"No info available to check for bucket map join. Cannot convert"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
specifier|public
name|int
name|mapJoinConversionPos
parameter_list|(
name|JoinOperator
name|joinOp
parameter_list|,
name|OptimizeTezProcContext
name|context
parameter_list|,
name|int
name|buckets
parameter_list|)
block|{
name|Set
argument_list|<
name|Integer
argument_list|>
name|bigTableCandidateSet
init|=
name|MapJoinProcessor
operator|.
name|getBigTableCandidates
argument_list|(
name|joinOp
operator|.
name|getConf
argument_list|()
operator|.
name|getConds
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|maxSize
init|=
name|context
operator|.
name|conf
operator|.
name|getLongVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD
argument_list|)
decl_stmt|;
name|int
name|bigTablePosition
init|=
operator|-
literal|1
decl_stmt|;
name|Statistics
name|bigInputStat
init|=
literal|null
decl_stmt|;
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
name|int
name|pos
init|=
literal|0
decl_stmt|;
comment|// bigTableFound means we've encountered a table that's bigger than the
comment|// max. This table is either the the big table or we cannot convert.
name|boolean
name|bigTableFound
init|=
literal|false
decl_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parentOp
range|:
name|joinOp
operator|.
name|getParentOperators
argument_list|()
control|)
block|{
name|Statistics
name|currInputStat
init|=
name|parentOp
operator|.
name|getStatistics
argument_list|()
decl_stmt|;
if|if
condition|(
name|currInputStat
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Couldn't get statistics from: "
operator|+
name|parentOp
argument_list|)
expr_stmt|;
return|return
operator|-
literal|1
return|;
block|}
name|long
name|inputSize
init|=
name|currInputStat
operator|.
name|getDataSize
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|bigInputStat
operator|==
literal|null
operator|)
operator|||
operator|(
operator|(
name|bigInputStat
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|inputSize
operator|>
name|bigInputStat
operator|.
name|getDataSize
argument_list|()
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|bigTableFound
condition|)
block|{
comment|// cannot convert to map join; we've already chosen a big table
comment|// on size and there's another one that's bigger.
return|return
operator|-
literal|1
return|;
block|}
if|if
condition|(
name|inputSize
operator|/
name|buckets
operator|>
name|maxSize
condition|)
block|{
if|if
condition|(
operator|!
name|bigTableCandidateSet
operator|.
name|contains
argument_list|(
name|pos
argument_list|)
condition|)
block|{
comment|// can't use the current table as the big table, but it's too
comment|// big for the map side.
return|return
operator|-
literal|1
return|;
block|}
name|bigTableFound
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|bigInputStat
operator|!=
literal|null
condition|)
block|{
comment|// we're replacing the current big table with a new one. Need
comment|// to count the current one as a map table then.
name|totalSize
operator|+=
name|bigInputStat
operator|.
name|getDataSize
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|totalSize
operator|/
name|buckets
operator|>
name|maxSize
condition|)
block|{
comment|// sum of small tables size in this join exceeds configured limit
comment|// hence cannot convert.
return|return
operator|-
literal|1
return|;
block|}
if|if
condition|(
name|bigTableCandidateSet
operator|.
name|contains
argument_list|(
name|pos
argument_list|)
condition|)
block|{
name|bigTablePosition
operator|=
name|pos
expr_stmt|;
name|bigInputStat
operator|=
name|currInputStat
expr_stmt|;
block|}
block|}
else|else
block|{
name|totalSize
operator|+=
name|currInputStat
operator|.
name|getDataSize
argument_list|()
expr_stmt|;
if|if
condition|(
name|totalSize
operator|/
name|buckets
operator|>
name|maxSize
condition|)
block|{
comment|// cannot hold all map tables in memory. Cannot convert.
return|return
operator|-
literal|1
return|;
block|}
block|}
name|pos
operator|++
expr_stmt|;
block|}
return|return
name|bigTablePosition
return|;
block|}
comment|/*    * Once we have decided on the map join, the tree would transform from    *    *        |                   |    *       Join               MapJoin    *       / \                /   \    *     RS   RS   --->     RS    TS (big table)    *    /      \           /    *   TS       TS        TS (small table)    *    * for tez.    */
specifier|public
name|MapJoinOperator
name|convertJoinMapJoin
parameter_list|(
name|JoinOperator
name|joinOp
parameter_list|,
name|OptimizeTezProcContext
name|context
parameter_list|,
name|int
name|bigTablePosition
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// bail on mux operator because currently the mux operator masks the emit keys
comment|// of the constituent reduce sinks.
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parentOp
range|:
name|joinOp
operator|.
name|getParentOperators
argument_list|()
control|)
block|{
if|if
condition|(
name|parentOp
operator|instanceof
name|MuxOperator
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
comment|//can safely convert the join to a map join.
name|ParseContext
name|parseContext
init|=
name|context
operator|.
name|parseContext
decl_stmt|;
name|MapJoinOperator
name|mapJoinOp
init|=
name|MapJoinProcessor
operator|.
name|convertJoinOpMapJoinOp
argument_list|(
name|context
operator|.
name|conf
argument_list|,
name|parseContext
operator|.
name|getOpParseCtx
argument_list|()
argument_list|,
name|joinOp
argument_list|,
name|parseContext
operator|.
name|getJoinContext
argument_list|()
operator|.
name|get
argument_list|(
name|joinOp
argument_list|)
argument_list|,
name|bigTablePosition
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|parentBigTableOp
init|=
name|mapJoinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
name|bigTablePosition
argument_list|)
decl_stmt|;
if|if
condition|(
name|parentBigTableOp
operator|instanceof
name|ReduceSinkOperator
condition|)
block|{
name|mapJoinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|remove
argument_list|(
name|bigTablePosition
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|mapJoinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|contains
argument_list|(
name|parentBigTableOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
operator|)
condition|)
block|{
name|mapJoinOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|add
argument_list|(
name|bigTablePosition
argument_list|,
name|parentBigTableOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|parentBigTableOp
operator|.
name|getParentOperators
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|removeChild
argument_list|(
name|parentBigTableOp
argument_list|)
expr_stmt|;
for|for
control|(
name|Operator
argument_list|<
name|?
extends|extends
name|OperatorDesc
argument_list|>
name|op
range|:
name|mapJoinOp
operator|.
name|getParentOperators
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
operator|(
name|op
operator|.
name|getChildOperators
argument_list|()
operator|.
name|contains
argument_list|(
name|mapJoinOp
argument_list|)
operator|)
condition|)
block|{
name|op
operator|.
name|getChildOperators
argument_list|()
operator|.
name|add
argument_list|(
name|mapJoinOp
argument_list|)
expr_stmt|;
block|}
name|op
operator|.
name|getChildOperators
argument_list|()
operator|.
name|remove
argument_list|(
name|joinOp
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|mapJoinOp
return|;
block|}
block|}
end_class

end_unit

