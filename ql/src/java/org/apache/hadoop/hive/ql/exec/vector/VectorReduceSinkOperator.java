begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|ReduceSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TopNHash
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|expressions
operator|.
name|VectorExpression
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|expressions
operator|.
name|VectorExpressionWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|vector
operator|.
name|expressions
operator|.
name|VectorExpressionWriterFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|OperatorDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ReduceSinkDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Serializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StandardUnionObjectInspector
operator|.
name|StandardUnion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IntWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_comment
comment|// import org.apache.hadoop.util.StringUtils;
end_comment

begin_class
specifier|public
class|class
name|VectorReduceSinkOperator
extends|extends
name|ReduceSinkOperator
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|VectorReduceSinkOperator
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
comment|/**    * The evaluators for the key columns. Key columns decide the sort order on    * the reducer side. Key columns are passed to the reducer in the "key".    */
specifier|private
name|VectorExpression
index|[]
name|keyEval
decl_stmt|;
comment|/**    * The key value writers. These know how to write the necessary writable type    * based on key column metadata, from the primitive vector type.    */
specifier|private
specifier|transient
name|VectorExpressionWriter
index|[]
name|keyWriters
decl_stmt|;
comment|/**    * The evaluators for the value columns. Value columns are passed to reducer    * in the "value".    */
specifier|private
name|VectorExpression
index|[]
name|valueEval
decl_stmt|;
comment|/**    * The output value writers. These know how to write the necessary writable type    * based on value column metadata, from the primitive vector type.    */
specifier|private
specifier|transient
name|VectorExpressionWriter
index|[]
name|valueWriters
decl_stmt|;
comment|/**    * The evaluators for the partition columns (CLUSTER BY or DISTRIBUTE BY in    * Hive language). Partition columns decide the reducer that the current row    * goes to. Partition columns are not passed to reducer.    */
specifier|private
name|VectorExpression
index|[]
name|partitionEval
decl_stmt|;
comment|/**   * Evaluators for bucketing columns. This is used to compute bucket number.   */
specifier|private
name|VectorExpression
index|[]
name|bucketEval
decl_stmt|;
specifier|private
name|int
name|buckColIdxInKey
decl_stmt|;
comment|/**    * The partition value writers. These know how to write the necessary writable type    * based on partition column metadata, from the primitive vector type.    */
specifier|private
specifier|transient
name|VectorExpressionWriter
index|[]
name|partitionWriters
decl_stmt|;
specifier|private
specifier|transient
name|VectorExpressionWriter
index|[]
name|bucketWriters
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|boolean
name|isDebugEnabled
init|=
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
decl_stmt|;
specifier|public
name|VectorReduceSinkOperator
parameter_list|(
name|VectorizationContext
name|vContext
parameter_list|,
name|OperatorDesc
name|conf
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
argument_list|()
expr_stmt|;
name|ReduceSinkDesc
name|desc
init|=
operator|(
name|ReduceSinkDesc
operator|)
name|conf
decl_stmt|;
name|this
operator|.
name|conf
operator|=
name|desc
expr_stmt|;
name|keyEval
operator|=
name|vContext
operator|.
name|getVectorExpressions
argument_list|(
name|desc
operator|.
name|getKeyCols
argument_list|()
argument_list|)
expr_stmt|;
name|valueEval
operator|=
name|vContext
operator|.
name|getVectorExpressions
argument_list|(
name|desc
operator|.
name|getValueCols
argument_list|()
argument_list|)
expr_stmt|;
name|partitionEval
operator|=
name|vContext
operator|.
name|getVectorExpressions
argument_list|(
name|desc
operator|.
name|getPartitionCols
argument_list|()
argument_list|)
expr_stmt|;
name|bucketEval
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|desc
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|desc
operator|.
name|getBucketCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|bucketEval
operator|=
name|vContext
operator|.
name|getVectorExpressions
argument_list|(
name|desc
operator|.
name|getBucketCols
argument_list|()
argument_list|)
expr_stmt|;
name|buckColIdxInKey
operator|=
name|desc
operator|.
name|getPartitionCols
argument_list|()
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|VectorReduceSinkOperator
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|initializeOp
parameter_list|(
name|Configuration
name|hconf
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|numDistributionKeys
operator|=
name|conf
operator|.
name|getNumDistributionKeys
argument_list|()
expr_stmt|;
name|distinctColIndices
operator|=
name|conf
operator|.
name|getDistinctColumnIndices
argument_list|()
expr_stmt|;
name|numDistinctExprs
operator|=
name|distinctColIndices
operator|.
name|size
argument_list|()
expr_stmt|;
name|TableDesc
name|keyTableDesc
init|=
name|conf
operator|.
name|getKeySerializeInfo
argument_list|()
decl_stmt|;
name|keySerializer
operator|=
operator|(
name|Serializer
operator|)
name|keyTableDesc
operator|.
name|getDeserializerClass
argument_list|()
operator|.
name|newInstance
argument_list|()
expr_stmt|;
name|keySerializer
operator|.
name|initialize
argument_list|(
literal|null
argument_list|,
name|keyTableDesc
operator|.
name|getProperties
argument_list|()
argument_list|)
expr_stmt|;
name|keyIsText
operator|=
name|keySerializer
operator|.
name|getSerializedClass
argument_list|()
operator|.
name|equals
argument_list|(
name|Text
operator|.
name|class
argument_list|)
expr_stmt|;
comment|/*        * Compute and assign the key writers and the key object inspector        */
name|VectorExpressionWriterFactory
operator|.
name|processVectorExpressions
argument_list|(
name|conf
operator|.
name|getKeyCols
argument_list|()
argument_list|,
name|conf
operator|.
name|getOutputKeyColumnNames
argument_list|()
argument_list|,
operator|new
name|VectorExpressionWriterFactory
operator|.
name|SingleOIDClosure
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|assign
parameter_list|(
name|VectorExpressionWriter
index|[]
name|writers
parameter_list|,
name|ObjectInspector
name|objectInspector
parameter_list|)
block|{
name|keyWriters
operator|=
name|writers
expr_stmt|;
name|keyObjectInspector
operator|=
name|objectInspector
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|String
name|colNames
init|=
literal|""
decl_stmt|;
for|for
control|(
name|String
name|colName
range|:
name|conf
operator|.
name|getOutputKeyColumnNames
argument_list|()
control|)
block|{
name|colNames
operator|=
name|String
operator|.
name|format
argument_list|(
literal|"%s %s"
argument_list|,
name|colNames
argument_list|,
name|colName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"keyObjectInspector [%s]%s => %s"
argument_list|,
name|keyObjectInspector
operator|.
name|getClass
argument_list|()
argument_list|,
name|keyObjectInspector
argument_list|,
name|colNames
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|partitionWriters
operator|=
name|VectorExpressionWriterFactory
operator|.
name|getExpressionWriters
argument_list|(
name|conf
operator|.
name|getPartitionCols
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|conf
operator|.
name|getBucketCols
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|bucketWriters
operator|=
name|VectorExpressionWriterFactory
operator|.
name|getExpressionWriters
argument_list|(
name|conf
operator|.
name|getBucketCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|TableDesc
name|valueTableDesc
init|=
name|conf
operator|.
name|getValueSerializeInfo
argument_list|()
decl_stmt|;
name|valueSerializer
operator|=
operator|(
name|Serializer
operator|)
name|valueTableDesc
operator|.
name|getDeserializerClass
argument_list|()
operator|.
name|newInstance
argument_list|()
expr_stmt|;
name|valueSerializer
operator|.
name|initialize
argument_list|(
literal|null
argument_list|,
name|valueTableDesc
operator|.
name|getProperties
argument_list|()
argument_list|)
expr_stmt|;
comment|/*        * Compute and assign the value writers and the value object inspector        */
name|VectorExpressionWriterFactory
operator|.
name|processVectorExpressions
argument_list|(
name|conf
operator|.
name|getValueCols
argument_list|()
argument_list|,
name|conf
operator|.
name|getOutputValueColumnNames
argument_list|()
argument_list|,
operator|new
name|VectorExpressionWriterFactory
operator|.
name|SingleOIDClosure
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|assign
parameter_list|(
name|VectorExpressionWriter
index|[]
name|writers
parameter_list|,
name|ObjectInspector
name|objectInspector
parameter_list|)
block|{
name|valueWriters
operator|=
name|writers
expr_stmt|;
name|valueObjectInspector
operator|=
name|objectInspector
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|colNames
operator|=
literal|""
expr_stmt|;
for|for
control|(
name|String
name|colName
range|:
name|conf
operator|.
name|getOutputValueColumnNames
argument_list|()
control|)
block|{
name|colNames
operator|=
name|String
operator|.
name|format
argument_list|(
literal|"%s %s"
argument_list|,
name|colNames
argument_list|,
name|colName
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"valueObjectInspector [%s]%s => %s"
argument_list|,
name|valueObjectInspector
operator|.
name|getClass
argument_list|()
argument_list|,
name|valueObjectInspector
argument_list|,
name|colNames
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|int
name|numKeys
init|=
name|numDistinctExprs
operator|>
literal|0
condition|?
name|numDistinctExprs
else|:
literal|1
decl_stmt|;
name|int
name|keyLen
init|=
name|numDistinctExprs
operator|>
literal|0
condition|?
name|numDistributionKeys
operator|+
literal|1
else|:
name|numDistributionKeys
decl_stmt|;
name|cachedKeys
operator|=
operator|new
name|Object
index|[
name|numKeys
index|]
index|[
name|keyLen
index|]
expr_stmt|;
name|cachedValues
operator|=
operator|new
name|Object
index|[
name|valueEval
operator|.
name|length
index|]
expr_stmt|;
name|int
name|tag
init|=
name|conf
operator|.
name|getTag
argument_list|()
decl_stmt|;
name|tagByte
index|[
literal|0
index|]
operator|=
operator|(
name|byte
operator|)
name|tag
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Using tag = "
operator|+
name|tag
argument_list|)
expr_stmt|;
name|int
name|limit
init|=
name|conf
operator|.
name|getTopN
argument_list|()
decl_stmt|;
name|float
name|memUsage
init|=
name|conf
operator|.
name|getTopNMemoryUsage
argument_list|()
decl_stmt|;
if|if
condition|(
name|limit
operator|>=
literal|0
operator|&&
name|memUsage
operator|>
literal|0
condition|)
block|{
name|reducerHash
operator|.
name|initialize
argument_list|(
name|limit
argument_list|,
name|memUsage
argument_list|,
name|conf
operator|.
name|isMapGroupBy
argument_list|()
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
name|autoParallel
operator|=
name|conf
operator|.
name|isAutoParallel
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|processOp
parameter_list|(
name|Object
name|row
parameter_list|,
name|int
name|tag
parameter_list|)
throws|throws
name|HiveException
block|{
name|VectorizedRowBatch
name|vrg
init|=
operator|(
name|VectorizedRowBatch
operator|)
name|row
decl_stmt|;
if|if
condition|(
name|isDebugEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"sinking %d rows, %d values, %d keys, %d parts"
argument_list|,
name|vrg
operator|.
name|size
argument_list|,
name|valueEval
operator|.
name|length
argument_list|,
name|keyEval
operator|.
name|length
argument_list|,
name|partitionEval
operator|.
name|length
argument_list|)
argument_list|)
expr_stmt|;
block|}
try|try
block|{
comment|// Evaluate the keys
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|keyEval
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|keyEval
index|[
name|i
index|]
operator|.
name|evaluate
argument_list|(
name|vrg
argument_list|)
expr_stmt|;
block|}
comment|// Determine which rows we need to emit based on topN optimization
name|int
name|startResult
init|=
name|reducerHash
operator|.
name|startVectorizedBatch
argument_list|(
name|vrg
operator|.
name|size
argument_list|)
decl_stmt|;
if|if
condition|(
name|startResult
operator|==
name|TopNHash
operator|.
name|EXCLUDE
condition|)
block|{
return|return;
comment|// TopN wants us to exclude all rows.
block|}
comment|// TODO: can we do this later/only for the keys that are needed? E.g. update vrg.selected.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partitionEval
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|partitionEval
index|[
name|i
index|]
operator|.
name|evaluate
argument_list|(
name|vrg
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bucketEval
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bucketEval
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|bucketEval
index|[
name|i
index|]
operator|.
name|evaluate
argument_list|(
name|vrg
argument_list|)
expr_stmt|;
block|}
block|}
comment|// run the vector evaluations
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|valueEval
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|valueEval
index|[
name|i
index|]
operator|.
name|evaluate
argument_list|(
name|vrg
argument_list|)
expr_stmt|;
block|}
name|boolean
name|useTopN
init|=
name|startResult
operator|!=
name|TopNHash
operator|.
name|FORWARD
decl_stmt|;
comment|// Go thru the batch once. If we are not using TopN, we will forward all things and be done.
comment|// If we are using topN, we will make the first key for each row and store/forward it.
comment|// Values, hashes and additional distinct rows will be handled in the 2nd pass in that case.
for|for
control|(
name|int
name|batchIndex
init|=
literal|0
init|;
name|batchIndex
operator|<
name|vrg
operator|.
name|size
condition|;
operator|++
name|batchIndex
control|)
block|{
name|int
name|rowIndex
init|=
name|batchIndex
decl_stmt|;
if|if
condition|(
name|vrg
operator|.
name|selectedInUse
condition|)
block|{
name|rowIndex
operator|=
name|vrg
operator|.
name|selected
index|[
name|batchIndex
index|]
expr_stmt|;
block|}
comment|// First, make distrib key components for this row and determine distKeyLength.
name|populatedCachedDistributionKeys
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|// replace bucketing columns with hashcode % numBuckets
name|int
name|buckNum
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|bucketEval
operator|!=
literal|null
condition|)
block|{
name|buckNum
operator|=
name|computeBucketNumber
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
name|conf
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
expr_stmt|;
name|cachedKeys
index|[
literal|0
index|]
index|[
name|buckColIdxInKey
index|]
operator|=
operator|new
name|IntWritable
argument_list|(
name|buckNum
argument_list|)
expr_stmt|;
block|}
name|HiveKey
name|firstKey
init|=
name|toHiveKey
argument_list|(
name|cachedKeys
index|[
literal|0
index|]
argument_list|,
name|tag
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|int
name|distKeyLength
init|=
name|firstKey
operator|.
name|getDistKeyLength
argument_list|()
decl_stmt|;
comment|// Add first distinct expression, if any.
if|if
condition|(
name|numDistinctExprs
operator|>
literal|0
condition|)
block|{
name|populateCachedDistinctKeys
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|firstKey
operator|=
name|toHiveKey
argument_list|(
name|cachedKeys
index|[
literal|0
index|]
argument_list|,
name|tag
argument_list|,
name|distKeyLength
argument_list|)
expr_stmt|;
block|}
specifier|final
name|int
name|hashCode
decl_stmt|;
comment|// distKeyLength doesn't include tag, but includes buckNum in cachedKeys[0]
if|if
condition|(
name|autoParallel
operator|&&
name|partitionEval
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|hashCode
operator|=
name|computeMurmurHash
argument_list|(
name|firstKey
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hashCode
operator|=
name|computeHashCode
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
name|buckNum
argument_list|)
expr_stmt|;
block|}
name|firstKey
operator|.
name|setHashCode
argument_list|(
name|hashCode
argument_list|)
expr_stmt|;
if|if
condition|(
name|useTopN
condition|)
block|{
name|reducerHash
operator|.
name|tryStoreVectorizedKey
argument_list|(
name|firstKey
argument_list|,
name|batchIndex
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// No TopN, just forward the first key and all others.
name|BytesWritable
name|value
init|=
name|makeValueWritable
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|)
decl_stmt|;
name|collect
argument_list|(
name|firstKey
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|forwardExtraDistinctRows
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
name|hashCode
argument_list|,
name|value
argument_list|,
name|distKeyLength
argument_list|,
name|tag
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|useTopN
condition|)
return|return;
comment|// All done.
comment|// If we use topN, we have called tryStore on every key now. We can process the results.
for|for
control|(
name|int
name|batchIndex
init|=
literal|0
init|;
name|batchIndex
operator|<
name|vrg
operator|.
name|size
condition|;
operator|++
name|batchIndex
control|)
block|{
name|int
name|result
init|=
name|reducerHash
operator|.
name|getVectorizedBatchResult
argument_list|(
name|batchIndex
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|==
name|TopNHash
operator|.
name|EXCLUDE
condition|)
continue|continue;
name|int
name|rowIndex
init|=
name|batchIndex
decl_stmt|;
if|if
condition|(
name|vrg
operator|.
name|selectedInUse
condition|)
block|{
name|rowIndex
operator|=
name|vrg
operator|.
name|selected
index|[
name|batchIndex
index|]
expr_stmt|;
block|}
comment|// Compute value and hashcode - we'd either store or forward them.
name|BytesWritable
name|value
init|=
name|makeValueWritable
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|)
decl_stmt|;
name|int
name|distKeyLength
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|hashCode
decl_stmt|;
if|if
condition|(
name|result
operator|==
name|TopNHash
operator|.
name|FORWARD
condition|)
block|{
name|HiveKey
name|firstKey
init|=
name|reducerHash
operator|.
name|getVectorizedKeyToForward
argument_list|(
name|batchIndex
argument_list|)
decl_stmt|;
name|distKeyLength
operator|=
name|firstKey
operator|.
name|getDistKeyLength
argument_list|()
expr_stmt|;
name|hashCode
operator|=
name|firstKey
operator|.
name|hashCode
argument_list|()
expr_stmt|;
name|collect
argument_list|(
name|firstKey
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|reducerHash
operator|.
name|storeValue
argument_list|(
name|result
argument_list|,
name|value
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|distKeyLength
operator|=
name|reducerHash
operator|.
name|getVectorizedKeyDistLength
argument_list|(
name|batchIndex
argument_list|)
expr_stmt|;
name|hashCode
operator|=
name|reducerHash
operator|.
name|getVectorizedKeyHashCode
argument_list|(
name|batchIndex
argument_list|)
expr_stmt|;
block|}
comment|// Now forward other the rows if there's multi-distinct (but see TODO in forward...).
comment|// Unfortunately, that means we will have to rebuild the cachedKeys. Start at 1.
if|if
condition|(
name|numDistinctExprs
operator|>
literal|1
condition|)
block|{
name|populatedCachedDistributionKeys
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|forwardExtraDistinctRows
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
name|hashCode
argument_list|,
name|value
argument_list|,
name|distKeyLength
argument_list|,
name|tag
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * This function creates and forwards all the additional KVs for the multi-distinct case,    * after the first (0th) KV pertaining to the row has already been stored or forwarded.    * @param vrg the batch    * @param rowIndex the row index in the batch    * @param hashCode the partitioning hash code to use; same as for the first KV    * @param value the value to use; same as for the first KV    * @param distKeyLength the distribution key length of the first key; TODO probably extraneous    * @param tag the tag    * @param baseIndex the index in cachedKeys where the pre-evaluated distribution keys are stored    */
specifier|private
name|void
name|forwardExtraDistinctRows
parameter_list|(
name|VectorizedRowBatch
name|vrg
parameter_list|,
name|int
name|rowIndex
parameter_list|,
name|int
name|hashCode
parameter_list|,
name|BytesWritable
name|value
parameter_list|,
name|int
name|distKeyLength
parameter_list|,
name|int
name|tag
parameter_list|,
name|int
name|baseIndex
parameter_list|)
throws|throws
name|HiveException
throws|,
name|SerDeException
throws|,
name|IOException
block|{
comment|// TODO: We don't have to forward extra distinct rows immediately (same in non-vector) if
comment|//       the first key has already been stored. There's few bytes difference between keys
comment|//       for different distincts, and the value/etc. are all the same.
comment|//       We could store deltas to re-gen extra rows when flushing TopN.
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|numDistinctExprs
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|!=
name|baseIndex
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|cachedKeys
index|[
name|baseIndex
index|]
argument_list|,
literal|0
argument_list|,
name|cachedKeys
index|[
name|i
index|]
argument_list|,
literal|0
argument_list|,
name|numDistributionKeys
argument_list|)
expr_stmt|;
block|}
name|populateCachedDistinctKeys
argument_list|(
name|vrg
argument_list|,
name|rowIndex
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|HiveKey
name|hiveKey
init|=
name|toHiveKey
argument_list|(
name|cachedKeys
index|[
name|i
index|]
argument_list|,
name|tag
argument_list|,
name|distKeyLength
argument_list|)
decl_stmt|;
name|hiveKey
operator|.
name|setHashCode
argument_list|(
name|hashCode
argument_list|)
expr_stmt|;
name|collect
argument_list|(
name|hiveKey
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Populate distribution keys part of cachedKeys for a particular row from the batch.    * @param vrg the batch    * @param rowIndex the row index in the batch    * @param index the cachedKeys index to write to    */
specifier|private
name|void
name|populatedCachedDistributionKeys
parameter_list|(
name|VectorizedRowBatch
name|vrg
parameter_list|,
name|int
name|rowIndex
parameter_list|,
name|int
name|index
parameter_list|)
throws|throws
name|HiveException
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numDistributionKeys
condition|;
name|i
operator|++
control|)
block|{
name|int
name|batchColumn
init|=
name|keyEval
index|[
name|i
index|]
operator|.
name|getOutputColumn
argument_list|()
decl_stmt|;
name|ColumnVector
name|vectorColumn
init|=
name|vrg
operator|.
name|cols
index|[
name|batchColumn
index|]
decl_stmt|;
name|cachedKeys
index|[
name|index
index|]
index|[
name|i
index|]
operator|=
name|keyWriters
index|[
name|i
index|]
operator|.
name|writeValue
argument_list|(
name|vectorColumn
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cachedKeys
index|[
name|index
index|]
operator|.
name|length
operator|>
name|numDistributionKeys
condition|)
block|{
name|cachedKeys
index|[
name|index
index|]
index|[
name|numDistributionKeys
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Populate distinct keys part of cachedKeys for a particular row from the batch.    * @param vrg the batch    * @param rowIndex the row index in the batch    * @param index the cachedKeys index to write to    */
specifier|private
name|void
name|populateCachedDistinctKeys
parameter_list|(
name|VectorizedRowBatch
name|vrg
parameter_list|,
name|int
name|rowIndex
parameter_list|,
name|int
name|index
parameter_list|)
throws|throws
name|HiveException
block|{
name|StandardUnion
name|union
decl_stmt|;
name|cachedKeys
index|[
name|index
index|]
index|[
name|numDistributionKeys
index|]
operator|=
name|union
operator|=
operator|new
name|StandardUnion
argument_list|(
operator|(
name|byte
operator|)
name|index
argument_list|,
operator|new
name|Object
index|[
name|distinctColIndices
operator|.
name|get
argument_list|(
name|index
argument_list|)
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
name|Object
index|[]
name|distinctParameters
init|=
operator|(
name|Object
index|[]
operator|)
name|union
operator|.
name|getObject
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|distinctParamI
init|=
literal|0
init|;
name|distinctParamI
operator|<
name|distinctParameters
operator|.
name|length
condition|;
name|distinctParamI
operator|++
control|)
block|{
name|int
name|distinctColIndex
init|=
name|distinctColIndices
operator|.
name|get
argument_list|(
name|index
argument_list|)
operator|.
name|get
argument_list|(
name|distinctParamI
argument_list|)
decl_stmt|;
name|int
name|batchColumn
init|=
name|keyEval
index|[
name|distinctColIndex
index|]
operator|.
name|getOutputColumn
argument_list|()
decl_stmt|;
name|distinctParameters
index|[
name|distinctParamI
index|]
operator|=
name|keyWriters
index|[
name|distinctColIndex
index|]
operator|.
name|writeValue
argument_list|(
name|vrg
operator|.
name|cols
index|[
name|batchColumn
index|]
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
block|}
name|union
operator|.
name|setTag
argument_list|(
operator|(
name|byte
operator|)
name|index
argument_list|)
expr_stmt|;
block|}
specifier|private
name|BytesWritable
name|makeValueWritable
parameter_list|(
name|VectorizedRowBatch
name|vrg
parameter_list|,
name|int
name|rowIndex
parameter_list|)
throws|throws
name|HiveException
throws|,
name|SerDeException
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|valueEval
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|int
name|batchColumn
init|=
name|valueEval
index|[
name|i
index|]
operator|.
name|getOutputColumn
argument_list|()
decl_stmt|;
name|ColumnVector
name|vectorColumn
init|=
name|vrg
operator|.
name|cols
index|[
name|batchColumn
index|]
decl_stmt|;
name|cachedValues
index|[
name|i
index|]
operator|=
name|valueWriters
index|[
name|i
index|]
operator|.
name|writeValue
argument_list|(
name|vectorColumn
argument_list|,
name|rowIndex
argument_list|)
expr_stmt|;
block|}
comment|// Serialize the value
return|return
operator|(
name|BytesWritable
operator|)
name|valueSerializer
operator|.
name|serialize
argument_list|(
name|cachedValues
argument_list|,
name|valueObjectInspector
argument_list|)
return|;
block|}
specifier|private
name|int
name|computeHashCode
parameter_list|(
name|VectorizedRowBatch
name|vrg
parameter_list|,
name|int
name|rowIndex
parameter_list|,
name|int
name|buckNum
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Evaluate the HashCode
name|int
name|keyHashCode
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|partitionEval
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|// If no partition cols, just distribute the data uniformly to provide better
comment|// load balance. If the requirement is to have a single reducer, we should set
comment|// the number of reducers to 1.
comment|// Use a constant seed to make the code deterministic.
if|if
condition|(
name|random
operator|==
literal|null
condition|)
block|{
name|random
operator|=
operator|new
name|Random
argument_list|(
literal|12345
argument_list|)
expr_stmt|;
block|}
name|keyHashCode
operator|=
name|random
operator|.
name|nextInt
argument_list|()
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|int
name|p
init|=
literal|0
init|;
name|p
operator|<
name|partitionEval
operator|.
name|length
condition|;
name|p
operator|++
control|)
block|{
name|ColumnVector
name|columnVector
init|=
name|vrg
operator|.
name|cols
index|[
name|partitionEval
index|[
name|p
index|]
operator|.
name|getOutputColumn
argument_list|()
index|]
decl_stmt|;
name|Object
name|partitionValue
init|=
name|partitionWriters
index|[
name|p
index|]
operator|.
name|writeValue
argument_list|(
name|columnVector
argument_list|,
name|rowIndex
argument_list|)
decl_stmt|;
name|keyHashCode
operator|=
name|keyHashCode
operator|*
literal|31
operator|+
name|ObjectInspectorUtils
operator|.
name|hashCode
argument_list|(
name|partitionValue
argument_list|,
name|partitionWriters
index|[
name|p
index|]
operator|.
name|getObjectInspector
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|buckNum
operator|<
literal|0
condition|?
name|keyHashCode
else|:
name|keyHashCode
operator|*
literal|31
operator|+
name|buckNum
return|;
block|}
specifier|private
name|int
name|computeBucketNumber
parameter_list|(
name|VectorizedRowBatch
name|vrg
parameter_list|,
name|int
name|rowIndex
parameter_list|,
name|int
name|numBuckets
parameter_list|)
throws|throws
name|HiveException
block|{
name|int
name|bucketNum
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|p
init|=
literal|0
init|;
name|p
operator|<
name|bucketEval
operator|.
name|length
condition|;
name|p
operator|++
control|)
block|{
name|ColumnVector
name|columnVector
init|=
name|vrg
operator|.
name|cols
index|[
name|bucketEval
index|[
name|p
index|]
operator|.
name|getOutputColumn
argument_list|()
index|]
decl_stmt|;
name|Object
name|bucketValue
init|=
name|bucketWriters
index|[
name|p
index|]
operator|.
name|writeValue
argument_list|(
name|columnVector
argument_list|,
name|rowIndex
argument_list|)
decl_stmt|;
name|bucketNum
operator|=
name|bucketNum
operator|*
literal|31
operator|+
name|ObjectInspectorUtils
operator|.
name|hashCode
argument_list|(
name|bucketValue
argument_list|,
name|bucketWriters
index|[
name|p
index|]
operator|.
name|getObjectInspector
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bucketNum
operator|<
literal|0
condition|)
block|{
name|bucketNum
operator|=
operator|-
literal|1
operator|*
name|bucketNum
expr_stmt|;
block|}
return|return
name|bucketNum
operator|%
name|numBuckets
return|;
block|}
specifier|static
specifier|public
name|String
name|getOperatorName
parameter_list|()
block|{
return|return
literal|"RS"
return|;
block|}
specifier|public
name|VectorExpression
index|[]
name|getPartitionEval
parameter_list|()
block|{
return|return
name|partitionEval
return|;
block|}
specifier|public
name|void
name|setPartitionEval
parameter_list|(
name|VectorExpression
index|[]
name|partitionEval
parameter_list|)
block|{
name|this
operator|.
name|partitionEval
operator|=
name|partitionEval
expr_stmt|;
block|}
specifier|public
name|VectorExpression
index|[]
name|getValueEval
parameter_list|()
block|{
return|return
name|valueEval
return|;
block|}
specifier|public
name|void
name|setValueEval
parameter_list|(
name|VectorExpression
index|[]
name|valueEval
parameter_list|)
block|{
name|this
operator|.
name|valueEval
operator|=
name|valueEval
expr_stmt|;
block|}
specifier|public
name|VectorExpression
index|[]
name|getKeyEval
parameter_list|()
block|{
return|return
name|keyEval
return|;
block|}
specifier|public
name|void
name|setKeyEval
parameter_list|(
name|VectorExpression
index|[]
name|keyEval
parameter_list|)
block|{
name|this
operator|.
name|keyEval
operator|=
name|keyEval
expr_stmt|;
block|}
block|}
end_class

end_unit

