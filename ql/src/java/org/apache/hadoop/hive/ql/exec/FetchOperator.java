begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringEscapeUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configurable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidTxnList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|ValidWriteIds
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|mr
operator|.
name|ExecMapperContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveContextAwareRecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveRecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|VirtualColumn
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SplitSample
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|FetchWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|TableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
operator|.
name|LogHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeSpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|InspectableObject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorConverters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorConverters
operator|.
name|Converter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspectorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructField
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|primitive
operator|.
name|PrimitiveObjectInspectorFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConfigurable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|input
operator|.
name|FileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|AnnotationUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|ReflectionUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterators
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_comment
comment|/**  * FetchTask implementation.  **/
end_comment

begin_class
specifier|public
class|class
name|FetchOperator
implements|implements
name|Serializable
block|{
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|FetchOperator
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|LogHelper
name|console
init|=
operator|new
name|LogHelper
argument_list|(
name|LOG
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|FETCH_OPERATOR_DIRECTORY_LIST
init|=
literal|"hive.complete.dir.list"
decl_stmt|;
specifier|private
name|FetchWork
name|work
decl_stmt|;
specifier|private
name|Operator
argument_list|<
name|?
argument_list|>
name|operator
decl_stmt|;
comment|// operator tree for processing row further (optional)
specifier|private
specifier|final
name|boolean
name|hasVC
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isStatReader
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isPartitioned
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|isNonNativeTable
decl_stmt|;
specifier|private
name|StructObjectInspector
name|vcsOI
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|VirtualColumn
argument_list|>
name|vcCols
decl_stmt|;
specifier|private
name|ExecMapperContext
name|context
decl_stmt|;
specifier|private
specifier|transient
name|Deserializer
name|tableSerDe
decl_stmt|;
specifier|private
specifier|transient
name|StructObjectInspector
name|tableOI
decl_stmt|;
specifier|private
specifier|transient
name|StructObjectInspector
name|partKeyOI
decl_stmt|;
specifier|private
specifier|transient
name|StructObjectInspector
name|convertedOI
decl_stmt|;
specifier|private
specifier|transient
name|Iterator
argument_list|<
name|Path
argument_list|>
name|iterPath
decl_stmt|;
specifier|private
specifier|transient
name|Iterator
argument_list|<
name|PartitionDesc
argument_list|>
name|iterPartDesc
decl_stmt|;
specifier|private
specifier|transient
name|Iterator
argument_list|<
name|FetchInputFormatSplit
argument_list|>
name|iterSplits
init|=
name|Iterators
operator|.
name|emptyIterator
argument_list|()
decl_stmt|;
specifier|private
specifier|transient
name|Path
name|currPath
decl_stmt|;
specifier|private
specifier|transient
name|PartitionDesc
name|currDesc
decl_stmt|;
specifier|private
specifier|transient
name|Deserializer
name|currSerDe
decl_stmt|;
specifier|private
specifier|transient
name|Converter
name|ObjectConverter
decl_stmt|;
specifier|private
specifier|transient
name|RecordReader
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|>
name|currRecReader
decl_stmt|;
specifier|private
specifier|transient
name|JobConf
name|job
decl_stmt|;
specifier|private
specifier|transient
name|WritableComparable
name|key
decl_stmt|;
specifier|private
specifier|transient
name|Writable
name|value
decl_stmt|;
specifier|private
specifier|transient
name|Object
index|[]
name|vcValues
decl_stmt|;
specifier|private
specifier|transient
name|int
name|headerCount
decl_stmt|;
specifier|private
specifier|transient
name|int
name|footerCount
decl_stmt|;
specifier|private
specifier|transient
name|FooterBuffer
name|footerBuffer
decl_stmt|;
specifier|private
specifier|transient
name|StructObjectInspector
name|outputOI
decl_stmt|;
specifier|private
specifier|transient
name|Object
index|[]
name|row
decl_stmt|;
specifier|private
specifier|transient
name|Map
argument_list|<
name|String
argument_list|,
name|ValidWriteIds
argument_list|>
name|writeIdMap
decl_stmt|;
specifier|public
name|FetchOperator
parameter_list|(
name|FetchWork
name|work
parameter_list|,
name|JobConf
name|job
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
argument_list|(
name|work
argument_list|,
name|job
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
name|FetchOperator
parameter_list|(
name|FetchWork
name|work
parameter_list|,
name|JobConf
name|job
parameter_list|,
name|Operator
argument_list|<
name|?
argument_list|>
name|operator
parameter_list|,
name|List
argument_list|<
name|VirtualColumn
argument_list|>
name|vcCols
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
operator|.
name|job
operator|=
name|job
expr_stmt|;
name|this
operator|.
name|work
operator|=
name|work
expr_stmt|;
name|this
operator|.
name|operator
operator|=
name|operator
expr_stmt|;
if|if
condition|(
name|operator
operator|instanceof
name|TableScanOperator
condition|)
block|{
name|Utilities
operator|.
name|addTableSchemaToConf
argument_list|(
name|job
argument_list|,
operator|(
name|TableScanOperator
operator|)
name|operator
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|vcCols
operator|=
name|vcCols
expr_stmt|;
name|this
operator|.
name|hasVC
operator|=
name|vcCols
operator|!=
literal|null
operator|&&
operator|!
name|vcCols
operator|.
name|isEmpty
argument_list|()
expr_stmt|;
name|this
operator|.
name|isStatReader
operator|=
name|work
operator|.
name|getTblDesc
argument_list|()
operator|==
literal|null
expr_stmt|;
name|this
operator|.
name|isPartitioned
operator|=
operator|!
name|isStatReader
operator|&&
name|work
operator|.
name|isPartitioned
argument_list|()
expr_stmt|;
name|this
operator|.
name|isNonNativeTable
operator|=
operator|!
name|isStatReader
operator|&&
name|work
operator|.
name|getTblDesc
argument_list|()
operator|.
name|isNonNative
argument_list|()
expr_stmt|;
name|initialize
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|setValidTxnList
parameter_list|(
name|String
name|txnStr
parameter_list|)
block|{
name|job
operator|.
name|set
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|,
name|txnStr
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|initialize
parameter_list|()
throws|throws
name|HiveException
block|{
if|if
condition|(
name|isStatReader
condition|)
block|{
name|outputOI
operator|=
name|work
operator|.
name|getStatRowOI
argument_list|()
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|hasVC
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|vcCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|ObjectInspector
argument_list|>
name|inspectors
init|=
operator|new
name|ArrayList
argument_list|<
name|ObjectInspector
argument_list|>
argument_list|(
name|vcCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|VirtualColumn
name|vc
range|:
name|vcCols
control|)
block|{
name|inspectors
operator|.
name|add
argument_list|(
name|vc
operator|.
name|getObjectInspector
argument_list|()
argument_list|)
expr_stmt|;
name|names
operator|.
name|add
argument_list|(
name|vc
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|vcsOI
operator|=
name|ObjectInspectorFactory
operator|.
name|getStandardStructObjectInspector
argument_list|(
name|names
argument_list|,
name|inspectors
argument_list|)
expr_stmt|;
name|vcValues
operator|=
operator|new
name|Object
index|[
name|vcCols
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
block|}
if|if
condition|(
name|hasVC
operator|&&
name|isPartitioned
condition|)
block|{
name|row
operator|=
operator|new
name|Object
index|[
literal|3
index|]
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hasVC
operator|||
name|isPartitioned
condition|)
block|{
name|row
operator|=
operator|new
name|Object
index|[
literal|2
index|]
expr_stmt|;
block|}
else|else
block|{
name|row
operator|=
operator|new
name|Object
index|[
literal|1
index|]
expr_stmt|;
block|}
if|if
condition|(
name|isPartitioned
condition|)
block|{
name|iterPath
operator|=
name|work
operator|.
name|getPartDir
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
name|iterPartDesc
operator|=
name|work
operator|.
name|getPartDesc
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|iterPath
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|work
operator|.
name|getTblDir
argument_list|()
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
name|iterPartDesc
operator|=
name|Iterators
operator|.
name|cycle
argument_list|(
operator|new
name|PartitionDesc
argument_list|(
name|work
operator|.
name|getTblDesc
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|outputOI
operator|=
name|setupOutputObjectInspector
argument_list|()
expr_stmt|;
name|context
operator|=
name|setupExecContext
argument_list|(
name|operator
argument_list|,
name|work
operator|.
name|getPathLists
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|ExecMapperContext
name|setupExecContext
parameter_list|(
name|Operator
name|operator
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|paths
parameter_list|)
block|{
name|ExecMapperContext
name|context
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hasVC
operator|||
name|work
operator|.
name|getSplitSample
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|context
operator|=
operator|new
name|ExecMapperContext
argument_list|(
name|job
argument_list|)
expr_stmt|;
if|if
condition|(
name|operator
operator|!=
literal|null
condition|)
block|{
name|operator
operator|.
name|passExecContext
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
block|}
name|setFetchOperatorContext
argument_list|(
name|job
argument_list|,
name|paths
argument_list|)
expr_stmt|;
return|return
name|context
return|;
block|}
specifier|public
name|FetchWork
name|getWork
parameter_list|()
block|{
return|return
name|work
return|;
block|}
specifier|public
name|void
name|setWork
parameter_list|(
name|FetchWork
name|work
parameter_list|)
block|{
name|this
operator|.
name|work
operator|=
name|work
expr_stmt|;
block|}
comment|/**    * A cache of InputFormat instances.    */
specifier|private
specifier|static
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|InputFormat
argument_list|>
name|inputFormats
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|InputFormat
argument_list|>
argument_list|()
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|static
name|InputFormat
name|getInputFormatFromCache
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|inputFormatClass
parameter_list|,
name|JobConf
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|Configurable
operator|.
name|class
operator|.
name|isAssignableFrom
argument_list|(
name|inputFormatClass
argument_list|)
operator|||
name|JobConfigurable
operator|.
name|class
operator|.
name|isAssignableFrom
argument_list|(
name|inputFormatClass
argument_list|)
condition|)
block|{
return|return
name|ReflectionUtil
operator|.
name|newInstance
argument_list|(
name|inputFormatClass
argument_list|,
name|conf
argument_list|)
return|;
block|}
comment|// TODO: why is this copy-pasted from HiveInputFormat?
name|InputFormat
name|format
init|=
name|inputFormats
operator|.
name|get
argument_list|(
name|inputFormatClass
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|format
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|format
operator|=
name|ReflectionUtil
operator|.
name|newInstance
argument_list|(
name|inputFormatClass
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|inputFormats
operator|.
name|put
argument_list|(
name|inputFormatClass
operator|.
name|getName
argument_list|()
argument_list|,
name|format
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot create an instance of InputFormat class "
operator|+
name|inputFormatClass
operator|.
name|getName
argument_list|()
operator|+
literal|" as specified in mapredWork!"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|format
return|;
block|}
specifier|private
name|StructObjectInspector
name|getPartitionKeyOI
parameter_list|(
name|TableDesc
name|tableDesc
parameter_list|)
throws|throws
name|Exception
block|{
name|String
name|pcols
init|=
name|tableDesc
operator|.
name|getProperties
argument_list|()
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|)
decl_stmt|;
name|String
name|pcolTypes
init|=
name|tableDesc
operator|.
name|getProperties
argument_list|()
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMN_TYPES
argument_list|)
decl_stmt|;
name|String
index|[]
name|partKeys
init|=
name|pcols
operator|.
name|trim
argument_list|()
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|String
index|[]
name|partKeyTypes
init|=
name|pcolTypes
operator|.
name|trim
argument_list|()
operator|.
name|split
argument_list|(
literal|":"
argument_list|)
decl_stmt|;
name|ObjectInspector
index|[]
name|inspectors
init|=
operator|new
name|ObjectInspector
index|[
name|partKeys
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partKeys
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|inspectors
index|[
name|i
index|]
operator|=
name|PrimitiveObjectInspectorFactory
operator|.
name|getPrimitiveWritableObjectInspector
argument_list|(
name|TypeInfoFactory
operator|.
name|getPrimitiveTypeInfo
argument_list|(
name|partKeyTypes
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|ObjectInspectorFactory
operator|.
name|getStandardStructObjectInspector
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|partKeys
argument_list|)
argument_list|,
name|Arrays
operator|.
name|asList
argument_list|(
name|inspectors
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|Object
index|[]
name|createPartValue
parameter_list|(
name|PartitionDesc
name|partDesc
parameter_list|,
name|StructObjectInspector
name|partOI
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
init|=
name|partDesc
operator|.
name|getPartSpec
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|?
extends|extends
name|StructField
argument_list|>
name|fields
init|=
name|partOI
operator|.
name|getAllStructFieldRefs
argument_list|()
decl_stmt|;
name|Object
index|[]
name|partValues
init|=
operator|new
name|Object
index|[
name|fields
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partValues
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|StructField
name|field
init|=
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|String
name|value
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getFieldName
argument_list|()
argument_list|)
decl_stmt|;
name|ObjectInspector
name|oi
init|=
name|field
operator|.
name|getFieldObjectInspector
argument_list|()
decl_stmt|;
name|partValues
index|[
name|i
index|]
operator|=
name|ObjectInspectorConverters
operator|.
name|getConverter
argument_list|(
name|PrimitiveObjectInspectorFactory
operator|.
name|javaStringObjectInspector
argument_list|,
name|oi
argument_list|)
operator|.
name|convert
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
return|return
name|partValues
return|;
block|}
specifier|private
name|boolean
name|getNextPath
parameter_list|()
throws|throws
name|Exception
block|{
while|while
condition|(
name|iterPath
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|currPath
operator|=
name|iterPath
operator|.
name|next
argument_list|()
expr_stmt|;
name|currDesc
operator|=
name|iterPartDesc
operator|.
name|next
argument_list|()
expr_stmt|;
if|if
condition|(
name|isNonNativeTable
condition|)
block|{
return|return
literal|true
return|;
block|}
name|FileSystem
name|fs
init|=
name|currPath
operator|.
name|getFileSystem
argument_list|(
name|job
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|currPath
argument_list|)
condition|)
block|{
for|for
control|(
name|FileStatus
name|fStat
range|:
name|listStatusUnderPath
argument_list|(
name|fs
argument_list|,
name|currPath
argument_list|)
control|)
block|{
if|if
condition|(
name|fStat
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Set context for this fetch operator in to the jobconf.    * This helps InputFormats make decisions based on the scope of the complete    * operation.    * @param conf the configuration to modify    * @param paths the list of input directories    */
specifier|static
name|void
name|setFetchOperatorContext
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|paths
parameter_list|)
block|{
if|if
condition|(
name|paths
operator|!=
literal|null
condition|)
block|{
name|StringBuilder
name|buff
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Path
name|path
range|:
name|paths
control|)
block|{
if|if
condition|(
name|buff
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|buff
operator|.
name|append
argument_list|(
literal|'\t'
argument_list|)
expr_stmt|;
block|}
name|buff
operator|.
name|append
argument_list|(
name|StringEscapeUtils
operator|.
name|escapeJava
argument_list|(
name|path
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
name|FETCH_OPERATOR_DIRECTORY_LIST
argument_list|,
name|buff
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|RecordReader
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|>
name|getRecordReader
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
operator|!
name|iterSplits
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|FetchInputFormatSplit
index|[]
name|splits
init|=
name|getNextSplits
argument_list|()
decl_stmt|;
if|if
condition|(
name|splits
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
operator|!
name|isPartitioned
operator|||
name|convertedOI
operator|==
literal|null
condition|)
block|{
name|currSerDe
operator|=
name|tableSerDe
expr_stmt|;
name|ObjectConverter
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|currSerDe
operator|=
name|needConversion
argument_list|(
name|currDesc
argument_list|)
condition|?
name|currDesc
operator|.
name|getDeserializer
argument_list|(
name|job
argument_list|)
else|:
name|tableSerDe
expr_stmt|;
name|ObjectInspector
name|inputOI
init|=
name|currSerDe
operator|.
name|getObjectInspector
argument_list|()
decl_stmt|;
name|ObjectConverter
operator|=
name|ObjectInspectorConverters
operator|.
name|getConverter
argument_list|(
name|inputOI
argument_list|,
name|convertedOI
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isPartitioned
condition|)
block|{
name|row
index|[
literal|1
index|]
operator|=
name|createPartValue
argument_list|(
name|currDesc
argument_list|,
name|partKeyOI
argument_list|)
expr_stmt|;
block|}
name|iterSplits
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|splits
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating fetchTask with deserializer typeinfo: "
operator|+
name|currSerDe
operator|.
name|getObjectInspector
argument_list|()
operator|.
name|getTypeName
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"deserializer properties:\ntable properties: "
operator|+
name|currDesc
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getProperties
argument_list|()
operator|+
literal|"\npartition properties: "
operator|+
name|currDesc
operator|.
name|getProperties
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|final
name|FetchInputFormatSplit
name|target
init|=
name|iterSplits
operator|.
name|next
argument_list|()
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|final
name|RecordReader
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|>
name|reader
init|=
name|target
operator|.
name|getRecordReader
argument_list|(
name|job
argument_list|)
decl_stmt|;
if|if
condition|(
name|hasVC
operator|||
name|work
operator|.
name|getSplitSample
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|currRecReader
operator|=
operator|new
name|HiveRecordReader
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|>
argument_list|(
name|reader
argument_list|,
name|job
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|doNext
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|value
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if current pos is larger than shrinkedLength which is calculated for
comment|// each split by table sampling, stop fetching any more (early exit)
if|if
condition|(
name|target
operator|.
name|shrinkedLength
operator|>
literal|0
operator|&&
name|context
operator|.
name|getIoCxt
argument_list|()
operator|.
name|getCurrentBlockStart
argument_list|()
operator|>
name|target
operator|.
name|shrinkedLength
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|super
operator|.
name|doNext
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
return|;
block|}
block|}
expr_stmt|;
operator|(
operator|(
name|HiveContextAwareRecordReader
operator|)
name|currRecReader
operator|)
operator|.
name|initIOContext
argument_list|(
name|target
argument_list|,
name|job
argument_list|,
name|target
operator|.
name|inputFormat
operator|.
name|getClass
argument_list|()
argument_list|,
name|reader
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|currRecReader
operator|=
name|reader
expr_stmt|;
block|}
name|key
operator|=
name|currRecReader
operator|.
name|createKey
argument_list|()
expr_stmt|;
name|value
operator|=
name|currRecReader
operator|.
name|createValue
argument_list|()
expr_stmt|;
name|headerCount
operator|=
name|footerCount
operator|=
literal|0
expr_stmt|;
return|return
name|currRecReader
return|;
block|}
specifier|protected
name|FetchInputFormatSplit
index|[]
name|getNextSplits
parameter_list|()
throws|throws
name|Exception
block|{
while|while
condition|(
name|getNextPath
argument_list|()
condition|)
block|{
comment|// not using FileInputFormat.setInputPaths() here because it forces a connection to the
comment|// default file system - which may or may not be online during pure metadata operations
name|job
operator|.
name|set
argument_list|(
literal|"mapred.input.dir"
argument_list|,
name|StringUtils
operator|.
name|escapeString
argument_list|(
name|currPath
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// Fetch operator is not vectorized and as such turn vectorization flag off so that
comment|// non-vectorized record reader is created below.
name|HiveConf
operator|.
name|setBoolVar
argument_list|(
name|job
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_VECTORIZATION_ENABLED
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|formatter
init|=
name|currDesc
operator|.
name|getInputFileFormatClass
argument_list|()
decl_stmt|;
name|Utilities
operator|.
name|copyTableJobPropertiesToConf
argument_list|(
name|currDesc
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|job
argument_list|)
expr_stmt|;
name|InputFormat
name|inputFormat
init|=
name|getInputFormatFromCache
argument_list|(
name|formatter
argument_list|,
name|job
argument_list|)
decl_stmt|;
name|String
name|inputs
init|=
name|processCurrPathForMmWriteIds
argument_list|(
name|inputFormat
argument_list|)
decl_stmt|;
name|Utilities
operator|.
name|LOG14535
operator|.
name|info
argument_list|(
literal|"Setting fetch inputs to "
operator|+
name|inputs
argument_list|)
expr_stmt|;
if|if
condition|(
name|inputs
operator|==
literal|null
condition|)
return|return
literal|null
return|;
name|job
operator|.
name|set
argument_list|(
literal|"mapred.input.dir"
argument_list|,
name|inputs
argument_list|)
expr_stmt|;
name|InputSplit
index|[]
name|splits
init|=
name|inputFormat
operator|.
name|getSplits
argument_list|(
name|job
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|FetchInputFormatSplit
index|[]
name|inputSplits
init|=
operator|new
name|FetchInputFormatSplit
index|[
name|splits
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|splits
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|inputSplits
index|[
name|i
index|]
operator|=
operator|new
name|FetchInputFormatSplit
argument_list|(
name|splits
index|[
name|i
index|]
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|work
operator|.
name|getSplitSample
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|inputSplits
operator|=
name|splitSampling
argument_list|(
name|work
operator|.
name|getSplitSample
argument_list|()
argument_list|,
name|inputSplits
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|inputSplits
operator|.
name|length
operator|>
literal|0
condition|)
block|{
return|return
name|inputSplits
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|private
name|String
name|processCurrPathForMmWriteIds
parameter_list|(
name|InputFormat
name|inputFormat
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|inputFormat
operator|instanceof
name|HiveInputFormat
condition|)
block|{
return|return
name|StringUtils
operator|.
name|escapeString
argument_list|(
name|currPath
operator|.
name|toString
argument_list|()
argument_list|)
return|;
comment|// No need to process here.
block|}
if|if
condition|(
name|writeIdMap
operator|==
literal|null
condition|)
block|{
name|writeIdMap
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|ValidWriteIds
argument_list|>
argument_list|()
expr_stmt|;
block|}
comment|// No need to check for MM table - if it is, the IDs should be in the job config.
name|ValidWriteIds
name|ids
init|=
name|HiveInputFormat
operator|.
name|extractWriteIds
argument_list|(
name|writeIdMap
argument_list|,
name|job
argument_list|,
name|currDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|ids
operator|!=
literal|null
condition|)
block|{
name|Utilities
operator|.
name|LOG14535
operator|.
name|info
argument_list|(
literal|"Observing "
operator|+
name|currDesc
operator|.
name|getTableName
argument_list|()
operator|+
literal|": "
operator|+
name|ids
argument_list|)
expr_stmt|;
block|}
name|Path
index|[]
name|dirs
init|=
name|HiveInputFormat
operator|.
name|processPathsForMmRead
argument_list|(
name|Lists
operator|.
name|newArrayList
argument_list|(
name|currPath
argument_list|)
argument_list|,
name|job
argument_list|,
name|ids
argument_list|)
decl_stmt|;
if|if
condition|(
name|dirs
operator|==
literal|null
operator|||
name|dirs
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
comment|// No valid inputs. This condition is logged inside the call.
block|}
name|StringBuffer
name|str
init|=
operator|new
name|StringBuffer
argument_list|(
name|StringUtils
operator|.
name|escapeString
argument_list|(
name|dirs
index|[
literal|0
index|]
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|dirs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|str
operator|.
name|append
argument_list|(
literal|","
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|escapeString
argument_list|(
name|dirs
index|[
name|i
index|]
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|str
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
name|FetchInputFormatSplit
index|[]
name|splitSampling
parameter_list|(
name|SplitSample
name|splitSample
parameter_list|,
name|FetchInputFormatSplit
index|[]
name|splits
parameter_list|)
block|{
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|FetchInputFormatSplit
name|split
range|:
name|splits
control|)
block|{
name|totalSize
operator|+=
name|split
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
name|List
argument_list|<
name|FetchInputFormatSplit
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|FetchInputFormatSplit
argument_list|>
argument_list|(
name|splits
operator|.
name|length
argument_list|)
decl_stmt|;
name|long
name|targetSize
init|=
name|splitSample
operator|.
name|getTargetSize
argument_list|(
name|totalSize
argument_list|)
decl_stmt|;
name|int
name|startIndex
init|=
name|splitSample
operator|.
name|getSeedNum
argument_list|()
operator|%
name|splits
operator|.
name|length
decl_stmt|;
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|splits
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|FetchInputFormatSplit
name|split
init|=
name|splits
index|[
operator|(
name|startIndex
operator|+
name|i
operator|)
operator|%
name|splits
operator|.
name|length
index|]
decl_stmt|;
name|result
operator|.
name|add
argument_list|(
name|split
argument_list|)
expr_stmt|;
name|long
name|splitgLength
init|=
name|split
operator|.
name|getLength
argument_list|()
decl_stmt|;
if|if
condition|(
name|size
operator|+
name|splitgLength
operator|>=
name|targetSize
condition|)
block|{
if|if
condition|(
name|size
operator|+
name|splitgLength
operator|>
name|targetSize
condition|)
block|{
name|split
operator|.
name|shrinkedLength
operator|=
name|targetSize
operator|-
name|size
expr_stmt|;
block|}
break|break;
block|}
name|size
operator|+=
name|splitgLength
expr_stmt|;
block|}
return|return
name|result
operator|.
name|toArray
argument_list|(
operator|new
name|FetchInputFormatSplit
index|[
name|result
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
comment|/**    * Get the next row and push down it to operator tree.    * Currently only used by FetchTask.    **/
specifier|public
name|boolean
name|pushRow
parameter_list|()
throws|throws
name|IOException
throws|,
name|HiveException
block|{
if|if
condition|(
name|operator
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|work
operator|.
name|getRowsComputedUsingStats
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|List
argument_list|<
name|Object
argument_list|>
name|row
range|:
name|work
operator|.
name|getRowsComputedUsingStats
argument_list|()
control|)
block|{
name|operator
operator|.
name|process
argument_list|(
name|row
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|flushRow
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
name|InspectableObject
name|row
init|=
name|getNextRow
argument_list|()
decl_stmt|;
if|if
condition|(
name|row
operator|!=
literal|null
condition|)
block|{
name|pushRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|flushRow
argument_list|()
expr_stmt|;
block|}
return|return
name|row
operator|!=
literal|null
return|;
block|}
specifier|protected
name|void
name|pushRow
parameter_list|(
name|InspectableObject
name|row
parameter_list|)
throws|throws
name|HiveException
block|{
name|operator
operator|.
name|process
argument_list|(
name|row
operator|.
name|o
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
specifier|protected
name|void
name|flushRow
parameter_list|()
throws|throws
name|HiveException
block|{
name|operator
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
specifier|private
specifier|transient
specifier|final
name|InspectableObject
name|inspectable
init|=
operator|new
name|InspectableObject
argument_list|()
decl_stmt|;
comment|/**    * Get the next row. The fetch context is modified appropriately.    *    **/
specifier|public
name|InspectableObject
name|getNextRow
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
name|boolean
name|opNotEOF
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|context
operator|!=
literal|null
condition|)
block|{
name|context
operator|.
name|resetRow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|currRecReader
operator|==
literal|null
condition|)
block|{
name|currRecReader
operator|=
name|getRecordReader
argument_list|()
expr_stmt|;
if|if
condition|(
name|currRecReader
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|/**            * Start reading a new file.            * If file contains header, skip header lines before reading the records.            * If file contains footer, used FooterBuffer to cache and remove footer            * records at the end of the file.            */
name|headerCount
operator|=
name|Utilities
operator|.
name|getHeaderCount
argument_list|(
name|currDesc
operator|.
name|getTableDesc
argument_list|()
argument_list|)
expr_stmt|;
name|footerCount
operator|=
name|Utilities
operator|.
name|getFooterCount
argument_list|(
name|currDesc
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|job
argument_list|)
expr_stmt|;
comment|// Skip header lines.
name|opNotEOF
operator|=
name|Utilities
operator|.
name|skipHeader
argument_list|(
name|currRecReader
argument_list|,
name|headerCount
argument_list|,
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
comment|// Initialize footer buffer.
if|if
condition|(
name|opNotEOF
operator|&&
name|footerCount
operator|>
literal|0
condition|)
block|{
name|footerBuffer
operator|=
operator|new
name|FooterBuffer
argument_list|()
expr_stmt|;
name|opNotEOF
operator|=
name|footerBuffer
operator|.
name|initializeBuffer
argument_list|(
name|job
argument_list|,
name|currRecReader
argument_list|,
name|footerCount
argument_list|,
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|opNotEOF
operator|&&
name|footerBuffer
operator|==
literal|null
condition|)
block|{
comment|/**            * When file doesn't end after skipping header line            * and there is no footer lines, read normally.            */
name|opNotEOF
operator|=
name|currRecReader
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|opNotEOF
operator|&&
name|footerBuffer
operator|!=
literal|null
condition|)
block|{
name|opNotEOF
operator|=
name|footerBuffer
operator|.
name|updateBuffer
argument_list|(
name|job
argument_list|,
name|currRecReader
argument_list|,
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|opNotEOF
condition|)
block|{
if|if
condition|(
name|operator
operator|!=
literal|null
operator|&&
name|context
operator|!=
literal|null
operator|&&
name|context
operator|.
name|inputFileChanged
argument_list|()
condition|)
block|{
comment|// The child operators cleanup if input file has changed
name|operator
operator|.
name|cleanUpInputFileChanged
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|hasVC
condition|)
block|{
name|row
index|[
name|isPartitioned
condition|?
literal|2
else|:
literal|1
index|]
operator|=
name|MapOperator
operator|.
name|populateVirtualColumnValues
argument_list|(
name|context
argument_list|,
name|vcCols
argument_list|,
name|vcValues
argument_list|,
name|currSerDe
argument_list|)
expr_stmt|;
block|}
name|Object
name|deserialized
init|=
name|currSerDe
operator|.
name|deserialize
argument_list|(
name|value
argument_list|)
decl_stmt|;
if|if
condition|(
name|ObjectConverter
operator|!=
literal|null
condition|)
block|{
name|deserialized
operator|=
name|ObjectConverter
operator|.
name|convert
argument_list|(
name|deserialized
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hasVC
operator|||
name|isPartitioned
condition|)
block|{
name|row
index|[
literal|0
index|]
operator|=
name|deserialized
expr_stmt|;
name|inspectable
operator|.
name|o
operator|=
name|row
expr_stmt|;
block|}
else|else
block|{
name|inspectable
operator|.
name|o
operator|=
name|deserialized
expr_stmt|;
block|}
name|inspectable
operator|.
name|oi
operator|=
name|currSerDe
operator|.
name|getObjectInspector
argument_list|()
expr_stmt|;
return|return
name|inspectable
return|;
block|}
else|else
block|{
name|currRecReader
operator|.
name|close
argument_list|()
expr_stmt|;
name|currRecReader
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Clear the context, if anything needs to be done.    *    **/
specifier|public
name|void
name|clearFetchContext
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
name|currRecReader
operator|!=
literal|null
condition|)
block|{
name|currRecReader
operator|.
name|close
argument_list|()
expr_stmt|;
name|currRecReader
operator|=
literal|null
expr_stmt|;
block|}
name|closeOperator
argument_list|()
expr_stmt|;
if|if
condition|(
name|context
operator|!=
literal|null
condition|)
block|{
name|context
operator|.
name|clear
argument_list|()
expr_stmt|;
name|context
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|currPath
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|iterPath
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|iterPartDesc
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|iterSplits
operator|=
name|Iterators
operator|.
name|emptyIterator
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Failed with exception "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|closeOperator
parameter_list|()
throws|throws
name|HiveException
block|{
if|if
condition|(
name|operator
operator|!=
literal|null
condition|)
block|{
name|operator
operator|.
name|close
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|operator
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * used for bucket map join    */
specifier|public
name|void
name|setupContext
parameter_list|(
name|List
argument_list|<
name|Path
argument_list|>
name|paths
parameter_list|)
block|{
name|this
operator|.
name|iterPath
operator|=
name|paths
operator|.
name|iterator
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|PartitionDesc
argument_list|>
name|partitionDescs
decl_stmt|;
if|if
condition|(
operator|!
name|isPartitioned
condition|)
block|{
name|this
operator|.
name|iterPartDesc
operator|=
name|Iterators
operator|.
name|cycle
argument_list|(
operator|new
name|PartitionDesc
argument_list|(
name|work
operator|.
name|getTblDesc
argument_list|()
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|iterPartDesc
operator|=
name|work
operator|.
name|getPartDescs
argument_list|(
name|paths
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|context
operator|=
name|setupExecContext
argument_list|(
name|operator
argument_list|,
name|paths
argument_list|)
expr_stmt|;
block|}
comment|/**    * returns output ObjectInspector, never null    */
specifier|public
name|ObjectInspector
name|getOutputObjectInspector
parameter_list|()
block|{
return|return
name|outputOI
return|;
block|}
specifier|private
name|StructObjectInspector
name|setupOutputObjectInspector
parameter_list|()
throws|throws
name|HiveException
block|{
name|TableDesc
name|tableDesc
init|=
name|work
operator|.
name|getTblDesc
argument_list|()
decl_stmt|;
try|try
block|{
name|tableSerDe
operator|=
name|tableDesc
operator|.
name|getDeserializer
argument_list|(
name|job
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|tableOI
operator|=
operator|(
name|StructObjectInspector
operator|)
name|tableSerDe
operator|.
name|getObjectInspector
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|isPartitioned
condition|)
block|{
return|return
name|getTableRowOI
argument_list|(
name|tableOI
argument_list|)
return|;
block|}
name|partKeyOI
operator|=
name|getPartitionKeyOI
argument_list|(
name|tableDesc
argument_list|)
expr_stmt|;
name|PartitionDesc
name|partDesc
init|=
operator|new
name|PartitionDesc
argument_list|(
name|tableDesc
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|PartitionDesc
argument_list|>
name|listParts
init|=
name|work
operator|.
name|getPartDesc
argument_list|()
decl_stmt|;
comment|// Chose the table descriptor if none of the partitions is present.
comment|// For eg: consider the query:
comment|// select /*+mapjoin(T1)*/ count(*) from T1 join T2 on T1.key=T2.key
comment|// Both T1 and T2 and partitioned tables, but T1 does not have any partitions
comment|// FetchOperator is invoked for T1, and listParts is empty. In that case,
comment|// use T1's schema to get the ObjectInspector.
if|if
condition|(
name|listParts
operator|==
literal|null
operator|||
name|listParts
operator|.
name|isEmpty
argument_list|()
operator|||
operator|!
name|needConversion
argument_list|(
name|tableDesc
argument_list|,
name|listParts
argument_list|)
condition|)
block|{
return|return
name|getPartitionedRowOI
argument_list|(
name|tableOI
argument_list|)
return|;
block|}
name|convertedOI
operator|=
operator|(
name|StructObjectInspector
operator|)
name|ObjectInspectorConverters
operator|.
name|getConvertedOI
argument_list|(
name|tableOI
argument_list|,
name|tableOI
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
name|getPartitionedRowOI
argument_list|(
name|convertedOI
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Failed with exception "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
throw|;
block|}
block|}
specifier|private
name|StructObjectInspector
name|getTableRowOI
parameter_list|(
name|StructObjectInspector
name|valueOI
parameter_list|)
block|{
return|return
name|hasVC
condition|?
name|ObjectInspectorFactory
operator|.
name|getUnionStructObjectInspector
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|valueOI
argument_list|,
name|vcsOI
argument_list|)
argument_list|)
else|:
name|valueOI
return|;
block|}
specifier|private
name|StructObjectInspector
name|getPartitionedRowOI
parameter_list|(
name|StructObjectInspector
name|valueOI
parameter_list|)
block|{
return|return
name|ObjectInspectorFactory
operator|.
name|getUnionStructObjectInspector
argument_list|(
name|hasVC
condition|?
name|Arrays
operator|.
name|asList
argument_list|(
name|valueOI
argument_list|,
name|partKeyOI
argument_list|,
name|vcsOI
argument_list|)
else|:
name|Arrays
operator|.
name|asList
argument_list|(
name|valueOI
argument_list|,
name|partKeyOI
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|boolean
name|needConversion
parameter_list|(
name|PartitionDesc
name|partitionDesc
parameter_list|)
block|{
name|boolean
name|isAcid
init|=
name|AcidUtils
operator|.
name|isTablePropertyTransactional
argument_list|(
name|partitionDesc
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getProperties
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|Utilities
operator|.
name|isSchemaEvolutionEnabled
argument_list|(
name|job
argument_list|,
name|isAcid
argument_list|)
operator|&&
name|Utilities
operator|.
name|isInputFileFormatSelfDescribing
argument_list|(
name|partitionDesc
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|needConversion
argument_list|(
name|partitionDesc
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|Arrays
operator|.
name|asList
argument_list|(
name|partitionDesc
argument_list|)
argument_list|)
return|;
block|}
comment|// if table and all partitions have the same schema and serde, no need to convert
specifier|private
name|boolean
name|needConversion
parameter_list|(
name|TableDesc
name|tableDesc
parameter_list|,
name|List
argument_list|<
name|PartitionDesc
argument_list|>
name|partDescs
parameter_list|)
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|tableSerDe
init|=
name|tableDesc
operator|.
name|getDeserializerClass
argument_list|()
decl_stmt|;
name|SerDeSpec
name|spec
init|=
name|AnnotationUtils
operator|.
name|getAnnotation
argument_list|(
name|tableSerDe
argument_list|,
name|SerDeSpec
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|spec
condition|)
block|{
comment|// Serde may not have this optional annotation defined in which case be conservative
comment|// and say conversion is needed.
return|return
literal|true
return|;
block|}
name|String
index|[]
name|schemaProps
init|=
name|spec
operator|.
name|schemaProps
argument_list|()
decl_stmt|;
name|Properties
name|tableProps
init|=
name|tableDesc
operator|.
name|getProperties
argument_list|()
decl_stmt|;
for|for
control|(
name|PartitionDesc
name|partitionDesc
range|:
name|partDescs
control|)
block|{
if|if
condition|(
operator|!
name|tableSerDe
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|partitionDesc
operator|.
name|getDeserializerClassName
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
name|Properties
name|partProps
init|=
name|partitionDesc
operator|.
name|getProperties
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|schemaProp
range|:
name|schemaProps
control|)
block|{
if|if
condition|(
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|equals
argument_list|(
name|tableProps
operator|.
name|getProperty
argument_list|(
name|schemaProp
argument_list|)
argument_list|,
name|partProps
operator|.
name|getProperty
argument_list|(
name|schemaProp
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Lists status for all files under a given path. Whether or not this is recursive depends on the    * setting of job configuration parameter mapred.input.dir.recursive.    *    * @param fs    *          file system    *    * @param p    *          path in file system    *    * @return list of file status entries    */
specifier|private
name|FileStatus
index|[]
name|listStatusUnderPath
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|recursive
init|=
name|job
operator|.
name|getBoolean
argument_list|(
name|FileInputFormat
operator|.
name|INPUT_DIR_RECURSIVE
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// If this is in acid format always read it recursively regardless of what the jobconf says.
if|if
condition|(
operator|!
name|recursive
operator|&&
operator|!
name|AcidUtils
operator|.
name|isAcid
argument_list|(
name|p
argument_list|,
name|job
argument_list|)
condition|)
block|{
return|return
name|fs
operator|.
name|listStatus
argument_list|(
name|p
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
return|;
block|}
name|List
argument_list|<
name|FileStatus
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FileStatus
name|stat
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|p
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
control|)
block|{
name|FileUtils
operator|.
name|listStatusRecursively
argument_list|(
name|fs
argument_list|,
name|stat
argument_list|,
name|results
argument_list|)
expr_stmt|;
block|}
return|return
name|results
operator|.
name|toArray
argument_list|(
operator|new
name|FileStatus
index|[
name|results
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
comment|// for split sampling. shrinkedLength is checked against IOContext.getCurrentBlockStart,
comment|// which is from RecordReader.getPos(). So some inputformats which does not support getPos()
comment|// like HiveHBaseTableInputFormat cannot be used with this (todo)
specifier|private
specifier|static
class|class
name|FetchInputFormatSplit
extends|extends
name|HiveInputFormat
operator|.
name|HiveInputSplit
block|{
comment|// shrinked size for this split. counter part of this in normal mode is
comment|// InputSplitShim.shrinkedLength.
comment|// what's different is that this is evaluated by unit of row using RecordReader.getPos()
comment|// and that is evaluated by unit of split using InputSplit.getLength().
specifier|private
name|long
name|shrinkedLength
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
specifier|final
name|InputFormat
name|inputFormat
decl_stmt|;
specifier|public
name|FetchInputFormatSplit
parameter_list|(
name|InputSplit
name|split
parameter_list|,
name|InputFormat
name|inputFormat
parameter_list|)
block|{
name|super
argument_list|(
name|split
argument_list|,
name|inputFormat
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputFormat
operator|=
name|inputFormat
expr_stmt|;
block|}
specifier|public
name|RecordReader
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|>
name|getRecordReader
parameter_list|(
name|JobConf
name|job
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|inputFormat
operator|.
name|getRecordReader
argument_list|(
name|getInputSplit
argument_list|()
argument_list|,
name|job
argument_list|,
name|Reporter
operator|.
name|NULL
argument_list|)
return|;
block|}
block|}
specifier|public
name|Configuration
name|getJobConf
parameter_list|()
block|{
return|return
name|job
return|;
block|}
block|}
end_class

end_unit

