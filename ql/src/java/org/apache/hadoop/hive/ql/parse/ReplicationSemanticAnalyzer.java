begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*   Licensed to the Apache Software Foundation (ASF) under one   or more contributor license agreements.  See the NOTICE file   distributed with this work for additional information   regarding copyright ownership.  The ASF licenses this file   to you under the Apache License, Version 2.0 (the   "License"); you may not use this file except in compliance   with the License.  You may obtain a copy of the License at        http://www.apache.org/licenses/LICENSE-2.0    Unless required by applicable law or agreed to in writing, software   distributed under the License is distributed on an "AS IS" BASIS,   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   See the License for the specific language governing permissions and   limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Predicate
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Collections2
import|;
end_import

begin_import
import|import
name|org
operator|.
name|antlr
operator|.
name|runtime
operator|.
name|tree
operator|.
name|Tree
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|QueryState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Task
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|TaskFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
operator|.
name|ReplDumpTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|repl
operator|.
name|ReplDumpWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|ReadEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|hooks
operator|.
name|WriteEntity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Hive
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|dump
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|DumpMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|EventDumpDirComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|MetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|message
operator|.
name|CreateFunctionHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|repl
operator|.
name|load
operator|.
name|message
operator|.
name|MessageHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterDatabaseDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AlterTableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|CreateDatabaseDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DDLWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DependencyCollectionWork
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|PlanUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
operator|.
name|TOK_FROM
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
operator|.
name|TOK_LIMIT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
operator|.
name|TOK_REPL_DUMP
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
operator|.
name|TOK_REPL_LOAD
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
operator|.
name|TOK_REPL_STATUS
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|HiveParser
operator|.
name|TOK_TO
import|;
end_import

begin_class
specifier|public
class|class
name|ReplicationSemanticAnalyzer
extends|extends
name|BaseSemanticAnalyzer
block|{
comment|// Database name or pattern
specifier|private
name|String
name|dbNameOrPattern
decl_stmt|;
comment|// Table name or pattern
specifier|private
name|String
name|tblNameOrPattern
decl_stmt|;
specifier|private
name|Long
name|eventFrom
decl_stmt|;
specifier|private
name|Long
name|eventTo
decl_stmt|;
specifier|private
name|Integer
name|maxEventLimit
decl_stmt|;
comment|// Base path for REPL LOAD
specifier|private
name|String
name|path
decl_stmt|;
specifier|private
specifier|static
name|String
name|testInjectDumpDir
init|=
literal|null
decl_stmt|;
comment|// unit tests can overwrite this to affect default dump behaviour
specifier|private
specifier|static
specifier|final
name|String
name|dumpSchema
init|=
literal|"dump_dir,last_repl_id#string,string"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|FUNCTIONS_ROOT_DIR_NAME
init|=
literal|"_functions"
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|Logger
name|REPL_STATE_LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"ReplState"
argument_list|)
decl_stmt|;
name|ReplicationSemanticAnalyzer
parameter_list|(
name|QueryState
name|queryState
parameter_list|)
throws|throws
name|SemanticException
block|{
name|super
argument_list|(
name|queryState
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|analyzeInternal
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
throws|throws
name|SemanticException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAanalyzer: analyzeInternal"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|ast
operator|.
name|getName
argument_list|()
operator|+
literal|":"
operator|+
name|ast
operator|.
name|getToken
argument_list|()
operator|.
name|getText
argument_list|()
operator|+
literal|"="
operator|+
name|ast
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|ast
operator|.
name|getToken
argument_list|()
operator|.
name|getType
argument_list|()
condition|)
block|{
case|case
name|TOK_REPL_DUMP
case|:
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer: analyzeInternal: dump"
argument_list|)
expr_stmt|;
name|initReplDump
argument_list|(
name|ast
argument_list|)
expr_stmt|;
name|analyzeReplDump
argument_list|(
name|ast
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|TOK_REPL_LOAD
case|:
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer: analyzeInternal: load"
argument_list|)
expr_stmt|;
name|initReplLoad
argument_list|(
name|ast
argument_list|)
expr_stmt|;
name|analyzeReplLoad
argument_list|(
name|ast
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|TOK_REPL_STATUS
case|:
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer: analyzeInternal: status"
argument_list|)
expr_stmt|;
name|initReplStatus
argument_list|(
name|ast
argument_list|)
expr_stmt|;
name|analyzeReplStatus
argument_list|(
name|ast
argument_list|)
expr_stmt|;
break|break;
block|}
default|default:
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Unexpected root token"
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|void
name|initReplDump
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
block|{
name|int
name|numChildren
init|=
name|ast
operator|.
name|getChildCount
argument_list|()
decl_stmt|;
name|dbNameOrPattern
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
literal|0
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
comment|// skip the first node, which is always required
name|int
name|currNode
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|currNode
operator|<
name|numChildren
condition|)
block|{
if|if
condition|(
name|ast
operator|.
name|getChild
argument_list|(
name|currNode
argument_list|)
operator|.
name|getType
argument_list|()
operator|!=
name|TOK_FROM
condition|)
block|{
comment|// optional tblName was specified.
name|tblNameOrPattern
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
name|currNode
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// TOK_FROM subtree
name|Tree
name|fromNode
init|=
name|ast
operator|.
name|getChild
argument_list|(
name|currNode
argument_list|)
decl_stmt|;
name|eventFrom
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|fromNode
operator|.
name|getChild
argument_list|(
literal|0
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// skip the first, which is always required
name|int
name|numChild
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|numChild
operator|<
name|fromNode
operator|.
name|getChildCount
argument_list|()
condition|)
block|{
if|if
condition|(
name|fromNode
operator|.
name|getChild
argument_list|(
name|numChild
argument_list|)
operator|.
name|getType
argument_list|()
operator|==
name|TOK_TO
condition|)
block|{
name|eventTo
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|fromNode
operator|.
name|getChild
argument_list|(
name|numChild
operator|+
literal|1
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// skip the next child, since we already took care of it
name|numChild
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|fromNode
operator|.
name|getChild
argument_list|(
name|numChild
argument_list|)
operator|.
name|getType
argument_list|()
operator|==
name|TOK_LIMIT
condition|)
block|{
name|maxEventLimit
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|fromNode
operator|.
name|getChild
argument_list|(
name|numChild
operator|+
literal|1
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// skip the next child, since we already took care of it
name|numChild
operator|++
expr_stmt|;
block|}
comment|// move to the next child in FROM tree
name|numChild
operator|++
expr_stmt|;
block|}
comment|// FROM node is always the last
break|break;
block|}
comment|// move to the next root node
name|currNode
operator|++
expr_stmt|;
block|}
block|}
comment|// REPL DUMP
specifier|private
name|void
name|analyzeReplDump
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
throws|throws
name|SemanticException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer.analyzeReplDump: "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|dbNameOrPattern
argument_list|)
operator|+
literal|"."
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|tblNameOrPattern
argument_list|)
operator|+
literal|" from "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|eventFrom
argument_list|)
operator|+
literal|" to "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|eventTo
argument_list|)
operator|+
literal|" maxEventLimit "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|maxEventLimit
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|ctx
operator|.
name|setResFile
argument_list|(
name|ctx
operator|.
name|getLocalTmpPath
argument_list|()
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|ReplDumpWork
argument_list|>
name|replDumpWorkTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|ReplDumpWork
argument_list|(
name|dbNameOrPattern
argument_list|,
name|tblNameOrPattern
argument_list|,
name|eventFrom
argument_list|,
name|eventTo
argument_list|,
name|ErrorMsg
operator|.
name|INVALID_PATH
operator|.
name|getMsg
argument_list|(
name|ast
argument_list|)
argument_list|,
name|maxEventLimit
argument_list|,
name|ctx
operator|.
name|getResFile
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|rootTasks
operator|.
name|add
argument_list|(
name|replDumpWorkTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|dbNameOrPattern
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|dbName
range|:
name|Utils
operator|.
name|matchesDb
argument_list|(
name|db
argument_list|,
name|dbNameOrPattern
argument_list|)
control|)
block|{
if|if
condition|(
name|tblNameOrPattern
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|tblName
range|:
name|Utils
operator|.
name|matchesTbl
argument_list|(
name|db
argument_list|,
name|dbName
argument_list|,
name|tblNameOrPattern
argument_list|)
control|)
block|{
name|inputs
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|db
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|inputs
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|db
operator|.
name|getDatabase
argument_list|(
name|dbName
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|setFetchTask
argument_list|(
name|createFetchTask
argument_list|(
name|dumpSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// TODO : simple wrap& rethrow for now, clean up with error codes
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error during analyzeReplDump"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// REPL LOAD
specifier|private
name|void
name|initReplLoad
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
block|{
name|int
name|numChildren
init|=
name|ast
operator|.
name|getChildCount
argument_list|()
decl_stmt|;
name|path
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
literal|0
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|numChildren
operator|>
literal|1
condition|)
block|{
name|dbNameOrPattern
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
literal|1
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|numChildren
operator|>
literal|2
condition|)
block|{
name|tblNameOrPattern
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
literal|2
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * Example dump dirs we need to be able to handle :    *    * for: hive.repl.rootdir = staging/    * Then, repl dumps will be created in staging/<dumpdir>    *    * single-db-dump: staging/blah12345 will contain a db dir for the db specified    *  blah12345/    *   default/    *    _metadata    *    tbl1/    *      _metadata    *      dt=20160907/    *        _files    *    tbl2/    *    tbl3/    *    unptn_tbl/    *      _metadata    *      _files    *    * multi-db-dump: staging/bar12347 will contain dirs for each db covered    * staging/    *  bar12347/    *   default/    *     ...    *   sales/    *     ...    *    * single table-dump: staging/baz123 will contain a table object dump inside    * staging/    *  baz123/    *    _metadata    *    dt=20150931/    *      _files    *    * incremental dump : staging/blue123 will contain dirs for each event inside.    * staging/    *  blue123/    *    34/    *    35/    *    36/    */
specifier|private
name|void
name|analyzeReplLoad
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
throws|throws
name|SemanticException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplSemanticAnalyzer.analyzeReplLoad: "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|dbNameOrPattern
argument_list|)
operator|+
literal|"."
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|tblNameOrPattern
argument_list|)
operator|+
literal|" from "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
comment|// for analyze repl load, we walk through the dir structure available in the path,
comment|// looking at each db, and then each table, and then setting up the appropriate
comment|// import job in its place.
try|try
block|{
name|Path
name|loadPath
init|=
operator|new
name|Path
argument_list|(
name|path
argument_list|)
decl_stmt|;
specifier|final
name|FileSystem
name|fs
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|loadPath
argument_list|)
condition|)
block|{
comment|// supposed dump path does not exist.
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
comment|// Now, the dumped path can be one of three things:
comment|// a) It can be a db dump, in which case we expect a set of dirs, each with a
comment|// db name, and with a _metadata file in each, and table dirs inside that.
comment|// b) It can be a table dump dir, in which case we expect a _metadata dump of
comment|// a table in question in the dir, and individual ptn dir hierarchy.
comment|// c) A dump can be an incremental dump, which means we have several subdirs
comment|// each of which have the evid as the dir name, and each of which correspond
comment|// to a event-level dump. Currently, only CREATE_TABLE and ADD_PARTITION are
comment|// handled, so all of these dumps will be at a table/ptn level.
comment|// For incremental repl, we will have individual events which can
comment|// be other things like roles and fns as well.
comment|// At this point, all dump dirs should contain a _dumpmetadata file that
comment|// tells us what is inside that dumpdir.
name|DumpMetaData
name|dmd
init|=
operator|new
name|DumpMetaData
argument_list|(
name|loadPath
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|boolean
name|evDump
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|dmd
operator|.
name|isIncrementalDump
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} contains an incremental dump"
argument_list|,
name|loadPath
argument_list|)
expr_stmt|;
name|evDump
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} contains an bootstrap dump"
argument_list|,
name|loadPath
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
operator|!
name|evDump
operator|)
operator|&&
operator|(
name|tblNameOrPattern
operator|!=
literal|null
operator|)
operator|&&
operator|!
operator|(
name|tblNameOrPattern
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
comment|// not an event dump, and table name pattern specified, this has to be a tbl-level dump
name|rootTasks
operator|.
name|addAll
argument_list|(
name|analyzeTableLoad
argument_list|(
name|dbNameOrPattern
argument_list|,
name|tblNameOrPattern
argument_list|,
name|path
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|FileStatus
index|[]
name|srcs
init|=
name|LoadSemanticAnalyzer
operator|.
name|matchFilesOrDir
argument_list|(
name|fs
argument_list|,
name|loadPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcs
operator|==
literal|null
operator|||
operator|(
name|srcs
operator|.
name|length
operator|==
literal|0
operator|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Nothing to load at {}"
argument_list|,
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
name|FileStatus
index|[]
name|dirsInLoadPath
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|loadPath
argument_list|,
name|EximUtil
operator|.
name|getDirectoryFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|dirsInLoadPath
operator|==
literal|null
operator|)
operator|||
operator|(
name|dirsInLoadPath
operator|.
name|length
operator|==
literal|0
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"No data to load in path "
operator|+
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|evDump
condition|)
block|{
comment|// not an event dump, not a table dump - thus, a db dump
if|if
condition|(
operator|(
name|dbNameOrPattern
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|dirsInLoadPath
operator|.
name|length
operator|>
literal|1
operator|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found multiple dirs when we expected 1:"
argument_list|)
expr_stmt|;
for|for
control|(
name|FileStatus
name|d
range|:
name|dirsInLoadPath
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"> "
operator|+
name|d
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Multiple dirs in "
operator|+
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" does not correspond to REPL LOAD expecting to load to a singular destination point."
argument_list|)
throw|;
block|}
for|for
control|(
name|FileStatus
name|dir
range|:
name|dirsInLoadPath
control|)
block|{
name|analyzeDatabaseLoad
argument_list|(
name|dbNameOrPattern
argument_list|,
name|fs
argument_list|,
name|dir
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Event dump, each sub-dir is an individual event dump.
comment|// We need to guarantee that the directory listing we got is in order of evid.
name|Arrays
operator|.
name|sort
argument_list|(
name|dirsInLoadPath
argument_list|,
operator|new
name|EventDumpDirComparator
argument_list|()
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|evTaskRoot
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DependencyCollectionWork
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|taskChainTail
init|=
name|evTaskRoot
decl_stmt|;
name|int
name|evstage
init|=
literal|0
decl_stmt|;
name|int
name|evIter
init|=
literal|0
decl_stmt|;
name|Long
name|lastEvid
init|=
literal|null
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|dbsUpdated
init|=
operator|new
name|ReplicationSpec
operator|.
name|ReplStateMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|tablesUpdated
init|=
operator|new
name|ReplicationSpec
operator|.
name|ReplStateMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Started analyzing Repl load for DB: {} from path {}, Dump Type: INCREMENTAL"
argument_list|,
operator|(
literal|null
operator|!=
name|dbNameOrPattern
operator|&&
operator|!
name|dbNameOrPattern
operator|.
name|isEmpty
argument_list|()
operator|)
condition|?
name|dbNameOrPattern
else|:
literal|"?"
argument_list|,
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|FileStatus
name|dir
range|:
name|dirsInLoadPath
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Loading event from {} to {}.{}"
argument_list|,
name|dir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
argument_list|,
name|dbNameOrPattern
argument_list|,
name|tblNameOrPattern
argument_list|)
expr_stmt|;
comment|// event loads will behave similar to table loads, with one crucial difference
comment|// precursor order is strict, and each event must be processed after the previous one.
comment|// The way we handle this strict order is as follows:
comment|// First, we start with a taskChainTail which is a dummy noop task (a DependecyCollectionTask)
comment|// at the head of our event chain. For each event we process, we tell analyzeTableLoad to
comment|// create tasks that use the taskChainTail as a dependency. Then, we collect all those tasks
comment|// and introduce a new barrier task(also a DependencyCollectionTask) which depends on all
comment|// these tasks. Then, this barrier task becomes our new taskChainTail. Thus, we get a set of
comment|// tasks as follows:
comment|//
comment|//                 --->ev1.task1--                          --->ev2.task1--
comment|//                /               \                        /               \
comment|//  evTaskRoot-->*---->ev1.task2---*--> ev1.barrierTask-->*---->ev2.task2---*->evTaskChainTail
comment|//                \               /
comment|//                 --->ev1.task3--
comment|//
comment|// Once this entire chain is generated, we add evTaskRoot to rootTasks, so as to execute the
comment|// entire chain
name|String
name|locn
init|=
name|dir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|DumpMetaData
name|eventDmd
init|=
operator|new
name|DumpMetaData
argument_list|(
operator|new
name|Path
argument_list|(
name|locn
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|evTasks
init|=
name|analyzeEventLoad
argument_list|(
name|dbNameOrPattern
argument_list|,
name|tblNameOrPattern
argument_list|,
name|locn
argument_list|,
name|taskChainTail
argument_list|,
name|dbsUpdated
argument_list|,
name|tablesUpdated
argument_list|,
name|eventDmd
argument_list|)
decl_stmt|;
name|evIter
operator|++
expr_stmt|;
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Analyzed load for event {}/{} "
operator|+
literal|"with ID: {}, Type: {}, Path: {}"
argument_list|,
name|evIter
argument_list|,
name|dirsInLoadPath
operator|.
name|length
argument_list|,
name|dir
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|eventDmd
operator|.
name|getDumpType
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|locn
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"evstage#{} got {} tasks"
argument_list|,
name|evstage
argument_list|,
name|evTasks
operator|!=
literal|null
condition|?
name|evTasks
operator|.
name|size
argument_list|()
else|:
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|evTasks
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|evTasks
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|barrierTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DependencyCollectionWork
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|t
range|:
name|evTasks
control|)
block|{
name|t
operator|.
name|addDependentTask
argument_list|(
name|barrierTask
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Added {}:{} as a precursor of barrier task {}:{}"
argument_list|,
name|t
operator|.
name|getClass
argument_list|()
argument_list|,
name|t
operator|.
name|getId
argument_list|()
argument_list|,
name|barrierTask
operator|.
name|getClass
argument_list|()
argument_list|,
name|barrierTask
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updated taskChainTail from {}{} to {}{}"
argument_list|,
name|taskChainTail
operator|.
name|getClass
argument_list|()
argument_list|,
name|taskChainTail
operator|.
name|getId
argument_list|()
argument_list|,
name|barrierTask
operator|.
name|getClass
argument_list|()
argument_list|,
name|barrierTask
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
name|taskChainTail
operator|=
name|barrierTask
expr_stmt|;
name|evstage
operator|++
expr_stmt|;
name|lastEvid
operator|=
name|dmd
operator|.
name|getEventTo
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Now, we need to update repl.last.id for the various parent objects that were updated.
comment|// This update logic will work differently based on what "level" REPL LOAD was run on.
comment|//  a) If this was a REPL LOAD at a table level, i.e. both dbNameOrPattern and
comment|//     tblNameOrPattern were specified, then the table is the only thing we should
comment|//     update the repl.last.id for.
comment|//  b) If this was a db-level REPL LOAD, then we should update the db, as well as any
comment|//     tables affected by partition level operations. (any table level ops will
comment|//     automatically be updated as the table gets updated. Note - renames will need
comment|//     careful handling.
comment|//  c) If this was a wh-level REPL LOAD, then we should update every db for which there
comment|//     were events occurring, as well as tables for which there were ptn-level ops
comment|//     happened. Again, renames must be taken care of.
comment|//
comment|// So, what we're going to do is have each event load update dbsUpdated and tablesUpdated
comment|// accordingly, but ignore updates to tablesUpdated& dbsUpdated in the case of a
comment|// table-level REPL LOAD, using only the table itself. In the case of a db-level REPL
comment|// LOAD, we ignore dbsUpdated, but inject our own, and do not ignore tblsUpdated.
comment|// And for wh-level, we do no special processing, and use all of dbsUpdated and
comment|// tblsUpdated as-is.
comment|// Additional Note - although this var says "dbNameOrPattern", on REPL LOAD side,
comment|// we do not support a pattern It can be null or empty, in which case
comment|// we re-use the existing name from the dump, or it can be specified,
comment|// in which case we honour it. However, having this be a pattern is an error.
comment|// Ditto for tblNameOrPattern.
if|if
condition|(
name|evstage
operator|>
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|tblNameOrPattern
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|tblNameOrPattern
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
comment|// if tblNameOrPattern is specified, then dbNameOrPattern will be too, and
comment|// thus, this is a table-level REPL LOAD - only table needs updating.
comment|// If any of the individual events logged any other dbs as having changed,
comment|// null them out.
name|dbsUpdated
operator|.
name|clear
argument_list|()
expr_stmt|;
name|tablesUpdated
operator|.
name|clear
argument_list|()
expr_stmt|;
name|tablesUpdated
operator|.
name|put
argument_list|(
name|dbNameOrPattern
operator|+
literal|"."
operator|+
name|tblNameOrPattern
argument_list|,
name|lastEvid
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|dbNameOrPattern
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|dbNameOrPattern
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
comment|// if dbNameOrPattern is specified and tblNameOrPattern isn't, this is a
comment|// db-level update, and thus, the database needs updating. In addition.
name|dbsUpdated
operator|.
name|clear
argument_list|()
expr_stmt|;
name|dbsUpdated
operator|.
name|put
argument_list|(
name|dbNameOrPattern
argument_list|,
name|lastEvid
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|String
name|tableName
range|:
name|tablesUpdated
operator|.
name|keySet
argument_list|()
control|)
block|{
comment|// weird - AlterTableDesc requires a HashMap to update props instead of a Map.
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|mapProp
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|eventId
init|=
name|tablesUpdated
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
name|mapProp
operator|.
name|put
argument_list|(
name|ReplicationSpec
operator|.
name|KEY
operator|.
name|CURR_STATE_ID
operator|.
name|toString
argument_list|()
argument_list|,
name|eventId
argument_list|)
expr_stmt|;
name|AlterTableDesc
name|alterTblDesc
init|=
operator|new
name|AlterTableDesc
argument_list|(
name|AlterTableDesc
operator|.
name|AlterTableTypes
operator|.
name|ADDPROPS
argument_list|,
operator|new
name|ReplicationSpec
argument_list|(
name|eventId
argument_list|,
name|eventId
argument_list|)
argument_list|)
decl_stmt|;
name|alterTblDesc
operator|.
name|setProps
argument_list|(
name|mapProp
argument_list|)
expr_stmt|;
name|alterTblDesc
operator|.
name|setOldName
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|updateReplIdTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DDLWork
argument_list|(
name|inputs
argument_list|,
name|outputs
argument_list|,
name|alterTblDesc
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|taskChainTail
operator|.
name|addDependentTask
argument_list|(
name|updateReplIdTask
argument_list|)
expr_stmt|;
name|taskChainTail
operator|=
name|updateReplIdTask
expr_stmt|;
block|}
for|for
control|(
name|String
name|dbName
range|:
name|dbsUpdated
operator|.
name|keySet
argument_list|()
control|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|mapProp
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|eventId
init|=
name|dbsUpdated
operator|.
name|get
argument_list|(
name|dbName
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
name|mapProp
operator|.
name|put
argument_list|(
name|ReplicationSpec
operator|.
name|KEY
operator|.
name|CURR_STATE_ID
operator|.
name|toString
argument_list|()
argument_list|,
name|eventId
argument_list|)
expr_stmt|;
name|AlterDatabaseDesc
name|alterDbDesc
init|=
operator|new
name|AlterDatabaseDesc
argument_list|(
name|dbName
argument_list|,
name|mapProp
argument_list|,
operator|new
name|ReplicationSpec
argument_list|(
name|eventId
argument_list|,
name|eventId
argument_list|)
argument_list|)
decl_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|updateReplIdTask
init|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DDLWork
argument_list|(
name|inputs
argument_list|,
name|outputs
argument_list|,
name|alterDbDesc
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|taskChainTail
operator|.
name|addDependentTask
argument_list|(
name|updateReplIdTask
argument_list|)
expr_stmt|;
name|taskChainTail
operator|=
name|updateReplIdTask
expr_stmt|;
block|}
name|rootTasks
operator|.
name|add
argument_list|(
name|evTaskRoot
argument_list|)
expr_stmt|;
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Completed analyzing Repl load for DB: {} from path {} and created import "
operator|+
literal|"(DDL/COPY/MOVE) tasks"
argument_list|,
operator|(
literal|null
operator|!=
name|dbNameOrPattern
operator|&&
operator|!
name|dbNameOrPattern
operator|.
name|isEmpty
argument_list|()
operator|)
condition|?
name|dbNameOrPattern
else|:
literal|"?"
argument_list|,
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// TODO : simple wrap& rethrow for now, clean up with error codes
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|analyzeEventLoad
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|location
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|precursor
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|dbsUpdated
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|tablesUpdated
parameter_list|,
name|DumpMetaData
name|dmd
parameter_list|)
throws|throws
name|SemanticException
block|{
name|MessageHandler
operator|.
name|Context
name|context
init|=
operator|new
name|MessageHandler
operator|.
name|Context
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|location
argument_list|,
name|precursor
argument_list|,
name|dmd
argument_list|,
name|conf
argument_list|,
name|db
argument_list|,
name|ctx
argument_list|,
name|LOG
argument_list|)
decl_stmt|;
name|MessageHandler
name|messageHandler
init|=
name|dmd
operator|.
name|getDumpType
argument_list|()
operator|.
name|handler
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|tasks
init|=
name|messageHandler
operator|.
name|handle
argument_list|(
name|context
argument_list|)
decl_stmt|;
if|if
condition|(
name|precursor
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|t
range|:
name|tasks
control|)
block|{
name|precursor
operator|.
name|addDependentTask
argument_list|(
name|t
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Added {}:{} as a precursor of {}:{}"
argument_list|,
name|precursor
operator|.
name|getClass
argument_list|()
argument_list|,
name|precursor
operator|.
name|getId
argument_list|()
argument_list|,
name|t
operator|.
name|getClass
argument_list|()
argument_list|,
name|t
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|dbsUpdated
operator|.
name|putAll
argument_list|(
name|messageHandler
operator|.
name|databasesUpdated
argument_list|()
argument_list|)
expr_stmt|;
name|tablesUpdated
operator|.
name|putAll
argument_list|(
name|messageHandler
operator|.
name|tablesUpdated
argument_list|()
argument_list|)
expr_stmt|;
name|inputs
operator|.
name|addAll
argument_list|(
name|messageHandler
operator|.
name|readEntities
argument_list|()
argument_list|)
expr_stmt|;
name|outputs
operator|.
name|addAll
argument_list|(
name|messageHandler
operator|.
name|writeEntities
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|tasks
return|;
block|}
specifier|private
name|boolean
name|existEmptyDb
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
name|Hive
name|hiveDb
init|=
name|Hive
operator|.
name|get
argument_list|()
decl_stmt|;
name|Database
name|db
init|=
name|hiveDb
operator|.
name|getDatabase
argument_list|(
name|dbName
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|!=
name|db
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|allTables
init|=
name|hiveDb
operator|.
name|getAllTables
argument_list|(
name|dbName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|allFunctions
init|=
name|hiveDb
operator|.
name|getFunctions
argument_list|(
name|dbName
argument_list|,
literal|"*"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|allTables
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|InvalidOperationException
argument_list|(
literal|"Database "
operator|+
name|db
operator|.
name|getName
argument_list|()
operator|+
literal|" is not empty. One or more tables exist."
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|allFunctions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|InvalidOperationException
argument_list|(
literal|"Database "
operator|+
name|db
operator|.
name|getName
argument_list|()
operator|+
literal|" is not empty. One or more functions exist."
argument_list|)
throw|;
block|}
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|void
name|analyzeDatabaseLoad
parameter_list|(
name|String
name|dbName
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|dir
parameter_list|)
throws|throws
name|SemanticException
block|{
try|try
block|{
comment|// Path being passed to us is a db dump location. We go ahead and load as needed.
comment|// dbName might be null or empty, in which case we keep the original db name for the new
comment|// database creation
comment|// Two steps here - first, we read the _metadata file here, and create a CreateDatabaseDesc
comment|// associated with that
comment|// Then, we iterate over all subdirs, and create table imports for each.
name|MetaData
name|rv
init|=
operator|new
name|MetaData
argument_list|()
decl_stmt|;
try|try
block|{
name|rv
operator|=
name|EximUtil
operator|.
name|readMetaData
argument_list|(
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|dir
operator|.
name|getPath
argument_list|()
argument_list|,
name|EximUtil
operator|.
name|METADATA_NAME
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PATH
operator|.
name|getMsg
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Database
name|dbObj
init|=
name|rv
operator|.
name|getDatabase
argument_list|()
decl_stmt|;
if|if
condition|(
name|dbObj
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"_metadata file read did not contain a db object - invalid dump."
argument_list|)
throw|;
block|}
if|if
condition|(
operator|(
name|dbName
operator|==
literal|null
operator|)
operator|||
operator|(
name|dbName
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
comment|// We use dbName specified as long as it is not null/empty. If so, then we use the original
comment|// name
comment|// recorded in the thrift object.
name|dbName
operator|=
name|dbObj
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Started analyzing Repl Load for DB: {} from Dump Dir: {}, Dump Type: BOOTSTRAP"
argument_list|,
name|dbName
argument_list|,
name|dir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|dbRootTask
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|existEmptyDb
argument_list|(
name|dbName
argument_list|)
condition|)
block|{
name|AlterDatabaseDesc
name|alterDbDesc
init|=
operator|new
name|AlterDatabaseDesc
argument_list|(
name|dbName
argument_list|,
name|dbObj
operator|.
name|getParameters
argument_list|()
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|dbRootTask
operator|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DDLWork
argument_list|(
name|inputs
argument_list|,
name|outputs
argument_list|,
name|alterDbDesc
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|CreateDatabaseDesc
name|createDbDesc
init|=
operator|new
name|CreateDatabaseDesc
argument_list|()
decl_stmt|;
name|createDbDesc
operator|.
name|setName
argument_list|(
name|dbName
argument_list|)
expr_stmt|;
name|createDbDesc
operator|.
name|setComment
argument_list|(
name|dbObj
operator|.
name|getDescription
argument_list|()
argument_list|)
expr_stmt|;
name|createDbDesc
operator|.
name|setDatabaseProperties
argument_list|(
name|dbObj
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
comment|// note that we do not set location - for repl load, we want that auto-created.
name|createDbDesc
operator|.
name|setIfNotExists
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// If it exists, we want this to be an error condition. Repl Load is not intended to replace a
comment|// db.
comment|// TODO: we might revisit this in create-drop-recreate cases, needs some thinking on.
name|dbRootTask
operator|=
name|TaskFactory
operator|.
name|get
argument_list|(
operator|new
name|DDLWork
argument_list|(
name|inputs
argument_list|,
name|outputs
argument_list|,
name|createDbDesc
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
name|rootTasks
operator|.
name|add
argument_list|(
name|dbRootTask
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|dirsInDbPath
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|dir
operator|.
name|getPath
argument_list|()
argument_list|,
name|EximUtil
operator|.
name|getDirectoryFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|tableDir
range|:
name|Collections2
operator|.
name|filter
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|dirsInDbPath
argument_list|)
argument_list|,
operator|new
name|TableDirPredicate
argument_list|()
argument_list|)
control|)
block|{
name|analyzeTableLoad
argument_list|(
name|dbName
argument_list|,
literal|null
argument_list|,
name|tableDir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|dbRootTask
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Analyzed table/view/partition load from path {}"
argument_list|,
name|tableDir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|//Function load
name|Path
name|functionMetaDataRoot
init|=
operator|new
name|Path
argument_list|(
name|dir
operator|.
name|getPath
argument_list|()
argument_list|,
name|FUNCTIONS_ROOT_DIR_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|functionMetaDataRoot
argument_list|)
condition|)
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|functionDirectories
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|fs
operator|.
name|listStatus
argument_list|(
name|functionMetaDataRoot
argument_list|,
name|EximUtil
operator|.
name|getDirectoryFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|functionDir
range|:
name|functionDirectories
control|)
block|{
name|analyzeFunctionLoad
argument_list|(
name|dbName
argument_list|,
name|functionDir
argument_list|,
name|dbRootTask
argument_list|)
expr_stmt|;
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Analyzed function load from path {}"
argument_list|,
name|functionDir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|REPL_STATE_LOG
operator|.
name|info
argument_list|(
literal|"Repl Load: Completed analyzing Repl Load for DB: {} and created import (DDL/COPY/MOVE) tasks"
argument_list|,
name|dbName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
class|class
name|TableDirPredicate
implements|implements
name|Predicate
argument_list|<
name|FileStatus
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
name|FileStatus
name|fileStatus
parameter_list|)
block|{
return|return
operator|!
name|fileStatus
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|contains
argument_list|(
name|FUNCTIONS_ROOT_DIR_NAME
argument_list|)
return|;
block|}
block|}
specifier|private
name|void
name|analyzeFunctionLoad
parameter_list|(
name|String
name|dbName
parameter_list|,
name|FileStatus
name|functionDir
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|createDbTask
parameter_list|)
throws|throws
name|IOException
throws|,
name|SemanticException
block|{
name|URI
name|fromURI
init|=
name|EximUtil
operator|.
name|getValidatedURI
argument_list|(
name|conf
argument_list|,
name|stripQuotes
argument_list|(
name|functionDir
operator|.
name|getPath
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|Path
name|fromPath
init|=
operator|new
name|Path
argument_list|(
name|fromURI
operator|.
name|getScheme
argument_list|()
argument_list|,
name|fromURI
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|fromURI
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|CreateFunctionHandler
name|handler
init|=
operator|new
name|CreateFunctionHandler
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|tasksList
init|=
name|handler
operator|.
name|handle
argument_list|(
operator|new
name|MessageHandler
operator|.
name|Context
argument_list|(
name|dbName
argument_list|,
literal|null
argument_list|,
name|fromPath
operator|.
name|toString
argument_list|()
argument_list|,
name|createDbTask
argument_list|,
literal|null
argument_list|,
name|conf
argument_list|,
name|db
argument_list|,
literal|null
argument_list|,
name|LOG
argument_list|)
argument_list|)
decl_stmt|;
name|tasksList
operator|.
name|forEach
argument_list|(
name|task
lambda|->
block|{
name|createDbTask
operator|.
name|addDependentTask
argument_list|(
name|task
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Added {}:{} as a precursor of {}:{}"
argument_list|,
name|createDbTask
operator|.
name|getClass
argument_list|()
argument_list|,
name|createDbTask
operator|.
name|getId
argument_list|()
argument_list|,
name|task
operator|.
name|getClass
argument_list|()
argument_list|,
name|task
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
name|inputs
operator|.
name|addAll
argument_list|(
name|handler
operator|.
name|readEntities
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|ErrorMsg
operator|.
name|INVALID_PATH
operator|.
name|getMsg
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|analyzeTableLoad
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|locn
parameter_list|,
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|precursor
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|dbsUpdated
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|tablesUpdated
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// Path being passed to us is a table dump location. We go ahead and load it in as needed.
comment|// If tblName is null, then we default to the table name specified in _metadata, which is good.
comment|// or are both specified, in which case, that's what we are intended to create the new table as.
if|if
condition|(
name|dbName
operator|==
literal|null
operator|||
name|dbName
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
literal|"Database name cannot be null for a table load"
argument_list|)
throw|;
block|}
try|try
block|{
comment|// no location set on repl loads
name|boolean
name|isLocationSet
init|=
literal|false
decl_stmt|;
comment|// all repl imports are non-external
name|boolean
name|isExternalSet
init|=
literal|false
decl_stmt|;
comment|// bootstrap loads are not partition level
name|boolean
name|isPartSpecSet
init|=
literal|false
decl_stmt|;
comment|// repl loads are not partition level
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parsedPartSpec
init|=
literal|null
decl_stmt|;
comment|// no location for repl imports
name|String
name|parsedLocation
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
name|importTasks
init|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|EximUtil
operator|.
name|SemanticAnalyzerWrapperContext
name|x
init|=
operator|new
name|EximUtil
operator|.
name|SemanticAnalyzerWrapperContext
argument_list|(
name|conf
argument_list|,
name|db
argument_list|,
name|inputs
argument_list|,
name|outputs
argument_list|,
name|importTasks
argument_list|,
name|LOG
argument_list|,
name|ctx
argument_list|)
decl_stmt|;
name|ImportSemanticAnalyzer
operator|.
name|prepareImport
argument_list|(
name|isLocationSet
argument_list|,
name|isExternalSet
argument_list|,
name|isPartSpecSet
argument_list|,
operator|(
name|precursor
operator|!=
literal|null
operator|)
argument_list|,
name|parsedLocation
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|,
name|parsedPartSpec
argument_list|,
name|locn
argument_list|,
name|x
argument_list|,
name|dbsUpdated
argument_list|,
name|tablesUpdated
argument_list|)
expr_stmt|;
if|if
condition|(
name|precursor
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Task
argument_list|<
name|?
extends|extends
name|Serializable
argument_list|>
name|t
range|:
name|importTasks
control|)
block|{
name|precursor
operator|.
name|addDependentTask
argument_list|(
name|t
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Added {}:{} as a precursor of {}:{}"
argument_list|,
name|precursor
operator|.
name|getClass
argument_list|()
argument_list|,
name|precursor
operator|.
name|getId
argument_list|()
argument_list|,
name|t
operator|.
name|getClass
argument_list|()
argument_list|,
name|t
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|importTasks
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// REPL STATUS
specifier|private
name|void
name|initReplStatus
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
block|{
name|int
name|numChildren
init|=
name|ast
operator|.
name|getChildCount
argument_list|()
decl_stmt|;
name|dbNameOrPattern
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
literal|0
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|numChildren
operator|>
literal|1
condition|)
block|{
name|tblNameOrPattern
operator|=
name|PlanUtils
operator|.
name|stripQuotes
argument_list|(
name|ast
operator|.
name|getChild
argument_list|(
literal|1
argument_list|)
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|analyzeReplStatus
parameter_list|(
name|ASTNode
name|ast
parameter_list|)
throws|throws
name|SemanticException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer.analyzeReplStatus: "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|dbNameOrPattern
argument_list|)
operator|+
literal|"."
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|tblNameOrPattern
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|replLastId
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|tblNameOrPattern
operator|!=
literal|null
condition|)
block|{
comment|// Checking for status of table
name|Table
name|tbl
init|=
name|db
operator|.
name|getTable
argument_list|(
name|dbNameOrPattern
argument_list|,
name|tblNameOrPattern
argument_list|)
decl_stmt|;
if|if
condition|(
name|tbl
operator|!=
literal|null
condition|)
block|{
name|inputs
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|tbl
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|tbl
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|!=
literal|null
operator|&&
operator|(
name|params
operator|.
name|containsKey
argument_list|(
name|ReplicationSpec
operator|.
name|KEY
operator|.
name|CURR_STATE_ID
operator|.
name|toString
argument_list|()
argument_list|)
operator|)
condition|)
block|{
name|replLastId
operator|=
name|params
operator|.
name|get
argument_list|(
name|ReplicationSpec
operator|.
name|KEY
operator|.
name|CURR_STATE_ID
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// Checking for status of a db
name|Database
name|database
init|=
name|db
operator|.
name|getDatabase
argument_list|(
name|dbNameOrPattern
argument_list|)
decl_stmt|;
if|if
condition|(
name|database
operator|!=
literal|null
condition|)
block|{
name|inputs
operator|.
name|add
argument_list|(
operator|new
name|ReadEntity
argument_list|(
name|database
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|database
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|!=
literal|null
operator|&&
operator|(
name|params
operator|.
name|containsKey
argument_list|(
name|ReplicationSpec
operator|.
name|KEY
operator|.
name|CURR_STATE_ID
operator|.
name|toString
argument_list|()
argument_list|)
operator|)
condition|)
block|{
name|replLastId
operator|=
name|params
operator|.
name|get
argument_list|(
name|ReplicationSpec
operator|.
name|KEY
operator|.
name|CURR_STATE_ID
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SemanticException
argument_list|(
name|e
argument_list|)
throw|;
comment|// TODO : simple wrap& rethrow for now, clean up with error
comment|// codes
block|}
name|prepareReturnValues
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|replLastId
argument_list|)
argument_list|,
literal|"last_repl_id#string"
argument_list|)
expr_stmt|;
name|setFetchTask
argument_list|(
name|createFetchTask
argument_list|(
literal|"last_repl_id#string"
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"ReplicationSemanticAnalyzer.analyzeReplStatus: writing repl.last.id={} out to {}"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|replLastId
argument_list|)
argument_list|,
name|ctx
operator|.
name|getResFile
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|prepareReturnValues
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|values
parameter_list|,
name|String
name|schema
parameter_list|)
throws|throws
name|SemanticException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"prepareReturnValues : "
operator|+
name|schema
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|values
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"> "
operator|+
name|s
argument_list|)
expr_stmt|;
block|}
name|ctx
operator|.
name|setResFile
argument_list|(
name|ctx
operator|.
name|getLocalTmpPath
argument_list|()
argument_list|)
expr_stmt|;
name|Utils
operator|.
name|writeOutput
argument_list|(
name|values
argument_list|,
name|ctx
operator|.
name|getResFile
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

