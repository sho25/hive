begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|spark
operator|.
name|session
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|HiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_comment
comment|/**  * Simple implementation of<i>SparkSessionManager</i>  *   - returns SparkSession when requested through<i>getSession</i> and keeps track of  *       created sessions. Currently no limit on the number sessions.  *   - SparkSession is reused if the userName in new conf and user name in session conf match.  */
end_comment

begin_class
specifier|public
class|class
name|SparkSessionManagerImpl
implements|implements
name|SparkSessionManager
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SparkSessionManagerImpl
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|Set
argument_list|<
name|SparkSession
argument_list|>
name|createdSessions
decl_stmt|;
specifier|private
name|boolean
name|inited
decl_stmt|;
specifier|private
specifier|static
name|SparkSessionManagerImpl
name|instance
decl_stmt|;
static|static
block|{
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|addShutdownHook
argument_list|(
operator|new
name|Thread
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
if|if
condition|(
name|instance
operator|!=
literal|null
condition|)
block|{
name|instance
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// ignore
block|}
block|}
block|}
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|synchronized
specifier|static
name|SparkSessionManagerImpl
name|getInstance
parameter_list|()
throws|throws
name|HiveException
block|{
if|if
condition|(
name|instance
operator|==
literal|null
condition|)
block|{
name|instance
operator|=
operator|new
name|SparkSessionManagerImpl
argument_list|()
expr_stmt|;
block|}
return|return
name|instance
return|;
block|}
specifier|private
name|SparkSessionManagerImpl
parameter_list|()
block|{   }
annotation|@
name|Override
specifier|public
name|void
name|setup
parameter_list|(
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|HiveException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting up the session manager."
argument_list|)
expr_stmt|;
name|init
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|init
parameter_list|()
block|{
name|createdSessions
operator|=
name|Collections
operator|.
name|synchronizedSet
argument_list|(
operator|new
name|HashSet
argument_list|<
name|SparkSession
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|inited
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * If the<i>existingSession</i> can be reused return it.    * Otherwise    *   - close it and remove it from the list.    *   - create a new session and add it to the list.    */
annotation|@
name|Override
specifier|public
name|SparkSession
name|getSession
parameter_list|(
name|SparkSession
name|existingSession
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|doOpen
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|inited
condition|)
block|{
name|init
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|existingSession
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|canReuseSession
argument_list|(
name|existingSession
argument_list|,
name|conf
argument_list|)
condition|)
block|{
comment|// Open the session if it is closed.
if|if
condition|(
operator|!
name|existingSession
operator|.
name|isOpen
argument_list|()
operator|&&
name|doOpen
condition|)
block|{
name|existingSession
operator|.
name|open
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
name|Preconditions
operator|.
name|checkState
argument_list|(
name|createdSessions
operator|.
name|contains
argument_list|(
name|existingSession
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Existing session (%s) is reused."
argument_list|,
name|existingSession
operator|.
name|getSessionId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|existingSession
return|;
block|}
else|else
block|{
comment|// Close the session, as the client is holding onto a session that can't be used
comment|// by the client anymore.
name|closeSession
argument_list|(
name|existingSession
argument_list|)
expr_stmt|;
block|}
block|}
name|SparkSession
name|sparkSession
init|=
operator|new
name|SparkSessionImpl
argument_list|()
decl_stmt|;
name|createdSessions
operator|.
name|add
argument_list|(
name|sparkSession
argument_list|)
expr_stmt|;
if|if
condition|(
name|doOpen
condition|)
block|{
name|sparkSession
operator|.
name|open
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"New session (%s) is created."
argument_list|,
name|sparkSession
operator|.
name|getSessionId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|sparkSession
return|;
block|}
comment|/**    * Currently we only match the userNames in existingSession conf and given conf.    */
specifier|private
name|boolean
name|canReuseSession
parameter_list|(
name|SparkSession
name|existingSession
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|UserGroupInformation
name|newUgi
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getUGIForConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|String
name|newUserName
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getShortUserName
argument_list|(
name|newUgi
argument_list|)
decl_stmt|;
name|UserGroupInformation
name|ugiInSession
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getUGIForConf
argument_list|(
name|existingSession
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|userNameInSession
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getShortUserName
argument_list|(
name|ugiInSession
argument_list|)
decl_stmt|;
return|return
name|newUserName
operator|.
name|equals
argument_list|(
name|userNameInSession
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Failed to get user info from HiveConf."
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|returnSession
parameter_list|(
name|SparkSession
name|sparkSession
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// In this particular SparkSessionManager implementation, we don't recycle
comment|// returned sessions. References to session are still valid.
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeSession
parameter_list|(
name|SparkSession
name|sparkSession
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|sparkSession
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Closing session (%s)."
argument_list|,
name|sparkSession
operator|.
name|getSessionId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|sparkSession
operator|.
name|close
argument_list|()
expr_stmt|;
name|createdSessions
operator|.
name|remove
argument_list|(
name|sparkSession
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|shutdown
parameter_list|()
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing the session manager."
argument_list|)
expr_stmt|;
if|if
condition|(
name|createdSessions
operator|!=
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|createdSessions
init|)
block|{
name|Iterator
argument_list|<
name|SparkSession
argument_list|>
name|it
init|=
name|createdSessions
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|it
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|SparkSession
name|session
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|session
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|createdSessions
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
name|inited
operator|=
literal|false
expr_stmt|;
block|}
block|}
end_class

end_unit

