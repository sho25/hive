begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Splitter
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableMap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|Constants
operator|.
name|MATERIALIZED_VIEW_REWRITING_TIME_WINDOW
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_STORAGE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|MetaStoreUtils
operator|.
name|getDefaultCatalog
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|DDLSemanticAnalyzer
operator|.
name|makeBinaryPredicate
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_FORMAT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|jdo
operator|.
name|JDODataStoreException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|plan
operator|.
name|RelOptMaterialization
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|plan
operator|.
name|hep
operator|.
name|HepPlanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|plan
operator|.
name|hep
operator|.
name|HepProgramBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|rel
operator|.
name|RelNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|rel
operator|.
name|RelVisitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|rel
operator|.
name|core
operator|.
name|Project
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|rel
operator|.
name|core
operator|.
name|TableScan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|calcite
operator|.
name|rex
operator|.
name|RexBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FilenameUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileChecksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Options
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsAction
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DistributedFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|classification
operator|.
name|InterfaceAudience
operator|.
name|LimitedPrivate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|classification
operator|.
name|InterfaceStability
operator|.
name|Unstable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|log
operator|.
name|InPlaceUpdate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|io
operator|.
name|HdfsUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaHookLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|IMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|PartitionDropOptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|RawStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|RetryingMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|SynchronizedMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ReplChangeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|MetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|ErrorMsg
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|AbstractFileMergeOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FunctionRegistry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FunctionTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FunctionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|SerializationUtilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|AcidUtils
operator|.
name|TableSnapshot
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|DbTxnManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lockmgr
operator|.
name|LockException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|log
operator|.
name|PerfLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|calcite
operator|.
name|RelOptHiveTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|calcite
operator|.
name|rules
operator|.
name|views
operator|.
name|HiveAugmentMaterializationRule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|listbucketingpruner
operator|.
name|ListBucketingPrunerUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|AddPartitionDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|DropTableDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeColumnDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeConstantDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeGenericFuncDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|LoadTableDesc
operator|.
name|LoadFileType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|CreateTableAutomaticGrant
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|PrimitiveTypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|TxnIdUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * This class has functions that implement meta data/DDL operations using calls  * to the metastore.  * It has a metastore client instance it uses to communicate with the metastore.  *  * It is a thread local variable, and the instances is accessed using static  * get methods in this class.  */
end_comment

begin_class
annotation|@
name|SuppressWarnings
argument_list|(
block|{
literal|"deprecation"
block|,
literal|"rawtypes"
block|}
argument_list|)
specifier|public
class|class
name|Hive
block|{
specifier|static
specifier|final
specifier|private
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"hive.ql.metadata.Hive"
argument_list|)
decl_stmt|;
specifier|private
name|HiveConf
name|conf
init|=
literal|null
decl_stmt|;
specifier|private
name|IMetaStoreClient
name|metaStoreClient
decl_stmt|;
specifier|private
name|SynchronizedMetaStoreClient
name|syncMetaStoreClient
decl_stmt|;
specifier|private
name|UserGroupInformation
name|owner
decl_stmt|;
comment|// metastore calls timing information
specifier|private
specifier|final
name|ConcurrentHashMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|metaCallTimeMap
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|static
name|ThreadLocal
argument_list|<
name|Hive
argument_list|>
name|hiveDB
init|=
operator|new
name|ThreadLocal
argument_list|<
name|Hive
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|Hive
name|initialValue
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|remove
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|get
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|get
argument_list|()
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|super
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
decl_stmt|;
comment|// Note that while this is an improvement over static initialization, it is still not,
comment|// technically, valid, cause nothing prevents us from connecting to several metastores in
comment|// the same process. This will still only get the functions from the first metastore.
specifier|private
specifier|final
specifier|static
name|AtomicInteger
name|didRegisterAllFuncs
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|int
name|REG_FUNCS_NO
init|=
literal|0
decl_stmt|,
name|REG_FUNCS_DONE
init|=
literal|2
decl_stmt|,
name|REG_FUNCS_PENDING
init|=
literal|1
decl_stmt|;
comment|// register all permanent functions. need improvement
specifier|private
name|void
name|registerAllFunctionsOnce
parameter_list|()
throws|throws
name|HiveException
block|{
name|boolean
name|breakLoop
init|=
literal|false
decl_stmt|;
while|while
condition|(
operator|!
name|breakLoop
condition|)
block|{
name|int
name|val
init|=
name|didRegisterAllFuncs
operator|.
name|get
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|val
condition|)
block|{
case|case
name|REG_FUNCS_NO
case|:
block|{
if|if
condition|(
name|didRegisterAllFuncs
operator|.
name|compareAndSet
argument_list|(
name|val
argument_list|,
name|REG_FUNCS_PENDING
argument_list|)
condition|)
block|{
name|breakLoop
operator|=
literal|true
expr_stmt|;
break|break;
block|}
continue|continue;
block|}
case|case
name|REG_FUNCS_PENDING
case|:
block|{
synchronized|synchronized
init|(
name|didRegisterAllFuncs
init|)
block|{
try|try
block|{
name|didRegisterAllFuncs
operator|.
name|wait
argument_list|(
literal|100
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
return|return;
block|}
block|}
continue|continue;
block|}
case|case
name|REG_FUNCS_DONE
case|:
return|return;
default|default:
throw|throw
operator|new
name|AssertionError
argument_list|(
name|val
argument_list|)
throw|;
block|}
block|}
try|try
block|{
name|reloadFunctions
argument_list|()
expr_stmt|;
name|didRegisterAllFuncs
operator|.
name|compareAndSet
argument_list|(
name|REG_FUNCS_PENDING
argument_list|,
name|REG_FUNCS_DONE
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to register all functions."
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|didRegisterAllFuncs
operator|.
name|compareAndSet
argument_list|(
name|REG_FUNCS_PENDING
argument_list|,
name|REG_FUNCS_NO
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|didRegisterAllFuncs
init|)
block|{
name|didRegisterAllFuncs
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|void
name|reloadFunctions
parameter_list|()
throws|throws
name|HiveException
block|{
name|HashSet
argument_list|<
name|String
argument_list|>
name|registryFunctions
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|FunctionRegistry
operator|.
name|getFunctionNames
argument_list|(
literal|".+\\..+"
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Function
name|function
range|:
name|getAllFunctions
argument_list|()
control|)
block|{
name|String
name|functionName
init|=
name|function
operator|.
name|getFunctionName
argument_list|()
decl_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Registering function "
operator|+
name|functionName
operator|+
literal|" "
operator|+
name|function
operator|.
name|getClassName
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|qualFunc
init|=
name|FunctionUtils
operator|.
name|qualifyFunctionName
argument_list|(
name|functionName
argument_list|,
name|function
operator|.
name|getDbName
argument_list|()
argument_list|)
decl_stmt|;
name|FunctionRegistry
operator|.
name|registerPermanentFunction
argument_list|(
name|qualFunc
argument_list|,
name|function
operator|.
name|getClassName
argument_list|()
argument_list|,
literal|false
argument_list|,
name|FunctionTask
operator|.
name|toFunctionResource
argument_list|(
name|function
operator|.
name|getResourceUris
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|registryFunctions
operator|.
name|remove
argument_list|(
name|qualFunc
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to register persistent function "
operator|+
name|functionName
operator|+
literal|":"
operator|+
name|function
operator|.
name|getClassName
argument_list|()
operator|+
literal|". Ignore and continue."
argument_list|)
expr_stmt|;
block|}
block|}
comment|// unregister functions from local system registry that are not in getAllFunctions()
for|for
control|(
name|String
name|functionName
range|:
name|registryFunctions
control|)
block|{
try|try
block|{
name|FunctionRegistry
operator|.
name|unregisterPermanentFunction
argument_list|(
name|functionName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to unregister persistent function "
operator|+
name|functionName
operator|+
literal|"on reload. Ignore and continue."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
specifier|static
name|Hive
name|get
parameter_list|(
name|Configuration
name|c
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|get
argument_list|(
name|c
operator|instanceof
name|HiveConf
condition|?
operator|(
name|HiveConf
operator|)
name|c
else|:
operator|new
name|HiveConf
argument_list|(
name|c
argument_list|,
name|clazz
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Gets hive object for the current thread. If one is not initialized then a    * new one is created If the new configuration is different in metadata conf    * vars, or the owner will be different then a new one is created.    *    * @param c    *          new Hive Configuration    * @return Hive object for current thread    * @throws HiveException    *    */
specifier|public
specifier|static
name|Hive
name|get
parameter_list|(
name|HiveConf
name|c
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getInternal
argument_list|(
name|c
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Same as {@link #get(HiveConf)}, except that it checks only the object identity of existing    * MS client, assuming the relevant settings would be unchanged within the same conf object.    */
specifier|public
specifier|static
name|Hive
name|getWithFastCheck
parameter_list|(
name|HiveConf
name|c
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getWithFastCheck
argument_list|(
name|c
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Same as {@link #get(HiveConf)}, except that it checks only the object identity of existing    * MS client, assuming the relevant settings would be unchanged within the same conf object.    */
specifier|public
specifier|static
name|Hive
name|getWithFastCheck
parameter_list|(
name|HiveConf
name|c
parameter_list|,
name|boolean
name|doRegisterAllFns
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getInternal
argument_list|(
name|c
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|doRegisterAllFns
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|Hive
name|getInternal
parameter_list|(
name|HiveConf
name|c
parameter_list|,
name|boolean
name|needsRefresh
parameter_list|,
name|boolean
name|isFastCheck
parameter_list|,
name|boolean
name|doRegisterAllFns
parameter_list|)
throws|throws
name|HiveException
block|{
name|Hive
name|db
init|=
name|hiveDB
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|db
operator|==
literal|null
operator|||
operator|!
name|db
operator|.
name|isCurrentUserOwner
argument_list|()
operator|||
name|needsRefresh
operator|||
operator|(
name|c
operator|!=
literal|null
operator|&&
operator|!
name|isCompatible
argument_list|(
name|db
argument_list|,
name|c
argument_list|,
name|isFastCheck
argument_list|)
operator|)
condition|)
block|{
name|db
operator|=
name|create
argument_list|(
name|c
argument_list|,
literal|false
argument_list|,
name|db
argument_list|,
name|doRegisterAllFns
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|c
operator|!=
literal|null
condition|)
block|{
name|db
operator|.
name|conf
operator|=
name|c
expr_stmt|;
block|}
return|return
name|db
return|;
block|}
specifier|private
specifier|static
name|Hive
name|create
parameter_list|(
name|HiveConf
name|c
parameter_list|,
name|boolean
name|needsRefresh
parameter_list|,
name|Hive
name|db
parameter_list|,
name|boolean
name|doRegisterAllFns
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|db
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating new db. db = "
operator|+
name|db
operator|+
literal|", needsRefresh = "
operator|+
name|needsRefresh
operator|+
literal|", db.isCurrentUserOwner = "
operator|+
name|db
operator|.
name|isCurrentUserOwner
argument_list|()
argument_list|)
expr_stmt|;
name|db
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|closeCurrent
argument_list|()
expr_stmt|;
if|if
condition|(
name|c
operator|==
literal|null
condition|)
block|{
name|c
operator|=
name|createHiveConf
argument_list|()
expr_stmt|;
block|}
name|c
operator|.
name|set
argument_list|(
literal|"fs.scheme.class"
argument_list|,
literal|"dfs"
argument_list|)
expr_stmt|;
name|Hive
name|newdb
init|=
operator|new
name|Hive
argument_list|(
name|c
argument_list|,
name|doRegisterAllFns
argument_list|)
decl_stmt|;
name|hiveDB
operator|.
name|set
argument_list|(
name|newdb
argument_list|)
expr_stmt|;
return|return
name|newdb
return|;
block|}
specifier|private
specifier|static
name|HiveConf
name|createHiveConf
parameter_list|()
block|{
name|SessionState
name|session
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
return|return
operator|(
name|session
operator|==
literal|null
operator|)
condition|?
operator|new
name|HiveConf
argument_list|(
name|Hive
operator|.
name|class
argument_list|)
else|:
name|session
operator|.
name|getConf
argument_list|()
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isCompatible
parameter_list|(
name|Hive
name|db
parameter_list|,
name|HiveConf
name|c
parameter_list|,
name|boolean
name|isFastCheck
parameter_list|)
block|{
if|if
condition|(
name|isFastCheck
condition|)
block|{
return|return
operator|(
name|db
operator|.
name|metaStoreClient
operator|==
literal|null
operator|||
name|db
operator|.
name|metaStoreClient
operator|.
name|isSameConfObj
argument_list|(
name|c
argument_list|)
operator|)
operator|&&
operator|(
name|db
operator|.
name|syncMetaStoreClient
operator|==
literal|null
operator|||
name|db
operator|.
name|syncMetaStoreClient
operator|.
name|isSameConfObj
argument_list|(
name|c
argument_list|)
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
name|db
operator|.
name|metaStoreClient
operator|==
literal|null
operator|||
name|db
operator|.
name|metaStoreClient
operator|.
name|isCompatibleWith
argument_list|(
name|c
argument_list|)
operator|)
operator|&&
operator|(
name|db
operator|.
name|syncMetaStoreClient
operator|==
literal|null
operator|||
name|db
operator|.
name|syncMetaStoreClient
operator|.
name|isCompatibleWith
argument_list|(
name|c
argument_list|)
operator|)
return|;
block|}
block|}
specifier|public
specifier|static
name|Hive
name|get
parameter_list|()
throws|throws
name|HiveException
block|{
return|return
name|get
argument_list|(
literal|true
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Hive
name|get
parameter_list|(
name|boolean
name|doRegisterAllFns
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getInternal
argument_list|(
literal|null
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
name|doRegisterAllFns
argument_list|)
return|;
block|}
comment|/**    * get a connection to metastore. see get(HiveConf) function for comments    *    * @param c    *          new conf    * @param needsRefresh    *          if true then creates a new one    * @return The connection to the metastore    * @throws HiveException    */
specifier|public
specifier|static
name|Hive
name|get
parameter_list|(
name|HiveConf
name|c
parameter_list|,
name|boolean
name|needsRefresh
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getInternal
argument_list|(
name|c
argument_list|,
name|needsRefresh
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|set
parameter_list|(
name|Hive
name|hive
parameter_list|)
block|{
name|hiveDB
operator|.
name|set
argument_list|(
name|hive
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|closeCurrent
parameter_list|()
block|{
name|hiveDB
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
comment|/**    * Hive    *    * @param c    *    */
specifier|private
name|Hive
parameter_list|(
name|HiveConf
name|c
parameter_list|,
name|boolean
name|doRegisterAllFns
parameter_list|)
throws|throws
name|HiveException
block|{
name|conf
operator|=
name|c
expr_stmt|;
if|if
condition|(
name|doRegisterAllFns
condition|)
block|{
name|registerAllFunctionsOnce
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|boolean
name|isCurrentUserOwner
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|owner
operator|==
literal|null
operator|||
name|owner
operator|.
name|equals
argument_list|(
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error getting current user: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * closes the connection to metastore for the calling thread    */
specifier|private
name|void
name|close
parameter_list|()
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing current thread's connection to Hive Metastore."
argument_list|)
expr_stmt|;
if|if
condition|(
name|metaStoreClient
operator|!=
literal|null
condition|)
block|{
name|metaStoreClient
operator|.
name|close
argument_list|()
expr_stmt|;
name|metaStoreClient
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|syncMetaStoreClient
operator|!=
literal|null
condition|)
block|{
name|syncMetaStoreClient
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|owner
operator|!=
literal|null
condition|)
block|{
name|owner
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Create a database    * @param db    * @param ifNotExist if true, will ignore AlreadyExistsException exception    * @throws AlreadyExistsException    * @throws HiveException    */
specifier|public
name|void
name|createDatabase
parameter_list|(
name|Database
name|db
parameter_list|,
name|boolean
name|ifNotExist
parameter_list|)
throws|throws
name|AlreadyExistsException
throws|,
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createDatabase
argument_list|(
name|db
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ifNotExist
condition|)
block|{
throw|throw
name|e
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create a Database. Raise an error if a database with the same name already exists.    * @param db    * @throws AlreadyExistsException    * @throws HiveException    */
specifier|public
name|void
name|createDatabase
parameter_list|(
name|Database
name|db
parameter_list|)
throws|throws
name|AlreadyExistsException
throws|,
name|HiveException
block|{
name|createDatabase
argument_list|(
name|db
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drop a database.    * @param name    * @throws NoSuchObjectException    * @throws HiveException    * @see org.apache.hadoop.hive.metastore.HiveMetaStoreClient#dropDatabase(java.lang.String)    */
specifier|public
name|void
name|dropDatabase
parameter_list|(
name|String
name|name
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
name|dropDatabase
argument_list|(
name|name
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drop a database    * @param name    * @param deleteData    * @param ignoreUnknownDb if true, will ignore NoSuchObjectException    * @throws HiveException    * @throws NoSuchObjectException    */
specifier|public
name|void
name|dropDatabase
parameter_list|(
name|String
name|name
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownDb
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
name|dropDatabase
argument_list|(
name|name
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownDb
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drop a database    * @param name    * @param deleteData    * @param ignoreUnknownDb if true, will ignore NoSuchObjectException    * @param cascade         if true, delete all tables on the DB if exists. Otherwise, the query    *                        will fail if table still exists.    * @throws HiveException    * @throws NoSuchObjectException    */
specifier|public
name|void
name|dropDatabase
parameter_list|(
name|String
name|name
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownDb
parameter_list|,
name|boolean
name|cascade
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropDatabase
argument_list|(
name|name
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownDb
argument_list|,
name|cascade
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Creates a table metadata and the directory for the table data    *    * @param tableName    *          name of the table    * @param columns    *          list of fields of the table    * @param partCols    *          partition keys of the table    * @param fileInputFormat    *          Class of the input format of the table data file    * @param fileOutputFormat    *          Class of the output format of the table data file    * @throws HiveException    *           thrown if the args are invalid or if the metadata or the data    *           directory couldn't be created    */
specifier|public
name|void
name|createTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|fileInputFormat
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|fileOutputFormat
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
operator|.
name|createTable
argument_list|(
name|tableName
argument_list|,
name|columns
argument_list|,
name|partCols
argument_list|,
name|fileInputFormat
argument_list|,
name|fileOutputFormat
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates a table metadata and the directory for the table data    *    * @param tableName    *          name of the table    * @param columns    *          list of fields of the table    * @param partCols    *          partition keys of the table    * @param fileInputFormat    *          Class of the input format of the table data file    * @param fileOutputFormat    *          Class of the output format of the table data file    * @param bucketCount    *          number of buckets that each partition (or the table itself) should    *          be divided into    * @throws HiveException    *           thrown if the args are invalid or if the metadata or the data    *           directory couldn't be created    */
specifier|public
name|void
name|createTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|fileInputFormat
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|fileOutputFormat
parameter_list|,
name|int
name|bucketCount
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
parameter_list|)
throws|throws
name|HiveException
block|{
name|createTable
argument_list|(
name|tableName
argument_list|,
name|columns
argument_list|,
name|partCols
argument_list|,
name|fileInputFormat
argument_list|,
name|fileOutputFormat
argument_list|,
name|bucketCount
argument_list|,
name|bucketCols
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a table metadata and the directory for the table data    * @param tableName table name    * @param columns list of fields of the table    * @param partCols partition keys of the table    * @param fileInputFormat Class of the input format of the table data file    * @param fileOutputFormat Class of the output format of the table data file    * @param bucketCount number of buckets that each partition (or the table itself) should be    *                    divided into    * @param bucketCols Bucket columns    * @param parameters Parameters for the table    * @throws HiveException    */
specifier|public
name|void
name|createTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|fileInputFormat
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|fileOutputFormat
parameter_list|,
name|int
name|bucketCount
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|columns
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"columns not specified for table "
operator|+
name|tableName
argument_list|)
throw|;
block|}
name|Table
name|tbl
init|=
name|newTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|tbl
operator|.
name|setInputFormatClass
argument_list|(
name|fileInputFormat
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setOutputFormatClass
argument_list|(
name|fileOutputFormat
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|col
range|:
name|columns
control|)
block|{
name|FieldSchema
name|field
init|=
operator|new
name|FieldSchema
argument_list|(
name|col
argument_list|,
name|STRING_TYPE_NAME
argument_list|,
literal|"default"
argument_list|)
decl_stmt|;
name|tbl
operator|.
name|getCols
argument_list|()
operator|.
name|add
argument_list|(
name|field
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|partCols
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|partCol
range|:
name|partCols
control|)
block|{
name|FieldSchema
name|part
init|=
operator|new
name|FieldSchema
argument_list|()
decl_stmt|;
name|part
operator|.
name|setName
argument_list|(
name|partCol
argument_list|)
expr_stmt|;
name|part
operator|.
name|setType
argument_list|(
name|STRING_TYPE_NAME
argument_list|)
expr_stmt|;
comment|// default partition key
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
block|}
block|}
name|tbl
operator|.
name|setSerializationLib
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setNumBuckets
argument_list|(
name|bucketCount
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setBucketCols
argument_list|(
name|bucketCols
argument_list|)
expr_stmt|;
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
name|tbl
operator|.
name|setParameters
argument_list|(
name|parameters
argument_list|)
expr_stmt|;
block|}
name|createTable
argument_list|(
name|tbl
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|alterTable
parameter_list|(
name|Table
name|newTbl
parameter_list|,
name|boolean
name|cascade
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|HiveException
block|{
name|alterTable
argument_list|(
name|newTbl
operator|.
name|getCatName
argument_list|()
argument_list|,
name|newTbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|newTbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|newTbl
argument_list|,
name|cascade
argument_list|,
name|environmentContext
argument_list|,
name|transactional
argument_list|)
expr_stmt|;
block|}
comment|/**    * Updates the existing table metadata with the new metadata.    *    * @param fullyQlfdTblName    *          name of the existing table    * @param newTbl    *          new name of the table. could be the old name    * @param transactional    *          Need to generate and save a table snapshot into the metastore?    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterTable
parameter_list|(
name|String
name|fullyQlfdTblName
parameter_list|,
name|Table
name|newTbl
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|fullyQlfdTblName
argument_list|)
decl_stmt|;
name|alterTable
argument_list|(
literal|null
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|newTbl
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|,
name|transactional
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|alterTable
parameter_list|(
name|String
name|fullyQlfdTblName
parameter_list|,
name|Table
name|newTbl
parameter_list|,
name|boolean
name|cascade
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|fullyQlfdTblName
argument_list|)
decl_stmt|;
name|alterTable
argument_list|(
literal|null
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|newTbl
argument_list|,
name|cascade
argument_list|,
name|environmentContext
argument_list|,
name|transactional
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|alterTable
parameter_list|(
name|String
name|catName
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|Table
name|newTbl
parameter_list|,
name|boolean
name|cascade
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|catName
operator|==
literal|null
condition|)
block|{
name|catName
operator|=
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
try|try
block|{
comment|// Remove the DDL_TIME so it gets refreshed
if|if
condition|(
name|newTbl
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|newTbl
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|hive_metastoreConstants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|newTbl
operator|.
name|checkValidity
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|environmentContext
operator|==
literal|null
condition|)
block|{
name|environmentContext
operator|=
operator|new
name|EnvironmentContext
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|cascade
condition|)
block|{
name|environmentContext
operator|.
name|putToProperties
argument_list|(
name|StatsSetupConst
operator|.
name|CASCADE
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
comment|// Take a table snapshot and set it to newTbl.
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|transactional
condition|)
block|{
comment|// Make sure we pass in the names, so we can get the correct snapshot for rename table.
name|tableSnapshot
operator|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|newTbl
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|tableSnapshot
operator|!=
literal|null
condition|)
block|{
name|newTbl
operator|.
name|getTTable
argument_list|()
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot get a table snapshot for "
operator|+
name|tblName
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Why is alter_partitions synchronized while this isn't?
name|getMSC
argument_list|()
operator|.
name|alter_table
argument_list|(
name|catName
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|,
name|newTbl
operator|.
name|getTTable
argument_list|()
argument_list|,
name|environmentContext
argument_list|,
name|tableSnapshot
operator|==
literal|null
condition|?
operator|-
literal|1
else|:
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
argument_list|,
name|tableSnapshot
operator|==
literal|null
condition|?
literal|null
else|:
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter table. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter table. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|updateCreationMetadata
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|CreationMetadata
name|cm
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|updateCreationMetadata
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|cm
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to update creation metadata "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Updates the existing partition metadata with the new metadata.    *    * @param tblName    *          name of the existing table    * @param newPart    *          new partition    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterPartition
parameter_list|(
name|String
name|tblName
parameter_list|,
name|Partition
name|newPart
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
name|alterPartition
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|newPart
argument_list|,
name|environmentContext
argument_list|,
name|transactional
argument_list|)
expr_stmt|;
block|}
comment|/**    * Updates the existing partition metadata with the new metadata.    *    * @param dbName    *          name of the exiting table's database    * @param tblName    *          name of the existing table    * @param newPart    *          new partition    * @param environmentContext    *          environment context for the method    * @param transactional    *          indicates this call is for transaction stats    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterPartition
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|Partition
name|newPart
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
try|try
block|{
name|validatePartition
argument_list|(
name|newPart
argument_list|)
expr_stmt|;
name|String
name|location
init|=
name|newPart
operator|.
name|getLocation
argument_list|()
decl_stmt|;
if|if
condition|(
name|location
operator|!=
literal|null
condition|)
block|{
name|location
operator|=
name|Utilities
operator|.
name|getQualifiedPath
argument_list|(
name|conf
argument_list|,
operator|new
name|Path
argument_list|(
name|location
argument_list|)
argument_list|)
expr_stmt|;
name|newPart
operator|.
name|setLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|environmentContext
operator|==
literal|null
condition|)
block|{
name|environmentContext
operator|=
operator|new
name|EnvironmentContext
argument_list|()
expr_stmt|;
block|}
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|transactional
condition|)
block|{
name|tableSnapshot
operator|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|newPart
operator|.
name|getTable
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|tableSnapshot
operator|!=
literal|null
condition|)
block|{
name|newPart
operator|.
name|getTPartition
argument_list|()
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot get a table snapshot for "
operator|+
name|tblName
argument_list|)
expr_stmt|;
block|}
block|}
name|getSynchronizedMSC
argument_list|()
operator|.
name|alter_partition
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|newPart
operator|.
name|getTPartition
argument_list|()
argument_list|,
name|environmentContext
argument_list|,
name|tableSnapshot
operator|==
literal|null
condition|?
operator|-
literal|1
else|:
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
argument_list|,
name|tableSnapshot
operator|==
literal|null
condition|?
literal|null
else|:
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|validatePartition
parameter_list|(
name|Partition
name|newPart
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Remove the DDL time so that it gets refreshed
if|if
condition|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|newPart
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|hive_metastoreConstants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|newPart
operator|.
name|checkValidity
argument_list|()
expr_stmt|;
block|}
comment|/**    * Updates the existing table metadata with the new metadata.    *    * @param tblName    *          name of the existing table    * @param newParts    *          new partitions    * @param transactional    *          Need to generate and save a table snapshot into the metastore?    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterPartitions
parameter_list|(
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|Partition
argument_list|>
name|newParts
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|,
name|boolean
name|transactional
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|newTParts
init|=
operator|new
name|ArrayList
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|transactional
condition|)
block|{
name|tableSnapshot
operator|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|newParts
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getTable
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Remove the DDL time so that it gets refreshed
for|for
control|(
name|Partition
name|tmpPart
range|:
name|newParts
control|)
block|{
if|if
condition|(
name|tmpPart
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|tmpPart
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|hive_metastoreConstants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|String
name|location
init|=
name|tmpPart
operator|.
name|getLocation
argument_list|()
decl_stmt|;
if|if
condition|(
name|location
operator|!=
literal|null
condition|)
block|{
name|location
operator|=
name|Utilities
operator|.
name|getQualifiedPath
argument_list|(
name|conf
argument_list|,
operator|new
name|Path
argument_list|(
name|location
argument_list|)
argument_list|)
expr_stmt|;
name|tmpPart
operator|.
name|setLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
name|newTParts
operator|.
name|add
argument_list|(
name|tmpPart
operator|.
name|getTPartition
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|getMSC
argument_list|()
operator|.
name|alter_partitions
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|newTParts
argument_list|,
name|environmentContext
argument_list|,
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
else|:
operator|-
literal|1
argument_list|,
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
else|:
literal|null
argument_list|,
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
else|:
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Rename a old partition to new partition    *    * @param tbl    *          existing table    * @param oldPartSpec    *          spec of old partition    * @param newPart    *          new partition    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|renamePartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|oldPartSpec
parameter_list|,
name|Partition
name|newPart
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|newPartSpec
init|=
name|newPart
operator|.
name|getSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldPartSpec
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|size
argument_list|()
operator|||
name|newPartSpec
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition to the same name: number of partition cols don't match. "
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|oldPartSpec
operator|.
name|keySet
argument_list|()
operator|.
name|equals
argument_list|(
name|newPartSpec
operator|.
name|keySet
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition to the same name: old and new partition cols don't match. "
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|tbl
operator|.
name|getPartCols
argument_list|()
control|)
block|{
name|String
name|val
init|=
name|oldPartSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
name|val
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"get partition: Value for key "
operator|+
name|field
operator|.
name|getName
argument_list|()
operator|+
literal|" is null or empty"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
block|}
name|getMSC
argument_list|()
operator|.
name|renamePartition
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|,
name|newPart
operator|.
name|getTPartition
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|alterDatabase
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Database
name|db
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|alterDatabase
argument_list|(
name|dbName
argument_list|,
name|db
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter database "
operator|+
name|dbName
operator|+
literal|". "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Database "
operator|+
name|dbName
operator|+
literal|" does not exists."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter database "
operator|+
name|dbName
operator|+
literal|". "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Creates the table with the give objects    *    * @param tbl    *          a table object    * @throws HiveException    */
specifier|public
name|void
name|createTable
parameter_list|(
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
name|createTable
argument_list|(
name|tbl
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates the table with the given objects. It takes additional arguments for    * primary keys and foreign keys associated with the table.    *    * @param tbl    *          a table object    * @param ifNotExists    *          if true, ignore AlreadyExistsException    * @param primaryKeys    *          primary key columns associated with the table    * @param foreignKeys    *          foreign key columns associated with the table    * @param uniqueConstraints    *          UNIQUE constraints associated with the table    * @param notNullConstraints    *          NOT NULL constraints associated with the table    * @param defaultConstraints    *          DEFAULT constraints associated with the table    * @param checkConstraints    *          CHECK constraints associated with the table    * @throws HiveException    */
specifier|public
name|void
name|createTable
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|boolean
name|ifNotExists
parameter_list|,
name|List
argument_list|<
name|SQLPrimaryKey
argument_list|>
name|primaryKeys
parameter_list|,
name|List
argument_list|<
name|SQLForeignKey
argument_list|>
name|foreignKeys
parameter_list|,
name|List
argument_list|<
name|SQLUniqueConstraint
argument_list|>
name|uniqueConstraints
parameter_list|,
name|List
argument_list|<
name|SQLNotNullConstraint
argument_list|>
name|notNullConstraints
parameter_list|,
name|List
argument_list|<
name|SQLDefaultConstraint
argument_list|>
name|defaultConstraints
parameter_list|,
name|List
argument_list|<
name|SQLCheckConstraint
argument_list|>
name|checkConstraints
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
name|tbl
operator|.
name|getDbName
argument_list|()
operator|==
literal|null
operator|||
literal|""
operator|.
name|equals
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
operator|.
name|trim
argument_list|()
argument_list|)
condition|)
block|{
name|tbl
operator|.
name|setDbName
argument_list|(
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentDatabase
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|tbl
operator|.
name|getCols
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|||
name|tbl
operator|.
name|getSd
argument_list|()
operator|.
name|getColsSize
argument_list|()
operator|==
literal|0
condition|)
block|{
name|tbl
operator|.
name|setFields
argument_list|(
name|HiveMetaStoreUtils
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getDeserializer
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|tbl
operator|.
name|checkValidity
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|tbl
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|tbl
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|hive_metastoreConstants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tTbl
init|=
name|tbl
operator|.
name|getTTable
argument_list|()
decl_stmt|;
name|PrincipalPrivilegeSet
name|principalPrivs
init|=
operator|new
name|PrincipalPrivilegeSet
argument_list|()
decl_stmt|;
name|SessionState
name|ss
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|ss
operator|!=
literal|null
condition|)
block|{
name|CreateTableAutomaticGrant
name|grants
init|=
name|ss
operator|.
name|getCreateTableGrants
argument_list|()
decl_stmt|;
if|if
condition|(
name|grants
operator|!=
literal|null
condition|)
block|{
name|principalPrivs
operator|.
name|setUserPrivileges
argument_list|(
name|grants
operator|.
name|getUserGrants
argument_list|()
argument_list|)
expr_stmt|;
name|principalPrivs
operator|.
name|setGroupPrivileges
argument_list|(
name|grants
operator|.
name|getGroupGrants
argument_list|()
argument_list|)
expr_stmt|;
name|principalPrivs
operator|.
name|setRolePrivileges
argument_list|(
name|grants
operator|.
name|getRoleGrants
argument_list|()
argument_list|)
expr_stmt|;
name|tTbl
operator|.
name|setPrivileges
argument_list|(
name|principalPrivs
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Set table snapshot to api.Table to make it persistent.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableSnapshot
operator|!=
literal|null
condition|)
block|{
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|primaryKeys
operator|==
literal|null
operator|&&
name|foreignKeys
operator|==
literal|null
operator|&&
name|uniqueConstraints
operator|==
literal|null
operator|&&
name|notNullConstraints
operator|==
literal|null
operator|&&
name|defaultConstraints
operator|==
literal|null
operator|&&
name|checkConstraints
operator|==
literal|null
condition|)
block|{
name|getMSC
argument_list|()
operator|.
name|createTable
argument_list|(
name|tTbl
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|getMSC
argument_list|()
operator|.
name|createTableWithConstraints
argument_list|(
name|tTbl
argument_list|,
name|primaryKeys
argument_list|,
name|foreignKeys
argument_list|,
name|uniqueConstraints
argument_list|,
name|notNullConstraints
argument_list|,
name|defaultConstraints
argument_list|,
name|checkConstraints
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ifNotExists
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createTable
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|boolean
name|ifNotExists
parameter_list|)
throws|throws
name|HiveException
block|{
name|createTable
argument_list|(
name|tbl
argument_list|,
name|ifNotExists
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|getFieldsFromDeserializerForMsStorage
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Deserializer
name|deserializer
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|MetaException
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema
init|=
name|HiveMetaStoreUtils
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|deserializer
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|schema
control|)
block|{
name|field
operator|.
name|setType
argument_list|(
name|MetaStoreUtils
operator|.
name|TYPE_FROM_DESERIALIZER
argument_list|)
expr_stmt|;
block|}
return|return
name|schema
return|;
block|}
comment|/**    * Drops table along with the data in it. If the table doesn't exist then it    * is a no-op. If ifPurge option is specified it is passed to the    * hdfs command that removes table data from warehouse to make it skip trash.    *    * @param tableName    *          table to drop    * @param ifPurge    *          completely purge the table (skipping trash) while removing data from warehouse    * @throws HiveException    *           thrown if the drop fails    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|boolean
name|ifPurge
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|dropTable
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
name|ifPurge
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drops table along with the data in it. If the table doesn't exist then it    * is a no-op    *    * @param tableName    *          table to drop    * @throws HiveException    *           thrown if the drop fails    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|dropTable
argument_list|(
name|tableName
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drops table along with the data in it. If the table doesn't exist then it    * is a no-op    *    * @param dbName    *          database where the table lives    * @param tableName    *          table to drop    * @throws HiveException    *           thrown if the drop fails    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|dropTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drops the table.    *    * @param dbName    * @param tableName    * @param deleteData    *          deletes the underlying data along with metadata    * @param ignoreUnknownTab    *          an exception is thrown if this is false and the table doesn't exist    * @throws HiveException    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownTab
parameter_list|)
throws|throws
name|HiveException
block|{
name|dropTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownTab
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drops the table.    *    * @param dbName    * @param tableName    * @param deleteData    *          deletes the underlying data along with metadata    * @param ignoreUnknownTab    *          an exception is thrown if this is false and the table doesn't exist    * @param ifPurge    *          completely purge the table skipping trash while removing data from warehouse    * @throws HiveException    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownTab
parameter_list|,
name|boolean
name|ifPurge
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownTab
argument_list|,
name|ifPurge
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreUnknownTab
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Truncates the table/partition as per specifications. Just trash the data files    *    * @param dbDotTableName    *          name of the table    * @throws HiveException    */
specifier|public
name|void
name|truncateTable
parameter_list|(
name|String
name|dbDotTableName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|Table
name|table
init|=
name|getTable
argument_list|(
name|dbDotTableName
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// TODO: we should refactor code to make sure snapshot is always obtained in the same layer e.g. Hive.java
name|AcidUtils
operator|.
name|TableSnapshot
name|snapshot
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|table
argument_list|)
condition|)
block|{
name|snapshot
operator|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|table
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|partNames
init|=
operator|(
operator|(
literal|null
operator|==
name|partSpec
operator|)
condition|?
literal|null
else|:
name|getPartitionNames
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partSpec
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
operator|)
decl_stmt|;
if|if
condition|(
name|snapshot
operator|==
literal|null
condition|)
block|{
name|getMSC
argument_list|()
operator|.
name|truncateTable
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|getMSC
argument_list|()
operator|.
name|truncateTable
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
argument_list|,
name|snapshot
operator|.
name|getTxnId
argument_list|()
argument_list|,
name|snapshot
operator|.
name|getValidWriteIdList
argument_list|()
argument_list|,
name|snapshot
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|HiveConf
name|getConf
parameter_list|()
block|{
return|return
operator|(
name|conf
operator|)
return|;
block|}
comment|/**    * Returns metadata for the table named tableName    * @param tableName the name of the table    * @return the table metadata    * @throws HiveException if there's an internal error or if the    * table doesn't exist    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|this
operator|.
name|getTable
argument_list|(
name|tableName
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Returns metadata for the table named tableName    * @param tableName the name of the table    * @param throwException controls whether an exception is thrown or a returns a null    * @return the table metadata    * @throws HiveException if there's an internal error or if the    * table doesn't exist    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|tableName
parameter_list|,
name|boolean
name|throwException
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|getTable
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|throwException
argument_list|)
return|;
block|}
comment|/**    * Returns metadata of the table    *    * @param dbName    *          the name of the database    * @param tableName    *          the name of the table    * @return the table    * @exception HiveException    *              if there's an internal error or if the table doesn't exist    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|dbName
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tableName
operator|.
name|contains
argument_list|(
literal|"."
argument_list|)
condition|)
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|getTable
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
literal|true
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|this
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
literal|true
argument_list|)
return|;
block|}
block|}
comment|/**    * Returns metadata of the table    *    * @param dbName    *          the name of the database    * @param tableName    *          the name of the table    * @param throwException    *          controls whether an exception is thrown or a returns a null    * @return the table or if throwException is false a null value.    * @throws HiveException    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|dbName
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|,
name|boolean
name|throwException
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|this
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|throwException
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Returns metadata of the table    *    * @param dbName    *          the name of the database    * @param tableName    *          the name of the table    * @param throwException    *          controls whether an exception is thrown or a returns a null    * @param checkTransactional    *          checks whether the metadata table stats are valid (or    *          compilant with the snapshot isolation of) for the current transaction.    * @return the table or if throwException is false a null value.    * @throws HiveException    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|dbName
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|,
name|boolean
name|throwException
parameter_list|,
name|boolean
name|checkTransactional
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tableName
operator|==
literal|null
operator|||
name|tableName
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"empty table creation??"
argument_list|)
throw|;
block|}
comment|// Get the table from metastore
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tTable
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// Note: this is currently called w/true from StatsOptimizer only.
if|if
condition|(
name|checkTransactional
condition|)
block|{
name|ValidWriteIdList
name|validWriteIdList
init|=
literal|null
decl_stmt|;
name|long
name|txnId
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|!=
literal|null
condition|?
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|.
name|getCurrentTxnId
argument_list|()
else|:
literal|0
decl_stmt|;
if|if
condition|(
name|txnId
operator|>
literal|0
condition|)
block|{
name|validWriteIdList
operator|=
name|AcidUtils
operator|.
name|getTableValidWriteIdListWithTxnList
argument_list|(
name|conf
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
block|}
name|tTable
operator|=
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|txnId
argument_list|,
name|validWriteIdList
operator|!=
literal|null
condition|?
name|validWriteIdList
operator|.
name|toString
argument_list|()
else|:
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tTable
operator|=
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
if|if
condition|(
name|throwException
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Table "
operator|+
name|dbName
operator|+
literal|"."
operator|+
name|tableName
operator|+
literal|" not found: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTableException
argument_list|(
name|tableName
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to fetch table "
operator|+
name|tableName
operator|+
literal|". "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// For non-views, we need to do some extra fixes
if|if
condition|(
operator|!
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|tTable
operator|.
name|getTableType
argument_list|()
argument_list|)
condition|)
block|{
comment|// Fix the non-printable chars
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
init|=
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getParameters
argument_list|()
decl_stmt|;
name|String
name|sf
init|=
name|parameters
operator|!=
literal|null
condition|?
name|parameters
operator|.
name|get
argument_list|(
name|SERIALIZATION_FORMAT
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|sf
operator|!=
literal|null
condition|)
block|{
name|char
index|[]
name|b
init|=
name|sf
operator|.
name|toCharArray
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|b
operator|.
name|length
operator|==
literal|1
operator|)
operator|&&
operator|(
name|b
index|[
literal|0
index|]
operator|<
literal|10
operator|)
condition|)
block|{
comment|// ^A, ^B, ^C, ^D, \t
name|parameters
operator|.
name|put
argument_list|(
name|SERIALIZATION_FORMAT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|b
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Use LazySimpleSerDe for MetadataTypedColumnsetSerDe.
comment|// NOTE: LazySimpleSerDe does not support tables with a single column of
comment|// col
comment|// of type "array<string>". This happens when the table is created using
comment|// an
comment|// earlier version of Hive.
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|MetadataTypedColumnsetSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
operator|&&
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getColsSize
argument_list|()
operator|>
literal|0
operator|&&
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getType
argument_list|()
operator|.
name|indexOf
argument_list|(
literal|'<'
argument_list|)
operator|==
operator|-
literal|1
condition|)
block|{
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|Table
argument_list|(
name|tTable
argument_list|)
return|;
block|}
comment|/**    * Get all table names for the current database.    * @return List of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllTables
parameter_list|()
throws|throws
name|HiveException
block|{
return|return
name|getTablesByType
argument_list|(
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentDatabase
argument_list|()
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Get all table names for the specified database.    * @param dbName    * @return List of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllTables
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByType
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Get all tables for the specified database.    * @param dbName    * @return List of all tables    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Table
argument_list|>
name|getAllTableObjects
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTableObjects
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Get all materialized view names for the specified database.    * @param dbName    * @return List of materialized view table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllMaterializedViews
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByType
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|,
name|TableType
operator|.
name|MATERIALIZED_VIEW
argument_list|)
return|;
block|}
comment|/**    * Get all materialized views for the specified database.    * @param dbName    * @return List of materialized view table objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Table
argument_list|>
name|getAllMaterializedViewObjects
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTableObjects
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|,
name|TableType
operator|.
name|MATERIALIZED_VIEW
argument_list|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|Table
argument_list|>
name|getTableObjects
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|pattern
parameter_list|,
name|TableType
name|tableType
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|Lists
operator|.
name|transform
argument_list|(
name|getMSC
argument_list|()
operator|.
name|getTableObjectsByName
argument_list|(
name|dbName
argument_list|,
name|getTablesByType
argument_list|(
name|dbName
argument_list|,
name|pattern
argument_list|,
name|tableType
argument_list|)
argument_list|)
argument_list|,
operator|new
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
argument_list|,
name|Table
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Table
name|apply
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
operator|new
name|Table
argument_list|(
name|table
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|Table
argument_list|>
name|getTableObjects
parameter_list|(
name|String
name|dbName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|tableNames
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|Lists
operator|.
name|transform
argument_list|(
name|getMSC
argument_list|()
operator|.
name|getTableObjectsByName
argument_list|(
name|dbName
argument_list|,
name|tableNames
argument_list|)
argument_list|,
operator|new
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
argument_list|,
name|Table
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Table
name|apply
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
operator|new
name|Table
argument_list|(
name|table
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Returns all existing tables from default database which match the given    * pattern. The matching occurs as per Java regular expressions    *    * @param tablePattern    *          java re pattern    * @return list of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesByPattern
parameter_list|(
name|String
name|tablePattern
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByType
argument_list|(
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentDatabase
argument_list|()
argument_list|,
name|tablePattern
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Returns all existing tables from the specified database which match the given    * pattern. The matching occurs as per Java regular expressions.    * @param dbName    * @param tablePattern    * @return list of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesByPattern
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tablePattern
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByType
argument_list|(
name|dbName
argument_list|,
name|tablePattern
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Returns all existing tables from the given database which match the given    * pattern. The matching occurs as per Java regular expressions    *    * @param database    *          the database name    * @param tablePattern    *          java re pattern    * @return list of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesForDb
parameter_list|(
name|String
name|database
parameter_list|,
name|String
name|tablePattern
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByType
argument_list|(
name|database
argument_list|,
name|tablePattern
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Returns all existing tables of a type (VIRTUAL_VIEW|EXTERNAL_TABLE|MANAGED_TABLE) from the specified    * database which match the given pattern. The matching occurs as per Java regular expressions.    * @param dbName Database name to find the tables in. if null, uses the current database in this session.    * @param pattern A pattern to match for the table names.If null, returns all names from this DB.    * @param type The type of tables to return. VIRTUAL_VIEWS for views. If null, returns all tables and views.    * @return list of table names that match the pattern.    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesByType
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|pattern
parameter_list|,
name|TableType
name|type
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|dbName
operator|==
literal|null
condition|)
block|{
name|dbName
operator|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentDatabase
argument_list|()
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|type
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|pattern
operator|!=
literal|null
condition|)
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getTables
argument_list|(
name|dbName
argument_list|,
name|pattern
argument_list|,
name|type
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getTables
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|,
name|type
argument_list|)
return|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|pattern
operator|!=
literal|null
condition|)
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getTables
argument_list|(
name|dbName
argument_list|,
name|pattern
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getTables
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get the materialized views that have been enabled for rewriting from the    * metastore. If the materialized view is in the cache, we do not need to    * parse it to generate a logical plan for the rewriting. Instead, we    * return the version present in the cache. Further, information provided    * by the invalidation cache is useful to know whether a materialized view    * can be used for rewriting or not.    *    * @return the list of materialized views available for rewriting    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|RelOptMaterialization
argument_list|>
name|getAllValidMaterializedViews
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|tablesUsed
parameter_list|,
name|boolean
name|forceMVContentsUpToDate
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// Final result
name|List
argument_list|<
name|RelOptMaterialization
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
try|try
block|{
for|for
control|(
name|String
name|dbName
range|:
name|getMSC
argument_list|()
operator|.
name|getAllDatabases
argument_list|()
control|)
block|{
comment|// From metastore (for security)
name|List
argument_list|<
name|String
argument_list|>
name|materializedViewNames
init|=
name|getMaterializedViewsForRewriting
argument_list|(
name|dbName
argument_list|)
decl_stmt|;
if|if
condition|(
name|materializedViewNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Bail out: empty list
continue|continue;
block|}
name|result
operator|.
name|addAll
argument_list|(
name|getValidMaterializedViews
argument_list|(
name|dbName
argument_list|,
name|materializedViewNames
argument_list|,
name|tablesUsed
argument_list|,
name|forceMVContentsUpToDate
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|RelOptMaterialization
argument_list|>
name|getValidMaterializedView
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|materializedViewName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|tablesUsed
parameter_list|,
name|boolean
name|forceMVContentsUpToDate
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getValidMaterializedViews
argument_list|(
name|dbName
argument_list|,
name|ImmutableList
operator|.
name|of
argument_list|(
name|materializedViewName
argument_list|)
argument_list|,
name|tablesUsed
argument_list|,
name|forceMVContentsUpToDate
argument_list|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|RelOptMaterialization
argument_list|>
name|getValidMaterializedViews
parameter_list|(
name|String
name|dbName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|materializedViewNames
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|tablesUsed
parameter_list|,
name|boolean
name|forceMVContentsUpToDate
parameter_list|)
throws|throws
name|HiveException
block|{
specifier|final
name|String
name|validTxnsList
init|=
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|)
decl_stmt|;
specifier|final
name|ValidTxnWriteIdList
name|currentTxnWriteIds
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|.
name|getValidWriteIds
argument_list|(
name|tablesUsed
argument_list|,
name|validTxnsList
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|tryIncrementalRewriting
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_MATERIALIZED_VIEW_REWRITING_INCREMENTAL
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|tryIncrementalRebuild
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_MATERIALIZED_VIEW_REBUILD_INCREMENTAL
argument_list|)
decl_stmt|;
specifier|final
name|long
name|defaultDiff
init|=
name|HiveConf
operator|.
name|getTimeVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_MATERIALIZED_VIEW_REWRITING_TIME_WINDOW
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
specifier|final
name|long
name|currentTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
try|try
block|{
comment|// Final result
name|List
argument_list|<
name|RelOptMaterialization
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Table
argument_list|>
name|materializedViewTables
init|=
name|getTableObjects
argument_list|(
name|dbName
argument_list|,
name|materializedViewNames
argument_list|)
decl_stmt|;
for|for
control|(
name|Table
name|materializedViewTable
range|:
name|materializedViewTables
control|)
block|{
comment|// Check if materialization defined its own invalidation time window
name|String
name|timeWindowString
init|=
name|materializedViewTable
operator|.
name|getProperty
argument_list|(
name|MATERIALIZED_VIEW_REWRITING_TIME_WINDOW
argument_list|)
decl_stmt|;
name|long
name|diff
init|=
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|timeWindowString
argument_list|)
condition|?
name|defaultDiff
else|:
name|HiveConf
operator|.
name|toTime
argument_list|(
name|timeWindowString
argument_list|,
name|HiveConf
operator|.
name|getDefaultTimeUnit
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_MATERIALIZED_VIEW_REWRITING_TIME_WINDOW
argument_list|)
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
name|CreationMetadata
name|creationMetadata
init|=
name|materializedViewTable
operator|.
name|getCreationMetadata
argument_list|()
decl_stmt|;
name|boolean
name|outdated
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|diff
operator|<
literal|0L
condition|)
block|{
comment|// We only consider the materialized view to be outdated if forceOutdated = true, i.e.,
comment|// if it is a rebuild. Otherwise, it passed the test and we use it as it is.
name|outdated
operator|=
name|forceMVContentsUpToDate
expr_stmt|;
block|}
else|else
block|{
comment|// Check whether the materialized view is invalidated
if|if
condition|(
name|forceMVContentsUpToDate
operator|||
name|diff
operator|==
literal|0L
operator|||
name|creationMetadata
operator|.
name|getMaterializationTime
argument_list|()
operator|<
name|currentTime
operator|-
name|diff
condition|)
block|{
if|if
condition|(
name|currentTxnWriteIds
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" ignored for rewriting as we could not obtain current txn ids"
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|creationMetadata
operator|.
name|getValidTxnList
argument_list|()
operator|==
literal|null
operator|||
name|creationMetadata
operator|.
name|getValidTxnList
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" ignored for rewriting as we could not obtain materialization txn ids"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|boolean
name|ignore
init|=
literal|false
decl_stmt|;
name|ValidTxnWriteIdList
name|mvTxnWriteIds
init|=
operator|new
name|ValidTxnWriteIdList
argument_list|(
name|creationMetadata
operator|.
name|getValidTxnList
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|qName
range|:
name|tablesUsed
control|)
block|{
comment|// Note. If the materialized view does not contain a table that is contained in the query,
comment|// we do not need to check whether that specific table is outdated or not. If a rewriting
comment|// is produced in those cases, it is because that additional table is joined with the
comment|// existing tables with an append-columns only join, i.e., PK-FK + not null.
if|if
condition|(
operator|!
name|creationMetadata
operator|.
name|getTablesUsed
argument_list|()
operator|.
name|contains
argument_list|(
name|qName
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|ValidWriteIdList
name|tableCurrentWriteIds
init|=
name|currentTxnWriteIds
operator|.
name|getTableValidWriteIdList
argument_list|(
name|qName
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableCurrentWriteIds
operator|==
literal|null
condition|)
block|{
comment|// Uses non-transactional table, cannot be considered
name|LOG
operator|.
name|debug
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" ignored for rewriting as it is outdated and cannot be considered for "
operator|+
literal|" rewriting because it uses non-transactional table "
operator|+
name|qName
argument_list|)
expr_stmt|;
name|ignore
operator|=
literal|true
expr_stmt|;
break|break;
block|}
name|ValidWriteIdList
name|tableWriteIds
init|=
name|mvTxnWriteIds
operator|.
name|getTableValidWriteIdList
argument_list|(
name|qName
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableWriteIds
operator|==
literal|null
condition|)
block|{
comment|// This should not happen, but we ignore for safety
name|LOG
operator|.
name|warn
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" ignored for rewriting as details about txn ids for table "
operator|+
name|qName
operator|+
literal|" could not be found in "
operator|+
name|mvTxnWriteIds
argument_list|)
expr_stmt|;
name|ignore
operator|=
literal|true
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|!
name|outdated
operator|&&
operator|!
name|TxnIdUtils
operator|.
name|checkEquivalentWriteIds
argument_list|(
name|tableCurrentWriteIds
argument_list|,
name|tableWriteIds
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" contents are outdated"
argument_list|)
expr_stmt|;
name|outdated
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|ignore
condition|)
block|{
continue|continue;
block|}
block|}
block|}
if|if
condition|(
name|outdated
condition|)
block|{
comment|// The MV is outdated, see whether we should consider it for rewriting or not
name|boolean
name|ignore
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|forceMVContentsUpToDate
operator|&&
operator|!
name|tryIncrementalRebuild
condition|)
block|{
comment|// We will not try partial rewriting for rebuild if incremental rebuild is disabled
name|ignore
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|forceMVContentsUpToDate
operator|&&
operator|!
name|tryIncrementalRewriting
condition|)
block|{
comment|// We will not try partial rewriting for non-rebuild if incremental rewriting is disabled
name|ignore
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|// Obtain additional information if we should try incremental rewriting / rebuild
comment|// We will not try partial rewriting if there were update/delete operations on source tables
name|Materialization
name|invalidationInfo
init|=
name|getMSC
argument_list|()
operator|.
name|getMaterializationInvalidationInfo
argument_list|(
name|creationMetadata
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|ValidTxnList
operator|.
name|VALID_TXNS_KEY
argument_list|)
argument_list|)
decl_stmt|;
name|ignore
operator|=
name|invalidationInfo
operator|==
literal|null
operator|||
name|invalidationInfo
operator|.
name|isSourceTablesUpdateDeleteModified
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|ignore
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" ignored for rewriting as its contents are outdated"
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
comment|// It passed the test, load
name|RelOptMaterialization
name|materialization
init|=
name|HiveMaterializedViewsRegistry
operator|.
name|get
argument_list|()
operator|.
name|getRewritingMaterializedView
argument_list|(
name|dbName
argument_list|,
name|materializedViewTable
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|materialization
operator|!=
literal|null
condition|)
block|{
name|RelNode
name|viewScan
init|=
name|materialization
operator|.
name|tableRel
decl_stmt|;
name|RelOptHiveTable
name|cachedMaterializedViewTable
decl_stmt|;
if|if
condition|(
name|viewScan
operator|instanceof
name|Project
condition|)
block|{
comment|// There is a Project on top (due to nullability)
name|cachedMaterializedViewTable
operator|=
operator|(
name|RelOptHiveTable
operator|)
name|viewScan
operator|.
name|getInput
argument_list|(
literal|0
argument_list|)
operator|.
name|getTable
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|cachedMaterializedViewTable
operator|=
operator|(
name|RelOptHiveTable
operator|)
name|viewScan
operator|.
name|getTable
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|cachedMaterializedViewTable
operator|.
name|getHiveTableMD
argument_list|()
operator|.
name|getCreateTime
argument_list|()
operator|==
name|materializedViewTable
operator|.
name|getCreateTime
argument_list|()
condition|)
block|{
comment|// It is in the cache and up to date
if|if
condition|(
name|outdated
condition|)
block|{
comment|// We will rewrite it to include the filters on transaction list
comment|// so we can produce partial rewritings
name|materialization
operator|=
name|augmentMaterializationWithTimeInformation
argument_list|(
name|materialization
argument_list|,
name|validTxnsList
argument_list|,
operator|new
name|ValidTxnWriteIdList
argument_list|(
name|creationMetadata
operator|.
name|getValidTxnList
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|result
operator|.
name|add
argument_list|(
name|materialization
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
comment|// It was not present in the cache (maybe because it was added by another HS2)
comment|// or it is not up to date.
if|if
condition|(
name|HiveMaterializedViewsRegistry
operator|.
name|get
argument_list|()
operator|.
name|isInitialized
argument_list|()
condition|)
block|{
comment|// But the registry was fully initialized, thus we need to add it
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" was not in the cache"
argument_list|)
expr_stmt|;
block|}
name|materialization
operator|=
name|HiveMaterializedViewsRegistry
operator|.
name|get
argument_list|()
operator|.
name|createMaterializedView
argument_list|(
name|conf
argument_list|,
name|materializedViewTable
argument_list|)
expr_stmt|;
if|if
condition|(
name|materialization
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|outdated
condition|)
block|{
comment|// We will rewrite it to include the filters on transaction list
comment|// so we can produce partial rewritings
name|materialization
operator|=
name|augmentMaterializationWithTimeInformation
argument_list|(
name|materialization
argument_list|,
name|validTxnsList
argument_list|,
operator|new
name|ValidTxnWriteIdList
argument_list|(
name|creationMetadata
operator|.
name|getValidTxnList
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|result
operator|.
name|add
argument_list|(
name|materialization
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Otherwise the registry has not been initialized, skip for the time being
if|if
condition|(
name|LOG
operator|.
name|isWarnEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Materialized view "
operator|+
name|materializedViewTable
operator|.
name|getFullyQualifiedName
argument_list|()
operator|+
literal|" was skipped "
operator|+
literal|"because cache has not been loaded yet"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Method to enrich the materialization query contained in the input with    * its invalidation.    */
specifier|private
specifier|static
name|RelOptMaterialization
name|augmentMaterializationWithTimeInformation
parameter_list|(
name|RelOptMaterialization
name|materialization
parameter_list|,
name|String
name|validTxnsList
parameter_list|,
name|ValidTxnWriteIdList
name|materializationTxnList
parameter_list|)
throws|throws
name|LockException
block|{
comment|// Extract tables used by the query which will in turn be used to generate
comment|// the corresponding txn write ids
name|List
argument_list|<
name|String
argument_list|>
name|tablesUsed
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
operator|new
name|RelVisitor
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
name|RelNode
name|node
parameter_list|,
name|int
name|ordinal
parameter_list|,
name|RelNode
name|parent
parameter_list|)
block|{
if|if
condition|(
name|node
operator|instanceof
name|TableScan
condition|)
block|{
name|TableScan
name|ts
init|=
operator|(
name|TableScan
operator|)
name|node
decl_stmt|;
name|tablesUsed
operator|.
name|add
argument_list|(
operator|(
operator|(
name|RelOptHiveTable
operator|)
name|ts
operator|.
name|getTable
argument_list|()
operator|)
operator|.
name|getHiveTableMD
argument_list|()
operator|.
name|getFullyQualifiedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|super
operator|.
name|visit
argument_list|(
name|node
argument_list|,
name|ordinal
argument_list|,
name|parent
argument_list|)
expr_stmt|;
block|}
block|}
operator|.
name|go
argument_list|(
name|materialization
operator|.
name|queryRel
argument_list|)
expr_stmt|;
name|ValidTxnWriteIdList
name|currentTxnList
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|.
name|getValidWriteIds
argument_list|(
name|tablesUsed
argument_list|,
name|validTxnsList
argument_list|)
decl_stmt|;
comment|// Augment
specifier|final
name|RexBuilder
name|rexBuilder
init|=
name|materialization
operator|.
name|queryRel
operator|.
name|getCluster
argument_list|()
operator|.
name|getRexBuilder
argument_list|()
decl_stmt|;
specifier|final
name|HepProgramBuilder
name|augmentMaterializationProgram
init|=
operator|new
name|HepProgramBuilder
argument_list|()
operator|.
name|addRuleInstance
argument_list|(
operator|new
name|HiveAugmentMaterializationRule
argument_list|(
name|rexBuilder
argument_list|,
name|currentTxnList
argument_list|,
name|materializationTxnList
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|HepPlanner
name|augmentMaterializationPlanner
init|=
operator|new
name|HepPlanner
argument_list|(
name|augmentMaterializationProgram
operator|.
name|build
argument_list|()
argument_list|)
decl_stmt|;
name|augmentMaterializationPlanner
operator|.
name|setRoot
argument_list|(
name|materialization
operator|.
name|queryRel
argument_list|)
expr_stmt|;
specifier|final
name|RelNode
name|modifiedQueryRel
init|=
name|augmentMaterializationPlanner
operator|.
name|findBestExp
argument_list|()
decl_stmt|;
return|return
operator|new
name|RelOptMaterialization
argument_list|(
name|materialization
operator|.
name|tableRel
argument_list|,
name|modifiedQueryRel
argument_list|,
literal|null
argument_list|,
name|materialization
operator|.
name|qualifiedTableName
argument_list|)
return|;
block|}
comment|/**    * Get materialized views for the specified database that have enabled rewriting.    * @param dbName    * @return List of materialized view table objects    * @throws HiveException    */
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|getMaterializedViewsForRewriting
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getMaterializedViewsForRewriting
argument_list|(
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all existing database names.    *    * @return List of database names.    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllDatabases
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getAllDatabases
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all existing databases that match the given    * pattern. The matching occurs as per Java regular expressions    *    * @param databasePattern    *          java re pattern    * @return list of database names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getDatabasesByPattern
parameter_list|(
name|String
name|databasePattern
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDatabases
argument_list|(
name|databasePattern
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|grantPrivileges
parameter_list|(
name|PrivilegeBag
name|privileges
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|grant_privileges
argument_list|(
name|privileges
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param privileges    *          a bag of privileges    * @return true on success    * @throws HiveException    */
specifier|public
name|boolean
name|revokePrivileges
parameter_list|(
name|PrivilegeBag
name|privileges
parameter_list|,
name|boolean
name|grantOption
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|revoke_privileges
argument_list|(
name|privileges
argument_list|,
name|grantOption
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Query metadata to see if a database with the given name already exists.    *    * @param dbName    * @return true if a database with the given name already exists, false if    *         does not exist.    * @throws HiveException    */
specifier|public
name|boolean
name|databaseExists
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getDatabase
argument_list|(
name|dbName
argument_list|)
operator|!=
literal|null
return|;
block|}
comment|/**    * Get the database by name.    * @param dbName the name of the database.    * @return a Database object if this database exists, null otherwise.    * @throws HiveException    */
specifier|public
name|Database
name|getDatabase
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get the database by name.    * @param catName catalog name    * @param dbName the name of the database.    * @return a Database object if this database exists, null otherwise.    * @throws HiveException    */
specifier|public
name|Database
name|getDatabase
parameter_list|(
name|String
name|catName
parameter_list|,
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|catName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get the Database object for current database    * @return a Database object if this database exists, null otherwise.    * @throws HiveException    */
specifier|public
name|Database
name|getDatabaseCurrent
parameter_list|()
throws|throws
name|HiveException
block|{
name|String
name|currentDb
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getCurrentDatabase
argument_list|()
decl_stmt|;
return|return
name|getDatabase
argument_list|(
name|currentDb
argument_list|)
return|;
block|}
comment|/**    * Load a directory into a Hive Table Partition - Alters existing content of    * the partition with the contents of loadPath. - If the partition does not    * exist - one is created - files in loadPath are moved into Hive. But the    * directory itself is not removed.    *    * @param loadPath    *          Directory containing files to load into Table    * @param  tbl    *          name of table to be loaded.    * @param partSpec    *          defines which partition needs to be loaded    * @param loadFileType    *          if REPLACE_ALL - replace files in the table,    *          otherwise add files to table (KEEP_EXISTING, OVERWRITE_EXISTING)    * @param inheritTableSpecs if true, on [re]creating the partition, take the    *          location/inputformat/outputformat/serde details from table spec    * @param isSrcLocal    *          If the source directory is LOCAL    * @param isAcidIUDoperation    *          true if this is an ACID operation Insert/Update/Delete operation    * @param hasFollowingStatsTask    *          true if there is a following task which updates the stats, so, this method need not update.    * @param writeId write ID allocated for the current load operation    * @param stmtId statement ID of the current load statement    * @param isInsertOverwrite    * @return Partition object being loaded with data    */
specifier|public
name|Partition
name|loadPartition
parameter_list|(
name|Path
name|loadPath
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|LoadFileType
name|loadFileType
parameter_list|,
name|boolean
name|inheritTableSpecs
parameter_list|,
name|boolean
name|isSkewedStoreAsSubdir
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|isAcidIUDoperation
parameter_list|,
name|boolean
name|hasFollowingStatsTask
parameter_list|,
name|Long
name|writeId
parameter_list|,
name|int
name|stmtId
parameter_list|,
name|boolean
name|isInsertOverwrite
parameter_list|)
throws|throws
name|HiveException
block|{
name|Path
name|tblDataLocationPath
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
decl_stmt|;
name|boolean
name|isMmTableWrite
init|=
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
assert|assert
name|tbl
operator|.
name|getPath
argument_list|()
operator|!=
literal|null
operator|:
literal|"null==getPath() for "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
assert|;
name|boolean
name|isFullAcidTable
init|=
name|AcidUtils
operator|.
name|isFullAcidTable
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
name|boolean
name|isTxnTable
init|=
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
try|try
block|{
name|PerfLogger
name|perfLogger
init|=
name|SessionState
operator|.
name|getPerfLogger
argument_list|()
decl_stmt|;
name|perfLogger
operator|.
name|PerfLogBegin
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|LOAD_PARTITION
argument_list|)
expr_stmt|;
comment|// Get the partition object if it already exists
name|Partition
name|oldPart
init|=
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|/**        * Move files before creating the partition since down stream processes        * check for existence of partition in metadata before accessing the data.        * If partition is created before data is moved, downstream waiting        * processes might move forward with partial data        */
name|Path
name|oldPartPath
init|=
operator|(
name|oldPart
operator|!=
literal|null
operator|)
condition|?
name|oldPart
operator|.
name|getDataLocation
argument_list|()
else|:
literal|null
decl_stmt|;
name|Path
name|newPartPath
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|inheritTableSpecs
condition|)
block|{
name|Path
name|partPath
init|=
operator|new
name|Path
argument_list|(
name|tbl
operator|.
name|getDataLocation
argument_list|()
argument_list|,
name|Warehouse
operator|.
name|makePartPath
argument_list|(
name|partSpec
argument_list|)
argument_list|)
decl_stmt|;
name|newPartPath
operator|=
operator|new
name|Path
argument_list|(
name|tblDataLocationPath
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
argument_list|,
name|tblDataLocationPath
operator|.
name|toUri
argument_list|()
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|partPath
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldPart
operator|!=
literal|null
condition|)
block|{
comment|/*            * If we are moving the partition across filesystem boundaries            * inherit from the table properties. Otherwise (same filesystem) use the            * original partition location.            *            * See: HIVE-1707 and HIVE-2117 for background            */
name|FileSystem
name|oldPartPathFS
init|=
name|oldPartPath
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|loadPathFS
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|FileUtils
operator|.
name|equalsFileSystem
argument_list|(
name|oldPartPathFS
argument_list|,
name|loadPathFS
argument_list|)
condition|)
block|{
name|newPartPath
operator|=
name|oldPartPath
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|newPartPath
operator|=
name|oldPartPath
expr_stmt|;
block|}
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
init|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
name|perfLogger
operator|.
name|PerfLogBegin
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|FILE_MOVES
argument_list|)
expr_stmt|;
comment|// If config is set, table is not temporary and partition being inserted exists, capture
comment|// the list of files added. For not yet existing partitions (insert overwrite to new partition
comment|// or dynamic partition inserts), the add partition event will capture the list of files added.
if|if
condition|(
name|areEventsForDmlNeeded
argument_list|(
name|tbl
argument_list|,
name|oldPart
argument_list|)
condition|)
block|{
name|newFiles
operator|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Note: the stats for ACID tables do not have any coordination with either Hive ACID logic
comment|//       like txn commits, time outs, etc.; nor the lower level sync in metastore pertaining
comment|//       to ACID updates. So the are not themselves ACID.
comment|// Note: this assumes both paths are qualified; which they are, currently.
if|if
condition|(
operator|(
name|isMmTableWrite
operator|||
name|isFullAcidTable
operator|)
operator|&&
name|loadPath
operator|.
name|equals
argument_list|(
name|newPartPath
argument_list|)
condition|)
block|{
comment|// MM insert query, move itself is a no-op.
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"not moving "
operator|+
name|loadPath
operator|+
literal|" to "
operator|+
name|newPartPath
operator|+
literal|" (MM)"
argument_list|)
expr_stmt|;
block|}
assert|assert
operator|!
name|isAcidIUDoperation
assert|;
if|if
condition|(
name|newFiles
operator|!=
literal|null
condition|)
block|{
name|listFilesCreatedByQuery
argument_list|(
name|loadPath
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|,
name|isMmTableWrite
condition|?
name|isInsertOverwrite
else|:
literal|false
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"maybe deleting stuff from "
operator|+
name|oldPartPath
operator|+
literal|" (new "
operator|+
name|newPartPath
operator|+
literal|") for replace"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Either a non-MM query, or a load into MM table from an external source.
name|Path
name|destPath
init|=
name|newPartPath
decl_stmt|;
if|if
condition|(
name|isMmTableWrite
condition|)
block|{
assert|assert
operator|!
name|isAcidIUDoperation
assert|;
comment|// We will load into MM directory, and hide previous directories if needed.
name|destPath
operator|=
operator|new
name|Path
argument_list|(
name|destPath
argument_list|,
name|isInsertOverwrite
condition|?
name|AcidUtils
operator|.
name|baseDir
argument_list|(
name|writeId
argument_list|)
else|:
name|AcidUtils
operator|.
name|deltaSubdir
argument_list|(
name|writeId
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|isAcidIUDoperation
operator|&&
name|isFullAcidTable
condition|)
block|{
name|destPath
operator|=
name|fixFullAcidPathForLoadData
argument_list|(
name|loadFileType
argument_list|,
name|destPath
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|,
name|tbl
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"moving "
operator|+
name|loadPath
operator|+
literal|" to "
operator|+
name|destPath
argument_list|)
expr_stmt|;
block|}
name|boolean
name|isManaged
init|=
name|tbl
operator|.
name|getTableType
argument_list|()
operator|==
name|TableType
operator|.
name|MANAGED_TABLE
decl_stmt|;
comment|// TODO: why is "&& !isAcidIUDoperation" needed here?
if|if
condition|(
operator|!
name|isTxnTable
operator|&&
operator|(
operator|(
name|loadFileType
operator|==
name|LoadFileType
operator|.
name|REPLACE_ALL
operator|)
operator|||
operator|(
name|oldPart
operator|==
literal|null
operator|&&
operator|!
name|isAcidIUDoperation
operator|)
operator|)
condition|)
block|{
comment|//for fullAcid tables we don't delete files for commands with OVERWRITE - we create a new
comment|// base_x.  (there is Insert Overwrite and Load Data Overwrite)
name|boolean
name|isAutoPurge
init|=
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|tbl
operator|.
name|getProperty
argument_list|(
literal|"auto.purge"
argument_list|)
argument_list|)
decl_stmt|;
name|boolean
name|needRecycle
init|=
operator|!
name|tbl
operator|.
name|isTemporary
argument_list|()
operator|&&
name|ReplChangeManager
operator|.
name|isSourceOfReplication
argument_list|(
name|Hive
operator|.
name|get
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|replaceFiles
argument_list|(
name|tbl
operator|.
name|getPath
argument_list|()
argument_list|,
name|loadPath
argument_list|,
name|destPath
argument_list|,
name|oldPartPath
argument_list|,
name|getConf
argument_list|()
argument_list|,
name|isSrcLocal
argument_list|,
name|isAutoPurge
argument_list|,
name|newFiles
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|,
name|needRecycle
argument_list|,
name|isManaged
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|FileSystem
name|fs
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|copyFiles
argument_list|(
name|conf
argument_list|,
name|loadPath
argument_list|,
name|destPath
argument_list|,
name|fs
argument_list|,
name|isSrcLocal
argument_list|,
name|isAcidIUDoperation
argument_list|,
operator|(
name|loadFileType
operator|==
name|LoadFileType
operator|.
name|OVERWRITE_EXISTING
operator|)
argument_list|,
name|newFiles
argument_list|,
name|tbl
operator|.
name|getNumBuckets
argument_list|()
operator|>
literal|0
argument_list|,
name|isFullAcidTable
argument_list|,
name|isManaged
argument_list|)
expr_stmt|;
block|}
block|}
name|perfLogger
operator|.
name|PerfLogEnd
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|FILE_MOVES
argument_list|)
expr_stmt|;
name|Partition
name|newTPart
init|=
name|oldPart
operator|!=
literal|null
condition|?
name|oldPart
else|:
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|newPartPath
argument_list|)
decl_stmt|;
name|alterPartitionSpecInMemory
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|newTPart
operator|.
name|getTPartition
argument_list|()
argument_list|,
name|inheritTableSpecs
argument_list|,
name|newPartPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|validatePartition
argument_list|(
name|newTPart
argument_list|)
expr_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
literal|null
decl_stmt|;
name|tableSnapshot
operator|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|newTPart
operator|.
name|getTable
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|tableSnapshot
operator|!=
literal|null
condition|)
block|{
name|newTPart
operator|.
name|getTPartition
argument_list|()
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// If config is set, table is not temporary and partition being inserted exists, capture
comment|// the list of files added. For not yet existing partitions (insert overwrite to new partition
comment|// or dynamic partition inserts), the add partition event will capture the list of files added.
comment|// Generate an insert event only if inserting into an existing partition
comment|// When inserting into a new partition, the add partition event takes care of insert event
if|if
condition|(
operator|(
literal|null
operator|!=
name|oldPart
operator|)
operator|&&
operator|(
literal|null
operator|!=
name|newFiles
operator|)
condition|)
block|{
if|if
condition|(
name|isTxnTable
condition|)
block|{
name|addWriteNotificationLog
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|newFiles
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|fireInsertEvent
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
operator|(
name|loadFileType
operator|==
name|LoadFileType
operator|.
name|REPLACE_ALL
operator|)
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No new files were created, and is not a replace, or we're inserting into a "
operator|+
literal|"partition that does not exist yet. Skipping generating INSERT event."
argument_list|)
expr_stmt|;
block|}
comment|// column stats will be inaccurate
if|if
condition|(
operator|!
name|hasFollowingStatsTask
condition|)
block|{
name|StatsSetupConst
operator|.
name|clearColumnStatsState
argument_list|(
name|newTPart
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// recreate the partition if it existed before
if|if
condition|(
name|isSkewedStoreAsSubdir
condition|)
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|newCreatedTpart
init|=
name|newTPart
operator|.
name|getTPartition
argument_list|()
decl_stmt|;
name|SkewedInfo
name|skewedInfo
init|=
name|newCreatedTpart
operator|.
name|getSd
argument_list|()
operator|.
name|getSkewedInfo
argument_list|()
decl_stmt|;
comment|/* Construct list bucketing location mappings from sub-directory name. */
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|skewedColValueLocationMaps
init|=
name|constructListBucketingLocationMap
argument_list|(
name|newPartPath
argument_list|,
name|skewedInfo
argument_list|)
decl_stmt|;
comment|/* Add list bucketing location mappings. */
name|skewedInfo
operator|.
name|setSkewedColValueLocationMaps
argument_list|(
name|skewedColValueLocationMaps
argument_list|)
expr_stmt|;
name|newCreatedTpart
operator|.
name|getSd
argument_list|()
operator|.
name|setSkewedInfo
argument_list|(
name|skewedInfo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESTATSAUTOGATHER
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|newTPart
operator|.
name|getParameters
argument_list|()
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|oldPart
operator|==
literal|null
condition|)
block|{
name|newTPart
operator|.
name|getTPartition
argument_list|()
operator|.
name|setParameters
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESTATSAUTOGATHER
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setStatsStateForCreateTable
argument_list|(
name|newTPart
operator|.
name|getParameters
argument_list|()
argument_list|,
name|MetaStoreUtils
operator|.
name|getColumnNames
argument_list|(
name|tbl
operator|.
name|getCols
argument_list|()
argument_list|)
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
comment|// Note: we are creating a brand new the partition, so this is going to be valid for ACID.
name|List
argument_list|<
name|FileStatus
argument_list|>
name|filesForStats
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isTxnTable
condition|)
block|{
name|filesForStats
operator|=
name|AcidUtils
operator|.
name|getAcidFilesForStats
argument_list|(
name|newTPart
operator|.
name|getTable
argument_list|()
argument_list|,
name|newPartPath
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|filesForStats
operator|=
name|HiveStatsUtils
operator|.
name|getFileStatusRecurse
argument_list|(
name|newPartPath
argument_list|,
operator|-
literal|1
argument_list|,
name|newPartPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filesForStats
operator|!=
literal|null
condition|)
block|{
name|MetaStoreUtils
operator|.
name|populateQuickStats
argument_list|(
name|filesForStats
argument_list|,
name|newTPart
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// The ACID state is probably absent. Warning is logged in the get method.
name|MetaStoreUtils
operator|.
name|clearQuickStats
argument_list|(
name|newTPart
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding new partition "
operator|+
name|newTPart
operator|.
name|getSpec
argument_list|()
argument_list|)
expr_stmt|;
name|getSynchronizedMSC
argument_list|()
operator|.
name|add_partition
argument_list|(
name|newTPart
operator|.
name|getTPartition
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|aee
parameter_list|)
block|{
comment|// With multiple users concurrently issuing insert statements on the same partition has
comment|// a side effect that some queries may not see a partition at the time when they're issued,
comment|// but will realize the partition is actually there when it is trying to add such partition
comment|// to the metastore and thus get AlreadyExistsException, because some earlier query just created it (race condition).
comment|// For example, imagine such a table is created:
comment|//  create table T (name char(50)) partitioned by (ds string);
comment|// and the following two queries are launched at the same time, from different sessions:
comment|//  insert into table T partition (ds) values ('Bob', 'today'); -- creates the partition 'today'
comment|//  insert into table T partition (ds) values ('Joe', 'today'); -- will fail with AlreadyExistsException
comment|// In that case, we want to retry with alterPartition.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Caught AlreadyExistsException, trying to alter partition instead"
argument_list|)
expr_stmt|;
name|setStatsPropAndAlterPartition
argument_list|(
name|hasFollowingStatsTask
argument_list|,
name|tbl
argument_list|,
name|newTPart
argument_list|,
name|tableSnapshot
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
try|try
block|{
specifier|final
name|FileSystem
name|newPathFileSystem
init|=
name|newPartPath
operator|.
name|getFileSystem
argument_list|(
name|this
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|isAutoPurge
init|=
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|tbl
operator|.
name|getProperty
argument_list|(
literal|"auto.purge"
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|FileStatus
name|status
init|=
name|newPathFileSystem
operator|.
name|getFileStatus
argument_list|(
name|newPartPath
argument_list|)
decl_stmt|;
name|Hive
operator|.
name|trashFiles
argument_list|(
name|newPathFileSystem
argument_list|,
operator|new
name|FileStatus
index|[]
block|{
name|status
block|}
argument_list|,
name|this
operator|.
name|getConf
argument_list|()
argument_list|,
name|isAutoPurge
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|io
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not delete partition directory contents after failed partition creation: "
argument_list|,
name|io
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
comment|// For acid table, add the acid_write event with file list at the time of load itself. But
comment|// it should be done after partition is created.
if|if
condition|(
name|isTxnTable
operator|&&
operator|(
literal|null
operator|!=
name|newFiles
operator|)
condition|)
block|{
name|addWriteNotificationLog
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|newFiles
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|setStatsPropAndAlterPartition
argument_list|(
name|hasFollowingStatsTask
argument_list|,
name|tbl
argument_list|,
name|newTPart
argument_list|,
name|tableSnapshot
argument_list|)
expr_stmt|;
block|}
name|perfLogger
operator|.
name|PerfLogEnd
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|LOAD_PARTITION
argument_list|)
expr_stmt|;
return|return
name|newTPart
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Load Data commands for fullAcid tables write to base_x (if there is overwrite clause) or    * delta_x_x directory - same as any other Acid write.  This method modifies the destPath to add    * this path component.    * @param writeId - write id of the operated table from current transaction (in which this operation is running)    * @param stmtId - see {@link DbTxnManager#getStmtIdAndIncrement()}    * @return appropriately modified path    */
specifier|private
name|Path
name|fixFullAcidPathForLoadData
parameter_list|(
name|LoadFileType
name|loadFileType
parameter_list|,
name|Path
name|destPath
parameter_list|,
name|long
name|writeId
parameter_list|,
name|int
name|stmtId
parameter_list|,
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
switch|switch
condition|(
name|loadFileType
condition|)
block|{
case|case
name|REPLACE_ALL
case|:
name|destPath
operator|=
operator|new
name|Path
argument_list|(
name|destPath
argument_list|,
name|AcidUtils
operator|.
name|baseDir
argument_list|(
name|writeId
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|KEEP_EXISTING
case|:
name|destPath
operator|=
operator|new
name|Path
argument_list|(
name|destPath
argument_list|,
name|AcidUtils
operator|.
name|deltaSubdir
argument_list|(
name|writeId
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|OVERWRITE_EXISTING
case|:
comment|//should not happen here - this is for replication
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unexpected "
operator|+
name|LoadFileType
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|loadFileType
argument_list|)
throw|;
block|}
try|try
block|{
name|FileSystem
name|fs
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|SessionState
operator|.
name|getSessionConf
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|FileUtils
operator|.
name|mkdir
argument_list|(
name|fs
argument_list|,
name|destPath
argument_list|,
name|conf
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|destPath
operator|+
literal|" already exists?!?!"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"load: error while creating "
operator|+
name|destPath
operator|+
literal|";loadFileType="
operator|+
name|loadFileType
argument_list|,
name|e
argument_list|)
throw|;
block|}
return|return
name|destPath
return|;
block|}
specifier|private
name|boolean
name|areEventsForDmlNeeded
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Partition
name|oldPart
parameter_list|)
block|{
comment|// For Acid IUD, add partition is a meta data only operation. So need to add the new files added
comment|// information into the TXN_WRITE_NOTIFICATION_LOG table.
return|return
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|FIRE_EVENTS_FOR_DML
argument_list|)
operator|&&
operator|!
name|tbl
operator|.
name|isTemporary
argument_list|()
operator|&&
operator|(
operator|(
literal|null
operator|!=
name|oldPart
operator|)
operator|||
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|tbl
argument_list|)
operator|)
return|;
block|}
specifier|private
name|void
name|listFilesInsideAcidDirectory
parameter_list|(
name|Path
name|acidDir
parameter_list|,
name|FileSystem
name|srcFs
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
comment|// list out all the files/directory in the path
name|FileStatus
index|[]
name|acidFiles
decl_stmt|;
name|acidFiles
operator|=
name|srcFs
operator|.
name|listStatus
argument_list|(
name|acidDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|acidFiles
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No files added by this query in: "
operator|+
name|acidDir
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|FileStatus
name|acidFile
range|:
name|acidFiles
control|)
block|{
comment|// need to list out only files, ignore folders.
if|if
condition|(
operator|!
name|acidFile
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|newFiles
operator|.
name|add
argument_list|(
name|acidFile
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|listFilesInsideAcidDirectory
argument_list|(
name|acidFile
operator|.
name|getPath
argument_list|()
argument_list|,
name|srcFs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|listFilesCreatedByQuery
parameter_list|(
name|Path
name|loadPath
parameter_list|,
name|long
name|writeId
parameter_list|,
name|int
name|stmtId
parameter_list|,
name|boolean
name|isInsertOverwrite
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|HiveException
block|{
name|Path
name|acidDir
init|=
operator|new
name|Path
argument_list|(
name|loadPath
argument_list|,
name|AcidUtils
operator|.
name|baseOrDeltaSubdir
argument_list|(
name|isInsertOverwrite
argument_list|,
name|writeId
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
name|FileSystem
name|srcFs
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcFs
operator|.
name|exists
argument_list|(
name|acidDir
argument_list|)
operator|&&
name|srcFs
operator|.
name|isDirectory
argument_list|(
name|acidDir
argument_list|)
condition|)
block|{
comment|// list out all the files in the path
name|listFilesInsideAcidDirectory
argument_list|(
name|acidDir
argument_list|,
name|srcFs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"directory does not exist: "
operator|+
name|acidDir
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error listing files"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return;
block|}
specifier|private
name|void
name|setStatsPropAndAlterPartition
parameter_list|(
name|boolean
name|hasFollowingStatsTask
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Partition
name|newTPart
parameter_list|,
name|TableSnapshot
name|tableSnapshot
parameter_list|)
throws|throws
name|MetaException
throws|,
name|TException
block|{
name|EnvironmentContext
name|ec
init|=
operator|new
name|EnvironmentContext
argument_list|()
decl_stmt|;
if|if
condition|(
name|hasFollowingStatsTask
condition|)
block|{
name|ec
operator|.
name|putToProperties
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Altering existing partition "
operator|+
name|newTPart
operator|.
name|getSpec
argument_list|()
argument_list|)
expr_stmt|;
name|getSynchronizedMSC
argument_list|()
operator|.
name|alter_partition
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|newTPart
operator|.
name|getTPartition
argument_list|()
argument_list|,
operator|new
name|EnvironmentContext
argument_list|()
argument_list|,
name|tableSnapshot
operator|==
literal|null
condition|?
operator|-
literal|1
else|:
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
argument_list|,
name|tableSnapshot
operator|==
literal|null
condition|?
literal|null
else|:
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**  * Walk through sub-directory tree to construct list bucketing location map.  *  * @param fSta  * @param fSys  * @param skewedColValueLocationMaps  * @param newPartPath  * @param skewedInfo  * @throws IOException  */
specifier|private
name|void
name|walkDirTree
parameter_list|(
name|FileStatus
name|fSta
parameter_list|,
name|FileSystem
name|fSys
parameter_list|,
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|skewedColValueLocationMaps
parameter_list|,
name|Path
name|newPartPath
parameter_list|,
name|SkewedInfo
name|skewedInfo
parameter_list|)
throws|throws
name|IOException
block|{
comment|/* Base Case. It's leaf. */
if|if
condition|(
operator|!
name|fSta
operator|.
name|isDir
argument_list|()
condition|)
block|{
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Processing LB leaf "
operator|+
name|fSta
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/* construct one location map if not exists. */
name|constructOneLBLocationMap
argument_list|(
name|fSta
argument_list|,
name|skewedColValueLocationMaps
argument_list|,
name|newPartPath
argument_list|,
name|skewedInfo
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* dfs. */
name|FileStatus
index|[]
name|children
init|=
name|fSys
operator|.
name|listStatus
argument_list|(
name|fSta
operator|.
name|getPath
argument_list|()
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
decl_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Processing LB dir "
operator|+
name|fSta
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|walkDirTree
argument_list|(
name|child
argument_list|,
name|fSys
argument_list|,
name|skewedColValueLocationMaps
argument_list|,
name|newPartPath
argument_list|,
name|skewedInfo
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**  * Construct a list bucketing location map  * @param fSta  * @param skewedColValueLocationMaps  * @param newPartPath  * @param skewedInfo  */
specifier|private
name|void
name|constructOneLBLocationMap
parameter_list|(
name|FileStatus
name|fSta
parameter_list|,
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|skewedColValueLocationMaps
parameter_list|,
name|Path
name|newPartPath
parameter_list|,
name|SkewedInfo
name|skewedInfo
parameter_list|)
block|{
name|Path
name|lbdPath
init|=
name|fSta
operator|.
name|getPath
argument_list|()
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|skewedValue
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|lbDirName
init|=
name|FileUtils
operator|.
name|unescapePathName
argument_list|(
name|lbdPath
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|partDirName
init|=
name|FileUtils
operator|.
name|unescapePathName
argument_list|(
name|newPartPath
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|lbDirSuffix
init|=
name|lbDirName
operator|.
name|replace
argument_list|(
name|partDirName
argument_list|,
literal|""
argument_list|)
decl_stmt|;
comment|// TODO: should it rather do a prefix?
if|if
condition|(
name|lbDirSuffix
operator|.
name|startsWith
argument_list|(
name|Path
operator|.
name|SEPARATOR
argument_list|)
condition|)
block|{
name|lbDirSuffix
operator|=
name|lbDirSuffix
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
name|String
index|[]
name|dirNames
init|=
name|lbDirSuffix
operator|.
name|split
argument_list|(
name|Path
operator|.
name|SEPARATOR
argument_list|)
decl_stmt|;
name|int
name|keysFound
init|=
literal|0
decl_stmt|,
name|dirsToTake
init|=
literal|0
decl_stmt|;
name|int
name|colCount
init|=
name|skewedInfo
operator|.
name|getSkewedColNames
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
while|while
condition|(
name|dirsToTake
operator|<
name|dirNames
operator|.
name|length
operator|&&
name|keysFound
operator|<
name|colCount
condition|)
block|{
name|String
name|dirName
init|=
name|dirNames
index|[
name|dirsToTake
operator|++
index|]
decl_stmt|;
comment|// Construct skewed-value to location map except default directory.
comment|// why? query logic knows default-dir structure and don't need to get from map
if|if
condition|(
name|dirName
operator|.
name|equalsIgnoreCase
argument_list|(
name|ListBucketingPrunerUtils
operator|.
name|HIVE_LIST_BUCKETING_DEFAULT_DIR_NAME
argument_list|)
condition|)
block|{
operator|++
name|keysFound
expr_stmt|;
block|}
else|else
block|{
name|String
index|[]
name|kv
init|=
name|dirName
operator|.
name|split
argument_list|(
literal|"="
argument_list|)
decl_stmt|;
if|if
condition|(
name|kv
operator|.
name|length
operator|==
literal|2
condition|)
block|{
name|skewedValue
operator|.
name|add
argument_list|(
name|kv
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
operator|++
name|keysFound
expr_stmt|;
block|}
else|else
block|{
comment|// TODO: we should really probably throw. Keep the existing logic for now.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Skipping unknown directory "
operator|+
name|dirName
operator|+
literal|" when expecting LB keys or default directory (from "
operator|+
name|lbDirName
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
operator|(
name|dirNames
operator|.
name|length
operator|-
name|dirsToTake
operator|)
condition|;
operator|++
name|i
control|)
block|{
name|lbdPath
operator|=
name|lbdPath
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Saving LB location "
operator|+
name|lbdPath
operator|+
literal|" based on "
operator|+
name|colCount
operator|+
literal|" keys and "
operator|+
name|fSta
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|skewedValue
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
operator|&&
operator|(
name|skewedValue
operator|.
name|size
argument_list|()
operator|==
name|colCount
operator|)
operator|&&
operator|!
name|skewedColValueLocationMaps
operator|.
name|containsKey
argument_list|(
name|skewedValue
argument_list|)
condition|)
block|{
name|skewedColValueLocationMaps
operator|.
name|put
argument_list|(
name|skewedValue
argument_list|,
name|lbdPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Construct location map from path    *    * @param newPartPath    * @param skewedInfo    * @return    * @throws IOException    * @throws FileNotFoundException    */
specifier|private
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|constructListBucketingLocationMap
parameter_list|(
name|Path
name|newPartPath
parameter_list|,
name|SkewedInfo
name|skewedInfo
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileNotFoundException
block|{
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|skewedColValueLocationMaps
init|=
operator|new
name|HashMap
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|FileSystem
name|fSys
init|=
name|newPartPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|walkDirTree
argument_list|(
name|fSys
operator|.
name|getFileStatus
argument_list|(
name|newPartPath
argument_list|)
argument_list|,
name|fSys
argument_list|,
name|skewedColValueLocationMaps
argument_list|,
name|newPartPath
argument_list|,
name|skewedInfo
argument_list|)
expr_stmt|;
return|return
name|skewedColValueLocationMaps
return|;
block|}
comment|/**    * Get the valid partitions from the path    * @param numDP number of dynamic partitions    * @param loadPath    * @return Set of valid partitions    * @throws HiveException    */
specifier|private
name|Set
argument_list|<
name|Path
argument_list|>
name|getValidPartitionsInPath
parameter_list|(
name|int
name|numDP
parameter_list|,
name|int
name|numLB
parameter_list|,
name|Path
name|loadPath
parameter_list|,
name|Long
name|writeId
parameter_list|,
name|int
name|stmtId
parameter_list|,
name|boolean
name|isMmTable
parameter_list|,
name|boolean
name|isInsertOverwrite
parameter_list|)
throws|throws
name|HiveException
block|{
name|Set
argument_list|<
name|Path
argument_list|>
name|validPartitions
init|=
operator|new
name|HashSet
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
name|FileSystem
name|fs
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|isMmTable
condition|)
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|leafStatus
init|=
name|HiveStatsUtils
operator|.
name|getFileStatusRecurse
argument_list|(
name|loadPath
argument_list|,
name|numDP
argument_list|,
name|fs
argument_list|)
decl_stmt|;
comment|// Check for empty partitions
for|for
control|(
name|FileStatus
name|s
range|:
name|leafStatus
control|)
block|{
if|if
condition|(
operator|!
name|s
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"partition "
operator|+
name|s
operator|.
name|getPath
argument_list|()
operator|+
literal|" is not a directory!"
argument_list|)
throw|;
block|}
name|Path
name|dpPath
init|=
name|s
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|validPartitions
operator|.
name|add
argument_list|(
name|dpPath
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// The non-MM path only finds new partitions, as it is looking at the temp path.
comment|// To produce the same effect, we will find all the partitions affected by this txn ID.
comment|// Note: we ignore the statement ID here, because it's currently irrelevant for MoveTask
comment|//       where this is used; we always want to load everything; also the only case where
comment|//       we have multiple statements anyway is union.
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Looking for dynamic partitions in {} ({} levels)"
argument_list|,
name|loadPath
argument_list|,
name|numDP
argument_list|)
expr_stmt|;
name|Path
index|[]
name|leafStatus
init|=
name|Utilities
operator|.
name|getMmDirectoryCandidates
argument_list|(
name|fs
argument_list|,
name|loadPath
argument_list|,
name|numDP
argument_list|,
literal|null
argument_list|,
name|writeId
argument_list|,
operator|-
literal|1
argument_list|,
name|conf
argument_list|,
name|isInsertOverwrite
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|p
range|:
name|leafStatus
control|)
block|{
name|Path
name|dpPath
init|=
name|p
operator|.
name|getParent
argument_list|()
decl_stmt|;
comment|// Skip the MM directory that we have found.
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Found DP "
operator|+
name|dpPath
argument_list|)
expr_stmt|;
block|}
name|validPartitions
operator|.
name|add
argument_list|(
name|dpPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|int
name|partsToLoad
init|=
name|validPartitions
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|partsToLoad
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No partition is generated by dynamic partitioning"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|partsToLoad
operator|>
name|conf
operator|.
name|getIntVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Number of dynamic partitions created is "
operator|+
name|partsToLoad
operator|+
literal|", which is more than "
operator|+
name|conf
operator|.
name|getIntVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
argument_list|)
operator|+
literal|". To solve this try to set "
operator|+
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
operator|.
name|varname
operator|+
literal|" to at least "
operator|+
name|partsToLoad
operator|+
literal|'.'
argument_list|)
throw|;
block|}
return|return
name|validPartitions
return|;
block|}
comment|/**    * Given a source directory name of the load path, load all dynamically generated partitions    * into the specified table and return a list of strings that represent the dynamic partition    * paths.    * @param loadPath    * @param tableName    * @param partSpec    * @param loadFileType    * @param numDP number of dynamic partitions    * @param isAcid true if this is an ACID operation    * @param writeId writeId, can be 0 unless isAcid == true    * @return partition map details (PartitionSpec and Partition)    * @throws HiveException    */
specifier|public
name|Map
argument_list|<
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|,
name|Partition
argument_list|>
name|loadDynamicPartitions
parameter_list|(
specifier|final
name|Path
name|loadPath
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|,
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
specifier|final
name|LoadFileType
name|loadFileType
parameter_list|,
specifier|final
name|int
name|numDP
parameter_list|,
specifier|final
name|int
name|numLB
parameter_list|,
specifier|final
name|boolean
name|isAcid
parameter_list|,
specifier|final
name|long
name|writeId
parameter_list|,
specifier|final
name|int
name|stmtId
parameter_list|,
specifier|final
name|boolean
name|hasFollowingStatsTask
parameter_list|,
specifier|final
name|AcidUtils
operator|.
name|Operation
name|operation
parameter_list|,
name|boolean
name|isInsertOverwrite
parameter_list|)
throws|throws
name|HiveException
block|{
name|PerfLogger
name|perfLogger
init|=
name|SessionState
operator|.
name|getPerfLogger
argument_list|()
decl_stmt|;
name|perfLogger
operator|.
name|PerfLogBegin
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|LOAD_DYNAMIC_PARTITIONS
argument_list|)
expr_stmt|;
specifier|final
name|Map
argument_list|<
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|,
name|Partition
argument_list|>
name|partitionsMap
init|=
name|Collections
operator|.
name|synchronizedMap
argument_list|(
operator|new
name|LinkedHashMap
argument_list|<
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|,
name|Partition
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|poolSize
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_LOAD_DYNAMIC_PARTITIONS_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|1
argument_list|)
decl_stmt|;
specifier|final
name|ExecutorService
name|pool
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|poolSize
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"load-dynamic-partitions-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
decl_stmt|;
comment|// Get all valid partition paths and existing partitions for them (if any)
specifier|final
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|validPartitions
init|=
name|getValidPartitionsInPath
argument_list|(
name|numDP
argument_list|,
name|numLB
argument_list|,
name|loadPath
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|,
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|)
argument_list|,
name|isInsertOverwrite
argument_list|)
decl_stmt|;
specifier|final
name|int
name|partsToLoad
init|=
name|validPartitions
operator|.
name|size
argument_list|()
decl_stmt|;
specifier|final
name|AtomicInteger
name|partitionsLoaded
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|inPlaceEligible
init|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"fs.trash.interval"
argument_list|,
literal|0
argument_list|)
operator|<=
literal|0
operator|&&
name|InPlaceUpdate
operator|.
name|canRenderInPlace
argument_list|(
name|conf
argument_list|)
operator|&&
operator|!
name|SessionState
operator|.
name|getConsole
argument_list|()
operator|.
name|getIsSilent
argument_list|()
decl_stmt|;
specifier|final
name|PrintStream
name|ps
init|=
operator|(
name|inPlaceEligible
operator|)
condition|?
name|SessionState
operator|.
name|getConsole
argument_list|()
operator|.
name|getInfoStream
argument_list|()
else|:
literal|null
decl_stmt|;
specifier|final
name|SessionState
name|parentSession
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|futures
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
try|try
block|{
comment|// for each dynamically created DP directory, construct a full partition spec
comment|// and load the partition based on that
specifier|final
name|Map
argument_list|<
name|Long
argument_list|,
name|RawStore
argument_list|>
name|rawStoreMap
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
specifier|final
name|Path
name|partPath
range|:
name|validPartitions
control|)
block|{
comment|// generate a full partition specification
specifier|final
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|fullPartSpec
init|=
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|partSpec
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|Warehouse
operator|.
name|makeSpecFromName
argument_list|(
name|fullPartSpec
argument_list|,
name|partPath
argument_list|,
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|partSpec
operator|.
name|keySet
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|warn
argument_list|(
literal|"Ignoring invalid DP directory "
operator|+
name|partPath
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|futures
operator|.
name|add
argument_list|(
name|pool
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|Exception
block|{
try|try
block|{
comment|// move file would require session details (needCopy() invokes SessionState.get)
name|SessionState
operator|.
name|setCurrentSessionState
argument_list|(
name|parentSession
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"New loading path = "
operator|+
name|partPath
operator|+
literal|" with partSpec "
operator|+
name|fullPartSpec
argument_list|)
expr_stmt|;
comment|// load the partition
name|Partition
name|newPartition
init|=
name|loadPartition
argument_list|(
name|partPath
argument_list|,
name|tbl
argument_list|,
name|fullPartSpec
argument_list|,
name|loadFileType
argument_list|,
literal|true
argument_list|,
name|numLB
operator|>
literal|0
argument_list|,
literal|false
argument_list|,
name|isAcid
argument_list|,
name|hasFollowingStatsTask
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|,
name|isInsertOverwrite
argument_list|)
decl_stmt|;
name|partitionsMap
operator|.
name|put
argument_list|(
name|fullPartSpec
argument_list|,
name|newPartition
argument_list|)
expr_stmt|;
if|if
condition|(
name|inPlaceEligible
condition|)
block|{
synchronized|synchronized
init|(
name|ps
init|)
block|{
name|InPlaceUpdate
operator|.
name|rePositionCursor
argument_list|(
name|ps
argument_list|)
expr_stmt|;
name|partitionsLoaded
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|InPlaceUpdate
operator|.
name|reprintLine
argument_list|(
name|ps
argument_list|,
literal|"Loaded : "
operator|+
name|partitionsLoaded
operator|.
name|get
argument_list|()
operator|+
literal|"/"
operator|+
name|partsToLoad
operator|+
literal|" partitions."
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Add embedded rawstore, so we can cleanup later to avoid memory leak
if|if
condition|(
name|getMSC
argument_list|()
operator|.
name|isLocalMetaStore
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|rawStoreMap
operator|.
name|containsKey
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getId
argument_list|()
argument_list|)
condition|)
block|{
name|rawStoreMap
operator|.
name|put
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getId
argument_list|()
argument_list|,
name|HiveMetaStore
operator|.
name|HMSHandler
operator|.
name|getRawStore
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception when loading partition with parameters "
operator|+
literal|" partPath="
operator|+
name|partPath
operator|+
literal|", "
operator|+
literal|" table="
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|", "
operator|+
literal|" partSpec="
operator|+
name|fullPartSpec
operator|+
literal|", "
operator|+
literal|" loadFileType="
operator|+
name|loadFileType
operator|.
name|toString
argument_list|()
operator|+
literal|", "
operator|+
literal|" listBucketingLevel="
operator|+
name|numLB
operator|+
literal|", "
operator|+
literal|" isAcid="
operator|+
name|isAcid
operator|+
literal|", "
operator|+
literal|" hasFollowingStatsTask="
operator|+
name|hasFollowingStatsTask
argument_list|,
name|t
argument_list|)
expr_stmt|;
throw|throw
name|t
throw|;
block|}
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Number of partitions to be added is "
operator|+
name|futures
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Future
name|future
range|:
name|futures
control|)
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
name|rawStoreMap
operator|.
name|forEach
argument_list|(
parameter_list|(
name|k
parameter_list|,
name|rs
parameter_list|)
lambda|->
name|rs
operator|.
name|shutdown
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cancelling "
operator|+
name|futures
operator|.
name|size
argument_list|()
operator|+
literal|" dynamic loading tasks"
argument_list|)
expr_stmt|;
comment|//cancel other futures
for|for
control|(
name|Future
name|future
range|:
name|futures
control|)
block|{
name|future
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Exception when loading "
operator|+
name|partsToLoad
operator|+
literal|" in table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" with loadPath="
operator|+
name|loadPath
argument_list|,
name|e
argument_list|)
throw|;
block|}
try|try
block|{
if|if
condition|(
name|isAcid
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|partNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partitionsMap
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Partition
name|p
range|:
name|partitionsMap
operator|.
name|values
argument_list|()
control|)
block|{
name|partNames
operator|.
name|add
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|getMSC
argument_list|()
operator|.
name|addDynamicPartitions
argument_list|(
name|parentSession
operator|.
name|getTxnMgr
argument_list|()
operator|.
name|getCurrentTxnId
argument_list|()
argument_list|,
name|writeId
argument_list|,
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
argument_list|,
name|AcidUtils
operator|.
name|toDataOperationType
argument_list|(
name|operation
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded "
operator|+
name|partitionsMap
operator|.
name|size
argument_list|()
operator|+
literal|" partitions"
argument_list|)
expr_stmt|;
name|perfLogger
operator|.
name|PerfLogEnd
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|LOAD_DYNAMIC_PARTITIONS
argument_list|)
expr_stmt|;
return|return
name|partitionsMap
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Exception updating metastore for acid table "
operator|+
name|tableName
operator|+
literal|" with partitions "
operator|+
name|partitionsMap
operator|.
name|values
argument_list|()
argument_list|,
name|te
argument_list|)
throw|;
block|}
block|}
comment|/**    * Load a directory into a Hive Table. - Alters existing content of table with    * the contents of loadPath. - If table does not exist - an exception is    * thrown - files in loadPath are moved into Hive. But the directory itself is    * not removed.    *    * @param loadPath    *          Directory containing files to load into Table    * @param tableName    *          name of table to be loaded.    * @param loadFileType    *          if REPLACE_ALL - replace files in the table,    *          otherwise add files to table (KEEP_EXISTING, OVERWRITE_EXISTING)    * @param isSrcLocal    *          If the source directory is LOCAL    * @param isSkewedStoreAsSubdir    *          if list bucketing enabled    * @param hasFollowingStatsTask    *          if there is any following stats task    * @param isAcidIUDoperation true if this is an ACID based Insert [overwrite]/update/delete    * @param writeId write ID allocated for the current load operation    * @param stmtId statement ID of the current load statement    */
specifier|public
name|void
name|loadTable
parameter_list|(
name|Path
name|loadPath
parameter_list|,
name|String
name|tableName
parameter_list|,
name|LoadFileType
name|loadFileType
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|isSkewedStoreAsSubdir
parameter_list|,
name|boolean
name|isAcidIUDoperation
parameter_list|,
name|boolean
name|hasFollowingStatsTask
parameter_list|,
name|Long
name|writeId
parameter_list|,
name|int
name|stmtId
parameter_list|,
name|boolean
name|isInsertOverwrite
parameter_list|)
throws|throws
name|HiveException
block|{
name|PerfLogger
name|perfLogger
init|=
name|SessionState
operator|.
name|getPerfLogger
argument_list|()
decl_stmt|;
name|perfLogger
operator|.
name|PerfLogBegin
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|LOAD_TABLE
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
init|=
literal|null
decl_stmt|;
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
assert|assert
name|tbl
operator|.
name|getPath
argument_list|()
operator|!=
literal|null
operator|:
literal|"null==getPath() for "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
assert|;
name|boolean
name|isTxnTable
init|=
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
name|boolean
name|isMmTable
init|=
name|AcidUtils
operator|.
name|isInsertOnlyTable
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
name|boolean
name|isFullAcidTable
init|=
name|AcidUtils
operator|.
name|isFullAcidTable
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|FIRE_EVENTS_FOR_DML
argument_list|)
operator|&&
operator|!
name|tbl
operator|.
name|isTemporary
argument_list|()
condition|)
block|{
name|newFiles
operator|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Note: this assumes both paths are qualified; which they are, currently.
if|if
condition|(
operator|(
name|isMmTable
operator|||
name|isFullAcidTable
operator|)
operator|&&
name|loadPath
operator|.
name|equals
argument_list|(
name|tbl
operator|.
name|getPath
argument_list|()
argument_list|)
condition|)
block|{
comment|/**        * some operations on Transactional tables (e.g. Import) write directly to the final location        * and avoid the 'move' operation.  Since MoveTask does other things, setting 'loadPath' to be        * the table/partition path indicates that the 'file move' part of MoveTask is not needed.        */
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|debug
argument_list|(
literal|"not moving "
operator|+
name|loadPath
operator|+
literal|" to "
operator|+
name|tbl
operator|.
name|getPath
argument_list|()
operator|+
literal|" (MM)"
argument_list|)
expr_stmt|;
block|}
comment|//new files list is required only for event notification.
if|if
condition|(
name|newFiles
operator|!=
literal|null
condition|)
block|{
name|listFilesCreatedByQuery
argument_list|(
name|loadPath
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|,
name|isMmTable
condition|?
name|isInsertOverwrite
else|:
literal|false
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Either a non-MM query, or a load into MM table from an external source.
name|Path
name|tblPath
init|=
name|tbl
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|destPath
init|=
name|tblPath
decl_stmt|;
if|if
condition|(
name|isMmTable
condition|)
block|{
assert|assert
operator|!
name|isAcidIUDoperation
assert|;
comment|// We will load into MM directory, and hide previous directories if needed.
name|destPath
operator|=
operator|new
name|Path
argument_list|(
name|destPath
argument_list|,
name|isInsertOverwrite
condition|?
name|AcidUtils
operator|.
name|baseDir
argument_list|(
name|writeId
argument_list|)
else|:
name|AcidUtils
operator|.
name|deltaSubdir
argument_list|(
name|writeId
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|isAcidIUDoperation
operator|&&
name|isFullAcidTable
condition|)
block|{
name|destPath
operator|=
name|fixFullAcidPathForLoadData
argument_list|(
name|loadFileType
argument_list|,
name|destPath
argument_list|,
name|writeId
argument_list|,
name|stmtId
argument_list|,
name|tbl
argument_list|)
expr_stmt|;
block|}
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|debug
argument_list|(
literal|"moving "
operator|+
name|loadPath
operator|+
literal|" to "
operator|+
name|tblPath
operator|+
literal|" (replace = "
operator|+
name|loadFileType
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|perfLogger
operator|.
name|PerfLogBegin
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|FILE_MOVES
argument_list|)
expr_stmt|;
name|boolean
name|isManaged
init|=
name|tbl
operator|.
name|getTableType
argument_list|()
operator|==
name|TableType
operator|.
name|MANAGED_TABLE
decl_stmt|;
if|if
condition|(
name|loadFileType
operator|==
name|LoadFileType
operator|.
name|REPLACE_ALL
operator|&&
operator|!
name|isTxnTable
condition|)
block|{
comment|//for fullAcid we don't want to delete any files even for OVERWRITE see HIVE-14988/HIVE-17361
name|boolean
name|isAutopurge
init|=
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|tbl
operator|.
name|getProperty
argument_list|(
literal|"auto.purge"
argument_list|)
argument_list|)
decl_stmt|;
name|boolean
name|needRecycle
init|=
operator|!
name|tbl
operator|.
name|isTemporary
argument_list|()
operator|&&
name|ReplChangeManager
operator|.
name|isSourceOfReplication
argument_list|(
name|Hive
operator|.
name|get
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|replaceFiles
argument_list|(
name|tblPath
argument_list|,
name|loadPath
argument_list|,
name|destPath
argument_list|,
name|tblPath
argument_list|,
name|conf
argument_list|,
name|isSrcLocal
argument_list|,
name|isAutopurge
argument_list|,
name|newFiles
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|,
name|needRecycle
argument_list|,
name|isManaged
argument_list|)
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|FileSystem
name|fs
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|copyFiles
argument_list|(
name|conf
argument_list|,
name|loadPath
argument_list|,
name|destPath
argument_list|,
name|fs
argument_list|,
name|isSrcLocal
argument_list|,
name|isAcidIUDoperation
argument_list|,
name|loadFileType
operator|==
name|LoadFileType
operator|.
name|OVERWRITE_EXISTING
argument_list|,
name|newFiles
argument_list|,
name|tbl
operator|.
name|getNumBuckets
argument_list|()
operator|>
literal|0
argument_list|,
name|isFullAcidTable
argument_list|,
name|isManaged
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"addFiles: filesystem error in check phase"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|perfLogger
operator|.
name|PerfLogEnd
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|FILE_MOVES
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|getConf
argument_list|()
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVESTATSAUTOGATHER
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
comment|//column stats will be inaccurate
if|if
condition|(
operator|!
name|hasFollowingStatsTask
condition|)
block|{
name|StatsSetupConst
operator|.
name|clearColumnStatsState
argument_list|(
name|tbl
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|isSkewedStoreAsSubdir
condition|)
block|{
name|SkewedInfo
name|skewedInfo
init|=
name|tbl
operator|.
name|getSkewedInfo
argument_list|()
decl_stmt|;
comment|// Construct list bucketing location mappings from sub-directory name.
name|Map
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|,
name|String
argument_list|>
name|skewedColValueLocationMaps
init|=
name|constructListBucketingLocationMap
argument_list|(
name|tbl
operator|.
name|getPath
argument_list|()
argument_list|,
name|skewedInfo
argument_list|)
decl_stmt|;
comment|// Add list bucketing location mappings.
name|skewedInfo
operator|.
name|setSkewedColValueLocationMaps
argument_list|(
name|skewedColValueLocationMaps
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|EnvironmentContext
name|environmentContext
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hasFollowingStatsTask
condition|)
block|{
name|environmentContext
operator|=
operator|new
name|EnvironmentContext
argument_list|()
expr_stmt|;
name|environmentContext
operator|.
name|putToProperties
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
name|alterTable
argument_list|(
name|tbl
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|AcidUtils
operator|.
name|isTransactionalTable
argument_list|(
name|tbl
argument_list|)
condition|)
block|{
name|addWriteNotificationLog
argument_list|(
name|tbl
argument_list|,
literal|null
argument_list|,
name|newFiles
argument_list|,
name|writeId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|fireInsertEvent
argument_list|(
name|tbl
argument_list|,
literal|null
argument_list|,
operator|(
name|loadFileType
operator|==
name|LoadFileType
operator|.
name|REPLACE_ALL
operator|)
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
name|perfLogger
operator|.
name|PerfLogEnd
argument_list|(
literal|"MoveTask"
argument_list|,
name|PerfLogger
operator|.
name|LOAD_TABLE
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates a partition.    *    * @param tbl    *          table for which partition needs to be created    * @param partSpec    *          partition keys and their values    * @return created partition object    * @throws HiveException    *           if table doesn't exist or partition already exists    */
annotation|@
name|VisibleForTesting
specifier|public
name|Partition
name|createPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
init|=
name|Partition
operator|.
name|createMetaPartitionObject
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
name|part
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
else|:
literal|0
argument_list|)
expr_stmt|;
return|return
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|getMSC
argument_list|()
operator|.
name|add_partition
argument_list|(
name|part
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|createPartitions
parameter_list|(
name|AddPartitionDesc
name|addPartitionDesc
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|addPartitionDesc
operator|.
name|getDbName
argument_list|()
argument_list|,
name|addPartitionDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|size
init|=
name|addPartitionDesc
operator|.
name|getPartitionCount
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|in
init|=
operator|new
name|ArrayList
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
argument_list|(
name|size
argument_list|)
decl_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|size
condition|;
operator|++
name|i
control|)
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tmpPart
init|=
name|convertAddSpecToMetaPartition
argument_list|(
name|tbl
argument_list|,
name|addPartitionDesc
operator|.
name|getPartition
argument_list|(
name|i
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmpPart
operator|!=
literal|null
operator|&&
name|tableSnapshot
operator|!=
literal|null
operator|&&
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
operator|>
literal|0
condition|)
block|{
name|tmpPart
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|in
operator|.
name|add
argument_list|(
name|tmpPart
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|out
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|addPartitionDesc
operator|.
name|getReplicationSpec
argument_list|()
operator|.
name|isInReplicationScope
argument_list|()
condition|)
block|{
comment|// TODO: normally, the result is not necessary; might make sense to pass false
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|outPart
range|:
name|getMSC
argument_list|()
operator|.
name|add_partitions
argument_list|(
name|in
argument_list|,
name|addPartitionDesc
operator|.
name|isIfNotExists
argument_list|()
argument_list|,
literal|true
argument_list|)
control|)
block|{
name|out
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|outPart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// For replication add-ptns, we need to follow a insert-if-not-exist, alter-if-exists scenario.
comment|// TODO : ideally, we should push this mechanism to the metastore, because, otherwise, we have
comment|// no choice but to iterate over the partitions here.
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|partsToAdd
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|partsToAlter
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|part_names
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|p
range|:
name|in
control|)
block|{
name|part_names
operator|.
name|add
argument_list|(
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|tbl
operator|.
name|getPartitionKeys
argument_list|()
argument_list|,
name|p
operator|.
name|getValues
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|ptn
init|=
name|getMSC
argument_list|()
operator|.
name|getPartition
argument_list|(
name|addPartitionDesc
operator|.
name|getDbName
argument_list|()
argument_list|,
name|addPartitionDesc
operator|.
name|getTableName
argument_list|()
argument_list|,
name|p
operator|.
name|getValues
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|addPartitionDesc
operator|.
name|getReplicationSpec
argument_list|()
operator|.
name|allowReplacementInto
argument_list|(
name|ptn
operator|.
name|getParameters
argument_list|()
argument_list|)
condition|)
block|{
name|partsToAlter
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
comment|// else ptn already exists, but we do nothing with it.
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|nsoe
parameter_list|)
block|{
comment|// if the object does not exist, we want to add it.
name|partsToAdd
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|outPart
range|:
name|getMSC
argument_list|()
operator|.
name|add_partitions
argument_list|(
name|partsToAdd
argument_list|,
name|addPartitionDesc
operator|.
name|isIfNotExists
argument_list|()
argument_list|,
literal|true
argument_list|)
control|)
block|{
name|out
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|outPart
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|getMSC
argument_list|()
operator|.
name|alter_partitions
argument_list|(
name|addPartitionDesc
operator|.
name|getDbName
argument_list|()
argument_list|,
name|addPartitionDesc
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partsToAlter
argument_list|,
operator|new
name|EnvironmentContext
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|outPart
range|:
name|getMSC
argument_list|()
operator|.
name|getPartitionsByNames
argument_list|(
name|addPartitionDesc
operator|.
name|getDbName
argument_list|()
argument_list|,
name|addPartitionDesc
operator|.
name|getTableName
argument_list|()
argument_list|,
name|part_names
argument_list|)
control|)
block|{
name|out
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|outPart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|out
return|;
block|}
specifier|public
specifier|static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|convertAddSpecToMetaPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|AddPartitionDesc
operator|.
name|OnePartitionDesc
name|addSpec
parameter_list|,
specifier|final
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|HiveException
block|{
name|Path
name|location
init|=
name|addSpec
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|?
operator|new
name|Path
argument_list|(
name|tbl
operator|.
name|getPath
argument_list|()
argument_list|,
name|addSpec
operator|.
name|getLocation
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|location
operator|!=
literal|null
condition|)
block|{
comment|// Ensure that it is a full qualified path (in most cases it will be since tbl.getPath() is full qualified)
name|location
operator|=
operator|new
name|Path
argument_list|(
name|Utilities
operator|.
name|getQualifiedPath
argument_list|(
name|conf
argument_list|,
name|location
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
init|=
name|Partition
operator|.
name|createMetaPartitionObject
argument_list|(
name|tbl
argument_list|,
name|addSpec
operator|.
name|getPartSpec
argument_list|()
argument_list|,
name|location
argument_list|)
decl_stmt|;
if|if
condition|(
name|addSpec
operator|.
name|getPartParams
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|setParameters
argument_list|(
name|addSpec
operator|.
name|getPartParams
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getInputFormat
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|setInputFormat
argument_list|(
name|addSpec
operator|.
name|getInputFormat
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getOutputFormat
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|setOutputFormat
argument_list|(
name|addSpec
operator|.
name|getOutputFormat
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getNumBuckets
argument_list|()
operator|!=
operator|-
literal|1
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|setNumBuckets
argument_list|(
name|addSpec
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|setCols
argument_list|(
name|addSpec
operator|.
name|getCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|addSpec
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getSerdeParams
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setParameters
argument_list|(
name|addSpec
operator|.
name|getSerdeParams
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|setBucketCols
argument_list|(
name|addSpec
operator|.
name|getBucketCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|addSpec
operator|.
name|getSortCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|setSortCols
argument_list|(
name|addSpec
operator|.
name|getSortCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|part
return|;
block|}
specifier|public
name|Partition
name|getPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|boolean
name|forceCreate
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|forceCreate
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Returns partition metadata    *    * @param tbl    *          the partition's table    * @param partSpec    *          partition keys and values    * @param forceCreate    *          if this is true and partition doesn't exist then a partition is    *          created    * @param partPath the path where the partition data is located    * @param inheritTableSpecs whether to copy over the table specs for if/of/serde    * @return result partition object or null if there is no partition    * @throws HiveException    */
specifier|public
name|Partition
name|getPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|boolean
name|forceCreate
parameter_list|,
name|String
name|partPath
parameter_list|,
name|boolean
name|inheritTableSpecs
parameter_list|)
throws|throws
name|HiveException
block|{
name|tbl
operator|.
name|validatePartColumnNames
argument_list|(
name|partSpec
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|tbl
operator|.
name|getPartCols
argument_list|()
control|)
block|{
name|String
name|val
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|// enable dynamic partitioning
if|if
condition|(
operator|(
name|val
operator|==
literal|null
operator|&&
operator|!
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONING
argument_list|)
operator|)
operator|||
operator|(
name|val
operator|!=
literal|null
operator|&&
name|val
operator|.
name|length
argument_list|()
operator|==
literal|0
operator|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"get partition: Value for key "
operator|+
name|field
operator|.
name|getName
argument_list|()
operator|+
literal|" is null or empty"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tpart
operator|=
name|getSynchronizedMSC
argument_list|()
operator|.
name|getPartitionWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|nsoe
parameter_list|)
block|{
comment|// this means no partition exists for the given partition
comment|// key value pairs - thrift cannot handle null return values, hence
comment|// getPartition() throws NoSuchObjectException to indicate null partition
name|tpart
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
try|try
block|{
if|if
condition|(
name|forceCreate
condition|)
block|{
if|if
condition|(
name|tpart
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"creating partition for table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" with partition spec : "
operator|+
name|partSpec
argument_list|)
expr_stmt|;
try|try
block|{
name|tpart
operator|=
name|getSynchronizedMSC
argument_list|()
operator|.
name|appendPartition
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|aee
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Caught already exists exception, trying to alter partition instead"
argument_list|)
expr_stmt|;
name|tpart
operator|=
name|getSynchronizedMSC
argument_list|()
operator|.
name|getPartitionWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
name|alterPartitionSpec
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|tpart
argument_list|,
name|inheritTableSpecs
argument_list|,
name|partPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|CheckJDOException
operator|.
name|isJDODataStoreException
argument_list|(
name|e
argument_list|)
condition|)
block|{
comment|// Using utility method above, so that JDODataStoreException doesn't
comment|// have to be used here. This helps avoid adding jdo dependency for
comment|// hcatalog client uses
name|LOG
operator|.
name|debug
argument_list|(
literal|"Caught JDO exception, trying to alter partition instead"
argument_list|)
expr_stmt|;
name|tpart
operator|=
name|getSynchronizedMSC
argument_list|()
operator|.
name|getPartitionWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpart
operator|==
literal|null
condition|)
block|{
comment|// This means the exception was caused by something other than a race condition
comment|// in creating the partition, since the partition still doesn't exist.
throw|throw
name|e
throw|;
block|}
name|alterPartitionSpec
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|tpart
argument_list|,
name|inheritTableSpecs
argument_list|,
name|partPath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
else|else
block|{
name|alterPartitionSpec
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|tpart
argument_list|,
name|inheritTableSpecs
argument_list|,
name|partPath
argument_list|)
expr_stmt|;
name|fireInsertEvent
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tpart
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
return|;
block|}
specifier|private
name|void
name|alterPartitionSpec
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
parameter_list|,
name|boolean
name|inheritTableSpecs
parameter_list|,
name|String
name|partPath
parameter_list|)
throws|throws
name|HiveException
throws|,
name|InvalidOperationException
block|{
name|alterPartitionSpecInMemory
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|tpart
argument_list|,
name|inheritTableSpecs
argument_list|,
name|partPath
argument_list|)
expr_stmt|;
name|String
name|fullName
init|=
name|tbl
operator|.
name|getTableName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|)
condition|)
block|{
name|fullName
operator|=
name|tbl
operator|.
name|getFullyQualifiedName
argument_list|()
expr_stmt|;
block|}
name|alterPartition
argument_list|(
name|fullName
argument_list|,
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|alterPartitionSpecInMemory
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
parameter_list|,
name|boolean
name|inheritTableSpecs
parameter_list|,
name|String
name|partPath
parameter_list|)
throws|throws
name|HiveException
throws|,
name|InvalidOperationException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"altering partition for table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" with partition spec : "
operator|+
name|partSpec
argument_list|)
expr_stmt|;
if|if
condition|(
name|inheritTableSpecs
condition|)
block|{
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setOutputFormat
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getOutputFormat
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setInputFormat
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getInputFormat
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|tbl
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setParameters
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setBucketCols
argument_list|(
name|tbl
operator|.
name|getBucketCols
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setNumBuckets
argument_list|(
name|tbl
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setSortCols
argument_list|(
name|tbl
operator|.
name|getSortCols
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|partPath
operator|==
literal|null
operator|||
name|partPath
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"new partition path should not be null or empty."
argument_list|)
throw|;
block|}
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setLocation
argument_list|(
name|partPath
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|addWriteNotificationLog
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionSpec
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|,
name|Long
name|writeId
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|FIRE_EVENTS_FOR_DML
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"write notification log is ignored as dml event logging is disabled"
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|tbl
operator|.
name|isTemporary
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"write notification log is ignored as "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" is temporary : "
operator|+
name|writeId
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|newFiles
operator|==
literal|null
operator|||
name|newFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"write notification log is ignored as file list is empty"
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"adding write notification log for operation "
operator|+
name|writeId
operator|+
literal|" table "
operator|+
name|tbl
operator|.
name|getCompleteName
argument_list|()
operator|+
literal|"partition "
operator|+
name|partitionSpec
operator|+
literal|" list of files "
operator|+
name|newFiles
argument_list|)
expr_stmt|;
try|try
block|{
name|FileSystem
name|fileSystem
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Long
name|txnId
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getTxnMgr
argument_list|()
operator|.
name|getCurrentTxnId
argument_list|()
decl_stmt|;
name|InsertEventRequestData
name|insertData
init|=
operator|new
name|InsertEventRequestData
argument_list|()
decl_stmt|;
name|insertData
operator|.
name|setReplace
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|WriteNotificationLogRequest
name|rqst
init|=
operator|new
name|WriteNotificationLogRequest
argument_list|(
name|txnId
argument_list|,
name|writeId
argument_list|,
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|insertData
argument_list|)
decl_stmt|;
name|addInsertFileInformation
argument_list|(
name|newFiles
argument_list|,
name|fileSystem
argument_list|,
name|insertData
argument_list|)
expr_stmt|;
if|if
condition|(
name|partitionSpec
operator|!=
literal|null
operator|&&
operator|!
name|partitionSpec
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|FieldSchema
name|fs
range|:
name|tbl
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
name|rqst
operator|.
name|addToPartitionVals
argument_list|(
name|partitionSpec
operator|.
name|get
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|getSynchronizedMSC
argument_list|()
operator|.
name|addWriteNotificationLog
argument_list|(
name|rqst
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|fireInsertEvent
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionSpec
parameter_list|,
name|boolean
name|replace
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|FIRE_EVENTS_FOR_DML
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Firing dml insert event"
argument_list|)
expr_stmt|;
if|if
condition|(
name|tbl
operator|.
name|isTemporary
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Not firing dml insert event as "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" is temporary"
argument_list|)
expr_stmt|;
return|return;
block|}
try|try
block|{
name|FileSystem
name|fileSystem
init|=
name|tbl
operator|.
name|getDataLocation
argument_list|()
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FireEventRequestData
name|data
init|=
operator|new
name|FireEventRequestData
argument_list|()
decl_stmt|;
name|InsertEventRequestData
name|insertData
init|=
operator|new
name|InsertEventRequestData
argument_list|()
decl_stmt|;
name|insertData
operator|.
name|setReplace
argument_list|(
name|replace
argument_list|)
expr_stmt|;
name|data
operator|.
name|setInsertData
argument_list|(
name|insertData
argument_list|)
expr_stmt|;
if|if
condition|(
name|newFiles
operator|!=
literal|null
operator|&&
operator|!
name|newFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|addInsertFileInformation
argument_list|(
name|newFiles
argument_list|,
name|fileSystem
argument_list|,
name|insertData
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|insertData
operator|.
name|setFilesAdded
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|FireEventRequest
name|rqst
init|=
operator|new
name|FireEventRequest
argument_list|(
literal|true
argument_list|,
name|data
argument_list|)
decl_stmt|;
name|rqst
operator|.
name|setDbName
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|)
expr_stmt|;
name|rqst
operator|.
name|setTableName
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|partitionSpec
operator|!=
literal|null
operator|&&
name|partitionSpec
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|partVals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|partitionSpec
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fs
range|:
name|tbl
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
name|partVals
operator|.
name|add
argument_list|(
name|partitionSpec
operator|.
name|get
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|rqst
operator|.
name|setPartitionVals
argument_list|(
name|partVals
argument_list|)
expr_stmt|;
block|}
name|getSynchronizedMSC
argument_list|()
operator|.
name|fireListenerEvent
argument_list|(
name|rqst
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
specifier|static
name|void
name|addInsertFileInformation
parameter_list|(
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|,
name|FileSystem
name|fileSystem
parameter_list|,
name|InsertEventRequestData
name|insertData
parameter_list|)
throws|throws
name|IOException
block|{
name|LinkedList
argument_list|<
name|Path
argument_list|>
name|directories
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Path
name|p
range|:
name|newFiles
control|)
block|{
if|if
condition|(
name|fileSystem
operator|.
name|isDirectory
argument_list|(
name|p
argument_list|)
condition|)
block|{
if|if
condition|(
name|directories
operator|==
literal|null
condition|)
block|{
name|directories
operator|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
name|directories
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|addInsertNonDirectoryInformation
argument_list|(
name|p
argument_list|,
name|fileSystem
argument_list|,
name|insertData
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|directories
operator|==
literal|null
condition|)
block|{
return|return;
block|}
comment|// We don't expect any nesting in most cases, or a lot of it if it is present; union and LB
comment|// are some examples where we would have 1, or few, levels respectively.
while|while
condition|(
operator|!
name|directories
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Path
name|dir
init|=
name|directories
operator|.
name|poll
argument_list|()
decl_stmt|;
name|FileStatus
index|[]
name|contents
init|=
name|fileSystem
operator|.
name|listStatus
argument_list|(
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|contents
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|FileStatus
name|status
range|:
name|contents
control|)
block|{
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|directories
operator|.
name|add
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|addInsertNonDirectoryInformation
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|,
name|fileSystem
argument_list|,
name|insertData
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|void
name|addInsertNonDirectoryInformation
parameter_list|(
name|Path
name|p
parameter_list|,
name|FileSystem
name|fileSystem
parameter_list|,
name|InsertEventRequestData
name|insertData
parameter_list|)
throws|throws
name|IOException
block|{
name|insertData
operator|.
name|addToFilesAdded
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|FileChecksum
name|cksum
init|=
name|fileSystem
operator|.
name|getFileChecksum
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|String
name|acidDirPath
init|=
name|AcidUtils
operator|.
name|getFirstLevelAcidDirPath
argument_list|(
name|p
operator|.
name|getParent
argument_list|()
argument_list|,
name|fileSystem
argument_list|)
decl_stmt|;
comment|// File checksum is not implemented for local filesystem (RawLocalFileSystem)
if|if
condition|(
name|cksum
operator|!=
literal|null
condition|)
block|{
name|String
name|checksumString
init|=
name|StringUtils
operator|.
name|byteToHexString
argument_list|(
name|cksum
operator|.
name|getBytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|cksum
operator|.
name|getLength
argument_list|()
argument_list|)
decl_stmt|;
name|insertData
operator|.
name|addToFilesAddedChecksum
argument_list|(
name|checksumString
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Add an empty checksum string for filesystems that don't generate one
name|insertData
operator|.
name|addToFilesAddedChecksum
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|// acid dir will be present only for acid write operations.
if|if
condition|(
name|acidDirPath
operator|!=
literal|null
condition|)
block|{
name|insertData
operator|.
name|addToSubDirectoryList
argument_list|(
name|acidDirPath
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|boolean
name|dropPartition
parameter_list|(
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|part_vals
parameter_list|,
name|boolean
name|deleteData
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
return|return
name|dropPartition
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|part_vals
argument_list|,
name|deleteData
argument_list|)
return|;
block|}
specifier|public
name|boolean
name|dropPartition
parameter_list|(
name|String
name|db_name
parameter_list|,
name|String
name|tbl_name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|part_vals
parameter_list|,
name|boolean
name|deleteData
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|dropPartition
argument_list|(
name|db_name
argument_list|,
name|tbl_name
argument_list|,
name|part_vals
argument_list|,
name|PartitionDropOptions
operator|.
name|instance
argument_list|()
operator|.
name|deleteData
argument_list|(
name|deleteData
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|boolean
name|dropPartition
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|PartitionDropOptions
name|options
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|dropPartition
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partVals
argument_list|,
name|options
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition or table doesn't exist."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * drop the partitions specified as directory names associated with the table.    *    * @param table object for which partition is needed    * @param partDirNames partition directories that need to be dropped    * @param deleteData whether data should be deleted from file system    * @param ifExists check for existence before attempting delete    *    * @return list of partition objects that were deleted    *    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|dropPartitions
parameter_list|(
name|Table
name|table
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partDirNames
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ifExists
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// partitions to be dropped in this batch
name|List
argument_list|<
name|DropTableDesc
operator|.
name|PartSpec
argument_list|>
name|partSpecs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partDirNames
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// parts of the partition
name|String
index|[]
name|parts
init|=
literal|null
decl_stmt|;
comment|// Expression splits of each part of the partition
name|String
index|[]
name|partExprParts
init|=
literal|null
decl_stmt|;
comment|// Column Types of all partitioned columns.  Used for generating partition specification
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|colTypes
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fs
range|:
name|table
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
name|colTypes
operator|.
name|put
argument_list|(
name|fs
operator|.
name|getName
argument_list|()
argument_list|,
name|fs
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Key to be used to save the partition to be dropped in partSpecs
name|int
name|partSpecKey
init|=
literal|0
decl_stmt|;
for|for
control|(
name|String
name|partDir
range|:
name|partDirNames
control|)
block|{
comment|// The expression to identify the partition to be dropped
name|ExprNodeGenericFuncDesc
name|expr
init|=
literal|null
decl_stmt|;
comment|// Split by "/" to identify partition parts
name|parts
operator|=
name|partDir
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
comment|// Loop through the partitions and form the expression
for|for
control|(
name|String
name|part
range|:
name|parts
control|)
block|{
comment|// Split the partition predicate to identify column and value
name|partExprParts
operator|=
name|part
operator|.
name|split
argument_list|(
literal|"="
argument_list|)
expr_stmt|;
comment|// Only two elements expected in partExprParts partition column name and partition value
assert|assert
name|partExprParts
operator|.
name|length
operator|==
literal|2
assert|;
comment|// Partition Column
name|String
name|partCol
init|=
name|partExprParts
index|[
literal|0
index|]
decl_stmt|;
comment|// Column Type
name|PrimitiveTypeInfo
name|pti
init|=
name|TypeInfoFactory
operator|.
name|getPrimitiveTypeInfo
argument_list|(
name|colTypes
operator|.
name|get
argument_list|(
name|partCol
argument_list|)
argument_list|)
decl_stmt|;
comment|// Form the expression node corresponding to column
name|ExprNodeColumnDesc
name|column
init|=
operator|new
name|ExprNodeColumnDesc
argument_list|(
name|pti
argument_list|,
name|partCol
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// Build the expression based on the partition predicate
name|ExprNodeGenericFuncDesc
name|op
init|=
name|makeBinaryPredicate
argument_list|(
literal|"="
argument_list|,
name|column
argument_list|,
operator|new
name|ExprNodeConstantDesc
argument_list|(
name|pti
argument_list|,
name|partExprParts
index|[
literal|1
index|]
argument_list|)
argument_list|)
decl_stmt|;
comment|// the multiple parts to partition predicate are joined using and
name|expr
operator|=
operator|(
name|expr
operator|==
literal|null
operator|)
condition|?
name|op
else|:
name|makeBinaryPredicate
argument_list|(
literal|"and"
argument_list|,
name|expr
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
comment|// Add the expression to partition specification
name|partSpecs
operator|.
name|add
argument_list|(
operator|new
name|DropTableDesc
operator|.
name|PartSpec
argument_list|(
name|expr
argument_list|,
name|partSpecKey
argument_list|)
argument_list|)
expr_stmt|;
comment|// Increment dropKey to get a new key for hash map
operator|++
name|partSpecKey
expr_stmt|;
block|}
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|table
operator|.
name|getFullyQualifiedName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|dropPartitions
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|partSpecs
argument_list|,
name|deleteData
argument_list|,
name|ifExists
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|dropPartitions
parameter_list|(
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|DropTableDesc
operator|.
name|PartSpec
argument_list|>
name|partSpecs
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ifExists
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
return|return
name|dropPartitions
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|partSpecs
argument_list|,
name|deleteData
argument_list|,
name|ifExists
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|dropPartitions
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|DropTableDesc
operator|.
name|PartSpec
argument_list|>
name|partSpecs
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ifExists
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|dropPartitions
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|partSpecs
argument_list|,
name|PartitionDropOptions
operator|.
name|instance
argument_list|()
operator|.
name|deleteData
argument_list|(
name|deleteData
argument_list|)
operator|.
name|ifExists
argument_list|(
name|ifExists
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|dropPartitions
parameter_list|(
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|DropTableDesc
operator|.
name|PartSpec
argument_list|>
name|partSpecs
parameter_list|,
name|PartitionDropOptions
name|dropOptions
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
return|return
name|dropPartitions
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|partSpecs
argument_list|,
name|dropOptions
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|dropPartitions
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|DropTableDesc
operator|.
name|PartSpec
argument_list|>
name|partSpecs
parameter_list|,
name|PartitionDropOptions
name|dropOptions
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|ObjectPair
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|partExprs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partSpecs
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|DropTableDesc
operator|.
name|PartSpec
name|partSpec
range|:
name|partSpecs
control|)
block|{
name|partExprs
operator|.
name|add
argument_list|(
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|utils
operator|.
name|ObjectPair
argument_list|<>
argument_list|(
name|partSpec
operator|.
name|getPrefixLength
argument_list|()
argument_list|,
name|SerializationUtilities
operator|.
name|serializeExpressionToKryo
argument_list|(
name|partSpec
operator|.
name|getPartSpec
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|dropPartitions
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|partExprs
argument_list|,
name|dropOptions
argument_list|)
decl_stmt|;
return|return
name|convertFromMetastore
argument_list|(
name|tbl
argument_list|,
name|tParts
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition or table doesn't exist."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionNames
parameter_list|(
name|String
name|tblName
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
return|return
name|getPartitionNames
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|max
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionNames
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
literal|null
decl_stmt|;
try|try
block|{
name|names
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionNames
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|max
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|names
return|;
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionNames
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
literal|null
decl_stmt|;
name|Table
name|t
init|=
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
name|MetaStoreUtils
operator|.
name|getPvals
argument_list|(
name|t
operator|.
name|getPartCols
argument_list|()
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
try|try
block|{
name|names
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionNames
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|pvals
argument_list|,
name|max
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|names
return|;
block|}
comment|/**    * get all the partitions that the table has    *    * @param tbl    *          object for which partition is needed    * @return list of partition objects    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitions
parameter_list|(
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
decl_stmt|;
try|try
block|{
name|tParts
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|tParts
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|parts
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|parts
return|;
block|}
else|else
block|{
name|Partition
name|part
init|=
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|parts
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
return|return
name|parts
return|;
block|}
block|}
comment|/**    * Get all the partitions; unlike {@link #getPartitions(Table)}, does not include auth.    * @param tbl table for which partitions are needed    * @return list of partition objects    */
specifier|public
name|Set
argument_list|<
name|Partition
argument_list|>
name|getAllPartitionsOf
parameter_list|(
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
return|return
name|Sets
operator|.
name|newHashSet
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|)
argument_list|)
return|;
block|}
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
decl_stmt|;
try|try
block|{
name|tParts
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitions
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|Set
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
operator|new
name|LinkedHashSet
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|tParts
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|parts
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|parts
return|;
block|}
comment|/**    * get all the partitions of the table that matches the given partial    * specification. partition columns whose value is can be anything should be    * an empty string.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @param limit number of partitions to return    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitions
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partialPartSpec
parameter_list|,
name|short
name|limit
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|TABLE_NOT_PARTITIONED
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|partialPvals
init|=
name|MetaStoreUtils
operator|.
name|getPvals
argument_list|(
name|tbl
operator|.
name|getPartCols
argument_list|()
argument_list|,
name|partialPartSpec
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|partitions
init|=
literal|null
decl_stmt|;
try|try
block|{
name|partitions
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partialPvals
argument_list|,
name|limit
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|qlPartitions
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|p
range|:
name|partitions
control|)
block|{
name|qlPartitions
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|qlPartitions
return|;
block|}
comment|/**    * get all the partitions of the table that matches the given partial    * specification. partition columns whose value is can be anything should be    * an empty string.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitions
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partialPartSpec
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getPartitions
argument_list|(
name|tbl
argument_list|,
name|partialPartSpec
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
return|;
block|}
comment|/**    * get all the partitions of the table that matches the given partial    * specification. partition columns whose value is can be anything should be    * an empty string.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @param partialPartSpec    *          partial partition specification (some subpartitions can be empty).    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsByNames
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partialPartSpec
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|TABLE_NOT_PARTITIONED
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
name|getPartitionNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partialPartSpec
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|getPartitionsByNames
argument_list|(
name|tbl
argument_list|,
name|names
argument_list|)
decl_stmt|;
return|return
name|partitions
return|;
block|}
comment|/**    * Get all partitions of the table that matches the list of given partition names.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @param partNames    *          list of partition names    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsByNames
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|TABLE_NOT_PARTITIONED
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|partNames
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|batchSize
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_BATCH_RETRIEVE_MAX
argument_list|)
decl_stmt|;
comment|// TODO: might want to increase the default batch size. 1024 is viable; MS gets OOM if too high.
name|int
name|nParts
init|=
name|partNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|nBatches
init|=
name|nParts
operator|/
name|batchSize
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nBatches
condition|;
operator|++
name|i
control|)
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|getPartitionsByNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|i
operator|*
name|batchSize
argument_list|,
operator|(
name|i
operator|+
literal|1
operator|)
operator|*
name|batchSize
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|tParts
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|partitions
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|nParts
operator|>
name|nBatches
operator|*
name|batchSize
condition|)
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|getPartitionsByNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|nBatches
operator|*
name|batchSize
argument_list|,
name|nParts
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|tParts
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|partitions
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|partitions
return|;
block|}
comment|/**    * Get a list of Partitions by filter.    * @param tbl The table containing the partitions.    * @param filter A string represent partition predicates.    * @return a list of partitions satisfying the partition predicates.    * @throws HiveException    * @throws MetaException    * @throws NoSuchObjectException    * @throws TException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsByFilter
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|String
name|filter
parameter_list|)
throws|throws
name|HiveException
throws|,
name|MetaException
throws|,
name|NoSuchObjectException
throws|,
name|TException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|ErrorMsg
operator|.
name|TABLE_NOT_PARTITIONED
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsByFilter
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|filter
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
return|return
name|convertFromMetastore
argument_list|(
name|tbl
argument_list|,
name|tParts
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|List
argument_list|<
name|Partition
argument_list|>
name|convertFromMetastore
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|partitions
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|partitions
operator|==
literal|null
condition|)
block|{
return|return
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
return|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|partitions
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tPart
range|:
name|partitions
control|)
block|{
name|results
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tPart
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
comment|/**    * Get a list of Partitions by expr.    * @param tbl The table containing the partitions.    * @param expr A serialized expression for partition predicates.    * @param conf Hive config.    * @param result the resulting list of partitions    * @return whether the resulting list contains partitions which may or may not match the expr    */
specifier|public
name|boolean
name|getPartitionsByExpr
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|ExprNodeGenericFuncDesc
name|expr
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|List
argument_list|<
name|Partition
argument_list|>
name|result
parameter_list|)
throws|throws
name|HiveException
throws|,
name|TException
block|{
assert|assert
name|result
operator|!=
literal|null
assert|;
name|byte
index|[]
name|exprBytes
init|=
name|SerializationUtilities
operator|.
name|serializeExpressionToKryo
argument_list|(
name|expr
argument_list|)
decl_stmt|;
name|String
name|defaultPartitionName
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|DEFAULTPARTITIONNAME
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|msParts
init|=
operator|new
name|ArrayList
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
name|boolean
name|hasUnknownParts
init|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsByExpr
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|exprBytes
argument_list|,
name|defaultPartitionName
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|,
name|msParts
argument_list|)
decl_stmt|;
name|result
operator|.
name|addAll
argument_list|(
name|convertFromMetastore
argument_list|(
name|tbl
argument_list|,
name|msParts
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|hasUnknownParts
return|;
block|}
comment|/**    * Get a number of Partitions by filter.    * @param tbl The table containing the partitions.    * @param filter A string represent partition predicates.    * @return the number of partitions satisfying the partition predicates.    * @throws HiveException    * @throws MetaException    * @throws NoSuchObjectException    * @throws TException    */
specifier|public
name|int
name|getNumPartitionsByFilter
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|String
name|filter
parameter_list|)
throws|throws
name|HiveException
throws|,
name|MetaException
throws|,
name|NoSuchObjectException
throws|,
name|TException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition spec should only be supplied for a "
operator|+
literal|"partitioned table"
argument_list|)
throw|;
block|}
name|int
name|numParts
init|=
name|getMSC
argument_list|()
operator|.
name|getNumPartitionsByFilter
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|filter
argument_list|)
decl_stmt|;
return|return
name|numParts
return|;
block|}
specifier|public
name|void
name|validatePartitionNameCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|validatePartitionNameCharacters
argument_list|(
name|partVals
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createRole
parameter_list|(
name|String
name|roleName
parameter_list|,
name|String
name|ownerName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|create_role
argument_list|(
operator|new
name|Role
argument_list|(
name|roleName
argument_list|,
operator|-
literal|1
argument_list|,
name|ownerName
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropRole
parameter_list|(
name|String
name|roleName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|drop_role
argument_list|(
name|roleName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all existing role names.    *    * @return List of role names.    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllRoleNames
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|listRoleNames
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|RolePrincipalGrant
argument_list|>
name|getRoleGrantInfoForPrincipal
parameter_list|(
name|String
name|principalName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|GetRoleGrantsForPrincipalRequest
name|req
init|=
operator|new
name|GetRoleGrantsForPrincipalRequest
argument_list|(
name|principalName
argument_list|,
name|principalType
argument_list|)
decl_stmt|;
name|GetRoleGrantsForPrincipalResponse
name|resp
init|=
name|getMSC
argument_list|()
operator|.
name|get_role_grants_for_principal
argument_list|(
name|req
argument_list|)
decl_stmt|;
return|return
name|resp
operator|.
name|getPrincipalGrants
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|grantRole
parameter_list|(
name|String
name|roleName
parameter_list|,
name|String
name|userName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|,
name|String
name|grantor
parameter_list|,
name|PrincipalType
name|grantorType
parameter_list|,
name|boolean
name|grantOption
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|grant_role
argument_list|(
name|roleName
argument_list|,
name|userName
argument_list|,
name|principalType
argument_list|,
name|grantor
argument_list|,
name|grantorType
argument_list|,
name|grantOption
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|revokeRole
parameter_list|(
name|String
name|roleName
parameter_list|,
name|String
name|userName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|,
name|boolean
name|grantOption
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|revoke_role
argument_list|(
name|roleName
argument_list|,
name|userName
argument_list|,
name|principalType
argument_list|,
name|grantOption
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|Role
argument_list|>
name|listRoles
parameter_list|(
name|String
name|userName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|list_roles
argument_list|(
name|userName
argument_list|,
name|principalType
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param objectType    *          hive object type    * @param db_name    *          database name    * @param table_name    *          table name    * @param part_values    *          partition values    * @param column_name    *          column name    * @param user_name    *          user name    * @param group_names    *          group names    * @return the privilege set    * @throws HiveException    */
specifier|public
name|PrincipalPrivilegeSet
name|get_privilege_set
parameter_list|(
name|HiveObjectType
name|objectType
parameter_list|,
name|String
name|db_name
parameter_list|,
name|String
name|table_name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|part_values
parameter_list|,
name|String
name|column_name
parameter_list|,
name|String
name|user_name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|group_names
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|HiveObjectRef
name|hiveObj
init|=
operator|new
name|HiveObjectRef
argument_list|(
name|objectType
argument_list|,
name|db_name
argument_list|,
name|table_name
argument_list|,
name|part_values
argument_list|,
name|column_name
argument_list|)
decl_stmt|;
return|return
name|getMSC
argument_list|()
operator|.
name|get_privilege_set
argument_list|(
name|hiveObj
argument_list|,
name|user_name
argument_list|,
name|group_names
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param objectType    *          hive object type    * @param principalName    * @param principalType    * @param dbName    * @param tableName    * @param partValues    * @param columnName    * @return list of privileges    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|HiveObjectPrivilege
argument_list|>
name|showPrivilegeGrant
parameter_list|(
name|HiveObjectType
name|objectType
parameter_list|,
name|String
name|principalName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partValues
parameter_list|,
name|String
name|columnName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|HiveObjectRef
name|hiveObj
init|=
operator|new
name|HiveObjectRef
argument_list|(
name|objectType
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partValues
argument_list|,
name|columnName
argument_list|)
decl_stmt|;
return|return
name|getMSC
argument_list|()
operator|.
name|list_privileges
argument_list|(
name|principalName
argument_list|,
name|principalType
argument_list|,
name|hiveObj
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|void
name|copyFiles
parameter_list|(
specifier|final
name|HiveConf
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|destFs
parameter_list|,
name|FileStatus
index|[]
name|srcs
parameter_list|,
specifier|final
name|FileSystem
name|srcFs
parameter_list|,
specifier|final
name|Path
name|destf
parameter_list|,
specifier|final
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|isOverwrite
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|,
name|boolean
name|acidRename
parameter_list|,
name|boolean
name|isManaged
parameter_list|)
throws|throws
name|HiveException
block|{
specifier|final
name|HdfsUtils
operator|.
name|HadoopFileStatus
name|fullDestStatus
decl_stmt|;
try|try
block|{
name|fullDestStatus
operator|=
operator|new
name|HdfsUtils
operator|.
name|HadoopFileStatus
argument_list|(
name|conf
argument_list|,
name|destFs
argument_list|,
name|destf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e1
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e1
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fullDestStatus
operator|.
name|getFileStatus
argument_list|()
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|destf
operator|+
literal|" is not a directory."
argument_list|)
throw|;
block|}
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|ObjectPair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
argument_list|>
name|futures
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|ExecutorService
name|pool
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_MOVE_FILES_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|25
argument_list|)
operator|>
literal|0
condition|?
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_MOVE_FILES_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|25
argument_list|)
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"Move-Thread-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
comment|// For ACID non-bucketed case, the filenames have to be in the format consistent with INSERT/UPDATE/DELETE Ops,
comment|// i.e, like 000000_0, 000001_0_copy_1, 000002_0.gz etc.
comment|// The extension is only maintained for files which are compressed.
name|int
name|taskId
init|=
literal|0
decl_stmt|;
comment|// Sort the files
name|Arrays
operator|.
name|sort
argument_list|(
name|srcs
argument_list|)
expr_stmt|;
name|String
name|configuredOwner
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_LOAD_DATA_OWNER
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|src
range|:
name|srcs
control|)
block|{
name|FileStatus
index|[]
name|files
decl_stmt|;
if|if
condition|(
name|src
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
try|try
block|{
name|files
operator|=
name|srcFs
operator|.
name|listStatus
argument_list|(
name|src
operator|.
name|getPath
argument_list|()
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
literal|null
operator|!=
name|pool
condition|)
block|{
name|pool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|files
operator|=
operator|new
name|FileStatus
index|[]
block|{
name|src
block|}
expr_stmt|;
block|}
specifier|final
name|SessionState
name|parentSession
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
comment|// Sort the files
name|Arrays
operator|.
name|sort
argument_list|(
name|files
argument_list|)
expr_stmt|;
for|for
control|(
specifier|final
name|FileStatus
name|srcFile
range|:
name|files
control|)
block|{
specifier|final
name|Path
name|srcP
init|=
name|srcFile
operator|.
name|getPath
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|needToCopy
init|=
name|needToCopy
argument_list|(
name|srcP
argument_list|,
name|destf
argument_list|,
name|srcFs
argument_list|,
name|destFs
argument_list|,
name|configuredOwner
argument_list|,
name|isManaged
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|isRenameAllowed
init|=
operator|!
name|needToCopy
operator|&&
operator|!
name|isSrcLocal
decl_stmt|;
specifier|final
name|String
name|msg
init|=
literal|"Unable to move source "
operator|+
name|srcP
operator|+
literal|" to destination "
operator|+
name|destf
decl_stmt|;
comment|// If we do a rename for a non-local file, we will be transfering the original
comment|// file permissions from source to the destination. Else, in case of mvFile() where we
comment|// copy from source to destination, we will inherit the destination's parent group ownership.
if|if
condition|(
literal|null
operator|==
name|pool
condition|)
block|{
try|try
block|{
name|Path
name|destPath
init|=
name|mvFile
argument_list|(
name|conf
argument_list|,
name|srcFs
argument_list|,
name|srcP
argument_list|,
name|destFs
argument_list|,
name|destf
argument_list|,
name|isSrcLocal
argument_list|,
name|isOverwrite
argument_list|,
name|isRenameAllowed
argument_list|,
name|acidRename
condition|?
name|taskId
operator|++
else|:
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|!=
name|newFiles
condition|)
block|{
name|newFiles
operator|.
name|add
argument_list|(
name|destPath
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|getHiveException
argument_list|(
name|e
argument_list|,
name|msg
argument_list|,
literal|"Failed to move: {}"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|// future only takes final or seemingly final values. Make a final copy of taskId
specifier|final
name|int
name|finalTaskId
init|=
name|acidRename
condition|?
name|taskId
operator|++
else|:
operator|-
literal|1
decl_stmt|;
name|futures
operator|.
name|add
argument_list|(
name|pool
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|ObjectPair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|ObjectPair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
name|call
parameter_list|()
throws|throws
name|HiveException
block|{
name|SessionState
operator|.
name|setCurrentSessionState
argument_list|(
name|parentSession
argument_list|)
expr_stmt|;
try|try
block|{
name|Path
name|destPath
init|=
name|mvFile
argument_list|(
name|conf
argument_list|,
name|srcFs
argument_list|,
name|srcP
argument_list|,
name|destFs
argument_list|,
name|destf
argument_list|,
name|isSrcLocal
argument_list|,
name|isOverwrite
argument_list|,
name|isRenameAllowed
argument_list|,
name|finalTaskId
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|!=
name|newFiles
condition|)
block|{
name|newFiles
operator|.
name|add
argument_list|(
name|destPath
argument_list|)
expr_stmt|;
block|}
return|return
name|ObjectPair
operator|.
name|create
argument_list|(
name|srcP
argument_list|,
name|destPath
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|getHiveException
argument_list|(
name|e
argument_list|,
name|msg
argument_list|)
throw|;
block|}
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
literal|null
operator|!=
name|pool
condition|)
block|{
name|pool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|Future
argument_list|<
name|ObjectPair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
name|ObjectPair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
name|pair
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moved src: {}, to dest: {}"
argument_list|,
name|pair
operator|.
name|getFirst
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|pair
operator|.
name|getSecond
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|handlePoolException
argument_list|(
name|pool
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
specifier|private
specifier|static
name|boolean
name|isSubDir
parameter_list|(
name|Path
name|srcf
parameter_list|,
name|Path
name|destf
parameter_list|,
name|FileSystem
name|srcFs
parameter_list|,
name|FileSystem
name|destFs
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|)
block|{
if|if
condition|(
name|srcf
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"The source path is null for isSubDir method."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|String
name|fullF1
init|=
name|getQualifiedPathWithoutSchemeAndAuthority
argument_list|(
name|srcf
argument_list|,
name|srcFs
argument_list|)
operator|.
name|toString
argument_list|()
operator|+
name|Path
operator|.
name|SEPARATOR
decl_stmt|;
name|String
name|fullF2
init|=
name|getQualifiedPathWithoutSchemeAndAuthority
argument_list|(
name|destf
argument_list|,
name|destFs
argument_list|)
operator|.
name|toString
argument_list|()
operator|+
name|Path
operator|.
name|SEPARATOR
decl_stmt|;
name|boolean
name|isInTest
init|=
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|srcFs
operator|.
name|getConf
argument_list|()
argument_list|,
name|ConfVars
operator|.
name|HIVE_IN_TEST
argument_list|)
decl_stmt|;
comment|// In the automation, the data warehouse is the local file system based.
name|LOG
operator|.
name|debug
argument_list|(
literal|"The source path is "
operator|+
name|fullF1
operator|+
literal|" and the destination path is "
operator|+
name|fullF2
argument_list|)
expr_stmt|;
if|if
condition|(
name|isInTest
condition|)
block|{
return|return
name|fullF1
operator|.
name|startsWith
argument_list|(
name|fullF2
argument_list|)
return|;
block|}
comment|// schema is diff, return false
name|String
name|schemaSrcf
init|=
name|srcf
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
decl_stmt|;
name|String
name|schemaDestf
init|=
name|destf
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
decl_stmt|;
comment|// if the schemaDestf is null, it means the destination is not in the local file system
if|if
condition|(
name|schemaDestf
operator|==
literal|null
operator|&&
name|isSrcLocal
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"The source file is in the local while the dest not."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// If both schema information are provided, they should be the same.
if|if
condition|(
name|schemaSrcf
operator|!=
literal|null
operator|&&
name|schemaDestf
operator|!=
literal|null
operator|&&
operator|!
name|schemaSrcf
operator|.
name|equals
argument_list|(
name|schemaDestf
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"The source path's schema is "
operator|+
name|schemaSrcf
operator|+
literal|" and the destination path's schema is "
operator|+
name|schemaDestf
operator|+
literal|"."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"The source path is "
operator|+
name|fullF1
operator|+
literal|" and the destination path is "
operator|+
name|fullF2
argument_list|)
expr_stmt|;
return|return
name|fullF1
operator|.
name|startsWith
argument_list|(
name|fullF2
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|Path
name|getQualifiedPathWithoutSchemeAndAuthority
parameter_list|(
name|Path
name|srcf
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
block|{
name|Path
name|currentWorkingDir
init|=
name|fs
operator|.
name|getWorkingDirectory
argument_list|()
decl_stmt|;
name|Path
name|path
init|=
name|srcf
operator|.
name|makeQualified
argument_list|(
name|srcf
operator|.
name|toUri
argument_list|()
argument_list|,
name|currentWorkingDir
argument_list|)
decl_stmt|;
return|return
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getPathWithoutSchemeAndAuthority
argument_list|(
name|path
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
name|getPathName
parameter_list|(
name|int
name|taskId
parameter_list|)
block|{
return|return
name|Utilities
operator|.
name|replaceTaskId
argument_list|(
literal|"000000"
argument_list|,
name|taskId
argument_list|)
operator|+
literal|"_0"
return|;
block|}
comment|/**    *<p>    *   Moves a file from one {@link Path} to another. If {@code isRenameAllowed} is true then the    *   {@link FileSystem#rename(Path, Path)} method is used to move the file. If its false then the data is copied, if    *   {@code isSrcLocal} is true then the {@link FileSystem#copyFromLocalFile(Path, Path)} method is used, else    *   {@link FileUtils#copy(FileSystem, Path, FileSystem, Path, boolean, boolean, HiveConf)} is used.    *</p>    *    *<p>    *   If the destination file already exists, then {@code _copy_[counter]} is appended to the file name, where counter    *   is an integer starting from 1.    *</p>    *    * @param conf the {@link HiveConf} to use if copying data    * @param sourceFs the {@link FileSystem} where the source file exists    * @param sourcePath the {@link Path} to move    * @param destFs the {@link FileSystem} to move the file to    * @param destDirPath the {@link Path} to move the file to    * @param isSrcLocal if the source file is on the local filesystem    * @param isOverwrite if true, then overwrite destination file if exist else make a duplicate copy    * @param isRenameAllowed true if the data should be renamed and not copied, false otherwise    *    * @return the {@link Path} the source file was moved to    *    * @throws IOException if there was an issue moving the file    */
specifier|private
specifier|static
name|Path
name|mvFile
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|FileSystem
name|sourceFs
parameter_list|,
name|Path
name|sourcePath
parameter_list|,
name|FileSystem
name|destFs
parameter_list|,
name|Path
name|destDirPath
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|isOverwrite
parameter_list|,
name|boolean
name|isRenameAllowed
parameter_list|,
name|int
name|taskId
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Strip off the file type, if any so we don't make:
comment|// 000000_0.gz -> 000000_0.gz_copy_1
specifier|final
name|String
name|fullname
init|=
name|sourcePath
operator|.
name|getName
argument_list|()
decl_stmt|;
specifier|final
name|String
name|name
decl_stmt|;
if|if
condition|(
name|taskId
operator|==
operator|-
literal|1
condition|)
block|{
comment|// non-acid
name|name
operator|=
name|FilenameUtils
operator|.
name|getBaseName
argument_list|(
name|sourcePath
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// acid
name|name
operator|=
name|getPathName
argument_list|(
name|taskId
argument_list|)
expr_stmt|;
block|}
specifier|final
name|String
name|type
init|=
name|FilenameUtils
operator|.
name|getExtension
argument_list|(
name|sourcePath
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|// Incase of ACID, the file is ORC so the extension is not relevant and should not be inherited.
name|Path
name|destFilePath
init|=
operator|new
name|Path
argument_list|(
name|destDirPath
argument_list|,
name|taskId
operator|==
operator|-
literal|1
condition|?
name|fullname
else|:
name|name
argument_list|)
decl_stmt|;
comment|/*     * The below loop may perform bad when the destination file already exists and it has too many _copy_     * files as well. A desired approach was to call listFiles() and get a complete list of files from     * the destination, and check whether the file exists or not on that list. However, millions of files     * could live on the destination directory, and on concurrent situations, this can cause OOM problems.     *     * I'll leave the below loop for now until a better approach is found.     */
for|for
control|(
name|int
name|counter
init|=
literal|1
init|;
name|destFs
operator|.
name|exists
argument_list|(
name|destFilePath
argument_list|)
condition|;
name|counter
operator|++
control|)
block|{
if|if
condition|(
name|isOverwrite
condition|)
block|{
name|destFs
operator|.
name|delete
argument_list|(
name|destFilePath
argument_list|,
literal|false
argument_list|)
expr_stmt|;
break|break;
block|}
name|destFilePath
operator|=
operator|new
name|Path
argument_list|(
name|destDirPath
argument_list|,
name|name
operator|+
operator|(
name|Utilities
operator|.
name|COPY_KEYWORD
operator|+
name|counter
operator|)
operator|+
operator|(
operator|(
name|taskId
operator|==
operator|-
literal|1
operator|&&
operator|!
name|type
operator|.
name|isEmpty
argument_list|()
operator|)
condition|?
literal|"."
operator|+
name|type
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isRenameAllowed
condition|)
block|{
name|destFs
operator|.
name|rename
argument_list|(
name|sourcePath
argument_list|,
name|destFilePath
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|isSrcLocal
condition|)
block|{
name|destFs
operator|.
name|copyFromLocalFile
argument_list|(
name|sourcePath
argument_list|,
name|destFilePath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|FileUtils
operator|.
name|copy
argument_list|(
name|sourceFs
argument_list|,
name|sourcePath
argument_list|,
name|destFs
argument_list|,
name|destFilePath
argument_list|,
literal|true
argument_list|,
comment|// delete source
literal|false
argument_list|,
comment|// overwrite destination
name|conf
argument_list|)
expr_stmt|;
block|}
return|return
name|destFilePath
return|;
block|}
comment|// Clears the dest dir when src is sub-dir of dest.
specifier|public
specifier|static
name|void
name|clearDestForSubDirSrc
parameter_list|(
specifier|final
name|HiveConf
name|conf
parameter_list|,
name|Path
name|dest
parameter_list|,
name|Path
name|src
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|destFS
init|=
name|dest
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileSystem
name|srcFS
init|=
name|src
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|isSubDir
argument_list|(
name|src
argument_list|,
name|dest
argument_list|,
name|srcFS
argument_list|,
name|destFS
argument_list|,
name|isSrcLocal
argument_list|)
condition|)
block|{
specifier|final
name|Path
name|fullSrcPath
init|=
name|getQualifiedPathWithoutSchemeAndAuthority
argument_list|(
name|src
argument_list|,
name|srcFS
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|fullDestPath
init|=
name|getQualifiedPathWithoutSchemeAndAuthority
argument_list|(
name|dest
argument_list|,
name|destFS
argument_list|)
decl_stmt|;
if|if
condition|(
name|fullSrcPath
operator|.
name|equals
argument_list|(
name|fullDestPath
argument_list|)
condition|)
block|{
return|return;
block|}
name|Path
name|parent
init|=
name|fullSrcPath
decl_stmt|;
while|while
condition|(
operator|!
name|parent
operator|.
name|getParent
argument_list|()
operator|.
name|equals
argument_list|(
name|fullDestPath
argument_list|)
condition|)
block|{
name|parent
operator|=
name|parent
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
name|FileStatus
index|[]
name|existingFiles
init|=
name|destFS
operator|.
name|listStatus
argument_list|(
name|dest
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|fileStatus
range|:
name|existingFiles
control|)
block|{
if|if
condition|(
operator|!
name|fileStatus
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|parent
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|destFS
operator|.
name|delete
argument_list|(
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// List the new files in destination path which gets copied from source.
specifier|public
specifier|static
name|void
name|listNewFilesRecursively
parameter_list|(
specifier|final
name|FileSystem
name|destFs
parameter_list|,
name|Path
name|dest
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
for|for
control|(
name|FileStatus
name|fileStatus
range|:
name|destFs
operator|.
name|listStatus
argument_list|(
name|dest
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
control|)
block|{
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
comment|// If it is a sub-directory, then recursively list the files.
name|listNewFilesRecursively
argument_list|(
name|destFs
argument_list|,
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|newFiles
operator|.
name|add
argument_list|(
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get source file statuses"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Recycles the files recursively from the input path to the cmroot directory either by copying or moving it.    *    * @param dataPath Path of the data files to be recycled to cmroot    * @param isPurge    *          When set to true files which needs to be recycled are not moved to Trash    */
specifier|public
name|void
name|recycleDirToCmPath
parameter_list|(
name|Path
name|dataPath
parameter_list|,
name|boolean
name|isPurge
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|CmRecycleRequest
name|request
init|=
operator|new
name|CmRecycleRequest
argument_list|(
name|dataPath
operator|.
name|toString
argument_list|()
argument_list|,
name|isPurge
argument_list|)
decl_stmt|;
name|getMSC
argument_list|()
operator|.
name|recycleDirToCmPath
argument_list|(
name|request
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|//it is assumed that parent directory of the destf should already exist when this
comment|//method is called. when the replace value is true, this method works a little different
comment|//from mv command if the destf is a directory, it replaces the destf instead of moving under
comment|//the destf. in this case, the replaced destf still preserves the original destf's permission
specifier|public
specifier|static
name|boolean
name|moveFile
parameter_list|(
specifier|final
name|HiveConf
name|conf
parameter_list|,
name|Path
name|srcf
parameter_list|,
specifier|final
name|Path
name|destf
parameter_list|,
name|boolean
name|replace
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|isManaged
parameter_list|)
throws|throws
name|HiveException
block|{
specifier|final
name|FileSystem
name|srcFs
decl_stmt|,
name|destFs
decl_stmt|;
try|try
block|{
name|destFs
operator|=
name|destf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get dest fs"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
try|try
block|{
name|srcFs
operator|=
name|srcf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to get src fs"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|HdfsUtils
operator|.
name|HadoopFileStatus
name|destStatus
init|=
literal|null
decl_stmt|;
name|String
name|configuredOwner
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|conf
argument_list|,
name|ConfVars
operator|.
name|HIVE_LOAD_DATA_OWNER
argument_list|)
decl_stmt|;
comment|// If source path is a subdirectory of the destination path (or the other way around):
comment|//   ex: INSERT OVERWRITE DIRECTORY 'target/warehouse/dest4.out' SELECT src.value WHERE src.key>= 300;
comment|//   where the staging directory is a subdirectory of the destination directory
comment|// (1) Do not delete the dest dir before doing the move operation.
comment|// (2) It is assumed that subdir and dir are in same encryption zone.
comment|// (3) Move individual files from scr dir to dest dir.
name|boolean
name|srcIsSubDirOfDest
init|=
name|isSubDir
argument_list|(
name|srcf
argument_list|,
name|destf
argument_list|,
name|srcFs
argument_list|,
name|destFs
argument_list|,
name|isSrcLocal
argument_list|)
decl_stmt|,
name|destIsSubDirOfSrc
init|=
name|isSubDir
argument_list|(
name|destf
argument_list|,
name|srcf
argument_list|,
name|destFs
argument_list|,
name|srcFs
argument_list|,
literal|false
argument_list|)
decl_stmt|;
specifier|final
name|String
name|msg
init|=
literal|"Unable to move source "
operator|+
name|srcf
operator|+
literal|" to destination "
operator|+
name|destf
decl_stmt|;
try|try
block|{
if|if
condition|(
name|replace
condition|)
block|{
try|try
block|{
name|destStatus
operator|=
operator|new
name|HdfsUtils
operator|.
name|HadoopFileStatus
argument_list|(
name|conf
argument_list|,
name|destFs
argument_list|,
name|destf
argument_list|)
expr_stmt|;
comment|//if destf is an existing directory:
comment|//if replace is true, delete followed by rename(mv) is equivalent to replace
comment|//if replace is false, rename (mv) actually move the src under dest dir
comment|//if destf is an existing file, rename is actually a replace, and do not need
comment|// to delete the file first
if|if
condition|(
name|replace
operator|&&
operator|!
name|srcIsSubDirOfDest
condition|)
block|{
name|destFs
operator|.
name|delete
argument_list|(
name|destf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"The path "
operator|+
name|destf
operator|.
name|toString
argument_list|()
operator|+
literal|" is deleted"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|ignore
parameter_list|)
block|{         }
block|}
specifier|final
name|HdfsUtils
operator|.
name|HadoopFileStatus
name|desiredStatus
init|=
name|destStatus
decl_stmt|;
specifier|final
name|SessionState
name|parentSession
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|isSrcLocal
condition|)
block|{
comment|// For local src file, copy to hdfs
name|destFs
operator|.
name|copyFromLocalFile
argument_list|(
name|srcf
argument_list|,
name|destf
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
if|if
condition|(
name|needToCopy
argument_list|(
name|srcf
argument_list|,
name|destf
argument_list|,
name|srcFs
argument_list|,
name|destFs
argument_list|,
name|configuredOwner
argument_list|,
name|isManaged
argument_list|)
condition|)
block|{
comment|//copy if across file system or encryption zones.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copying source "
operator|+
name|srcf
operator|+
literal|" to "
operator|+
name|destf
operator|+
literal|" because HDFS encryption zones are different."
argument_list|)
expr_stmt|;
return|return
name|FileUtils
operator|.
name|copy
argument_list|(
name|srcf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|srcf
argument_list|,
name|destf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|destf
argument_list|,
literal|true
argument_list|,
comment|// delete source
name|replace
argument_list|,
comment|// overwrite destination
name|conf
argument_list|)
return|;
block|}
else|else
block|{
if|if
condition|(
name|srcIsSubDirOfDest
operator|||
name|destIsSubDirOfSrc
condition|)
block|{
name|FileStatus
index|[]
name|srcs
init|=
name|destFs
operator|.
name|listStatus
argument_list|(
name|srcf
argument_list|,
name|FileUtils
operator|.
name|HIDDEN_FILES_PATH_FILTER
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|futures
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|ExecutorService
name|pool
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_MOVE_FILES_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|25
argument_list|)
operator|>
literal|0
condition|?
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_MOVE_FILES_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|25
argument_list|)
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"Move-Thread-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|destIsSubDirOfSrc
operator|&&
operator|!
name|destFs
operator|.
name|exists
argument_list|(
name|destf
argument_list|)
condition|)
block|{
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
literal|"Creating "
operator|+
name|destf
argument_list|)
expr_stmt|;
block|}
name|destFs
operator|.
name|mkdirs
argument_list|(
name|destf
argument_list|)
expr_stmt|;
block|}
comment|/* Move files one by one because source is a subdirectory of destination */
for|for
control|(
specifier|final
name|FileStatus
name|srcStatus
range|:
name|srcs
control|)
block|{
specifier|final
name|Path
name|destFile
init|=
operator|new
name|Path
argument_list|(
name|destf
argument_list|,
name|srcStatus
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|String
name|poolMsg
init|=
literal|"Unable to move source "
operator|+
name|srcStatus
operator|.
name|getPath
argument_list|()
operator|+
literal|" to destination "
operator|+
name|destFile
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|pool
condition|)
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|destFs
operator|instanceof
name|DistributedFileSystem
condition|)
block|{
operator|(
operator|(
name|DistributedFileSystem
operator|)
name|destFs
operator|)
operator|.
name|rename
argument_list|(
name|srcStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|destFile
argument_list|,
name|Options
operator|.
name|Rename
operator|.
name|OVERWRITE
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|destFs
operator|.
name|delete
argument_list|(
name|destFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|success
operator|=
name|destFs
operator|.
name|rename
argument_list|(
name|srcStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|destFile
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|success
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"rename for src path: "
operator|+
name|srcStatus
operator|.
name|getPath
argument_list|()
operator|+
literal|" to dest:"
operator|+
name|destf
operator|+
literal|" returned false"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|futures
operator|.
name|add
argument_list|(
name|pool
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|HiveException
block|{
name|SessionState
operator|.
name|setCurrentSessionState
argument_list|(
name|parentSession
argument_list|)
expr_stmt|;
try|try
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|destFs
operator|instanceof
name|DistributedFileSystem
condition|)
block|{
operator|(
operator|(
name|DistributedFileSystem
operator|)
name|destFs
operator|)
operator|.
name|rename
argument_list|(
name|srcStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|destFile
argument_list|,
name|Options
operator|.
name|Rename
operator|.
name|OVERWRITE
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|destFs
operator|.
name|delete
argument_list|(
name|destFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|success
operator|=
name|destFs
operator|.
name|rename
argument_list|(
name|srcStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|destFile
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|success
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"rename for src path: "
operator|+
name|srcStatus
operator|.
name|getPath
argument_list|()
operator|+
literal|" to dest path:"
operator|+
name|destFile
operator|+
literal|" returned false"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|getHiveException
argument_list|(
name|e
argument_list|,
name|poolMsg
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
literal|null
operator|!=
name|pool
condition|)
block|{
name|pool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|Future
argument_list|<
name|Void
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|handlePoolException
argument_list|(
name|pool
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
return|return
literal|true
return|;
block|}
else|else
block|{
if|if
condition|(
name|destFs
operator|.
name|rename
argument_list|(
name|srcf
argument_list|,
name|destf
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|getHiveException
argument_list|(
name|e
argument_list|,
name|msg
argument_list|)
throw|;
block|}
block|}
specifier|static
specifier|private
name|HiveException
name|getHiveException
parameter_list|(
name|Exception
name|e
parameter_list|,
name|String
name|msg
parameter_list|)
block|{
return|return
name|getHiveException
argument_list|(
name|e
argument_list|,
name|msg
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|static
specifier|private
name|HiveException
name|handlePoolException
parameter_list|(
name|ExecutorService
name|pool
parameter_list|,
name|Exception
name|e
parameter_list|)
block|{
name|HiveException
name|he
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|e
operator|instanceof
name|HiveException
condition|)
block|{
name|he
operator|=
operator|(
name|HiveException
operator|)
name|e
expr_stmt|;
if|if
condition|(
name|he
operator|.
name|getCanonicalErrorMsg
argument_list|()
operator|!=
name|ErrorMsg
operator|.
name|GENERIC_ERROR
condition|)
block|{
if|if
condition|(
name|he
operator|.
name|getCanonicalErrorMsg
argument_list|()
operator|==
name|ErrorMsg
operator|.
name|UNRESOLVED_RT_EXCEPTION
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to move: {}"
argument_list|,
name|he
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to move: {}"
argument_list|,
name|he
operator|.
name|getRemoteErrorMsg
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to move: {}"
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|he
operator|=
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|pool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
return|return
name|he
return|;
block|}
specifier|static
specifier|private
name|HiveException
name|getHiveException
parameter_list|(
name|Exception
name|e
parameter_list|,
name|String
name|msg
parameter_list|,
name|String
name|logMsg
parameter_list|)
block|{
comment|// The message from remote exception includes the entire stack.  The error thrown from
comment|// hive based on the remote exception needs only the first line.
name|String
name|hiveErrMsg
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|e
operator|.
name|getMessage
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|hiveErrMsg
operator|=
name|String
operator|.
name|format
argument_list|(
literal|"%s%s%s"
argument_list|,
name|msg
argument_list|,
literal|": "
argument_list|,
name|Splitter
operator|.
name|on
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"line.separator"
argument_list|)
argument_list|)
operator|.
name|split
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hiveErrMsg
operator|=
name|msg
expr_stmt|;
block|}
name|ErrorMsg
name|errorMsg
init|=
name|ErrorMsg
operator|.
name|getErrorMsg
argument_list|(
name|e
argument_list|)
decl_stmt|;
if|if
condition|(
name|logMsg
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
name|logMsg
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|errorMsg
operator|!=
name|ErrorMsg
operator|.
name|UNRESOLVED_RT_EXCEPTION
condition|)
block|{
return|return
operator|new
name|HiveException
argument_list|(
name|e
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|errorMsg
argument_list|,
name|hiveErrMsg
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|HiveException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
return|;
block|}
block|}
comment|/**    * If moving across different FileSystems or differnent encryption zone, need to do a File copy instead of rename.    * TODO- consider if need to do this for different file authority.    * @throws HiveException    */
specifier|static
specifier|private
name|boolean
name|needToCopy
parameter_list|(
name|Path
name|srcf
parameter_list|,
name|Path
name|destf
parameter_list|,
name|FileSystem
name|srcFs
parameter_list|,
name|FileSystem
name|destFs
parameter_list|,
name|String
name|configuredOwner
parameter_list|,
name|boolean
name|isManaged
parameter_list|)
throws|throws
name|HiveException
block|{
comment|//Check if different FileSystems
if|if
condition|(
operator|!
name|FileUtils
operator|.
name|equalsFileSystem
argument_list|(
name|srcFs
argument_list|,
name|destFs
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|isManaged
operator|&&
operator|!
name|configuredOwner
operator|.
name|isEmpty
argument_list|()
operator|&&
name|srcFs
operator|instanceof
name|DistributedFileSystem
condition|)
block|{
comment|// Need some extra checks
comment|// Get the running owner
name|FileStatus
name|srcs
decl_stmt|;
try|try
block|{
name|srcs
operator|=
name|srcFs
operator|.
name|getFileStatus
argument_list|(
name|srcf
argument_list|)
expr_stmt|;
name|String
name|runningUser
init|=
name|UserGroupInformation
operator|.
name|getLoginUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
decl_stmt|;
name|boolean
name|isOwned
init|=
name|FileUtils
operator|.
name|isOwnerOfFileHierarchy
argument_list|(
name|srcFs
argument_list|,
name|srcs
argument_list|,
name|configuredOwner
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|configuredOwner
operator|.
name|equals
argument_list|(
name|runningUser
argument_list|)
condition|)
block|{
comment|// Check if owner has write permission, else it will have to copy
if|if
condition|(
operator|!
operator|(
name|isOwned
operator|&&
name|FileUtils
operator|.
name|isActionPermittedForFileHierarchy
argument_list|(
name|srcFs
argument_list|,
name|srcs
argument_list|,
name|configuredOwner
argument_list|,
name|FsAction
operator|.
name|WRITE
argument_list|,
literal|false
argument_list|)
operator|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
else|else
block|{
comment|// If the configured owner does not own the file, throw
if|if
condition|(
operator|!
name|isOwned
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Load Data failed for "
operator|+
name|srcf
operator|+
literal|" as the file is not owned by "
operator|+
name|configuredOwner
operator|+
literal|" and load data is also not ran as "
operator|+
name|configuredOwner
argument_list|)
throw|;
block|}
else|else
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Could not fetch FileStatus for source file"
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|" Failed in looking up Permissions on file + "
operator|+
name|srcf
argument_list|)
throw|;
block|}
block|}
comment|//Check if different encryption zones
name|HadoopShims
operator|.
name|HdfsEncryptionShim
name|srcHdfsEncryptionShim
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getHdfsEncryptionShim
argument_list|(
name|srcFs
argument_list|)
decl_stmt|;
name|HadoopShims
operator|.
name|HdfsEncryptionShim
name|destHdfsEncryptionShim
init|=
name|SessionState
operator|.
name|get
argument_list|()
operator|.
name|getHdfsEncryptionShim
argument_list|(
name|destFs
argument_list|)
decl_stmt|;
try|try
block|{
return|return
name|srcHdfsEncryptionShim
operator|!=
literal|null
operator|&&
name|destHdfsEncryptionShim
operator|!=
literal|null
operator|&&
operator|(
name|srcHdfsEncryptionShim
operator|.
name|isPathEncrypted
argument_list|(
name|srcf
argument_list|)
operator|||
name|destHdfsEncryptionShim
operator|.
name|isPathEncrypted
argument_list|(
name|destf
argument_list|)
operator|)
operator|&&
operator|!
name|srcHdfsEncryptionShim
operator|.
name|arePathsOnSameEncryptionZone
argument_list|(
name|srcf
argument_list|,
name|destf
argument_list|,
name|destHdfsEncryptionShim
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Copy files.  This handles building the mapping for buckets and such between the source and    * destination    * @param conf Configuration object    * @param srcf source directory, if bucketed should contain bucket files    * @param destf directory to move files into    * @param fs Filesystem    * @param isSrcLocal true if source is on local file system    * @param isAcidIUD true if this is an ACID based Insert/Update/Delete    * @param isOverwrite if true, then overwrite if destination file exist, else add a duplicate copy    * @param newFiles if this is non-null, a list of files that were created as a result of this    *                 move will be returned.    * @param isManaged if table is managed.    * @throws HiveException    */
specifier|static
specifier|protected
name|void
name|copyFiles
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|Path
name|srcf
parameter_list|,
name|Path
name|destf
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|isAcidIUD
parameter_list|,
name|boolean
name|isOverwrite
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|,
name|boolean
name|isBucketed
parameter_list|,
name|boolean
name|isFullAcidTable
parameter_list|,
name|boolean
name|isManaged
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
comment|// create the destination if it does not exist
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|destf
argument_list|)
condition|)
block|{
name|FileUtils
operator|.
name|mkdir
argument_list|(
name|fs
argument_list|,
name|destf
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"copyFiles: error while checking/creating destination directory!!!"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|FileStatus
index|[]
name|srcs
decl_stmt|;
name|FileSystem
name|srcFs
decl_stmt|;
try|try
block|{
name|srcFs
operator|=
name|srcf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|srcs
operator|=
name|srcFs
operator|.
name|globStatus
argument_list|(
name|srcf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"addFiles: filesystem error in check phase. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|srcs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No sources specified to move: "
operator|+
name|srcf
argument_list|)
expr_stmt|;
return|return;
comment|// srcs = new FileStatus[0]; Why is this needed?
block|}
comment|// If we're moving files around for an ACID write then the rules and paths are all different.
comment|// You can blame this on Owen.
if|if
condition|(
name|isAcidIUD
condition|)
block|{
name|moveAcidFiles
argument_list|(
name|srcFs
argument_list|,
name|srcs
argument_list|,
name|destf
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// For ACID non-bucketed case, the filenames have to be in the format consistent with INSERT/UPDATE/DELETE Ops,
comment|// i.e, like 000000_0, 000001_0_copy_1, 000002_0.gz etc.
comment|// The extension is only maintained for files which are compressed.
name|copyFiles
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|srcs
argument_list|,
name|srcFs
argument_list|,
name|destf
argument_list|,
name|isSrcLocal
argument_list|,
name|isOverwrite
argument_list|,
name|newFiles
argument_list|,
name|isFullAcidTable
operator|&&
operator|!
name|isBucketed
argument_list|,
name|isManaged
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|void
name|moveAcidFiles
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
index|[]
name|stats
parameter_list|,
name|Path
name|dst
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|HiveException
block|{
comment|// The layout for ACID files is table|partname/base|delta|delete_delta/bucket
comment|// We will always only be writing delta files ( except IOW which writes base_X/ ).
comment|// In the buckets created by FileSinkOperator
comment|// it will look like original_bucket/delta|delete_delta/bucket
comment|// (e.g. .../-ext-10004/000000_0/delta_0000014_0000014_0000/bucket_00000).  So we need to
comment|// move that into the above structure. For the first mover there will be no delta directory,
comment|// so we can move the whole directory.
comment|// For everyone else we will need to just move the buckets under the existing delta
comment|// directory.
name|Set
argument_list|<
name|Path
argument_list|>
name|createdDeltaDirs
init|=
operator|new
name|HashSet
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
comment|// Open the original path we've been given and find the list of original buckets
for|for
control|(
name|FileStatus
name|stat
range|:
name|stats
control|)
block|{
name|Path
name|srcPath
init|=
name|stat
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Acid move Looking for original buckets in "
operator|+
name|srcPath
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|origBucketStats
init|=
literal|null
decl_stmt|;
try|try
block|{
name|origBucketStats
operator|=
name|fs
operator|.
name|listStatus
argument_list|(
name|srcPath
argument_list|,
name|AcidUtils
operator|.
name|originalBucketFilter
argument_list|)
expr_stmt|;
if|if
condition|(
name|origBucketStats
operator|==
literal|null
operator|||
name|origBucketStats
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|/**            check if we are dealing with data with non-standard layout. For example a write            produced by a (optimized) Union All query            which looks like            -ext-10000              HIVE_UNION_SUBDIR_1               000000_0                   delta_0000019_0000019_0001                       _orc_acid_version                       bucket_00000              HIVE_UNION_SUBDIR_2               000000_0                   delta_0000019_0000019_0002                       _orc_acid_version                       bucket_00000            The assumption is that we either have all data in subdirs or root of srcPath            but not both.            For Union case, we expect delta dirs to have unique names which is assured by            {@link org.apache.hadoop.hive.ql.optimizer.QueryPlanPostProcessor}           */
name|FileStatus
index|[]
name|unionSubdirs
init|=
name|fs
operator|.
name|globStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|srcPath
argument_list|,
name|AbstractFileMergeOperator
operator|.
name|UNION_SUDBIR_PREFIX
operator|+
literal|"[0-9]*"
argument_list|)
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|buckets
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|FileStatus
name|unionSubdir
range|:
name|unionSubdirs
control|)
block|{
name|Collections
operator|.
name|addAll
argument_list|(
name|buckets
argument_list|,
name|fs
operator|.
name|listStatus
argument_list|(
name|unionSubdir
operator|.
name|getPath
argument_list|()
argument_list|,
name|AcidUtils
operator|.
name|originalBucketFilter
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|origBucketStats
operator|=
name|buckets
operator|.
name|toArray
argument_list|(
operator|new
name|FileStatus
index|[
name|buckets
operator|.
name|size
argument_list|()
index|]
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Unable to look for bucket files in src path "
operator|+
name|srcPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Acid move found "
operator|+
name|origBucketStats
operator|.
name|length
operator|+
literal|" original buckets"
argument_list|)
expr_stmt|;
for|for
control|(
name|FileStatus
name|origBucketStat
range|:
name|origBucketStats
control|)
block|{
name|Path
name|origBucketPath
init|=
name|origBucketStat
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|moveAcidFiles
argument_list|(
name|AcidUtils
operator|.
name|DELTA_PREFIX
argument_list|,
name|AcidUtils
operator|.
name|deltaFileFilter
argument_list|,
name|fs
argument_list|,
name|dst
argument_list|,
name|origBucketPath
argument_list|,
name|createdDeltaDirs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|moveAcidFiles
argument_list|(
name|AcidUtils
operator|.
name|DELETE_DELTA_PREFIX
argument_list|,
name|AcidUtils
operator|.
name|deleteEventDeltaDirFilter
argument_list|,
name|fs
argument_list|,
name|dst
argument_list|,
name|origBucketPath
argument_list|,
name|createdDeltaDirs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|moveAcidFiles
argument_list|(
name|AcidUtils
operator|.
name|BASE_PREFIX
argument_list|,
name|AcidUtils
operator|.
name|baseFileFilter
argument_list|,
comment|//for Insert Overwrite
name|fs
argument_list|,
name|dst
argument_list|,
name|origBucketPath
argument_list|,
name|createdDeltaDirs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|void
name|moveAcidFiles
parameter_list|(
name|String
name|deltaFileType
parameter_list|,
name|PathFilter
name|pathFilter
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dst
parameter_list|,
name|Path
name|origBucketPath
parameter_list|,
name|Set
argument_list|<
name|Path
argument_list|>
name|createdDeltaDirs
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|HiveException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Acid move looking for "
operator|+
name|deltaFileType
operator|+
literal|" files in bucket "
operator|+
name|origBucketPath
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|deltaStats
init|=
literal|null
decl_stmt|;
try|try
block|{
name|deltaStats
operator|=
name|fs
operator|.
name|listStatus
argument_list|(
name|origBucketPath
argument_list|,
name|pathFilter
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to look for "
operator|+
name|deltaFileType
operator|+
literal|" files in original bucket "
operator|+
name|origBucketPath
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Acid move found "
operator|+
name|deltaStats
operator|.
name|length
operator|+
literal|" "
operator|+
name|deltaFileType
operator|+
literal|" files"
argument_list|)
expr_stmt|;
for|for
control|(
name|FileStatus
name|deltaStat
range|:
name|deltaStats
control|)
block|{
name|Path
name|deltaPath
init|=
name|deltaStat
operator|.
name|getPath
argument_list|()
decl_stmt|;
comment|// Create the delta directory.  Don't worry if it already exists,
comment|// as that likely means another task got to it first.  Then move each of the buckets.
comment|// it would be more efficient to try to move the delta with it's buckets but that is
comment|// harder to make race condition proof.
name|Path
name|deltaDest
init|=
operator|new
name|Path
argument_list|(
name|dst
argument_list|,
name|deltaPath
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|createdDeltaDirs
operator|.
name|contains
argument_list|(
name|deltaDest
argument_list|)
condition|)
block|{
try|try
block|{
if|if
condition|(
name|fs
operator|.
name|mkdirs
argument_list|(
name|deltaDest
argument_list|)
condition|)
block|{
name|fs
operator|.
name|rename
argument_list|(
name|AcidUtils
operator|.
name|OrcAcidVersion
operator|.
name|getVersionFilePath
argument_list|(
name|deltaStat
operator|.
name|getPath
argument_list|()
argument_list|)
argument_list|,
name|AcidUtils
operator|.
name|OrcAcidVersion
operator|.
name|getVersionFilePath
argument_list|(
name|deltaDest
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|createdDeltaDirs
operator|.
name|add
argument_list|(
name|deltaDest
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|swallowIt
parameter_list|)
block|{
comment|// Don't worry about this, as it likely just means it's already been created.
name|LOG
operator|.
name|info
argument_list|(
literal|"Unable to create "
operator|+
name|deltaFileType
operator|+
literal|" directory "
operator|+
name|deltaDest
operator|+
literal|", assuming it already exists: "
operator|+
name|swallowIt
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|FileStatus
index|[]
name|bucketStats
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|deltaPath
argument_list|,
name|AcidUtils
operator|.
name|bucketFileFilter
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Acid move found "
operator|+
name|bucketStats
operator|.
name|length
operator|+
literal|" bucket files"
argument_list|)
expr_stmt|;
for|for
control|(
name|FileStatus
name|bucketStat
range|:
name|bucketStats
control|)
block|{
name|Path
name|bucketSrc
init|=
name|bucketStat
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|bucketDest
init|=
operator|new
name|Path
argument_list|(
name|deltaDest
argument_list|,
name|bucketSrc
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|String
name|msg
init|=
literal|"Unable to move source "
operator|+
name|bucketSrc
operator|+
literal|" to destination "
operator|+
name|bucketDest
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Moving bucket "
operator|+
name|bucketSrc
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" to "
operator|+
name|bucketDest
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|fs
operator|.
name|rename
argument_list|(
name|bucketSrc
argument_list|,
name|bucketDest
argument_list|)
expr_stmt|;
if|if
condition|(
name|newFiles
operator|!=
literal|null
condition|)
block|{
name|newFiles
operator|.
name|add
argument_list|(
name|bucketDest
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|getHiveException
argument_list|(
name|e
argument_list|,
name|msg
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error moving acid files "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Replaces files in the partition with new data set specified by srcf. Works    * by renaming directory of srcf to the destination file.    * srcf, destf, and tmppath should resident in the same DFS, but the oldPath can be in a    * different DFS.    *    * @param tablePath path of the table.  Used to identify permission inheritance.    * @param srcf    *          Source directory to be renamed to tmppath. It should be a    *          leaf directory where the final data files reside. However it    *          could potentially contain subdirectories as well.    * @param destf    *          The directory where the final data needs to go    * @param oldPath    *          The directory where the old data location, need to be cleaned up.  Most of time, will be the same    *          as destf, unless its across FileSystem boundaries.    * @param purge    *          When set to true files which needs to be deleted are not moved to Trash    * @param isSrcLocal    *          If the source directory is LOCAL    * @param newFiles    *          Output the list of new files replaced in the destination path    * @param isManaged    *          If the table is managed.    */
specifier|protected
name|void
name|replaceFiles
parameter_list|(
name|Path
name|tablePath
parameter_list|,
name|Path
name|srcf
parameter_list|,
name|Path
name|destf
parameter_list|,
name|Path
name|oldPath
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|isSrcLocal
parameter_list|,
name|boolean
name|purge
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|,
name|PathFilter
name|deletePathFilter
parameter_list|,
name|boolean
name|isNeedRecycle
parameter_list|,
name|boolean
name|isManaged
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|FileSystem
name|destFs
init|=
name|destf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|// check if srcf contains nested sub-directories
name|FileStatus
index|[]
name|srcs
decl_stmt|;
name|FileSystem
name|srcFs
decl_stmt|;
try|try
block|{
name|srcFs
operator|=
name|srcf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|srcs
operator|=
name|srcFs
operator|.
name|globStatus
argument_list|(
name|srcf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Getting globStatus "
operator|+
name|srcf
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|srcs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No sources specified to move: "
operator|+
name|srcf
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|oldPath
operator|!=
literal|null
condition|)
block|{
name|deleteOldPathForReplace
argument_list|(
name|destf
argument_list|,
name|oldPath
argument_list|,
name|conf
argument_list|,
name|purge
argument_list|,
name|deletePathFilter
argument_list|,
name|isNeedRecycle
argument_list|)
expr_stmt|;
block|}
comment|// first call FileUtils.mkdir to make sure that destf directory exists, if not, it creates
comment|// destf
name|boolean
name|destfExist
init|=
name|FileUtils
operator|.
name|mkdir
argument_list|(
name|destFs
argument_list|,
name|destf
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|destfExist
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Directory "
operator|+
name|destf
operator|.
name|toString
argument_list|()
operator|+
literal|" does not exist and could not be created."
argument_list|)
throw|;
block|}
comment|// Two cases:
comment|// 1. srcs has only a src directory, if rename src directory to destf, we also need to
comment|// Copy/move each file under the source directory to avoid to delete the destination
comment|// directory if it is the root of an HDFS encryption zone.
comment|// 2. srcs must be a list of files -- ensured by LoadSemanticAnalyzer
comment|// in both cases, we move the file under destf
if|if
condition|(
name|srcs
operator|.
name|length
operator|==
literal|1
operator|&&
name|srcs
index|[
literal|0
index|]
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|moveFile
argument_list|(
name|conf
argument_list|,
name|srcs
index|[
literal|0
index|]
operator|.
name|getPath
argument_list|()
argument_list|,
name|destf
argument_list|,
literal|true
argument_list|,
name|isSrcLocal
argument_list|,
name|isManaged
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Error moving: "
operator|+
name|srcf
operator|+
literal|" into: "
operator|+
name|destf
argument_list|)
throw|;
block|}
comment|// Add file paths of the files that will be moved to the destination if the caller needs it
if|if
condition|(
literal|null
operator|!=
name|newFiles
condition|)
block|{
name|listNewFilesRecursively
argument_list|(
name|destFs
argument_list|,
name|destf
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// its either a file or glob
for|for
control|(
name|FileStatus
name|src
range|:
name|srcs
control|)
block|{
name|Path
name|destFile
init|=
operator|new
name|Path
argument_list|(
name|destf
argument_list|,
name|src
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moveFile
argument_list|(
name|conf
argument_list|,
name|src
operator|.
name|getPath
argument_list|()
argument_list|,
name|destFile
argument_list|,
literal|true
argument_list|,
name|isSrcLocal
argument_list|,
name|isManaged
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Error moving: "
operator|+
name|srcf
operator|+
literal|" into: "
operator|+
name|destf
argument_list|)
throw|;
block|}
comment|// Add file paths of the files that will be moved to the destination if the caller needs it
if|if
condition|(
literal|null
operator|!=
name|newFiles
condition|)
block|{
name|newFiles
operator|.
name|add
argument_list|(
name|destFile
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|deleteOldPathForReplace
parameter_list|(
name|Path
name|destPath
parameter_list|,
name|Path
name|oldPath
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|purge
parameter_list|,
name|PathFilter
name|pathFilter
parameter_list|,
name|boolean
name|isNeedRecycle
parameter_list|)
throws|throws
name|HiveException
block|{
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|debug
argument_list|(
literal|"Deleting old paths for replace in "
operator|+
name|destPath
operator|+
literal|" and old path "
operator|+
name|oldPath
argument_list|)
expr_stmt|;
name|boolean
name|isOldPathUnderDestf
init|=
literal|false
decl_stmt|;
try|try
block|{
name|FileSystem
name|oldFs
init|=
name|oldPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileSystem
name|destFs
init|=
name|destPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|// if oldPath is destf or its subdir, its should definitely be deleted, otherwise its
comment|// existing content might result in incorrect (extra) data.
comment|// But not sure why we changed not to delete the oldPath in HIVE-8750 if it is
comment|// not the destf or its subdir?
name|isOldPathUnderDestf
operator|=
name|isSubDir
argument_list|(
name|oldPath
argument_list|,
name|destPath
argument_list|,
name|oldFs
argument_list|,
name|destFs
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|isOldPathUnderDestf
condition|)
block|{
name|cleanUpOneDirectoryForReplace
argument_list|(
name|oldPath
argument_list|,
name|oldFs
argument_list|,
name|pathFilter
argument_list|,
name|conf
argument_list|,
name|purge
argument_list|,
name|isNeedRecycle
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isOldPathUnderDestf
condition|)
block|{
comment|// if oldPath is a subdir of destf but it could not be cleaned
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Directory "
operator|+
name|oldPath
operator|.
name|toString
argument_list|()
operator|+
literal|" could not be cleaned up."
argument_list|,
name|e
argument_list|)
throw|;
block|}
else|else
block|{
comment|//swallow the exception since it won't affect the final result
name|LOG
operator|.
name|warn
argument_list|(
literal|"Directory "
operator|+
name|oldPath
operator|.
name|toString
argument_list|()
operator|+
literal|" cannot be cleaned: "
operator|+
name|e
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|cleanUpOneDirectoryForReplace
parameter_list|(
name|Path
name|path
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|PathFilter
name|pathFilter
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|purge
parameter_list|,
name|boolean
name|isNeedRecycle
parameter_list|)
throws|throws
name|IOException
throws|,
name|HiveException
block|{
if|if
condition|(
name|isNeedRecycle
operator|&&
name|conf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|REPLCMENABLED
argument_list|)
condition|)
block|{
name|recycleDirToCmPath
argument_list|(
name|path
argument_list|,
name|purge
argument_list|)
expr_stmt|;
block|}
name|FileStatus
index|[]
name|statuses
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|path
argument_list|,
name|pathFilter
argument_list|)
decl_stmt|;
if|if
condition|(
name|statuses
operator|==
literal|null
operator|||
name|statuses
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|String
name|s
init|=
literal|"Deleting files under "
operator|+
name|path
operator|+
literal|" for replace: "
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|statuses
control|)
block|{
name|s
operator|+=
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|", "
expr_stmt|;
block|}
name|Utilities
operator|.
name|FILE_OP_LOGGER
operator|.
name|trace
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|trashFiles
argument_list|(
name|fs
argument_list|,
name|statuses
argument_list|,
name|conf
argument_list|,
name|purge
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Old path "
operator|+
name|path
operator|+
literal|" has not been cleaned up."
argument_list|)
throw|;
block|}
block|}
comment|/**    * Trashes or deletes all files under a directory. Leaves the directory as is.    * @param fs FileSystem to use    * @param statuses fileStatuses of files to be deleted    * @param conf hive configuration    * @return true if deletion successful    * @throws IOException    */
specifier|public
specifier|static
name|boolean
name|trashFiles
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|FileStatus
index|[]
name|statuses
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|boolean
name|purge
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|result
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|statuses
operator|==
literal|null
operator|||
name|statuses
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|Boolean
argument_list|>
argument_list|>
name|futures
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|ExecutorService
name|pool
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_MOVE_FILES_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|25
argument_list|)
operator|>
literal|0
condition|?
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|ConfVars
operator|.
name|HIVE_MOVE_FILES_THREAD_COUNT
operator|.
name|varname
argument_list|,
literal|25
argument_list|)
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"Delete-Thread-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
specifier|final
name|SessionState
name|parentSession
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
for|for
control|(
specifier|final
name|FileStatus
name|status
range|:
name|statuses
control|)
block|{
if|if
condition|(
literal|null
operator|==
name|pool
condition|)
block|{
name|result
operator|&=
name|FileUtils
operator|.
name|moveToTrash
argument_list|(
name|fs
argument_list|,
name|status
operator|.
name|getPath
argument_list|()
argument_list|,
name|conf
argument_list|,
name|purge
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|futures
operator|.
name|add
argument_list|(
name|pool
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Boolean
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Boolean
name|call
parameter_list|()
throws|throws
name|Exception
block|{
name|SessionState
operator|.
name|setCurrentSessionState
argument_list|(
name|parentSession
argument_list|)
expr_stmt|;
return|return
name|FileUtils
operator|.
name|moveToTrash
argument_list|(
name|fs
argument_list|,
name|status
operator|.
name|getPath
argument_list|()
argument_list|,
name|conf
argument_list|,
name|purge
argument_list|)
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
literal|null
operator|!=
name|pool
condition|)
block|{
name|pool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|Future
argument_list|<
name|Boolean
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
name|result
operator|&=
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to delete: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|pool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
return|return
name|result
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isHadoop1
parameter_list|()
block|{
return|return
name|ShimLoader
operator|.
name|getMajorVersion
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"0.20"
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|exchangeTablePartitions
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitionSpecs
parameter_list|,
name|String
name|sourceDb
parameter_list|,
name|String
name|sourceTable
parameter_list|,
name|String
name|destDb
parameter_list|,
name|String
name|destinationTableName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|partitions
init|=
name|getMSC
argument_list|()
operator|.
name|exchange_partitions
argument_list|(
name|partitionSpecs
argument_list|,
name|sourceDb
argument_list|,
name|sourceTable
argument_list|,
name|destDb
argument_list|,
name|destinationTableName
argument_list|)
decl_stmt|;
return|return
name|convertFromMetastore
argument_list|(
name|getTable
argument_list|(
name|destDb
argument_list|,
name|destinationTableName
argument_list|)
argument_list|,
name|partitions
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ex
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
comment|/**    * Creates a metastore client. Currently it creates only JDBC based client as    * File based store support is removed    *    * @returns a Meta Store Client    * @throws HiveMetaException    *           if a working client can't be created    */
specifier|private
name|IMetaStoreClient
name|createMetaStoreClient
parameter_list|(
name|boolean
name|allowEmbedded
parameter_list|)
throws|throws
name|MetaException
block|{
name|HiveMetaHookLoader
name|hookLoader
init|=
operator|new
name|HiveMetaHookLoader
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|HiveMetaHook
name|getHook
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tbl
parameter_list|)
throws|throws
name|MetaException
block|{
name|HiveStorageHandler
name|storageHandler
init|=
name|createStorageHandler
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
return|return
name|storageHandler
operator|==
literal|null
condition|?
literal|null
else|:
name|storageHandler
operator|.
name|getMetaHook
argument_list|()
return|;
block|}
block|}
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolVar
argument_list|(
name|ConfVars
operator|.
name|METASTORE_FASTPATH
argument_list|)
condition|)
block|{
return|return
operator|new
name|SessionHiveMetaStoreClient
argument_list|(
name|conf
argument_list|,
name|hookLoader
argument_list|,
name|allowEmbedded
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|RetryingMetaStoreClient
operator|.
name|getProxy
argument_list|(
name|conf
argument_list|,
name|hookLoader
argument_list|,
name|metaCallTimeMap
argument_list|,
name|SessionHiveMetaStoreClient
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|allowEmbedded
argument_list|)
return|;
block|}
block|}
annotation|@
name|Nullable
specifier|private
name|HiveStorageHandler
name|createStorageHandler
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tbl
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
if|if
condition|(
name|tbl
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|HiveStorageHandler
name|storageHandler
init|=
name|HiveUtils
operator|.
name|getStorageHandler
argument_list|(
name|conf
argument_list|,
name|tbl
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|META_TABLE_STORAGE
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|storageHandler
return|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ex
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to load storage handler:  "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
class|class
name|SchemaException
extends|extends
name|MetaException
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|public
name|SchemaException
parameter_list|(
name|String
name|message
parameter_list|)
block|{
name|super
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @return synchronized metastore client    * @throws MetaException    */
annotation|@
name|LimitedPrivate
argument_list|(
name|value
operator|=
block|{
literal|"Hive"
block|}
argument_list|)
annotation|@
name|Unstable
specifier|public
specifier|synchronized
name|SynchronizedMetaStoreClient
name|getSynchronizedMSC
parameter_list|()
throws|throws
name|MetaException
block|{
if|if
condition|(
name|syncMetaStoreClient
operator|==
literal|null
condition|)
block|{
name|syncMetaStoreClient
operator|=
operator|new
name|SynchronizedMetaStoreClient
argument_list|(
name|getMSC
argument_list|(
literal|true
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|syncMetaStoreClient
return|;
block|}
comment|/**    * @return the metastore client for the current thread    * @throws MetaException    */
annotation|@
name|LimitedPrivate
argument_list|(
name|value
operator|=
block|{
literal|"Hive"
block|}
argument_list|)
annotation|@
name|Unstable
specifier|public
specifier|synchronized
name|IMetaStoreClient
name|getMSC
parameter_list|()
throws|throws
name|MetaException
block|{
return|return
name|getMSC
argument_list|(
literal|true
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * @return the metastore client for the current thread    * @throws MetaException    */
annotation|@
name|LimitedPrivate
argument_list|(
name|value
operator|=
block|{
literal|"Hive"
block|}
argument_list|)
annotation|@
name|Unstable
specifier|public
specifier|synchronized
name|IMetaStoreClient
name|getMSC
parameter_list|(
name|boolean
name|allowEmbedded
parameter_list|,
name|boolean
name|forceCreate
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|metaStoreClient
operator|==
literal|null
operator|||
name|forceCreate
condition|)
block|{
try|try
block|{
name|owner
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Error getting current user: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|msg
operator|+
literal|"\n"
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
throw|;
block|}
try|try
block|{
name|metaStoreClient
operator|=
name|createMetaStoreClient
argument_list|(
name|allowEmbedded
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|ex
parameter_list|)
block|{
name|Throwable
name|t
init|=
name|ex
operator|.
name|getCause
argument_list|()
decl_stmt|;
while|while
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|t
operator|instanceof
name|JDODataStoreException
operator|&&
name|t
operator|.
name|getMessage
argument_list|()
operator|!=
literal|null
operator|&&
name|t
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
literal|"autoCreate"
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cannot initialize metastore due to autoCreate error"
argument_list|,
name|t
argument_list|)
expr_stmt|;
comment|// DataNucleus wants us to auto-create, but we shall do no such thing.
throw|throw
operator|new
name|SchemaException
argument_list|(
literal|"Hive metastore database is not initialized. Please use "
operator|+
literal|"schematool (e.g. ./schematool -initSchema -dbType ...) to create the schema. If "
operator|+
literal|"needed, don't forget to include the option to auto-create the underlying database"
operator|+
literal|" in your JDBC connection string (e.g. ?createDatabaseIfNotExist=true for mysql)"
argument_list|)
throw|;
block|}
name|t
operator|=
name|t
operator|.
name|getCause
argument_list|()
expr_stmt|;
block|}
throw|throw
name|ex
throw|;
block|}
name|String
name|metaStoreUris
init|=
name|conf
operator|.
name|getVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREURIS
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|metaStoreUris
argument_list|)
condition|)
block|{
comment|// get a synchronized wrapper if the meta store is remote.
name|metaStoreClient
operator|=
name|HiveMetaStoreClient
operator|.
name|newSynchronizedClient
argument_list|(
name|metaStoreClient
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|metaStoreClient
return|;
block|}
specifier|private
specifier|static
name|String
name|getUserName
parameter_list|()
block|{
return|return
name|SessionState
operator|.
name|getUserFromAuthenticator
argument_list|()
return|;
block|}
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|getGroupNames
parameter_list|()
block|{
name|SessionState
name|ss
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|ss
operator|!=
literal|null
operator|&&
name|ss
operator|.
name|getAuthenticator
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|ss
operator|.
name|getAuthenticator
argument_list|()
operator|.
name|getGroupNames
argument_list|()
return|;
block|}
return|return
literal|null
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|getFieldsFromDeserializer
parameter_list|(
name|String
name|name
parameter_list|,
name|Deserializer
name|serde
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|HiveMetaStoreUtils
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|name
argument_list|,
name|serde
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error in getting fields from serde. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error in getting fields from serde."
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|setPartitionColumnStatistics
parameter_list|(
name|SetPartitionsStatsRequest
name|request
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|ColumnStatistics
name|colStat
init|=
name|request
operator|.
name|getColStats
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|ColumnStatisticsDesc
name|statsDesc
init|=
name|colStat
operator|.
name|getStatsDesc
argument_list|()
decl_stmt|;
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|statsDesc
operator|.
name|getDbName
argument_list|()
argument_list|,
name|statsDesc
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|request
operator|.
name|setTxnId
argument_list|(
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
else|:
literal|0
argument_list|)
expr_stmt|;
name|request
operator|.
name|setValidWriteIdList
argument_list|(
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
else|:
literal|null
argument_list|)
expr_stmt|;
name|request
operator|.
name|setWriteId
argument_list|(
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getWriteId
argument_list|()
else|:
literal|0
argument_list|)
expr_stmt|;
return|return
name|getMSC
argument_list|()
operator|.
name|setPartitionColumnStatistics
argument_list|(
name|request
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|getTableColumnStatistics
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|colNames
parameter_list|,
name|boolean
name|checkTransactional
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|retv
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|checkTransactional
condition|)
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
operator|>
literal|0
condition|)
block|{
name|retv
operator|=
name|getMSC
argument_list|()
operator|.
name|getTableColumnStatistics
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|colNames
argument_list|,
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
else|:
operator|-
literal|1
argument_list|,
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
else|:
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|retv
operator|=
name|getMSC
argument_list|()
operator|.
name|getTableColumnStatistics
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|colNames
argument_list|)
expr_stmt|;
block|}
return|return
name|retv
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|>
name|getPartitionColumnStatistics
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|colNames
parameter_list|,
name|boolean
name|checkTransactional
parameter_list|)
throws|throws
name|HiveException
block|{
name|long
name|txnId
init|=
operator|-
literal|1
decl_stmt|;
name|String
name|writeIdList
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|checkTransactional
condition|)
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
name|txnId
operator|=
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
else|:
operator|-
literal|1
expr_stmt|;
name|writeIdList
operator|=
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
else|:
literal|null
expr_stmt|;
block|}
return|return
name|getMSC
argument_list|()
operator|.
name|getPartitionColumnStatistics
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partNames
argument_list|,
name|colNames
argument_list|,
name|txnId
argument_list|,
name|writeIdList
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|AggrStats
name|getAggrColStatsFor
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|colNames
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partName
parameter_list|,
name|boolean
name|checkTransactional
parameter_list|)
block|{
name|long
name|txnId
init|=
operator|-
literal|1
decl_stmt|;
name|String
name|writeIdList
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|checkTransactional
condition|)
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|AcidUtils
operator|.
name|TableSnapshot
name|tableSnapshot
init|=
name|AcidUtils
operator|.
name|getTableSnapshot
argument_list|(
name|conf
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
name|txnId
operator|=
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getTxnId
argument_list|()
else|:
operator|-
literal|1
expr_stmt|;
name|writeIdList
operator|=
name|tableSnapshot
operator|!=
literal|null
condition|?
name|tableSnapshot
operator|.
name|getValidWriteIdList
argument_list|()
else|:
literal|null
expr_stmt|;
block|}
return|return
name|getMSC
argument_list|()
operator|.
name|getAggrColStatsFor
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|colNames
argument_list|,
name|partName
argument_list|,
name|txnId
argument_list|,
name|writeIdList
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|new
name|AggrStats
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|ColumnStatisticsObj
argument_list|>
argument_list|()
argument_list|,
literal|0
argument_list|)
return|;
block|}
block|}
specifier|public
name|boolean
name|deleteTableColumnStatistics
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|colName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|deleteTableColumnStatistics
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|colName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|deletePartitionColumnStatistics
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|partName
parameter_list|,
name|String
name|colName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|deletePartitionColumnStatistics
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partName
argument_list|,
name|colName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Table
name|newTable
parameter_list|(
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|Utilities
operator|.
name|getDbTableName
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
return|return
operator|new
name|Table
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|)
return|;
block|}
specifier|public
name|String
name|getDelegationToken
parameter_list|(
name|String
name|owner
parameter_list|,
name|String
name|renewer
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDelegationToken
argument_list|(
name|owner
argument_list|,
name|renewer
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|cancelDelegationToken
parameter_list|(
name|String
name|tokenStrForm
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|cancelDelegationToken
argument_list|(
name|tokenStrForm
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @deprecated use {@link #compact2(String, String, String, String, Map)}    */
annotation|@
name|Deprecated
specifier|public
name|void
name|compact
parameter_list|(
name|String
name|dbname
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|partName
parameter_list|,
name|String
name|compactType
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|)
throws|throws
name|HiveException
block|{
name|compact2
argument_list|(
name|dbname
argument_list|,
name|tableName
argument_list|,
name|partName
argument_list|,
name|compactType
argument_list|,
name|tblproperties
argument_list|)
expr_stmt|;
block|}
comment|/**    * Enqueue a compaction request.  Only 1 compaction for a given resource (db/table/partSpec) can    * be scheduled/running at any given time.    * @param dbname name of the database, if null default will be used.    * @param tableName name of the table, cannot be null    * @param partName name of the partition, if null table will be compacted (valid only for    *                 non-partitioned tables).    * @param compactType major or minor    * @param tblproperties the list of tblproperties to overwrite for this compaction    * @return id of new request or id already existing request for specified resource    * @throws HiveException    */
specifier|public
name|CompactionResponse
name|compact2
parameter_list|(
name|String
name|dbname
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|partName
parameter_list|,
name|String
name|compactType
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblproperties
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|CompactionType
name|cr
init|=
literal|null
decl_stmt|;
if|if
condition|(
literal|"major"
operator|.
name|equalsIgnoreCase
argument_list|(
name|compactType
argument_list|)
condition|)
block|{
name|cr
operator|=
name|CompactionType
operator|.
name|MAJOR
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"minor"
operator|.
name|equalsIgnoreCase
argument_list|(
name|compactType
argument_list|)
condition|)
block|{
name|cr
operator|=
name|CompactionType
operator|.
name|MINOR
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown compaction type "
operator|+
name|compactType
argument_list|)
throw|;
block|}
return|return
name|getMSC
argument_list|()
operator|.
name|compact2
argument_list|(
name|dbname
argument_list|,
name|tableName
argument_list|,
name|partName
argument_list|,
name|cr
argument_list|,
name|tblproperties
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|ShowCompactResponse
name|showCompactions
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|showCompactions
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|GetOpenTxnsInfoResponse
name|showTransactions
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|showTxns
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|abortTransactions
parameter_list|(
name|List
argument_list|<
name|Long
argument_list|>
name|txnids
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|abortTxns
argument_list|(
name|txnids
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createFunction
parameter_list|(
name|Function
name|func
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createFunction
argument_list|(
name|func
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|alterFunction
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|funcName
parameter_list|,
name|Function
name|newFunction
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|alterFunction
argument_list|(
name|dbName
argument_list|,
name|funcName
argument_list|,
name|newFunction
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropFunction
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|funcName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropFunction
argument_list|(
name|dbName
argument_list|,
name|funcName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Function
name|getFunction
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|funcName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getFunction
argument_list|(
name|dbName
argument_list|,
name|funcName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|Function
argument_list|>
name|getAllFunctions
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|Function
argument_list|>
name|functions
init|=
name|getMSC
argument_list|()
operator|.
name|getAllFunctions
argument_list|()
operator|.
name|getFunctions
argument_list|()
decl_stmt|;
return|return
name|functions
operator|==
literal|null
condition|?
operator|new
name|ArrayList
argument_list|<
name|Function
argument_list|>
argument_list|()
else|:
name|functions
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getFunctions
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|pattern
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getFunctions
argument_list|(
name|dbName
argument_list|,
name|pattern
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|setMetaConf
parameter_list|(
name|String
name|propName
parameter_list|,
name|String
name|propValue
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|setMetaConf
argument_list|(
name|propName
argument_list|,
name|propValue
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|String
name|getMetaConf
parameter_list|(
name|String
name|propName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getMetaConf
argument_list|(
name|propName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|te
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|te
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|clearMetaCallTiming
parameter_list|()
block|{
name|metaCallTimeMap
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
specifier|public
name|ImmutableMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|dumpAndClearMetaCallTiming
parameter_list|(
name|String
name|phase
parameter_list|)
block|{
name|boolean
name|phaseInfoLogged
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|phaseInfoLogged
operator|=
name|logDumpPhase
argument_list|(
name|phase
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Total time spent in each metastore function (ms): "
operator|+
name|metaCallTimeMap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
comment|// print information about calls that took longer time at INFO level
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|callTime
range|:
name|metaCallTimeMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// dump information if call took more than 1 sec (1000ms)
if|if
condition|(
name|callTime
operator|.
name|getValue
argument_list|()
operator|>
literal|1000
condition|)
block|{
if|if
condition|(
operator|!
name|phaseInfoLogged
condition|)
block|{
name|phaseInfoLogged
operator|=
name|logDumpPhase
argument_list|(
name|phase
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Total time spent in this metastore function was greater than 1000ms : "
operator|+
name|callTime
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|ImmutableMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|result
init|=
name|ImmutableMap
operator|.
name|copyOf
argument_list|(
name|metaCallTimeMap
argument_list|)
decl_stmt|;
name|metaCallTimeMap
operator|.
name|clear
argument_list|()
expr_stmt|;
return|return
name|result
return|;
block|}
specifier|private
name|boolean
name|logDumpPhase
parameter_list|(
name|String
name|phase
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Dumping metastore api call timing information for : "
operator|+
name|phase
operator|+
literal|" phase"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|public
name|Iterable
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|ByteBuffer
argument_list|>
argument_list|>
name|getFileMetadata
parameter_list|(
name|List
argument_list|<
name|Long
argument_list|>
name|fileIds
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getFileMetadata
argument_list|(
name|fileIds
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Iterable
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|MetadataPpdResult
argument_list|>
argument_list|>
name|getFileMetadataByExpr
parameter_list|(
name|List
argument_list|<
name|Long
argument_list|>
name|fileIds
parameter_list|,
name|ByteBuffer
name|sarg
parameter_list|,
name|boolean
name|doGetFooters
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getFileMetadataBySarg
argument_list|(
name|fileIds
argument_list|,
name|sarg
argument_list|,
name|doGetFooters
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|clearFileMetadata
parameter_list|(
name|List
argument_list|<
name|Long
argument_list|>
name|fileIds
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|clearFileMetadata
argument_list|(
name|fileIds
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|putFileMetadata
parameter_list|(
name|List
argument_list|<
name|Long
argument_list|>
name|fileIds
parameter_list|,
name|List
argument_list|<
name|ByteBuffer
argument_list|>
name|metadata
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|putFileMetadata
argument_list|(
name|fileIds
argument_list|,
name|metadata
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|cacheFileMetadata
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|partName
parameter_list|,
name|boolean
name|allParts
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|boolean
name|willCache
init|=
name|getMSC
argument_list|()
operator|.
name|cacheFileMetadata
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partName
argument_list|,
name|allParts
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|willCache
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Caching file metadata is not supported by metastore or for this file format"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropConstraint
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|constraintName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropConstraint
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|constraintName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|SQLPrimaryKey
argument_list|>
name|getPrimaryKeyList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getPrimaryKeys
argument_list|(
operator|new
name|PrimaryKeysRequest
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|SQLForeignKey
argument_list|>
name|getForeignKeyList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getForeignKeys
argument_list|(
operator|new
name|ForeignKeysRequest
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|SQLUniqueConstraint
argument_list|>
name|getUniqueConstraintList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getUniqueConstraints
argument_list|(
operator|new
name|UniqueConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|SQLNotNullConstraint
argument_list|>
name|getNotNullConstraintList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getNotNullConstraints
argument_list|(
operator|new
name|NotNullConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|SQLDefaultConstraint
argument_list|>
name|getDefaultConstraintList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDefaultConstraints
argument_list|(
operator|new
name|DefaultConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|SQLCheckConstraint
argument_list|>
name|getCheckConstraintList
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getCheckConstraints
argument_list|(
operator|new
name|CheckConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all primary key columns associated with the table.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Primary Key associated with the table.    * @throws HiveException    */
specifier|public
name|PrimaryKeyInfo
name|getPrimaryKeys
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getPrimaryKeys
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Get primary key columns associated with the table that are available for optimization.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Primary Key associated with the table.    * @throws HiveException    */
specifier|public
name|PrimaryKeyInfo
name|getReliablePrimaryKeys
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getPrimaryKeys
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|true
argument_list|)
return|;
block|}
specifier|private
name|PrimaryKeyInfo
name|getPrimaryKeys
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|boolean
name|onlyReliable
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLPrimaryKey
argument_list|>
name|primaryKeys
init|=
name|getMSC
argument_list|()
operator|.
name|getPrimaryKeys
argument_list|(
operator|new
name|PrimaryKeysRequest
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|onlyReliable
operator|&&
name|primaryKeys
operator|!=
literal|null
operator|&&
operator|!
name|primaryKeys
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|primaryKeys
operator|=
name|primaryKeys
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|pk
lambda|->
name|pk
operator|.
name|isRely_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|PrimaryKeyInfo
argument_list|(
name|primaryKeys
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all foreign keys associated with the table.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Foreign keys associated with the table.    * @throws HiveException    */
specifier|public
name|ForeignKeyInfo
name|getForeignKeys
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getForeignKeys
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Get foreign keys associated with the table that are available for optimization.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Foreign keys associated with the table.    * @throws HiveException    */
specifier|public
name|ForeignKeyInfo
name|getReliableForeignKeys
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getForeignKeys
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|true
argument_list|)
return|;
block|}
specifier|private
name|ForeignKeyInfo
name|getForeignKeys
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|boolean
name|onlyReliable
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLForeignKey
argument_list|>
name|foreignKeys
init|=
name|getMSC
argument_list|()
operator|.
name|getForeignKeys
argument_list|(
operator|new
name|ForeignKeysRequest
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|onlyReliable
operator|&&
name|foreignKeys
operator|!=
literal|null
operator|&&
operator|!
name|foreignKeys
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|foreignKeys
operator|=
name|foreignKeys
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|fk
lambda|->
name|fk
operator|.
name|isRely_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|ForeignKeyInfo
argument_list|(
name|foreignKeys
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all unique constraints associated with the table.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Unique constraints associated with the table.    * @throws HiveException    */
specifier|public
name|UniqueConstraint
name|getUniqueConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getUniqueConstraints
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Get unique constraints associated with the table that are available for optimization.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Unique constraints associated with the table.    * @throws HiveException    */
specifier|public
name|UniqueConstraint
name|getReliableUniqueConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getUniqueConstraints
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|true
argument_list|)
return|;
block|}
specifier|private
name|UniqueConstraint
name|getUniqueConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|boolean
name|onlyReliable
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLUniqueConstraint
argument_list|>
name|uniqueConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getUniqueConstraints
argument_list|(
operator|new
name|UniqueConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|onlyReliable
operator|&&
name|uniqueConstraints
operator|!=
literal|null
operator|&&
operator|!
name|uniqueConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|uniqueConstraints
operator|=
name|uniqueConstraints
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|uk
lambda|->
name|uk
operator|.
name|isRely_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|UniqueConstraint
argument_list|(
name|uniqueConstraints
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all not null constraints associated with the table.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Not null constraints associated with the table.    * @throws HiveException    */
specifier|public
name|NotNullConstraint
name|getNotNullConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getNotNullConstraints
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Get not null constraints associated with the table that are available for optimization.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Not null constraints associated with the table.    * @throws HiveException    */
specifier|public
name|NotNullConstraint
name|getReliableNotNullConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getNotNullConstraints
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Get not null constraints associated with the table that are enabled/enforced.    *    * @param dbName Database Name    * @param tblName Table Name    * @return Not null constraints associated with the table.    * @throws HiveException    */
specifier|public
name|NotNullConstraint
name|getEnabledNotNullConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLNotNullConstraint
argument_list|>
name|notNullConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getNotNullConstraints
argument_list|(
operator|new
name|NotNullConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|notNullConstraints
operator|!=
literal|null
operator|&&
operator|!
name|notNullConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|notNullConstraints
operator|=
name|notNullConstraints
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|nnc
lambda|->
name|nnc
operator|.
name|isEnable_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|NotNullConstraint
argument_list|(
name|notNullConstraints
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get CHECK constraints associated with the table that are enabled    *    * @param dbName Database Name    * @param tblName Table Name    * @return CHECK constraints associated with the table.    * @throws HiveException    */
specifier|public
name|CheckConstraint
name|getEnabledCheckConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLCheckConstraint
argument_list|>
name|checkConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getCheckConstraints
argument_list|(
operator|new
name|CheckConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|checkConstraints
operator|!=
literal|null
operator|&&
operator|!
name|checkConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|checkConstraints
operator|=
name|checkConstraints
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|nnc
lambda|->
name|nnc
operator|.
name|isEnable_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|CheckConstraint
argument_list|(
name|checkConstraints
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get Default constraints associated with the table that are enabled    *    * @param dbName Database Name    * @param tblName Table Name    * @return Default constraints associated with the table.    * @throws HiveException    */
specifier|public
name|DefaultConstraint
name|getEnabledDefaultConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLDefaultConstraint
argument_list|>
name|defaultConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getDefaultConstraints
argument_list|(
operator|new
name|DefaultConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|defaultConstraints
operator|!=
literal|null
operator|&&
operator|!
name|defaultConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|defaultConstraints
operator|=
name|defaultConstraints
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|nnc
lambda|->
name|nnc
operator|.
name|isEnable_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|DefaultConstraint
argument_list|(
name|defaultConstraints
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|NotNullConstraint
name|getNotNullConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|boolean
name|onlyReliable
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLNotNullConstraint
argument_list|>
name|notNullConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getNotNullConstraints
argument_list|(
operator|new
name|NotNullConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|onlyReliable
operator|&&
name|notNullConstraints
operator|!=
literal|null
operator|&&
operator|!
name|notNullConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|notNullConstraints
operator|=
name|notNullConstraints
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|nnc
lambda|->
name|nnc
operator|.
name|isRely_cstr
argument_list|()
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|NotNullConstraint
argument_list|(
name|notNullConstraints
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|DefaultConstraint
name|getDefaultConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLDefaultConstraint
argument_list|>
name|defaultConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getDefaultConstraints
argument_list|(
operator|new
name|DefaultConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|defaultConstraints
operator|!=
literal|null
operator|&&
operator|!
name|defaultConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|defaultConstraints
operator|=
name|defaultConstraints
operator|.
name|stream
argument_list|()
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|DefaultConstraint
argument_list|(
name|defaultConstraints
argument_list|,
name|tblName
argument_list|,
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|CheckConstraint
name|getCheckConstraints
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|List
argument_list|<
name|SQLCheckConstraint
argument_list|>
name|checkConstraints
init|=
name|getMSC
argument_list|()
operator|.
name|getCheckConstraints
argument_list|(
operator|new
name|CheckConstraintsRequest
argument_list|(
name|getDefaultCatalog
argument_list|(
name|conf
argument_list|)
argument_list|,
name|dbName
argument_list|,
name|tblName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|checkConstraints
operator|!=
literal|null
operator|&&
operator|!
name|checkConstraints
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|checkConstraints
operator|=
name|checkConstraints
operator|.
name|stream
argument_list|()
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|CheckConstraint
argument_list|(
name|checkConstraints
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|addPrimaryKey
parameter_list|(
name|List
argument_list|<
name|SQLPrimaryKey
argument_list|>
name|primaryKeyCols
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|addPrimaryKey
argument_list|(
name|primaryKeyCols
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|addForeignKey
parameter_list|(
name|List
argument_list|<
name|SQLForeignKey
argument_list|>
name|foreignKeyCols
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|addForeignKey
argument_list|(
name|foreignKeyCols
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|addUniqueConstraint
parameter_list|(
name|List
argument_list|<
name|SQLUniqueConstraint
argument_list|>
name|uniqueConstraintCols
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|addUniqueConstraint
argument_list|(
name|uniqueConstraintCols
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|addNotNullConstraint
parameter_list|(
name|List
argument_list|<
name|SQLNotNullConstraint
argument_list|>
name|notNullConstraintCols
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|addNotNullConstraint
argument_list|(
name|notNullConstraintCols
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|addDefaultConstraint
parameter_list|(
name|List
argument_list|<
name|SQLDefaultConstraint
argument_list|>
name|defaultConstraints
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|addDefaultConstraint
argument_list|(
name|defaultConstraints
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|addCheckConstraint
parameter_list|(
name|List
argument_list|<
name|SQLCheckConstraint
argument_list|>
name|checkConstraints
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|addCheckConstraint
argument_list|(
name|checkConstraints
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createResourcePlan
parameter_list|(
name|WMResourcePlan
name|resourcePlan
parameter_list|,
name|String
name|copyFromName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createResourcePlan
argument_list|(
name|resourcePlan
argument_list|,
name|copyFromName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|WMFullResourcePlan
name|getResourcePlan
parameter_list|(
name|String
name|rpName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getResourcePlan
argument_list|(
name|rpName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|WMResourcePlan
argument_list|>
name|getAllResourcePlans
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getAllResourcePlans
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropResourcePlan
parameter_list|(
name|String
name|rpName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropResourcePlan
argument_list|(
name|rpName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|WMFullResourcePlan
name|alterResourcePlan
parameter_list|(
name|String
name|rpName
parameter_list|,
name|WMNullableResourcePlan
name|resourcePlan
parameter_list|,
name|boolean
name|canActivateDisabled
parameter_list|,
name|boolean
name|isForceDeactivate
parameter_list|,
name|boolean
name|isReplace
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|alterResourcePlan
argument_list|(
name|rpName
argument_list|,
name|resourcePlan
argument_list|,
name|canActivateDisabled
argument_list|,
name|isForceDeactivate
argument_list|,
name|isReplace
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|WMFullResourcePlan
name|getActiveResourcePlan
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getActiveResourcePlan
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|WMValidateResourcePlanResponse
name|validateResourcePlan
parameter_list|(
name|String
name|rpName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|validateResourcePlan
argument_list|(
name|rpName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createWMTrigger
parameter_list|(
name|WMTrigger
name|trigger
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createWMTrigger
argument_list|(
name|trigger
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|alterWMTrigger
parameter_list|(
name|WMTrigger
name|trigger
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|alterWMTrigger
argument_list|(
name|trigger
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropWMTrigger
parameter_list|(
name|String
name|rpName
parameter_list|,
name|String
name|triggerName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropWMTrigger
argument_list|(
name|rpName
argument_list|,
name|triggerName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createWMPool
parameter_list|(
name|WMPool
name|pool
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createWMPool
argument_list|(
name|pool
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|alterWMPool
parameter_list|(
name|WMNullablePool
name|pool
parameter_list|,
name|String
name|poolPath
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|alterWMPool
argument_list|(
name|pool
argument_list|,
name|poolPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropWMPool
parameter_list|(
name|String
name|resourcePlanName
parameter_list|,
name|String
name|poolPath
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropWMPool
argument_list|(
name|resourcePlanName
argument_list|,
name|poolPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createOrUpdateWMMapping
parameter_list|(
name|WMMapping
name|mapping
parameter_list|,
name|boolean
name|isUpdate
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createOrUpdateWMMapping
argument_list|(
name|mapping
argument_list|,
name|isUpdate
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropWMMapping
parameter_list|(
name|WMMapping
name|mapping
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropWMMapping
argument_list|(
name|mapping
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|createOrDropTriggerToPoolMapping
parameter_list|(
name|String
name|resourcePlanName
parameter_list|,
name|String
name|triggerName
parameter_list|,
name|String
name|poolPath
parameter_list|,
name|boolean
name|shouldDrop
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createOrDropTriggerToPoolMapping
argument_list|(
name|resourcePlanName
argument_list|,
name|triggerName
argument_list|,
name|poolPath
argument_list|,
name|shouldDrop
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Nullable
specifier|public
name|StorageHandlerInfo
name|getStorageHandlerInfo
parameter_list|(
name|Table
name|table
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|HiveStorageHandler
name|storageHandler
init|=
name|createStorageHandler
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|storageHandler
operator|==
literal|null
condition|?
literal|null
else|:
name|storageHandler
operator|.
name|getStorageHandlerInfo
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

