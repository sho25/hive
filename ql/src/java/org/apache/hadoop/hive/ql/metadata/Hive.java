begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MetaStoreUtils
operator|.
name|DEFAULT_DATABASE_NAME
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
operator|.
name|META_TABLE_STORAGE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|COLLECTION_DELIM
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|ESCAPE_CHAR
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|FIELD_DELIM
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|LINE_DELIM
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|MAPKEY_DELIM
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|SERIALIZATION_FORMAT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|Constants
operator|.
name|STRING_TYPE_NAME
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FsShell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaHookLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|IMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MetaStoreUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|TableType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|AlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|HiveObjectPrivilege
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|HiveObjectRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|HiveObjectType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Index
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Order
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|PrincipalPrivilegeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|PrincipalType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|PrivilegeBag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Role
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SerDeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|index
operator|.
name|HiveIndexHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|CreateTableAutomaticGrant
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_comment
comment|/**  * The Hive class contains information about this instance of Hive. An instance  * of Hive represents a set of data in a file system (usually HDFS) organized  * for easy query processing  *  */
end_comment

begin_class
specifier|public
class|class
name|Hive
block|{
specifier|static
specifier|final
specifier|private
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
literal|"hive.ql.metadata.Hive"
argument_list|)
decl_stmt|;
specifier|private
name|HiveConf
name|conf
init|=
literal|null
decl_stmt|;
specifier|private
name|IMetaStoreClient
name|metaStoreClient
decl_stmt|;
specifier|private
name|String
name|currentDatabase
decl_stmt|;
specifier|private
specifier|static
name|ThreadLocal
argument_list|<
name|Hive
argument_list|>
name|hiveDB
init|=
operator|new
name|ThreadLocal
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
specifier|synchronized
name|Object
name|initialValue
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|remove
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|get
argument_list|()
operator|!=
literal|null
condition|)
block|{
operator|(
operator|(
name|Hive
operator|)
name|this
operator|.
name|get
argument_list|()
operator|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|super
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
decl_stmt|;
comment|/**    * Gets hive object for the current thread. If one is not initialized then a    * new one is created If the new configuration is different in metadata conf    * vars then a new one is created.    *    * @param c    *          new Hive Configuration    * @return Hive object for current thread    * @throws HiveException    *    */
specifier|public
specifier|static
name|Hive
name|get
parameter_list|(
name|HiveConf
name|c
parameter_list|)
throws|throws
name|HiveException
block|{
name|boolean
name|needsRefresh
init|=
literal|false
decl_stmt|;
name|Hive
name|db
init|=
name|hiveDB
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|db
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HiveConf
operator|.
name|ConfVars
name|oneVar
range|:
name|HiveConf
operator|.
name|metaVars
control|)
block|{
comment|// Since metaVars are all of different types, use string for comparison
name|String
name|oldVar
init|=
name|db
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|oneVar
operator|.
name|varname
argument_list|,
literal|""
argument_list|)
decl_stmt|;
name|String
name|newVar
init|=
name|c
operator|.
name|get
argument_list|(
name|oneVar
operator|.
name|varname
argument_list|,
literal|""
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldVar
operator|.
name|compareToIgnoreCase
argument_list|(
name|newVar
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|needsRefresh
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
block|}
return|return
name|get
argument_list|(
name|c
argument_list|,
name|needsRefresh
argument_list|)
return|;
block|}
comment|/**    * get a connection to metastore. see get(HiveConf) function for comments    *    * @param c    *          new conf    * @param needsRefresh    *          if true then creates a new one    * @return The connection to the metastore    * @throws HiveException    */
specifier|public
specifier|static
name|Hive
name|get
parameter_list|(
name|HiveConf
name|c
parameter_list|,
name|boolean
name|needsRefresh
parameter_list|)
throws|throws
name|HiveException
block|{
name|Hive
name|db
init|=
name|hiveDB
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|db
operator|==
literal|null
operator|||
name|needsRefresh
condition|)
block|{
name|closeCurrent
argument_list|()
expr_stmt|;
name|c
operator|.
name|set
argument_list|(
literal|"fs.scheme.class"
argument_list|,
literal|"dfs"
argument_list|)
expr_stmt|;
name|Hive
name|newdb
init|=
operator|new
name|Hive
argument_list|(
name|c
argument_list|)
decl_stmt|;
if|if
condition|(
name|db
operator|!=
literal|null
operator|&&
name|db
operator|.
name|getCurrentDatabase
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|newdb
operator|.
name|setCurrentDatabase
argument_list|(
name|db
operator|.
name|getCurrentDatabase
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|hiveDB
operator|.
name|set
argument_list|(
name|newdb
argument_list|)
expr_stmt|;
return|return
name|newdb
return|;
block|}
return|return
name|db
return|;
block|}
specifier|public
specifier|static
name|Hive
name|get
parameter_list|()
throws|throws
name|HiveException
block|{
name|Hive
name|db
init|=
name|hiveDB
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|db
operator|==
literal|null
condition|)
block|{
name|db
operator|=
operator|new
name|Hive
argument_list|(
operator|new
name|HiveConf
argument_list|(
name|Hive
operator|.
name|class
argument_list|)
argument_list|)
expr_stmt|;
name|hiveDB
operator|.
name|set
argument_list|(
name|db
argument_list|)
expr_stmt|;
block|}
return|return
name|db
return|;
block|}
specifier|public
specifier|static
name|void
name|closeCurrent
parameter_list|()
block|{
name|hiveDB
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
comment|/**    * Hive    *    * @param argFsRoot    * @param c    *    */
specifier|private
name|Hive
parameter_list|(
name|HiveConf
name|c
parameter_list|)
throws|throws
name|HiveException
block|{
name|conf
operator|=
name|c
expr_stmt|;
block|}
comment|/**    * closes the connection to metastore for the calling thread    */
specifier|private
name|void
name|close
parameter_list|()
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing current thread's connection to Hive Metastore."
argument_list|)
expr_stmt|;
if|if
condition|(
name|metaStoreClient
operator|!=
literal|null
condition|)
block|{
name|metaStoreClient
operator|.
name|close
argument_list|()
expr_stmt|;
name|metaStoreClient
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Create a database    * @param db    * @param ifNotExist if true, will ignore AlreadyExistsException exception    * @throws AlreadyExistsException    * @throws HiveException    */
specifier|public
name|void
name|createDatabase
parameter_list|(
name|Database
name|db
parameter_list|,
name|boolean
name|ifNotExist
parameter_list|)
throws|throws
name|AlreadyExistsException
throws|,
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|createDatabase
argument_list|(
name|db
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ifNotExist
condition|)
block|{
throw|throw
name|e
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create a Database. Raise an error if a database with the same name already exists.    * @param db    * @throws AlreadyExistsException    * @throws HiveException    */
specifier|public
name|void
name|createDatabase
parameter_list|(
name|Database
name|db
parameter_list|)
throws|throws
name|AlreadyExistsException
throws|,
name|HiveException
block|{
name|createDatabase
argument_list|(
name|db
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drop a database.    * @param name    * @throws NoSuchObjectException    * @throws HiveException    * @see org.apache.hadoop.hive.metastore.HiveMetaStoreClient#dropDatabase(java.lang.String)    */
specifier|public
name|void
name|dropDatabase
parameter_list|(
name|String
name|name
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
name|dropDatabase
argument_list|(
name|name
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drop a database    * @param name    * @param deleteData    * @param ignoreUnknownDb if true, will ignore NoSuchObjectException    * @return    * @throws HiveException    * @throws NoSuchObjectException    */
specifier|public
name|void
name|dropDatabase
parameter_list|(
name|String
name|name
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownDb
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
name|dropDatabase
argument_list|(
name|name
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownDb
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drop a database    * @param name    * @param deleteData    * @param ignoreUnknownDb if true, will ignore NoSuchObjectException    * @param cascade           if true, delete all tables on the DB if exists. Othewise, the query    *                        will fail if table still exists.    * @return    * @throws HiveException    * @throws NoSuchObjectException    */
specifier|public
name|void
name|dropDatabase
parameter_list|(
name|String
name|name
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownDb
parameter_list|,
name|boolean
name|cascade
parameter_list|)
throws|throws
name|HiveException
throws|,
name|NoSuchObjectException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropDatabase
argument_list|(
name|name
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownDb
argument_list|,
name|cascade
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Creates a table metdata and the directory for the table data    *    * @param tableName    *          name of the table    * @param columns    *          list of fields of the table    * @param partCols    *          partition keys of the table    * @param fileInputFormat    *          Class of the input format of the table data file    * @param fileOutputFormat    *          Class of the output format of the table data file    * @throws HiveException    *           thrown if the args are invalid or if the metadata or the data    *           directory couldn't be created    */
specifier|public
name|void
name|createTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|fileInputFormat
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|fileOutputFormat
parameter_list|)
throws|throws
name|HiveException
block|{
name|this
operator|.
name|createTable
argument_list|(
name|tableName
argument_list|,
name|columns
argument_list|,
name|partCols
argument_list|,
name|fileInputFormat
argument_list|,
name|fileOutputFormat
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates a table metdata and the directory for the table data    *    * @param tableName    *          name of the table    * @param columns    *          list of fields of the table    * @param partCols    *          partition keys of the table    * @param fileInputFormat    *          Class of the input format of the table data file    * @param fileOutputFormat    *          Class of the output format of the table data file    * @param bucketCount    *          number of buckets that each partition (or the table itself) should    *          be divided into    * @throws HiveException    *           thrown if the args are invalid or if the metadata or the data    *           directory couldn't be created    */
specifier|public
name|void
name|createTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|fileInputFormat
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
name|fileOutputFormat
parameter_list|,
name|int
name|bucketCount
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|columns
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"columns not specified for table "
operator|+
name|tableName
argument_list|)
throw|;
block|}
name|Table
name|tbl
init|=
name|newTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|tbl
operator|.
name|setInputFormatClass
argument_list|(
name|fileInputFormat
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setOutputFormatClass
argument_list|(
name|fileOutputFormat
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|col
range|:
name|columns
control|)
block|{
name|FieldSchema
name|field
init|=
operator|new
name|FieldSchema
argument_list|(
name|col
argument_list|,
name|STRING_TYPE_NAME
argument_list|,
literal|"default"
argument_list|)
decl_stmt|;
name|tbl
operator|.
name|getCols
argument_list|()
operator|.
name|add
argument_list|(
name|field
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|partCols
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|partCol
range|:
name|partCols
control|)
block|{
name|FieldSchema
name|part
init|=
operator|new
name|FieldSchema
argument_list|()
decl_stmt|;
name|part
operator|.
name|setName
argument_list|(
name|partCol
argument_list|)
expr_stmt|;
name|part
operator|.
name|setType
argument_list|(
name|STRING_TYPE_NAME
argument_list|)
expr_stmt|;
comment|// default partition key
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
block|}
block|}
name|tbl
operator|.
name|setSerializationLib
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setNumBuckets
argument_list|(
name|bucketCount
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setBucketCols
argument_list|(
name|bucketCols
argument_list|)
expr_stmt|;
name|createTable
argument_list|(
name|tbl
argument_list|)
expr_stmt|;
block|}
comment|/**    * Updates the existing table metadata with the new metadata.    *    * @param tblName    *          name of the existing table    * @param newTbl    *          new name of the table. could be the old name    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterTable
parameter_list|(
name|String
name|tblName
parameter_list|,
name|Table
name|newTbl
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Remove the DDL_TIME so it gets refreshed
if|if
condition|(
name|newTbl
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|newTbl
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|Constants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|getMSC
argument_list|()
operator|.
name|alter_table
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|newTbl
operator|.
name|getTTable
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter table."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter table."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Updates the existing index metadata with the new metadata.    *    * @param idxName    *          name of the existing index    * @param newIdx    *          new name of the index. could be the old name    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterIndex
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|baseTblName
parameter_list|,
name|String
name|idxName
parameter_list|,
name|Index
name|newIdx
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|alter_index
argument_list|(
name|dbName
argument_list|,
name|baseTblName
argument_list|,
name|idxName
argument_list|,
name|newIdx
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter index."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter index."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Updates the existing table metadata with the new metadata.    *    * @param tblName    *          name of the existing table    * @param newTbl    *          new name of the table. could be the old name    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|alterPartition
parameter_list|(
name|String
name|tblName
parameter_list|,
name|Partition
name|newPart
parameter_list|)
throws|throws
name|InvalidOperationException
throws|,
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Remove the DDL time so that it gets refreshed
if|if
condition|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|newPart
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|Constants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|getMSC
argument_list|()
operator|.
name|alter_partition
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|newPart
operator|.
name|getTPartition
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter partition."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter partition."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Rename a old partition to new partition    *    * @param tbl    *          existing table    * @param oldPartSpec    *          spec of old partition    * @param newPart    *          new partition    * @throws InvalidOperationException    *           if the changes in metadata is not acceptable    * @throws TException    */
specifier|public
name|void
name|renamePartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|oldPartSpec
parameter_list|,
name|Partition
name|newPart
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|newPartSpec
init|=
name|newPart
operator|.
name|getSpec
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldPartSpec
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|size
argument_list|()
operator|||
name|newPartSpec
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|tbl
operator|.
name|getPartCols
argument_list|()
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition to the same name: number of partition cols don't match. "
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|oldPartSpec
operator|.
name|keySet
argument_list|()
operator|.
name|equals
argument_list|(
name|newPartSpec
operator|.
name|keySet
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition to the same name: old and new partition cols don't match. "
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|tbl
operator|.
name|getPartCols
argument_list|()
control|)
block|{
name|String
name|val
init|=
name|oldPartSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
name|val
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"get partition: Value for key "
operator|+
name|field
operator|.
name|getName
argument_list|()
operator|+
literal|" is null or empty"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
block|}
name|getMSC
argument_list|()
operator|.
name|renamePartition
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|,
name|newPart
operator|.
name|getTPartition
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to rename partition."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|alterDatabase
parameter_list|(
name|String
name|dbName
parameter_list|,
name|Database
name|db
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|alterDatabase
argument_list|(
name|dbName
argument_list|,
name|db
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter database "
operator|+
name|dbName
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Database "
operator|+
name|dbName
operator|+
literal|" does not exists."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to alter database "
operator|+
name|dbName
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Creates the table with the give objects    *    * @param tbl    *          a table object    * @throws HiveException    */
specifier|public
name|void
name|createTable
parameter_list|(
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
name|createTable
argument_list|(
name|tbl
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates the table with the give objects    *    * @param tbl    *          a table object    * @param ifNotExists    *          if true, ignore AlreadyExistsException    * @throws HiveException    */
specifier|public
name|void
name|createTable
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|boolean
name|ifNotExists
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
if|if
condition|(
name|tbl
operator|.
name|getDbName
argument_list|()
operator|==
literal|null
operator|||
literal|""
operator|.
name|equals
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
operator|.
name|trim
argument_list|()
argument_list|)
condition|)
block|{
name|tbl
operator|.
name|setDbName
argument_list|(
name|getCurrentDatabase
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|tbl
operator|.
name|getCols
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|tbl
operator|.
name|setFields
argument_list|(
name|MetaStoreUtils
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getDeserializer
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|tbl
operator|.
name|checkValidity
argument_list|()
expr_stmt|;
if|if
condition|(
name|tbl
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|tbl
operator|.
name|getParameters
argument_list|()
operator|.
name|remove
argument_list|(
name|Constants
operator|.
name|DDL_TIME
argument_list|)
expr_stmt|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tTbl
init|=
name|tbl
operator|.
name|getTTable
argument_list|()
decl_stmt|;
name|PrincipalPrivilegeSet
name|principalPrivs
init|=
operator|new
name|PrincipalPrivilegeSet
argument_list|()
decl_stmt|;
name|SessionState
name|ss
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|ss
operator|!=
literal|null
condition|)
block|{
name|CreateTableAutomaticGrant
name|grants
init|=
name|ss
operator|.
name|getCreateTableGrants
argument_list|()
decl_stmt|;
if|if
condition|(
name|grants
operator|!=
literal|null
condition|)
block|{
name|principalPrivs
operator|.
name|setUserPrivileges
argument_list|(
name|grants
operator|.
name|getUserGrants
argument_list|()
argument_list|)
expr_stmt|;
name|principalPrivs
operator|.
name|setGroupPrivileges
argument_list|(
name|grants
operator|.
name|getGroupGrants
argument_list|()
argument_list|)
expr_stmt|;
name|principalPrivs
operator|.
name|setRolePrivileges
argument_list|(
name|grants
operator|.
name|getRoleGrants
argument_list|()
argument_list|)
expr_stmt|;
name|tTbl
operator|.
name|setPrivileges
argument_list|(
name|principalPrivs
argument_list|)
expr_stmt|;
block|}
block|}
name|getMSC
argument_list|()
operator|.
name|createTable
argument_list|(
name|tTbl
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyExistsException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ifNotExists
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    *    * @param tableName    *          table name    * @param indexName    *          index name    * @param indexHandlerClass    *          index handler class    * @param indexedCols    *          index columns    * @param indexTblName    *          index table's name    * @param deferredRebuild    *          referred build index table's data    * @param inputFormat    *          input format    * @param outputFormat    *          output format    * @param serde    * @param storageHandler    *          index table's storage handler    * @param location    *          location    * @param idxProps    *          idx    * @param serdeProps    *          serde properties    * @param collItemDelim    * @param fieldDelim    * @param fieldEscape    * @param lineDelim    * @param mapKeyDelim    * @throws HiveException    */
specifier|public
name|void
name|createIndex
parameter_list|(
name|String
name|tableName
parameter_list|,
name|String
name|indexName
parameter_list|,
name|String
name|indexHandlerClass
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|indexedCols
parameter_list|,
name|String
name|indexTblName
parameter_list|,
name|boolean
name|deferredRebuild
parameter_list|,
name|String
name|inputFormat
parameter_list|,
name|String
name|outputFormat
parameter_list|,
name|String
name|serde
parameter_list|,
name|String
name|storageHandler
parameter_list|,
name|String
name|location
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|idxProps
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|tblProps
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|serdeProps
parameter_list|,
name|String
name|collItemDelim
parameter_list|,
name|String
name|fieldDelim
parameter_list|,
name|String
name|fieldEscape
parameter_list|,
name|String
name|lineDelim
parameter_list|,
name|String
name|mapKeyDelim
parameter_list|,
name|String
name|indexComment
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|String
name|dbName
init|=
name|getCurrentDatabase
argument_list|()
decl_stmt|;
name|Index
name|old_index
init|=
literal|null
decl_stmt|;
try|try
block|{
name|old_index
operator|=
name|getIndex
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|indexName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{       }
if|if
condition|(
name|old_index
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Index "
operator|+
name|indexName
operator|+
literal|" already exists on table "
operator|+
name|tableName
operator|+
literal|", db="
operator|+
name|dbName
argument_list|)
throw|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|baseTbl
init|=
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|baseTbl
operator|.
name|getTableType
argument_list|()
operator|==
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"tableName="
operator|+
name|tableName
operator|+
literal|" is a VIRTUAL VIEW. Index on VIRTUAL VIEW is not supported."
argument_list|)
throw|;
block|}
if|if
condition|(
name|indexTblName
operator|==
literal|null
condition|)
block|{
name|indexTblName
operator|=
name|MetaStoreUtils
operator|.
name|getIndexTableName
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|indexName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|temp
init|=
literal|null
decl_stmt|;
try|try
block|{
name|temp
operator|=
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|indexTblName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{         }
if|if
condition|(
name|temp
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Table name "
operator|+
name|indexTblName
operator|+
literal|" already exists. Choose another name."
argument_list|)
throw|;
block|}
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|storageDescriptor
init|=
name|baseTbl
operator|.
name|getSd
argument_list|()
operator|.
name|deepCopy
argument_list|()
decl_stmt|;
name|SerDeInfo
name|serdeInfo
init|=
name|storageDescriptor
operator|.
name|getSerdeInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|serde
operator|!=
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|setSerializationLib
argument_list|(
name|serde
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|storageHandler
operator|==
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|setSerializationLib
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|HiveStorageHandler
name|sh
init|=
name|HiveUtils
operator|.
name|getStorageHandler
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|storageHandler
argument_list|)
decl_stmt|;
name|String
name|serDeClassName
init|=
name|sh
operator|.
name|getSerDeClass
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|serdeInfo
operator|.
name|setSerializationLib
argument_list|(
name|serDeClassName
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|fieldDelim
operator|!=
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|FIELD_DELIM
argument_list|,
name|fieldDelim
argument_list|)
expr_stmt|;
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|SERIALIZATION_FORMAT
argument_list|,
name|fieldDelim
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fieldEscape
operator|!=
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|ESCAPE_CHAR
argument_list|,
name|fieldEscape
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|collItemDelim
operator|!=
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|COLLECTION_DELIM
argument_list|,
name|collItemDelim
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mapKeyDelim
operator|!=
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|MAPKEY_DELIM
argument_list|,
name|mapKeyDelim
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|lineDelim
operator|!=
literal|null
condition|)
block|{
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|LINE_DELIM
argument_list|,
name|lineDelim
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serdeProps
operator|!=
literal|null
condition|)
block|{
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|iter
init|=
name|serdeProps
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|m
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|m
operator|.
name|getKey
argument_list|()
argument_list|,
name|m
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|storageDescriptor
operator|.
name|setLocation
argument_list|(
literal|null
argument_list|)
expr_stmt|;
if|if
condition|(
name|location
operator|!=
literal|null
condition|)
block|{
name|storageDescriptor
operator|.
name|setLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
name|storageDescriptor
operator|.
name|setInputFormat
argument_list|(
name|inputFormat
argument_list|)
expr_stmt|;
name|storageDescriptor
operator|.
name|setOutputFormat
argument_list|(
name|outputFormat
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|indexTblCols
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Order
argument_list|>
name|sortCols
init|=
operator|new
name|ArrayList
argument_list|<
name|Order
argument_list|>
argument_list|()
decl_stmt|;
name|storageDescriptor
operator|.
name|setBucketCols
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|int
name|k
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|storageDescriptor
operator|.
name|getCols
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|FieldSchema
name|col
init|=
name|storageDescriptor
operator|.
name|getCols
argument_list|()
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexedCols
operator|.
name|contains
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|indexTblCols
operator|.
name|add
argument_list|(
name|col
argument_list|)
expr_stmt|;
name|sortCols
operator|.
name|add
argument_list|(
operator|new
name|Order
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|k
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|k
operator|!=
name|indexedCols
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Check the index columns, they should appear in the table being indexed."
argument_list|)
throw|;
block|}
name|storageDescriptor
operator|.
name|setCols
argument_list|(
name|indexTblCols
argument_list|)
expr_stmt|;
name|storageDescriptor
operator|.
name|setSortCols
argument_list|(
name|sortCols
argument_list|)
expr_stmt|;
name|int
name|time
init|=
call|(
name|int
call|)
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|/
literal|1000
argument_list|)
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tt
init|=
literal|null
decl_stmt|;
name|HiveIndexHandler
name|indexHandler
init|=
name|HiveUtils
operator|.
name|getIndexHandler
argument_list|(
name|this
operator|.
name|getConf
argument_list|()
argument_list|,
name|indexHandlerClass
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexHandler
operator|.
name|usesIndexTable
argument_list|()
condition|)
block|{
name|tt
operator|=
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
argument_list|(
name|dbName
argument_list|,
name|indexTblName
argument_list|)
operator|.
name|getTTable
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partKeys
init|=
name|baseTbl
operator|.
name|getPartitionKeys
argument_list|()
decl_stmt|;
name|tt
operator|.
name|setPartitionKeys
argument_list|(
name|partKeys
argument_list|)
expr_stmt|;
name|tt
operator|.
name|setTableType
argument_list|(
name|TableType
operator|.
name|INDEX_TABLE
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|tblProps
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|prop
range|:
name|tblProps
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|tt
operator|.
name|putToParameters
argument_list|(
name|prop
operator|.
name|getKey
argument_list|()
argument_list|,
name|prop
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|deferredRebuild
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Please specify deferred rebuild using \" WITH DEFERRED REBUILD \"."
argument_list|)
throw|;
block|}
name|Index
name|indexDesc
init|=
operator|new
name|Index
argument_list|(
name|indexName
argument_list|,
name|indexHandlerClass
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|,
name|time
argument_list|,
name|time
argument_list|,
name|indexTblName
argument_list|,
name|storageDescriptor
argument_list|,
name|params
argument_list|,
name|deferredRebuild
argument_list|)
decl_stmt|;
name|indexDesc
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
literal|"comment"
argument_list|,
name|indexComment
argument_list|)
expr_stmt|;
if|if
condition|(
name|idxProps
operator|!=
literal|null
condition|)
block|{
name|indexDesc
operator|.
name|getParameters
argument_list|()
operator|.
name|putAll
argument_list|(
name|idxProps
argument_list|)
expr_stmt|;
block|}
name|indexHandler
operator|.
name|analyzeIndexDefinition
argument_list|(
name|baseTbl
argument_list|,
name|indexDesc
argument_list|,
name|tt
argument_list|)
expr_stmt|;
name|this
operator|.
name|getMSC
argument_list|()
operator|.
name|createIndex
argument_list|(
name|indexDesc
argument_list|,
name|tt
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Index
name|getIndex
parameter_list|(
name|String
name|qualifiedIndexName
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|getQualifiedNames
argument_list|(
name|qualifiedIndexName
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|names
operator|.
name|length
condition|)
block|{
case|case
literal|3
case|:
return|return
name|getIndex
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|,
name|names
index|[
literal|2
index|]
argument_list|)
return|;
case|case
literal|2
case|:
return|return
name|getIndex
argument_list|(
name|getCurrentDatabase
argument_list|()
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|)
return|;
default|default:
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Invalid index name:"
operator|+
name|qualifiedIndexName
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Index
name|getIndex
parameter_list|(
name|String
name|baseTableName
parameter_list|,
name|String
name|indexName
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|baseTableName
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|getIndex
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|indexName
argument_list|)
return|;
block|}
specifier|public
name|Index
name|getIndex
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|baseTableName
parameter_list|,
name|String
name|indexName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|this
operator|.
name|getMSC
argument_list|()
operator|.
name|getIndex
argument_list|(
name|dbName
argument_list|,
name|baseTableName
argument_list|,
name|indexName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|dropIndex
parameter_list|(
name|String
name|db_name
parameter_list|,
name|String
name|tbl_name
parameter_list|,
name|String
name|index_name
parameter_list|,
name|boolean
name|deleteData
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|dropIndex
argument_list|(
name|db_name
argument_list|,
name|tbl_name
argument_list|,
name|index_name
argument_list|,
name|deleteData
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition or table doesn't exist."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unknown error. Please check logs."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Drops table along with the data in it. If the table doesn't exist    * then it is a no-op    * @param dbName database where the table lives    * @param tableName table to drop    * @throws HiveException thrown if the drop fails    * Drops table along with the data in it. If the table doesn't exist then it    * is a no-op    *    * @param dbName    *          database where the table lives    * @param tableName    *          table to drop    * @throws HiveException    *           thrown if the drop fails    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|dropTable
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drops table along with the data in it. If the table doesn't exist    * then it is a no-op    * @param dbName database where the table lives    * @param tableName table to drop    * @throws HiveException thrown if the drop fails    * Drops table along with the data in it. If the table doesn't exist then it    * is a no-op    *    * @param dbName    *          database where the table lives    * @param tableName    *          table to drop    * @throws HiveException    *           thrown if the drop fails    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|dropTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Drops the table.    *    * @param tableName    * @param deleteData    *          deletes the underlying data along with metadata    * @param ignoreUnknownTab    *          an exception if thrown if this is falser and table doesn't exist    * @throws HiveException    */
specifier|public
name|void
name|dropTable
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|boolean
name|deleteData
parameter_list|,
name|boolean
name|ignoreUnknownTab
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|dropTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
name|deleteData
argument_list|,
name|ignoreUnknownTab
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreUnknownTab
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|HiveConf
name|getConf
parameter_list|()
block|{
return|return
operator|(
name|conf
operator|)
return|;
block|}
comment|/**    * Returns metadata for the table named tableName    * @param tableName the name of the table    * @return    * @throws HiveException if there's an internal error or if the    * table doesn't exist    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|getTable
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Returns metadata for the table named tableName    * @param tableName the name of the table    * @param throwException controls whether an exception is thrown or a returns a null    * @return    * @throws HiveException if there's an internal error or if the    * table doesn't exist    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|tableName
parameter_list|,
name|boolean
name|throwException
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|getTable
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|throwException
argument_list|)
return|;
block|}
comment|/**    * Returns metadata of the table    *    * @param dbName    *          the name of the database    * @param tableName    *          the name of the table    * @return the table    * @exception HiveException    *              if there's an internal error or if the table doesn't exist    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|dbName
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tableName
operator|.
name|contains
argument_list|(
literal|"."
argument_list|)
condition|)
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|getTable
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
literal|true
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|this
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|,
literal|true
argument_list|)
return|;
block|}
block|}
comment|/**    * Returns metadata of the table    *    * @param dbName    *          the name of the database    * @param tableName    *          the name of the table    * @param throwException    *          controls whether an exception is thrown or a returns a null    * @return the table or if throwException is false a null value.    * @throws HiveException    */
specifier|public
name|Table
name|getTable
parameter_list|(
specifier|final
name|String
name|dbName
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|,
name|boolean
name|throwException
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tableName
operator|==
literal|null
operator|||
name|tableName
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"empty table creation??"
argument_list|)
throw|;
block|}
comment|// Get the table from metastore
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tTable
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tTable
operator|=
name|getMSC
argument_list|()
operator|.
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
if|if
condition|(
name|throwException
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTableException
argument_list|(
literal|"Table "
operator|+
name|tableName
operator|+
literal|" not found "
argument_list|,
name|tableName
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to fetch table "
operator|+
name|tableName
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// For non-views, we need to do some extra fixes
if|if
condition|(
operator|!
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|tTable
operator|.
name|getTableType
argument_list|()
argument_list|)
condition|)
block|{
comment|// Fix the non-printable chars
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
init|=
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getParameters
argument_list|()
decl_stmt|;
name|String
name|sf
init|=
name|parameters
operator|.
name|get
argument_list|(
name|SERIALIZATION_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|sf
operator|!=
literal|null
condition|)
block|{
name|char
index|[]
name|b
init|=
name|sf
operator|.
name|toCharArray
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|b
operator|.
name|length
operator|==
literal|1
operator|)
operator|&&
operator|(
name|b
index|[
literal|0
index|]
operator|<
literal|10
operator|)
condition|)
block|{
comment|// ^A, ^B, ^C, ^D, \t
name|parameters
operator|.
name|put
argument_list|(
name|SERIALIZATION_FORMAT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|b
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Use LazySimpleSerDe for MetadataTypedColumnsetSerDe.
comment|// NOTE: LazySimpleSerDe does not support tables with a single column of
comment|// col
comment|// of type "array<string>". This happens when the table is created using
comment|// an
comment|// earlier version of Hive.
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|MetadataTypedColumnsetSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
operator|&&
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getColsSize
argument_list|()
operator|>
literal|0
operator|&&
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getType
argument_list|()
operator|.
name|indexOf
argument_list|(
literal|'<'
argument_list|)
operator|==
operator|-
literal|1
condition|)
block|{
name|tTable
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|Table
name|table
init|=
operator|new
name|Table
argument_list|(
name|tTable
argument_list|)
decl_stmt|;
name|table
operator|.
name|checkValidity
argument_list|()
expr_stmt|;
return|return
name|table
return|;
block|}
comment|/**    * Get all table names for the current database.    * @return List of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllTables
parameter_list|()
throws|throws
name|HiveException
block|{
return|return
name|getAllTables
argument_list|(
name|getCurrentDatabase
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get all table names for the specified database.    * @param dbName    * @return List of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllTables
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByPattern
argument_list|(
name|dbName
argument_list|,
literal|".*"
argument_list|)
return|;
block|}
comment|/**    * Returns all existing tables from default database which match the given    * pattern. The matching occurs as per Java regular expressions    *    * @param tablePattern    *          java re pattern    * @return list of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesByPattern
parameter_list|(
name|String
name|tablePattern
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getTablesByPattern
argument_list|(
name|getCurrentDatabase
argument_list|()
argument_list|,
name|tablePattern
argument_list|)
return|;
block|}
comment|/**    * Returns all existing tables from the specified database which match the given    * pattern. The matching occurs as per Java regular expressions.    * @param dbName    * @param tablePattern    * @return list of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesByPattern
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tablePattern
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getTables
argument_list|(
name|dbName
argument_list|,
name|tablePattern
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Returns all existing tables from the given database which match the given    * pattern. The matching occurs as per Java regular expressions    *    * @param database    *          the database name    * @param tablePattern    *          java re pattern    * @return list of table names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getTablesForDb
parameter_list|(
name|String
name|database
parameter_list|,
name|String
name|tablePattern
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getTables
argument_list|(
name|database
argument_list|,
name|tablePattern
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all existing database names.    *    * @return List of database names.    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllDatabases
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getAllDatabases
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all existing databases that match the given    * pattern. The matching occurs as per Java regular expressions    *    * @param databasePattern    *          java re pattern    * @return list of database names    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getDatabasesByPattern
parameter_list|(
name|String
name|databasePattern
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDatabases
argument_list|(
name|databasePattern
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|grantPrivileges
parameter_list|(
name|PrivilegeBag
name|privileges
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|grant_privileges
argument_list|(
name|privileges
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param userName    *          principal name    * @param isRole    *          is the given principal name a role    * @param isGroup    *          is the given principal name a group    * @param privileges    *          a bag of privileges    * @return    * @throws HiveException    */
specifier|public
name|boolean
name|revokePrivileges
parameter_list|(
name|PrivilegeBag
name|privileges
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|revoke_privileges
argument_list|(
name|privileges
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Query metadata to see if a database with the given name already exists.    *    * @param dbName    * @return true if a database with the given name already exists, false if    *         does not exist.    * @throws HiveException    */
specifier|public
name|boolean
name|databaseExists
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getDatabase
argument_list|(
name|dbName
argument_list|)
operator|!=
literal|null
return|;
block|}
comment|/**    * Get the database by name.    * @param dbName the name of the database.    * @return a Database object if this database exists, null otherwise.    * @throws HiveException    */
specifier|public
name|Database
name|getDatabase
parameter_list|(
name|String
name|dbName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|dbName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Load a directory into a Hive Table Partition - Alters existing content of    * the partition with the contents of loadPath. - If he partition does not    * exist - one is created - files in loadPath are moved into Hive. But the    * directory itself is not removed.    *    * @param loadPath    *          Directory containing files to load into Table    * @param tableName    *          name of table to be loaded.    * @param partSpec    *          defines which partition needs to be loaded    * @param replace    *          if true - replace files in the partition, otherwise add files to    *          the partition    * @param holdDDLTime if true, force [re]create the partition    * @param inheritTableSpecs if true, on [re]creating the partition, take the    *          location/inputformat/outputformat/serde details from table spec    * @param tmpDirPath    *          The temporary directory.    */
specifier|public
name|void
name|loadPartition
parameter_list|(
name|Path
name|loadPath
parameter_list|,
name|String
name|tableName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|boolean
name|replace
parameter_list|,
name|boolean
name|holdDDLTime
parameter_list|,
name|boolean
name|inheritTableSpecs
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
try|try
block|{
comment|/**        * Move files before creating the partition since down stream processes        * check for existence of partition in metadata before accessing the data.        * If partition is created before data is moved, downstream waiting        * processes might move forward with partial data        */
name|Partition
name|oldPart
init|=
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|Path
name|oldPartPath
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|oldPart
operator|!=
literal|null
condition|)
block|{
name|oldPartPath
operator|=
name|oldPart
operator|.
name|getPartitionPath
argument_list|()
expr_stmt|;
block|}
name|Path
name|newPartPath
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|inheritTableSpecs
condition|)
block|{
name|Path
name|partPath
init|=
operator|new
name|Path
argument_list|(
name|tbl
operator|.
name|getDataLocation
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|,
name|Warehouse
operator|.
name|makePartPath
argument_list|(
name|partSpec
argument_list|)
argument_list|)
decl_stmt|;
name|newPartPath
operator|=
operator|new
name|Path
argument_list|(
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
argument_list|,
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|partPath
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldPart
operator|!=
literal|null
condition|)
block|{
comment|/*            * If we are moving the partition across filesystem boundaries            * inherit from the table properties. Otherwise (same filesystem) use the            * original partition location.            *            * See: HIVE-1707 and HIVE-2117 for background            */
name|FileSystem
name|oldPartPathFS
init|=
name|oldPartPath
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|loadPathFS
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldPartPathFS
operator|.
name|equals
argument_list|(
name|loadPathFS
argument_list|)
condition|)
block|{
name|newPartPath
operator|=
name|oldPartPath
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|newPartPath
operator|=
name|oldPartPath
expr_stmt|;
block|}
if|if
condition|(
name|replace
condition|)
block|{
name|Hive
operator|.
name|replaceFiles
argument_list|(
name|loadPath
argument_list|,
name|newPartPath
argument_list|,
name|oldPartPath
argument_list|,
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|tbl
operator|.
name|getDataLocation
argument_list|()
argument_list|,
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|Hive
operator|.
name|copyFiles
argument_list|(
name|loadPath
argument_list|,
name|newPartPath
argument_list|,
name|fs
argument_list|)
expr_stmt|;
block|}
comment|// recreate the partition if it existed before
if|if
condition|(
operator|!
name|holdDDLTime
condition|)
block|{
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|true
argument_list|,
name|newPartPath
operator|.
name|toString
argument_list|()
argument_list|,
name|inheritTableSpecs
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Given a source directory name of the load path, load all dynamically generated partitions    * into the specified table and return a list of strings that represent the dynamic partition    * paths.    * @param loadPath    * @param tableName    * @param partSpec    * @param replace    * @param tmpDirPath    * @param numSp: number of static partitions in the partition spec    * @return    * @throws HiveException    */
specifier|public
name|ArrayList
argument_list|<
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|loadDynamicPartitions
parameter_list|(
name|Path
name|loadPath
parameter_list|,
name|String
name|tableName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|boolean
name|replace
parameter_list|,
name|int
name|numDP
parameter_list|,
name|boolean
name|holdDDLTime
parameter_list|)
throws|throws
name|HiveException
block|{
name|Set
argument_list|<
name|Path
argument_list|>
name|validPartitions
init|=
operator|new
name|HashSet
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
name|ArrayList
argument_list|<
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|fullPartSpecs
init|=
operator|new
name|ArrayList
argument_list|<
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|leafStatus
init|=
name|Utilities
operator|.
name|getFileStatusRecurse
argument_list|(
name|loadPath
argument_list|,
name|numDP
operator|+
literal|1
argument_list|,
name|fs
argument_list|)
decl_stmt|;
comment|// Check for empty partitions
for|for
control|(
name|FileStatus
name|s
range|:
name|leafStatus
control|)
block|{
if|if
condition|(
name|s
operator|.
name|isDir
argument_list|()
condition|)
block|{
comment|// No leaves in this directory
name|LOG
operator|.
name|info
argument_list|(
literal|"NOT moving empty directory: "
operator|+
name|s
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|validPartitions
operator|.
name|add
argument_list|(
name|s
operator|.
name|getPath
argument_list|()
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|validPartitions
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No partition is genereated by dynamic partitioning"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|validPartitions
operator|.
name|size
argument_list|()
operator|>
name|conf
operator|.
name|getIntVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Number of dynamic partitions created is "
operator|+
name|validPartitions
operator|.
name|size
argument_list|()
operator|+
literal|", which is more than "
operator|+
name|conf
operator|.
name|getIntVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
argument_list|)
operator|+
literal|". To solve this try to set "
operator|+
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
operator|.
name|varname
operator|+
literal|" to at least "
operator|+
name|validPartitions
operator|.
name|size
argument_list|()
operator|+
literal|'.'
argument_list|)
throw|;
block|}
comment|// for each dynamically created DP directory, construct a full partition spec
comment|// and load the partition based on that
name|Iterator
argument_list|<
name|Path
argument_list|>
name|iter
init|=
name|validPartitions
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
comment|// get the dynamically created directory
name|Path
name|partPath
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|fs
operator|.
name|getFileStatus
argument_list|(
name|partPath
argument_list|)
operator|.
name|isDir
argument_list|()
operator|:
literal|"partitions "
operator|+
name|partPath
operator|+
literal|" is not a directory !"
assert|;
comment|// generate a full partition specification
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|fullPartSpec
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|(
name|partSpec
argument_list|)
decl_stmt|;
name|Warehouse
operator|.
name|makeSpecFromName
argument_list|(
name|fullPartSpec
argument_list|,
name|partPath
argument_list|)
expr_stmt|;
name|fullPartSpecs
operator|.
name|add
argument_list|(
name|fullPartSpec
argument_list|)
expr_stmt|;
comment|// finally load the partition -- move the file to the final table address
name|loadPartition
argument_list|(
name|partPath
argument_list|,
name|tableName
argument_list|,
name|fullPartSpec
argument_list|,
name|replace
argument_list|,
name|holdDDLTime
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"New loading path = "
operator|+
name|partPath
operator|+
literal|" with partSpec "
operator|+
name|fullPartSpec
argument_list|)
expr_stmt|;
block|}
return|return
name|fullPartSpecs
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Load a directory into a Hive Table. - Alters existing content of table with    * the contents of loadPath. - If table does not exist - an exception is    * thrown - files in loadPath are moved into Hive. But the directory itself is    * not removed.    *    * @param loadPath    *          Directory containing files to load into Table    * @param tableName    *          name of table to be loaded.    * @param replace    *          if true - replace files in the table, otherwise add files to table    * @param tmpDirPath    *          The temporary directory.    */
specifier|public
name|void
name|loadTable
parameter_list|(
name|Path
name|loadPath
parameter_list|,
name|String
name|tableName
parameter_list|,
name|boolean
name|replace
parameter_list|,
name|boolean
name|holdDDLTime
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|tbl
init|=
name|getTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|replace
condition|)
block|{
name|tbl
operator|.
name|replaceFiles
argument_list|(
name|loadPath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tbl
operator|.
name|copyFiles
argument_list|(
name|loadPath
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|holdDDLTime
condition|)
block|{
try|try
block|{
name|alterTable
argument_list|(
name|tableName
argument_list|,
name|tbl
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvalidOperationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Creates a partition.    *    * @param tbl    *          table for which partition needs to be created    * @param partSpec    *          partition keys and their values    * @return created partition object    * @throws HiveException    *           if table doesn't exist or partition already exists    */
specifier|public
name|Partition
name|createPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|createPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Creates a partition    *    * @param tbl    *          table for which partition needs to be created    * @param partSpec    *          partition keys and their values    * @param location    *          location of this partition    * @param partParams    *          partition parameters    * @param inputFormat the inputformat class    * @param outputformat the outputformat class    * @param numBuckets the number of buckets    * @param cols the column schema    * @param serializationLib the serde class    * @param serdeParams the serde parameters    * @param bucketCols the bucketing columns    * @param sortCols sort columns and order    *    * @return created partition object    * @throws HiveException    *           if table doesn't exist or partition already exists    */
specifier|public
name|Partition
name|createPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|Path
name|location
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partParams
parameter_list|,
name|String
name|inputFormat
parameter_list|,
name|String
name|outputFormat
parameter_list|,
name|int
name|numBuckets
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|,
name|String
name|serializationLib
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|serdeParams
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|bucketCols
parameter_list|,
name|List
argument_list|<
name|Order
argument_list|>
name|sortCols
parameter_list|)
throws|throws
name|HiveException
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|partition
init|=
literal|null
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|tbl
operator|.
name|getPartCols
argument_list|()
control|)
block|{
name|String
name|val
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
name|val
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"add partition: Value for key "
operator|+
name|field
operator|.
name|getName
argument_list|()
operator|+
literal|" is null or empty"
argument_list|)
throw|;
block|}
block|}
try|try
block|{
name|Partition
name|tmpPart
init|=
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|location
argument_list|)
decl_stmt|;
comment|// No need to clear DDL_TIME in parameters since we know it's
comment|// not populated on construction.
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|inPart
init|=
name|tmpPart
operator|.
name|getTPartition
argument_list|()
decl_stmt|;
if|if
condition|(
name|partParams
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|setParameters
argument_list|(
name|partParams
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|inputFormat
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|setInputFormat
argument_list|(
name|inputFormat
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|outputFormat
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|setOutputFormat
argument_list|(
name|outputFormat
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|numBuckets
operator|!=
operator|-
literal|1
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|setNumBuckets
argument_list|(
name|numBuckets
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cols
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|setCols
argument_list|(
name|cols
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serializationLib
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|serializationLib
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|serdeParams
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setParameters
argument_list|(
name|serdeParams
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bucketCols
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|setBucketCols
argument_list|(
name|bucketCols
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sortCols
operator|!=
literal|null
condition|)
block|{
name|inPart
operator|.
name|getSd
argument_list|()
operator|.
name|setSortCols
argument_list|(
name|sortCols
argument_list|)
expr_stmt|;
block|}
name|partition
operator|=
name|getMSC
argument_list|()
operator|.
name|add_partition
argument_list|(
name|inPart
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|partition
argument_list|)
return|;
block|}
specifier|public
name|Partition
name|getPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|boolean
name|forceCreate
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getPartition
argument_list|(
name|tbl
argument_list|,
name|partSpec
argument_list|,
name|forceCreate
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Returns partition metadata    *    * @param tbl    *          the partition's table    * @param partSpec    *          partition keys and values    * @param forceCreate    *          if this is true and partition doesn't exist then a partition is    *          created    * @param partPath the path where the partition data is located    * @param inheritTableSpecs whether to copy over the table specs for if/of/serde    * @return result partition object or null if there is no partition    * @throws HiveException    */
specifier|public
name|Partition
name|getPartition
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|boolean
name|forceCreate
parameter_list|,
name|String
name|partPath
parameter_list|,
name|boolean
name|inheritTableSpecs
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isValidSpec
argument_list|(
name|partSpec
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Invalid partition: "
operator|+
name|partSpec
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|tbl
operator|.
name|getPartCols
argument_list|()
control|)
block|{
name|String
name|val
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|// enable dynamic partitioning
if|if
condition|(
name|val
operator|==
literal|null
operator|&&
operator|!
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONING
argument_list|)
operator|||
name|val
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"get partition: Value for key "
operator|+
name|field
operator|.
name|getName
argument_list|()
operator|+
literal|" is null or empty"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tpart
operator|=
name|getMSC
argument_list|()
operator|.
name|getPartitionWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|nsoe
parameter_list|)
block|{
comment|// this means no partition exists for the given partition
comment|// key value pairs - thrift cannot handle null return values, hence
comment|// getPartition() throws NoSuchObjectException to indicate null partition
name|tpart
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
try|try
block|{
if|if
condition|(
name|forceCreate
condition|)
block|{
if|if
condition|(
name|tpart
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"creating partition for table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" with partition spec : "
operator|+
name|partSpec
argument_list|)
expr_stmt|;
name|tpart
operator|=
name|getMSC
argument_list|()
operator|.
name|appendPartition
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|pvals
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"altering partition for table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" with partition spec : "
operator|+
name|partSpec
argument_list|)
expr_stmt|;
if|if
condition|(
name|inheritTableSpecs
condition|)
block|{
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setOutputFormat
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getOutputFormat
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setInputFormat
argument_list|(
name|tbl
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getInputFormat
argument_list|()
argument_list|)
expr_stmt|;
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|setSerializationLib
argument_list|(
name|tbl
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|partPath
operator|==
literal|null
operator|||
name|partPath
operator|.
name|trim
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"new partition path should not be null or empty."
argument_list|)
throw|;
block|}
name|tpart
operator|.
name|getSd
argument_list|()
operator|.
name|setLocation
argument_list|(
name|partPath
argument_list|)
expr_stmt|;
name|alterPartition
argument_list|(
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tpart
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
return|;
block|}
specifier|public
name|boolean
name|dropPartition
parameter_list|(
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|part_vals
parameter_list|,
name|boolean
name|deleteData
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
return|return
name|dropPartition
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|part_vals
argument_list|,
name|deleteData
argument_list|)
return|;
block|}
specifier|public
name|boolean
name|dropPartition
parameter_list|(
name|String
name|db_name
parameter_list|,
name|String
name|tbl_name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|part_vals
parameter_list|,
name|boolean
name|deleteData
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|dropPartition
argument_list|(
name|db_name
argument_list|,
name|tbl_name
argument_list|,
name|part_vals
argument_list|,
name|deleteData
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition or table doesn't exist."
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unknown error. Please check logs."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionNames
parameter_list|(
name|String
name|tblName
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|Table
name|t
init|=
name|newTable
argument_list|(
name|tblName
argument_list|)
decl_stmt|;
return|return
name|getPartitionNames
argument_list|(
name|t
operator|.
name|getDbName
argument_list|()
argument_list|,
name|t
operator|.
name|getTableName
argument_list|()
argument_list|,
name|max
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionNames
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
literal|null
decl_stmt|;
try|try
block|{
name|names
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionNames
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|max
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|names
return|;
block|}
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getPartitionNames
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
literal|null
decl_stmt|;
name|Table
name|t
init|=
name|getTable
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
name|getPvals
argument_list|(
name|t
operator|.
name|getPartCols
argument_list|()
argument_list|,
name|partSpec
argument_list|)
decl_stmt|;
try|try
block|{
name|names
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionNames
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|pvals
argument_list|,
name|max
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|names
return|;
block|}
comment|/**    * get all the partitions that the table has    *    * @param tbl    *          object for which partition is needed    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitions
parameter_list|(
name|Table
name|tbl
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
decl_stmt|;
try|try
block|{
name|tParts
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|tParts
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|parts
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|parts
return|;
block|}
else|else
block|{
name|Partition
name|part
init|=
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|parts
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
return|return
name|parts
return|;
block|}
block|}
specifier|private
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPvals
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|partCols
control|)
block|{
name|String
name|val
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
literal|""
expr_stmt|;
block|}
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
return|return
name|pvals
return|;
block|}
comment|/**    * get all the partitions of the table that matches the given partial    * specification. partition columns whose value is can be anything should be    * an empty string.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @param limit number of partitions to return    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitions
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partialPartSpec
parameter_list|,
name|short
name|limit
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition spec should only be supplied for a "
operator|+
literal|"partitioned table"
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|partialPvals
init|=
name|getPvals
argument_list|(
name|tbl
operator|.
name|getPartCols
argument_list|()
argument_list|,
name|partialPartSpec
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|partitions
init|=
literal|null
decl_stmt|;
try|try
block|{
name|partitions
operator|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsWithAuthInfo
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partialPvals
argument_list|,
name|limit
argument_list|,
name|getUserName
argument_list|()
argument_list|,
name|getGroupNames
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|qlPartitions
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|p
range|:
name|partitions
control|)
block|{
name|qlPartitions
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|qlPartitions
return|;
block|}
comment|/**    * get all the partitions of the table that matches the given partial    * specification. partition columns whose value is can be anything should be    * an empty string.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitions
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partialPartSpec
parameter_list|)
throws|throws
name|HiveException
block|{
return|return
name|getPartitions
argument_list|(
name|tbl
argument_list|,
name|partialPartSpec
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
return|;
block|}
comment|/**    * get all the partitions of the table that matches the given partial    * specification. partition columns whose value is can be anything should be    * an empty string.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @param partialPartSpec    *          partial partition specification (some subpartitions can be empty).    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsByNames
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partialPartSpec
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition spec should only be supplied for a "
operator|+
literal|"partitioned table"
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
name|getPartitionNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partialPartSpec
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
name|getPartitionsByNames
argument_list|(
name|tbl
argument_list|,
name|names
argument_list|)
decl_stmt|;
return|return
name|partitions
return|;
block|}
comment|/**    * Get all partitions of the table that matches the list of given partition names.    *    * @param tbl    *          object for which partition is needed. Must be partitioned.    * @param partNames    *          list of partition names    * @return list of partition objects    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsByNames
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|)
throws|throws
name|HiveException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition spec should only be supplied for a "
operator|+
literal|"partitioned table"
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|Partition
argument_list|>
name|partitions
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|partNames
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|batchSize
init|=
name|HiveConf
operator|.
name|getIntVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_BATCH_RETRIEVE_MAX
argument_list|)
decl_stmt|;
name|int
name|nParts
init|=
name|partNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|nBatches
init|=
name|nParts
operator|/
name|batchSize
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nBatches
condition|;
operator|++
name|i
control|)
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|getPartitionsByNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|i
operator|*
name|batchSize
argument_list|,
operator|(
name|i
operator|+
literal|1
operator|)
operator|*
name|batchSize
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|tParts
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|partitions
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|nParts
operator|>
name|nBatches
operator|*
name|batchSize
condition|)
block|{
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|getPartitionsByNames
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|nBatches
operator|*
name|batchSize
argument_list|,
name|nParts
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|tParts
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tpart
range|:
name|tParts
control|)
block|{
name|partitions
operator|.
name|add
argument_list|(
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tpart
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|partitions
return|;
block|}
comment|/**    * Get a list of Partitions by filter.    * @param tbl The table containing the partitions.    * @param filter A string represent partition predicates.    * @return a list of partitions satisfying the partition predicates.    * @throws HiveException    * @throws MetaException    * @throws NoSuchObjectException    * @throws TException    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsByFilter
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|String
name|filter
parameter_list|)
throws|throws
name|HiveException
throws|,
name|MetaException
throws|,
name|NoSuchObjectException
throws|,
name|TException
block|{
if|if
condition|(
operator|!
name|tbl
operator|.
name|isPartitioned
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Partition spec should only be supplied for a "
operator|+
literal|"partitioned table"
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
argument_list|>
name|tParts
init|=
name|getMSC
argument_list|()
operator|.
name|listPartitionsByFilter
argument_list|(
name|tbl
operator|.
name|getDbName
argument_list|()
argument_list|,
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|,
name|filter
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|tParts
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|tPart
range|:
name|tParts
control|)
block|{
name|Partition
name|part
init|=
operator|new
name|Partition
argument_list|(
name|tbl
argument_list|,
name|tPart
argument_list|)
decl_stmt|;
name|results
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
comment|/**    * Get the name of the current database    * @return    */
specifier|public
name|String
name|getCurrentDatabase
parameter_list|()
block|{
if|if
condition|(
literal|null
operator|==
name|currentDatabase
condition|)
block|{
name|currentDatabase
operator|=
name|DEFAULT_DATABASE_NAME
expr_stmt|;
block|}
return|return
name|currentDatabase
return|;
block|}
comment|/**    * Set the name of the current database    * @param currentDatabase    */
specifier|public
name|void
name|setCurrentDatabase
parameter_list|(
name|String
name|currentDatabase
parameter_list|)
block|{
name|this
operator|.
name|currentDatabase
operator|=
name|currentDatabase
expr_stmt|;
block|}
specifier|public
name|void
name|createRole
parameter_list|(
name|String
name|roleName
parameter_list|,
name|String
name|ownerName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|create_role
argument_list|(
operator|new
name|Role
argument_list|(
name|roleName
argument_list|,
operator|-
literal|1
argument_list|,
name|ownerName
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dropRole
parameter_list|(
name|String
name|roleName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|getMSC
argument_list|()
operator|.
name|drop_role
argument_list|(
name|roleName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get all existing role names.    *    * @return List of role names.    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getAllRoleNames
parameter_list|()
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|listRoleNames
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|Role
argument_list|>
name|showRoleGrant
parameter_list|(
name|String
name|principalName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|list_roles
argument_list|(
name|principalName
argument_list|,
name|principalType
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|grantRole
parameter_list|(
name|String
name|roleName
parameter_list|,
name|String
name|userName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|,
name|String
name|grantor
parameter_list|,
name|PrincipalType
name|grantorType
parameter_list|,
name|boolean
name|grantOption
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|grant_role
argument_list|(
name|roleName
argument_list|,
name|userName
argument_list|,
name|principalType
argument_list|,
name|grantor
argument_list|,
name|grantorType
argument_list|,
name|grantOption
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|boolean
name|revokeRole
parameter_list|(
name|String
name|roleName
parameter_list|,
name|String
name|userName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|revoke_role
argument_list|(
name|roleName
argument_list|,
name|userName
argument_list|,
name|principalType
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|Role
argument_list|>
name|listRoles
parameter_list|(
name|String
name|userName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|getMSC
argument_list|()
operator|.
name|list_roles
argument_list|(
name|userName
argument_list|,
name|principalType
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param objectType    *          hive object type    * @param db_name    *          database name    * @param table_name    *          table name    * @param part_values    *          partition values    * @param column_name    *          column name    * @param user_name    *          user name    * @param group_names    *          group names    * @return    * @throws HiveException    */
specifier|public
name|PrincipalPrivilegeSet
name|get_privilege_set
parameter_list|(
name|HiveObjectType
name|objectType
parameter_list|,
name|String
name|db_name
parameter_list|,
name|String
name|table_name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|part_values
parameter_list|,
name|String
name|column_name
parameter_list|,
name|String
name|user_name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|group_names
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|HiveObjectRef
name|hiveObj
init|=
operator|new
name|HiveObjectRef
argument_list|(
name|objectType
argument_list|,
name|db_name
argument_list|,
name|table_name
argument_list|,
name|part_values
argument_list|,
name|column_name
argument_list|)
decl_stmt|;
return|return
name|getMSC
argument_list|()
operator|.
name|get_privilege_set
argument_list|(
name|hiveObj
argument_list|,
name|user_name
argument_list|,
name|group_names
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param objectType    *          hive object type    * @param principalName    * @param principalType    * @param dbName    * @param tableName    * @param partValues    * @param columnName    * @return    * @throws HiveException    */
specifier|public
name|List
argument_list|<
name|HiveObjectPrivilege
argument_list|>
name|showPrivilegeGrant
parameter_list|(
name|HiveObjectType
name|objectType
parameter_list|,
name|String
name|principalName
parameter_list|,
name|PrincipalType
name|principalType
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partValues
parameter_list|,
name|String
name|columnName
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|HiveObjectRef
name|hiveObj
init|=
operator|new
name|HiveObjectRef
argument_list|(
name|objectType
argument_list|,
name|dbName
argument_list|,
name|tableName
argument_list|,
name|partValues
argument_list|,
name|columnName
argument_list|)
decl_stmt|;
return|return
name|getMSC
argument_list|()
operator|.
name|list_privileges
argument_list|(
name|principalName
argument_list|,
name|principalType
argument_list|,
name|hiveObj
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|static
specifier|private
name|void
name|checkPaths
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
index|[]
name|srcs
parameter_list|,
name|Path
name|destf
parameter_list|,
name|boolean
name|replace
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
for|for
control|(
name|FileStatus
name|src
range|:
name|srcs
control|)
block|{
name|FileStatus
index|[]
name|items
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|src
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|item
range|:
name|items
control|)
block|{
name|Path
name|itemStaging
init|=
name|item
operator|.
name|getPath
argument_list|()
decl_stmt|;
if|if
condition|(
name|Utilities
operator|.
name|isTempPath
argument_list|(
name|item
argument_list|)
condition|)
block|{
comment|// This check is redundant because temp files are removed by
comment|// execution layer before
comment|// calling loadTable/Partition. But leaving it in just in case.
name|fs
operator|.
name|delete
argument_list|(
name|itemStaging
argument_list|,
literal|true
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|item
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"checkPaths: "
operator|+
name|src
operator|.
name|getPath
argument_list|()
operator|+
literal|" has nested directory"
operator|+
name|itemStaging
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|replace
condition|)
block|{
comment|// It's possible that the file we're copying may have the same
comment|// relative name as an existing file in the "destf" directory.
comment|// So let's make a quick check to see if we can rename any
comment|// potential offenders so as to allow them to move into the
comment|// "destf" directory. The scheme is dead simple: simply tack
comment|// on "_copy_N" where N starts at 1 and works its way up until
comment|// we find a free space.
comment|// Note: there are race conditions here, but I don't believe
comment|// they're worse than what was already present.
name|int
name|counter
init|=
literal|1
decl_stmt|;
comment|// Strip off the file type, if any so we don't make:
comment|// 000000_0.gz -> 000000_0.gz_copy_1
name|String
name|name
init|=
name|itemStaging
operator|.
name|getName
argument_list|()
decl_stmt|;
name|String
name|filetype
decl_stmt|;
name|int
name|index
init|=
name|name
operator|.
name|lastIndexOf
argument_list|(
literal|'.'
argument_list|)
decl_stmt|;
if|if
condition|(
name|index
operator|>=
literal|0
condition|)
block|{
name|filetype
operator|=
name|name
operator|.
name|substring
argument_list|(
name|index
argument_list|)
expr_stmt|;
name|name
operator|=
name|name
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|index
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|filetype
operator|=
literal|""
expr_stmt|;
block|}
name|Path
name|itemDest
init|=
operator|new
name|Path
argument_list|(
name|destf
argument_list|,
name|itemStaging
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|itemStagingBase
init|=
operator|new
name|Path
argument_list|(
name|itemStaging
operator|.
name|getParent
argument_list|()
argument_list|,
name|name
argument_list|)
decl_stmt|;
while|while
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|itemDest
argument_list|)
condition|)
block|{
name|Path
name|proposedStaging
init|=
name|itemStagingBase
operator|.
name|suffix
argument_list|(
literal|"_copy_"
operator|+
name|counter
operator|++
argument_list|)
operator|.
name|suffix
argument_list|(
name|filetype
argument_list|)
decl_stmt|;
name|Path
name|proposedDest
init|=
operator|new
name|Path
argument_list|(
name|destf
argument_list|,
name|proposedStaging
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|proposedDest
argument_list|)
condition|)
block|{
comment|// There's already a file in our destination directory with our
comment|// _copy_N suffix. We've been here before...
name|LOG
operator|.
name|trace
argument_list|(
name|proposedDest
operator|+
literal|" already exists"
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|itemStaging
argument_list|,
name|proposedStaging
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Unsuccessfully in attempt to rename "
operator|+
name|itemStaging
operator|+
literal|" to "
operator|+
name|proposedStaging
operator|+
literal|"..."
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Successfully renamed "
operator|+
name|itemStaging
operator|+
literal|" to "
operator|+
name|proposedStaging
argument_list|)
expr_stmt|;
name|itemDest
operator|=
name|proposedDest
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"checkPaths: filesystem error in check phase"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|static
specifier|protected
name|void
name|copyFiles
parameter_list|(
name|Path
name|srcf
parameter_list|,
name|Path
name|destf
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
comment|// create the destination if it does not exist
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|destf
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|destf
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"copyFiles: error while checking/creating destination directory!!!"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|FileStatus
index|[]
name|srcs
decl_stmt|;
try|try
block|{
name|srcs
operator|=
name|fs
operator|.
name|globStatus
argument_list|(
name|srcf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"addFiles: filesystem error in check phase"
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|srcs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No sources specified to move: "
operator|+
name|srcf
argument_list|)
expr_stmt|;
return|return;
comment|// srcs = new FileStatus[0]; Why is this needed?
block|}
comment|// check that source and target paths exist
name|checkPaths
argument_list|(
name|fs
argument_list|,
name|srcs
argument_list|,
name|destf
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// move it, move it
try|try
block|{
for|for
control|(
name|FileStatus
name|src
range|:
name|srcs
control|)
block|{
name|FileStatus
index|[]
name|items
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|src
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|item
range|:
name|items
control|)
block|{
name|Path
name|source
init|=
name|item
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|target
init|=
operator|new
name|Path
argument_list|(
name|destf
argument_list|,
name|item
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|source
argument_list|,
name|target
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot move "
operator|+
name|source
operator|+
literal|" to "
operator|+
name|target
argument_list|)
throw|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"copyFiles: error while moving files!!!"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Replaces files in the partition with new data set specified by srcf. Works    * by renaming directory of srcf to the destination file.    * srcf, destf, and tmppath should resident in the same DFS, but the oldPath can be in a    * different DFS.    *    * @param srcf    *          Source directory to be renamed to tmppath. It should be a    *          leaf directory where the final data files reside. However it    *          could potentially contain subdirectories as well.    * @param destf    *          The directory where the final data needs to go    * @param oldPath    *          The directory where the old data location, need to be cleaned up.    */
specifier|static
specifier|protected
name|void
name|replaceFiles
parameter_list|(
name|Path
name|srcf
parameter_list|,
name|Path
name|destf
parameter_list|,
name|Path
name|oldPath
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
name|FileSystem
name|fs
init|=
name|srcf
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|// check if srcf contains nested sub-directories
name|FileStatus
index|[]
name|srcs
decl_stmt|;
try|try
block|{
name|srcs
operator|=
name|fs
operator|.
name|globStatus
argument_list|(
name|srcf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Getting globStatus "
operator|+
name|srcf
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|srcs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No sources specified to move: "
operator|+
name|srcf
argument_list|)
expr_stmt|;
return|return;
block|}
name|checkPaths
argument_list|(
name|fs
argument_list|,
name|srcs
argument_list|,
name|destf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// point of no return -- delete oldPath
if|if
condition|(
name|oldPath
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|FileSystem
name|fs2
init|=
name|oldPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs2
operator|.
name|exists
argument_list|(
name|oldPath
argument_list|)
condition|)
block|{
comment|// use FsShell to move data to .Trash first rather than delete permanently
name|FsShell
name|fshell
init|=
operator|new
name|FsShell
argument_list|()
decl_stmt|;
name|fshell
operator|.
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|fshell
operator|.
name|run
argument_list|(
operator|new
name|String
index|[]
block|{
literal|"-rmr"
block|,
name|oldPath
operator|.
name|toString
argument_list|()
block|}
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|//swallow the exception
name|LOG
operator|.
name|warn
argument_list|(
literal|"Directory "
operator|+
name|oldPath
operator|.
name|toString
argument_list|()
operator|+
literal|" canot be removed."
argument_list|)
expr_stmt|;
block|}
block|}
comment|// rename src directory to destf
if|if
condition|(
name|srcs
operator|.
name|length
operator|==
literal|1
operator|&&
name|srcs
index|[
literal|0
index|]
operator|.
name|isDir
argument_list|()
condition|)
block|{
comment|// rename can fail if the parent doesn't exist
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|destf
operator|.
name|getParent
argument_list|()
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|destf
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|destf
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|destf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|boolean
name|b
init|=
name|fs
operator|.
name|rename
argument_list|(
name|srcs
index|[
literal|0
index|]
operator|.
name|getPath
argument_list|()
argument_list|,
name|destf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|b
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Unable to move results from "
operator|+
name|srcs
index|[
literal|0
index|]
operator|.
name|getPath
argument_list|()
operator|+
literal|" to destination directory: "
operator|+
name|destf
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Renaming:"
operator|+
name|srcf
operator|.
name|toString
argument_list|()
operator|+
literal|" to "
operator|+
name|destf
operator|.
name|toString
argument_list|()
operator|+
literal|",Status:"
operator|+
name|b
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// srcf is a file or pattern containing wildcards
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|destf
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|destf
argument_list|)
expr_stmt|;
block|}
comment|// srcs must be a list of files -- ensured by LoadSemanticAnalyzer
for|for
control|(
name|FileStatus
name|src
range|:
name|srcs
control|)
block|{
name|Path
name|destPath
init|=
operator|new
name|Path
argument_list|(
name|destf
argument_list|,
name|src
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|src
operator|.
name|getPath
argument_list|()
argument_list|,
name|destPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error moving: "
operator|+
name|src
operator|.
name|getPath
argument_list|()
operator|+
literal|" into: "
operator|+
name|destf
argument_list|)
throw|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Creates a metastore client. Currently it creates only JDBC based client as    * File based store support is removed    *    * @returns a Meta Store Client    * @throws HiveMetaException    *           if a working client can't be created    */
specifier|private
name|IMetaStoreClient
name|createMetaStoreClient
parameter_list|()
throws|throws
name|MetaException
block|{
name|HiveMetaHookLoader
name|hookLoader
init|=
operator|new
name|HiveMetaHookLoader
argument_list|()
block|{
specifier|public
name|HiveMetaHook
name|getHook
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|tbl
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
if|if
condition|(
name|tbl
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|HiveStorageHandler
name|storageHandler
init|=
name|HiveUtils
operator|.
name|getStorageHandler
argument_list|(
name|conf
argument_list|,
name|tbl
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|META_TABLE_STORAGE
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|storageHandler
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|storageHandler
operator|.
name|getMetaHook
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|HiveException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ex
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to load storage handler:  "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
decl_stmt|;
return|return
operator|new
name|HiveMetaStoreClient
argument_list|(
name|conf
argument_list|,
name|hookLoader
argument_list|)
return|;
block|}
comment|/**    *    * @return the metastore client for the current thread    * @throws MetaException    */
specifier|private
name|IMetaStoreClient
name|getMSC
parameter_list|()
throws|throws
name|MetaException
block|{
if|if
condition|(
name|metaStoreClient
operator|==
literal|null
condition|)
block|{
name|metaStoreClient
operator|=
name|createMetaStoreClient
argument_list|()
expr_stmt|;
block|}
return|return
name|metaStoreClient
return|;
block|}
specifier|private
name|String
name|getUserName
parameter_list|()
block|{
name|SessionState
name|ss
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|ss
operator|!=
literal|null
operator|&&
name|ss
operator|.
name|getAuthenticator
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|ss
operator|.
name|getAuthenticator
argument_list|()
operator|.
name|getUserName
argument_list|()
return|;
block|}
return|return
literal|null
return|;
block|}
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|getGroupNames
parameter_list|()
block|{
name|SessionState
name|ss
init|=
name|SessionState
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|ss
operator|!=
literal|null
operator|&&
name|ss
operator|.
name|getAuthenticator
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|ss
operator|.
name|getAuthenticator
argument_list|()
operator|.
name|getGroupNames
argument_list|()
return|;
block|}
return|return
literal|null
return|;
block|}
specifier|public
specifier|static
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|getFieldsFromDeserializer
parameter_list|(
name|String
name|name
parameter_list|,
name|Deserializer
name|serde
parameter_list|)
throws|throws
name|HiveException
block|{
try|try
block|{
return|return
name|MetaStoreUtils
operator|.
name|getFieldsFromDeserializer
argument_list|(
name|name
argument_list|,
name|serde
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|SerDeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error in getting fields from serde. "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Error in getting fields from serde."
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|List
argument_list|<
name|Index
argument_list|>
name|getIndexes
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|short
name|max
parameter_list|)
throws|throws
name|HiveException
block|{
name|List
argument_list|<
name|Index
argument_list|>
name|indexes
init|=
literal|null
decl_stmt|;
try|try
block|{
name|indexes
operator|=
name|getMSC
argument_list|()
operator|.
name|listIndexes
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|max
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HiveException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|indexes
return|;
block|}
specifier|public
name|Table
name|newTable
parameter_list|(
name|String
name|tableName
parameter_list|)
throws|throws
name|HiveException
block|{
name|String
index|[]
name|names
init|=
name|getQualifiedNames
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|names
operator|.
name|length
condition|)
block|{
case|case
literal|2
case|:
return|return
operator|new
name|Table
argument_list|(
name|names
index|[
literal|0
index|]
argument_list|,
name|names
index|[
literal|1
index|]
argument_list|)
return|;
case|case
literal|1
case|:
return|return
operator|new
name|Table
argument_list|(
name|getCurrentDatabase
argument_list|()
argument_list|,
name|names
index|[
literal|0
index|]
argument_list|)
return|;
default|default:
try|try
block|{
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Invalid table name: "
operator|+
name|tableName
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
throw|throw
operator|new
name|HiveException
argument_list|(
literal|"Invalid table name: "
operator|+
name|tableName
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|String
index|[]
name|getQualifiedNames
parameter_list|(
name|String
name|qualifiedName
parameter_list|)
block|{
return|return
name|qualifiedName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
return|;
block|}
block|}
end_class

begin_empty_stmt
empty_stmt|;
end_empty_stmt

end_unit

