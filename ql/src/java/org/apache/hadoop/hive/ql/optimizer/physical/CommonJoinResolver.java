begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|optimizer
operator|.
name|physical
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|Dispatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|lib
operator|.
name|TaskGraphWalker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|parse
operator|.
name|SemanticException
import|;
end_import

begin_comment
comment|/*  * Convert tasks involving JOIN into MAPJOIN.  * If hive.auto.convert.join is true, the tasks involving join are converted.  * Consider the query:  * select .... from T1 join T2 on T1.key = T2.key join T3 on T1.key = T3.key  *  * There is a map-reduce task which performs a 3-way join (T1, T2, T3).  * The task would be converted to a conditional task which would have 4 children  * a. Mapjoin considering T1 as the big table  * b. Mapjoin considering T2 as the big table  * c. Mapjoin considering T3 as the big table  * d. Map-reduce join (the original task).  *  *  Note that the sizes of all the inputs may not be available at compile time. At runtime, it is  *  determined which branch we want to pick up from the above.  *  * However, if hive.auto.convert.join.noconditionaltask is set to true, and  * the sum of any n-1 tables is smaller than hive.auto.convert.join.noconditionaltask.size,  * then a mapjoin is created instead of the conditional task. For the above, if the size of  * T1 + T2 is less than the threshold, then the task is converted to a mapjoin task with T3 as  * the big table.  *  * In this case, further optimization is performed by merging 2 consecutive map-only jobs.  * Consider the query:  * select ... from T1 join T2 on T1.key1 = T2.key1 join T3 on T1.key2 = T3.key2  *  * Initially, the plan would consist of 2 Map-reduce jobs (1 to perform join for T1 and T2)  * followed by another map-reduce job (to perform join of the result with T3). After the  * optimization, both these tasks would be converted to map-only tasks. These 2 map-only jobs  * are then merged into a single map-only job. As a followup (HIVE-3952), it would be possible to  * merge a map-only task with a map-reduce task.  * Consider the query:  * select T1.key2, count(*) from T1 join T2 on T1.key1 = T2.key1 group by T1.key2;  * Initially, the plan would consist of 2 Map-reduce jobs (1 to perform join for T1 and T2)  * followed by another map-reduce job (to perform groupby of the result). After the  * optimization, the join task would be converted to map-only tasks. After HIVE-3952, the map-only  * task would be merged with the map-reduce task to create a single map-reduce task.  */
end_comment

begin_class
specifier|public
class|class
name|CommonJoinResolver
implements|implements
name|PhysicalPlanResolver
block|{
annotation|@
name|Override
specifier|public
name|PhysicalContext
name|resolve
parameter_list|(
name|PhysicalContext
name|pctx
parameter_list|)
throws|throws
name|SemanticException
block|{
comment|// create dispatcher and graph walker
name|Dispatcher
name|disp
init|=
operator|new
name|CommonJoinTaskDispatcher
argument_list|(
name|pctx
argument_list|)
decl_stmt|;
name|TaskGraphWalker
name|ogw
init|=
operator|new
name|TaskGraphWalker
argument_list|(
name|disp
argument_list|)
decl_stmt|;
comment|// get all the tasks nodes from root task
name|List
argument_list|<
name|Node
argument_list|>
name|topNodes
init|=
operator|new
name|ArrayList
argument_list|<
name|Node
argument_list|>
argument_list|()
decl_stmt|;
name|topNodes
operator|.
name|addAll
argument_list|(
name|pctx
operator|.
name|rootTasks
argument_list|)
expr_stmt|;
comment|// begin to walk through the task tree.
name|ogw
operator|.
name|startWalking
argument_list|(
name|topNodes
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|pctx
return|;
block|}
block|}
end_class

end_unit

