PREHOOK: query: create table a (val1 int, val2 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@a
POSTHOOK: query: create table a (val1 int, val2 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@a
PREHOOK: query: create table b (val1 int, val2 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@b
POSTHOOK: query: create table b (val1 int, val2 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@b
PREHOOK: query: create table c (val1 int, val2 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@c
POSTHOOK: query: create table c (val1 int, val2 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@c
PREHOOK: query: create table d (val1 int, val2 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@d
POSTHOOK: query: create table d (val1 int, val2 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@d
PREHOOK: query: create table e (val1 int, val2 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@e
POSTHOOK: query: create table e (val1 int, val2 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@e
PREHOOK: query: explain select * from a join b on a.val1=b.val1 join c on a.val1=c.val1 join d on a.val1=d.val1 join e on a.val2=e.val2
PREHOOK: type: QUERY
POSTHOOK: query: explain select * from a join b on a.val1=b.val1 join c on a.val1=c.val1 join d on a.val1=d.val1 join e on a.val2=e.val2
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: d
                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                  Filter Operator
                    predicate: val1 is not null (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Spark HashTable Sink Operator
                      condition expressions:
                        0 {val1} {val2}
                        1 {val1} {val2}
                        2 {val1} {val2}
                        3 {val2}
                      keys:
                        0 val1 (type: int)
                        1 val1 (type: int)
                        2 val1 (type: int)
                        3 val1 (type: int)
            Local Work:
              Map Reduce Local Work
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: e
                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                  Filter Operator
                    predicate: val2 is not null (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Spark HashTable Sink Operator
                      condition expressions:
                        0 {_col0} {_col1} {_col5} {_col6} {_col10} {_col11} {_col15} {_col16}
                        1 {val1}
                      keys:
                        0 _col1 (type: int)
                        1 val2 (type: int)
            Local Work:
              Map Reduce Local Work
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                  Filter Operator
                    predicate: val1 is not null (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Spark HashTable Sink Operator
                      condition expressions:
                        0 {val1} {val2}
                        1 {val2}
                        2 {val1} {val2}
                        3 {val1} {val2}
                      keys:
                        0 val1 (type: int)
                        1 val1 (type: int)
                        2 val1 (type: int)
                        3 val1 (type: int)
            Local Work:
              Map Reduce Local Work
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                  Filter Operator
                    predicate: val1 is not null (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Spark HashTable Sink Operator
                      condition expressions:
                        0 {val1} {val2}
                        1 {val1} {val2}
                        2 {val2}
                        3 {val1} {val2}
                      keys:
                        0 val1 (type: int)
                        1 val1 (type: int)
                        2 val1 (type: int)
                        3 val1 (type: int)
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                  Filter Operator
                    predicate: (val1 is not null and val2 is not null) (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                           Inner Join 0 to 2
                           Inner Join 0 to 3
                      condition expressions:
                        0 {val1} {val2}
                        1 {val1} {val2}
                        2 {val1} {val2}
                        3 {val1} {val2}
                      keys:
                        0 val1 (type: int)
                        1 val1 (type: int)
                        2 val1 (type: int)
                        3 val1 (type: int)
                      outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11, _col15, _col16
                      input vertices:
                        1 Map 3
                        2 Map 4
                        3 Map 1
                      Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        condition expressions:
                          0 {_col0} {_col1} {_col5} {_col6} {_col10} {_col11} {_col15} {_col16}
                          1 {val1} {val2}
                        keys:
                          0 _col1 (type: int)
                          1 val2 (type: int)
                        outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11, _col15, _col16, _col20, _col21
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                        Select Operator
                          expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int), _col15 (type: int), _col16 (type: int), _col20 (type: int), _col21 (type: int)
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                          Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: --HIVE-3070 filter on outer join condition removed while merging join tree
explain select * from src a join src b on a.key=b.key left outer join src c on b.key=c.key and b.key<10
PREHOOK: type: QUERY
POSTHOOK: query: --HIVE-3070 filter on outer join condition removed while merging join tree
explain select * from src a join src b on a.key=b.key left outer join src c on b.key=c.key and b.key<10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Spark HashTable Sink Operator
                    condition expressions:
                      0 {key} {value}
                      1 {value}
                      2 {key} {value}
                    filter predicates:
                      0 
                      1 {(key < 10)}
                      2 
                    keys:
                      0 key (type: string)
                      1 key (type: string)
                      2 key (type: string)
            Local Work:
              Map Reduce Local Work
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Spark HashTable Sink Operator
                    condition expressions:
                      0 {key} {value}
                      1 {key} {value}
                      2 {value}
                    filter predicates:
                      0 
                      1 {(key < 10)}
                      2 
                    keys:
                      0 key (type: string)
                      1 key (type: string)
                      2 key (type: string)
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                         Left Outer Join1 to 2
                    condition expressions:
                      0 {key} {value}
                      1 {key} {value}
                      2 {key} {value}
                    filter predicates:
                      0 
                      1 {(key < 10)}
                      2 
                    keys:
                      0 key (type: string)
                      1 key (type: string)
                      2 key (type: string)
                    outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                    input vertices:
                      1 Map 1
                      2 Map 2
                    Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: string), _col5 (type: string), _col6 (type: string), _col10 (type: string), _col11 (type: string)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                      Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

