PREHOOK: query: -- SORT_QUERY_RESULTS

create table src0 like src
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@src0
POSTHOOK: query: -- SORT_QUERY_RESULTS

create table src0 like src
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src0
PREHOOK: query: insert into table src0 select * from src where src.key < 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@src0
[Error 30017]: Skipping stats aggregation by error org.apache.hadoop.hive.ql.metadata.HiveException: [Error 30015]: Stats aggregator of type counter cannot be connected to
POSTHOOK: query: insert into table src0 select * from src where src.key < 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src0
POSTHOOK: Lineage: src0.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src0.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain 
select src1.key as k1, src1.value as v1, src2.key, src2.value
from src0 src1 inner join src0 src2 on src1.key = src2.key
PREHOOK: type: QUERY
POSTHOOK: query: explain 
select src1.key as k1, src1.value as v1, src2.key, src2.value
from src0 src1 inner join src0 src2 on src1.key = src2.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 1), Map 3 (GROUP PARTITION-LEVEL SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src2
                  Statistics: Num rows: 0 Data size: 80 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: string)
                      sort order: +
                      Map-reduce partition columns: key (type: string)
                      Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                      value expressions: value (type: string)
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: src1
                  Statistics: Num rows: 0 Data size: 80 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: string)
                      sort order: +
                      Map-reduce partition columns: key (type: string)
                      Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                      value expressions: value (type: string)
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                condition expressions:
                  0 {KEY.reducesinkkey0} {VALUE._col0}
                  1 {KEY.reducesinkkey0} {VALUE._col0}
                outputColumnNames: _col0, _col1, _col5, _col6
                Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), _col5 (type: string), _col6 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select src1.key as k1, src1.value as v1, src2.key, src2.value
from src0 src1 inner join src0 src2 on src1.key = src2.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src0
#### A masked pattern was here ####
POSTHOOK: query: select src1.key as k1, src1.value as v1, src2.key, src2.value
from src0 src1 inner join src0 src2 on src1.key = src2.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src0
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
2	val_2	2	val_2
4	val_4	4	val_4
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
5	val_5	5	val_5
8	val_8	8	val_8
9	val_9	9	val_9
PREHOOK: query: drop table src0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src0
PREHOOK: Output: default@src0
POSTHOOK: query: drop table src0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src0
POSTHOOK: Output: default@src0
