PREHOOK: query: DROP TABLE part
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE part
POSTHOOK: type: DROPTABLE
PREHOOK: query: -- data setup
CREATE TABLE part( 
    p_partkey INT,
    p_name STRING,
    p_mfgr STRING,
    p_brand STRING,
    p_type STRING,
    p_size INT,
    p_container STRING,
    p_retailprice DOUBLE,
    p_comment STRING
)
PREHOOK: type: CREATETABLE
POSTHOOK: query: -- data setup
CREATE TABLE part( 
    p_partkey INT,
    p_name STRING,
    p_mfgr STRING,
    p_brand STRING,
    p_type STRING,
    p_size INT,
    p_container STRING,
    p_retailprice DOUBLE,
    p_comment STRING
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@part
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/part_tiny.txt' overwrite into table part
PREHOOK: type: LOAD
PREHOOK: Output: default@part
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/part_tiny.txt' overwrite into table part
POSTHOOK: type: LOAD
POSTHOOK: Output: default@part
PREHOOK: query: -- non agg, non corr
explain
select key, count(*) 
from src 
group by key
having key not in  
  ( select key  from src s1 
    where s1.key > '12'
  )
PREHOOK: type: QUERY
POSTHOOK: query: -- non agg, non corr
explain
select key, count(*) 
from src 
group by key
having key not in  
  ( select key  from src s1 
    where s1.key > '12'
  )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (not (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL s1) key) '12')))) (TOK_TABLE_OR_COL key))))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-5
  Stage-3 depends on stages: Stage-2
  Stage-5 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1_notin_nullcheck:sq_1:s1 
          TableScan
            alias: s1
            Filter Operator
              predicate:
                  expr: ((key > '12') and key is null)
                  type: boolean
              Select Operator
                Group By Operator
                  aggregations:
                        expr: count()
                  bucketGroup: false
                  mode: hash
                  outputColumnNames: _col0
                  Reduce Output Operator
                    sort order: 
                    tag: -1
                    value expressions:
                          expr: _col0
                          type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          mode: mergepartial
          outputColumnNames: _col0
          Filter Operator
            predicate:
                expr: (_col0 = 0)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: bigint
              outputColumnNames: _col0
              Group By Operator
                bucketGroup: false
                keys:
                      expr: _col0
                      type: bigint
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              sort order: 
              tag: 1
        $INTNAME1 
          TableScan
            Reduce Output Operator
              sort order: 
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: bigint
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: bigint
        sq_1:s1 
          TableScan
            alias: s1
            Filter Operator
              predicate:
                  expr: (key > '12')
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: string
                outputColumnNames: _col0
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: 1
                  value expressions:
                        expr: _col0
                        type: string
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4
          Filter Operator
            predicate:
                expr: ((1 = 1) and _col4 is null)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: key
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                keys:
                      expr: key
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- non agg, corr
explain
select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from (select p_mfgr, min(p_retailprice) l, max(p_retailprice) r, avg(p_retailprice) a from part group by p_mfgr) a 
  where min(p_retailprice) = l and r - l > 600
  )
PREHOOK: type: QUERY
POSTHOOK: query: -- non agg, corr
explain
select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from (select p_mfgr, min(p_retailprice) l, max(p_retailprice) r, avg(p_retailprice) a from part group by p_mfgr) a 
  where min(p_retailprice) = l and r - l > 600
  )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part) b)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) p_mfgr)) (TOK_SELEXPR (TOK_FUNCTION min (TOK_TABLE_OR_COL p_retailprice)))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL b) p_mfgr)) (TOK_HAVING (not (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL p_mfgr)) (TOK_SELEXPR (TOK_FUNCTION min (TOK_TABLE_OR_COL p_retailprice)) l) (TOK_SELEXPR (TOK_FUNCTION max (TOK_TABLE_OR_COL p_retailprice)) r) (TOK_SELEXPR (TOK_FUNCTION avg (TOK_TABLE_OR_COL p_retailprice)) a)) (TOK_GROUPBY (TOK_TABLE_OR_COL p_mfgr)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL p_mfgr))) (TOK_WHERE (and (= (TOK_FUNCTION min (TOK_TABLE_OR_COL p_retailprice)) (TOK_TABLE_OR_COL l)) (> (- (TOK_TABLE_OR_COL r) (TOK_TABLE_OR_COL l)) 600))))) (. (TOK_TABLE_OR_COL b) p_mfgr))))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-6
  Stage-3 depends on stages: Stage-2, Stage-4
  Stage-4 is a root stage
  Stage-5 is a root stage
  Stage-6 depends on stages: Stage-5
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_retailprice
                    type: double
              outputColumnNames: p_mfgr, p_retailprice
              Group By Operator
                aggregations:
                      expr: min(p_retailprice)
                      expr: max(p_retailprice)
                      expr: avg(p_retailprice)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: double
                        expr: _col2
                        type: double
                        expr: _col3
                        type: struct<count:bigint,sum:double>
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: min(VALUE._col0)
                expr: max(VALUE._col1)
                expr: avg(VALUE._col2)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              sort order: 
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
                    expr: _col1
                    type: double
        $INTNAME1 
          TableScan
            Reduce Output Operator
              sort order: 
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col5}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col5
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col5
                    type: double
              sort order: ++
              Map-reduce partition columns:
                    expr: _col0
                    type: string
                    expr: _col5
                    type: double
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
              sort order: ++
              Map-reduce partition columns:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
              tag: 1
              value expressions:
                    expr: _col0
                    type: string
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col7
          Filter Operator
            predicate:
                expr: ((1 = 1) and _col7 is null)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1:a:part 
          TableScan
            alias: part
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_retailprice
                    type: double
              outputColumnNames: p_mfgr, p_retailprice
              Group By Operator
                aggregations:
                      expr: min(p_retailprice)
                      expr: max(p_retailprice)
                      expr: avg(p_retailprice)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: double
                        expr: _col2
                        type: double
                        expr: _col3
                        type: struct<count:bigint,sum:double>
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: min(VALUE._col0)
                expr: max(VALUE._col1)
                expr: avg(VALUE._col2)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Filter Operator
            predicate:
                expr: ((_col2 - _col1) > 600)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1_notin_nullcheck:sq_1:a:part 
          TableScan
            alias: part
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_retailprice
                    type: double
              outputColumnNames: p_mfgr, p_retailprice
              Group By Operator
                aggregations:
                      expr: min(p_retailprice)
                      expr: max(p_retailprice)
                      expr: avg(p_retailprice)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: double
                        expr: _col2
                        type: double
                        expr: _col3
                        type: struct<count:bigint,sum:double>
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: min(VALUE._col0)
                expr: max(VALUE._col1)
                expr: avg(VALUE._col2)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Filter Operator
            predicate:
                expr: (((_col2 - _col1) > 600) and (_col0 is null or _col1 is null))
                type: boolean
            Select Operator
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-6
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
          TableScan
            Reduce Output Operator
              sort order: 
              tag: -1
              value expressions:
                    expr: _col0
                    type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          mode: mergepartial
          outputColumnNames: _col0
          Filter Operator
            predicate:
                expr: (_col0 = 0)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: bigint
              outputColumnNames: _col0
              Group By Operator
                bucketGroup: false
                keys:
                      expr: _col0
                      type: bigint
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from (select p_mfgr, min(p_retailprice) l, max(p_retailprice) r, avg(p_retailprice) a from part group by p_mfgr) a 
  where min(p_retailprice) = l and r - l > 600
  )
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from (select p_mfgr, min(p_retailprice) l, max(p_retailprice) r, avg(p_retailprice) a from part group by p_mfgr) a 
  where min(p_retailprice) = l and r - l > 600
  )
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
Manufacturer#1	1173.15
Manufacturer#2	1690.68
PREHOOK: query: -- agg, non corr
explain
select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from part a
  group by p_mfgr
  having max(p_retailprice) - min(p_retailprice) > 600
  )
PREHOOK: type: QUERY
POSTHOOK: query: -- agg, non corr
explain
select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from part a
  group by p_mfgr
  having max(p_retailprice) - min(p_retailprice) > 600
  )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part) b)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) p_mfgr)) (TOK_SELEXPR (TOK_FUNCTION min (TOK_TABLE_OR_COL p_retailprice)))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL b) p_mfgr)) (TOK_HAVING (not (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL p_mfgr))) (TOK_GROUPBY (TOK_TABLE_OR_COL p_mfgr)) (TOK_HAVING (> (- (TOK_FUNCTION max (TOK_TABLE_OR_COL p_retailprice)) (TOK_FUNCTION min (TOK_TABLE_OR_COL p_retailprice))) 600)))) (. (TOK_TABLE_OR_COL b) p_mfgr))))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-5
  Stage-3 depends on stages: Stage-2, Stage-6
  Stage-4 is a root stage
  Stage-5 depends on stages: Stage-4
  Stage-6 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_retailprice
                    type: double
              outputColumnNames: p_mfgr, p_retailprice
              Group By Operator
                aggregations:
                      expr: min(p_retailprice)
                      expr: max(p_retailprice)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: double
                        expr: _col2
                        type: double
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: min(VALUE._col0)
                expr: max(VALUE._col1)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              sort order: 
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
        $INTNAME1 
          TableScan
            Reduce Output Operator
              sort order: 
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: 1
              value expressions:
                    expr: _col0
                    type: string
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col5
          Filter Operator
            predicate:
                expr: ((1 = 1) and _col5 is null)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1_notin_nullcheck:sq_1:a 
          TableScan
            alias: a
            Filter Operator
              predicate:
                  expr: p_mfgr is null
                  type: boolean
              Select Operator
                expressions:
                      expr: p_mfgr
                      type: string
                      expr: p_retailprice
                      type: double
                outputColumnNames: p_mfgr, p_retailprice
                Group By Operator
                  aggregations:
                        expr: max(p_retailprice)
                        expr: min(p_retailprice)
                  bucketGroup: false
                  keys:
                        expr: p_mfgr
                        type: string
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2
                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: string
                    sort order: +
                    Map-reduce partition columns:
                          expr: _col0
                          type: string
                    tag: -1
                    value expressions:
                          expr: _col1
                          type: double
                          expr: _col2
                          type: double
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: max(VALUE._col0)
                expr: min(VALUE._col1)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: (((_col1 - _col2) > 600) and _col0 is null)
                type: boolean
            Select Operator
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
          TableScan
            Reduce Output Operator
              sort order: 
              tag: -1
              value expressions:
                    expr: _col0
                    type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          mode: mergepartial
          outputColumnNames: _col0
          Filter Operator
            predicate:
                expr: (_col0 = 0)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: bigint
              outputColumnNames: _col0
              Group By Operator
                bucketGroup: false
                keys:
                      expr: _col0
                      type: bigint
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-6
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1:a 
          TableScan
            alias: a
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_retailprice
                    type: double
              outputColumnNames: p_mfgr, p_retailprice
              Group By Operator
                aggregations:
                      expr: max(p_retailprice)
                      expr: min(p_retailprice)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: double
                        expr: _col2
                        type: double
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: max(VALUE._col0)
                expr: min(VALUE._col1)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: ((_col1 - _col2) > 600)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from part a
  group by p_mfgr
  having max(p_retailprice) - min(p_retailprice) > 600
  )
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select b.p_mfgr, min(p_retailprice) 
from part b 
group by b.p_mfgr
having b.p_mfgr not in 
  (select p_mfgr 
  from part a
  group by p_mfgr
  having max(p_retailprice) - min(p_retailprice) > 600
  )
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
Manufacturer#1	1173.15
Manufacturer#2	1690.68
