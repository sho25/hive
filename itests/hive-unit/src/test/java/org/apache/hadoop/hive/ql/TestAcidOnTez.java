begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowCompactRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ShowCompactResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|TxnDbUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|TxnStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|txn
operator|.
name|TxnUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|BucketCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|HiveInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|processors
operator|.
name|CommandProcessorResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assert
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Ignore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Rule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|rules
operator|.
name|TestName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * This class resides in itests to facilitate running query using Tez engine, since the jars are  * fully loaded here, which is not the case if it stays in ql.  */
end_comment

begin_class
specifier|public
class|class
name|TestAcidOnTez
block|{
specifier|static
specifier|final
specifier|private
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|TestAcidOnTez
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|TEST_DATA_DIR
init|=
operator|new
name|File
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"java.io.tmpdir"
argument_list|)
operator|+
name|File
operator|.
name|separator
operator|+
name|TestAcidOnTez
operator|.
name|class
operator|.
name|getCanonicalName
argument_list|()
operator|+
literal|"-"
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
operator|.
name|getPath
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"\\\\"
argument_list|,
literal|"/"
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|TEST_WAREHOUSE_DIR
init|=
name|TEST_DATA_DIR
operator|+
literal|"/warehouse"
decl_stmt|;
comment|//bucket count for test tables; set it to 1 for easier debugging
specifier|private
specifier|static
name|int
name|BUCKET_COUNT
init|=
literal|2
decl_stmt|;
annotation|@
name|Rule
specifier|public
name|TestName
name|testName
init|=
operator|new
name|TestName
argument_list|()
decl_stmt|;
specifier|private
name|HiveConf
name|hiveConf
decl_stmt|;
specifier|private
name|Driver
name|d
decl_stmt|;
specifier|private
specifier|static
enum|enum
name|Table
block|{
name|ACIDTBL
argument_list|(
literal|"acidTbl"
argument_list|)
block|,
name|ACIDTBLPART
argument_list|(
literal|"acidTblPart"
argument_list|)
block|,
name|ACIDNOBUCKET
argument_list|(
literal|"acidNoBucket"
argument_list|)
block|,
name|NONACIDORCTBL
argument_list|(
literal|"nonAcidOrcTbl"
argument_list|)
block|,
name|NONACIDPART
argument_list|(
literal|"nonAcidPart"
argument_list|)
block|,
name|NONACIDNONBUCKET
argument_list|(
literal|"nonAcidNonBucket"
argument_list|)
block|;
specifier|private
specifier|final
name|String
name|name
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|name
return|;
block|}
name|Table
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|this
operator|.
name|name
operator|=
name|name
expr_stmt|;
block|}
block|}
annotation|@
name|Before
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|tearDown
argument_list|()
expr_stmt|;
name|hiveConf
operator|=
operator|new
name|HiveConf
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|PREEXECHOOKS
operator|.
name|varname
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|POSTEXECHOOKS
operator|.
name|varname
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SUPPORT_CONCURRENCY
operator|.
name|varname
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREWAREHOUSE
operator|.
name|varname
argument_list|,
name|TEST_WAREHOUSE_DIR
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|setVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEMAPREDMODE
argument_list|,
literal|"nonstrict"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|setVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVEINPUTFORMAT
argument_list|,
name|HiveInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|setVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_AUTHORIZATION_MANAGER
argument_list|,
literal|"org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory"
argument_list|)
expr_stmt|;
name|TxnDbUtil
operator|.
name|setConfValues
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|TxnDbUtil
operator|.
name|prepDb
argument_list|()
expr_stmt|;
name|File
name|f
init|=
operator|new
name|File
argument_list|(
name|TEST_WAREHOUSE_DIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|f
operator|.
name|exists
argument_list|()
condition|)
block|{
name|FileUtil
operator|.
name|fullyDelete
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
operator|new
name|File
argument_list|(
name|TEST_WAREHOUSE_DIR
argument_list|)
operator|.
name|mkdirs
argument_list|()
operator|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Could not create "
operator|+
name|TEST_WAREHOUSE_DIR
argument_list|)
throw|;
block|}
name|SessionState
operator|.
name|start
argument_list|(
operator|new
name|SessionState
argument_list|(
name|hiveConf
argument_list|)
argument_list|)
expr_stmt|;
name|d
operator|=
operator|new
name|Driver
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|dropTables
argument_list|()
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|"(a int, b int) clustered by (a) into "
operator|+
name|BUCKET_COUNT
operator|+
literal|" buckets stored as orc "
operator|+
name|getTblProperties
argument_list|()
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|ACIDTBLPART
operator|+
literal|"(a int, b int) partitioned by (p string) clustered by (a) into "
operator|+
name|BUCKET_COUNT
operator|+
literal|" buckets stored as orc "
operator|+
name|getTblProperties
argument_list|()
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|NONACIDORCTBL
operator|+
literal|"(a int, b int) clustered by (a) into "
operator|+
name|BUCKET_COUNT
operator|+
literal|" buckets stored as orc "
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|"(a int, b int) partitioned by (p string) stored as orc "
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|"(a,b) values(1,2)"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|"(a,b) values(3,4)"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|"(a,b) values(5,6)"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|"(a,b) values(7,8)"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|"(a,b) values(9,10)"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|NONACIDORCTBL
operator|+
literal|"(a,b) values(1,2),(3,4),(5,6),(7,8),(9,10)"
argument_list|)
expr_stmt|;
block|}
comment|/**    * this is to test differety types of Acid tables    */
name|String
name|getTblProperties
parameter_list|()
block|{
return|return
literal|"TBLPROPERTIES ('transactional'='true')"
return|;
block|}
specifier|private
name|void
name|dropTables
parameter_list|()
throws|throws
name|Exception
block|{
for|for
control|(
name|Table
name|t
range|:
name|Table
operator|.
name|values
argument_list|()
control|)
block|{
name|runStatementOnDriver
argument_list|(
literal|"drop table if exists "
operator|+
name|t
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|After
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
try|try
block|{
if|if
condition|(
name|d
operator|!=
literal|null
condition|)
block|{
name|dropTables
argument_list|()
expr_stmt|;
name|d
operator|.
name|destroy
argument_list|()
expr_stmt|;
name|d
operator|.
name|close
argument_list|()
expr_stmt|;
name|d
operator|=
literal|null
expr_stmt|;
block|}
name|TxnDbUtil
operator|.
name|cleanDb
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|FileUtils
operator|.
name|deleteDirectory
argument_list|(
operator|new
name|File
argument_list|(
name|TEST_DATA_DIR
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Test
specifier|public
name|void
name|testMergeJoinOnMR
parameter_list|()
throws|throws
name|Exception
block|{
name|testJoin
argument_list|(
literal|"mr"
argument_list|,
literal|"MergeJoin"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Test
specifier|public
name|void
name|testMapJoinOnMR
parameter_list|()
throws|throws
name|Exception
block|{
name|testJoin
argument_list|(
literal|"mr"
argument_list|,
literal|"MapJoin"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Test
specifier|public
name|void
name|testMergeJoinOnTez
parameter_list|()
throws|throws
name|Exception
block|{
name|testJoin
argument_list|(
literal|"tez"
argument_list|,
literal|"MergeJoin"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Test
specifier|public
name|void
name|testMapJoinOnTez
parameter_list|()
throws|throws
name|Exception
block|{
name|testJoin
argument_list|(
literal|"tez"
argument_list|,
literal|"MapJoin"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Tests non acid to acid conversion where starting table has non-standard layout, i.e.    * where "original" files are not immediate children of the partition dir    */
annotation|@
name|Test
specifier|public
name|void
name|testNonStandardConversion01
parameter_list|()
throws|throws
name|Exception
block|{
name|HiveConf
name|confForTez
init|=
operator|new
name|HiveConf
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
comment|// make a clone of existing hive conf
name|setupTez
argument_list|(
name|confForTez
argument_list|)
expr_stmt|;
comment|//CTAS with non-ACID target table
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" stored as ORC TBLPROPERTIES('transactional'='false') as "
operator|+
literal|"select a, b from "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" where a<= 5 union all select a, b from "
operator|+
name|Table
operator|.
name|NONACIDORCTBL
operator|+
literal|" where a>= 5"
argument_list|,
name|confForTez
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|rs
init|=
name|runStatementOnDriver
argument_list|(
literal|"select a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" order by a, b, INPUT__FILE__NAME"
argument_list|)
decl_stmt|;
name|String
name|expected0
index|[]
index|[]
init|=
block|{
block|{
literal|"1\t2"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"3\t4"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"5\t6"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"5\t6"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"7\t8"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"9\t10"
block|,
literal|"/2/000000_0"
block|}
block|,     }
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after ctas"
argument_list|,
name|expected0
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected0
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected0
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected0
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//make the table ACID
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" SET TBLPROPERTIES ('transactional'='true')"
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after ctas:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|BucketCodec
operator|.
name|determineVersion
argument_list|(
literal|536870912
argument_list|)
operator|.
name|decodeWriterId
argument_list|(
literal|536870912
argument_list|)
argument_list|)
expr_stmt|;
comment|/*     * Expected result 0th entry i the RecordIdentifier + data.  1st entry file before compact*/
name|String
name|expected
index|[]
index|[]
init|=
block|{
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":0}\t1\t2"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":1}\t3\t4"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":2}\t5\t6"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":3}\t9\t10"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":4}\t7\t8"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":5}\t5\t6"
block|,
literal|"/2/000000_0"
block|}
block|,     }
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after ctas"
argument_list|,
name|expected
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//perform some Update/Delete
name|runStatementOnDriver
argument_list|(
literal|"update "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" set a = 70, b  = 80 where a = 7"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"delete from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" where a = 5"
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after update/delete:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|String
index|[]
index|[]
name|expected2
init|=
block|{
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":0}\t1\t2"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":1}\t3\t4"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":3}\t9\t10"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":21,\"bucketid\":536870912,\"rowid\":0}\t70\t80"
block|,
literal|"delta_0000021_0000021_0000/bucket_00000"
block|}
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after update"
argument_list|,
name|expected2
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//now make sure delete deltas are present
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|status
init|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|TEST_WAREHOUSE_DIR
operator|+
literal|"/"
operator|+
operator|(
name|Table
operator|.
name|NONACIDNONBUCKET
operator|)
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
argument_list|,
name|FileUtils
operator|.
name|STAGING_DIR_PATH_FILTER
argument_list|)
decl_stmt|;
name|String
index|[]
name|expectedDelDelta
init|=
block|{
literal|"delete_delta_0000021_0000021_0000"
block|,
literal|"delete_delta_0000022_0000022_0000"
block|}
decl_stmt|;
for|for
control|(
name|FileStatus
name|stat
range|:
name|status
control|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|expectedDelDelta
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
name|stat
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
name|expectedDelDelta
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|expectedDelDelta
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertNull
argument_list|(
literal|"at "
operator|+
name|i
operator|+
literal|" "
operator|+
name|expectedDelDelta
index|[
name|i
index|]
operator|+
literal|" not found on disk"
argument_list|,
name|expectedDelDelta
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|//run Minor compaction
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" compact 'minor'"
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runWorker
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after compact minor:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after update"
argument_list|,
name|expected2
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify the data is the same
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|//todo: since HIVE-16669 is not done, Minor compact compacts insert delta as well - it should not
comment|//Assert.assertTrue("Actual line(file) " + i + " bc: " + rs.get(i), rs.get(i).endsWith(expected2[i][1]));
block|}
comment|//check we have right delete delta files after minor compaction
name|status
operator|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|TEST_WAREHOUSE_DIR
operator|+
literal|"/"
operator|+
operator|(
name|Table
operator|.
name|NONACIDNONBUCKET
operator|)
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
argument_list|,
name|FileUtils
operator|.
name|STAGING_DIR_PATH_FILTER
argument_list|)
expr_stmt|;
name|String
index|[]
name|expectedDelDelta2
init|=
block|{
literal|"delete_delta_0000021_0000021_0000"
block|,
literal|"delete_delta_0000022_0000022_0000"
block|,
literal|"delete_delta_0000021_0000022"
block|}
decl_stmt|;
for|for
control|(
name|FileStatus
name|stat
range|:
name|status
control|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|expectedDelDelta2
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
name|stat
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
name|expectedDelDelta2
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|expectedDelDelta2
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
break|break;
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertNull
argument_list|(
literal|"at "
operator|+
name|i
operator|+
literal|" "
operator|+
name|expectedDelDelta2
index|[
name|i
index|]
operator|+
literal|" not found on disk"
argument_list|,
name|expectedDelDelta2
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|//run Major compaction
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" compact 'major'"
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runWorker
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after compact major:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after major compact"
argument_list|,
name|expected2
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|//everything is now in base/
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
literal|"base_0000022/bucket_00000"
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Tests non acid to acid conversion where starting table has non-standard layout, i.e.    * where "original" files are not immediate children of the partition dir - partitioned table    *    * How to do this?  CTAS is the only way to create data files which are not immediate children    * of the partition dir.  CTAS/Union/Tez doesn't support partition tables.  The only way is to copy    * data files in directly.    */
annotation|@
name|Ignore
argument_list|(
literal|"HIVE-17214"
argument_list|)
annotation|@
name|Test
specifier|public
name|void
name|testNonStandardConversion02
parameter_list|()
throws|throws
name|Exception
block|{
name|HiveConf
name|confForTez
init|=
operator|new
name|HiveConf
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
comment|// make a clone of existing hive conf
name|confForTez
operator|.
name|setBoolean
argument_list|(
literal|"mapred.input.dir.recursive"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|setupTez
argument_list|(
name|confForTez
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" stored as ORC "
operator|+
literal|"TBLPROPERTIES('transactional'='false') as "
operator|+
literal|"select a, b from "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" where a<= 3 union all "
operator|+
literal|"select a, b from "
operator|+
name|Table
operator|.
name|NONACIDORCTBL
operator|+
literal|" where a>= 7 "
operator|+
literal|"union all select a, b from "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" where a = 5"
argument_list|,
name|confForTez
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|rs
init|=
name|runStatementOnDriver
argument_list|(
literal|"select a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDNONBUCKET
operator|+
literal|" order by a, b"
argument_list|)
decl_stmt|;
name|String
name|expected0
index|[]
index|[]
init|=
block|{
block|{
literal|"1\t2"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"3\t4"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"5\t6"
block|,
literal|"/3/000000_0"
block|}
block|,
block|{
literal|"7\t8"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"9\t10"
block|,
literal|"/2/000000_0"
block|}
block|,     }
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after ctas"
argument_list|,
name|expected0
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected0
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected0
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected0
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|status
init|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|TEST_WAREHOUSE_DIR
operator|+
literal|"/"
operator|+
operator|(
name|Table
operator|.
name|NONACIDNONBUCKET
operator|)
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
argument_list|,
name|FileUtils
operator|.
name|STAGING_DIR_PATH_FILTER
argument_list|)
decl_stmt|;
comment|//ensure there is partition dir
name|runStatementOnDriver
argument_list|(
literal|"insert into "
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|" partition (p=1) values (100,110)"
argument_list|)
expr_stmt|;
comment|//creates more files in that partition
for|for
control|(
name|FileStatus
name|stat
range|:
name|status
control|)
block|{
name|int
name|limit
init|=
literal|5
decl_stmt|;
name|Path
name|p
init|=
name|stat
operator|.
name|getPath
argument_list|()
decl_stmt|;
comment|//dirs 1/, 2/, 3/
name|Path
name|to
init|=
operator|new
name|Path
argument_list|(
name|TEST_WAREHOUSE_DIR
operator|+
literal|"/"
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|"/p=1/"
operator|+
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|limit
operator|--
operator|>
literal|0
operator|&&
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|p
argument_list|,
name|to
argument_list|)
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|200
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|limit
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Could not rename "
operator|+
name|p
operator|+
literal|" to "
operator|+
name|to
argument_list|)
throw|;
block|}
block|}
comment|/*     This is what we expect on disk     ekoifman:warehouse ekoifman$ tree nonacidpart/     nonacidpart/     └── p=1     ├── 000000_0     ├── 1     │   └── 000000_0     ├── 2     │   └── 000000_0     └── 3         └── 000000_0  4 directories, 4 files     **/
comment|//make the table ACID
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|" SET TBLPROPERTIES ('transactional'='true')"
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, p, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after acid conversion:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|String
index|[]
index|[]
name|expected
init|=
block|{
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":0}\t100\t110\t1"
block|,
literal|"nonacidpart/p=1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":1}\t1\t2\t1"
block|,
literal|"nonacidpart/p=1/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":2}\t3\t4\t1"
block|,
literal|"nonacidpart/p=1/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":3}\t9\t10\t1"
block|,
literal|"nonacidpart/p=1/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":4}\t7\t8\t1"
block|,
literal|"nonacidpart/p=1/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":5}\t5\t6\t1"
block|,
literal|"nonacidpart/p=1/3/000000_0"
block|}
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Wrong row count"
argument_list|,
name|expected
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//run Major compaction
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|" partition (p=1) compact 'major'"
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runWorker
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, p, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|NONACIDPART
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after major compaction:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" ac: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" ac: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
literal|"nonacidpart/p=1/base_-9223372036854775808/bucket_00000"
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * CTAS + Tez + Union creates a non-standard layout in table dir    * Each leg of the union places data into a subdir of the table/partition.  Subdirs are named 1/, 2/, etc    * The way this currently works is that CTAS creates an Acid table but the insert statement writes    * the data in non-acid layout.  Then on read, it's treated like an non-acid to acid conversion.    * Longer term CTAS should create acid layout from the get-go.    */
annotation|@
name|Test
specifier|public
name|void
name|testCtasTezUnion
parameter_list|()
throws|throws
name|Exception
block|{
name|HiveConf
name|confForTez
init|=
operator|new
name|HiveConf
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
comment|// make a clone of existing hive conf
name|setupTez
argument_list|(
name|confForTez
argument_list|)
expr_stmt|;
comment|//CTAS with ACID target table
name|runStatementOnDriver
argument_list|(
literal|"create table "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" stored as ORC TBLPROPERTIES('transactional'='true') as "
operator|+
literal|"select a, b from "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" where a<= 5 union all select a, b from "
operator|+
name|Table
operator|.
name|NONACIDORCTBL
operator|+
literal|" where a>= 5"
argument_list|,
name|confForTez
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|rs
init|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after ctas:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|BucketCodec
operator|.
name|determineVersion
argument_list|(
literal|536870912
argument_list|)
operator|.
name|decodeWriterId
argument_list|(
literal|536870912
argument_list|)
argument_list|)
expr_stmt|;
comment|/*     * Expected result 0th entry i the RecordIdentifier + data.  1st entry file before compact*/
name|String
name|expected
index|[]
index|[]
init|=
block|{
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":0}\t1\t2"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":1}\t3\t4"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":2}\t5\t6"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":3}\t9\t10"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":4}\t7\t8"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":5}\t5\t6"
block|,
literal|"/2/000000_0"
block|}
block|,     }
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after ctas"
argument_list|,
name|expected
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//perform some Update/Delete
name|runStatementOnDriver
argument_list|(
literal|"update "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" set a = 70, b  = 80 where a = 7"
argument_list|)
expr_stmt|;
name|runStatementOnDriver
argument_list|(
literal|"delete from "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" where a = 5"
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after update/delete:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|String
index|[]
index|[]
name|expected2
init|=
block|{
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":0}\t1\t2"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":1}\t3\t4"
block|,
literal|"/1/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":0,\"bucketid\":536870912,\"rowid\":3}\t9\t10"
block|,
literal|"/2/000000_0"
block|}
block|,
block|{
literal|"{\"transactionid\":19,\"bucketid\":536870912,\"rowid\":0}\t70\t80"
block|,
literal|"delta_0000019_0000019_0000/bucket_00000"
block|}
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after update"
argument_list|,
name|expected2
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify data and layout
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//now make sure delete deltas are present
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|status
init|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|TEST_WAREHOUSE_DIR
operator|+
literal|"/"
operator|+
operator|(
name|Table
operator|.
name|ACIDNOBUCKET
operator|)
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
argument_list|,
name|FileUtils
operator|.
name|STAGING_DIR_PATH_FILTER
argument_list|)
decl_stmt|;
name|String
index|[]
name|expectedDelDelta
init|=
block|{
literal|"delete_delta_0000019_0000019_0000"
block|,
literal|"delete_delta_0000020_0000020_0000"
block|}
decl_stmt|;
for|for
control|(
name|FileStatus
name|stat
range|:
name|status
control|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|expectedDelDelta
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
name|stat
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
name|expectedDelDelta
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|expectedDelDelta
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertNull
argument_list|(
literal|"at "
operator|+
name|i
operator|+
literal|" "
operator|+
name|expectedDelDelta
index|[
name|i
index|]
operator|+
literal|" not found on disk"
argument_list|,
name|expectedDelDelta
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|//run Minor compaction
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" compact 'minor'"
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runWorker
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after compact minor:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after update"
argument_list|,
name|expected2
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|//verify the data is the same
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|//todo: since HIVE-16669 is not done, Minor compact compacts insert delta as well - it should not
comment|//Assert.assertTrue("Actual line(file) " + i + " bc: " + rs.get(i), rs.get(i).endsWith(expected2[i][1]));
block|}
comment|//check we have right delete delta files after minor compaction
name|status
operator|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|TEST_WAREHOUSE_DIR
operator|+
literal|"/"
operator|+
operator|(
name|Table
operator|.
name|ACIDNOBUCKET
operator|)
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
argument_list|,
name|FileUtils
operator|.
name|STAGING_DIR_PATH_FILTER
argument_list|)
expr_stmt|;
name|String
index|[]
name|expectedDelDelta2
init|=
block|{
literal|"delete_delta_0000019_0000019_0000"
block|,
literal|"delete_delta_0000020_0000020_0000"
block|,
literal|"delete_delta_0000019_0000020"
block|}
decl_stmt|;
for|for
control|(
name|FileStatus
name|stat
range|:
name|status
control|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|expectedDelDelta2
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
name|stat
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
name|expectedDelDelta2
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|expectedDelDelta2
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
break|break;
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expectedDelDelta2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertNull
argument_list|(
literal|"at "
operator|+
name|i
operator|+
literal|" "
operator|+
name|expectedDelDelta2
index|[
name|i
index|]
operator|+
literal|" not found on disk"
argument_list|,
name|expectedDelDelta2
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|//run Major compaction
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" compact 'major'"
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runWorker
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
literal|"select ROW__ID, a, b, INPUT__FILE__NAME from "
operator|+
name|Table
operator|.
name|ACIDNOBUCKET
operator|+
literal|" order by ROW__ID"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"after compact major:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|s
range|:
name|rs
control|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected row count after major compact"
argument_list|,
name|expected2
operator|.
name|length
argument_list|,
name|rs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expected2
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|startsWith
argument_list|(
name|expected2
index|[
name|i
index|]
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|//everything is now in base/
name|Assert
operator|.
name|assertTrue
argument_list|(
literal|"Actual line(file) "
operator|+
name|i
operator|+
literal|" bc: "
operator|+
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|rs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|endsWith
argument_list|(
literal|"base_0000020/bucket_00000"
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Ideally test like this should be a qfile test. However, the explain output from qfile is always
comment|// slightly different depending on where the test is run, specifically due to file size estimation
specifier|private
name|void
name|testJoin
parameter_list|(
name|String
name|engine
parameter_list|,
name|String
name|joinType
parameter_list|)
throws|throws
name|Exception
block|{
name|HiveConf
name|confForTez
init|=
operator|new
name|HiveConf
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
comment|// make a clone of existing hive conf
name|HiveConf
name|confForMR
init|=
operator|new
name|HiveConf
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
comment|// make a clone of existing hive conf
if|if
condition|(
name|engine
operator|.
name|equals
argument_list|(
literal|"tez"
argument_list|)
condition|)
block|{
name|setupTez
argument_list|(
name|confForTez
argument_list|)
expr_stmt|;
comment|// one-time setup to make query able to run with Tez
block|}
if|if
condition|(
name|joinType
operator|.
name|equals
argument_list|(
literal|"MapJoin"
argument_list|)
condition|)
block|{
name|setupMapJoin
argument_list|(
name|confForTez
argument_list|)
expr_stmt|;
name|setupMapJoin
argument_list|(
name|confForMR
argument_list|)
expr_stmt|;
block|}
name|runQueries
argument_list|(
name|engine
argument_list|,
name|joinType
argument_list|,
name|confForTez
argument_list|,
name|confForMR
argument_list|)
expr_stmt|;
comment|// Perform compaction. Join result after compaction should still be the same
name|runStatementOnDriver
argument_list|(
literal|"alter table "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" compact 'MAJOR'"
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runWorker
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|TxnStore
name|txnHandler
init|=
name|TxnUtils
operator|.
name|getTxnStore
argument_list|(
name|hiveConf
argument_list|)
decl_stmt|;
name|ShowCompactResponse
name|resp
init|=
name|txnHandler
operator|.
name|showCompact
argument_list|(
operator|new
name|ShowCompactRequest
argument_list|()
argument_list|)
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected number of compactions in history"
argument_list|,
literal|1
argument_list|,
name|resp
operator|.
name|getCompactsSize
argument_list|()
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Unexpected 0 compaction state"
argument_list|,
name|TxnStore
operator|.
name|CLEANING_RESPONSE
argument_list|,
name|resp
operator|.
name|getCompacts
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getState
argument_list|()
argument_list|)
expr_stmt|;
name|TestTxnCommands2
operator|.
name|runCleaner
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|runQueries
argument_list|(
name|engine
argument_list|,
name|joinType
argument_list|,
name|confForTez
argument_list|,
name|confForMR
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|runQueries
parameter_list|(
name|String
name|engine
parameter_list|,
name|String
name|joinType
parameter_list|,
name|HiveConf
name|confForTez
parameter_list|,
name|HiveConf
name|confForMR
parameter_list|)
throws|throws
name|Exception
block|{
name|List
argument_list|<
name|String
argument_list|>
name|queries
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|queries
operator|.
name|add
argument_list|(
literal|"select count(*) from "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" t1 join "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" t2 on t1.a=t2.a"
argument_list|)
expr_stmt|;
name|queries
operator|.
name|add
argument_list|(
literal|"select count(*) from "
operator|+
name|Table
operator|.
name|ACIDTBL
operator|+
literal|" t1 join "
operator|+
name|Table
operator|.
name|NONACIDORCTBL
operator|+
literal|" t2 on t1.a=t2.a"
argument_list|)
expr_stmt|;
comment|// more queries can be added here in the future to test acid joins
name|List
argument_list|<
name|String
argument_list|>
name|explain
decl_stmt|;
comment|// stores Explain output
name|int
index|[]
index|[]
name|expected
init|=
block|{
block|{
literal|5
block|}
block|}
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|rs
init|=
literal|null
decl_stmt|;
for|for
control|(
name|String
name|query
range|:
name|queries
control|)
block|{
if|if
condition|(
name|engine
operator|.
name|equals
argument_list|(
literal|"tez"
argument_list|)
condition|)
block|{
name|explain
operator|=
name|runStatementOnDriver
argument_list|(
literal|"explain "
operator|+
name|query
argument_list|,
name|confForTez
argument_list|)
expr_stmt|;
if|if
condition|(
name|joinType
operator|.
name|equals
argument_list|(
literal|"MergeJoin"
argument_list|)
condition|)
block|{
name|TestTxnCommands2
operator|.
name|assertExplainHasString
argument_list|(
literal|"Merge Join Operator"
argument_list|,
name|explain
argument_list|,
literal|"Didn't find "
operator|+
name|joinType
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// MapJoin
name|TestTxnCommands2
operator|.
name|assertExplainHasString
argument_list|(
literal|"Map Join Operator"
argument_list|,
name|explain
argument_list|,
literal|"Didn't find "
operator|+
name|joinType
argument_list|)
expr_stmt|;
block|}
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
name|query
argument_list|,
name|confForTez
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// mr
name|explain
operator|=
name|runStatementOnDriver
argument_list|(
literal|"explain "
operator|+
name|query
argument_list|,
name|confForMR
argument_list|)
expr_stmt|;
if|if
condition|(
name|joinType
operator|.
name|equals
argument_list|(
literal|"MergeJoin"
argument_list|)
condition|)
block|{
name|TestTxnCommands2
operator|.
name|assertExplainHasString
argument_list|(
literal|"  Join Operator"
argument_list|,
name|explain
argument_list|,
literal|"Didn't find "
operator|+
name|joinType
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// MapJoin
name|TestTxnCommands2
operator|.
name|assertExplainHasString
argument_list|(
literal|"Map Join Operator"
argument_list|,
name|explain
argument_list|,
literal|"Didn't find "
operator|+
name|joinType
argument_list|)
expr_stmt|;
block|}
name|rs
operator|=
name|runStatementOnDriver
argument_list|(
name|query
argument_list|,
name|confForMR
argument_list|)
expr_stmt|;
block|}
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"Join result incorrect"
argument_list|,
name|TestTxnCommands2
operator|.
name|stringifyValues
argument_list|(
name|expected
argument_list|)
argument_list|,
name|rs
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|setupTez
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
name|conf
operator|.
name|setVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|,
literal|"tez"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_USER_INSTALL_DIR
argument_list|,
name|TEST_DATA_DIR
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"tez.local.mode"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"fs.defaultFS"
argument_list|,
literal|"file:///"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"tez.runtime.optimize.local.fetch"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"tez.staging-dir"
argument_list|,
name|TEST_DATA_DIR
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"tez.ignore.lib.uris"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|setupMapJoin
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
name|conf
operator|.
name|setBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOIN
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOINNOCONDITIONALTASK
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setLongVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
block|}
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|runStatementOnDriver
parameter_list|(
name|String
name|stmt
parameter_list|)
throws|throws
name|Exception
block|{
name|CommandProcessorResponse
name|cpr
init|=
name|d
operator|.
name|run
argument_list|(
name|stmt
argument_list|)
decl_stmt|;
if|if
condition|(
name|cpr
operator|.
name|getResponseCode
argument_list|()
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|stmt
operator|+
literal|" failed: "
operator|+
name|cpr
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|rs
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|d
operator|.
name|getResults
argument_list|(
name|rs
argument_list|)
expr_stmt|;
return|return
name|rs
return|;
block|}
comment|/**    * Run statement with customized hive conf    */
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|runStatementOnDriver
parameter_list|(
name|String
name|stmt
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|Exception
block|{
name|Driver
name|driver
init|=
operator|new
name|Driver
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|CommandProcessorResponse
name|cpr
init|=
name|driver
operator|.
name|run
argument_list|(
name|stmt
argument_list|)
decl_stmt|;
if|if
condition|(
name|cpr
operator|.
name|getResponseCode
argument_list|()
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|stmt
operator|+
literal|" failed: "
operator|+
name|cpr
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|rs
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|driver
operator|.
name|getResults
argument_list|(
name|rs
argument_list|)
expr_stmt|;
return|return
name|rs
return|;
block|}
block|}
end_class

end_unit

