begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|jdbc
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Paths
import|;
end_import

begin_import
import|import
name|java
operator|.
name|sql
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|sql
operator|.
name|DriverManager
import|;
end_import

begin_import
import|import
name|java
operator|.
name|sql
operator|.
name|ResultSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|sql
operator|.
name|SQLException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|sql
operator|.
name|Statement
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
operator|.
name|HdfsErasureCodingShim
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|HadoopShims
operator|.
name|MiniDFSShim
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|jdbc
operator|.
name|miniHS2
operator|.
name|MiniHS2
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|AfterClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|QTestUtil
operator|.
name|DEFAULT_TEST_EC_POLICY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|jdbc
operator|.
name|TestJdbcWithMiniHS2
operator|.
name|getDetailedTableDescription
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_comment
comment|/**  * Run erasure Coding tests with jdbc.  */
end_comment

begin_class
specifier|public
class|class
name|TestJdbcWithMiniHS2ErasureCoding
block|{
specifier|private
specifier|static
specifier|final
name|String
name|DB_NAME
init|=
literal|"ecTestDb"
decl_stmt|;
specifier|private
specifier|static
name|MiniHS2
name|miniHS2
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|HiveConf
name|conf
decl_stmt|;
specifier|private
name|Connection
name|hs2Conn
init|=
literal|null
decl_stmt|;
specifier|private
specifier|static
name|HiveConf
name|createHiveOnSparkConf
parameter_list|()
block|{
name|HiveConf
name|hiveConf
init|=
operator|new
name|HiveConf
argument_list|()
decl_stmt|;
comment|// Tell dfs not to consider load when choosing a datanode as this can cause failure as
comment|// in a test we do not have spare datanode capacity.
name|hiveConf
operator|.
name|setBoolean
argument_list|(
literal|"dfs.namenode.redundancy.considerLoad"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
literal|"hive.execution.engine"
argument_list|,
literal|"spark"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
literal|"spark.serializer"
argument_list|,
literal|"org.apache.spark.serializer.KryoSerializer"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
literal|"spark.master"
argument_list|,
literal|"local-cluster[2,2,1024]"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
literal|"hive.spark.client.connect.timeout"
argument_list|,
literal|"30000ms"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
literal|"spark.local.dir"
argument_list|,
name|Paths
operator|.
name|get
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.tmp.dir"
argument_list|)
argument_list|,
literal|"TestJdbcWithMiniHS2ErasureCoding-local-dir"
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|setBoolVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_SUPPORT_CONCURRENCY
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// avoid ZK errors
return|return
name|hiveConf
return|;
block|}
comment|/**      * Setup a mini HS2 with miniMR.      */
annotation|@
name|BeforeClass
specifier|public
specifier|static
name|void
name|beforeTest
parameter_list|()
throws|throws
name|Exception
block|{
name|Class
operator|.
name|forName
argument_list|(
name|MiniHS2
operator|.
name|getJdbcDriverName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|=
name|createHiveOnSparkConf
argument_list|()
expr_stmt|;
name|DriverManager
operator|.
name|setLoginTimeout
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|miniHS2
operator|=
operator|new
name|MiniHS2
operator|.
name|Builder
argument_list|()
operator|.
name|withConf
argument_list|(
name|conf
argument_list|)
operator|.
name|withMiniMR
argument_list|()
operator|.
name|withDataNodes
argument_list|(
literal|5
argument_list|)
comment|// sufficient for RS-3-2-1024k
operator|.
name|build
argument_list|()
expr_stmt|;
name|miniHS2
operator|.
name|start
argument_list|(
name|Collections
operator|.
name|emptyMap
argument_list|()
argument_list|)
expr_stmt|;
name|createDb
argument_list|()
expr_stmt|;
name|MiniDFSShim
name|dfs
init|=
name|miniHS2
operator|.
name|getDfs
argument_list|()
decl_stmt|;
name|addErasurePolicy
argument_list|(
name|dfs
argument_list|,
literal|"hdfs:///"
argument_list|,
name|DEFAULT_TEST_EC_POLICY
argument_list|)
expr_stmt|;
block|}
comment|/**    * Shutdown the mini HS2.    */
annotation|@
name|AfterClass
specifier|public
specifier|static
name|void
name|afterTest
parameter_list|()
block|{
if|if
condition|(
name|miniHS2
operator|!=
literal|null
operator|&&
name|miniHS2
operator|.
name|isStarted
argument_list|()
condition|)
block|{
name|miniHS2
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Setup a connection to the test database before each test.    */
annotation|@
name|Before
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|hs2Conn
operator|=
name|DriverManager
operator|.
name|getConnection
argument_list|(
name|miniHS2
operator|.
name|getJdbcURL
argument_list|(
name|DB_NAME
argument_list|)
argument_list|,
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|,
literal|"bar"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Close connection after each test.    */
annotation|@
name|After
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|hs2Conn
operator|!=
literal|null
condition|)
block|{
name|hs2Conn
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Create a database.    */
specifier|private
specifier|static
name|void
name|createDb
parameter_list|()
throws|throws
name|Exception
block|{
try|try
init|(
name|Connection
name|conn
init|=
name|DriverManager
operator|.
name|getConnection
argument_list|(
name|miniHS2
operator|.
name|getJdbcURL
argument_list|()
argument_list|,
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|,
literal|"bar"
argument_list|)
init|;
name|Statement
name|stmt2
operator|=
name|conn
operator|.
name|createStatement
argument_list|()
init|)
block|{
name|stmt2
operator|.
name|execute
argument_list|(
literal|"DROP DATABASE IF EXISTS "
operator|+
name|DB_NAME
operator|+
literal|" CASCADE"
argument_list|)
expr_stmt|;
name|stmt2
operator|.
name|execute
argument_list|(
literal|"CREATE DATABASE "
operator|+
name|DB_NAME
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Test EXPLAIN on fs with Erasure Coding.    */
annotation|@
name|Test
specifier|public
name|void
name|testExplainErasureCoding
parameter_list|()
throws|throws
name|Exception
block|{
try|try
init|(
name|Statement
name|stmt
init|=
name|hs2Conn
operator|.
name|createStatement
argument_list|()
init|)
block|{
name|String
name|tableName
init|=
literal|"pTableEc"
decl_stmt|;
name|stmt
operator|.
name|execute
argument_list|(
literal|" CREATE TABLE "
operator|+
name|tableName
operator|+
literal|" (userid VARCHAR(64), link STRING, source STRING) "
operator|+
literal|"PARTITIONED BY (datestamp STRING, i int) "
operator|+
literal|"CLUSTERED BY (userid) INTO 4 BUCKETS STORED AS PARQUET"
argument_list|)
expr_stmt|;
comment|// insert data to create 2 partitions
name|stmt
operator|.
name|execute
argument_list|(
literal|"INSERT INTO TABLE "
operator|+
name|tableName
operator|+
literal|" PARTITION (datestamp = '2014-09-23', i = 1)(userid,link) VALUES ('jsmith', 'mail.com')"
argument_list|)
expr_stmt|;
name|stmt
operator|.
name|execute
argument_list|(
literal|"INSERT INTO TABLE "
operator|+
name|tableName
operator|+
literal|" PARTITION (datestamp = '2014-09-24', i = 2)(userid,link) VALUES ('mac', 'superchunk.com')"
argument_list|)
expr_stmt|;
name|String
name|explain
init|=
name|getExtendedExplain
argument_list|(
name|stmt
argument_list|,
literal|"select userid from "
operator|+
name|tableName
argument_list|)
decl_stmt|;
name|assertMatchAndCount
argument_list|(
name|explain
argument_list|,
literal|" numFiles 4"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|assertMatchAndCount
argument_list|(
name|explain
argument_list|,
literal|" numFilesErasureCoded 4"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Test DESCRIBE on fs with Erasure Coding.    */
annotation|@
name|Test
specifier|public
name|void
name|testDescribeErasureCoding
parameter_list|()
throws|throws
name|Exception
block|{
try|try
init|(
name|Statement
name|stmt
init|=
name|hs2Conn
operator|.
name|createStatement
argument_list|()
init|)
block|{
name|String
name|table
init|=
literal|"pageviews"
decl_stmt|;
name|stmt
operator|.
name|execute
argument_list|(
literal|" CREATE TABLE "
operator|+
name|table
operator|+
literal|" (userid VARCHAR(64), link STRING, source STRING) "
operator|+
literal|"PARTITIONED BY (datestamp STRING, i int) CLUSTERED BY (userid) INTO 4 BUCKETS STORED AS PARQUET"
argument_list|)
expr_stmt|;
name|stmt
operator|.
name|execute
argument_list|(
literal|"INSERT INTO TABLE "
operator|+
name|table
operator|+
literal|" PARTITION (datestamp = '2014-09-23', i = 1)"
operator|+
literal|"(userid,link) VALUES ('jsmith', 'mail.com')"
argument_list|)
expr_stmt|;
name|stmt
operator|.
name|execute
argument_list|(
literal|"INSERT INTO TABLE "
operator|+
name|table
operator|+
literal|" PARTITION (datestamp = '2014-09-24', i = 1)"
operator|+
literal|"(userid,link) VALUES ('dpatel', 'gmail.com')"
argument_list|)
expr_stmt|;
name|String
name|description
init|=
name|getDetailedTableDescription
argument_list|(
name|stmt
argument_list|,
name|table
argument_list|)
decl_stmt|;
name|assertMatchAndCount
argument_list|(
name|description
argument_list|,
literal|"numFiles=8"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|assertMatchAndCount
argument_list|(
name|description
argument_list|,
literal|"numFilesErasureCoded=8"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|assertMatchAndCount
argument_list|(
name|description
argument_list|,
literal|"numPartitions=2"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Add a Erasure Coding Policy to a Path.    */
specifier|private
specifier|static
name|void
name|addErasurePolicy
parameter_list|(
name|MiniDFSShim
name|dfs
parameter_list|,
name|String
name|pathString
parameter_list|,
name|String
name|policyName
parameter_list|)
throws|throws
name|IOException
block|{
name|HadoopShims
name|hadoopShims
init|=
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
decl_stmt|;
name|HdfsErasureCodingShim
name|erasureCodingShim
init|=
name|hadoopShims
operator|.
name|createHdfsErasureCodingShim
argument_list|(
name|dfs
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|erasureCodingShim
operator|.
name|enableErasureCodingPolicy
argument_list|(
name|policyName
argument_list|)
expr_stmt|;
name|Path
name|fsRoot
init|=
operator|new
name|Path
argument_list|(
name|pathString
argument_list|)
decl_stmt|;
name|erasureCodingShim
operator|.
name|setErasureCodingPolicy
argument_list|(
name|fsRoot
argument_list|,
name|policyName
argument_list|)
expr_stmt|;
name|HadoopShims
operator|.
name|HdfsFileErasureCodingPolicy
name|erasureCodingPolicy
init|=
name|erasureCodingShim
operator|.
name|getErasureCodingPolicy
argument_list|(
name|fsRoot
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
name|policyName
argument_list|,
name|erasureCodingPolicy
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get Extended Explain output via jdbc.    */
specifier|private
specifier|static
name|String
name|getExtendedExplain
parameter_list|(
name|Statement
name|stmt
parameter_list|,
name|String
name|query
parameter_list|)
throws|throws
name|SQLException
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|2048
argument_list|)
decl_stmt|;
try|try
init|(
name|ResultSet
name|rs
init|=
name|stmt
operator|.
name|executeQuery
argument_list|(
literal|"explain extended "
operator|+
name|query
argument_list|)
init|)
block|{
while|while
condition|(
name|rs
operator|.
name|next
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|rs
operator|.
name|getString
argument_list|(
literal|1
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Check that the expected string occurs correctly in the output string.    * @param output string to probe    * @param expectedString string to find in output    * @param expectedCount the expected number of occurrences of the expected string    */
specifier|private
name|void
name|assertMatchAndCount
parameter_list|(
name|String
name|output
parameter_list|,
name|String
name|expectedString
parameter_list|,
name|int
name|expectedCount
parameter_list|)
block|{
name|assertTrue
argument_list|(
literal|"Did not find expected '"
operator|+
name|expectedString
operator|+
literal|"' in text "
operator|+
name|output
argument_list|,
name|output
operator|.
name|contains
argument_list|(
name|expectedString
argument_list|)
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"wrong count of matches of '"
operator|+
name|expectedString
operator|+
literal|"' in text "
operator|+
name|output
argument_list|,
name|expectedCount
argument_list|,
name|StringUtils
operator|.
name|countMatches
argument_list|(
name|output
argument_list|,
name|expectedString
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

