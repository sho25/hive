begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|jdbc
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|LlapArrowRowInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|LlapBaseInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|LlapInputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|llap
operator|.
name|Row
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_comment
comment|/**  * TestNewGetSplitsFormat.  */
end_comment

begin_class
specifier|public
class|class
name|TestNewGetSplitsFormat
extends|extends
name|BaseJdbcWithMiniLlap
block|{
annotation|@
name|BeforeClass
specifier|public
specifier|static
name|void
name|beforeTest
parameter_list|()
throws|throws
name|Exception
block|{
name|HiveConf
name|conf
init|=
name|defaultConf
argument_list|()
decl_stmt|;
name|conf
operator|.
name|setBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|LLAP_OUTPUT_FORMAT_ARROW
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_VECTORIZATION_FILESINK_ARROW_NATIVE_ENABLED
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|BaseJdbcWithMiniLlap
operator|.
name|beforeTest
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|InputFormat
argument_list|<
name|NullWritable
argument_list|,
name|Row
argument_list|>
name|getInputFormat
parameter_list|()
block|{
comment|//For unit testing, no harm in hard-coding allocator ceiling to LONG.MAX_VALUE
return|return
operator|new
name|LlapArrowRowInputFormat
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|testDataTypes
parameter_list|()
throws|throws
name|Exception
block|{
name|TestJdbcWithMiniLlapVectorArrow
name|testJdbcWithMiniLlapVectorArrow
init|=
operator|new
name|TestJdbcWithMiniLlapVectorArrow
argument_list|()
decl_stmt|;
name|testJdbcWithMiniLlapVectorArrow
operator|.
name|testDataTypes
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|processQuery
parameter_list|(
name|String
name|currentDatabase
parameter_list|,
name|String
name|query
parameter_list|,
name|int
name|numSplits
parameter_list|,
name|RowProcessor
name|rowProcessor
parameter_list|)
throws|throws
name|Exception
block|{
name|String
name|url
init|=
name|miniHS2
operator|.
name|getJdbcURL
argument_list|()
decl_stmt|;
name|String
name|user
init|=
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
decl_stmt|;
name|String
name|pwd
init|=
name|user
decl_stmt|;
name|String
name|handleId
init|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|InputFormat
argument_list|<
name|NullWritable
argument_list|,
name|Row
argument_list|>
name|inputFormat
init|=
name|getInputFormat
argument_list|()
decl_stmt|;
comment|// Get splits
name|JobConf
name|job
init|=
operator|new
name|JobConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|URL_KEY
argument_list|,
name|url
argument_list|)
expr_stmt|;
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|USER_KEY
argument_list|,
name|user
argument_list|)
expr_stmt|;
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|PWD_KEY
argument_list|,
name|pwd
argument_list|)
expr_stmt|;
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|QUERY_KEY
argument_list|,
name|query
argument_list|)
expr_stmt|;
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|HANDLE_ID
argument_list|,
name|handleId
argument_list|)
expr_stmt|;
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|USE_NEW_SPLIT_FORMAT
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentDatabase
operator|!=
literal|null
condition|)
block|{
name|job
operator|.
name|set
argument_list|(
name|LlapBaseInputFormat
operator|.
name|DB_KEY
argument_list|,
name|currentDatabase
argument_list|)
expr_stmt|;
block|}
name|InputSplit
index|[]
name|splits
init|=
name|inputFormat
operator|.
name|getSplits
argument_list|(
name|job
argument_list|,
name|numSplits
argument_list|)
decl_stmt|;
if|if
condition|(
name|splits
operator|.
name|length
operator|<=
literal|1
condition|)
block|{
return|return
literal|0
return|;
block|}
comment|// populate actual splits with schema and planBytes[]
name|LlapInputSplit
name|schemaSplit
init|=
operator|(
name|LlapInputSplit
operator|)
name|splits
index|[
literal|0
index|]
decl_stmt|;
name|LlapInputSplit
name|planSplit
init|=
operator|(
name|LlapInputSplit
operator|)
name|splits
index|[
literal|1
index|]
decl_stmt|;
name|List
argument_list|<
name|LlapInputSplit
argument_list|>
name|actualSplits
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|2
init|;
name|i
operator|<
name|splits
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|LlapInputSplit
name|actualSplit
init|=
operator|(
name|LlapInputSplit
operator|)
name|splits
index|[
name|i
index|]
decl_stmt|;
name|actualSplit
operator|.
name|setSchema
argument_list|(
name|schemaSplit
operator|.
name|getSchema
argument_list|()
argument_list|)
expr_stmt|;
name|actualSplit
operator|.
name|setPlanBytes
argument_list|(
name|planSplit
operator|.
name|getPlanBytes
argument_list|()
argument_list|)
expr_stmt|;
name|actualSplits
operator|.
name|add
argument_list|(
name|actualSplit
argument_list|)
expr_stmt|;
block|}
comment|// Fetch rows from splits
name|int
name|rowCount
init|=
literal|0
decl_stmt|;
for|for
control|(
name|InputSplit
name|split
range|:
name|actualSplits
control|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Processing split "
operator|+
name|split
operator|.
name|getLocations
argument_list|()
argument_list|)
expr_stmt|;
name|RecordReader
argument_list|<
name|NullWritable
argument_list|,
name|Row
argument_list|>
name|reader
init|=
name|inputFormat
operator|.
name|getRecordReader
argument_list|(
name|split
argument_list|,
name|job
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|Row
name|row
init|=
name|reader
operator|.
name|createValue
argument_list|()
decl_stmt|;
while|while
condition|(
name|reader
operator|.
name|next
argument_list|(
name|NullWritable
operator|.
name|get
argument_list|()
argument_list|,
name|row
argument_list|)
condition|)
block|{
name|rowProcessor
operator|.
name|process
argument_list|(
name|row
argument_list|)
expr_stmt|;
operator|++
name|rowCount
expr_stmt|;
block|}
comment|//In arrow-mode this will throw exception unless all buffers have been released
comment|//See org.apache.hadoop.hive.llap.LlapArrowBatchRecordReader
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|LlapBaseInputFormat
operator|.
name|close
argument_list|(
name|handleId
argument_list|)
expr_stmt|;
return|return
name|rowCount
return|;
block|}
block|}
end_class

end_unit

