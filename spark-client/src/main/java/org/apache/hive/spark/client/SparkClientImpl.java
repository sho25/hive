begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_SECURITY_AUTHENTICATION
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Charsets
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Throwables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|io
operator|.
name|Resources
import|;
end_import

begin_import
import|import
name|io
operator|.
name|netty
operator|.
name|channel
operator|.
name|ChannelHandlerContext
import|;
end_import

begin_import
import|import
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|GenericFutureListener
import|;
end_import

begin_import
import|import
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Promise
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStreamReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStreamWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Writer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|Rpc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|RpcConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|RpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|spark
operator|.
name|SparkContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|spark
operator|.
name|SparkException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_class
class|class
name|SparkClientImpl
implements|implements
name|SparkClient
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|SparkClientImpl
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_SHUTDOWN_TIMEOUT
init|=
literal|10000
decl_stmt|;
comment|// In milliseconds
specifier|private
specifier|static
specifier|final
name|long
name|MAX_ERR_LOG_LINES_FOR_RPC
init|=
literal|1000
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|OSX_TEST_OPTS
init|=
literal|"SPARK_OSX_TEST_OPTS"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPARK_HOME_ENV
init|=
literal|"SPARK_HOME"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPARK_HOME_KEY
init|=
literal|"spark.home"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DRIVER_OPTS_KEY
init|=
literal|"spark.driver.extraJavaOptions"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|EXECUTOR_OPTS_KEY
init|=
literal|"spark.executor.extraJavaOptions"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DRIVER_EXTRA_CLASSPATH
init|=
literal|"spark.driver.extraClassPath"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|EXECUTOR_EXTRA_CLASSPATH
init|=
literal|"spark.executor.extraClassPath"
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|conf
decl_stmt|;
specifier|private
specifier|final
name|HiveConf
name|hiveConf
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|childIdGenerator
decl_stmt|;
specifier|private
specifier|final
name|Thread
name|driverThread
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
argument_list|>
name|jobs
decl_stmt|;
specifier|private
specifier|final
name|Rpc
name|driverRpc
decl_stmt|;
specifier|private
specifier|final
name|ClientProtocol
name|protocol
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|isAlive
decl_stmt|;
name|SparkClientImpl
parameter_list|(
name|RpcServer
name|rpcServer
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|conf
parameter_list|,
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|IOException
throws|,
name|SparkException
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|hiveConf
operator|=
name|hiveConf
expr_stmt|;
name|this
operator|.
name|childIdGenerator
operator|=
operator|new
name|AtomicInteger
argument_list|()
expr_stmt|;
name|this
operator|.
name|jobs
operator|=
name|Maps
operator|.
name|newConcurrentMap
argument_list|()
expr_stmt|;
name|String
name|clientId
init|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|String
name|secret
init|=
name|rpcServer
operator|.
name|createSecret
argument_list|()
decl_stmt|;
name|this
operator|.
name|driverThread
operator|=
name|startDriver
argument_list|(
name|rpcServer
argument_list|,
name|clientId
argument_list|,
name|secret
argument_list|)
expr_stmt|;
name|this
operator|.
name|protocol
operator|=
operator|new
name|ClientProtocol
argument_list|()
expr_stmt|;
try|try
block|{
comment|// The RPC server will take care of timeouts here.
name|this
operator|.
name|driverRpc
operator|=
name|rpcServer
operator|.
name|registerClient
argument_list|(
name|clientId
argument_list|,
name|secret
argument_list|,
name|protocol
argument_list|)
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getCause
argument_list|()
operator|instanceof
name|TimeoutException
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Timed out waiting for client to connect.\nPossible reasons include network "
operator|+
literal|"issues, errors in remote driver or the cluster has no available resources, etc."
operator|+
literal|"\nPlease check YARN or Spark driver's logs for further information."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while waiting for client to connect."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|driverThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
try|try
block|{
name|driverThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Give up.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted before driver thread was finished."
argument_list|)
expr_stmt|;
block|}
throw|throw
name|Throwables
operator|.
name|propagate
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|driverRpc
operator|.
name|addListener
argument_list|(
operator|new
name|Rpc
operator|.
name|Listener
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|rpcClosed
parameter_list|(
name|Rpc
name|rpc
parameter_list|)
block|{
if|if
condition|(
name|isAlive
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Client RPC channel closed unexpectedly."
argument_list|)
expr_stmt|;
name|isAlive
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
name|isAlive
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|JobHandle
argument_list|<
name|T
argument_list|>
name|submit
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|)
block|{
return|return
name|protocol
operator|.
name|submit
argument_list|(
name|job
argument_list|,
name|Collections
operator|.
expr|<
name|JobHandle
operator|.
name|Listener
argument_list|<
name|T
argument_list|>
operator|>
name|emptyList
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|JobHandle
argument_list|<
name|T
argument_list|>
name|submit
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|,
name|List
argument_list|<
name|JobHandle
operator|.
name|Listener
argument_list|<
name|T
argument_list|>
argument_list|>
name|listeners
parameter_list|)
block|{
return|return
name|protocol
operator|.
name|submit
argument_list|(
name|job
argument_list|,
name|listeners
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|Future
argument_list|<
name|T
argument_list|>
name|run
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|)
block|{
return|return
name|protocol
operator|.
name|run
argument_list|(
name|job
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|stop
parameter_list|()
block|{
if|if
condition|(
name|isAlive
condition|)
block|{
name|isAlive
operator|=
literal|false
expr_stmt|;
try|try
block|{
name|protocol
operator|.
name|endSession
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception while waiting for end session reply."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|driverRpc
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
name|long
name|endTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|+
name|DEFAULT_SHUTDOWN_TIMEOUT
decl_stmt|;
try|try
block|{
name|driverThread
operator|.
name|join
argument_list|(
name|DEFAULT_SHUTDOWN_TIMEOUT
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted before driver thread was finished."
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|endTime
operator|-
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Timed out shutting down remote driver, interrupting..."
argument_list|)
expr_stmt|;
name|driverThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|?
argument_list|>
name|addJar
parameter_list|(
name|URI
name|uri
parameter_list|)
block|{
return|return
name|run
argument_list|(
operator|new
name|AddJarJob
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|?
argument_list|>
name|addFile
parameter_list|(
name|URI
name|uri
parameter_list|)
block|{
return|return
name|run
argument_list|(
operator|new
name|AddFileJob
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|Integer
argument_list|>
name|getExecutorCount
parameter_list|()
block|{
return|return
name|run
argument_list|(
operator|new
name|GetExecutorCountJob
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|Integer
argument_list|>
name|getDefaultParallelism
parameter_list|()
block|{
return|return
name|run
argument_list|(
operator|new
name|GetDefaultParallelismJob
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isActive
parameter_list|()
block|{
return|return
name|isAlive
operator|&&
name|driverRpc
operator|.
name|isActive
argument_list|()
return|;
block|}
name|void
name|cancel
parameter_list|(
name|String
name|jobId
parameter_list|)
block|{
name|protocol
operator|.
name|cancel
argument_list|(
name|jobId
argument_list|)
expr_stmt|;
block|}
specifier|private
name|Thread
name|startDriver
parameter_list|(
specifier|final
name|RpcServer
name|rpcServer
parameter_list|,
specifier|final
name|String
name|clientId
parameter_list|,
specifier|final
name|String
name|secret
parameter_list|)
throws|throws
name|IOException
block|{
name|Runnable
name|runnable
decl_stmt|;
specifier|final
name|String
name|serverAddress
init|=
name|rpcServer
operator|.
name|getAddress
argument_list|()
decl_stmt|;
specifier|final
name|String
name|serverPort
init|=
name|String
operator|.
name|valueOf
argument_list|(
name|rpcServer
operator|.
name|getPort
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|containsKey
argument_list|(
name|SparkClientFactory
operator|.
name|CONF_KEY_IN_PROCESS
argument_list|)
condition|)
block|{
comment|// Mostly for testing things quickly. Do not do this in production.
comment|// when invoked in-process it inherits the environment variables of the parent
name|LOG
operator|.
name|warn
argument_list|(
literal|"!!!! Running remote driver in-process. !!!!"
argument_list|)
expr_stmt|;
name|runnable
operator|=
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|List
argument_list|<
name|String
argument_list|>
name|args
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"--remote-host"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|serverAddress
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"--remote-port"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|serverPort
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"--client-id"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|clientId
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
literal|"--secret"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|secret
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|conf
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|args
operator|.
name|add
argument_list|(
literal|"--conf"
argument_list|)
expr_stmt|;
name|args
operator|.
name|add
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"%s=%s"
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|RemoteDriver
operator|.
name|main
argument_list|(
name|args
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|args
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error running driver."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
expr_stmt|;
block|}
else|else
block|{
comment|// If a Spark installation is provided, use the spark-submit script. Otherwise, call the
comment|// SparkSubmit class directly, which has some caveats (like having to provide a proper
comment|// version of Guava on the classpath depending on the deploy mode).
name|String
name|sparkHome
init|=
name|Strings
operator|.
name|emptyToNull
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|SPARK_HOME_KEY
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|sparkHome
operator|==
literal|null
condition|)
block|{
name|sparkHome
operator|=
name|Strings
operator|.
name|emptyToNull
argument_list|(
name|System
operator|.
name|getenv
argument_list|(
name|SPARK_HOME_ENV
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sparkHome
operator|==
literal|null
condition|)
block|{
name|sparkHome
operator|=
name|Strings
operator|.
name|emptyToNull
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
name|SPARK_HOME_KEY
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|sparkLogDir
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"hive.spark.log.dir"
argument_list|)
decl_stmt|;
if|if
condition|(
name|sparkLogDir
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|sparkHome
operator|==
literal|null
condition|)
block|{
name|sparkLogDir
operator|=
literal|"./target/"
expr_stmt|;
block|}
else|else
block|{
name|sparkLogDir
operator|=
name|sparkHome
operator|+
literal|"/logs/"
expr_stmt|;
block|}
block|}
name|String
name|osxTestOpts
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|Strings
operator|.
name|nullToEmpty
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"os.name"
argument_list|)
argument_list|)
operator|.
name|toLowerCase
argument_list|()
operator|.
name|contains
argument_list|(
literal|"mac"
argument_list|)
condition|)
block|{
name|osxTestOpts
operator|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
name|System
operator|.
name|getenv
argument_list|(
name|OSX_TEST_OPTS
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|driverJavaOpts
init|=
name|Joiner
operator|.
name|on
argument_list|(
literal|" "
argument_list|)
operator|.
name|skipNulls
argument_list|()
operator|.
name|join
argument_list|(
literal|"-Dhive.spark.log.dir="
operator|+
name|sparkLogDir
argument_list|,
name|osxTestOpts
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|DRIVER_OPTS_KEY
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|executorJavaOpts
init|=
name|Joiner
operator|.
name|on
argument_list|(
literal|" "
argument_list|)
operator|.
name|skipNulls
argument_list|()
operator|.
name|join
argument_list|(
literal|"-Dhive.spark.log.dir="
operator|+
name|sparkLogDir
argument_list|,
name|osxTestOpts
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|EXECUTOR_OPTS_KEY
argument_list|)
argument_list|)
decl_stmt|;
comment|// Create a file with all the job properties to be read by spark-submit. Change the
comment|// file's permissions so that only the owner can read it. This avoid having the
comment|// connection secret show up in the child process's command line.
name|File
name|properties
init|=
name|File
operator|.
name|createTempFile
argument_list|(
literal|"spark-submit."
argument_list|,
literal|".properties"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|properties
operator|.
name|setReadable
argument_list|(
literal|false
argument_list|)
operator|||
operator|!
name|properties
operator|.
name|setReadable
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot change permissions of job properties file."
argument_list|)
throw|;
block|}
name|properties
operator|.
name|deleteOnExit
argument_list|()
expr_stmt|;
name|Properties
name|allProps
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
comment|// first load the defaults from spark-defaults.conf if available
try|try
block|{
name|URL
name|sparkDefaultsUrl
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getContextClassLoader
argument_list|()
operator|.
name|getResource
argument_list|(
literal|"spark-defaults.conf"
argument_list|)
decl_stmt|;
if|if
condition|(
name|sparkDefaultsUrl
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading spark defaults: "
operator|+
name|sparkDefaultsUrl
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|load
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|Resources
operator|.
name|toByteArray
argument_list|(
name|sparkDefaultsUrl
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Exception trying to load spark-defaults.conf: "
operator|+
name|e
decl_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// then load the SparkClientImpl config
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|conf
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|allProps
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|allProps
operator|.
name|put
argument_list|(
name|SparkClientFactory
operator|.
name|CONF_CLIENT_ID
argument_list|,
name|clientId
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|SparkClientFactory
operator|.
name|CONF_KEY_SECRET
argument_list|,
name|secret
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|DRIVER_OPTS_KEY
argument_list|,
name|driverJavaOpts
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|EXECUTOR_OPTS_KEY
argument_list|,
name|executorJavaOpts
argument_list|)
expr_stmt|;
name|String
name|isTesting
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.testing"
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTesting
operator|!=
literal|null
operator|&&
name|isTesting
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
condition|)
block|{
name|String
name|hiveHadoopTestClasspath
init|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
name|System
operator|.
name|getenv
argument_list|(
literal|"HIVE_HADOOP_TEST_CLASSPATH"
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|hiveHadoopTestClasspath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
name|extraDriverClasspath
init|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
operator|(
name|String
operator|)
name|allProps
operator|.
name|get
argument_list|(
name|DRIVER_EXTRA_CLASSPATH
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|extraDriverClasspath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|allProps
operator|.
name|put
argument_list|(
name|DRIVER_EXTRA_CLASSPATH
argument_list|,
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|extraDriverClasspath
operator|=
name|extraDriverClasspath
operator|.
name|endsWith
argument_list|(
name|File
operator|.
name|pathSeparator
argument_list|)
condition|?
name|extraDriverClasspath
else|:
name|extraDriverClasspath
operator|+
name|File
operator|.
name|pathSeparator
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|DRIVER_EXTRA_CLASSPATH
argument_list|,
name|extraDriverClasspath
operator|+
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
name|String
name|extraExecutorClasspath
init|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
operator|(
name|String
operator|)
name|allProps
operator|.
name|get
argument_list|(
name|EXECUTOR_EXTRA_CLASSPATH
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|extraExecutorClasspath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|allProps
operator|.
name|put
argument_list|(
name|EXECUTOR_EXTRA_CLASSPATH
argument_list|,
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|extraExecutorClasspath
operator|=
name|extraExecutorClasspath
operator|.
name|endsWith
argument_list|(
name|File
operator|.
name|pathSeparator
argument_list|)
condition|?
name|extraExecutorClasspath
else|:
name|extraExecutorClasspath
operator|+
name|File
operator|.
name|pathSeparator
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|EXECUTOR_EXTRA_CLASSPATH
argument_list|,
name|extraExecutorClasspath
operator|+
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|Writer
name|writer
init|=
operator|new
name|OutputStreamWriter
argument_list|(
operator|new
name|FileOutputStream
argument_list|(
name|properties
argument_list|)
argument_list|,
name|Charsets
operator|.
name|UTF_8
argument_list|)
decl_stmt|;
try|try
block|{
name|allProps
operator|.
name|store
argument_list|(
name|writer
argument_list|,
literal|"Spark Context configuration"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// Define how to pass options to the child process. If launching in client (or local)
comment|// mode, the driver options need to be passed directly on the command line. Otherwise,
comment|// SparkSubmit will take care of that for us.
name|String
name|master
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.master"
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|master
operator|!=
literal|null
argument_list|,
literal|"spark.master is not defined."
argument_list|)
expr_stmt|;
name|String
name|deployMode
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.submit.deployMode"
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|argv
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
if|if
condition|(
name|sparkHome
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
operator|new
name|File
argument_list|(
name|sparkHome
argument_list|,
literal|"bin/spark-submit"
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No spark.home provided, calling SparkSubmit directly."
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
operator|new
name|File
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"java.home"
argument_list|)
argument_list|,
literal|"bin/java"
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|master
operator|.
name|startsWith
argument_list|(
literal|"local"
argument_list|)
operator|||
name|master
operator|.
name|startsWith
argument_list|(
literal|"mesos"
argument_list|)
operator|||
name|SparkClientUtilities
operator|.
name|isYarnClientMode
argument_list|(
name|master
argument_list|,
name|deployMode
argument_list|)
operator|||
name|master
operator|.
name|startsWith
argument_list|(
literal|"spark"
argument_list|)
condition|)
block|{
name|String
name|mem
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.driver.memory"
argument_list|)
decl_stmt|;
if|if
condition|(
name|mem
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"-Xms"
operator|+
name|mem
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"-Xmx"
operator|+
name|mem
argument_list|)
expr_stmt|;
block|}
name|String
name|cp
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.driver.extraClassPath"
argument_list|)
decl_stmt|;
if|if
condition|(
name|cp
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"-classpath"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|cp
argument_list|)
expr_stmt|;
block|}
name|String
name|libPath
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.driver.extraLibPath"
argument_list|)
decl_stmt|;
if|if
condition|(
name|libPath
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"-Djava.library.path="
operator|+
name|libPath
argument_list|)
expr_stmt|;
block|}
name|String
name|extra
init|=
name|conf
operator|.
name|get
argument_list|(
name|DRIVER_OPTS_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|extra
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|opt
range|:
name|extra
operator|.
name|split
argument_list|(
literal|"[ ]"
argument_list|)
control|)
block|{
if|if
condition|(
operator|!
name|opt
operator|.
name|trim
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
name|opt
operator|.
name|trim
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|argv
operator|.
name|add
argument_list|(
literal|"org.apache.spark.deploy.SparkSubmit"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
literal|"kerberos"
operator|.
name|equals
argument_list|(
name|hiveConf
operator|.
name|get
argument_list|(
name|HADOOP_SECURITY_AUTHENTICATION
argument_list|)
argument_list|)
condition|)
block|{
name|String
name|principal
init|=
name|SecurityUtil
operator|.
name|getServerPrincipal
argument_list|(
name|hiveConf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_SERVER2_KERBEROS_PRINCIPAL
argument_list|)
argument_list|,
literal|"0.0.0.0"
argument_list|)
decl_stmt|;
name|String
name|keyTabFile
init|=
name|hiveConf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_SERVER2_KERBEROS_KEYTAB
argument_list|)
decl_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--principal"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|principal
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--keytab"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|keyTabFile
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|SparkClientUtilities
operator|.
name|isYarnClusterMode
argument_list|(
name|master
argument_list|,
name|deployMode
argument_list|)
condition|)
block|{
name|String
name|executorCores
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executor.cores"
argument_list|)
decl_stmt|;
if|if
condition|(
name|executorCores
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--executor-cores"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|executorCores
argument_list|)
expr_stmt|;
block|}
name|String
name|executorMemory
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executor.memory"
argument_list|)
decl_stmt|;
if|if
condition|(
name|executorMemory
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--executor-memory"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|executorMemory
argument_list|)
expr_stmt|;
block|}
name|String
name|numOfExecutors
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executor.instances"
argument_list|)
decl_stmt|;
if|if
condition|(
name|numOfExecutors
operator|!=
literal|null
condition|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--num-executors"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|numOfExecutors
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|hiveConf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SERVER2_ENABLE_DOAS
argument_list|)
condition|)
block|{
try|try
block|{
name|String
name|currentUser
init|=
name|Utils
operator|.
name|getUGI
argument_list|()
operator|.
name|getShortUserName
argument_list|()
decl_stmt|;
comment|// do not do impersonation in CLI mode
if|if
condition|(
operator|!
name|currentUser
operator|.
name|equals
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Attempting impersonation of "
operator|+
name|currentUser
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--proxy-user"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|currentUser
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Cannot obtain username: "
operator|+
name|e
decl_stmt|;
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|argv
operator|.
name|add
argument_list|(
literal|"--properties-file"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|properties
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--class"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|RemoteDriver
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|jar
init|=
literal|"spark-internal"
decl_stmt|;
if|if
condition|(
name|SparkContext
operator|.
name|jarOfClass
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
operator|.
name|isDefined
argument_list|()
condition|)
block|{
name|jar
operator|=
name|SparkContext
operator|.
name|jarOfClass
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
name|argv
operator|.
name|add
argument_list|(
name|jar
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--remote-host"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|serverAddress
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--remote-port"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|serverPort
argument_list|)
expr_stmt|;
comment|//hive.spark.* keys are passed down to the RemoteDriver via --conf,
comment|//as --properties-file contains the spark.* keys that are meant for SparkConf object.
for|for
control|(
name|String
name|hiveSparkConfKey
range|:
name|RpcConfiguration
operator|.
name|HIVE_SPARK_RSC_CONFIGS
control|)
block|{
name|String
name|value
init|=
name|RpcConfiguration
operator|.
name|getValue
argument_list|(
name|hiveConf
argument_list|,
name|hiveSparkConfKey
argument_list|)
decl_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--conf"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"%s=%s"
argument_list|,
name|hiveSparkConfKey
argument_list|,
name|value
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|cmd
init|=
name|Joiner
operator|.
name|on
argument_list|(
literal|" "
argument_list|)
operator|.
name|join
argument_list|(
name|argv
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Running client driver with argv: {}"
argument_list|,
name|cmd
argument_list|)
expr_stmt|;
name|ProcessBuilder
name|pb
init|=
operator|new
name|ProcessBuilder
argument_list|(
literal|"sh"
argument_list|,
literal|"-c"
argument_list|,
name|cmd
argument_list|)
decl_stmt|;
comment|// Prevent hive configurations from being visible in Spark.
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|remove
argument_list|(
literal|"HIVE_HOME"
argument_list|)
expr_stmt|;
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|remove
argument_list|(
literal|"HIVE_CONF_DIR"
argument_list|)
expr_stmt|;
comment|// Add credential provider password to the child process's environment
comment|// In case of Spark the credential provider location is provided in the jobConf when the job is submitted
name|String
name|password
init|=
name|getSparkJobCredentialProviderPassword
argument_list|()
decl_stmt|;
if|if
condition|(
name|password
operator|!=
literal|null
condition|)
block|{
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|put
argument_list|(
name|Constants
operator|.
name|HADOOP_CREDENTIAL_PASSWORD_ENVVAR
argument_list|,
name|password
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isTesting
operator|!=
literal|null
condition|)
block|{
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|put
argument_list|(
literal|"SPARK_TESTING"
argument_list|,
name|isTesting
argument_list|)
expr_stmt|;
block|}
specifier|final
name|Process
name|child
init|=
name|pb
operator|.
name|start
argument_list|()
decl_stmt|;
name|int
name|childId
init|=
name|childIdGenerator
operator|.
name|incrementAndGet
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|childErrorLog
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|redirect
argument_list|(
literal|"stdout-redir-"
operator|+
name|childId
argument_list|,
operator|new
name|Redirector
argument_list|(
name|child
operator|.
name|getInputStream
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|redirect
argument_list|(
literal|"stderr-redir-"
operator|+
name|childId
argument_list|,
operator|new
name|Redirector
argument_list|(
name|child
operator|.
name|getErrorStream
argument_list|()
argument_list|,
name|childErrorLog
argument_list|)
argument_list|)
expr_stmt|;
name|runnable
operator|=
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|int
name|exitCode
init|=
name|child
operator|.
name|waitFor
argument_list|()
decl_stmt|;
if|if
condition|(
name|exitCode
operator|!=
literal|0
condition|)
block|{
name|StringBuilder
name|errStr
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|s
range|:
name|childErrorLog
control|)
block|{
name|errStr
operator|.
name|append
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|errStr
operator|.
name|append
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
block|}
name|rpcServer
operator|.
name|cancelClient
argument_list|(
name|clientId
argument_list|,
literal|"Child process exited before connecting back with error log "
operator|+
name|errStr
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Child process exited with code {}"
argument_list|,
name|exitCode
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Waiting thread interrupted, killing child process."
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|interrupted
argument_list|()
expr_stmt|;
name|child
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception while waiting for child process."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
expr_stmt|;
block|}
name|Thread
name|thread
init|=
operator|new
name|Thread
argument_list|(
name|runnable
argument_list|)
decl_stmt|;
name|thread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|thread
operator|.
name|setName
argument_list|(
literal|"Driver"
argument_list|)
expr_stmt|;
name|thread
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|thread
return|;
block|}
specifier|private
name|String
name|getSparkJobCredentialProviderPassword
parameter_list|()
block|{
if|if
condition|(
name|conf
operator|.
name|containsKey
argument_list|(
literal|"spark.yarn.appMasterEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
condition|)
block|{
return|return
name|conf
operator|.
name|get
argument_list|(
literal|"spark.yarn.appMasterEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|conf
operator|.
name|containsKey
argument_list|(
literal|"spark.executorEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
condition|)
block|{
return|return
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executorEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
specifier|private
name|void
name|redirect
parameter_list|(
name|String
name|name
parameter_list|,
name|Redirector
name|redirector
parameter_list|)
block|{
name|Thread
name|thread
init|=
operator|new
name|Thread
argument_list|(
name|redirector
argument_list|)
decl_stmt|;
name|thread
operator|.
name|setName
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|thread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|thread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
specifier|private
class|class
name|ClientProtocol
extends|extends
name|BaseProtocol
block|{
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|JobHandleImpl
argument_list|<
name|T
argument_list|>
name|submit
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|,
name|List
argument_list|<
name|JobHandle
operator|.
name|Listener
argument_list|<
name|T
argument_list|>
argument_list|>
name|listeners
parameter_list|)
block|{
specifier|final
name|String
name|jobId
init|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
specifier|final
name|Promise
argument_list|<
name|T
argument_list|>
name|promise
init|=
name|driverRpc
operator|.
name|createPromise
argument_list|()
decl_stmt|;
specifier|final
name|JobHandleImpl
argument_list|<
name|T
argument_list|>
name|handle
init|=
operator|new
name|JobHandleImpl
argument_list|<
name|T
argument_list|>
argument_list|(
name|SparkClientImpl
operator|.
name|this
argument_list|,
name|promise
argument_list|,
name|jobId
argument_list|,
name|listeners
argument_list|)
decl_stmt|;
name|jobs
operator|.
name|put
argument_list|(
name|jobId
argument_list|,
name|handle
argument_list|)
expr_stmt|;
specifier|final
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|Void
argument_list|>
name|rpc
init|=
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|JobRequest
argument_list|(
name|jobId
argument_list|,
name|job
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Send JobRequest[{}]."
argument_list|,
name|jobId
argument_list|)
expr_stmt|;
comment|// Link the RPC and the promise so that events from one are propagated to the other as
comment|// needed.
name|rpc
operator|.
name|addListener
argument_list|(
operator|new
name|GenericFutureListener
argument_list|<
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|operationComplete
parameter_list|(
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|Void
argument_list|>
name|f
parameter_list|)
block|{
if|if
condition|(
name|f
operator|.
name|isSuccess
argument_list|()
condition|)
block|{
comment|// If the spark job finishes before this listener is called, the QUEUED status will not be set
name|handle
operator|.
name|changeState
argument_list|(
name|JobHandle
operator|.
name|State
operator|.
name|QUEUED
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|promise
operator|.
name|isDone
argument_list|()
condition|)
block|{
name|promise
operator|.
name|setFailure
argument_list|(
name|f
operator|.
name|cause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
name|promise
operator|.
name|addListener
argument_list|(
operator|new
name|GenericFutureListener
argument_list|<
name|Promise
argument_list|<
name|T
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|operationComplete
parameter_list|(
name|Promise
argument_list|<
name|T
argument_list|>
name|p
parameter_list|)
block|{
if|if
condition|(
name|jobId
operator|!=
literal|null
condition|)
block|{
name|jobs
operator|.
name|remove
argument_list|(
name|jobId
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|p
operator|.
name|isCancelled
argument_list|()
operator|&&
operator|!
name|rpc
operator|.
name|isDone
argument_list|()
condition|)
block|{
name|rpc
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|handle
return|;
block|}
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|Future
argument_list|<
name|T
argument_list|>
name|run
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|)
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|final
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|T
argument_list|>
name|rpc
init|=
operator|(
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|T
argument_list|>
operator|)
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|SyncJobRequest
argument_list|(
name|job
argument_list|)
argument_list|,
name|Serializable
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
name|rpc
return|;
block|}
name|void
name|cancel
parameter_list|(
name|String
name|jobId
parameter_list|)
block|{
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|CancelJob
argument_list|(
name|jobId
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Future
argument_list|<
name|?
argument_list|>
name|endSession
parameter_list|()
block|{
return|return
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|EndSession
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|Error
name|msg
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error reported from remote driver."
argument_list|,
name|msg
operator|.
name|cause
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobMetrics
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|get
argument_list|(
name|msg
operator|.
name|jobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|handle
operator|.
name|getMetrics
argument_list|()
operator|.
name|addMetrics
argument_list|(
name|msg
operator|.
name|sparkJobId
argument_list|,
name|msg
operator|.
name|stageId
argument_list|,
name|msg
operator|.
name|taskId
argument_list|,
name|msg
operator|.
name|metrics
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received metrics for unknown job {}"
argument_list|,
name|msg
operator|.
name|jobId
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobResult
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|remove
argument_list|(
name|msg
operator|.
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Received result for {}"
argument_list|,
name|msg
operator|.
name|id
argument_list|)
expr_stmt|;
name|handle
operator|.
name|setSparkCounters
argument_list|(
name|msg
operator|.
name|sparkCounters
argument_list|)
expr_stmt|;
name|Throwable
name|error
init|=
name|msg
operator|.
name|error
operator|!=
literal|null
condition|?
operator|new
name|SparkException
argument_list|(
name|msg
operator|.
name|error
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|error
operator|==
literal|null
condition|)
block|{
name|handle
operator|.
name|setSuccess
argument_list|(
name|msg
operator|.
name|result
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|handle
operator|.
name|setFailure
argument_list|(
name|error
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received result for unknown job {}"
argument_list|,
name|msg
operator|.
name|id
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobStarted
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|get
argument_list|(
name|msg
operator|.
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|handle
operator|.
name|changeState
argument_list|(
name|JobHandle
operator|.
name|State
operator|.
name|STARTED
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received event for unknown job {}"
argument_list|,
name|msg
operator|.
name|id
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobSubmitted
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|get
argument_list|(
name|msg
operator|.
name|clientJobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Received spark job ID: {} for {}"
argument_list|,
name|msg
operator|.
name|sparkJobId
argument_list|,
name|msg
operator|.
name|clientJobId
argument_list|)
expr_stmt|;
name|handle
operator|.
name|addSparkJobId
argument_list|(
name|msg
operator|.
name|sparkJobId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received spark job ID: {} for unknown job {}"
argument_list|,
name|msg
operator|.
name|sparkJobId
argument_list|,
name|msg
operator|.
name|clientJobId
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
class|class
name|Redirector
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|BufferedReader
name|in
decl_stmt|;
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|errLogs
decl_stmt|;
specifier|private
name|int
name|numErrLogLines
init|=
literal|0
decl_stmt|;
name|Redirector
parameter_list|(
name|InputStream
name|in
parameter_list|)
block|{
name|this
operator|.
name|in
operator|=
operator|new
name|BufferedReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|in
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Redirector
parameter_list|(
name|InputStream
name|in
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|errLogs
parameter_list|)
block|{
name|this
operator|.
name|in
operator|=
operator|new
name|BufferedReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|in
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|errLogs
operator|=
name|errLogs
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|String
name|line
init|=
literal|null
decl_stmt|;
while|while
condition|(
operator|(
name|line
operator|=
name|in
operator|.
name|readLine
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|line
argument_list|)
expr_stmt|;
if|if
condition|(
name|errLogs
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|numErrLogLines
operator|++
operator|<
name|MAX_ERR_LOG_LINES_FOR_RPC
condition|)
block|{
name|errLogs
operator|.
name|add
argument_list|(
name|line
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isAlive
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"I/O error in redirector thread."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// When stopping the remote driver the process might be destroyed during reading from the stream.
comment|// We should not log the related exceptions in a visible level as they might mislead the user.
name|LOG
operator|.
name|debug
argument_list|(
literal|"I/O error in redirector thread while stopping the remote driver"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error in redirector thread."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
class|class
name|AddJarJob
implements|implements
name|Job
argument_list|<
name|Serializable
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|final
name|String
name|path
decl_stmt|;
name|AddJarJob
parameter_list|()
block|{
name|this
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|AddJarJob
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Serializable
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|addJar
argument_list|(
name|path
argument_list|)
expr_stmt|;
comment|// Following remote job may refer to classes in this jar, and the remote job would be executed
comment|// in a different thread, so we add this jar path to JobContext for further usage.
name|jc
operator|.
name|getAddedJars
argument_list|()
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|AddFileJob
implements|implements
name|Job
argument_list|<
name|Serializable
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|final
name|String
name|path
decl_stmt|;
name|AddFileJob
parameter_list|()
block|{
name|this
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|AddFileJob
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Serializable
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|addFile
argument_list|(
name|path
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetExecutorCountJob
implements|implements
name|Job
argument_list|<
name|Integer
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
annotation|@
name|Override
specifier|public
name|Integer
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
comment|// minus 1 here otherwise driver is also counted as an executor
name|int
name|count
init|=
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|sc
argument_list|()
operator|.
name|getExecutorMemoryStatus
argument_list|()
operator|.
name|size
argument_list|()
operator|-
literal|1
decl_stmt|;
return|return
name|Integer
operator|.
name|valueOf
argument_list|(
name|count
argument_list|)
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetDefaultParallelismJob
implements|implements
name|Job
argument_list|<
name|Integer
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
annotation|@
name|Override
specifier|public
name|Integer
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|sc
argument_list|()
operator|.
name|defaultParallelism
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

