begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|FutureTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|log
operator|.
name|LogRedirector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|RpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Extends the {@link AbstractSparkClient} and launches a child process to run Spark's {@code  * bin/spark-submit} script. Logs are re-directed from the child process logs.  */
end_comment

begin_class
class|class
name|SparkSubmitSparkClient
extends|extends
name|AbstractSparkClient
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|SparkSubmitSparkClient
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPARK_HOME_ENV
init|=
literal|"SPARK_HOME"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPARK_HOME_KEY
init|=
literal|"spark.home"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
operator|-
literal|4272763023516238171L
decl_stmt|;
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|argv
decl_stmt|;
name|SparkSubmitSparkClient
parameter_list|(
name|RpcServer
name|rpcServer
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|conf
parameter_list|,
name|HiveConf
name|hiveConf
parameter_list|,
name|String
name|sessionid
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|rpcServer
argument_list|,
name|conf
argument_list|,
name|hiveConf
argument_list|,
name|sessionid
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|String
name|getSparkHome
parameter_list|()
block|{
name|String
name|sparkHome
init|=
name|Strings
operator|.
name|emptyToNull
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|SPARK_HOME_KEY
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|sparkHome
operator|==
literal|null
condition|)
block|{
name|sparkHome
operator|=
name|Strings
operator|.
name|emptyToNull
argument_list|(
name|System
operator|.
name|getenv
argument_list|(
name|SPARK_HOME_ENV
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sparkHome
operator|==
literal|null
condition|)
block|{
name|sparkHome
operator|=
name|Strings
operator|.
name|emptyToNull
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
name|SPARK_HOME_KEY
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|sparkHome
argument_list|,
literal|"Cannot use "
operator|+
name|HiveConf
operator|.
name|HIVE_SPARK_SUBMIT_CLIENT
operator|+
literal|" without setting Spark Home"
argument_list|)
expr_stmt|;
name|String
name|master
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.master"
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|master
operator|!=
literal|null
argument_list|,
literal|"spark.master is not defined."
argument_list|)
expr_stmt|;
name|argv
operator|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
operator|new
name|File
argument_list|(
name|sparkHome
argument_list|,
literal|"bin/spark-submit"
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|sparkHome
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addAppArg
parameter_list|(
name|String
name|arg
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
name|arg
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addExecutableJar
parameter_list|(
name|String
name|jar
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
name|jar
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addPropertiesFile
parameter_list|(
name|String
name|absolutePath
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--properties-file"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|absolutePath
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addClass
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--class"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|RemoteDriver
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addJars
parameter_list|(
name|String
name|jars
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--jars"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|jars
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addProxyUser
parameter_list|(
name|String
name|proxyUser
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--proxy-user"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|proxyUser
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addKeytabAndPrincipal
parameter_list|(
name|boolean
name|isDoAsEnabled
parameter_list|,
name|String
name|keyTabFile
parameter_list|,
name|String
name|principal
parameter_list|)
block|{
if|if
condition|(
name|isDoAsEnabled
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|kinitArgv
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|kinitArgv
operator|.
name|add
argument_list|(
literal|"kinit"
argument_list|)
expr_stmt|;
name|kinitArgv
operator|.
name|add
argument_list|(
name|principal
argument_list|)
expr_stmt|;
name|kinitArgv
operator|.
name|add
argument_list|(
literal|"-k"
argument_list|)
expr_stmt|;
name|kinitArgv
operator|.
name|add
argument_list|(
literal|"-t"
argument_list|)
expr_stmt|;
name|kinitArgv
operator|.
name|add
argument_list|(
name|keyTabFile
operator|+
literal|";"
argument_list|)
expr_stmt|;
name|kinitArgv
operator|.
name|addAll
argument_list|(
name|argv
argument_list|)
expr_stmt|;
name|argv
operator|=
name|kinitArgv
expr_stmt|;
block|}
else|else
block|{
comment|// if doAs is not enabled, we pass the principal/keypad to spark-submit in order to
comment|// support the possible delegation token renewal in Spark
name|argv
operator|.
name|add
argument_list|(
literal|"--principal"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|principal
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
literal|"--keytab"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|keyTabFile
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addNumExecutors
parameter_list|(
name|String
name|numOfExecutors
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--num-executors"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|numOfExecutors
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addExecutorMemory
parameter_list|(
name|String
name|executorMemory
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--executor-memory"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|executorMemory
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|addExecutorCores
parameter_list|(
name|String
name|executorCores
parameter_list|)
block|{
name|argv
operator|.
name|add
argument_list|(
literal|"--executor-cores"
argument_list|)
expr_stmt|;
name|argv
operator|.
name|add
argument_list|(
name|executorCores
argument_list|)
expr_stmt|;
block|}
specifier|private
name|String
name|getSparkJobCredentialProviderPassword
parameter_list|()
block|{
if|if
condition|(
name|conf
operator|.
name|containsKey
argument_list|(
literal|"spark.yarn.appMasterEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
condition|)
block|{
return|return
name|conf
operator|.
name|get
argument_list|(
literal|"spark.yarn.appMasterEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|conf
operator|.
name|containsKey
argument_list|(
literal|"spark.executorEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
condition|)
block|{
return|return
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executorEnv.HADOOP_CREDSTORE_PASSWORD"
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|protected
name|Future
argument_list|<
name|Void
argument_list|>
name|launchDriver
parameter_list|(
name|String
name|isTesting
parameter_list|,
name|RpcServer
name|rpcServer
parameter_list|,
name|String
name|clientId
parameter_list|)
throws|throws
name|IOException
block|{
name|Callable
argument_list|<
name|Void
argument_list|>
name|runnable
decl_stmt|;
name|String
name|cmd
init|=
name|Joiner
operator|.
name|on
argument_list|(
literal|" "
argument_list|)
operator|.
name|join
argument_list|(
name|argv
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Running client driver with argv: {}"
argument_list|,
name|cmd
argument_list|)
expr_stmt|;
name|ProcessBuilder
name|pb
init|=
operator|new
name|ProcessBuilder
argument_list|(
literal|"sh"
argument_list|,
literal|"-c"
argument_list|,
name|cmd
argument_list|)
decl_stmt|;
comment|// Prevent hive configurations from being visible in Spark.
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|remove
argument_list|(
literal|"HIVE_HOME"
argument_list|)
expr_stmt|;
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|remove
argument_list|(
literal|"HIVE_CONF_DIR"
argument_list|)
expr_stmt|;
comment|// Add credential provider password to the child process's environment
comment|// In case of Spark the credential provider location is provided in the jobConf when the job is submitted
name|String
name|password
init|=
name|getSparkJobCredentialProviderPassword
argument_list|()
decl_stmt|;
if|if
condition|(
name|password
operator|!=
literal|null
condition|)
block|{
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|put
argument_list|(
name|Constants
operator|.
name|HADOOP_CREDENTIAL_PASSWORD_ENVVAR
argument_list|,
name|password
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isTesting
operator|!=
literal|null
condition|)
block|{
name|pb
operator|.
name|environment
argument_list|()
operator|.
name|put
argument_list|(
literal|"SPARK_TESTING"
argument_list|,
name|isTesting
argument_list|)
expr_stmt|;
block|}
specifier|final
name|Process
name|child
init|=
name|pb
operator|.
name|start
argument_list|()
decl_stmt|;
name|String
name|threadName
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|childErrorLog
init|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|LogRedirector
operator|.
name|LogSourceCallback
name|callback
init|=
parameter_list|()
lambda|->
name|isAlive
decl_stmt|;
name|LogRedirector
operator|.
name|redirect
argument_list|(
literal|"spark-submit-stdout-redir-"
operator|+
name|threadName
argument_list|,
operator|new
name|LogRedirector
argument_list|(
name|child
operator|.
name|getInputStream
argument_list|()
argument_list|,
name|LOG
argument_list|,
name|callback
argument_list|)
argument_list|)
expr_stmt|;
name|LogRedirector
operator|.
name|redirect
argument_list|(
literal|"spark-submit-stderr-redir-"
operator|+
name|threadName
argument_list|,
operator|new
name|LogRedirector
argument_list|(
name|child
operator|.
name|getErrorStream
argument_list|()
argument_list|,
name|LOG
argument_list|,
name|childErrorLog
argument_list|,
name|callback
argument_list|)
argument_list|)
expr_stmt|;
name|runnable
operator|=
parameter_list|()
lambda|->
block|{
try|try
block|{
name|int
name|exitCode
init|=
name|child
operator|.
name|waitFor
argument_list|()
decl_stmt|;
if|if
condition|(
name|exitCode
operator|!=
literal|0
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|errorMessages
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|childErrorLog
init|)
block|{
for|for
control|(
name|String
name|line
range|:
name|childErrorLog
control|)
block|{
if|if
condition|(
name|StringUtils
operator|.
name|containsIgnoreCase
argument_list|(
name|line
argument_list|,
literal|"Error"
argument_list|)
condition|)
block|{
name|errorMessages
operator|.
name|add
argument_list|(
literal|"\""
operator|+
name|line
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|String
name|errStr
init|=
name|errorMessages
operator|.
name|isEmpty
argument_list|()
condition|?
literal|"?"
else|:
name|Joiner
operator|.
name|on
argument_list|(
literal|','
argument_list|)
operator|.
name|join
argument_list|(
name|errorMessages
argument_list|)
decl_stmt|;
name|rpcServer
operator|.
name|cancelClient
argument_list|(
name|clientId
argument_list|,
operator|new
name|RuntimeException
argument_list|(
literal|"spark-submit process failed "
operator|+
literal|"with exit code "
operator|+
name|exitCode
operator|+
literal|" and error "
operator|+
name|errStr
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Thread waiting on the child process (spark-submit) is interrupted, killing the child process."
argument_list|)
expr_stmt|;
name|rpcServer
operator|.
name|cancelClient
argument_list|(
name|clientId
argument_list|,
literal|"Thread waiting on the child process (spark-submit) is interrupted"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|interrupted
argument_list|()
expr_stmt|;
name|child
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|errMsg
init|=
literal|"Exception while waiting for child process (spark-submit)"
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|errMsg
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|rpcServer
operator|.
name|cancelClient
argument_list|(
name|clientId
argument_list|,
name|errMsg
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
expr_stmt|;
name|FutureTask
argument_list|<
name|Void
argument_list|>
name|futureTask
init|=
operator|new
name|FutureTask
argument_list|<>
argument_list|(
name|runnable
argument_list|)
decl_stmt|;
name|Thread
name|driverThread
init|=
operator|new
name|Thread
argument_list|(
name|futureTask
argument_list|)
decl_stmt|;
name|driverThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|driverThread
operator|.
name|setName
argument_list|(
literal|"SparkSubmitMonitor"
argument_list|)
expr_stmt|;
name|driverThread
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|futureTask
return|;
block|}
block|}
end_class

end_unit

