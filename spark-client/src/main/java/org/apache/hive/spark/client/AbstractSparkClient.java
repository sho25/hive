begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeysPublic
operator|.
name|HADOOP_SECURITY_AUTHENTICATION
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|SparkClientUtilities
operator|.
name|HIVE_KRYO_REG_NAME
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Charsets
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Throwables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|io
operator|.
name|Resources
import|;
end_import

begin_import
import|import
name|io
operator|.
name|netty
operator|.
name|channel
operator|.
name|ChannelHandlerContext
import|;
end_import

begin_import
import|import
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|GenericFutureListener
import|;
end_import

begin_import
import|import
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Promise
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStreamWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Writer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
operator|.
name|ConfVars
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|Rpc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|RpcConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|spark
operator|.
name|client
operator|.
name|rpc
operator|.
name|RpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|spark
operator|.
name|SparkContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * An abstract implementation of {@link SparkClient} that allows sub-classes to override how the  * spark application is launched. It provides the following functionality: (1) creating the client  * connection to the {@link RemoteDriver} and managing its lifecycle, (2) monitoring the thread  * used to submit the Spark application, (3) safe shutdown of the {@link RemoteDriver}, and (4)  * configuration handling for submitting the Spark application.  *  *<p>  *   This class contains the client protocol used to communicate with the {@link RemoteDriver}.  *   It uses this protocol to submit {@link Job}s to the {@link RemoteDriver}.  *</p>  */
end_comment

begin_class
specifier|abstract
class|class
name|AbstractSparkClient
implements|implements
name|SparkClient
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AbstractSparkClient
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_SHUTDOWN_TIMEOUT
init|=
literal|10000
decl_stmt|;
comment|// In milliseconds
specifier|private
specifier|static
specifier|final
name|String
name|OSX_TEST_OPTS
init|=
literal|"SPARK_OSX_TEST_OPTS"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DRIVER_OPTS_KEY
init|=
literal|"spark.driver.extraJavaOptions"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|EXECUTOR_OPTS_KEY
init|=
literal|"spark.executor.extraJavaOptions"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DRIVER_EXTRA_CLASSPATH
init|=
literal|"spark.driver.extraClassPath"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|EXECUTOR_EXTRA_CLASSPATH
init|=
literal|"spark.executor.extraClassPath"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPARK_DEPLOY_MODE
init|=
literal|"spark.submit.deployMode"
decl_stmt|;
specifier|protected
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|conf
decl_stmt|;
specifier|private
specifier|final
name|HiveConf
name|hiveConf
decl_stmt|;
specifier|private
specifier|final
name|Future
argument_list|<
name|Void
argument_list|>
name|driverFuture
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
argument_list|>
name|jobs
decl_stmt|;
specifier|private
specifier|final
name|Rpc
name|driverRpc
decl_stmt|;
specifier|private
specifier|final
name|ClientProtocol
name|protocol
decl_stmt|;
specifier|protected
specifier|volatile
name|boolean
name|isAlive
decl_stmt|;
specifier|protected
name|AbstractSparkClient
parameter_list|(
name|RpcServer
name|rpcServer
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|conf
parameter_list|,
name|HiveConf
name|hiveConf
parameter_list|,
name|String
name|sessionid
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|hiveConf
operator|=
name|hiveConf
expr_stmt|;
name|this
operator|.
name|jobs
operator|=
name|Maps
operator|.
name|newConcurrentMap
argument_list|()
expr_stmt|;
name|String
name|secret
init|=
name|rpcServer
operator|.
name|createSecret
argument_list|()
decl_stmt|;
name|this
operator|.
name|driverFuture
operator|=
name|startDriver
argument_list|(
name|rpcServer
argument_list|,
name|sessionid
argument_list|,
name|secret
argument_list|)
expr_stmt|;
name|this
operator|.
name|protocol
operator|=
operator|new
name|ClientProtocol
argument_list|()
expr_stmt|;
try|try
block|{
comment|// The RPC server will take care of timeouts here.
name|this
operator|.
name|driverRpc
operator|=
name|rpcServer
operator|.
name|registerClient
argument_list|(
name|sessionid
argument_list|,
name|secret
argument_list|,
name|protocol
argument_list|)
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|String
name|errorMsg
decl_stmt|;
if|if
condition|(
name|e
operator|.
name|getCause
argument_list|()
operator|instanceof
name|TimeoutException
condition|)
block|{
name|errorMsg
operator|=
literal|"Timed out waiting for Remote Spark Driver to connect to HiveServer2.\nPossible reasons "
operator|+
literal|"include network issues, errors in remote driver, cluster has no available resources, etc."
operator|+
literal|"\nPlease check YARN or Spark driver's logs for further information."
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|e
operator|.
name|getCause
argument_list|()
operator|instanceof
name|InterruptedException
condition|)
block|{
name|errorMsg
operator|=
literal|"Interrupted while waiting for Remote Spark Driver to connect to HiveServer2.\nIt is possible "
operator|+
literal|"that the query was cancelled which would cause the Spark Session to close."
expr_stmt|;
block|}
else|else
block|{
name|errorMsg
operator|=
literal|"Error while waiting for Remote Spark Driver to connect back to HiveServer2."
expr_stmt|;
block|}
name|LOG
operator|.
name|error
argument_list|(
name|errorMsg
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|driverFuture
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
try|try
block|{
name|driverFuture
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Give up.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted before driver thread was finished."
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|ee
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Driver thread failed"
argument_list|,
name|ee
argument_list|)
expr_stmt|;
block|}
throw|throw
name|Throwables
operator|.
name|propagate
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully connected to Remote Spark Driver at: "
operator|+
name|this
operator|.
name|driverRpc
operator|.
name|getRemoteAddress
argument_list|()
argument_list|)
expr_stmt|;
name|driverRpc
operator|.
name|addListener
argument_list|(
operator|new
name|Rpc
operator|.
name|Listener
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|rpcClosed
parameter_list|(
name|Rpc
name|rpc
parameter_list|)
block|{
if|if
condition|(
name|isAlive
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Connection to Remote Spark Driver {} closed unexpectedly"
argument_list|,
name|driverRpc
operator|.
name|getRemoteAddress
argument_list|()
argument_list|)
expr_stmt|;
name|isAlive
operator|=
literal|false
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"Connection to Remote Spark Driver Closed Unexpectedly"
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|isAlive
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|JobHandle
argument_list|<
name|T
argument_list|>
name|submit
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|)
block|{
return|return
name|protocol
operator|.
name|submit
argument_list|(
name|job
argument_list|,
name|Collections
operator|.
expr|<
name|JobHandle
operator|.
name|Listener
argument_list|<
name|T
argument_list|>
operator|>
name|emptyList
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|JobHandle
argument_list|<
name|T
argument_list|>
name|submit
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|,
name|List
argument_list|<
name|JobHandle
operator|.
name|Listener
argument_list|<
name|T
argument_list|>
argument_list|>
name|listeners
parameter_list|)
block|{
return|return
name|protocol
operator|.
name|submit
argument_list|(
name|job
argument_list|,
name|listeners
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|Future
argument_list|<
name|T
argument_list|>
name|run
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|)
block|{
return|return
name|protocol
operator|.
name|run
argument_list|(
name|job
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|stop
parameter_list|()
block|{
if|if
condition|(
name|isAlive
condition|)
block|{
name|isAlive
operator|=
literal|false
expr_stmt|;
try|try
block|{
name|protocol
operator|.
name|endSession
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception while waiting for end session reply."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|driverRpc
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
try|try
block|{
name|driverFuture
operator|.
name|get
argument_list|(
name|DEFAULT_SHUTDOWN_TIMEOUT
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while waiting for driver future to complete"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Timed out shutting down remote driver, cancelling..."
argument_list|)
expr_stmt|;
name|driverFuture
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted before driver thread was finished."
argument_list|)
expr_stmt|;
name|driverFuture
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|?
argument_list|>
name|addJar
parameter_list|(
name|URI
name|uri
parameter_list|)
block|{
return|return
name|run
argument_list|(
operator|new
name|AddJarJob
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|?
argument_list|>
name|addFile
parameter_list|(
name|URI
name|uri
parameter_list|)
block|{
return|return
name|run
argument_list|(
operator|new
name|AddFileJob
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|Integer
argument_list|>
name|getExecutorCount
parameter_list|()
block|{
return|return
name|run
argument_list|(
operator|new
name|GetExecutorCountJob
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Future
argument_list|<
name|Integer
argument_list|>
name|getDefaultParallelism
parameter_list|()
block|{
return|return
name|run
argument_list|(
operator|new
name|GetDefaultParallelismJob
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isActive
parameter_list|()
block|{
return|return
name|isAlive
operator|&&
name|driverRpc
operator|.
name|isActive
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|cancel
parameter_list|(
name|String
name|jobId
parameter_list|)
block|{
name|protocol
operator|.
name|cancel
argument_list|(
name|jobId
argument_list|)
expr_stmt|;
block|}
specifier|private
name|Future
argument_list|<
name|Void
argument_list|>
name|startDriver
parameter_list|(
specifier|final
name|RpcServer
name|rpcServer
parameter_list|,
specifier|final
name|String
name|clientId
parameter_list|,
specifier|final
name|String
name|secret
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|String
name|serverAddress
init|=
name|rpcServer
operator|.
name|getAddress
argument_list|()
decl_stmt|;
specifier|final
name|String
name|serverPort
init|=
name|String
operator|.
name|valueOf
argument_list|(
name|rpcServer
operator|.
name|getPort
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|sparkHome
init|=
name|getSparkHome
argument_list|()
decl_stmt|;
name|String
name|sparkLogDir
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"hive.spark.log.dir"
argument_list|)
decl_stmt|;
if|if
condition|(
name|sparkLogDir
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|sparkHome
operator|==
literal|null
condition|)
block|{
name|sparkLogDir
operator|=
literal|"./target/"
expr_stmt|;
block|}
else|else
block|{
name|sparkLogDir
operator|=
name|sparkHome
operator|+
literal|"/logs/"
expr_stmt|;
block|}
block|}
name|String
name|osxTestOpts
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|Strings
operator|.
name|nullToEmpty
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"os.name"
argument_list|)
argument_list|)
operator|.
name|toLowerCase
argument_list|()
operator|.
name|contains
argument_list|(
literal|"mac"
argument_list|)
condition|)
block|{
name|osxTestOpts
operator|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
name|System
operator|.
name|getenv
argument_list|(
name|OSX_TEST_OPTS
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|driverJavaOpts
init|=
name|Joiner
operator|.
name|on
argument_list|(
literal|" "
argument_list|)
operator|.
name|skipNulls
argument_list|()
operator|.
name|join
argument_list|(
literal|"-Dhive.spark.log.dir="
operator|+
name|sparkLogDir
argument_list|,
name|osxTestOpts
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|DRIVER_OPTS_KEY
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|executorJavaOpts
init|=
name|Joiner
operator|.
name|on
argument_list|(
literal|" "
argument_list|)
operator|.
name|skipNulls
argument_list|()
operator|.
name|join
argument_list|(
literal|"-Dhive.spark.log.dir="
operator|+
name|sparkLogDir
argument_list|,
name|osxTestOpts
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|EXECUTOR_OPTS_KEY
argument_list|)
argument_list|)
decl_stmt|;
comment|// Create a file with all the job properties to be read by spark-submit. Change the
comment|// file's permissions so that only the owner can read it. This avoid having the
comment|// connection secret show up in the child process's command line.
name|File
name|properties
init|=
name|File
operator|.
name|createTempFile
argument_list|(
literal|"spark-submit."
argument_list|,
literal|".properties"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|properties
operator|.
name|setReadable
argument_list|(
literal|false
argument_list|)
operator|||
operator|!
name|properties
operator|.
name|setReadable
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot change permissions of job properties file."
argument_list|)
throw|;
block|}
name|properties
operator|.
name|deleteOnExit
argument_list|()
expr_stmt|;
name|Properties
name|allProps
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
comment|// first load the defaults from spark-defaults.conf if available
try|try
block|{
name|URL
name|sparkDefaultsUrl
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getContextClassLoader
argument_list|()
operator|.
name|getResource
argument_list|(
literal|"spark-defaults.conf"
argument_list|)
decl_stmt|;
if|if
condition|(
name|sparkDefaultsUrl
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading spark defaults configs from: "
operator|+
name|sparkDefaultsUrl
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|load
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|Resources
operator|.
name|toByteArray
argument_list|(
name|sparkDefaultsUrl
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Exception trying to load spark-defaults.conf: "
operator|+
name|e
decl_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// then load the SparkClientImpl config
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|conf
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|allProps
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|allProps
operator|.
name|put
argument_list|(
name|SparkClientFactory
operator|.
name|CONF_CLIENT_ID
argument_list|,
name|clientId
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|SparkClientFactory
operator|.
name|CONF_KEY_SECRET
argument_list|,
name|secret
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|DRIVER_OPTS_KEY
argument_list|,
name|driverJavaOpts
argument_list|)
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|EXECUTOR_OPTS_KEY
argument_list|,
name|executorJavaOpts
argument_list|)
expr_stmt|;
name|String
name|isTesting
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.testing"
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTesting
operator|!=
literal|null
operator|&&
name|isTesting
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
condition|)
block|{
name|String
name|hiveHadoopTestClasspath
init|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
name|System
operator|.
name|getenv
argument_list|(
literal|"HIVE_HADOOP_TEST_CLASSPATH"
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|hiveHadoopTestClasspath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
name|extraDriverClasspath
init|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
operator|(
name|String
operator|)
name|allProps
operator|.
name|get
argument_list|(
name|DRIVER_EXTRA_CLASSPATH
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|extraDriverClasspath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|allProps
operator|.
name|put
argument_list|(
name|DRIVER_EXTRA_CLASSPATH
argument_list|,
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|extraDriverClasspath
operator|=
name|extraDriverClasspath
operator|.
name|endsWith
argument_list|(
name|File
operator|.
name|pathSeparator
argument_list|)
condition|?
name|extraDriverClasspath
else|:
name|extraDriverClasspath
operator|+
name|File
operator|.
name|pathSeparator
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|DRIVER_EXTRA_CLASSPATH
argument_list|,
name|extraDriverClasspath
operator|+
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
name|String
name|extraExecutorClasspath
init|=
name|Strings
operator|.
name|nullToEmpty
argument_list|(
operator|(
name|String
operator|)
name|allProps
operator|.
name|get
argument_list|(
name|EXECUTOR_EXTRA_CLASSPATH
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|extraExecutorClasspath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|allProps
operator|.
name|put
argument_list|(
name|EXECUTOR_EXTRA_CLASSPATH
argument_list|,
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|extraExecutorClasspath
operator|=
name|extraExecutorClasspath
operator|.
name|endsWith
argument_list|(
name|File
operator|.
name|pathSeparator
argument_list|)
condition|?
name|extraExecutorClasspath
else|:
name|extraExecutorClasspath
operator|+
name|File
operator|.
name|pathSeparator
expr_stmt|;
name|allProps
operator|.
name|put
argument_list|(
name|EXECUTOR_EXTRA_CLASSPATH
argument_list|,
name|extraExecutorClasspath
operator|+
name|hiveHadoopTestClasspath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|Writer
name|writer
init|=
operator|new
name|OutputStreamWriter
argument_list|(
operator|new
name|FileOutputStream
argument_list|(
name|properties
argument_list|)
argument_list|,
name|Charsets
operator|.
name|UTF_8
argument_list|)
decl_stmt|;
try|try
block|{
name|allProps
operator|.
name|store
argument_list|(
name|writer
argument_list|,
literal|"Spark Context configuration"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// Define how to pass options to the child process. If launching in client (or local)
comment|// mode, the driver options need to be passed directly on the command line. Otherwise,
comment|// SparkSubmit will take care of that for us.
name|String
name|master
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.master"
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|master
operator|!=
literal|null
argument_list|,
literal|"spark.master is not defined."
argument_list|)
expr_stmt|;
name|String
name|deployMode
init|=
name|conf
operator|.
name|get
argument_list|(
name|SPARK_DEPLOY_MODE
argument_list|)
decl_stmt|;
if|if
condition|(
name|SparkClientUtilities
operator|.
name|isYarnClusterMode
argument_list|(
name|master
argument_list|,
name|deployMode
argument_list|)
condition|)
block|{
name|String
name|executorCores
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executor.cores"
argument_list|)
decl_stmt|;
if|if
condition|(
name|executorCores
operator|!=
literal|null
condition|)
block|{
name|addExecutorCores
argument_list|(
name|executorCores
argument_list|)
expr_stmt|;
block|}
name|String
name|executorMemory
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executor.memory"
argument_list|)
decl_stmt|;
if|if
condition|(
name|executorMemory
operator|!=
literal|null
condition|)
block|{
name|addExecutorMemory
argument_list|(
name|executorMemory
argument_list|)
expr_stmt|;
block|}
name|String
name|numOfExecutors
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.executor.instances"
argument_list|)
decl_stmt|;
if|if
condition|(
name|numOfExecutors
operator|!=
literal|null
condition|)
block|{
name|addNumExecutors
argument_list|(
name|numOfExecutors
argument_list|)
expr_stmt|;
block|}
block|}
comment|// The options --principal/--keypad do not work with --proxy-user in spark-submit.sh
comment|// (see HIVE-15485, SPARK-5493, SPARK-19143), so Hive could only support doAs or
comment|// delegation token renewal, but not both. Since doAs is a more common case, if both
comment|// are needed, we choose to favor doAs. So when doAs is enabled, we use kinit command,
comment|// otherwise, we pass the principal/keypad to spark to support the token renewal for
comment|// long-running application.
if|if
condition|(
literal|"kerberos"
operator|.
name|equals
argument_list|(
name|hiveConf
operator|.
name|get
argument_list|(
name|HADOOP_SECURITY_AUTHENTICATION
argument_list|)
argument_list|)
condition|)
block|{
name|String
name|principal
init|=
name|SecurityUtil
operator|.
name|getServerPrincipal
argument_list|(
name|hiveConf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_SERVER2_KERBEROS_PRINCIPAL
argument_list|)
argument_list|,
literal|"0.0.0.0"
argument_list|)
decl_stmt|;
name|String
name|keyTabFile
init|=
name|hiveConf
operator|.
name|getVar
argument_list|(
name|ConfVars
operator|.
name|HIVE_SERVER2_KERBEROS_KEYTAB
argument_list|)
decl_stmt|;
name|boolean
name|isDoAsEnabled
init|=
name|hiveConf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SERVER2_ENABLE_DOAS
argument_list|)
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|principal
argument_list|)
operator|&&
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|keyTabFile
argument_list|)
condition|)
block|{
name|addKeytabAndPrincipal
argument_list|(
name|isDoAsEnabled
argument_list|,
name|keyTabFile
argument_list|,
name|principal
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|hiveConf
operator|.
name|getBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SERVER2_ENABLE_DOAS
argument_list|)
condition|)
block|{
try|try
block|{
name|String
name|currentUser
init|=
name|Utils
operator|.
name|getUGI
argument_list|()
operator|.
name|getShortUserName
argument_list|()
decl_stmt|;
comment|// do not do impersonation in CLI mode
if|if
condition|(
operator|!
name|currentUser
operator|.
name|equals
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Attempting impersonation of "
operator|+
name|currentUser
argument_list|)
expr_stmt|;
name|addProxyUser
argument_list|(
name|currentUser
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Cannot obtain username: "
operator|+
name|e
decl_stmt|;
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|String
name|regStr
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"spark.kryo.registrator"
argument_list|)
decl_stmt|;
if|if
condition|(
name|HIVE_KRYO_REG_NAME
operator|.
name|equals
argument_list|(
name|regStr
argument_list|)
condition|)
block|{
name|addJars
argument_list|(
name|SparkClientUtilities
operator|.
name|findKryoRegistratorJar
argument_list|(
name|hiveConf
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|addPropertiesFile
argument_list|(
name|properties
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
name|addClass
argument_list|(
name|RemoteDriver
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|jar
init|=
literal|"spark-internal"
decl_stmt|;
if|if
condition|(
name|SparkContext
operator|.
name|jarOfClass
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
operator|.
name|isDefined
argument_list|()
condition|)
block|{
name|jar
operator|=
name|SparkContext
operator|.
name|jarOfClass
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
name|addExecutableJar
argument_list|(
name|jar
argument_list|)
expr_stmt|;
name|addAppArg
argument_list|(
name|RemoteDriver
operator|.
name|REMOTE_DRIVER_HOST_CONF
argument_list|)
expr_stmt|;
name|addAppArg
argument_list|(
name|serverAddress
argument_list|)
expr_stmt|;
name|addAppArg
argument_list|(
name|RemoteDriver
operator|.
name|REMOTE_DRIVER_PORT_CONF
argument_list|)
expr_stmt|;
name|addAppArg
argument_list|(
name|serverPort
argument_list|)
expr_stmt|;
comment|//hive.spark.* keys are passed down to the RemoteDriver via REMOTE_DRIVER_CONF
comment|// so that they are not used in sparkContext but only in remote driver,
comment|//as --properties-file contains the spark.* keys that are meant for SparkConf object.
for|for
control|(
name|String
name|hiveSparkConfKey
range|:
name|RpcConfiguration
operator|.
name|HIVE_SPARK_RSC_CONFIGS
control|)
block|{
name|String
name|value
init|=
name|RpcConfiguration
operator|.
name|getValue
argument_list|(
name|hiveConf
argument_list|,
name|hiveSparkConfKey
argument_list|)
decl_stmt|;
name|addAppArg
argument_list|(
name|RemoteDriver
operator|.
name|REMOTE_DRIVER_CONF
argument_list|)
expr_stmt|;
name|addAppArg
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"%s=%s"
argument_list|,
name|hiveSparkConfKey
argument_list|,
name|value
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|launchDriver
argument_list|(
name|isTesting
argument_list|,
name|rpcServer
argument_list|,
name|clientId
argument_list|)
return|;
block|}
specifier|protected
specifier|abstract
name|Future
argument_list|<
name|Void
argument_list|>
name|launchDriver
parameter_list|(
name|String
name|isTesting
parameter_list|,
name|RpcServer
name|rpcServer
parameter_list|,
name|String
name|clientId
parameter_list|)
throws|throws
name|IOException
function_decl|;
specifier|protected
specifier|abstract
name|String
name|getSparkHome
parameter_list|()
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addAppArg
parameter_list|(
name|String
name|arg
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addExecutableJar
parameter_list|(
name|String
name|jar
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addPropertiesFile
parameter_list|(
name|String
name|absolutePath
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addClass
parameter_list|(
name|String
name|name
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addJars
parameter_list|(
name|String
name|jars
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addProxyUser
parameter_list|(
name|String
name|proxyUser
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addKeytabAndPrincipal
parameter_list|(
name|boolean
name|isDoAsEnabled
parameter_list|,
name|String
name|keyTabFile
parameter_list|,
name|String
name|principal
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addNumExecutors
parameter_list|(
name|String
name|numOfExecutors
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addExecutorMemory
parameter_list|(
name|String
name|executorMemory
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|addExecutorCores
parameter_list|(
name|String
name|executorCores
parameter_list|)
function_decl|;
specifier|private
class|class
name|ClientProtocol
extends|extends
name|BaseProtocol
block|{
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|JobHandleImpl
argument_list|<
name|T
argument_list|>
name|submit
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|,
name|List
argument_list|<
name|JobHandle
operator|.
name|Listener
argument_list|<
name|T
argument_list|>
argument_list|>
name|listeners
parameter_list|)
block|{
specifier|final
name|String
name|jobId
init|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
specifier|final
name|Promise
argument_list|<
name|T
argument_list|>
name|promise
init|=
name|driverRpc
operator|.
name|createPromise
argument_list|()
decl_stmt|;
specifier|final
name|JobHandleImpl
argument_list|<
name|T
argument_list|>
name|handle
init|=
operator|new
name|JobHandleImpl
argument_list|<
name|T
argument_list|>
argument_list|(
name|AbstractSparkClient
operator|.
name|this
argument_list|,
name|promise
argument_list|,
name|jobId
argument_list|,
name|listeners
argument_list|)
decl_stmt|;
name|jobs
operator|.
name|put
argument_list|(
name|jobId
argument_list|,
name|handle
argument_list|)
expr_stmt|;
specifier|final
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|Void
argument_list|>
name|rpc
init|=
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|JobRequest
argument_list|(
name|jobId
argument_list|,
name|job
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Send JobRequest[{}]."
argument_list|,
name|jobId
argument_list|)
expr_stmt|;
comment|// Link the RPC and the promise so that events from one are propagated to the other as
comment|// needed.
name|rpc
operator|.
name|addListener
argument_list|(
operator|new
name|GenericFutureListener
argument_list|<
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|operationComplete
parameter_list|(
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|Void
argument_list|>
name|f
parameter_list|)
block|{
if|if
condition|(
name|f
operator|.
name|isSuccess
argument_list|()
condition|)
block|{
comment|// If the spark job finishes before this listener is called, the QUEUED status will not be set
name|handle
operator|.
name|changeState
argument_list|(
name|JobHandle
operator|.
name|State
operator|.
name|QUEUED
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|promise
operator|.
name|isDone
argument_list|()
condition|)
block|{
name|promise
operator|.
name|setFailure
argument_list|(
name|f
operator|.
name|cause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
name|promise
operator|.
name|addListener
argument_list|(
operator|new
name|GenericFutureListener
argument_list|<
name|Promise
argument_list|<
name|T
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|operationComplete
parameter_list|(
name|Promise
argument_list|<
name|T
argument_list|>
name|p
parameter_list|)
block|{
if|if
condition|(
name|jobId
operator|!=
literal|null
condition|)
block|{
name|jobs
operator|.
name|remove
argument_list|(
name|jobId
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|p
operator|.
name|isCancelled
argument_list|()
operator|&&
operator|!
name|rpc
operator|.
name|isDone
argument_list|()
condition|)
block|{
name|rpc
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|handle
return|;
block|}
parameter_list|<
name|T
extends|extends
name|Serializable
parameter_list|>
name|Future
argument_list|<
name|T
argument_list|>
name|run
parameter_list|(
name|Job
argument_list|<
name|T
argument_list|>
name|job
parameter_list|)
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|final
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|T
argument_list|>
name|rpc
init|=
operator|(
name|io
operator|.
name|netty
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
argument_list|<
name|T
argument_list|>
operator|)
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|SyncJobRequest
argument_list|(
name|job
argument_list|)
argument_list|,
name|Serializable
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
name|rpc
return|;
block|}
name|void
name|cancel
parameter_list|(
name|String
name|jobId
parameter_list|)
block|{
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|CancelJob
argument_list|(
name|jobId
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Future
argument_list|<
name|?
argument_list|>
name|endSession
parameter_list|()
block|{
return|return
name|driverRpc
operator|.
name|call
argument_list|(
operator|new
name|EndSession
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|Error
name|msg
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error reported from Remote Spark Driver: {}"
argument_list|,
name|msg
operator|.
name|cause
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobMetrics
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|get
argument_list|(
name|msg
operator|.
name|jobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|handle
operator|.
name|getMetrics
argument_list|()
operator|.
name|addMetrics
argument_list|(
name|msg
operator|.
name|sparkJobId
argument_list|,
name|msg
operator|.
name|stageId
argument_list|,
name|msg
operator|.
name|taskId
argument_list|,
name|msg
operator|.
name|metrics
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received metrics for unknown Spark job {}"
argument_list|,
name|msg
operator|.
name|sparkJobId
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobResult
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|remove
argument_list|(
name|msg
operator|.
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Received result for client job {}"
argument_list|,
name|msg
operator|.
name|id
argument_list|)
expr_stmt|;
name|handle
operator|.
name|setSparkCounters
argument_list|(
name|msg
operator|.
name|sparkCounters
argument_list|)
expr_stmt|;
name|Throwable
name|error
init|=
name|msg
operator|.
name|error
decl_stmt|;
if|if
condition|(
name|error
operator|==
literal|null
condition|)
block|{
name|handle
operator|.
name|setSuccess
argument_list|(
name|msg
operator|.
name|result
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|handle
operator|.
name|setFailure
argument_list|(
name|error
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received result for unknown client job {}"
argument_list|,
name|msg
operator|.
name|id
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobStarted
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|get
argument_list|(
name|msg
operator|.
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|handle
operator|.
name|changeState
argument_list|(
name|JobHandle
operator|.
name|State
operator|.
name|STARTED
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received event for unknown client job {}"
argument_list|,
name|msg
operator|.
name|id
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handle
parameter_list|(
name|ChannelHandlerContext
name|ctx
parameter_list|,
name|JobSubmitted
name|msg
parameter_list|)
block|{
name|JobHandleImpl
argument_list|<
name|?
argument_list|>
name|handle
init|=
name|jobs
operator|.
name|get
argument_list|(
name|msg
operator|.
name|clientJobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|handle
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Received Spark job ID: {} for client job {}"
argument_list|,
name|msg
operator|.
name|sparkJobId
argument_list|,
name|msg
operator|.
name|clientJobId
argument_list|)
expr_stmt|;
name|handle
operator|.
name|addSparkJobId
argument_list|(
name|msg
operator|.
name|sparkJobId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received Spark job ID: {} for unknown client job {}"
argument_list|,
name|msg
operator|.
name|sparkJobId
argument_list|,
name|msg
operator|.
name|clientJobId
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|protected
name|String
name|name
parameter_list|()
block|{
return|return
literal|"HiveServer2 to Remote Spark Driver Connection"
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|AddJarJob
implements|implements
name|Job
argument_list|<
name|Serializable
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|final
name|String
name|path
decl_stmt|;
name|AddJarJob
parameter_list|()
block|{
name|this
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|AddJarJob
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Serializable
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|addJar
argument_list|(
name|path
argument_list|)
expr_stmt|;
comment|// Following remote job may refer to classes in this jar, and the remote job would be executed
comment|// in a different thread, so we add this jar path to JobContext for further usage.
name|jc
operator|.
name|getAddedJars
argument_list|()
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|AddFileJob
implements|implements
name|Job
argument_list|<
name|Serializable
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|private
specifier|final
name|String
name|path
decl_stmt|;
name|AddFileJob
parameter_list|()
block|{
name|this
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|AddFileJob
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Serializable
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|addFile
argument_list|(
name|path
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetExecutorCountJob
implements|implements
name|Job
argument_list|<
name|Integer
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
annotation|@
name|Override
specifier|public
name|Integer
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
comment|// minus 1 here otherwise driver is also counted as an executor
name|int
name|count
init|=
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|sc
argument_list|()
operator|.
name|getExecutorMemoryStatus
argument_list|()
operator|.
name|size
argument_list|()
operator|-
literal|1
decl_stmt|;
return|return
name|Integer
operator|.
name|valueOf
argument_list|(
name|count
argument_list|)
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetDefaultParallelismJob
implements|implements
name|Job
argument_list|<
name|Integer
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
annotation|@
name|Override
specifier|public
name|Integer
name|call
parameter_list|(
name|JobContext
name|jc
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|jc
operator|.
name|sc
argument_list|()
operator|.
name|sc
argument_list|()
operator|.
name|defaultParallelism
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

