begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|metadata
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|hcatalog
operator|.
name|mapreduce
operator|.
name|HCatMapRedUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
operator|.
name|State
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|ErrorType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatFieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatSchemaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|har
operator|.
name|HarOutputCommitterPostProcessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Part of the FileOutput*Container classes  * See {@link FileOutputFormatContainer} for more information  * @deprecated Use/modify {@link org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer} instead  */
end_comment

begin_class
class|class
name|FileOutputCommitterContainer
extends|extends
name|OutputCommitterContainer
block|{
specifier|private
specifier|static
specifier|final
name|String
name|TEMP_DIR_NAME
init|=
literal|"_temporary"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|LOGS_DIR_NAME
init|=
literal|"_logs"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|FileOutputCommitterContainer
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|dynamicPartitioningUsed
decl_stmt|;
specifier|private
name|boolean
name|partitionsDiscovered
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|partitionsDiscoveredByPath
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|JobContext
argument_list|>
name|contextDiscoveredByPath
decl_stmt|;
specifier|private
specifier|final
name|HCatStorageHandler
name|cachedStorageHandler
decl_stmt|;
name|HarOutputCommitterPostProcessor
name|harProcessor
init|=
operator|new
name|HarOutputCommitterPostProcessor
argument_list|()
decl_stmt|;
specifier|private
name|String
name|ptnRootLocation
init|=
literal|null
decl_stmt|;
specifier|private
name|OutputJobInfo
name|jobInfo
init|=
literal|null
decl_stmt|;
comment|/**    * @param context current JobContext    * @param baseCommitter OutputCommitter to contain    * @throws IOException    */
specifier|public
name|FileOutputCommitterContainer
parameter_list|(
name|JobContext
name|context
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|OutputCommitter
name|baseCommitter
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|context
argument_list|,
name|baseCommitter
argument_list|)
expr_stmt|;
name|jobInfo
operator|=
name|HCatOutputFormat
operator|.
name|getJobInfo
argument_list|(
name|context
argument_list|)
expr_stmt|;
name|dynamicPartitioningUsed
operator|=
name|jobInfo
operator|.
name|isDynamicPartitioningUsed
argument_list|()
expr_stmt|;
name|this
operator|.
name|partitionsDiscovered
operator|=
operator|!
name|dynamicPartitioningUsed
expr_stmt|;
name|cachedStorageHandler
operator|=
name|HCatUtil
operator|.
name|getStorageHandler
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|jobInfo
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getStorerInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|abortTask
parameter_list|(
name|TaskAttemptContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
name|getBaseOutputCommitter
argument_list|()
operator|.
name|abortTask
argument_list|(
name|HCatMapRedUtil
operator|.
name|createTaskAttemptContext
argument_list|(
name|context
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|commitTask
parameter_list|(
name|TaskAttemptContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
comment|//See HCATALOG-499
name|FileOutputFormatContainer
operator|.
name|setWorkOutputPath
argument_list|(
name|context
argument_list|)
expr_stmt|;
name|getBaseOutputCommitter
argument_list|()
operator|.
name|commitTask
argument_list|(
name|HCatMapRedUtil
operator|.
name|createTaskAttemptContext
argument_list|(
name|context
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|needsTaskCommit
parameter_list|(
name|TaskAttemptContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
return|return
name|getBaseOutputCommitter
argument_list|()
operator|.
name|needsTaskCommit
argument_list|(
name|HCatMapRedUtil
operator|.
name|createTaskAttemptContext
argument_list|(
name|context
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// called explicitly through FileRecordWriterContainer.close() if dynamic - return false by default
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|setupJob
parameter_list|(
name|JobContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|getBaseOutputCommitter
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
name|getBaseOutputCommitter
argument_list|()
operator|.
name|setupJob
argument_list|(
name|HCatMapRedUtil
operator|.
name|createJobContext
argument_list|(
name|context
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// in dynamic usecase, called through FileRecordWriterContainer
block|}
annotation|@
name|Override
specifier|public
name|void
name|setupTask
parameter_list|(
name|TaskAttemptContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
name|getBaseOutputCommitter
argument_list|()
operator|.
name|setupTask
argument_list|(
name|HCatMapRedUtil
operator|.
name|createTaskAttemptContext
argument_list|(
name|context
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|abortJob
parameter_list|(
name|JobContext
name|jobContext
parameter_list|,
name|State
name|state
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
name|discoverPartitions
argument_list|(
name|jobContext
argument_list|)
expr_stmt|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobContext
name|mapRedJobContext
init|=
name|HCatMapRedUtil
operator|.
name|createJobContext
argument_list|(
name|jobContext
argument_list|)
decl_stmt|;
if|if
condition|(
name|getBaseOutputCommitter
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
name|getBaseOutputCommitter
argument_list|()
operator|.
name|abortJob
argument_list|(
name|mapRedJobContext
argument_list|,
name|state
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
for|for
control|(
name|JobContext
name|currContext
range|:
name|contextDiscoveredByPath
operator|.
name|values
argument_list|()
control|)
block|{
try|try
block|{
operator|new
name|JobConf
argument_list|(
name|currContext
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|getOutputCommitter
argument_list|()
operator|.
name|abortJob
argument_list|(
name|currContext
argument_list|,
name|state
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
name|Path
name|src
decl_stmt|;
name|OutputJobInfo
name|jobInfo
init|=
name|HCatOutputFormat
operator|.
name|getJobInfo
argument_list|(
name|jobContext
argument_list|)
decl_stmt|;
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
name|src
operator|=
operator|new
name|Path
argument_list|(
name|getPartitionRootLocation
argument_list|(
name|jobInfo
operator|.
name|getLocation
argument_list|()
argument_list|,
name|jobInfo
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getTable
argument_list|()
operator|.
name|getPartitionKeysSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|src
operator|=
operator|new
name|Path
argument_list|(
name|jobInfo
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|FileSystem
name|fs
init|=
name|src
operator|.
name|getFileSystem
argument_list|(
name|jobContext
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Job failed. Cleaning up temporary directory [{}]."
argument_list|,
name|src
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|cancelDelegationTokens
argument_list|(
name|jobContext
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
specifier|final
name|String
name|SUCCEEDED_FILE_NAME
init|=
literal|"_SUCCESS"
decl_stmt|;
specifier|static
specifier|final
name|String
name|SUCCESSFUL_JOB_OUTPUT_DIR_MARKER
init|=
literal|"mapreduce.fileoutputcommitter.marksuccessfuljobs"
decl_stmt|;
specifier|private
specifier|static
name|boolean
name|getOutputDirMarking
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getBoolean
argument_list|(
name|SUCCESSFUL_JOB_OUTPUT_DIR_MARKER
argument_list|,
literal|false
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|commitJob
parameter_list|(
name|JobContext
name|jobContext
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
name|discoverPartitions
argument_list|(
name|jobContext
argument_list|)
expr_stmt|;
comment|// Commit each partition so it gets moved out of the job work
comment|// dir
for|for
control|(
name|JobContext
name|context
range|:
name|contextDiscoveredByPath
operator|.
name|values
argument_list|()
control|)
block|{
operator|new
name|JobConf
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|getOutputCommitter
argument_list|()
operator|.
name|commitJob
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|getBaseOutputCommitter
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
name|getBaseOutputCommitter
argument_list|()
operator|.
name|commitJob
argument_list|(
name|HCatMapRedUtil
operator|.
name|createJobContext
argument_list|(
name|jobContext
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|registerPartitions
argument_list|(
name|jobContext
argument_list|)
expr_stmt|;
comment|// create _SUCCESS FILE if so requested.
name|OutputJobInfo
name|jobInfo
init|=
name|HCatOutputFormat
operator|.
name|getJobInfo
argument_list|(
name|jobContext
argument_list|)
decl_stmt|;
if|if
condition|(
name|getOutputDirMarking
argument_list|(
name|jobContext
operator|.
name|getConfiguration
argument_list|()
argument_list|)
condition|)
block|{
name|Path
name|outputPath
init|=
operator|new
name|Path
argument_list|(
name|jobInfo
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fileSys
init|=
name|outputPath
operator|.
name|getFileSystem
argument_list|(
name|jobContext
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
comment|// create a file in the folder to mark it
if|if
condition|(
name|fileSys
operator|.
name|exists
argument_list|(
name|outputPath
argument_list|)
condition|)
block|{
name|Path
name|filePath
init|=
operator|new
name|Path
argument_list|(
name|outputPath
argument_list|,
name|SUCCEEDED_FILE_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fileSys
operator|.
name|exists
argument_list|(
name|filePath
argument_list|)
condition|)
block|{
comment|// may have been
comment|// created by
comment|// baseCommitter.commitJob()
name|fileSys
operator|.
name|create
argument_list|(
name|filePath
argument_list|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
finally|finally
block|{
name|cancelDelegationTokens
argument_list|(
name|jobContext
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|cleanupJob
parameter_list|(
name|JobContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The method cleanupJob is deprecated and should not be called."
argument_list|)
throw|;
block|}
specifier|private
name|String
name|getPartitionRootLocation
parameter_list|(
name|String
name|ptnLocn
parameter_list|,
name|int
name|numPtnKeys
parameter_list|)
block|{
if|if
condition|(
name|ptnRootLocation
operator|==
literal|null
condition|)
block|{
comment|// we only need to calculate it once, it'll be the same for other partitions in this job.
name|Path
name|ptnRoot
init|=
operator|new
name|Path
argument_list|(
name|ptnLocn
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numPtnKeys
condition|;
name|i
operator|++
control|)
block|{
comment|//          LOG.info("Getting parent of "+ptnRoot.getName());
name|ptnRoot
operator|=
name|ptnRoot
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
name|ptnRootLocation
operator|=
name|ptnRoot
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
comment|//      LOG.info("Returning final parent : "+ptnRootLocation);
return|return
name|ptnRootLocation
return|;
block|}
comment|/**    * Generate partition metadata object to be used to add to metadata.    * @param context The job context.    * @param jobInfo The OutputJobInfo.    * @param partLocnRoot The table-equivalent location root of the partition    *                       (temporary dir if dynamic partition, table dir if static)    * @param partKVs The keyvalue pairs that form the partition    * @param outputSchema The output schema for the partition    * @param params The parameters to store inside the partition    * @param table The Table metadata object under which this Partition will reside    * @param fs FileSystem object to operate on the underlying filesystem    * @param grpName Group name that owns the table dir    * @param perms FsPermission that's the default permission of the table dir.    * @return Constructed Partition metadata object    * @throws java.io.IOException    */
specifier|private
name|Partition
name|constructPartition
parameter_list|(
name|JobContext
name|context
parameter_list|,
name|OutputJobInfo
name|jobInfo
parameter_list|,
name|String
name|partLocnRoot
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partKVs
parameter_list|,
name|HCatSchema
name|outputSchema
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|,
name|Table
name|table
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|String
name|grpName
parameter_list|,
name|FsPermission
name|perms
parameter_list|)
throws|throws
name|IOException
block|{
name|Partition
name|partition
init|=
operator|new
name|Partition
argument_list|()
decl_stmt|;
name|partition
operator|.
name|setDbName
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|)
expr_stmt|;
name|partition
operator|.
name|setTableName
argument_list|(
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|partition
operator|.
name|setSd
argument_list|(
operator|new
name|StorageDescriptor
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fields
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HCatFieldSchema
name|fieldSchema
range|:
name|outputSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|fields
operator|.
name|add
argument_list|(
name|HCatSchemaUtils
operator|.
name|getFieldSchema
argument_list|(
name|fieldSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|partition
operator|.
name|getSd
argument_list|()
operator|.
name|setCols
argument_list|(
name|fields
argument_list|)
expr_stmt|;
name|partition
operator|.
name|setValues
argument_list|(
name|FileOutputFormatContainer
operator|.
name|getPartitionValueList
argument_list|(
name|table
argument_list|,
name|partKVs
argument_list|)
argument_list|)
expr_stmt|;
name|partition
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
comment|// Sets permissions and group name on partition dirs and files.
name|Path
name|partPath
decl_stmt|;
if|if
condition|(
name|Boolean
operator|.
name|valueOf
argument_list|(
operator|(
name|String
operator|)
name|table
operator|.
name|getProperty
argument_list|(
literal|"EXTERNAL"
argument_list|)
argument_list|)
operator|&&
name|jobInfo
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
operator|&&
name|jobInfo
operator|.
name|getLocation
argument_list|()
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// honor external table that specifies the location
name|partPath
operator|=
operator|new
name|Path
argument_list|(
name|jobInfo
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partPath
operator|=
operator|new
name|Path
argument_list|(
name|partLocnRoot
argument_list|)
expr_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|FieldSchema
name|partKey
range|:
name|table
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
if|if
condition|(
name|i
operator|++
operator|!=
literal|0
condition|)
block|{
name|applyGroupAndPerms
argument_list|(
name|fs
argument_list|,
name|partPath
argument_list|,
name|perms
argument_list|,
name|grpName
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|partPath
operator|=
name|constructPartialPartPath
argument_list|(
name|partPath
argument_list|,
name|partKey
operator|.
name|getName
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|partKVs
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Apply the group and permissions to the leaf partition and files.
comment|// Need not bother in case of HDFS as permission is taken care of by setting UMask
if|if
condition|(
operator|!
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getHCatShim
argument_list|()
operator|.
name|isFileInHDFS
argument_list|(
name|fs
argument_list|,
name|partPath
argument_list|)
condition|)
block|{
name|applyGroupAndPerms
argument_list|(
name|fs
argument_list|,
name|partPath
argument_list|,
name|perms
argument_list|,
name|grpName
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Set the location in the StorageDescriptor
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
name|String
name|dynamicPartitionDestination
init|=
name|getFinalDynamicPartitionDestination
argument_list|(
name|table
argument_list|,
name|partKVs
argument_list|)
decl_stmt|;
if|if
condition|(
name|harProcessor
operator|.
name|isEnabled
argument_list|()
condition|)
block|{
name|harProcessor
operator|.
name|exec
argument_list|(
name|context
argument_list|,
name|partition
argument_list|,
name|partPath
argument_list|)
expr_stmt|;
name|partition
operator|.
name|getSd
argument_list|()
operator|.
name|setLocation
argument_list|(
name|harProcessor
operator|.
name|getProcessedLocation
argument_list|(
operator|new
name|Path
argument_list|(
name|dynamicPartitionDestination
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partition
operator|.
name|getSd
argument_list|()
operator|.
name|setLocation
argument_list|(
name|dynamicPartitionDestination
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|partition
operator|.
name|getSd
argument_list|()
operator|.
name|setLocation
argument_list|(
name|partPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|partition
return|;
block|}
specifier|private
name|void
name|applyGroupAndPerms
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|String
name|group
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
name|fs
operator|.
name|setPermission
argument_list|(
name|dir
argument_list|,
name|permission
argument_list|)
expr_stmt|;
if|if
condition|(
name|recursive
condition|)
block|{
for|for
control|(
name|FileStatus
name|fileStatus
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|dir
argument_list|)
control|)
block|{
if|if
condition|(
name|fileStatus
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|applyGroupAndPerms
argument_list|(
name|fs
argument_list|,
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|permission
argument_list|,
name|group
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|fs
operator|.
name|setPermission
argument_list|(
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|permission
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|String
name|getFinalDynamicPartitionDestination
parameter_list|(
name|Table
name|table
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partKVs
parameter_list|)
block|{
comment|// file:///tmp/hcat_junit_warehouse/employee/_DYN0.7770480401313761/emp_country=IN/emp_state=KA  ->
comment|// file:///tmp/hcat_junit_warehouse/employee/emp_country=IN/emp_state=KA
name|Path
name|partPath
init|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|partKey
range|:
name|table
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
name|partPath
operator|=
name|constructPartialPartPath
argument_list|(
name|partPath
argument_list|,
name|partKey
operator|.
name|getName
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|partKVs
argument_list|)
expr_stmt|;
block|}
return|return
name|partPath
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getStorerParameterMap
parameter_list|(
name|StorerInfo
name|storer
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
comment|//Copy table level hcat.* keys to the partition
for|for
control|(
name|Entry
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
name|entry
range|:
name|storer
operator|.
name|getProperties
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|params
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|params
return|;
block|}
specifier|private
name|Path
name|constructPartialPartPath
parameter_list|(
name|Path
name|partialPath
parameter_list|,
name|String
name|partKey
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partKVs
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
name|FileUtils
operator|.
name|escapePathName
argument_list|(
name|partKey
argument_list|)
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"="
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|FileUtils
operator|.
name|escapePathName
argument_list|(
name|partKVs
operator|.
name|get
argument_list|(
name|partKey
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|new
name|Path
argument_list|(
name|partialPath
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Update table schema, adding new columns as added for the partition.    * @param client the client    * @param table the table    * @param partitionSchema the schema of the partition    * @throws java.io.IOException Signals that an I/O exception has occurred.    * @throws org.apache.hadoop.hive.metastore.api.InvalidOperationException the invalid operation exception    * @throws org.apache.hadoop.hive.metastore.api.MetaException the meta exception    * @throws org.apache.thrift.TException the t exception    */
specifier|private
name|void
name|updateTableSchema
parameter_list|(
name|HiveMetaStoreClient
name|client
parameter_list|,
name|Table
name|table
parameter_list|,
name|HCatSchema
name|partitionSchema
parameter_list|)
throws|throws
name|IOException
throws|,
name|InvalidOperationException
throws|,
name|MetaException
throws|,
name|TException
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newColumns
init|=
name|HCatUtil
operator|.
name|validatePartitionSchema
argument_list|(
name|table
argument_list|,
name|partitionSchema
argument_list|)
decl_stmt|;
if|if
condition|(
name|newColumns
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|tableColumns
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
argument_list|)
decl_stmt|;
name|tableColumns
operator|.
name|addAll
argument_list|(
name|newColumns
argument_list|)
expr_stmt|;
comment|//Update table schema to add the newly added columns
name|table
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|setCols
argument_list|(
name|tableColumns
argument_list|)
expr_stmt|;
name|client
operator|.
name|alter_table
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getTTable
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Move all of the files from the temp directory to the final location    * @param fs the output file system    * @param file the file to move    * @param srcDir the source directory    * @param destDir the target directory    * @param dryRun - a flag that simply tests if this move would succeed or not based    *                 on whether other files exist where we're trying to copy    * @throws java.io.IOException    */
specifier|private
name|void
name|moveTaskOutputs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|file
parameter_list|,
name|Path
name|srcDir
parameter_list|,
name|Path
name|destDir
parameter_list|,
specifier|final
name|boolean
name|dryRun
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|file
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|TEMP_DIR_NAME
argument_list|)
operator|||
name|file
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|LOGS_DIR_NAME
argument_list|)
operator|||
name|file
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|SUCCEEDED_FILE_NAME
argument_list|)
condition|)
block|{
return|return;
block|}
specifier|final
name|Path
name|finalOutputPath
init|=
name|getFinalPath
argument_list|(
name|file
argument_list|,
name|srcDir
argument_list|,
name|destDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|isFile
argument_list|(
name|file
argument_list|)
condition|)
block|{
if|if
condition|(
name|dryRun
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Testing if moving file: ["
operator|+
name|file
operator|+
literal|"] to ["
operator|+
name|finalOutputPath
operator|+
literal|"] would cause a problem"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|finalOutputPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
literal|"Data already exists in "
operator|+
name|finalOutputPath
operator|+
literal|", duplicate publish not possible."
argument_list|)
throw|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moving file: [ "
operator|+
name|file
operator|+
literal|"] to ["
operator|+
name|finalOutputPath
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
comment|// Make sure the parent directory exists.  It is not an error
comment|// to recreate an existing directory
name|fs
operator|.
name|mkdirs
argument_list|(
name|finalOutputPath
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|file
argument_list|,
name|finalOutputPath
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|finalOutputPath
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
literal|"Failed to delete existing path "
operator|+
name|finalOutputPath
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|file
argument_list|,
name|finalOutputPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
literal|"Failed to move output to "
operator|+
name|finalOutputPath
argument_list|)
throw|;
block|}
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|fs
operator|.
name|getFileStatus
argument_list|(
name|file
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|FileStatus
index|[]
name|children
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|file
argument_list|)
decl_stmt|;
name|FileStatus
name|firstChild
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
name|int
name|index
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|index
operator|<
name|children
operator|.
name|length
condition|)
block|{
if|if
condition|(
operator|!
name|children
index|[
name|index
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|TEMP_DIR_NAME
argument_list|)
operator|&&
operator|!
name|children
index|[
name|index
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|LOGS_DIR_NAME
argument_list|)
operator|&&
operator|!
name|children
index|[
name|index
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|SUCCEEDED_FILE_NAME
argument_list|)
condition|)
block|{
name|firstChild
operator|=
name|children
index|[
name|index
index|]
expr_stmt|;
break|break;
block|}
name|index
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|firstChild
operator|!=
literal|null
operator|&&
name|firstChild
operator|.
name|isDir
argument_list|()
condition|)
block|{
comment|// If the first child is directory, then rest would be directory too according to HCatalog dir structure
comment|// recurse in that case
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|child
operator|.
name|getPath
argument_list|()
argument_list|,
name|srcDir
argument_list|,
name|destDir
argument_list|,
name|dryRun
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|dryRun
condition|)
block|{
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
comment|// Optimization: if the first child is file, we have reached the leaf directory, move the parent directory itself
comment|// instead of moving each file under the directory. See HCATALOG-538
specifier|final
name|Path
name|parentDir
init|=
name|finalOutputPath
operator|.
name|getParent
argument_list|()
decl_stmt|;
comment|// Create the directory
name|Path
name|placeholder
init|=
operator|new
name|Path
argument_list|(
name|parentDir
argument_list|,
literal|"_placeholder"
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|mkdirs
argument_list|(
name|parentDir
argument_list|)
condition|)
block|{
comment|// It is weired but we need a placeholder,
comment|// otherwise rename cannot move file to the right place
name|fs
operator|.
name|create
argument_list|(
name|placeholder
argument_list|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moving directory: "
operator|+
name|file
operator|+
literal|" to "
operator|+
name|parentDir
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|file
argument_list|,
name|parentDir
argument_list|)
condition|)
block|{
specifier|final
name|String
name|msg
init|=
literal|"Failed to move file: "
operator|+
name|file
operator|+
literal|" to "
operator|+
name|parentDir
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
name|msg
argument_list|)
throw|;
block|}
name|fs
operator|.
name|delete
argument_list|(
name|placeholder
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// In case of no partition we have to move each file
for|for
control|(
name|FileStatus
name|child
range|:
name|children
control|)
block|{
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|child
operator|.
name|getPath
argument_list|()
argument_list|,
name|srcDir
argument_list|,
name|destDir
argument_list|,
name|dryRun
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|finalOutputPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
literal|"Data already exists in "
operator|+
name|finalOutputPath
operator|+
literal|", duplicate publish not possible."
argument_list|)
throw|;
block|}
block|}
block|}
block|}
else|else
block|{
comment|// Should never happen
specifier|final
name|String
name|msg
init|=
literal|"Unknown file type being asked to be moved, erroring out"
decl_stmt|;
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
name|msg
argument_list|)
throw|;
block|}
block|}
comment|/**    * Find the final name of a given output file, given the output directory    * and the work directory.    * @param file the file to move    * @param src the source directory    * @param dest the target directory    * @return the final path for the specific output file    * @throws java.io.IOException    */
specifier|private
name|Path
name|getFinalPath
parameter_list|(
name|Path
name|file
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dest
parameter_list|)
throws|throws
name|IOException
block|{
name|URI
name|taskOutputUri
init|=
name|file
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|URI
name|relativePath
init|=
name|src
operator|.
name|toUri
argument_list|()
operator|.
name|relativize
argument_list|(
name|taskOutputUri
argument_list|)
decl_stmt|;
if|if
condition|(
name|taskOutputUri
operator|==
name|relativePath
condition|)
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_MOVE_FAILED
argument_list|,
literal|"Can not get the relative path: base = "
operator|+
name|src
operator|+
literal|" child = "
operator|+
name|file
argument_list|)
throw|;
block|}
if|if
condition|(
name|relativePath
operator|.
name|getPath
argument_list|()
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dest
argument_list|,
name|relativePath
operator|.
name|getPath
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|dest
return|;
block|}
block|}
comment|/**    * Run to discover dynamic partitions available    */
specifier|private
name|void
name|discoverPartitions
parameter_list|(
name|JobContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|partitionsDiscovered
condition|)
block|{
comment|//      LOG.info("discover ptns called");
name|OutputJobInfo
name|jobInfo
init|=
name|HCatOutputFormat
operator|.
name|getJobInfo
argument_list|(
name|context
argument_list|)
decl_stmt|;
name|harProcessor
operator|.
name|setEnabled
argument_list|(
name|jobInfo
operator|.
name|getHarRequested
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|dynamicPartCols
init|=
name|jobInfo
operator|.
name|getPosOfDynPartCols
argument_list|()
decl_stmt|;
name|int
name|maxDynamicPartitions
init|=
name|jobInfo
operator|.
name|getMaxDynamicPartitions
argument_list|()
decl_stmt|;
name|Path
name|loadPath
init|=
operator|new
name|Path
argument_list|(
name|jobInfo
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|loadPath
operator|.
name|getFileSystem
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
comment|// construct a path pattern (e.g., /*/*) to find all dynamically generated paths
name|String
name|dynPathSpec
init|=
name|loadPath
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|dynPathSpec
operator|=
name|dynPathSpec
operator|.
name|replaceAll
argument_list|(
literal|"__HIVE_DEFAULT_PARTITION__"
argument_list|,
literal|"*"
argument_list|)
expr_stmt|;
comment|//      LOG.info("Searching for "+dynPathSpec);
name|Path
name|pathPattern
init|=
operator|new
name|Path
argument_list|(
name|dynPathSpec
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|status
init|=
name|fs
operator|.
name|globStatus
argument_list|(
name|pathPattern
argument_list|)
decl_stmt|;
name|partitionsDiscoveredByPath
operator|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
name|contextDiscoveredByPath
operator|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|JobContext
argument_list|>
argument_list|()
expr_stmt|;
if|if
condition|(
name|status
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|//        LOG.warn("No partition found genereated by dynamic partitioning in ["
comment|//            +loadPath+"] with depth["+jobInfo.getTable().getPartitionKeysSize()
comment|//            +"], dynSpec["+dynPathSpec+"]");
block|}
else|else
block|{
if|if
condition|(
operator|(
name|maxDynamicPartitions
operator|!=
operator|-
literal|1
operator|)
operator|&&
operator|(
name|status
operator|.
name|length
operator|>
name|maxDynamicPartitions
operator|)
condition|)
block|{
name|this
operator|.
name|partitionsDiscovered
operator|=
literal|true
expr_stmt|;
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_TOO_MANY_DYNAMIC_PTNS
argument_list|,
literal|"Number of dynamic partitions being created "
operator|+
literal|"exceeds configured max allowable partitions["
operator|+
name|maxDynamicPartitions
operator|+
literal|"], increase parameter ["
operator|+
name|HiveConf
operator|.
name|ConfVars
operator|.
name|DYNAMICPARTITIONMAXPARTS
operator|.
name|varname
operator|+
literal|"] if needed."
argument_list|)
throw|;
block|}
for|for
control|(
name|FileStatus
name|st
range|:
name|status
control|)
block|{
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|fullPartSpec
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|Warehouse
operator|.
name|makeSpecFromName
argument_list|(
name|fullPartSpec
argument_list|,
name|st
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|partitionsDiscoveredByPath
operator|.
name|put
argument_list|(
name|st
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|fullPartSpec
argument_list|)
expr_stmt|;
name|JobConf
name|jobConf
init|=
operator|(
name|JobConf
operator|)
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|JobContext
name|currContext
init|=
name|HCatMapRedUtil
operator|.
name|createJobContext
argument_list|(
name|jobConf
argument_list|,
name|context
operator|.
name|getJobID
argument_list|()
argument_list|,
name|InternalUtil
operator|.
name|createReporter
argument_list|(
name|HCatMapRedUtil
operator|.
name|createTaskAttemptContext
argument_list|(
name|jobConf
argument_list|,
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getHCatShim
argument_list|()
operator|.
name|createTaskAttemptID
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|HCatOutputFormat
operator|.
name|configureOutputStorageHandler
argument_list|(
name|currContext
argument_list|,
name|jobInfo
argument_list|,
name|fullPartSpec
argument_list|)
expr_stmt|;
name|contextDiscoveredByPath
operator|.
name|put
argument_list|(
name|st
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|currContext
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|partitionsDiscovered
operator|=
literal|true
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|registerPartitions
parameter_list|(
name|JobContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|dynamicPartitioningUsed
condition|)
block|{
name|discoverPartitions
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
name|OutputJobInfo
name|jobInfo
init|=
name|HCatOutputFormat
operator|.
name|getJobInfo
argument_list|(
name|context
argument_list|)
decl_stmt|;
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|Table
name|table
init|=
operator|new
name|Table
argument_list|(
name|jobInfo
operator|.
name|getTableInfo
argument_list|()
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|tblPath
init|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|tblPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|//Move data from temp directory the actual table directory
comment|//No metastore operation required.
name|Path
name|src
init|=
operator|new
name|Path
argument_list|(
name|jobInfo
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|src
argument_list|,
name|src
argument_list|,
name|tblPath
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
name|HiveMetaStoreClient
name|client
init|=
literal|null
decl_stmt|;
name|HCatTableInfo
name|tableInfo
init|=
name|jobInfo
operator|.
name|getTableInfo
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitionsAdded
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
name|HiveConf
name|hiveConf
init|=
name|HCatUtil
operator|.
name|getHiveConf
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|client
operator|=
name|HCatUtil
operator|.
name|getHiveClient
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
name|StorerInfo
name|storer
init|=
name|InternalUtil
operator|.
name|extractStorerInfo
argument_list|(
name|table
operator|.
name|getTTable
argument_list|()
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
name|FileStatus
name|tblStat
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|tblPath
argument_list|)
decl_stmt|;
name|String
name|grpName
init|=
name|tblStat
operator|.
name|getGroup
argument_list|()
decl_stmt|;
name|FsPermission
name|perms
init|=
name|tblStat
operator|.
name|getPermission
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|partitionsToAdd
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|dynamicPartitioningUsed
condition|)
block|{
name|partitionsToAdd
operator|.
name|add
argument_list|(
name|constructPartition
argument_list|(
name|context
argument_list|,
name|jobInfo
argument_list|,
name|tblPath
operator|.
name|toString
argument_list|()
argument_list|,
name|jobInfo
operator|.
name|getPartitionValues
argument_list|()
argument_list|,
name|jobInfo
operator|.
name|getOutputSchema
argument_list|()
argument_list|,
name|getStorerParameterMap
argument_list|(
name|storer
argument_list|)
argument_list|,
name|table
argument_list|,
name|fs
argument_list|,
name|grpName
argument_list|,
name|perms
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|entry
range|:
name|partitionsDiscoveredByPath
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|partitionsToAdd
operator|.
name|add
argument_list|(
name|constructPartition
argument_list|(
name|context
argument_list|,
name|jobInfo
argument_list|,
name|getPartitionRootLocation
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|jobInfo
operator|.
name|getOutputSchema
argument_list|()
argument_list|,
name|getStorerParameterMap
argument_list|(
name|storer
argument_list|)
argument_list|,
name|table
argument_list|,
name|fs
argument_list|,
name|grpName
argument_list|,
name|perms
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|ArrayList
argument_list|<
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|ptnInfos
init|=
operator|new
name|ArrayList
argument_list|<
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Partition
name|ptn
range|:
name|partitionsToAdd
control|)
block|{
name|ptnInfos
operator|.
name|add
argument_list|(
name|InternalUtil
operator|.
name|createPtnKeyValueMap
argument_list|(
operator|new
name|Table
argument_list|(
name|tableInfo
operator|.
name|getTable
argument_list|()
argument_list|)
argument_list|,
name|ptn
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//Publish the new partition(s)
if|if
condition|(
name|dynamicPartitioningUsed
operator|&&
name|harProcessor
operator|.
name|isEnabled
argument_list|()
operator|&&
operator|(
operator|!
name|partitionsToAdd
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
name|Path
name|src
init|=
operator|new
name|Path
argument_list|(
name|ptnRootLocation
argument_list|)
decl_stmt|;
comment|// check here for each dir we're copying out, to see if it
comment|// already exists, error out if so
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|src
argument_list|,
name|src
argument_list|,
name|tblPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|src
argument_list|,
name|src
argument_list|,
name|tblPath
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|true
argument_list|)
expr_stmt|;
try|try
block|{
name|updateTableSchema
argument_list|(
name|client
argument_list|,
name|table
argument_list|,
name|jobInfo
operator|.
name|getOutputSchema
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"HAR is being used. The table {} has new partitions {}."
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|ptnInfos
argument_list|)
expr_stmt|;
name|client
operator|.
name|add_partitions
argument_list|(
name|partitionsToAdd
argument_list|)
expr_stmt|;
name|partitionsAdded
operator|=
name|partitionsToAdd
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// There was an error adding partitions : rollback fs copy and rethrow
for|for
control|(
name|Partition
name|p
range|:
name|partitionsToAdd
control|)
block|{
name|Path
name|ptnPath
init|=
operator|new
name|Path
argument_list|(
name|harProcessor
operator|.
name|getParentFSPath
argument_list|(
operator|new
name|Path
argument_list|(
name|p
operator|.
name|getSd
argument_list|()
operator|.
name|getLocation
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|ptnPath
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|ptnPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
block|}
else|else
block|{
comment|// no harProcessor, regular operation
name|updateTableSchema
argument_list|(
name|client
argument_list|,
name|table
argument_list|,
name|jobInfo
operator|.
name|getOutputSchema
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"HAR not is not being used. The table {} has new partitions {}."
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|ptnInfos
argument_list|)
expr_stmt|;
if|if
condition|(
name|dynamicPartitioningUsed
operator|&&
operator|(
name|partitionsToAdd
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
condition|)
block|{
name|Path
name|src
init|=
operator|new
name|Path
argument_list|(
name|ptnRootLocation
argument_list|)
decl_stmt|;
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|src
argument_list|,
name|src
argument_list|,
name|tblPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|moveTaskOutputs
argument_list|(
name|fs
argument_list|,
name|src
argument_list|,
name|src
argument_list|,
name|tblPath
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|client
operator|.
name|add_partitions
argument_list|(
name|partitionsToAdd
argument_list|)
expr_stmt|;
name|partitionsAdded
operator|=
name|partitionsToAdd
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|partitionsAdded
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
comment|// baseCommitter.cleanupJob failed, try to clean up the
comment|// metastore
for|for
control|(
name|Partition
name|p
range|:
name|partitionsAdded
control|)
block|{
name|client
operator|.
name|dropPartition
argument_list|(
name|tableInfo
operator|.
name|getDatabaseName
argument_list|()
argument_list|,
name|tableInfo
operator|.
name|getTableName
argument_list|()
argument_list|,
name|p
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|te
parameter_list|)
block|{
comment|// Keep cause as the original exception
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_PUBLISHING_PARTITION
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|e
operator|instanceof
name|HCatException
condition|)
block|{
throw|throw
operator|(
name|HCatException
operator|)
name|e
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_PUBLISHING_PARTITION
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
name|HCatUtil
operator|.
name|closeHiveClientQuietly
argument_list|(
name|client
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|cancelDelegationTokens
parameter_list|(
name|JobContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Cancelling deletgation token for the job."
argument_list|)
expr_stmt|;
name|HiveMetaStoreClient
name|client
init|=
literal|null
decl_stmt|;
try|try
block|{
name|HiveConf
name|hiveConf
init|=
name|HCatUtil
operator|.
name|getHiveConf
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|client
operator|=
name|HCatUtil
operator|.
name|getHiveClient
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
comment|// cancel the deleg. tokens that were acquired for this job now that
comment|// we are done - we should cancel if the tokens were acquired by
comment|// HCatOutputFormat and not if they were supplied by Oozie.
comment|// In the latter case the HCAT_KEY_TOKEN_SIGNATURE property in
comment|// the conf will not be set
name|String
name|tokenStrForm
init|=
name|client
operator|.
name|getTokenStrForm
argument_list|()
decl_stmt|;
if|if
condition|(
name|tokenStrForm
operator|!=
literal|null
operator|&&
name|context
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|HCatConstants
operator|.
name|HCAT_KEY_TOKEN_SIGNATURE
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|client
operator|.
name|cancelDelegationToken
argument_list|(
name|tokenStrForm
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"MetaException while cancelling delegation token."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"TException while cancelling delegation token."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|HCatUtil
operator|.
name|closeHiveClientQuietly
argument_list|(
name|client
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

