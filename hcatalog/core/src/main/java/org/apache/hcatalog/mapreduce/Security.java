begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Method
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|thrift
operator|.
name|DelegationTokenSelector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|Credentials
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenSelector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * @deprecated Use/modify {@link org.apache.hive.hcatalog.mapreduce.Security} instead  */
end_comment

begin_class
specifier|final
class|class
name|Security
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HCatOutputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// making sure this is not initialized unless needed
specifier|private
specifier|static
specifier|final
class|class
name|LazyHolder
block|{
specifier|public
specifier|static
specifier|final
name|Security
name|INSTANCE
init|=
operator|new
name|Security
argument_list|()
decl_stmt|;
block|}
specifier|public
specifier|static
name|Security
name|getInstance
parameter_list|()
block|{
return|return
name|LazyHolder
operator|.
name|INSTANCE
return|;
block|}
name|boolean
name|isSecurityEnabled
parameter_list|()
block|{
try|try
block|{
name|Method
name|m
init|=
name|UserGroupInformation
operator|.
name|class
operator|.
name|getMethod
argument_list|(
literal|"isSecurityEnabled"
argument_list|)
decl_stmt|;
return|return
operator|(
name|Boolean
operator|)
name|m
operator|.
name|invoke
argument_list|(
literal|null
argument_list|,
operator|(
name|Object
index|[]
operator|)
literal|null
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NoSuchMethodException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Security is not supported by this version of hadoop."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvocationTargetException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Failed to call isSecurityEnabled()"
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IllegalAccessException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Failed to call isSecurityEnabled()"
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
return|return
literal|false
return|;
block|}
comment|// a signature string to associate with a HCatTableInfo - essentially
comment|// a concatenation of dbname, tablename and partition keyvalues.
name|String
name|getTokenSignature
parameter_list|(
name|OutputJobInfo
name|outputJobInfo
parameter_list|)
block|{
name|StringBuilder
name|result
init|=
operator|new
name|StringBuilder
argument_list|(
literal|""
argument_list|)
decl_stmt|;
name|String
name|dbName
init|=
name|outputJobInfo
operator|.
name|getDatabaseName
argument_list|()
decl_stmt|;
if|if
condition|(
name|dbName
operator|!=
literal|null
condition|)
block|{
name|result
operator|.
name|append
argument_list|(
name|dbName
argument_list|)
expr_stmt|;
block|}
name|String
name|tableName
init|=
name|outputJobInfo
operator|.
name|getTableName
argument_list|()
decl_stmt|;
if|if
condition|(
name|tableName
operator|!=
literal|null
condition|)
block|{
name|result
operator|.
name|append
argument_list|(
literal|"."
operator|+
name|tableName
argument_list|)
expr_stmt|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partValues
init|=
name|outputJobInfo
operator|.
name|getPartitionValues
argument_list|()
decl_stmt|;
if|if
condition|(
name|partValues
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|entry
range|:
name|partValues
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|result
operator|.
name|append
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|"="
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
operator|.
name|toString
argument_list|()
return|;
block|}
name|void
name|handleSecurity
parameter_list|(
name|Credentials
name|credentials
parameter_list|,
name|OutputJobInfo
name|outputJobInfo
parameter_list|,
name|HiveMetaStoreClient
name|client
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|harRequested
parameter_list|)
throws|throws
name|IOException
throws|,
name|MetaException
throws|,
name|TException
throws|,
name|Exception
block|{
if|if
condition|(
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
name|UserGroupInformation
name|ugi
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
decl_stmt|;
comment|// check if oozie has set up a hcat deleg. token - if so use it
name|TokenSelector
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|hiveTokenSelector
init|=
operator|new
name|DelegationTokenSelector
argument_list|()
decl_stmt|;
comment|//Oozie does not change the service field of the token
comment|//hence by default token generation will have a value of "new Text("")"
comment|//HiveClient will look for a use TokenSelector.selectToken() with service
comment|//set to empty "Text" if hive.metastore.token.signature property is set to null
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|hiveToken
init|=
name|hiveTokenSelector
operator|.
name|selectToken
argument_list|(
operator|new
name|Text
argument_list|()
argument_list|,
name|ugi
operator|.
name|getTokens
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|hiveToken
operator|==
literal|null
condition|)
block|{
comment|// we did not get token set up by oozie, let's get them ourselves here.
comment|// we essentially get a token per unique Output HCatTableInfo - this is
comment|// done because through Pig, setOutput() method is called multiple times
comment|// We want to only get the token once per unique output HCatTableInfo -
comment|// we cannot just get one token since in multi-query case (> 1 store in 1 job)
comment|// or the case when a single pig script results in> 1 jobs, the single
comment|// token will get cancelled by the output committer and the subsequent
comment|// stores will fail - by tying the token with the concatenation of
comment|// dbname, tablename and partition keyvalues of the output
comment|// TableInfo, we can have as many tokens as there are stores and the TokenSelector
comment|// will correctly pick the right tokens which the committer will use and
comment|// cancel.
name|String
name|tokenSignature
init|=
name|getTokenSignature
argument_list|(
name|outputJobInfo
argument_list|)
decl_stmt|;
comment|// get delegation tokens from hcat server and store them into the "job"
comment|// These will be used in to publish partitions to
comment|// hcat normally in OutputCommitter.commitJob()
comment|// when the JobTracker in Hadoop MapReduce starts supporting renewal of
comment|// arbitrary tokens, the renewer should be the principal of the JobTracker
name|hiveToken
operator|=
name|HCatUtil
operator|.
name|extractThriftToken
argument_list|(
name|client
operator|.
name|getDelegationToken
argument_list|(
name|ugi
operator|.
name|getUserName
argument_list|()
argument_list|)
argument_list|,
name|tokenSignature
argument_list|)
expr_stmt|;
if|if
condition|(
name|harRequested
condition|)
block|{
name|TokenSelector
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|jtTokenSelector
init|=
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
operator|.
name|token
operator|.
name|delegation
operator|.
name|DelegationTokenSelector
argument_list|()
decl_stmt|;
name|Token
name|jtToken
init|=
name|jtTokenSelector
operator|.
name|selectToken
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
operator|.
name|buildTokenService
argument_list|(
name|ShimLoader
operator|.
name|getHadoopShims
argument_list|()
operator|.
name|getHCatShim
argument_list|()
operator|.
name|getResourceManagerAddress
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|,
name|ugi
operator|.
name|getTokens
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|jtToken
operator|==
literal|null
condition|)
block|{
comment|//we don't need to cancel this token as the TokenRenewer for JT tokens
comment|//takes care of cancelling them
name|credentials
operator|.
name|addToken
argument_list|(
operator|new
name|Text
argument_list|(
literal|"hcat jt token"
argument_list|)
argument_list|,
name|HCatUtil
operator|.
name|getJobTrackerDelegationToken
argument_list|(
name|conf
argument_list|,
name|ugi
operator|.
name|getUserName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|credentials
operator|.
name|addToken
argument_list|(
operator|new
name|Text
argument_list|(
name|ugi
operator|.
name|getUserName
argument_list|()
operator|+
literal|"_"
operator|+
name|tokenSignature
argument_list|)
argument_list|,
name|hiveToken
argument_list|)
expr_stmt|;
comment|// this will be used by the outputcommitter to pass on to the metastore client
comment|// which in turn will pass on to the TokenSelector so that it can select
comment|// the right token.
name|conf
operator|.
name|set
argument_list|(
name|HCatConstants
operator|.
name|HCAT_KEY_TOKEN_SIGNATURE
argument_list|,
name|tokenSignature
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|void
name|handleSecurity
parameter_list|(
name|Job
name|job
parameter_list|,
name|OutputJobInfo
name|outputJobInfo
parameter_list|,
name|HiveMetaStoreClient
name|client
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|harRequested
parameter_list|)
throws|throws
name|IOException
throws|,
name|MetaException
throws|,
name|TException
throws|,
name|Exception
block|{
name|handleSecurity
argument_list|(
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|,
name|outputJobInfo
argument_list|,
name|client
argument_list|,
name|conf
argument_list|,
name|harRequested
argument_list|)
expr_stmt|;
block|}
comment|// we should cancel hcat token if it was acquired by hcat
comment|// and not if it was supplied (ie Oozie). In the latter
comment|// case the HCAT_KEY_TOKEN_SIGNATURE property in the conf will not be set
name|void
name|cancelToken
parameter_list|(
name|HiveMetaStoreClient
name|client
parameter_list|,
name|JobContext
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|MetaException
block|{
name|String
name|tokenStrForm
init|=
name|client
operator|.
name|getTokenStrForm
argument_list|()
decl_stmt|;
if|if
condition|(
name|tokenStrForm
operator|!=
literal|null
operator|&&
name|context
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|HCatConstants
operator|.
name|HCAT_KEY_TOKEN_SIGNATURE
argument_list|)
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|client
operator|.
name|cancelDelegationToken
argument_list|(
name|tokenStrForm
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Failed to cancel delegation token"
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
end_class

end_unit

