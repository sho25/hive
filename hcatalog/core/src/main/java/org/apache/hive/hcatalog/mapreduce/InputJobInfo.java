begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|hcatalog
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|MetaStoreUtils
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ObjectInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ObjectOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Serializable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|Deflater
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|DeflaterOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|InflaterInputStream
import|;
end_import

begin_comment
comment|/**  * Container for metadata read from the metadata server.  * Prior to release 0.5, InputJobInfo was a key part of the public API, exposed directly  * to end-users as an argument to  * HCatInputFormat#setInput(org.apache.hadoop.mapreduce.Job, InputJobInfo).  * Going forward, we plan on treating InputJobInfo as an implementation detail and no longer  * expose to end-users. Should you have a need to use InputJobInfo outside HCatalog itself,  * please contact the developer mailing list before depending on this class.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
specifier|public
class|class
name|InputJobInfo
implements|implements
name|Serializable
block|{
comment|/** The serialization version */
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
comment|/** The db and table names. */
specifier|private
specifier|final
name|String
name|databaseName
decl_stmt|;
specifier|private
specifier|final
name|String
name|tableName
decl_stmt|;
comment|/** meta information of the table to be read from */
specifier|private
name|HCatTableInfo
name|tableInfo
decl_stmt|;
comment|/** The partition filter */
specifier|private
name|String
name|filter
decl_stmt|;
comment|/** The list of partitions matching the filter. */
specifier|transient
specifier|private
name|List
argument_list|<
name|PartInfo
argument_list|>
name|partitions
decl_stmt|;
comment|/** implementation specific job properties */
specifier|private
name|Properties
name|properties
decl_stmt|;
comment|/**    * Initializes a new InputJobInfo    * for reading data from a table.    * @param databaseName the db name    * @param tableName the table name    * @param filter the partition filter    * @param properties implementation specific job properties    */
specifier|public
specifier|static
name|InputJobInfo
name|create
parameter_list|(
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|filter
parameter_list|,
name|Properties
name|properties
parameter_list|)
block|{
return|return
operator|new
name|InputJobInfo
argument_list|(
name|databaseName
argument_list|,
name|tableName
argument_list|,
name|filter
argument_list|,
name|properties
argument_list|)
return|;
block|}
specifier|private
name|InputJobInfo
parameter_list|(
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|String
name|filter
parameter_list|,
name|Properties
name|properties
parameter_list|)
block|{
name|this
operator|.
name|databaseName
operator|=
operator|(
name|databaseName
operator|==
literal|null
operator|)
condition|?
name|MetaStoreUtils
operator|.
name|DEFAULT_DATABASE_NAME
else|:
name|databaseName
expr_stmt|;
name|this
operator|.
name|tableName
operator|=
name|tableName
expr_stmt|;
name|this
operator|.
name|filter
operator|=
name|filter
expr_stmt|;
name|this
operator|.
name|properties
operator|=
name|properties
operator|==
literal|null
condition|?
operator|new
name|Properties
argument_list|()
else|:
name|properties
expr_stmt|;
block|}
comment|/**    * Gets the value of databaseName    * @return the databaseName    */
specifier|public
name|String
name|getDatabaseName
parameter_list|()
block|{
return|return
name|databaseName
return|;
block|}
comment|/**    * Gets the value of tableName    * @return the tableName    */
specifier|public
name|String
name|getTableName
parameter_list|()
block|{
return|return
name|tableName
return|;
block|}
comment|/**    * Gets the table's meta information    * @return the HCatTableInfo    */
specifier|public
name|HCatTableInfo
name|getTableInfo
parameter_list|()
block|{
return|return
name|tableInfo
return|;
block|}
comment|/**    * set the tablInfo instance    * this should be the same instance    * determined by this object's DatabaseName and TableName    * @param tableInfo    */
name|void
name|setTableInfo
parameter_list|(
name|HCatTableInfo
name|tableInfo
parameter_list|)
block|{
name|this
operator|.
name|tableInfo
operator|=
name|tableInfo
expr_stmt|;
block|}
comment|/**    * Gets the value of partition filter    * @return the filter string    */
specifier|public
name|String
name|getFilter
parameter_list|()
block|{
return|return
name|filter
return|;
block|}
comment|/**    * @return partition info    */
specifier|public
name|List
argument_list|<
name|PartInfo
argument_list|>
name|getPartitions
parameter_list|()
block|{
return|return
name|partitions
return|;
block|}
comment|/**    * @return partition info  list    */
name|void
name|setPartitions
parameter_list|(
name|List
argument_list|<
name|PartInfo
argument_list|>
name|partitions
parameter_list|)
block|{
name|this
operator|.
name|partitions
operator|=
name|partitions
expr_stmt|;
block|}
comment|/**    * Set/Get Property information to be passed down to *StorageHandler implementation    * put implementation specific storage handler configurations here    * @return the implementation specific job properties    */
specifier|public
name|Properties
name|getProperties
parameter_list|()
block|{
return|return
name|properties
return|;
block|}
comment|/**    * Serialize this object, compressing the partitions which can exceed the    * allowed jobConf size.    * @see<a href="https://issues.apache.org/jira/browse/HCATALOG-453">HCATALOG-453</a>    */
specifier|private
name|void
name|writeObject
parameter_list|(
name|ObjectOutputStream
name|oos
parameter_list|)
throws|throws
name|IOException
block|{
name|oos
operator|.
name|defaultWriteObject
argument_list|()
expr_stmt|;
name|Deflater
name|def
init|=
operator|new
name|Deflater
argument_list|(
name|Deflater
operator|.
name|BEST_COMPRESSION
argument_list|)
decl_stmt|;
name|ObjectOutputStream
name|partInfoWriter
init|=
operator|new
name|ObjectOutputStream
argument_list|(
operator|new
name|DeflaterOutputStream
argument_list|(
name|oos
argument_list|,
name|def
argument_list|)
argument_list|)
decl_stmt|;
name|partInfoWriter
operator|.
name|writeObject
argument_list|(
name|partitions
argument_list|)
expr_stmt|;
name|partInfoWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Deserialize this object, decompressing the partitions which can exceed the    * allowed jobConf size.    * @see<a href="https://issues.apache.org/jira/browse/HCATALOG-453">HCATALOG-453</a>    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|void
name|readObject
parameter_list|(
name|ObjectInputStream
name|ois
parameter_list|)
throws|throws
name|IOException
throws|,
name|ClassNotFoundException
block|{
name|ois
operator|.
name|defaultReadObject
argument_list|()
expr_stmt|;
name|ObjectInputStream
name|partInfoReader
init|=
operator|new
name|ObjectInputStream
argument_list|(
operator|new
name|InflaterInputStream
argument_list|(
name|ois
argument_list|)
argument_list|)
decl_stmt|;
name|partitions
operator|=
operator|(
name|List
argument_list|<
name|PartInfo
argument_list|>
operator|)
name|partInfoReader
operator|.
name|readObject
argument_list|()
expr_stmt|;
block|}
block|}
end_class

end_unit

