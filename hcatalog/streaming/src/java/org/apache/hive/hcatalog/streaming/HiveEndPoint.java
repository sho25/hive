begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|hcatalog
operator|.
name|streaming
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|DataOperationType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|cli
operator|.
name|CliSessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|IMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|LockComponentBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|LockRequestBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Warehouse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|HeartbeatTxnRangeResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|LockState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchTxnException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|TxnAbortedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|CommandNeedRetryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|Driver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|session
operator|.
name|SessionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|thrift
operator|.
name|TException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedExceptionAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_comment
comment|/**  * Information about the hive end point (i.e. table or partition) to write to.  * A light weight object that does NOT internally hold on to resources such as  * network connections. It can be stored in Hashed containers such as sets and hash tables.  */
end_comment

begin_class
specifier|public
class|class
name|HiveEndPoint
block|{
specifier|public
specifier|final
name|String
name|metaStoreUri
decl_stmt|;
specifier|public
specifier|final
name|String
name|database
decl_stmt|;
specifier|public
specifier|final
name|String
name|table
decl_stmt|;
specifier|public
specifier|final
name|ArrayList
argument_list|<
name|String
argument_list|>
name|partitionVals
decl_stmt|;
specifier|static
specifier|final
specifier|private
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HiveEndPoint
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|/**    *    * @param metaStoreUri   URI of the metastore to connect to eg: thrift://localhost:9083    * @param database       Name of the Hive database    * @param table          Name of table to stream to    * @param partitionVals  Indicates the specific partition to stream to. Can be null or empty List    *                       if streaming to a table without partitions. The order of values in this    *                       list must correspond exactly to the order of partition columns specified    *                       during the table creation. E.g. For a table partitioned by    *                       (continent string, country string), partitionVals could be the list    *                       ("Asia", "India").    */
specifier|public
name|HiveEndPoint
parameter_list|(
name|String
name|metaStoreUri
parameter_list|,
name|String
name|database
parameter_list|,
name|String
name|table
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partitionVals
parameter_list|)
block|{
name|this
operator|.
name|metaStoreUri
operator|=
name|metaStoreUri
expr_stmt|;
if|if
condition|(
name|database
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Database cannot be null for HiveEndPoint"
argument_list|)
throw|;
block|}
name|this
operator|.
name|database
operator|=
name|database
expr_stmt|;
name|this
operator|.
name|table
operator|=
name|table
expr_stmt|;
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Table cannot be null for HiveEndPoint"
argument_list|)
throw|;
block|}
name|this
operator|.
name|partitionVals
operator|=
name|partitionVals
operator|==
literal|null
condition|?
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
else|:
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|partitionVals
argument_list|)
expr_stmt|;
block|}
comment|/**    * @deprecated Use {@link #newConnection(boolean, String)}    */
specifier|public
name|StreamingConnection
name|newConnection
parameter_list|(
specifier|final
name|boolean
name|createPartIfNotExists
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
return|return
name|newConnection
argument_list|(
name|createPartIfNotExists
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * @deprecated Use {@link #newConnection(boolean, HiveConf, String)}    */
specifier|public
name|StreamingConnection
name|newConnection
parameter_list|(
specifier|final
name|boolean
name|createPartIfNotExists
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
return|return
name|newConnection
argument_list|(
name|createPartIfNotExists
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * @deprecated Use {@link #newConnection(boolean, HiveConf, UserGroupInformation, String)}    */
specifier|public
name|StreamingConnection
name|newConnection
parameter_list|(
specifier|final
name|boolean
name|createPartIfNotExists
parameter_list|,
specifier|final
name|HiveConf
name|conf
parameter_list|,
specifier|final
name|UserGroupInformation
name|authenticatedUser
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
return|return
name|newConnection
argument_list|(
name|createPartIfNotExists
argument_list|,
name|conf
argument_list|,
name|authenticatedUser
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Acquire a new connection to MetaStore for streaming    * @param createPartIfNotExists If true, the partition specified in the endpoint    *                              will be auto created if it does not exist    * @param agentInfo should uniquely identify the process/entity that is using this batch.  This    *                  should be something that can be correlated with calling application log files    *                  and/or monitoring consoles.    * @return    * @throws ConnectionError if problem connecting    * @throws InvalidPartition  if specified partition is not valid (createPartIfNotExists = false)    * @throws ImpersonationFailed  if not able to impersonate 'proxyUser'    * @throws PartitionCreationFailed if failed to create partition    * @throws InterruptedException    */
specifier|public
name|StreamingConnection
name|newConnection
parameter_list|(
specifier|final
name|boolean
name|createPartIfNotExists
parameter_list|,
name|String
name|agentInfo
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
return|return
name|newConnection
argument_list|(
name|createPartIfNotExists
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|agentInfo
argument_list|)
return|;
block|}
comment|/**    * Acquire a new connection to MetaStore for streaming    * @param createPartIfNotExists If true, the partition specified in the endpoint    *                              will be auto created if it does not exist    * @param conf HiveConf object, set it to null if not using advanced hive settings.    * @param agentInfo should uniquely identify the process/entity that is using this batch.  This    *                  should be something that can be correlated with calling application log files    *                  and/or monitoring consoles.    * @return    * @throws ConnectionError if problem connecting    * @throws InvalidPartition  if specified partition is not valid (createPartIfNotExists = false)    * @throws ImpersonationFailed  if not able to impersonate 'proxyUser'    * @throws PartitionCreationFailed if failed to create partition    * @throws InterruptedException    */
specifier|public
name|StreamingConnection
name|newConnection
parameter_list|(
specifier|final
name|boolean
name|createPartIfNotExists
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|String
name|agentInfo
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
return|return
name|newConnection
argument_list|(
name|createPartIfNotExists
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
name|agentInfo
argument_list|)
return|;
block|}
comment|/**    * Acquire a new connection to MetaStore for streaming. To connect using Kerberos,    *   'authenticatedUser' argument should have been used to do a kerberos login.  Additionally the    *   'hive.metastore.kerberos.principal' setting should be set correctly either in hive-site.xml or    *    in the 'conf' argument (if not null). If using hive-site.xml, it should be in classpath.    *    * @param createPartIfNotExists If true, the partition specified in the endpoint    *                              will be auto created if it does not exist    * @param conf               HiveConf object to be used for the connection. Can be null.    * @param authenticatedUser  UserGroupInformation object obtained from successful authentication.    *                           Uses non-secure mode if this argument is null.    * @param agentInfo should uniquely identify the process/entity that is using this batch.  This    *                  should be something that can be correlated with calling application log files    *                  and/or monitoring consoles.    * @return    * @throws ConnectionError if there is a connection problem    * @throws InvalidPartition  if specified partition is not valid (createPartIfNotExists = false)    * @throws ImpersonationFailed  if not able to impersonate 'username'    * @throws PartitionCreationFailed if failed to create partition    * @throws InterruptedException    */
specifier|public
name|StreamingConnection
name|newConnection
parameter_list|(
specifier|final
name|boolean
name|createPartIfNotExists
parameter_list|,
specifier|final
name|HiveConf
name|conf
parameter_list|,
specifier|final
name|UserGroupInformation
name|authenticatedUser
parameter_list|,
specifier|final
name|String
name|agentInfo
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|authenticatedUser
operator|==
literal|null
condition|)
block|{
return|return
name|newConnectionImpl
argument_list|(
name|authenticatedUser
argument_list|,
name|createPartIfNotExists
argument_list|,
name|conf
argument_list|,
name|agentInfo
argument_list|)
return|;
block|}
try|try
block|{
return|return
name|authenticatedUser
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|StreamingConnection
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|StreamingConnection
name|run
parameter_list|()
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
block|{
return|return
name|newConnectionImpl
argument_list|(
name|authenticatedUser
argument_list|,
name|createPartIfNotExists
argument_list|,
name|conf
argument_list|,
name|agentInfo
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ConnectionError
argument_list|(
literal|"Failed to connect as : "
operator|+
name|authenticatedUser
operator|.
name|getShortUserName
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|StreamingConnection
name|newConnectionImpl
parameter_list|(
name|UserGroupInformation
name|ugi
parameter_list|,
name|boolean
name|createPartIfNotExists
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|String
name|agentInfo
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
block|{
return|return
operator|new
name|ConnectionImpl
argument_list|(
name|this
argument_list|,
name|ugi
argument_list|,
name|conf
argument_list|,
name|createPartIfNotExists
argument_list|,
name|agentInfo
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|UserGroupInformation
name|getUserGroupInfo
parameter_list|(
name|String
name|user
parameter_list|)
throws|throws
name|ImpersonationFailed
block|{
try|try
block|{
return|return
name|UserGroupInformation
operator|.
name|createProxyUser
argument_list|(
name|user
argument_list|,
name|UserGroupInformation
operator|.
name|getLoginUser
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to get UserGroupInfo for user : "
operator|+
name|user
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
name|user
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
if|if
condition|(
name|this
operator|==
name|o
condition|)
return|return
literal|true
return|;
if|if
condition|(
name|o
operator|==
literal|null
operator|||
name|getClass
argument_list|()
operator|!=
name|o
operator|.
name|getClass
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|HiveEndPoint
name|endPoint
init|=
operator|(
name|HiveEndPoint
operator|)
name|o
decl_stmt|;
if|if
condition|(
name|database
operator|!=
literal|null
condition|?
operator|!
name|database
operator|.
name|equals
argument_list|(
name|endPoint
operator|.
name|database
argument_list|)
else|:
name|endPoint
operator|.
name|database
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|metaStoreUri
operator|!=
literal|null
condition|?
operator|!
name|metaStoreUri
operator|.
name|equals
argument_list|(
name|endPoint
operator|.
name|metaStoreUri
argument_list|)
else|:
name|endPoint
operator|.
name|metaStoreUri
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
operator|!
name|partitionVals
operator|.
name|equals
argument_list|(
name|endPoint
operator|.
name|partitionVals
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|table
operator|!=
literal|null
condition|?
operator|!
name|table
operator|.
name|equals
argument_list|(
name|endPoint
operator|.
name|table
argument_list|)
else|:
name|endPoint
operator|.
name|table
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
name|int
name|result
init|=
name|metaStoreUri
operator|!=
literal|null
condition|?
name|metaStoreUri
operator|.
name|hashCode
argument_list|()
else|:
literal|0
decl_stmt|;
name|result
operator|=
literal|31
operator|*
name|result
operator|+
operator|(
name|database
operator|!=
literal|null
condition|?
name|database
operator|.
name|hashCode
argument_list|()
else|:
literal|0
operator|)
expr_stmt|;
name|result
operator|=
literal|31
operator|*
name|result
operator|+
operator|(
name|table
operator|!=
literal|null
condition|?
name|table
operator|.
name|hashCode
argument_list|()
else|:
literal|0
operator|)
expr_stmt|;
name|result
operator|=
literal|31
operator|*
name|result
operator|+
name|partitionVals
operator|.
name|hashCode
argument_list|()
expr_stmt|;
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"{"
operator|+
literal|"metaStoreUri='"
operator|+
name|metaStoreUri
operator|+
literal|'\''
operator|+
literal|", database='"
operator|+
name|database
operator|+
literal|'\''
operator|+
literal|", table='"
operator|+
name|table
operator|+
literal|'\''
operator|+
literal|", partitionVals="
operator|+
name|partitionVals
operator|+
literal|" }"
return|;
block|}
specifier|private
specifier|static
class|class
name|ConnectionImpl
implements|implements
name|StreamingConnection
block|{
specifier|private
specifier|final
name|IMetaStoreClient
name|msClient
decl_stmt|;
specifier|private
specifier|final
name|IMetaStoreClient
name|heartbeaterMSClient
decl_stmt|;
specifier|private
specifier|final
name|HiveEndPoint
name|endPt
decl_stmt|;
specifier|private
specifier|final
name|UserGroupInformation
name|ugi
decl_stmt|;
specifier|private
specifier|final
name|String
name|username
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|secureMode
decl_stmt|;
specifier|private
specifier|final
name|String
name|agentInfo
decl_stmt|;
comment|/**      * @param endPoint end point to connect to      * @param ugi on behalf of whom streaming is done. cannot be null      * @param conf HiveConf object      * @param createPart create the partition if it does not exist      * @throws ConnectionError if there is trouble connecting      * @throws InvalidPartition if specified partition does not exist (and createPart=false)      * @throws InvalidTable if specified table does not exist      * @throws PartitionCreationFailed if createPart=true and not able to create partition      */
specifier|private
name|ConnectionImpl
parameter_list|(
name|HiveEndPoint
name|endPoint
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|createPart
parameter_list|,
name|String
name|agentInfo
parameter_list|)
throws|throws
name|ConnectionError
throws|,
name|InvalidPartition
throws|,
name|InvalidTable
throws|,
name|PartitionCreationFailed
block|{
name|this
operator|.
name|endPt
operator|=
name|endPoint
expr_stmt|;
name|this
operator|.
name|ugi
operator|=
name|ugi
expr_stmt|;
name|this
operator|.
name|agentInfo
operator|=
name|agentInfo
expr_stmt|;
name|this
operator|.
name|username
operator|=
name|ugi
operator|==
literal|null
condition|?
name|System
operator|.
name|getProperty
argument_list|(
literal|"user.name"
argument_list|)
else|:
name|ugi
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
name|conf
operator|=
name|HiveEndPoint
operator|.
name|createHiveConf
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|,
name|endPoint
operator|.
name|metaStoreUri
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|overrideConfSettings
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|secureMode
operator|=
name|ugi
operator|==
literal|null
condition|?
literal|false
else|:
name|ugi
operator|.
name|hasKerberosCredentials
argument_list|()
expr_stmt|;
name|this
operator|.
name|msClient
operator|=
name|getMetaStoreClient
argument_list|(
name|endPoint
argument_list|,
name|conf
argument_list|,
name|secureMode
argument_list|)
expr_stmt|;
comment|// We use a separate metastore client for heartbeat calls to ensure heartbeat RPC calls are
comment|// isolated from the other transaction related RPC calls.
name|this
operator|.
name|heartbeaterMSClient
operator|=
name|getMetaStoreClient
argument_list|(
name|endPoint
argument_list|,
name|conf
argument_list|,
name|secureMode
argument_list|)
expr_stmt|;
name|checkEndPoint
argument_list|(
name|endPoint
argument_list|,
name|msClient
argument_list|)
expr_stmt|;
if|if
condition|(
name|createPart
operator|&&
operator|!
name|endPoint
operator|.
name|partitionVals
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|createPartitionIfNotExists
argument_list|(
name|endPoint
argument_list|,
name|msClient
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Checks the validity of endpoint      * @param endPoint the HiveEndPoint to be checked      * @param msClient the metastore client      * @throws InvalidTable      */
specifier|private
name|void
name|checkEndPoint
parameter_list|(
name|HiveEndPoint
name|endPoint
parameter_list|,
name|IMetaStoreClient
name|msClient
parameter_list|)
throws|throws
name|InvalidTable
throws|,
name|ConnectionError
block|{
name|Table
name|t
decl_stmt|;
try|try
block|{
name|t
operator|=
name|msClient
operator|.
name|getTable
argument_list|(
name|endPoint
operator|.
name|database
argument_list|,
name|endPoint
operator|.
name|table
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to check the endPoint: "
operator|+
name|endPoint
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTable
argument_list|(
name|endPoint
operator|.
name|database
argument_list|,
name|endPoint
operator|.
name|table
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// 1 - check if TBLPROPERTIES ('transactional'='true') is set on table
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|t
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|!=
literal|null
condition|)
block|{
name|String
name|transactionalProp
init|=
name|params
operator|.
name|get
argument_list|(
literal|"transactional"
argument_list|)
decl_stmt|;
if|if
condition|(
name|transactionalProp
operator|==
literal|null
operator|||
operator|!
name|transactionalProp
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"'transactional' property is not set on Table "
operator|+
name|endPoint
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTable
argument_list|(
name|endPoint
operator|.
name|database
argument_list|,
name|endPoint
operator|.
name|table
argument_list|,
literal|"\'transactional\' property"
operator|+
literal|" is not set on Table"
argument_list|)
throw|;
block|}
block|}
comment|// 2 - check if partitionvals are legitimate
if|if
condition|(
name|t
operator|.
name|getPartitionKeys
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|t
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|&&
name|endPoint
operator|.
name|partitionVals
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Invalid if table is partitioned, but endPoint's partitionVals is empty
name|String
name|errMsg
init|=
literal|"HiveEndPoint "
operator|+
name|endPoint
operator|+
literal|" doesn't specify any partitions for "
operator|+
literal|"partitioned table"
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|errMsg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|ConnectionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
if|if
condition|(
operator|(
name|t
operator|.
name|getPartitionKeys
argument_list|()
operator|==
literal|null
operator|||
name|t
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|)
operator|&&
operator|!
name|endPoint
operator|.
name|partitionVals
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Invalid if table is not partitioned, but endPoint's partitionVals is not empty
name|String
name|errMsg
init|=
literal|"HiveEndPoint"
operator|+
name|endPoint
operator|+
literal|" specifies partitions for unpartitioned table"
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|errMsg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|ConnectionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
block|}
comment|/**      * Close connection      */
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|msClient
operator|.
name|close
argument_list|()
expr_stmt|;
name|heartbeaterMSClient
operator|.
name|close
argument_list|()
expr_stmt|;
return|return;
block|}
try|try
block|{
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|Exception
block|{
name|msClient
operator|.
name|close
argument_list|()
expr_stmt|;
name|heartbeaterMSClient
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
try|try
block|{
name|FileSystem
operator|.
name|closeAllForUGI
argument_list|(
name|ugi
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|exception
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not clean up file-system handles for UGI: "
operator|+
name|ugi
argument_list|,
name|exception
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error closing connection to "
operator|+
name|endPt
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted when closing connection to "
operator|+
name|endPt
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Acquires a new batch of transactions from Hive.      *      * @param numTransactions is a hint from client indicating how many transactions client needs.      * @param recordWriter  Used to write record. The same writer instance can      *                      be shared with another TransactionBatch (to the same endpoint)      *                      only after the first TransactionBatch has been closed.      *                      Writer will be closed when the TransactionBatch is closed.      * @return      * @throws StreamingIOFailure if failed to create new RecordUpdater for batch      * @throws TransactionBatchUnAvailable if failed to acquire a new Transaction batch      * @throws ImpersonationFailed failed to run command as proxyUser      * @throws InterruptedException      */
specifier|public
name|TransactionBatch
name|fetchTransactionBatch
parameter_list|(
specifier|final
name|int
name|numTransactions
parameter_list|,
specifier|final
name|RecordWriter
name|recordWriter
parameter_list|)
throws|throws
name|StreamingException
throws|,
name|TransactionBatchUnAvailable
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
return|return
name|fetchTransactionBatchImpl
argument_list|(
name|numTransactions
argument_list|,
name|recordWriter
argument_list|)
return|;
block|}
try|try
block|{
return|return
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|TransactionBatch
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|TransactionBatch
name|run
parameter_list|()
throws|throws
name|StreamingException
throws|,
name|InterruptedException
block|{
return|return
name|fetchTransactionBatchImpl
argument_list|(
name|numTransactions
argument_list|,
name|recordWriter
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
literal|"Failed to fetch Txn Batch as user '"
operator|+
name|ugi
operator|.
name|getShortUserName
argument_list|()
operator|+
literal|"' when acquiring Transaction Batch on endPoint "
operator|+
name|endPt
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|TransactionBatch
name|fetchTransactionBatchImpl
parameter_list|(
name|int
name|numTransactions
parameter_list|,
name|RecordWriter
name|recordWriter
parameter_list|)
throws|throws
name|StreamingException
throws|,
name|TransactionBatchUnAvailable
throws|,
name|InterruptedException
block|{
return|return
operator|new
name|TransactionBatchImpl
argument_list|(
name|username
argument_list|,
name|ugi
argument_list|,
name|endPt
argument_list|,
name|numTransactions
argument_list|,
name|msClient
argument_list|,
name|heartbeaterMSClient
argument_list|,
name|recordWriter
argument_list|,
name|agentInfo
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|void
name|createPartitionIfNotExists
parameter_list|(
name|HiveEndPoint
name|ep
parameter_list|,
name|IMetaStoreClient
name|msClient
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|InvalidTable
throws|,
name|PartitionCreationFailed
block|{
if|if
condition|(
name|ep
operator|.
name|partitionVals
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|SessionState
name|localSession
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|SessionState
operator|.
name|get
argument_list|()
operator|==
literal|null
condition|)
block|{
name|localSession
operator|=
name|SessionState
operator|.
name|start
argument_list|(
operator|new
name|CliSessionState
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Driver
name|driver
init|=
operator|new
name|Driver
argument_list|(
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Attempting to create partition (if not existent) "
operator|+
name|ep
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partKeys
init|=
name|msClient
operator|.
name|getTable
argument_list|(
name|ep
operator|.
name|database
argument_list|,
name|ep
operator|.
name|table
argument_list|)
operator|.
name|getPartitionKeys
argument_list|()
decl_stmt|;
name|runDDL
argument_list|(
name|driver
argument_list|,
literal|"use "
operator|+
name|ep
operator|.
name|database
argument_list|)
expr_stmt|;
name|String
name|query
init|=
literal|"alter table "
operator|+
name|ep
operator|.
name|table
operator|+
literal|" add if not exists partition "
operator|+
name|partSpecStr
argument_list|(
name|partKeys
argument_list|,
name|ep
operator|.
name|partitionVals
argument_list|)
decl_stmt|;
name|runDDL
argument_list|(
name|driver
argument_list|,
name|query
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to create partition : "
operator|+
name|ep
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|PartitionCreationFailed
argument_list|(
name|ep
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|NoSuchObjectException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to create partition : "
operator|+
name|ep
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InvalidTable
argument_list|(
name|ep
operator|.
name|database
argument_list|,
name|ep
operator|.
name|table
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to create partition : "
operator|+
name|ep
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|PartitionCreationFailed
argument_list|(
name|ep
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|QueryFailedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to create partition : "
operator|+
name|ep
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|PartitionCreationFailed
argument_list|(
name|ep
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|driver
operator|.
name|close
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|localSession
operator|!=
literal|null
condition|)
block|{
name|localSession
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error closing SessionState used to run Hive DDL."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|boolean
name|runDDL
parameter_list|(
name|Driver
name|driver
parameter_list|,
name|String
name|sql
parameter_list|)
throws|throws
name|QueryFailedException
block|{
name|int
name|retryCount
init|=
literal|1
decl_stmt|;
comment|// # of times to retry if first attempt fails
for|for
control|(
name|int
name|attempt
init|=
literal|0
init|;
name|attempt
operator|<=
name|retryCount
condition|;
operator|++
name|attempt
control|)
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Running Hive Query: "
operator|+
name|sql
argument_list|)
expr_stmt|;
block|}
name|driver
operator|.
name|run
argument_list|(
name|sql
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|CommandNeedRetryException
name|e
parameter_list|)
block|{
if|if
condition|(
name|attempt
operator|==
name|retryCount
condition|)
block|{
throw|throw
operator|new
name|QueryFailedException
argument_list|(
name|sql
argument_list|,
name|e
argument_list|)
throw|;
block|}
continue|continue;
block|}
block|}
comment|// for
return|return
literal|false
return|;
block|}
specifier|private
specifier|static
name|String
name|partSpecStr
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partKeys
parameter_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|)
block|{
if|if
condition|(
name|partKeys
operator|.
name|size
argument_list|()
operator|!=
name|partVals
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Partition values:"
operator|+
name|partVals
operator|+
literal|", does not match the partition Keys in table :"
operator|+
name|partKeys
argument_list|)
throw|;
block|}
name|StringBuilder
name|buff
init|=
operator|new
name|StringBuilder
argument_list|(
name|partKeys
operator|.
name|size
argument_list|()
operator|*
literal|20
argument_list|)
decl_stmt|;
name|buff
operator|.
name|append
argument_list|(
literal|" ( "
argument_list|)
expr_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|FieldSchema
name|schema
range|:
name|partKeys
control|)
block|{
name|buff
operator|.
name|append
argument_list|(
name|schema
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|buff
operator|.
name|append
argument_list|(
literal|"='"
argument_list|)
expr_stmt|;
name|buff
operator|.
name|append
argument_list|(
name|partVals
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|buff
operator|.
name|append
argument_list|(
literal|"'"
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|!=
name|partKeys
operator|.
name|size
argument_list|()
operator|-
literal|1
condition|)
block|{
name|buff
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
operator|++
name|i
expr_stmt|;
block|}
name|buff
operator|.
name|append
argument_list|(
literal|" )"
argument_list|)
expr_stmt|;
return|return
name|buff
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
specifier|static
name|IMetaStoreClient
name|getMetaStoreClient
parameter_list|(
name|HiveEndPoint
name|endPoint
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|boolean
name|secureMode
parameter_list|)
throws|throws
name|ConnectionError
block|{
if|if
condition|(
name|endPoint
operator|.
name|metaStoreUri
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|setVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREURIS
argument_list|,
name|endPoint
operator|.
name|metaStoreUri
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|secureMode
condition|)
block|{
name|conf
operator|.
name|setBoolVar
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_USE_THRIFT_SASL
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
try|try
block|{
return|return
name|HCatUtil
operator|.
name|getHiveMetastoreClient
argument_list|(
name|conf
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ConnectionError
argument_list|(
literal|"Error connecting to Hive Metastore URI: "
operator|+
name|endPoint
operator|.
name|metaStoreUri
operator|+
literal|". "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ConnectionError
argument_list|(
literal|"Error connecting to Hive Metastore URI: "
operator|+
name|endPoint
operator|.
name|metaStoreUri
operator|+
literal|". "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|// class ConnectionImpl
specifier|private
specifier|static
class|class
name|TransactionBatchImpl
implements|implements
name|TransactionBatch
block|{
specifier|private
specifier|final
name|String
name|username
decl_stmt|;
specifier|private
specifier|final
name|UserGroupInformation
name|ugi
decl_stmt|;
specifier|private
specifier|final
name|HiveEndPoint
name|endPt
decl_stmt|;
specifier|private
specifier|final
name|IMetaStoreClient
name|msClient
decl_stmt|;
specifier|private
specifier|final
name|IMetaStoreClient
name|heartbeaterMSClient
decl_stmt|;
specifier|private
specifier|final
name|RecordWriter
name|recordWriter
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|Long
argument_list|>
name|txnIds
decl_stmt|;
specifier|private
name|int
name|currentTxnIndex
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
specifier|final
name|String
name|partNameForLock
decl_stmt|;
specifier|private
name|TxnState
name|state
decl_stmt|;
specifier|private
name|LockRequest
name|lockRequest
init|=
literal|null
decl_stmt|;
comment|/**      * once any operation on this batch encounters a system exception      * (e.g. IOException on write) it's safest to assume that we can't write to the      * file backing this batch any more.  This guards important public methods      */
specifier|private
specifier|volatile
name|boolean
name|isClosed
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|String
name|agentInfo
decl_stmt|;
comment|/**      * Represents a batch of transactions acquired from MetaStore      *      * @throws StreamingException if failed to create new RecordUpdater for batch      * @throws TransactionBatchUnAvailable if failed to acquire a new Transaction batch      */
specifier|private
name|TransactionBatchImpl
parameter_list|(
specifier|final
name|String
name|user
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|,
name|HiveEndPoint
name|endPt
parameter_list|,
specifier|final
name|int
name|numTxns
parameter_list|,
specifier|final
name|IMetaStoreClient
name|msClient
parameter_list|,
specifier|final
name|IMetaStoreClient
name|heartbeaterMSClient
parameter_list|,
name|RecordWriter
name|recordWriter
parameter_list|,
name|String
name|agentInfo
parameter_list|)
throws|throws
name|StreamingException
throws|,
name|TransactionBatchUnAvailable
throws|,
name|InterruptedException
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|endPt
operator|.
name|partitionVals
operator|!=
literal|null
operator|&&
operator|!
name|endPt
operator|.
name|partitionVals
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Table
name|tableObj
init|=
name|msClient
operator|.
name|getTable
argument_list|(
name|endPt
operator|.
name|database
argument_list|,
name|endPt
operator|.
name|table
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partKeys
init|=
name|tableObj
operator|.
name|getPartitionKeys
argument_list|()
decl_stmt|;
name|partNameForLock
operator|=
name|Warehouse
operator|.
name|makePartName
argument_list|(
name|partKeys
argument_list|,
name|endPt
operator|.
name|partitionVals
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|partNameForLock
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|username
operator|=
name|user
expr_stmt|;
name|this
operator|.
name|ugi
operator|=
name|ugi
expr_stmt|;
name|this
operator|.
name|endPt
operator|=
name|endPt
expr_stmt|;
name|this
operator|.
name|msClient
operator|=
name|msClient
expr_stmt|;
name|this
operator|.
name|heartbeaterMSClient
operator|=
name|heartbeaterMSClient
expr_stmt|;
name|this
operator|.
name|recordWriter
operator|=
name|recordWriter
expr_stmt|;
name|this
operator|.
name|agentInfo
operator|=
name|agentInfo
expr_stmt|;
name|txnIds
operator|=
name|openTxnImpl
argument_list|(
name|msClient
argument_list|,
name|user
argument_list|,
name|numTxns
argument_list|,
name|ugi
argument_list|)
expr_stmt|;
name|this
operator|.
name|state
operator|=
name|TxnState
operator|.
name|INACTIVE
expr_stmt|;
name|recordWriter
operator|.
name|newBatch
argument_list|(
name|txnIds
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|,
name|txnIds
operator|.
name|get
argument_list|(
name|txnIds
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionBatchUnAvailable
argument_list|(
name|endPt
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionBatchUnAvailable
argument_list|(
name|endPt
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
comment|//clean up if above throws
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|Long
argument_list|>
name|openTxnImpl
parameter_list|(
specifier|final
name|IMetaStoreClient
name|msClient
parameter_list|,
specifier|final
name|String
name|user
parameter_list|,
specifier|final
name|int
name|numTxns
parameter_list|,
name|UserGroupInformation
name|ugi
parameter_list|)
throws|throws
name|IOException
throws|,
name|TException
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
return|return
name|msClient
operator|.
name|openTxns
argument_list|(
name|user
argument_list|,
name|numTxns
argument_list|)
operator|.
name|getTxn_ids
argument_list|()
return|;
block|}
return|return
operator|(
name|List
argument_list|<
name|Long
argument_list|>
operator|)
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Object
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Object
name|run
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|msClient
operator|.
name|openTxns
argument_list|(
name|user
argument_list|,
name|numTxns
argument_list|)
operator|.
name|getTxn_ids
argument_list|()
return|;
block|}
block|}
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
if|if
condition|(
name|txnIds
operator|==
literal|null
operator|||
name|txnIds
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|"{}"
return|;
block|}
return|return
literal|"TxnIds=["
operator|+
name|txnIds
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|+
literal|"..."
operator|+
name|txnIds
operator|.
name|get
argument_list|(
name|txnIds
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|+
literal|"] on endPoint = "
operator|+
name|endPt
return|;
block|}
comment|/**      * Activate the next available transaction in the current transaction batch      * @throws TransactionError failed to switch to next transaction      */
annotation|@
name|Override
specifier|public
name|void
name|beginNextTransaction
parameter_list|()
throws|throws
name|TransactionError
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|beginNextTransactionImpl
argument_list|()
expr_stmt|;
return|return;
block|}
try|try
block|{
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|TransactionError
block|{
name|beginNextTransactionImpl
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
literal|"Failed switching to next Txn as user '"
operator|+
name|username
operator|+
literal|"' in Txn batch :"
operator|+
name|this
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|beginNextTransactionImpl
parameter_list|()
throws|throws
name|TransactionError
block|{
name|state
operator|=
name|TxnState
operator|.
name|INACTIVE
expr_stmt|;
comment|//clear state from previous txn
if|if
condition|(
name|currentTxnIndex
operator|+
literal|1
operator|>=
name|txnIds
operator|.
name|size
argument_list|()
condition|)
throw|throw
operator|new
name|InvalidTrasactionState
argument_list|(
literal|"No more transactions available in"
operator|+
literal|" current batch for end point : "
operator|+
name|endPt
argument_list|)
throw|;
operator|++
name|currentTxnIndex
expr_stmt|;
name|state
operator|=
name|TxnState
operator|.
name|OPEN
expr_stmt|;
name|lockRequest
operator|=
name|createLockRequest
argument_list|(
name|endPt
argument_list|,
name|partNameForLock
argument_list|,
name|username
argument_list|,
name|getCurrentTxnId
argument_list|()
argument_list|,
name|agentInfo
argument_list|)
expr_stmt|;
try|try
block|{
name|LockResponse
name|res
init|=
name|msClient
operator|.
name|lock
argument_list|(
name|lockRequest
argument_list|)
decl_stmt|;
if|if
condition|(
name|res
operator|.
name|getState
argument_list|()
operator|!=
name|LockState
operator|.
name|ACQUIRED
condition|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to acquire lock on "
operator|+
name|endPt
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to acquire lock on "
operator|+
name|endPt
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**      * Get Id of currently open transaction      * @return -1 if there is no open TX      */
annotation|@
name|Override
specifier|public
name|Long
name|getCurrentTxnId
parameter_list|()
block|{
if|if
condition|(
name|currentTxnIndex
operator|>=
literal|0
condition|)
block|{
return|return
name|txnIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
return|;
block|}
return|return
operator|-
literal|1L
return|;
block|}
comment|/**      * get state of current transaction      * @return      */
annotation|@
name|Override
specifier|public
name|TxnState
name|getCurrentTransactionState
parameter_list|()
block|{
return|return
name|state
return|;
block|}
comment|/**      * Remaining transactions are the ones that are not committed or aborted or active.      * Active transaction is not considered part of remaining txns.      * @return number of transactions remaining this batch.      */
annotation|@
name|Override
specifier|public
name|int
name|remainingTransactions
parameter_list|()
block|{
if|if
condition|(
name|currentTxnIndex
operator|>=
literal|0
condition|)
block|{
return|return
name|txnIds
operator|.
name|size
argument_list|()
operator|-
name|currentTxnIndex
operator|-
literal|1
return|;
block|}
return|return
name|txnIds
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**      *  Write record using RecordWriter      * @param record  the data to be written      * @throws StreamingIOFailure I/O failure      * @throws SerializationError  serialization error      * @throws ImpersonationFailed error writing on behalf of proxyUser      * @throws InterruptedException      */
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|byte
index|[]
name|record
parameter_list|)
throws|throws
name|StreamingException
throws|,
name|InterruptedException
block|{
name|write
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|record
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|checkIsClosed
parameter_list|()
throws|throws
name|IllegalStateException
block|{
if|if
condition|(
name|isClosed
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"TransactionBatch "
operator|+
name|toString
argument_list|()
operator|+
literal|" has been closed()"
argument_list|)
throw|;
block|}
block|}
comment|/**      * A transaction batch opens a single HDFS file and writes multiple transaction to it.  If there is any issue      * with the write, we can't continue to write to the same file any as it may be corrupted now (at the tail).      * This ensures that a client can't ignore these failures and continue to write.      */
specifier|private
name|void
name|markDead
parameter_list|(
name|boolean
name|success
parameter_list|)
block|{
if|if
condition|(
name|success
condition|)
block|{
return|return;
block|}
name|isClosed
operator|=
literal|true
expr_stmt|;
comment|//also ensures that heartbeat() is no-op since client is likely doing it async
try|try
block|{
name|abort
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|//abort all remaining txns
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Fatal error on "
operator|+
name|toString
argument_list|()
operator|+
literal|"; cause "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|closeImpl
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Fatal error on "
operator|+
name|toString
argument_list|()
operator|+
literal|"; cause "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      *  Write records using RecordWriter      * @param records collection of rows to be written      * @throws StreamingException  serialization error      * @throws ImpersonationFailed error writing on behalf of proxyUser      * @throws InterruptedException      */
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|records
parameter_list|)
throws|throws
name|StreamingException
throws|,
name|InterruptedException
throws|,
name|ImpersonationFailed
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|writeImpl
argument_list|(
name|records
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|StreamingException
block|{
name|writeImpl
argument_list|(
name|records
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SerializationError
name|ex
parameter_list|)
block|{
comment|//this exception indicates that a {@code record} could not be parsed and the
comment|//caller can decide whether to drop it or send it to dead letter queue.
comment|//rolling back the txn and retrying won't help since the tuple will be exactly the same
comment|//when it's replayed.
name|success
operator|=
literal|true
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
literal|"Failed writing as user '"
operator|+
name|username
operator|+
literal|"' to endPoint :"
operator|+
name|endPt
operator|+
literal|". Transaction Id: "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|writeImpl
parameter_list|(
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|records
parameter_list|)
throws|throws
name|StreamingException
block|{
for|for
control|(
name|byte
index|[]
name|record
range|:
name|records
control|)
block|{
name|recordWriter
operator|.
name|write
argument_list|(
name|getCurrentTxnId
argument_list|()
argument_list|,
name|record
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Commit the currently open transaction      * @throws TransactionError      * @throws StreamingIOFailure  if flushing records failed      * @throws ImpersonationFailed if      * @throws InterruptedException      */
annotation|@
name|Override
specifier|public
name|void
name|commit
parameter_list|()
throws|throws
name|TransactionError
throws|,
name|StreamingException
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
name|checkIsClosed
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|commitImpl
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|StreamingException
block|{
name|commitImpl
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
literal|"Failed committing Txn ID "
operator|+
name|getCurrentTxnId
argument_list|()
operator|+
literal|" as user '"
operator|+
name|username
operator|+
literal|"'on endPoint :"
operator|+
name|endPt
operator|+
literal|". Transaction Id: "
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|markDead
argument_list|(
name|success
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|commitImpl
parameter_list|()
throws|throws
name|TransactionError
throws|,
name|StreamingException
block|{
try|try
block|{
name|recordWriter
operator|.
name|flush
argument_list|()
expr_stmt|;
name|msClient
operator|.
name|commitTxn
argument_list|(
name|txnIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
argument_list|)
expr_stmt|;
name|state
operator|=
name|TxnState
operator|.
name|COMMITTED
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchTxnException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Invalid transaction id : "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TxnAbortedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Aborted transaction cannot be committed"
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to commit transaction"
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**      * Abort the currently open transaction      * @throws TransactionError      */
annotation|@
name|Override
specifier|public
name|void
name|abort
parameter_list|()
throws|throws
name|TransactionError
throws|,
name|StreamingException
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|isClosed
condition|)
block|{
comment|/**          * isDead is only set internally by this class.  {@link #markDead(boolean)} will abort all          * remaining txns, so make this no-op to make sure that a well-behaved client that calls abort()          * error doesn't get misleading errors          */
return|return;
block|}
name|abort
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|abort
parameter_list|(
specifier|final
name|boolean
name|abortAllRemaining
parameter_list|)
throws|throws
name|TransactionError
throws|,
name|StreamingException
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|abortImpl
argument_list|(
name|abortAllRemaining
argument_list|)
expr_stmt|;
return|return;
block|}
try|try
block|{
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|StreamingException
block|{
name|abortImpl
argument_list|(
name|abortAllRemaining
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
literal|"Failed aborting Txn "
operator|+
name|getCurrentTxnId
argument_list|()
operator|+
literal|" as user '"
operator|+
name|username
operator|+
literal|"' on endPoint :"
operator|+
name|endPt
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|abortImpl
parameter_list|(
name|boolean
name|abortAllRemaining
parameter_list|)
throws|throws
name|TransactionError
throws|,
name|StreamingException
block|{
try|try
block|{
if|if
condition|(
name|abortAllRemaining
condition|)
block|{
comment|//when last txn finished (abort/commit) the currentTxnIndex is pointing at that txn
comment|//so we need to start from next one, if any.  Also if batch was created but
comment|//fetchTransactionBatch() was never called, we want to start with first txn
name|int
name|minOpenTxnIndex
init|=
name|Math
operator|.
name|max
argument_list|(
name|currentTxnIndex
operator|+
operator|(
name|state
operator|==
name|TxnState
operator|.
name|ABORTED
operator|||
name|state
operator|==
name|TxnState
operator|.
name|COMMITTED
condition|?
literal|1
else|:
literal|0
operator|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|currentTxnIndex
operator|=
name|minOpenTxnIndex
init|;
name|currentTxnIndex
operator|<
name|txnIds
operator|.
name|size
argument_list|()
condition|;
name|currentTxnIndex
operator|++
control|)
block|{
name|msClient
operator|.
name|rollbackTxn
argument_list|(
name|txnIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|currentTxnIndex
operator|--
expr_stmt|;
comment|//since the loop left it == txnId.size()
block|}
else|else
block|{
if|if
condition|(
name|getCurrentTxnId
argument_list|()
operator|>
literal|0
condition|)
block|{
name|msClient
operator|.
name|rollbackTxn
argument_list|(
name|getCurrentTxnId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|state
operator|=
name|TxnState
operator|.
name|ABORTED
expr_stmt|;
name|recordWriter
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchTxnException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to abort invalid transaction id : "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|TransactionError
argument_list|(
literal|"Unable to abort transaction id : "
operator|+
name|getCurrentTxnId
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|heartbeat
parameter_list|()
throws|throws
name|StreamingException
throws|,
name|HeartBeatFailure
block|{
if|if
condition|(
name|isClosed
condition|)
block|{
return|return;
block|}
name|Long
name|first
init|=
name|txnIds
operator|.
name|get
argument_list|(
name|currentTxnIndex
argument_list|)
decl_stmt|;
name|Long
name|last
init|=
name|txnIds
operator|.
name|get
argument_list|(
name|txnIds
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
try|try
block|{
name|HeartbeatTxnRangeResponse
name|resp
init|=
name|heartbeaterMSClient
operator|.
name|heartbeatTxnRange
argument_list|(
name|first
argument_list|,
name|last
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|resp
operator|.
name|getAborted
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|||
operator|!
name|resp
operator|.
name|getNosuch
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|HeartBeatFailure
argument_list|(
name|resp
operator|.
name|getAborted
argument_list|()
argument_list|,
name|resp
operator|.
name|getNosuch
argument_list|()
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|TException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|StreamingException
argument_list|(
literal|"Failure to heartbeat on ids ("
operator|+
name|first
operator|+
literal|"src/gen/thrift"
operator|+
name|last
operator|+
literal|") on end point : "
operator|+
name|endPt
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|isClosed
return|;
block|}
comment|/**      * Close the TransactionBatch.  This will abort any still open txns in this batch.      * @throws StreamingIOFailure I/O failure when closing transaction batch      */
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|StreamingException
throws|,
name|ImpersonationFailed
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|isClosed
condition|)
block|{
return|return;
block|}
name|isClosed
operator|=
literal|true
expr_stmt|;
name|abortImpl
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|//abort proactively so that we don't wait for timeout
name|closeImpl
argument_list|()
expr_stmt|;
comment|//perhaps we should add a version of RecordWriter.closeBatch(boolean abort) which
comment|//will call RecordUpdater.close(boolean abort)
block|}
specifier|private
name|void
name|closeImpl
parameter_list|()
throws|throws
name|StreamingException
throws|,
name|InterruptedException
block|{
name|state
operator|=
name|TxnState
operator|.
name|INACTIVE
expr_stmt|;
if|if
condition|(
name|ugi
operator|==
literal|null
condition|)
block|{
name|recordWriter
operator|.
name|closeBatch
argument_list|()
expr_stmt|;
return|return;
block|}
try|try
block|{
name|ugi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|StreamingException
block|{
name|recordWriter
operator|.
name|closeBatch
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
try|try
block|{
name|FileSystem
operator|.
name|closeAllForUGI
argument_list|(
name|ugi
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|exception
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not clean up file-system handles for UGI: "
operator|+
name|ugi
argument_list|,
name|exception
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ImpersonationFailed
argument_list|(
literal|"Failed closing Txn Batch as user '"
operator|+
name|username
operator|+
literal|"' on  endPoint :"
operator|+
name|endPt
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|LockRequest
name|createLockRequest
parameter_list|(
specifier|final
name|HiveEndPoint
name|hiveEndPoint
parameter_list|,
name|String
name|partNameForLock
parameter_list|,
name|String
name|user
parameter_list|,
name|long
name|txnId
parameter_list|,
name|String
name|agentInfo
parameter_list|)
block|{
name|LockRequestBuilder
name|rqstBuilder
init|=
name|agentInfo
operator|==
literal|null
condition|?
operator|new
name|LockRequestBuilder
argument_list|()
else|:
operator|new
name|LockRequestBuilder
argument_list|(
name|agentInfo
argument_list|)
decl_stmt|;
name|rqstBuilder
operator|.
name|setUser
argument_list|(
name|user
argument_list|)
expr_stmt|;
name|rqstBuilder
operator|.
name|setTransactionId
argument_list|(
name|txnId
argument_list|)
expr_stmt|;
name|LockComponentBuilder
name|lockCompBuilder
init|=
operator|new
name|LockComponentBuilder
argument_list|()
operator|.
name|setDbName
argument_list|(
name|hiveEndPoint
operator|.
name|database
argument_list|)
operator|.
name|setTableName
argument_list|(
name|hiveEndPoint
operator|.
name|table
argument_list|)
operator|.
name|setShared
argument_list|()
operator|.
name|setOperationType
argument_list|(
name|DataOperationType
operator|.
name|INSERT
argument_list|)
decl_stmt|;
if|if
condition|(
name|partNameForLock
operator|!=
literal|null
operator|&&
operator|!
name|partNameForLock
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|lockCompBuilder
operator|.
name|setPartitionName
argument_list|(
name|partNameForLock
argument_list|)
expr_stmt|;
block|}
name|rqstBuilder
operator|.
name|addLockComponent
argument_list|(
name|lockCompBuilder
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|rqstBuilder
operator|.
name|build
argument_list|()
return|;
block|}
block|}
comment|// class TransactionBatchImpl
specifier|static
name|HiveConf
name|createHiveConf
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
parameter_list|,
name|String
name|metaStoreUri
parameter_list|)
block|{
name|HiveConf
name|conf
init|=
operator|new
name|HiveConf
argument_list|(
name|clazz
argument_list|)
decl_stmt|;
if|if
condition|(
name|metaStoreUri
operator|!=
literal|null
condition|)
block|{
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREURIS
argument_list|,
name|metaStoreUri
argument_list|)
expr_stmt|;
block|}
name|HiveEndPoint
operator|.
name|overrideConfSettings
argument_list|(
name|conf
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
specifier|private
specifier|static
name|void
name|overrideConfSettings
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_TXN_MANAGER
argument_list|,
literal|"org.apache.hadoop.hive.ql.lockmgr.DbTxnManager"
argument_list|)
expr_stmt|;
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SUPPORT_CONCURRENCY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_EXECUTE_SET_UGI
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// Avoids creating Tez Client sessions internally as it takes much longer currently
name|setHiveConf
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_EXECUTION_ENGINE
argument_list|,
literal|"mr"
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|setHiveConf
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|HiveConf
operator|.
name|ConfVars
name|var
parameter_list|,
name|String
name|value
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overriding HiveConf setting : "
operator|+
name|var
operator|+
literal|" = "
operator|+
name|value
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setVar
argument_list|(
name|var
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|setHiveConf
parameter_list|(
name|HiveConf
name|conf
parameter_list|,
name|HiveConf
operator|.
name|ConfVars
name|var
parameter_list|,
name|boolean
name|value
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overriding HiveConf setting : "
operator|+
name|var
operator|+
literal|" = "
operator|+
name|value
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setBoolVar
argument_list|(
name|var
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|// class HiveEndPoint
end_comment

end_unit

