begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|pig
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|RecordWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|DefaultHCatRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|HCatRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatFieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatFieldSchema
operator|.
name|Type
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|ResourceSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|ResourceStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|StoreFunc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|StoreMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|backend
operator|.
name|BackendException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|backend
operator|.
name|executionengine
operator|.
name|ExecException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|DataBag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|DataType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|Tuple
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|logicalLayer
operator|.
name|FrontendException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|logicalLayer
operator|.
name|schema
operator|.
name|Schema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|logicalLayer
operator|.
name|schema
operator|.
name|Schema
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|util
operator|.
name|ObjectSerializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|util
operator|.
name|UDFContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|util
operator|.
name|Utils
import|;
end_import

begin_comment
comment|/**  * Base class for HCatStorer and HCatEximStorer  *  */
end_comment

begin_class
specifier|public
specifier|abstract
class|class
name|HCatBaseStorer
extends|extends
name|StoreFunc
implements|implements
name|StoreMetadata
block|{
comment|/**    *    */
specifier|protected
specifier|static
specifier|final
name|String
name|COMPUTED_OUTPUT_SCHEMA
init|=
literal|"hcat.output.schema"
decl_stmt|;
specifier|protected
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|partitionKeys
decl_stmt|;
specifier|protected
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitions
decl_stmt|;
specifier|protected
name|Schema
name|pigSchema
decl_stmt|;
specifier|private
name|RecordWriter
argument_list|<
name|WritableComparable
argument_list|<
name|?
argument_list|>
argument_list|,
name|HCatRecord
argument_list|>
name|writer
decl_stmt|;
specifier|protected
name|HCatSchema
name|computedSchema
decl_stmt|;
specifier|protected
specifier|static
specifier|final
name|String
name|PIG_SCHEMA
init|=
literal|"hcat.pig.store.schema"
decl_stmt|;
specifier|protected
name|String
name|sign
decl_stmt|;
specifier|public
name|HCatBaseStorer
parameter_list|(
name|String
name|partSpecs
parameter_list|,
name|String
name|schema
parameter_list|)
throws|throws
name|Exception
block|{
name|partitionKeys
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|partitions
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
if|if
condition|(
name|partSpecs
operator|!=
literal|null
operator|&&
operator|!
name|partSpecs
operator|.
name|trim
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
index|[]
name|partKVPs
init|=
name|partSpecs
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|partKVP
range|:
name|partKVPs
control|)
block|{
name|String
index|[]
name|partKV
init|=
name|partKVP
operator|.
name|split
argument_list|(
literal|"="
argument_list|)
decl_stmt|;
if|if
condition|(
name|partKV
operator|.
name|length
operator|==
literal|2
condition|)
block|{
name|String
name|partKey
init|=
name|partKV
index|[
literal|0
index|]
operator|.
name|trim
argument_list|()
decl_stmt|;
name|partitionKeys
operator|.
name|add
argument_list|(
name|partKey
argument_list|)
expr_stmt|;
name|partitions
operator|.
name|put
argument_list|(
name|partKey
argument_list|,
name|partKV
index|[
literal|1
index|]
operator|.
name|trim
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Invalid partition column specification. "
operator|+
name|partSpecs
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|schema
operator|!=
literal|null
condition|)
block|{
name|pigSchema
operator|=
name|Utils
operator|.
name|getSchemaFromString
argument_list|(
name|schema
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|checkSchema
parameter_list|(
name|ResourceSchema
name|resourceSchema
parameter_list|)
throws|throws
name|IOException
block|{
comment|/*  Schema provided by user and the schema computed by Pig      * at the time of calling store must match.      */
name|Schema
name|runtimeSchema
init|=
name|Schema
operator|.
name|getPigSchema
argument_list|(
name|resourceSchema
argument_list|)
decl_stmt|;
if|if
condition|(
name|pigSchema
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|Schema
operator|.
name|equals
argument_list|(
name|runtimeSchema
argument_list|,
name|pigSchema
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Schema provided in store statement doesn't match with the Schema"
operator|+
literal|"returned by Pig run-time. Schema provided in HCatStorer: "
operator|+
name|pigSchema
operator|.
name|toString
argument_list|()
operator|+
literal|" Schema received from Pig runtime: "
operator|+
name|runtimeSchema
operator|.
name|toString
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|pigSchema
operator|=
name|runtimeSchema
expr_stmt|;
block|}
name|UDFContext
operator|.
name|getUDFContext
argument_list|()
operator|.
name|getUDFProperties
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|,
operator|new
name|String
index|[]
block|{
name|sign
block|}
argument_list|)
operator|.
name|setProperty
argument_list|(
name|PIG_SCHEMA
argument_list|,
name|ObjectSerializer
operator|.
name|serialize
argument_list|(
name|pigSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/** Constructs HCatSchema from pigSchema. Passed tableSchema is the existing    * schema of the table in metastore.    */
specifier|protected
name|HCatSchema
name|convertPigSchemaToHCatSchema
parameter_list|(
name|Schema
name|pigSchema
parameter_list|,
name|HCatSchema
name|tableSchema
parameter_list|)
throws|throws
name|FrontendException
block|{
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|fieldSchemas
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
name|pigSchema
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fSchema
range|:
name|pigSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|byte
name|type
init|=
name|fSchema
operator|.
name|type
decl_stmt|;
name|HCatFieldSchema
name|hcatFSchema
decl_stmt|;
try|try
block|{
comment|// Find out if we need to throw away the tuple or not.
if|if
condition|(
name|type
operator|==
name|DataType
operator|.
name|BAG
operator|&&
name|removeTupleFromBag
argument_list|(
name|tableSchema
argument_list|,
name|fSchema
argument_list|)
condition|)
block|{
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|arrFields
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|arrFields
operator|.
name|add
argument_list|(
name|getHCatFSFromPigFS
argument_list|(
name|fSchema
operator|.
name|schema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
argument_list|,
name|tableSchema
argument_list|)
argument_list|)
expr_stmt|;
name|hcatFSchema
operator|=
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|ARRAY
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|arrFields
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hcatFSchema
operator|=
name|getHCatFSFromPigFS
argument_list|(
name|fSchema
argument_list|,
name|tableSchema
argument_list|)
expr_stmt|;
block|}
name|fieldSchemas
operator|.
name|add
argument_list|(
name|hcatFSchema
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|HCatException
name|he
parameter_list|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
name|he
operator|.
name|getMessage
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|,
name|he
argument_list|)
throw|;
block|}
block|}
return|return
operator|new
name|HCatSchema
argument_list|(
name|fieldSchemas
argument_list|)
return|;
block|}
specifier|private
name|void
name|validateUnNested
parameter_list|(
name|Schema
name|innerSchema
parameter_list|)
throws|throws
name|FrontendException
block|{
for|for
control|(
name|FieldSchema
name|innerField
range|:
name|innerSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|validateAlias
argument_list|(
name|innerField
operator|.
name|alias
argument_list|)
expr_stmt|;
if|if
condition|(
name|DataType
operator|.
name|isComplex
argument_list|(
name|innerField
operator|.
name|type
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Complex types cannot be nested. "
operator|+
name|innerField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|boolean
name|removeTupleFromBag
parameter_list|(
name|HCatSchema
name|tableSchema
parameter_list|,
name|FieldSchema
name|bagFieldSchema
parameter_list|)
throws|throws
name|HCatException
block|{
name|String
name|colName
init|=
name|bagFieldSchema
operator|.
name|alias
decl_stmt|;
for|for
control|(
name|HCatFieldSchema
name|field
range|:
name|tableSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
if|if
condition|(
name|colName
operator|.
name|equalsIgnoreCase
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
operator|(
name|field
operator|.
name|getArrayElementSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|STRUCT
operator|)
condition|?
literal|false
else|:
literal|true
return|;
block|}
block|}
comment|// Column was not found in table schema. Its a new column
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|tupSchema
init|=
name|bagFieldSchema
operator|.
name|schema
operator|.
name|getFields
argument_list|()
decl_stmt|;
return|return
operator|(
name|tupSchema
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|&&
name|tupSchema
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|==
literal|null
operator|)
condition|?
literal|true
else|:
literal|false
return|;
block|}
specifier|private
name|HCatFieldSchema
name|getHCatFSFromPigFS
parameter_list|(
name|FieldSchema
name|fSchema
parameter_list|,
name|HCatSchema
name|hcatTblSchema
parameter_list|)
throws|throws
name|FrontendException
throws|,
name|HCatException
block|{
name|byte
name|type
init|=
name|fSchema
operator|.
name|type
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|DataType
operator|.
name|CHARARRAY
case|:
case|case
name|DataType
operator|.
name|BIGCHARARRAY
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|INTEGER
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|INT
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|LONG
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|BIGINT
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|FLOAT
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|FLOAT
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|DOUBLE
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|DOUBLE
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|BAG
case|:
name|Schema
name|bagSchema
init|=
name|fSchema
operator|.
name|schema
decl_stmt|;
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|arrFields
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|arrFields
operator|.
name|add
argument_list|(
name|getHCatFSFromPigFS
argument_list|(
name|bagSchema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
argument_list|,
name|hcatTblSchema
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|ARRAY
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|arrFields
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
case|case
name|DataType
operator|.
name|TUPLE
case|:
name|List
argument_list|<
name|String
argument_list|>
name|fieldNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|hcatFSs
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|fSchema
operator|.
name|schema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|fieldNames
operator|.
name|add
argument_list|(
name|fieldSchema
operator|.
name|alias
argument_list|)
expr_stmt|;
name|hcatFSs
operator|.
name|add
argument_list|(
name|getHCatFSFromPigFS
argument_list|(
name|fieldSchema
argument_list|,
name|hcatTblSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|STRUCT
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|hcatFSs
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
case|case
name|DataType
operator|.
name|MAP
case|:
block|{
comment|// Pig's schema contain no type information about map's keys and
comment|// values. So, if its a new column assume<string,string> if its existing
comment|// return whatever is contained in the existing column.
name|HCatFieldSchema
name|mapField
init|=
name|getTableCol
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|hcatTblSchema
argument_list|)
decl_stmt|;
name|HCatFieldSchema
name|valFS
decl_stmt|;
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|valFSList
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapField
operator|!=
literal|null
condition|)
block|{
name|Type
name|mapValType
init|=
name|mapField
operator|.
name|getMapValueSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getType
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|mapValType
condition|)
block|{
case|case
name|STRING
case|:
case|case
name|BIGINT
case|:
case|case
name|INT
case|:
case|case
name|FLOAT
case|:
case|case
name|DOUBLE
case|:
name|valFS
operator|=
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|mapValType
argument_list|,
literal|null
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Only pig primitive types are supported as map value types."
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
name|valFSList
operator|.
name|add
argument_list|(
name|valFS
argument_list|)
expr_stmt|;
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|MAP
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|valFSList
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
block|}
comment|// Column not found in target table. Its a new column. Its schema is map<string,string>
name|valFS
operator|=
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|valFSList
operator|.
name|add
argument_list|(
name|valFS
argument_list|)
expr_stmt|;
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|MAP
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|valFSList
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
block|}
default|default:
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Unsupported type: "
operator|+
name|type
operator|+
literal|"  in Pig's schema"
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|prepareToWrite
parameter_list|(
name|RecordWriter
name|writer
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|writer
operator|=
name|writer
expr_stmt|;
name|computedSchema
operator|=
operator|(
name|HCatSchema
operator|)
name|ObjectSerializer
operator|.
name|deserialize
argument_list|(
name|UDFContext
operator|.
name|getUDFContext
argument_list|()
operator|.
name|getUDFProperties
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|,
operator|new
name|String
index|[]
block|{
name|sign
block|}
argument_list|)
operator|.
name|getProperty
argument_list|(
name|COMPUTED_OUTPUT_SCHEMA
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|putNext
parameter_list|(
name|Tuple
name|tuple
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Object
argument_list|>
name|outgoing
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
name|tuple
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|HCatFieldSchema
name|fSchema
range|:
name|computedSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|outgoing
operator|.
name|add
argument_list|(
name|getJavaObj
argument_list|(
name|tuple
operator|.
name|get
argument_list|(
name|i
operator|++
argument_list|)
argument_list|,
name|fSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|writer
operator|.
name|write
argument_list|(
literal|null
argument_list|,
operator|new
name|DefaultHCatRecord
argument_list|(
name|outgoing
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|BackendException
argument_list|(
literal|"Error while writing tuple: "
operator|+
name|tuple
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|Object
name|getJavaObj
parameter_list|(
name|Object
name|pigObj
parameter_list|,
name|HCatFieldSchema
name|hcatFS
parameter_list|)
throws|throws
name|ExecException
throws|,
name|HCatException
block|{
comment|// The real work-horse. Spend time and energy in this method if there is
comment|// need to keep HCatStorer lean and go fast.
name|Type
name|type
init|=
name|hcatFS
operator|.
name|getType
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|STRUCT
case|:
comment|// Unwrap the tuple.
return|return
operator|(
operator|(
name|Tuple
operator|)
name|pigObj
operator|)
operator|.
name|getAll
argument_list|()
return|;
comment|//        Tuple innerTup = (Tuple)pigObj;
comment|//
comment|//      List<Object> innerList = new ArrayList<Object>(innerTup.size());
comment|//      int i = 0;
comment|//      for(HCatTypeInfo structFieldTypeInfo : typeInfo.getAllStructFieldTypeInfos()){
comment|//        innerList.add(getJavaObj(innerTup.get(i++), structFieldTypeInfo));
comment|//      }
comment|//      return innerList;
case|case
name|ARRAY
case|:
comment|// Unwrap the bag.
name|DataBag
name|pigBag
init|=
operator|(
name|DataBag
operator|)
name|pigObj
decl_stmt|;
name|HCatFieldSchema
name|tupFS
init|=
name|hcatFS
operator|.
name|getArrayElementSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|boolean
name|needTuple
init|=
name|tupFS
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|STRUCT
decl_stmt|;
name|List
argument_list|<
name|Object
argument_list|>
name|bagContents
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
operator|(
name|int
operator|)
name|pigBag
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Tuple
argument_list|>
name|bagItr
init|=
name|pigBag
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|bagItr
operator|.
name|hasNext
argument_list|()
condition|)
block|{
comment|// If there is only one element in tuple contained in bag, we throw away the tuple.
name|bagContents
operator|.
name|add
argument_list|(
name|needTuple
condition|?
name|getJavaObj
argument_list|(
name|bagItr
operator|.
name|next
argument_list|()
argument_list|,
name|tupFS
argument_list|)
else|:
name|bagItr
operator|.
name|next
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|bagContents
return|;
comment|//    case MAP:
comment|//     Map<String,DataByteArray> pigMap = (Map<String,DataByteArray>)pigObj;
comment|//     Map<String,Long> typeMap = new HashMap<String, Long>();
comment|//     for(Entry<String, DataByteArray> entry: pigMap.entrySet()){
comment|//       typeMap.put(entry.getKey(), new Long(entry.getValue().toString()));
comment|//     }
comment|//     return typeMap;
default|default:
return|return
name|pigObj
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|relToAbsPathForStoreLocation
parameter_list|(
name|String
name|location
parameter_list|,
name|Path
name|curDir
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Need to necessarily override this method since default impl assumes HDFS
comment|// based location string.
return|return
name|location
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setStoreFuncUDFContextSignature
parameter_list|(
name|String
name|signature
parameter_list|)
block|{
name|sign
operator|=
name|signature
expr_stmt|;
block|}
specifier|protected
name|void
name|doSchemaValidations
parameter_list|(
name|Schema
name|pigSchema
parameter_list|,
name|HCatSchema
name|tblSchema
parameter_list|)
throws|throws
name|FrontendException
throws|,
name|HCatException
block|{
comment|// Iterate through all the elements in Pig Schema and do validations as
comment|// dictated by semantics, consult HCatSchema of table when need be.
for|for
control|(
name|FieldSchema
name|pigField
range|:
name|pigSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|byte
name|type
init|=
name|pigField
operator|.
name|type
decl_stmt|;
name|String
name|alias
init|=
name|pigField
operator|.
name|alias
decl_stmt|;
name|validateAlias
argument_list|(
name|alias
argument_list|)
expr_stmt|;
name|HCatFieldSchema
name|hcatField
init|=
name|getTableCol
argument_list|(
name|alias
argument_list|,
name|tblSchema
argument_list|)
decl_stmt|;
if|if
condition|(
name|DataType
operator|.
name|isComplex
argument_list|(
name|type
argument_list|)
condition|)
block|{
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|DataType
operator|.
name|MAP
case|:
if|if
condition|(
name|hcatField
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|hcatField
operator|.
name|getMapKeyType
argument_list|()
operator|!=
name|Type
operator|.
name|STRING
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Key Type of map must be String "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
if|if
condition|(
name|hcatField
operator|.
name|getMapValueSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|isComplex
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Value type of map cannot be complex"
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
break|break;
case|case
name|DataType
operator|.
name|BAG
case|:
comment|// Only map is allowed as complex type in tuples inside bag.
for|for
control|(
name|FieldSchema
name|innerField
range|:
name|pigField
operator|.
name|schema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|.
name|getFields
argument_list|()
control|)
block|{
if|if
condition|(
name|innerField
operator|.
name|type
operator|==
name|DataType
operator|.
name|BAG
operator|||
name|innerField
operator|.
name|type
operator|==
name|DataType
operator|.
name|TUPLE
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Complex types cannot be nested. "
operator|+
name|innerField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
name|validateAlias
argument_list|(
name|innerField
operator|.
name|alias
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hcatField
operator|!=
literal|null
condition|)
block|{
comment|// Do the same validation for HCatSchema.
name|HCatFieldSchema
name|arrayFieldScehma
init|=
name|hcatField
operator|.
name|getArrayElementSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|Type
name|hType
init|=
name|arrayFieldScehma
operator|.
name|getType
argument_list|()
decl_stmt|;
if|if
condition|(
name|hType
operator|==
name|Type
operator|.
name|STRUCT
condition|)
block|{
for|for
control|(
name|HCatFieldSchema
name|structFieldInBag
range|:
name|arrayFieldScehma
operator|.
name|getStructSubSchema
argument_list|()
operator|.
name|getFields
argument_list|()
control|)
block|{
if|if
condition|(
name|structFieldInBag
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|STRUCT
operator|||
name|structFieldInBag
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|ARRAY
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Nested Complex types not allowed "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|hType
operator|==
name|Type
operator|.
name|MAP
condition|)
block|{
if|if
condition|(
name|arrayFieldScehma
operator|.
name|getMapKeyType
argument_list|()
operator|!=
name|Type
operator|.
name|STRING
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Key Type of map must be String "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
if|if
condition|(
name|arrayFieldScehma
operator|.
name|getMapValueSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|isComplex
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Value type of map cannot be complex "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|hType
operator|==
name|Type
operator|.
name|ARRAY
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Arrays cannot contain array within it. "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
break|break;
case|case
name|DataType
operator|.
name|TUPLE
case|:
name|validateUnNested
argument_list|(
name|pigField
operator|.
name|schema
argument_list|)
expr_stmt|;
if|if
condition|(
name|hcatField
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HCatFieldSchema
name|structFieldSchema
range|:
name|hcatField
operator|.
name|getStructSubSchema
argument_list|()
operator|.
name|getFields
argument_list|()
control|)
block|{
if|if
condition|(
name|structFieldSchema
operator|.
name|isComplex
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Nested Complex types are not allowed."
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
break|break;
default|default:
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Internal Error."
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
for|for
control|(
name|HCatFieldSchema
name|hcatField
range|:
name|tblSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
comment|// We dont do type promotion/demotion.
name|Type
name|hType
init|=
name|hcatField
operator|.
name|getType
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|hType
condition|)
block|{
case|case
name|SMALLINT
case|:
case|case
name|TINYINT
case|:
case|case
name|BOOLEAN
case|:
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Incompatible type found in hcat table schema: "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|void
name|validateAlias
parameter_list|(
name|String
name|alias
parameter_list|)
throws|throws
name|FrontendException
block|{
if|if
condition|(
name|alias
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Column name for a field is not specified. Please provide the full schema as an argument to HCatStorer."
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
if|if
condition|(
name|alias
operator|.
name|matches
argument_list|(
literal|".*[A-Z]+.*"
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Column names should all be in lowercase. Invalid name found: "
operator|+
name|alias
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
comment|// Finds column by name in HCatSchema, if not found returns null.
specifier|private
name|HCatFieldSchema
name|getTableCol
parameter_list|(
name|String
name|alias
parameter_list|,
name|HCatSchema
name|tblSchema
parameter_list|)
block|{
for|for
control|(
name|HCatFieldSchema
name|hcatField
range|:
name|tblSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
if|if
condition|(
name|hcatField
operator|.
name|getName
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|alias
argument_list|)
condition|)
block|{
return|return
name|hcatField
return|;
block|}
block|}
comment|// Its a new column
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|cleanupOnFailure
parameter_list|(
name|String
name|location
parameter_list|,
name|Job
name|job
parameter_list|)
throws|throws
name|IOException
block|{
comment|// No-op.
block|}
annotation|@
name|Override
specifier|public
name|void
name|storeStatistics
parameter_list|(
name|ResourceStatistics
name|stats
parameter_list|,
name|String
name|arg1
parameter_list|,
name|Job
name|job
parameter_list|)
throws|throws
name|IOException
block|{   }
block|}
end_class

end_unit

