begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStoreClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|ErrorType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatSchema
import|;
end_import

begin_comment
comment|/**  * The Class which handles querying the metadata server using the MetaStoreClient. The list of  * partitions matching the partition filter is fetched from the server and the information is  * serialized and written into the JobContext configuration. The inputInfo is also updated with  * info required in the client process context.  */
end_comment

begin_class
specifier|public
class|class
name|InitializeInput
block|{
comment|/** The prefix for keys used for storage driver arguments */
specifier|static
specifier|final
name|String
name|HCAT_KEY_PREFIX
init|=
literal|"hcat."
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|HiveConf
name|hiveConf
init|=
operator|new
name|HiveConf
argument_list|(
name|HCatInputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
name|HiveMetaStoreClient
name|createHiveMetaClient
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|HCatTableInfo
name|inputInfo
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
name|inputInfo
operator|.
name|getServerUri
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|hiveConf
operator|.
name|setBoolean
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_USE_THRIFT_SASL
operator|.
name|varname
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_KERBEROS_PRINCIPAL
operator|.
name|varname
argument_list|,
name|inputInfo
operator|.
name|getServerKerberosPrincipal
argument_list|()
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
literal|"hive.metastore.local"
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|hiveConf
operator|.
name|set
argument_list|(
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTOREURIS
operator|.
name|varname
argument_list|,
name|inputInfo
operator|.
name|getServerUri
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|HiveMetaStoreClient
argument_list|(
name|hiveConf
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Set the input to use for the Job. This queries the metadata server with the specified partition predicates,    * gets the matching partitions, puts the information in the configuration object.    * @param job the job object    * @param inputInfo the hcat table input info    * @throws Exception    */
specifier|public
specifier|static
name|void
name|setInput
parameter_list|(
name|Job
name|job
parameter_list|,
name|HCatTableInfo
name|inputInfo
parameter_list|)
throws|throws
name|Exception
block|{
comment|//* Create and initialize an JobInfo object
comment|//* Serialize the JobInfo and save in the Job's Configuration object
name|HiveMetaStoreClient
name|client
init|=
literal|null
decl_stmt|;
try|try
block|{
name|client
operator|=
name|createHiveMetaClient
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|inputInfo
argument_list|)
expr_stmt|;
name|Table
name|table
init|=
name|client
operator|.
name|getTable
argument_list|(
name|inputInfo
operator|.
name|getDatabaseName
argument_list|()
argument_list|,
name|inputInfo
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|HCatSchema
name|tableSchema
init|=
name|HCatUtil
operator|.
name|getTableSchemaWithPtnCols
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|PartInfo
argument_list|>
name|partInfoList
init|=
operator|new
name|ArrayList
argument_list|<
name|PartInfo
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
comment|//Partitioned table
name|List
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
name|client
operator|.
name|listPartitionsByFilter
argument_list|(
name|inputInfo
operator|.
name|getDatabaseName
argument_list|()
argument_list|,
name|inputInfo
operator|.
name|getTableName
argument_list|()
argument_list|,
name|inputInfo
operator|.
name|getFilter
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
comment|// Default to 100,000 partitions if hive.metastore.maxpartition is not defined
name|int
name|maxPart
init|=
name|hiveConf
operator|.
name|getInt
argument_list|(
literal|"hcat.metastore.maxpartitions"
argument_list|,
literal|100000
argument_list|)
decl_stmt|;
if|if
condition|(
name|parts
operator|!=
literal|null
operator|&&
name|parts
operator|.
name|size
argument_list|()
operator|>
name|maxPart
condition|)
block|{
throw|throw
operator|new
name|HCatException
argument_list|(
name|ErrorType
operator|.
name|ERROR_EXCEED_MAXPART
argument_list|,
literal|"total number of partitions is "
operator|+
name|parts
operator|.
name|size
argument_list|()
argument_list|)
throw|;
block|}
comment|// populate partition info
for|for
control|(
name|Partition
name|ptn
range|:
name|parts
control|)
block|{
name|PartInfo
name|partInfo
init|=
name|extractPartInfo
argument_list|(
name|ptn
operator|.
name|getSd
argument_list|()
argument_list|,
name|ptn
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
name|partInfo
operator|.
name|setPartitionValues
argument_list|(
name|createPtnKeyValueMap
argument_list|(
name|table
argument_list|,
name|ptn
argument_list|)
argument_list|)
expr_stmt|;
name|partInfoList
operator|.
name|add
argument_list|(
name|partInfo
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|//Non partitioned table
name|PartInfo
name|partInfo
init|=
name|extractPartInfo
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
decl_stmt|;
name|partInfo
operator|.
name|setPartitionValues
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|partInfoList
operator|.
name|add
argument_list|(
name|partInfo
argument_list|)
expr_stmt|;
block|}
name|JobInfo
name|hcatJobInfo
init|=
operator|new
name|JobInfo
argument_list|(
name|inputInfo
argument_list|,
name|tableSchema
argument_list|,
name|partInfoList
argument_list|)
decl_stmt|;
name|inputInfo
operator|.
name|setJobInfo
argument_list|(
name|hcatJobInfo
argument_list|)
expr_stmt|;
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|set
argument_list|(
name|HCatConstants
operator|.
name|HCAT_KEY_JOB_INFO
argument_list|,
name|HCatUtil
operator|.
name|serialize
argument_list|(
name|hcatJobInfo
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|client
operator|!=
literal|null
condition|)
block|{
name|client
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|createPtnKeyValueMap
parameter_list|(
name|Table
name|table
parameter_list|,
name|Partition
name|ptn
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|values
init|=
name|ptn
operator|.
name|getValues
argument_list|()
decl_stmt|;
if|if
condition|(
name|values
operator|.
name|size
argument_list|()
operator|!=
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Partition values in partition inconsistent with table definition, table "
operator|+
name|table
operator|.
name|getTableName
argument_list|()
operator|+
literal|" has "
operator|+
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|" partition keys, partition has "
operator|+
name|values
operator|.
name|size
argument_list|()
operator|+
literal|"partition values"
argument_list|)
throw|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|ptnKeyValues
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|FieldSchema
name|schema
range|:
name|table
operator|.
name|getPartitionKeys
argument_list|()
control|)
block|{
comment|// CONCERN : the way this mapping goes, the order *needs* to be preserved for table.getPartitionKeys() and ptn.getValues()
name|ptnKeyValues
operator|.
name|put
argument_list|(
name|schema
operator|.
name|getName
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|values
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|i
operator|++
expr_stmt|;
block|}
return|return
name|ptnKeyValues
return|;
block|}
specifier|static
name|PartInfo
name|extractPartInfo
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
throws|throws
name|IOException
block|{
name|HCatSchema
name|schema
init|=
name|HCatUtil
operator|.
name|extractSchemaFromStorageDescriptor
argument_list|(
name|sd
argument_list|)
decl_stmt|;
name|String
name|inputStorageDriverClass
init|=
literal|null
decl_stmt|;
name|Properties
name|hcatProperties
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
if|if
condition|(
name|parameters
operator|.
name|containsKey
argument_list|(
name|HCatConstants
operator|.
name|HCAT_ISD_CLASS
argument_list|)
condition|)
block|{
name|inputStorageDriverClass
operator|=
name|parameters
operator|.
name|get
argument_list|(
name|HCatConstants
operator|.
name|HCAT_ISD_CLASS
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// attempt to default to RCFile if the storage descriptor says it's an RCFile
if|if
condition|(
operator|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|.
name|equals
argument_list|(
name|HCatConstants
operator|.
name|HIVE_RCFILE_IF_CLASS
argument_list|)
operator|)
condition|)
block|{
name|inputStorageDriverClass
operator|=
name|HCatConstants
operator|.
name|HCAT_RCFILE_ISD_CLASS
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No input storage driver classname found, cannot read partition"
argument_list|)
throw|;
block|}
block|}
for|for
control|(
name|String
name|key
range|:
name|parameters
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|key
operator|.
name|startsWith
argument_list|(
name|HCAT_KEY_PREFIX
argument_list|)
condition|)
block|{
name|hcatProperties
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|parameters
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|PartInfo
argument_list|(
name|schema
argument_list|,
name|inputStorageDriverClass
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|,
name|hcatProperties
argument_list|)
return|;
block|}
specifier|static
name|StorerInfo
name|extractStorerInfo
parameter_list|(
name|StorageDescriptor
name|sd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|properties
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|inputSDClass
decl_stmt|,
name|outputSDClass
decl_stmt|;
if|if
condition|(
name|properties
operator|.
name|containsKey
argument_list|(
name|HCatConstants
operator|.
name|HCAT_ISD_CLASS
argument_list|)
condition|)
block|{
name|inputSDClass
operator|=
name|properties
operator|.
name|get
argument_list|(
name|HCatConstants
operator|.
name|HCAT_ISD_CLASS
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// attempt to default to RCFile if the storage descriptor says it's an RCFile
if|if
condition|(
operator|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|sd
operator|.
name|getInputFormat
argument_list|()
operator|.
name|equals
argument_list|(
name|HCatConstants
operator|.
name|HIVE_RCFILE_IF_CLASS
argument_list|)
operator|)
condition|)
block|{
name|inputSDClass
operator|=
name|HCatConstants
operator|.
name|HCAT_RCFILE_ISD_CLASS
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No input storage driver classname found for table, cannot write partition"
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|properties
operator|.
name|containsKey
argument_list|(
name|HCatConstants
operator|.
name|HCAT_OSD_CLASS
argument_list|)
condition|)
block|{
name|outputSDClass
operator|=
name|properties
operator|.
name|get
argument_list|(
name|HCatConstants
operator|.
name|HCAT_OSD_CLASS
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// attempt to default to RCFile if the storage descriptor says it's an RCFile
if|if
condition|(
operator|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|sd
operator|.
name|getOutputFormat
argument_list|()
operator|.
name|equals
argument_list|(
name|HCatConstants
operator|.
name|HIVE_RCFILE_OF_CLASS
argument_list|)
operator|)
condition|)
block|{
name|outputSDClass
operator|=
name|HCatConstants
operator|.
name|HCAT_RCFILE_OSD_CLASS
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No output storage driver classname found for table, cannot write partition"
argument_list|)
throw|;
block|}
block|}
name|Properties
name|hcatProperties
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|key
range|:
name|properties
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|key
operator|.
name|startsWith
argument_list|(
name|HCAT_KEY_PREFIX
argument_list|)
condition|)
block|{
name|hcatProperties
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|properties
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|StorerInfo
argument_list|(
name|inputSDClass
argument_list|,
name|outputSDClass
argument_list|,
name|hcatProperties
argument_list|)
return|;
block|}
block|}
end_class

end_unit

