begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|pig
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|RecordWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|common
operator|.
name|HCatException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|DefaultHCatRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|HCatRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatFieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatFieldSchema
operator|.
name|Type
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hcatalog
operator|.
name|data
operator|.
name|schema
operator|.
name|HCatSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|ResourceSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|ResourceStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|StoreFunc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|StoreMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|backend
operator|.
name|BackendException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|DataBag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|DataByteArray
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|DataType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|data
operator|.
name|Tuple
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|logicalLayer
operator|.
name|FrontendException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|logicalLayer
operator|.
name|schema
operator|.
name|Schema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|logicalLayer
operator|.
name|schema
operator|.
name|Schema
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|util
operator|.
name|ObjectSerializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|util
operator|.
name|UDFContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|pig
operator|.
name|impl
operator|.
name|util
operator|.
name|Utils
import|;
end_import

begin_comment
comment|/**  * Base class for HCatStorer and HCatEximStorer  *  * @deprecated Use/modify {@link org.apache.hive.hcatalog.pig.HCatBaseStorer} instead  */
end_comment

begin_class
specifier|abstract
class|class
name|HCatBaseStorer
extends|extends
name|StoreFunc
implements|implements
name|StoreMetadata
block|{
specifier|private
specifier|static
specifier|final
name|List
argument_list|<
name|Type
argument_list|>
name|SUPPORTED_INTEGER_CONVERSIONS
init|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|Type
operator|.
name|TINYINT
argument_list|,
name|Type
operator|.
name|SMALLINT
argument_list|,
name|Type
operator|.
name|INT
argument_list|)
decl_stmt|;
specifier|protected
specifier|static
specifier|final
name|String
name|COMPUTED_OUTPUT_SCHEMA
init|=
literal|"hcat.output.schema"
decl_stmt|;
specifier|protected
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|partitionKeys
decl_stmt|;
specifier|protected
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partitions
decl_stmt|;
specifier|protected
name|Schema
name|pigSchema
decl_stmt|;
specifier|private
name|RecordWriter
argument_list|<
name|WritableComparable
argument_list|<
name|?
argument_list|>
argument_list|,
name|HCatRecord
argument_list|>
name|writer
decl_stmt|;
specifier|protected
name|HCatSchema
name|computedSchema
decl_stmt|;
specifier|protected
specifier|static
specifier|final
name|String
name|PIG_SCHEMA
init|=
literal|"hcat.pig.store.schema"
decl_stmt|;
specifier|protected
name|String
name|sign
decl_stmt|;
specifier|public
name|HCatBaseStorer
parameter_list|(
name|String
name|partSpecs
parameter_list|,
name|String
name|schema
parameter_list|)
throws|throws
name|Exception
block|{
name|partitionKeys
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|partitions
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
if|if
condition|(
name|partSpecs
operator|!=
literal|null
operator|&&
operator|!
name|partSpecs
operator|.
name|trim
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
index|[]
name|partKVPs
init|=
name|partSpecs
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|partKVP
range|:
name|partKVPs
control|)
block|{
name|String
index|[]
name|partKV
init|=
name|partKVP
operator|.
name|split
argument_list|(
literal|"="
argument_list|)
decl_stmt|;
if|if
condition|(
name|partKV
operator|.
name|length
operator|==
literal|2
condition|)
block|{
name|String
name|partKey
init|=
name|partKV
index|[
literal|0
index|]
operator|.
name|trim
argument_list|()
decl_stmt|;
name|partitionKeys
operator|.
name|add
argument_list|(
name|partKey
argument_list|)
expr_stmt|;
name|partitions
operator|.
name|put
argument_list|(
name|partKey
argument_list|,
name|partKV
index|[
literal|1
index|]
operator|.
name|trim
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Invalid partition column specification. "
operator|+
name|partSpecs
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|schema
operator|!=
literal|null
condition|)
block|{
name|pigSchema
operator|=
name|Utils
operator|.
name|getSchemaFromString
argument_list|(
name|schema
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|checkSchema
parameter_list|(
name|ResourceSchema
name|resourceSchema
parameter_list|)
throws|throws
name|IOException
block|{
comment|/*  Schema provided by user and the schema computed by Pig     * at the time of calling store must match.     */
name|Schema
name|runtimeSchema
init|=
name|Schema
operator|.
name|getPigSchema
argument_list|(
name|resourceSchema
argument_list|)
decl_stmt|;
if|if
condition|(
name|pigSchema
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|Schema
operator|.
name|equals
argument_list|(
name|runtimeSchema
argument_list|,
name|pigSchema
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Schema provided in store statement doesn't match with the Schema"
operator|+
literal|"returned by Pig run-time. Schema provided in HCatStorer: "
operator|+
name|pigSchema
operator|.
name|toString
argument_list|()
operator|+
literal|" Schema received from Pig runtime: "
operator|+
name|runtimeSchema
operator|.
name|toString
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|pigSchema
operator|=
name|runtimeSchema
expr_stmt|;
block|}
name|UDFContext
operator|.
name|getUDFContext
argument_list|()
operator|.
name|getUDFProperties
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|,
operator|new
name|String
index|[]
block|{
name|sign
block|}
argument_list|)
operator|.
name|setProperty
argument_list|(
name|PIG_SCHEMA
argument_list|,
name|ObjectSerializer
operator|.
name|serialize
argument_list|(
name|pigSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/** Constructs HCatSchema from pigSchema. Passed tableSchema is the existing    * schema of the table in metastore.    */
specifier|protected
name|HCatSchema
name|convertPigSchemaToHCatSchema
parameter_list|(
name|Schema
name|pigSchema
parameter_list|,
name|HCatSchema
name|tableSchema
parameter_list|)
throws|throws
name|FrontendException
block|{
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|fieldSchemas
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
name|pigSchema
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fSchema
range|:
name|pigSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
try|try
block|{
name|HCatFieldSchema
name|hcatFieldSchema
init|=
name|getColFromSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|tableSchema
argument_list|)
decl_stmt|;
name|fieldSchemas
operator|.
name|add
argument_list|(
name|getHCatFSFromPigFS
argument_list|(
name|fSchema
argument_list|,
name|hcatFieldSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|HCatException
name|he
parameter_list|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
name|he
operator|.
name|getMessage
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|,
name|he
argument_list|)
throw|;
block|}
block|}
return|return
operator|new
name|HCatSchema
argument_list|(
name|fieldSchemas
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|removeTupleFromBag
parameter_list|(
name|HCatFieldSchema
name|hcatFieldSchema
parameter_list|,
name|FieldSchema
name|bagFieldSchema
parameter_list|)
throws|throws
name|HCatException
block|{
if|if
condition|(
name|hcatFieldSchema
operator|!=
literal|null
operator|&&
name|hcatFieldSchema
operator|.
name|getArrayElementSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getType
argument_list|()
operator|!=
name|Type
operator|.
name|STRUCT
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Column was not found in table schema. Its a new column
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|tupSchema
init|=
name|bagFieldSchema
operator|.
name|schema
operator|.
name|getFields
argument_list|()
decl_stmt|;
if|if
condition|(
name|hcatFieldSchema
operator|==
literal|null
operator|&&
name|tupSchema
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|&&
operator|(
name|tupSchema
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|==
literal|null
operator|||
operator|(
name|tupSchema
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|type
operator|==
name|DataType
operator|.
name|TUPLE
operator|&&
name|tupSchema
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|)
operator|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|HCatFieldSchema
name|getHCatFSFromPigFS
parameter_list|(
name|FieldSchema
name|fSchema
parameter_list|,
name|HCatFieldSchema
name|hcatFieldSchema
parameter_list|)
throws|throws
name|FrontendException
throws|,
name|HCatException
block|{
name|byte
name|type
init|=
name|fSchema
operator|.
name|type
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|DataType
operator|.
name|CHARARRAY
case|:
case|case
name|DataType
operator|.
name|BIGCHARARRAY
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|INTEGER
case|:
if|if
condition|(
name|hcatFieldSchema
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|SUPPORTED_INTEGER_CONVERSIONS
operator|.
name|contains
argument_list|(
name|hcatFieldSchema
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Unsupported type: "
operator|+
name|type
operator|+
literal|"  in Pig's schema"
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|hcatFieldSchema
operator|.
name|getType
argument_list|()
argument_list|,
literal|null
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|INT
argument_list|,
literal|null
argument_list|)
return|;
block|}
case|case
name|DataType
operator|.
name|LONG
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|BIGINT
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|FLOAT
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|FLOAT
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|DOUBLE
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|DOUBLE
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|BYTEARRAY
case|:
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|BINARY
argument_list|,
literal|null
argument_list|)
return|;
case|case
name|DataType
operator|.
name|BAG
case|:
name|Schema
name|bagSchema
init|=
name|fSchema
operator|.
name|schema
decl_stmt|;
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|arrFields
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|FieldSchema
name|field
decl_stmt|;
comment|// Find out if we need to throw away the tuple or not.
if|if
condition|(
name|removeTupleFromBag
argument_list|(
name|hcatFieldSchema
argument_list|,
name|fSchema
argument_list|)
condition|)
block|{
name|field
operator|=
name|bagSchema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|field
operator|=
name|bagSchema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|arrFields
operator|.
name|add
argument_list|(
name|getHCatFSFromPigFS
argument_list|(
name|field
argument_list|,
name|hcatFieldSchema
operator|==
literal|null
condition|?
literal|null
else|:
name|hcatFieldSchema
operator|.
name|getArrayElementSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|ARRAY
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|arrFields
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
case|case
name|DataType
operator|.
name|TUPLE
case|:
name|List
argument_list|<
name|String
argument_list|>
name|fieldNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|hcatFSs
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|()
decl_stmt|;
name|HCatSchema
name|structSubSchema
init|=
name|hcatFieldSchema
operator|==
literal|null
condition|?
literal|null
else|:
name|hcatFieldSchema
operator|.
name|getStructSubSchema
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fields
init|=
name|fSchema
operator|.
name|schema
operator|.
name|getFields
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fields
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|FieldSchema
name|fieldSchema
init|=
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|fieldNames
operator|.
name|add
argument_list|(
name|fieldSchema
operator|.
name|alias
argument_list|)
expr_stmt|;
name|hcatFSs
operator|.
name|add
argument_list|(
name|getHCatFSFromPigFS
argument_list|(
name|fieldSchema
argument_list|,
name|structSubSchema
operator|==
literal|null
condition|?
literal|null
else|:
name|structSubSchema
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|STRUCT
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|hcatFSs
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
case|case
name|DataType
operator|.
name|MAP
case|:
block|{
comment|// Pig's schema contain no type information about map's keys and
comment|// values. So, if its a new column assume<string,string> if its existing
comment|// return whatever is contained in the existing column.
name|HCatFieldSchema
name|valFS
decl_stmt|;
name|List
argument_list|<
name|HCatFieldSchema
argument_list|>
name|valFSList
init|=
operator|new
name|ArrayList
argument_list|<
name|HCatFieldSchema
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|hcatFieldSchema
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|MAP
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
name|hcatFieldSchema
operator|.
name|getMapValueSchema
argument_list|()
argument_list|,
literal|""
argument_list|)
return|;
block|}
comment|// Column not found in target table. Its a new column. Its schema is map<string,string>
name|valFS
operator|=
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|valFSList
operator|.
name|add
argument_list|(
name|valFS
argument_list|)
expr_stmt|;
return|return
operator|new
name|HCatFieldSchema
argument_list|(
name|fSchema
operator|.
name|alias
argument_list|,
name|Type
operator|.
name|MAP
argument_list|,
name|Type
operator|.
name|STRING
argument_list|,
operator|new
name|HCatSchema
argument_list|(
name|valFSList
argument_list|)
argument_list|,
literal|""
argument_list|)
return|;
block|}
default|default:
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Unsupported type: "
operator|+
name|type
operator|+
literal|"  in Pig's schema"
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|prepareToWrite
parameter_list|(
name|RecordWriter
name|writer
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|writer
operator|=
name|writer
expr_stmt|;
name|computedSchema
operator|=
operator|(
name|HCatSchema
operator|)
name|ObjectSerializer
operator|.
name|deserialize
argument_list|(
name|UDFContext
operator|.
name|getUDFContext
argument_list|()
operator|.
name|getUDFProperties
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|,
operator|new
name|String
index|[]
block|{
name|sign
block|}
argument_list|)
operator|.
name|getProperty
argument_list|(
name|COMPUTED_OUTPUT_SCHEMA
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|putNext
parameter_list|(
name|Tuple
name|tuple
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Object
argument_list|>
name|outgoing
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
name|tuple
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|HCatFieldSchema
name|fSchema
range|:
name|computedSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|outgoing
operator|.
name|add
argument_list|(
name|getJavaObj
argument_list|(
name|tuple
operator|.
name|get
argument_list|(
name|i
operator|++
argument_list|)
argument_list|,
name|fSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|writer
operator|.
name|write
argument_list|(
literal|null
argument_list|,
operator|new
name|DefaultHCatRecord
argument_list|(
name|outgoing
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|BackendException
argument_list|(
literal|"Error while writing tuple: "
operator|+
name|tuple
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|Object
name|getJavaObj
parameter_list|(
name|Object
name|pigObj
parameter_list|,
name|HCatFieldSchema
name|hcatFS
parameter_list|)
throws|throws
name|HCatException
throws|,
name|BackendException
block|{
try|try
block|{
comment|// The real work-horse. Spend time and energy in this method if there is
comment|// need to keep HCatStorer lean and go fast.
name|Type
name|type
init|=
name|hcatFS
operator|.
name|getType
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|BINARY
case|:
if|if
condition|(
name|pigObj
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
operator|(
operator|(
name|DataByteArray
operator|)
name|pigObj
operator|)
operator|.
name|get
argument_list|()
return|;
case|case
name|STRUCT
case|:
if|if
condition|(
name|pigObj
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|HCatSchema
name|structSubSchema
init|=
name|hcatFS
operator|.
name|getStructSubSchema
argument_list|()
decl_stmt|;
comment|// Unwrap the tuple.
name|List
argument_list|<
name|Object
argument_list|>
name|all
init|=
operator|(
operator|(
name|Tuple
operator|)
name|pigObj
operator|)
operator|.
name|getAll
argument_list|()
decl_stmt|;
name|ArrayList
argument_list|<
name|Object
argument_list|>
name|converted
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
name|all
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|all
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|converted
operator|.
name|add
argument_list|(
name|getJavaObj
argument_list|(
name|all
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|structSubSchema
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|converted
return|;
case|case
name|ARRAY
case|:
if|if
condition|(
name|pigObj
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Unwrap the bag.
name|DataBag
name|pigBag
init|=
operator|(
name|DataBag
operator|)
name|pigObj
decl_stmt|;
name|HCatFieldSchema
name|tupFS
init|=
name|hcatFS
operator|.
name|getArrayElementSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|boolean
name|needTuple
init|=
name|tupFS
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|STRUCT
decl_stmt|;
name|List
argument_list|<
name|Object
argument_list|>
name|bagContents
init|=
operator|new
name|ArrayList
argument_list|<
name|Object
argument_list|>
argument_list|(
operator|(
name|int
operator|)
name|pigBag
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Tuple
argument_list|>
name|bagItr
init|=
name|pigBag
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|bagItr
operator|.
name|hasNext
argument_list|()
condition|)
block|{
comment|// If there is only one element in tuple contained in bag, we throw away the tuple.
name|bagContents
operator|.
name|add
argument_list|(
name|getJavaObj
argument_list|(
name|needTuple
condition|?
name|bagItr
operator|.
name|next
argument_list|()
else|:
name|bagItr
operator|.
name|next
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|,
name|tupFS
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|bagContents
return|;
case|case
name|MAP
case|:
if|if
condition|(
name|pigObj
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|Map
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|pigMap
init|=
operator|(
name|Map
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
operator|)
name|pigObj
decl_stmt|;
name|Map
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
name|typeMap
init|=
operator|new
name|HashMap
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|entry
range|:
name|pigMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// the value has a schema and not a FieldSchema
name|typeMap
operator|.
name|put
argument_list|(
comment|// Schema validation enforces that the Key is a String
operator|(
name|String
operator|)
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|getJavaObj
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|hcatFS
operator|.
name|getMapValueSchema
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|typeMap
return|;
case|case
name|STRING
case|:
case|case
name|INT
case|:
case|case
name|BIGINT
case|:
case|case
name|FLOAT
case|:
case|case
name|DOUBLE
case|:
return|return
name|pigObj
return|;
case|case
name|SMALLINT
case|:
if|if
condition|(
name|pigObj
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
operator|(
name|Integer
operator|)
name|pigObj
argument_list|<
name|Short
operator|.
name|MIN_VALUE
operator|||
operator|(
name|Integer
operator|)
name|pigObj
argument_list|>
name|Short
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|BackendException
argument_list|(
literal|"Value "
operator|+
name|pigObj
operator|+
literal|" is outside the bounds of column "
operator|+
name|hcatFS
operator|.
name|getName
argument_list|()
operator|+
literal|" with type "
operator|+
name|hcatFS
operator|.
name|getType
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
return|return
operator|(
operator|(
name|Integer
operator|)
name|pigObj
operator|)
operator|.
name|shortValue
argument_list|()
return|;
case|case
name|TINYINT
case|:
if|if
condition|(
name|pigObj
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
operator|(
name|Integer
operator|)
name|pigObj
argument_list|<
name|Byte
operator|.
name|MIN_VALUE
operator|||
operator|(
name|Integer
operator|)
name|pigObj
argument_list|>
name|Byte
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|BackendException
argument_list|(
literal|"Value "
operator|+
name|pigObj
operator|+
literal|" is outside the bounds of column "
operator|+
name|hcatFS
operator|.
name|getName
argument_list|()
operator|+
literal|" with type "
operator|+
name|hcatFS
operator|.
name|getType
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
return|return
operator|(
operator|(
name|Integer
operator|)
name|pigObj
operator|)
operator|.
name|byteValue
argument_list|()
return|;
case|case
name|BOOLEAN
case|:
comment|// would not pass schema validation anyway
throw|throw
operator|new
name|BackendException
argument_list|(
literal|"Incompatible type "
operator|+
name|type
operator|+
literal|" found in hcat table schema: "
operator|+
name|hcatFS
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
default|default:
throw|throw
operator|new
name|BackendException
argument_list|(
literal|"Unexpected type "
operator|+
name|type
operator|+
literal|" for value "
operator|+
name|pigObj
operator|+
operator|(
name|pigObj
operator|==
literal|null
condition|?
literal|""
else|:
literal|" of class "
operator|+
name|pigObj
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|)
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|BackendException
name|e
parameter_list|)
block|{
comment|// provide the path to the field in the error message
throw|throw
operator|new
name|BackendException
argument_list|(
operator|(
name|hcatFS
operator|.
name|getName
argument_list|()
operator|==
literal|null
condition|?
literal|" "
else|:
name|hcatFS
operator|.
name|getName
argument_list|()
operator|+
literal|"."
operator|)
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
operator|.
name|getCause
argument_list|()
operator|==
literal|null
condition|?
name|e
else|:
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|relToAbsPathForStoreLocation
parameter_list|(
name|String
name|location
parameter_list|,
name|Path
name|curDir
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Need to necessarily override this method since default impl assumes HDFS
comment|// based location string.
return|return
name|location
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setStoreFuncUDFContextSignature
parameter_list|(
name|String
name|signature
parameter_list|)
block|{
name|sign
operator|=
name|signature
expr_stmt|;
block|}
specifier|protected
name|void
name|doSchemaValidations
parameter_list|(
name|Schema
name|pigSchema
parameter_list|,
name|HCatSchema
name|tblSchema
parameter_list|)
throws|throws
name|FrontendException
throws|,
name|HCatException
block|{
comment|// Iterate through all the elements in Pig Schema and do validations as
comment|// dictated by semantics, consult HCatSchema of table when need be.
for|for
control|(
name|FieldSchema
name|pigField
range|:
name|pigSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|HCatFieldSchema
name|hcatField
init|=
name|getColFromSchema
argument_list|(
name|pigField
operator|.
name|alias
argument_list|,
name|tblSchema
argument_list|)
decl_stmt|;
name|validateSchema
argument_list|(
name|pigField
argument_list|,
name|hcatField
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|PigHCatUtil
operator|.
name|validateHCatTableSchemaFollowsPigRules
argument_list|(
name|tblSchema
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"HCatalog schema is not compatible with Pig: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|validateSchema
parameter_list|(
name|FieldSchema
name|pigField
parameter_list|,
name|HCatFieldSchema
name|hcatField
parameter_list|)
throws|throws
name|HCatException
throws|,
name|FrontendException
block|{
name|validateAlias
argument_list|(
name|pigField
operator|.
name|alias
argument_list|)
expr_stmt|;
name|byte
name|type
init|=
name|pigField
operator|.
name|type
decl_stmt|;
if|if
condition|(
name|DataType
operator|.
name|isComplex
argument_list|(
name|type
argument_list|)
condition|)
block|{
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|DataType
operator|.
name|MAP
case|:
if|if
condition|(
name|hcatField
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|hcatField
operator|.
name|getMapKeyType
argument_list|()
operator|!=
name|Type
operator|.
name|STRING
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Key Type of map must be String "
operator|+
name|hcatField
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
comment|// Map values can be primitive or complex
block|}
break|break;
case|case
name|DataType
operator|.
name|BAG
case|:
name|HCatSchema
name|arrayElementSchema
init|=
name|hcatField
operator|==
literal|null
condition|?
literal|null
else|:
name|hcatField
operator|.
name|getArrayElementSchema
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|innerField
range|:
name|pigField
operator|.
name|schema
operator|.
name|getField
argument_list|(
literal|0
argument_list|)
operator|.
name|schema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|validateSchema
argument_list|(
name|innerField
argument_list|,
name|getColFromSchema
argument_list|(
name|pigField
operator|.
name|alias
argument_list|,
name|arrayElementSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|DataType
operator|.
name|TUPLE
case|:
name|HCatSchema
name|structSubSchema
init|=
name|hcatField
operator|==
literal|null
condition|?
literal|null
else|:
name|hcatField
operator|.
name|getStructSubSchema
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|innerField
range|:
name|pigField
operator|.
name|schema
operator|.
name|getFields
argument_list|()
control|)
block|{
name|validateSchema
argument_list|(
name|innerField
argument_list|,
name|getColFromSchema
argument_list|(
name|pigField
operator|.
name|alias
argument_list|,
name|structSubSchema
argument_list|)
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Internal Error."
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|void
name|validateAlias
parameter_list|(
name|String
name|alias
parameter_list|)
throws|throws
name|FrontendException
block|{
if|if
condition|(
name|alias
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Column name for a field is not specified. Please provide the full schema as an argument to HCatStorer."
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
if|if
condition|(
name|alias
operator|.
name|matches
argument_list|(
literal|".*[A-Z]+.*"
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FrontendException
argument_list|(
literal|"Column names should all be in lowercase. Invalid name found: "
operator|+
name|alias
argument_list|,
name|PigHCatUtil
operator|.
name|PIG_EXCEPTION_CODE
argument_list|)
throw|;
block|}
block|}
comment|// Finds column by name in HCatSchema, if not found returns null.
specifier|private
name|HCatFieldSchema
name|getColFromSchema
parameter_list|(
name|String
name|alias
parameter_list|,
name|HCatSchema
name|tblSchema
parameter_list|)
block|{
if|if
condition|(
name|tblSchema
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HCatFieldSchema
name|hcatField
range|:
name|tblSchema
operator|.
name|getFields
argument_list|()
control|)
block|{
if|if
condition|(
name|hcatField
operator|!=
literal|null
operator|&&
name|hcatField
operator|.
name|getName
argument_list|()
operator|!=
literal|null
operator|&&
name|hcatField
operator|.
name|getName
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|alias
argument_list|)
condition|)
block|{
return|return
name|hcatField
return|;
block|}
block|}
block|}
comment|// Its a new column
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|cleanupOnFailure
parameter_list|(
name|String
name|location
parameter_list|,
name|Job
name|job
parameter_list|)
throws|throws
name|IOException
block|{
comment|// No-op.
block|}
annotation|@
name|Override
specifier|public
name|void
name|storeStatistics
parameter_list|(
name|ResourceStatistics
name|stats
parameter_list|,
name|String
name|arg1
parameter_list|,
name|Job
name|job
parameter_list|)
throws|throws
name|IOException
block|{   }
block|}
end_class

end_unit

