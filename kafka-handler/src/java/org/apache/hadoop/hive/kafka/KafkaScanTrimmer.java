begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|kafka
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableMap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableSet
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FunctionRegistry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|io
operator|.
name|sarg
operator|.
name|PredicateLeaf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeColumnDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeConstantDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeDescUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|plan
operator|.
name|ExprNodeGenericFuncDesc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDF
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFBaseCompare
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFBridge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFOPEqual
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFOPEqualOrGreaterThan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFOPEqualOrLessThan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFOPGreaterThan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFOPLessThan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToBinary
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToChar
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToDate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToDecimal
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToUnixTimeStamp
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToUtcTimestamp
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|udf
operator|.
name|generic
operator|.
name|GenericUDFToVarchar
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|KafkaConsumer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|OffsetAndTimestamp
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|TopicPartition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Predicate
import|;
end_import

begin_comment
comment|/**  * Kafka Range trimmer, takes a full kafka scan and prune the scan based on a filter expression  * it is a Best effort trimmer and it can not replace the filter it self, filtration still takes place in Hive executor.  */
end_comment

begin_class
class|class
name|KafkaScanTrimmer
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|KafkaScanTrimmer
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|fullHouse
decl_stmt|;
specifier|private
specifier|final
name|KafkaConsumer
name|kafkaConsumer
decl_stmt|;
comment|/**    * @param fullHouse     initial full scan to be pruned, this is a map of Topic partition to input split.    * @param kafkaConsumer kafka consumer used to pull offsets for time filter if needed    */
name|KafkaScanTrimmer
parameter_list|(
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|fullHouse
parameter_list|,
name|KafkaConsumer
name|kafkaConsumer
parameter_list|)
block|{
name|this
operator|.
name|fullHouse
operator|=
name|fullHouse
expr_stmt|;
name|this
operator|.
name|kafkaConsumer
operator|=
name|kafkaConsumer
expr_stmt|;
block|}
comment|/**    * This might block due to calls like.    * org.apache.kafka.clients.consumer.KafkaConsumer#offsetsForTimes(java.util.Map)    *    * @param filterExpression filter expression to be used for pruning scan    *    * @return tiny house of of the full house based on filter expression    */
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|computeOptimizedScan
parameter_list|(
name|ExprNodeGenericFuncDesc
name|filterExpression
parameter_list|)
block|{
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|optimizedScan
init|=
name|parseAndOptimize
argument_list|(
name|filterExpression
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|optimizedScan
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Optimized scan:"
argument_list|)
expr_stmt|;
name|optimizedScan
operator|.
name|forEach
argument_list|(
parameter_list|(
name|tp
parameter_list|,
name|input
parameter_list|)
lambda|->
name|LOG
operator|.
name|debug
argument_list|(
literal|"Topic-[{}] Partition-[{}] - Split startOffset [{}] :-> endOffset [{}]"
argument_list|,
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
name|input
operator|.
name|getStartOffset
argument_list|()
argument_list|,
name|input
operator|.
name|getEndOffset
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No optimization thus using full scan "
argument_list|)
expr_stmt|;
name|fullHouse
operator|.
name|forEach
argument_list|(
parameter_list|(
name|tp
parameter_list|,
name|input
parameter_list|)
lambda|->
name|LOG
operator|.
name|debug
argument_list|(
literal|"Topic-[{}] Partition-[{}] - Split startOffset [{}] :-> endOffset [{}]"
argument_list|,
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
name|input
operator|.
name|getStartOffset
argument_list|()
argument_list|,
name|input
operator|.
name|getEndOffset
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|optimizedScan
operator|==
literal|null
condition|?
name|fullHouse
else|:
name|optimizedScan
return|;
block|}
comment|/**    * @param expression filter to parseAndOptimize and trim the full scan    *    * @return Map of optimized kafka range scans or null if it is impossible to optimize.    */
annotation|@
name|Nullable
specifier|private
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|parseAndOptimize
parameter_list|(
name|ExprNodeDesc
name|expression
parameter_list|)
block|{
if|if
condition|(
name|expression
operator|.
name|getClass
argument_list|()
operator|!=
name|ExprNodeGenericFuncDesc
operator|.
name|class
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// get the kind of expression
name|ExprNodeGenericFuncDesc
name|expr
init|=
operator|(
name|ExprNodeGenericFuncDesc
operator|)
name|expression
decl_stmt|;
name|Class
argument_list|<
name|?
argument_list|>
name|op
init|=
name|expr
operator|.
name|getGenericUDF
argument_list|()
operator|.
name|getClass
argument_list|()
decl_stmt|;
comment|// handle the logical operators
if|if
condition|(
name|FunctionRegistry
operator|.
name|isOpOr
argument_list|(
name|expr
argument_list|)
condition|)
block|{
return|return
name|pushOrOp
argument_list|(
name|expr
argument_list|)
return|;
block|}
if|if
condition|(
name|FunctionRegistry
operator|.
name|isOpAnd
argument_list|(
name|expr
argument_list|)
condition|)
block|{
return|return
name|pushAndOp
argument_list|(
name|expr
argument_list|)
return|;
block|}
if|if
condition|(
name|op
operator|==
name|GenericUDFOPGreaterThan
operator|.
name|class
condition|)
block|{
return|return
name|pushLeaf
argument_list|(
name|expr
argument_list|,
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|LESS_THAN_EQUALS
argument_list|,
literal|true
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|op
operator|==
name|GenericUDFOPEqualOrGreaterThan
operator|.
name|class
condition|)
block|{
return|return
name|pushLeaf
argument_list|(
name|expr
argument_list|,
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|LESS_THAN
argument_list|,
literal|true
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|op
operator|==
name|GenericUDFOPLessThan
operator|.
name|class
condition|)
block|{
return|return
name|pushLeaf
argument_list|(
name|expr
argument_list|,
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|LESS_THAN
argument_list|,
literal|false
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|op
operator|==
name|GenericUDFOPEqualOrLessThan
operator|.
name|class
condition|)
block|{
return|return
name|pushLeaf
argument_list|(
name|expr
argument_list|,
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|LESS_THAN_EQUALS
argument_list|,
literal|false
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|op
operator|==
name|GenericUDFOPEqual
operator|.
name|class
condition|)
block|{
return|return
name|pushLeaf
argument_list|(
name|expr
argument_list|,
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|EQUALS
argument_list|,
literal|false
argument_list|)
return|;
comment|// otherwise, we didn't understand it, so bailout
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/**    * @param expr     leaf node to push    * @param operator operator    * @param negation true if it is a negation, this is used to represent:    *                 GenericUDFOPGreaterThan and GenericUDFOPEqualOrGreaterThan    *                 using PredicateLeaf.Operator.LESS_THAN and PredicateLeaf.Operator.LESS_THAN_EQUALS    *    * @return leaf scan or null if can not figure out push down    */
annotation|@
name|Nullable
specifier|private
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|pushLeaf
parameter_list|(
name|ExprNodeGenericFuncDesc
name|expr
parameter_list|,
name|PredicateLeaf
operator|.
name|Operator
name|operator
parameter_list|,
name|boolean
name|negation
parameter_list|)
block|{
if|if
condition|(
name|expr
operator|.
name|getChildren
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
literal|2
condition|)
block|{
return|return
literal|null
return|;
block|}
name|GenericUDF
name|genericUDF
init|=
name|expr
operator|.
name|getGenericUDF
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|genericUDF
operator|instanceof
name|GenericUDFBaseCompare
operator|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|ExprNodeDesc
name|expr1
init|=
name|expr
operator|.
name|getChildren
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|ExprNodeDesc
name|expr2
init|=
name|expr
operator|.
name|getChildren
argument_list|()
operator|.
name|get
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|// We may need to peel off the GenericUDFBridge that is added by CBO or user
if|if
condition|(
name|expr1
operator|.
name|getTypeInfo
argument_list|()
operator|.
name|equals
argument_list|(
name|expr2
operator|.
name|getTypeInfo
argument_list|()
argument_list|)
condition|)
block|{
name|expr1
operator|=
name|getColumnExpr
argument_list|(
name|expr1
argument_list|)
expr_stmt|;
name|expr2
operator|=
name|getColumnExpr
argument_list|(
name|expr2
argument_list|)
expr_stmt|;
block|}
name|ExprNodeDesc
index|[]
name|extracted
init|=
name|ExprNodeDescUtils
operator|.
name|extractComparePair
argument_list|(
name|expr1
argument_list|,
name|expr2
argument_list|)
decl_stmt|;
if|if
condition|(
name|extracted
operator|==
literal|null
operator|||
operator|(
name|extracted
operator|.
name|length
operator|>
literal|2
operator|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|ExprNodeColumnDesc
name|columnDesc
decl_stmt|;
name|ExprNodeConstantDesc
name|constantDesc
decl_stmt|;
specifier|final
name|boolean
name|flip
decl_stmt|;
if|if
condition|(
name|extracted
index|[
literal|0
index|]
operator|instanceof
name|ExprNodeColumnDesc
condition|)
block|{
name|columnDesc
operator|=
operator|(
name|ExprNodeColumnDesc
operator|)
name|extracted
index|[
literal|0
index|]
expr_stmt|;
name|constantDesc
operator|=
operator|(
name|ExprNodeConstantDesc
operator|)
name|extracted
index|[
literal|1
index|]
expr_stmt|;
name|flip
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|flip
operator|=
literal|true
expr_stmt|;
name|columnDesc
operator|=
operator|(
name|ExprNodeColumnDesc
operator|)
name|extracted
index|[
literal|1
index|]
expr_stmt|;
name|constantDesc
operator|=
operator|(
name|ExprNodeConstantDesc
operator|)
name|extracted
index|[
literal|0
index|]
expr_stmt|;
block|}
if|if
condition|(
name|columnDesc
operator|.
name|getColumn
argument_list|()
operator|.
name|equals
argument_list|(
name|KafkaStreamingUtils
operator|.
name|MetadataColumn
operator|.
name|PARTITION
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
name|buildScanFromPartitionPredicate
argument_list|(
name|fullHouse
argument_list|,
name|operator
argument_list|,
operator|(
operator|(
name|Number
operator|)
name|constantDesc
operator|.
name|getValue
argument_list|()
operator|)
operator|.
name|intValue
argument_list|()
argument_list|,
name|flip
argument_list|,
name|negation
argument_list|)
return|;
block|}
if|if
condition|(
name|columnDesc
operator|.
name|getColumn
argument_list|()
operator|.
name|equals
argument_list|(
name|KafkaStreamingUtils
operator|.
name|MetadataColumn
operator|.
name|OFFSET
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
name|buildScanFromOffsetPredicate
argument_list|(
name|fullHouse
argument_list|,
name|operator
argument_list|,
operator|(
operator|(
name|Number
operator|)
name|constantDesc
operator|.
name|getValue
argument_list|()
operator|)
operator|.
name|longValue
argument_list|()
argument_list|,
name|flip
argument_list|,
name|negation
argument_list|)
return|;
block|}
if|if
condition|(
name|columnDesc
operator|.
name|getColumn
argument_list|()
operator|.
name|equals
argument_list|(
name|KafkaStreamingUtils
operator|.
name|MetadataColumn
operator|.
name|TIMESTAMP
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|long
name|timestamp
init|=
operator|(
operator|(
name|Number
operator|)
name|constantDesc
operator|.
name|getValue
argument_list|()
operator|)
operator|.
name|longValue
argument_list|()
decl_stmt|;
comment|//noinspection unchecked
return|return
name|buildScanForTimesPredicate
argument_list|(
name|fullHouse
argument_list|,
name|operator
argument_list|,
name|timestamp
argument_list|,
name|flip
argument_list|,
name|negation
argument_list|,
name|kafkaConsumer
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Trim kafka scan using a leaf binary predicate on partition column.    *    * @param fullScan       kafka full scan to be optimized    * @param operator       predicate operator, equal, lessThan or lessThanEqual    * @param partitionConst partition constant value    * @param flip           true if the position of column and constant is flipped by default assuming column OP constant    * @param negation       true if the expression is a negation of the original expression    *    * @return filtered kafka scan    */
annotation|@
name|VisibleForTesting
specifier|static
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|buildScanFromPartitionPredicate
parameter_list|(
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|fullScan
parameter_list|,
name|PredicateLeaf
operator|.
name|Operator
name|operator
parameter_list|,
name|int
name|partitionConst
parameter_list|,
name|boolean
name|flip
parameter_list|,
name|boolean
name|negation
parameter_list|)
block|{
specifier|final
name|Predicate
argument_list|<
name|TopicPartition
argument_list|>
name|predicate
decl_stmt|;
specifier|final
name|Predicate
argument_list|<
name|TopicPartition
argument_list|>
name|intermediatePredicate
decl_stmt|;
switch|switch
condition|(
name|operator
condition|)
block|{
case|case
name|EQUALS
case|:
name|predicate
operator|=
name|topicPartition
lambda|->
name|topicPartition
operator|!=
literal|null
operator|&&
name|topicPartition
operator|.
name|partition
argument_list|()
operator|==
name|partitionConst
expr_stmt|;
break|break;
case|case
name|LESS_THAN
case|:
name|intermediatePredicate
operator|=
name|flip
condition|?
name|topicPartition
lambda|->
name|topicPartition
operator|!=
literal|null
operator|&&
name|partitionConst
operator|<
name|topicPartition
operator|.
name|partition
argument_list|()
else|:
name|topicPartition
lambda|->
name|topicPartition
operator|!=
literal|null
operator|&&
name|topicPartition
operator|.
name|partition
argument_list|()
operator|<
name|partitionConst
expr_stmt|;
name|predicate
operator|=
name|negation
condition|?
name|intermediatePredicate
operator|.
name|negate
argument_list|()
else|:
name|intermediatePredicate
expr_stmt|;
break|break;
case|case
name|LESS_THAN_EQUALS
case|:
name|intermediatePredicate
operator|=
name|flip
condition|?
name|topicPartition
lambda|->
name|topicPartition
operator|!=
literal|null
operator|&&
name|partitionConst
operator|<=
name|topicPartition
operator|.
name|partition
argument_list|()
else|:
name|topicPartition
lambda|->
name|topicPartition
operator|!=
literal|null
operator|&&
name|topicPartition
operator|.
name|partition
argument_list|()
operator|<=
name|partitionConst
expr_stmt|;
name|predicate
operator|=
name|negation
condition|?
name|intermediatePredicate
operator|.
name|negate
argument_list|()
else|:
name|intermediatePredicate
expr_stmt|;
break|break;
default|default:
comment|//Default to select * for unknown cases
name|predicate
operator|=
name|topicPartition
lambda|->
literal|true
expr_stmt|;
block|}
name|ImmutableMap
operator|.
name|Builder
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|builder
init|=
name|ImmutableMap
operator|.
name|builder
argument_list|()
decl_stmt|;
comment|// Filter full scan based on predicate
name|fullScan
operator|.
name|entrySet
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|entry
lambda|->
name|predicate
operator|.
name|test
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
operator|.
name|forEach
argument_list|(
name|entry
lambda|->
name|builder
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|clone
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|builder
operator|.
name|build
argument_list|()
return|;
block|}
comment|/**    * @param fullScan    full kafka scan to be pruned    * @param operator    operator kind    * @param offsetConst offset constant value    * @param flip        true if position of constant and column were flipped by default assuming COLUMN OP CONSTANT    * @param negation    true if the expression is a negation of the original expression    *    * @return optimized kafka scan    */
annotation|@
name|VisibleForTesting
specifier|static
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|buildScanFromOffsetPredicate
parameter_list|(
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|fullScan
parameter_list|,
name|PredicateLeaf
operator|.
name|Operator
name|operator
parameter_list|,
name|long
name|offsetConst
parameter_list|,
name|boolean
name|flip
parameter_list|,
name|boolean
name|negation
parameter_list|)
block|{
specifier|final
name|boolean
name|isEndBound
decl_stmt|;
specifier|final
name|long
name|startOffset
decl_stmt|;
specifier|final
name|long
name|endOffset
decl_stmt|;
name|isEndBound
operator|=
name|flip
operator|==
name|negation
expr_stmt|;
switch|switch
condition|(
name|operator
condition|)
block|{
case|case
name|LESS_THAN_EQUALS
case|:
if|if
condition|(
name|isEndBound
condition|)
block|{
name|startOffset
operator|=
operator|-
literal|1
expr_stmt|;
name|endOffset
operator|=
name|negation
condition|?
name|offsetConst
else|:
name|offsetConst
operator|+
literal|1
expr_stmt|;
block|}
else|else
block|{
name|endOffset
operator|=
operator|-
literal|1
expr_stmt|;
name|startOffset
operator|=
name|negation
condition|?
name|offsetConst
operator|+
literal|1
else|:
name|offsetConst
expr_stmt|;
block|}
break|break;
case|case
name|EQUALS
case|:
name|startOffset
operator|=
name|offsetConst
expr_stmt|;
name|endOffset
operator|=
name|offsetConst
operator|+
literal|1
expr_stmt|;
break|break;
case|case
name|LESS_THAN
case|:
if|if
condition|(
name|isEndBound
condition|)
block|{
name|endOffset
operator|=
name|negation
condition|?
name|offsetConst
operator|+
literal|1
else|:
name|offsetConst
expr_stmt|;
name|startOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
name|endOffset
operator|=
operator|-
literal|1
expr_stmt|;
name|startOffset
operator|=
name|negation
condition|?
name|offsetConst
else|:
name|offsetConst
operator|+
literal|1
expr_stmt|;
block|}
break|break;
default|default:
comment|// default to select *
name|startOffset
operator|=
operator|-
literal|1
expr_stmt|;
name|endOffset
operator|=
operator|-
literal|1
expr_stmt|;
block|}
specifier|final
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|newScan
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|fullScan
operator|.
name|forEach
argument_list|(
parameter_list|(
name|tp
parameter_list|,
name|existingInputSplit
parameter_list|)
lambda|->
block|{
specifier|final
name|KafkaPullerInputSplit
name|newInputSplit
decl_stmt|;
if|if
condition|(
name|startOffset
operator|!=
operator|-
literal|1
operator|&&
name|endOffset
operator|==
operator|-
literal|1
condition|)
block|{
name|newInputSplit
operator|=
operator|new
name|KafkaPullerInputSplit
argument_list|(
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
comment|//if the user ask for start offset> max offset will replace with last offset
name|Math
operator|.
name|min
argument_list|(
name|startOffset
argument_list|,
name|existingInputSplit
operator|.
name|getEndOffset
argument_list|()
argument_list|)
argument_list|,
name|existingInputSplit
operator|.
name|getEndOffset
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|endOffset
operator|!=
operator|-
literal|1
operator|&&
name|startOffset
operator|==
operator|-
literal|1
condition|)
block|{
name|newInputSplit
operator|=
operator|new
name|KafkaPullerInputSplit
argument_list|(
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getStartOffset
argument_list|()
argument_list|,
comment|//@TODO check this, if user ask for non existing end offset ignore it and position head on start
comment|// This can be an issue when doing ingestion from kafka into Hive, what happen if there is some gaps
comment|// Shall we fail the ingest or carry-on and ignore non existing offsets
name|Math
operator|.
name|max
argument_list|(
name|endOffset
argument_list|,
name|existingInputSplit
operator|.
name|getStartOffset
argument_list|()
argument_list|)
argument_list|,
name|existingInputSplit
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|endOffset
operator|==
name|startOffset
operator|+
literal|1
condition|)
block|{
if|if
condition|(
name|startOffset
operator|<
name|existingInputSplit
operator|.
name|getStartOffset
argument_list|()
operator|||
name|startOffset
operator|>=
name|existingInputSplit
operator|.
name|getEndOffset
argument_list|()
condition|)
block|{
name|newInputSplit
operator|=
operator|new
name|KafkaPullerInputSplit
argument_list|(
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
comment|// non existing offset will be seeking last offset
name|existingInputSplit
operator|.
name|getEndOffset
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getEndOffset
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|newInputSplit
operator|=
operator|new
name|KafkaPullerInputSplit
argument_list|(
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
name|startOffset
argument_list|,
name|endOffset
argument_list|,
name|existingInputSplit
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|newInputSplit
operator|=
operator|new
name|KafkaPullerInputSplit
argument_list|(
name|tp
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getStartOffset
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getEndOffset
argument_list|()
argument_list|,
name|existingInputSplit
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|newScan
operator|.
name|put
argument_list|(
name|tp
argument_list|,
name|KafkaPullerInputSplit
operator|.
name|intersectRange
argument_list|(
name|newInputSplit
argument_list|,
name|existingInputSplit
argument_list|)
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
return|return
name|newScan
return|;
block|}
annotation|@
name|Nullable
specifier|private
specifier|static
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|buildScanForTimesPredicate
parameter_list|(
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|fullHouse
parameter_list|,
name|PredicateLeaf
operator|.
name|Operator
name|operator
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|boolean
name|flip
parameter_list|,
name|boolean
name|negation
parameter_list|,
name|KafkaConsumer
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|consumer
parameter_list|)
block|{
name|long
name|increment
init|=
operator|(
name|flip
operator|&&
name|operator
operator|==
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|LESS_THAN
operator|||
name|negation
operator|&&
name|operator
operator|==
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|LESS_THAN_EQUALS
operator|)
condition|?
literal|1L
else|:
literal|0L
decl_stmt|;
comment|// only accepted cases are timestamp_column [> ;>= ; = ]constant
if|if
condition|(
name|operator
operator|==
name|PredicateLeaf
operator|.
name|Operator
operator|.
name|EQUALS
operator|||
name|flip
operator|^
name|negation
condition|)
block|{
specifier|final
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|Long
argument_list|>
name|timePartitionsMap
init|=
name|Maps
operator|.
name|toMap
argument_list|(
name|fullHouse
operator|.
name|keySet
argument_list|()
argument_list|,
name|tp
lambda|->
name|timestamp
operator|+
name|increment
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Based on Kafka docs
comment|// NULL will be returned for that partition If the message format version in a partition is before 0.10.0
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|OffsetAndTimestamp
argument_list|>
name|offsetAndTimestamp
init|=
name|consumer
operator|.
name|offsetsForTimes
argument_list|(
name|timePartitionsMap
argument_list|)
decl_stmt|;
return|return
name|Maps
operator|.
name|toMap
argument_list|(
name|fullHouse
operator|.
name|keySet
argument_list|()
argument_list|,
name|tp
lambda|->
block|{
name|KafkaPullerInputSplit
name|existing
init|=
name|fullHouse
operator|.
name|get
argument_list|(
name|tp
argument_list|)
decl_stmt|;
name|OffsetAndTimestamp
name|foundOffsetAndTime
init|=
name|offsetAndTimestamp
operator|.
name|get
argument_list|(
name|tp
argument_list|)
decl_stmt|;
comment|//Null in case filter doesn't match or field not existing ie old broker thus return empty scan.
specifier|final
name|long
name|startOffset
init|=
name|foundOffsetAndTime
operator|==
literal|null
condition|?
name|existing
operator|.
name|getEndOffset
argument_list|()
else|:
name|foundOffsetAndTime
operator|.
name|offset
argument_list|()
decl_stmt|;
return|return
operator|new
name|KafkaPullerInputSplit
argument_list|(
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|tp
argument_list|)
operator|.
name|topic
argument_list|()
argument_list|,
name|tp
operator|.
name|partition
argument_list|()
argument_list|,
name|startOffset
argument_list|,
name|existing
operator|.
name|getEndOffset
argument_list|()
argument_list|,
name|existing
operator|.
name|getPath
argument_list|()
argument_list|)
return|;
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while looking up offsets for time"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//Bailout when can not figure out offsets for times.
return|return
literal|null
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
comment|/**    * @param expr And expression to be parsed    *    * @return either full scan or an optimized sub scan.    */
specifier|private
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|pushAndOp
parameter_list|(
name|ExprNodeGenericFuncDesc
name|expr
parameter_list|)
block|{
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|currentScan
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|fullHouse
operator|.
name|forEach
argument_list|(
parameter_list|(
name|tp
parameter_list|,
name|input
parameter_list|)
lambda|->
name|currentScan
operator|.
name|put
argument_list|(
name|tp
argument_list|,
name|KafkaPullerInputSplit
operator|.
name|copyOf
argument_list|(
name|input
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|ExprNodeDesc
name|child
range|:
name|expr
operator|.
name|getChildren
argument_list|()
control|)
block|{
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|scan
init|=
name|parseAndOptimize
argument_list|(
name|child
argument_list|)
decl_stmt|;
if|if
condition|(
name|scan
operator|!=
literal|null
condition|)
block|{
name|Set
argument_list|<
name|TopicPartition
argument_list|>
name|currentKeys
init|=
name|ImmutableSet
operator|.
name|copyOf
argument_list|(
name|currentScan
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
name|currentKeys
operator|.
name|forEach
argument_list|(
name|key
lambda|->
block|{
name|KafkaPullerInputSplit
name|newSplit
init|=
name|scan
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|KafkaPullerInputSplit
name|oldSplit
init|=
name|currentScan
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|currentScan
operator|.
name|remove
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
name|newSplit
operator|!=
literal|null
condition|)
block|{
name|KafkaPullerInputSplit
name|intersectionSplit
init|=
name|KafkaPullerInputSplit
operator|.
name|intersectRange
argument_list|(
name|newSplit
argument_list|,
name|oldSplit
argument_list|)
decl_stmt|;
if|if
condition|(
name|intersectionSplit
operator|!=
literal|null
condition|)
block|{
name|currentScan
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|intersectionSplit
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|currentScan
return|;
block|}
annotation|@
name|Nullable
specifier|private
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|pushOrOp
parameter_list|(
name|ExprNodeGenericFuncDesc
name|expr
parameter_list|)
block|{
specifier|final
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|currentScan
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|ExprNodeDesc
name|child
range|:
name|expr
operator|.
name|getChildren
argument_list|()
control|)
block|{
name|Map
argument_list|<
name|TopicPartition
argument_list|,
name|KafkaPullerInputSplit
argument_list|>
name|scan
init|=
name|parseAndOptimize
argument_list|(
name|child
argument_list|)
decl_stmt|;
if|if
condition|(
name|scan
operator|==
literal|null
condition|)
block|{
comment|// if any of the children is unknown bailout
return|return
literal|null
return|;
block|}
name|scan
operator|.
name|forEach
argument_list|(
parameter_list|(
name|tp
parameter_list|,
name|input
parameter_list|)
lambda|->
block|{
name|KafkaPullerInputSplit
name|existingSplit
init|=
name|currentScan
operator|.
name|get
argument_list|(
name|tp
argument_list|)
decl_stmt|;
name|currentScan
operator|.
name|put
argument_list|(
name|tp
argument_list|,
name|KafkaPullerInputSplit
operator|.
name|unionRange
argument_list|(
name|input
argument_list|,
name|existingSplit
operator|==
literal|null
condition|?
name|input
else|:
name|existingSplit
argument_list|)
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
block|}
return|return
name|currentScan
return|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"Duplicates"
argument_list|)
specifier|private
specifier|static
name|ExprNodeDesc
name|getColumnExpr
parameter_list|(
name|ExprNodeDesc
name|expr
parameter_list|)
block|{
if|if
condition|(
name|expr
operator|instanceof
name|ExprNodeColumnDesc
condition|)
block|{
return|return
name|expr
return|;
block|}
name|ExprNodeGenericFuncDesc
name|funcDesc
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|expr
operator|instanceof
name|ExprNodeGenericFuncDesc
condition|)
block|{
name|funcDesc
operator|=
operator|(
name|ExprNodeGenericFuncDesc
operator|)
name|expr
expr_stmt|;
block|}
if|if
condition|(
literal|null
operator|==
name|funcDesc
condition|)
block|{
return|return
name|expr
return|;
block|}
name|GenericUDF
name|udf
init|=
name|funcDesc
operator|.
name|getGenericUDF
argument_list|()
decl_stmt|;
comment|// check if its a simple cast expression.
if|if
condition|(
operator|(
name|udf
operator|instanceof
name|GenericUDFBridge
operator|||
name|udf
operator|instanceof
name|GenericUDFToBinary
operator|||
name|udf
operator|instanceof
name|GenericUDFToChar
operator|||
name|udf
operator|instanceof
name|GenericUDFToVarchar
operator|||
name|udf
operator|instanceof
name|GenericUDFToDecimal
operator|||
name|udf
operator|instanceof
name|GenericUDFToDate
operator|||
name|udf
operator|instanceof
name|GenericUDFToUnixTimeStamp
operator|||
name|udf
operator|instanceof
name|GenericUDFToUtcTimestamp
operator|)
operator|&&
name|funcDesc
operator|.
name|getChildren
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|&&
name|funcDesc
operator|.
name|getChildren
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|instanceof
name|ExprNodeColumnDesc
condition|)
block|{
return|return
name|expr
operator|.
name|getChildren
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
return|;
block|}
return|return
name|expr
return|;
block|}
block|}
end_class

end_unit

