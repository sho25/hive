begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|kafka
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|Utilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|AbstractSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|ReflectionUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|CommonClientConfigs
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|ConsumerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|ProducerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|ProducerRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|AuthenticationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|AuthorizationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|InvalidTopicException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|OffsetMetadataTooLarge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|SecurityDisabledException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|SerializationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|UnknownServerException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|serialization
operator|.
name|ByteArrayDeserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_comment
comment|/**  * Utils class for Kafka Storage handler plus some Constants.  */
end_comment

begin_class
specifier|final
class|class
name|KafkaUtils
block|{
specifier|private
specifier|final
specifier|static
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|KafkaUtils
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|JAAS_TEMPLATE
init|=
literal|"com.sun.security.auth.module.Krb5LoginModule required "
operator|+
literal|"useKeyTab=true storeKey=true keyTab=\"%s\" principal=\"%s\";"
decl_stmt|;
specifier|private
name|KafkaUtils
parameter_list|()
block|{   }
comment|/**    * Table property prefix used to inject kafka consumer properties, e.g "kafka.consumer.max.poll.records" = "5000"    * this will lead to inject max.poll.records=5000 to the Kafka Consumer. NOT MANDATORY defaults to nothing    */
specifier|static
specifier|final
name|String
name|CONSUMER_CONFIGURATION_PREFIX
init|=
literal|"kafka.consumer"
decl_stmt|;
comment|/**    * Table property prefix used to inject kafka producer properties, e.g "kafka.producer.lingers.ms" = "100".    */
specifier|static
specifier|final
name|String
name|PRODUCER_CONFIGURATION_PREFIX
init|=
literal|"kafka.producer"
decl_stmt|;
comment|/**    * Set of Kafka properties that the user can not set via DDLs.    */
specifier|static
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|FORBIDDEN_PROPERTIES
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|ImmutableList
operator|.
name|of
argument_list|(
name|ConsumerConfig
operator|.
name|ENABLE_AUTO_COMMIT_CONFIG
argument_list|,
name|ConsumerConfig
operator|.
name|AUTO_OFFSET_RESET_CONFIG
argument_list|,
name|ConsumerConfig
operator|.
name|KEY_DESERIALIZER_CLASS_CONFIG
argument_list|,
name|ConsumerConfig
operator|.
name|VALUE_DESERIALIZER_CLASS_CONFIG
argument_list|,
name|ProducerConfig
operator|.
name|TRANSACTIONAL_ID_CONFIG
argument_list|,
name|ProducerConfig
operator|.
name|KEY_SERIALIZER_CLASS_CONFIG
argument_list|,
name|ProducerConfig
operator|.
name|VALUE_SERIALIZER_CLASS_CONFIG
argument_list|)
argument_list|)
decl_stmt|;
comment|/**    * @param configuration Job configs    *    * @return default consumer properties    */
specifier|static
name|Properties
name|consumerProperties
parameter_list|(
name|Configuration
name|configuration
parameter_list|)
block|{
specifier|final
name|Properties
name|props
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
comment|// we are managing the commit offset
name|props
operator|.
name|setProperty
argument_list|(
name|CommonClientConfigs
operator|.
name|CLIENT_ID_CONFIG
argument_list|,
name|Utilities
operator|.
name|getTaskId
argument_list|(
name|configuration
argument_list|)
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
name|ConsumerConfig
operator|.
name|ENABLE_AUTO_COMMIT_CONFIG
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
comment|// we are seeking in the stream so no reset
name|props
operator|.
name|setProperty
argument_list|(
name|ConsumerConfig
operator|.
name|AUTO_OFFSET_RESET_CONFIG
argument_list|,
literal|"none"
argument_list|)
expr_stmt|;
name|String
name|brokerEndPoint
init|=
name|configuration
operator|.
name|get
argument_list|(
name|KafkaTableProperties
operator|.
name|HIVE_KAFKA_BOOTSTRAP_SERVERS
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|brokerEndPoint
operator|==
literal|null
operator|||
name|brokerEndPoint
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Kafka Broker End Point is missing Please set Config "
operator|+
name|KafkaTableProperties
operator|.
name|HIVE_KAFKA_BOOTSTRAP_SERVERS
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
name|props
operator|.
name|setProperty
argument_list|(
name|CommonClientConfigs
operator|.
name|BOOTSTRAP_SERVERS_CONFIG
argument_list|,
name|brokerEndPoint
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
name|ConsumerConfig
operator|.
name|KEY_DESERIALIZER_CLASS_CONFIG
argument_list|,
name|ByteArrayDeserializer
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
name|ConsumerConfig
operator|.
name|VALUE_DESERIALIZER_CLASS_CONFIG
argument_list|,
name|ByteArrayDeserializer
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
comment|//case Kerberos is On
if|if
condition|(
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
name|addKerberosJaasConf
argument_list|(
name|configuration
argument_list|,
name|props
argument_list|)
expr_stmt|;
block|}
comment|// user can always override stuff
name|props
operator|.
name|putAll
argument_list|(
name|extractExtraProperties
argument_list|(
name|configuration
argument_list|,
name|CONSUMER_CONFIGURATION_PREFIX
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|props
return|;
block|}
specifier|private
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|extractExtraProperties
parameter_list|(
specifier|final
name|Configuration
name|configuration
parameter_list|,
name|String
name|prefix
parameter_list|)
block|{
name|ImmutableMap
operator|.
name|Builder
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|builder
init|=
name|ImmutableMap
operator|.
name|builder
argument_list|()
decl_stmt|;
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|kafkaProperties
init|=
name|configuration
operator|.
name|getValByRegex
argument_list|(
literal|"^"
operator|+
name|prefix
operator|+
literal|"\\..*"
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|entry
range|:
name|kafkaProperties
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|key
init|=
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|substring
argument_list|(
name|prefix
operator|.
name|length
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|FORBIDDEN_PROPERTIES
operator|.
name|contains
argument_list|(
name|key
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Not suppose to set Kafka Property "
operator|+
name|key
argument_list|)
throw|;
block|}
name|builder
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|builder
operator|.
name|build
argument_list|()
return|;
block|}
specifier|static
name|Properties
name|producerProperties
parameter_list|(
name|Configuration
name|configuration
parameter_list|)
block|{
specifier|final
name|String
name|writeSemanticValue
init|=
name|configuration
operator|.
name|get
argument_list|(
name|KafkaTableProperties
operator|.
name|WRITE_SEMANTIC_PROPERTY
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|KafkaOutputFormat
operator|.
name|WriteSemantic
name|writeSemantic
init|=
name|KafkaOutputFormat
operator|.
name|WriteSemantic
operator|.
name|valueOf
argument_list|(
name|writeSemanticValue
argument_list|)
decl_stmt|;
specifier|final
name|Properties
name|properties
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|String
name|brokerEndPoint
init|=
name|configuration
operator|.
name|get
argument_list|(
name|KafkaTableProperties
operator|.
name|HIVE_KAFKA_BOOTSTRAP_SERVERS
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|brokerEndPoint
operator|==
literal|null
operator|||
name|brokerEndPoint
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Kafka Broker End Point is missing Please set Config "
operator|+
name|KafkaTableProperties
operator|.
name|HIVE_KAFKA_BOOTSTRAP_SERVERS
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
name|properties
operator|.
name|setProperty
argument_list|(
name|CommonClientConfigs
operator|.
name|BOOTSTRAP_SERVERS_CONFIG
argument_list|,
name|brokerEndPoint
argument_list|)
expr_stmt|;
comment|//case Kerberos is On
if|if
condition|(
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
name|addKerberosJaasConf
argument_list|(
name|configuration
argument_list|,
name|properties
argument_list|)
expr_stmt|;
block|}
comment|// user can always override stuff
name|properties
operator|.
name|putAll
argument_list|(
name|extractExtraProperties
argument_list|(
name|configuration
argument_list|,
name|PRODUCER_CONFIGURATION_PREFIX
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|taskId
init|=
name|configuration
operator|.
name|get
argument_list|(
literal|"mapred.task.id"
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|properties
operator|.
name|setProperty
argument_list|(
name|CommonClientConfigs
operator|.
name|CLIENT_ID_CONFIG
argument_list|,
name|taskId
operator|==
literal|null
condition|?
literal|"random_"
operator|+
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
else|:
name|taskId
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|writeSemantic
condition|)
block|{
case|case
name|AT_LEAST_ONCE
case|:
name|properties
operator|.
name|setProperty
argument_list|(
name|ProducerConfig
operator|.
name|RETRIES_CONFIG
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
argument_list|)
expr_stmt|;
comment|//The number of acknowledgments the producer requires the leader to have received before considering a request as
comment|//complete. Here all means from all replicas.
name|properties
operator|.
name|setProperty
argument_list|(
name|ProducerConfig
operator|.
name|ACKS_CONFIG
argument_list|,
literal|"all"
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXACTLY_ONCE
case|:
comment|// Assuming that TaskId is ReducerId_attemptId. need the Reducer ID to fence out zombie kafka producers.
name|String
name|reducerId
init|=
name|getTaskId
argument_list|(
name|configuration
argument_list|)
decl_stmt|;
comment|//The number of acknowledgments the producer requires the leader to have received before considering a request as
comment|// complete, all means from all replicas.
name|properties
operator|.
name|setProperty
argument_list|(
name|ProducerConfig
operator|.
name|ACKS_CONFIG
argument_list|,
literal|"all"
argument_list|)
expr_stmt|;
name|properties
operator|.
name|setProperty
argument_list|(
name|ProducerConfig
operator|.
name|RETRIES_CONFIG
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
argument_list|)
expr_stmt|;
name|properties
operator|.
name|setProperty
argument_list|(
name|ProducerConfig
operator|.
name|TRANSACTIONAL_ID_CONFIG
argument_list|,
name|reducerId
argument_list|)
expr_stmt|;
comment|//Producer set to be IDEMPOTENT eg ensure that send() retries are idempotent.
name|properties
operator|.
name|setProperty
argument_list|(
name|ProducerConfig
operator|.
name|ENABLE_IDEMPOTENCE_CONFIG
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unknown Semantic "
operator|+
name|writeSemantic
argument_list|)
throw|;
block|}
return|return
name|properties
return|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"SameParameterValue"
argument_list|)
specifier|static
name|void
name|copyDependencyJars
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
modifier|...
name|classes
parameter_list|)
throws|throws
name|IOException
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|jars
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|FileSystem
name|localFs
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|jars
operator|.
name|addAll
argument_list|(
name|conf
operator|.
name|getStringCollection
argument_list|(
literal|"tmpjars"
argument_list|)
argument_list|)
expr_stmt|;
name|jars
operator|.
name|addAll
argument_list|(
name|Arrays
operator|.
name|stream
argument_list|(
name|classes
argument_list|)
operator|.
name|filter
argument_list|(
name|Objects
operator|::
name|nonNull
argument_list|)
operator|.
name|map
argument_list|(
name|clazz
lambda|->
block|{
name|String
name|path
init|=
name|Utilities
operator|.
name|jarFinderGetJar
argument_list|(
name|clazz
argument_list|)
decl_stmt|;
if|if
condition|(
name|path
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Could not find jar for class "
operator|+
name|clazz
operator|+
literal|" in order to ship it to the cluster."
argument_list|)
throw|;
block|}
try|try
block|{
if|if
condition|(
operator|!
name|localFs
operator|.
name|exists
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Could not validate jar file "
operator|+
name|path
operator|+
literal|" for class "
operator|+
name|clazz
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|path
return|;
block|}
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|jars
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|conf
operator|.
name|set
argument_list|(
literal|"tmpjars"
argument_list|,
name|StringUtils
operator|.
name|arrayToString
argument_list|(
name|jars
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
literal|0
index|]
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|static
name|AbstractSerDe
name|createDelegate
parameter_list|(
name|String
name|className
parameter_list|)
block|{
specifier|final
name|Class
argument_list|<
name|?
extends|extends
name|AbstractSerDe
argument_list|>
name|clazz
decl_stmt|;
try|try
block|{
comment|//noinspection unchecked
name|clazz
operator|=
operator|(
name|Class
argument_list|<
name|?
extends|extends
name|AbstractSerDe
argument_list|>
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|className
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
comment|// we are not setting conf thus null is okay
return|return
name|ReflectionUtil
operator|.
name|newInstance
argument_list|(
name|clazz
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|static
name|ProducerRecord
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|toProducerRecord
parameter_list|(
name|String
name|topic
parameter_list|,
name|KafkaWritable
name|value
parameter_list|)
block|{
return|return
operator|new
name|ProducerRecord
argument_list|<>
argument_list|(
name|topic
argument_list|,
name|value
operator|.
name|getPartition
argument_list|()
operator|!=
operator|-
literal|1
condition|?
name|value
operator|.
name|getPartition
argument_list|()
else|:
literal|null
argument_list|,
name|value
operator|.
name|getTimestamp
argument_list|()
operator|!=
operator|-
literal|1L
condition|?
name|value
operator|.
name|getTimestamp
argument_list|()
else|:
literal|null
argument_list|,
name|value
operator|.
name|getRecordKey
argument_list|()
argument_list|,
name|value
operator|.
name|getValue
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Check if the exception is Non-Retriable there a show stopper all we can do is clean and exit.    * @param exception input exception object.    * @return true if the exception is fatal thus we only can abort and rethrow the cause.    */
specifier|static
name|boolean
name|exceptionIsFatal
parameter_list|(
specifier|final
name|Throwable
name|exception
parameter_list|)
block|{
specifier|final
name|boolean
name|securityException
init|=
name|exception
operator|instanceof
name|AuthenticationException
operator|||
name|exception
operator|instanceof
name|AuthorizationException
operator|||
name|exception
operator|instanceof
name|SecurityDisabledException
decl_stmt|;
specifier|final
name|boolean
name|communicationException
init|=
name|exception
operator|instanceof
name|InvalidTopicException
operator|||
name|exception
operator|instanceof
name|UnknownServerException
operator|||
name|exception
operator|instanceof
name|SerializationException
operator|||
name|exception
operator|instanceof
name|OffsetMetadataTooLarge
operator|||
name|exception
operator|instanceof
name|IllegalStateException
decl_stmt|;
return|return
name|securityException
operator|||
name|communicationException
return|;
block|}
comment|/**    * Computes the kafka producer transaction id. The Tx id HAS to be the same across task restarts,    * that is why we are excluding the attempt id by removing the last string after last `_`.    * Assuming the taskId format is taskId_[m-r]_attemptId.    *    * @param hiveConf Hive Configuration.    * @return the taskId without the attempt id.    */
specifier|static
name|String
name|getTaskId
parameter_list|(
name|Configuration
name|hiveConf
parameter_list|)
block|{
name|String
name|id
init|=
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|hiveConf
operator|.
name|get
argument_list|(
literal|"mapred.task.id"
argument_list|,
literal|null
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|index
init|=
name|id
operator|.
name|lastIndexOf
argument_list|(
literal|"_"
argument_list|)
decl_stmt|;
if|if
condition|(
name|index
operator|!=
operator|-
literal|1
condition|)
block|{
return|return
name|id
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|index
argument_list|)
return|;
block|}
return|return
name|id
return|;
block|}
comment|/**    * Helper method that add Kerberos Jaas configs to the properties.    * @param configuration Hive config containing kerberos key and principal    * @param props properties to be populated    */
specifier|static
name|void
name|addKerberosJaasConf
parameter_list|(
name|Configuration
name|configuration
parameter_list|,
name|Properties
name|props
parameter_list|)
block|{
comment|//based on this https://kafka.apache.org/documentation/#security_jaas_client
name|props
operator|.
name|setProperty
argument_list|(
literal|"security.protocol"
argument_list|,
literal|"SASL_PLAINTEXT"
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"sasl.mechanism"
argument_list|,
literal|"GSSAPI"
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"sasl.kerberos.service.name"
argument_list|,
literal|"kafka"
argument_list|)
expr_stmt|;
comment|//Construct the principal/keytab
name|String
name|principalHost
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|configuration
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SERVER2_KERBEROS_PRINCIPAL
argument_list|)
decl_stmt|;
name|String
name|keyTab
init|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|configuration
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SERVER2_KERBEROS_KEYTAB
argument_list|)
decl_stmt|;
comment|// back to use LLAP keys if HS2 conf are not set or visible for the Task.
if|if
condition|(
name|principalHost
operator|==
literal|null
operator|||
name|principalHost
operator|.
name|isEmpty
argument_list|()
operator|||
name|keyTab
operator|==
literal|null
operator|||
name|keyTab
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|keyTab
operator|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|configuration
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|LLAP_FS_KERBEROS_KEYTAB_FILE
argument_list|)
expr_stmt|;
name|principalHost
operator|=
name|HiveConf
operator|.
name|getVar
argument_list|(
name|configuration
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|LLAP_FS_KERBEROS_PRINCIPAL
argument_list|)
expr_stmt|;
block|}
name|String
name|principal
decl_stmt|;
try|try
block|{
name|principal
operator|=
name|SecurityUtil
operator|.
name|getServerPrincipal
argument_list|(
name|principalHost
argument_list|,
literal|"0.0.0.0"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Can not construct kerberos principal"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
specifier|final
name|String
name|jaasConf
init|=
name|String
operator|.
name|format
argument_list|(
name|JAAS_TEMPLATE
argument_list|,
name|keyTab
argument_list|,
name|principal
argument_list|)
decl_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"sasl.jaas.config"
argument_list|,
name|jaasConf
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"Kafka client running with following JAAS = [{}]"
argument_list|,
name|jaasConf
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

