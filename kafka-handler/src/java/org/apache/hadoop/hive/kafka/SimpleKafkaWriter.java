begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|kafka
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|ql
operator|.
name|exec
operator|.
name|FileSinkOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RecordWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|Callback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|KafkaProducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|ProducerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|KafkaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|serialization
operator|.
name|ByteArraySerializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_comment
comment|/**  * Hive to Kafka Simple Record Writer. It can be used to achieve AT LEAST ONCE semantic, or no guaranties at all.  */
end_comment

begin_class
class|class
name|SimpleKafkaWriter
implements|implements
name|FileSinkOperator
operator|.
name|RecordWriter
implements|,
name|RecordWriter
argument_list|<
name|BytesWritable
argument_list|,
name|KafkaWritable
argument_list|>
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|SimpleKafkaWriter
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|TIMEOUT_CONFIG_HINT
init|=
literal|"Try increasing producer property [`retries`] and [`retry.backoff.ms`] to avoid this error [{}]."
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|ABORT_MSG
init|=
literal|"Writer [%s] aborting Send. Caused by [%s]. Sending to topic [%s]. Record offset [%s];"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|ACTION_ABORT
init|=
literal|"WriterId [{}] lost record from Topic [{}], delivery Semantic [{}] -> ACTION=ABORT, ERROR caused by [{}]"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|ACTION_CARRY_ON
init|=
literal|"WriterId [{}], lost record from Topic [{}], delivery Semantic [{}] -> ACTION=CARRY-ON"
decl_stmt|;
specifier|private
specifier|final
name|String
name|topic
decl_stmt|;
specifier|private
specifier|final
name|String
name|writerId
decl_stmt|;
specifier|private
specifier|final
name|KafkaOutputFormat
operator|.
name|WriteSemantic
name|writeSemantic
decl_stmt|;
specifier|private
specifier|final
name|KafkaProducer
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|producer
decl_stmt|;
specifier|private
specifier|final
name|Callback
name|callback
decl_stmt|;
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|Exception
argument_list|>
name|sendExceptionRef
init|=
operator|new
name|AtomicReference
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|AtomicLong
name|lostRecords
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
specifier|private
name|long
name|sentRecords
init|=
literal|0L
decl_stmt|;
comment|/**    * @param topic Kafka Topic.    * @param writerId Writer Id use for logging.    * @param atLeastOnce true if the desired delivery semantic is at least once.    * @param properties Kafka Producer properties.    */
name|SimpleKafkaWriter
parameter_list|(
name|String
name|topic
parameter_list|,
annotation|@
name|Nullable
name|String
name|writerId
parameter_list|,
name|boolean
name|atLeastOnce
parameter_list|,
name|Properties
name|properties
parameter_list|)
block|{
name|this
operator|.
name|writeSemantic
operator|=
name|atLeastOnce
condition|?
name|KafkaOutputFormat
operator|.
name|WriteSemantic
operator|.
name|AT_LEAST_ONCE
else|:
name|KafkaOutputFormat
operator|.
name|WriteSemantic
operator|.
name|BEST_EFFORT
expr_stmt|;
name|this
operator|.
name|writerId
operator|=
name|writerId
operator|==
literal|null
condition|?
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
else|:
name|writerId
expr_stmt|;
name|this
operator|.
name|topic
operator|=
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|topic
argument_list|,
literal|"Topic can not be null"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|properties
operator|.
name|getProperty
argument_list|(
name|ProducerConfig
operator|.
name|BOOTSTRAP_SERVERS_CONFIG
argument_list|)
operator|!=
literal|null
argument_list|,
literal|"set ["
operator|+
name|ProducerConfig
operator|.
name|BOOTSTRAP_SERVERS_CONFIG
operator|+
literal|"] property"
argument_list|)
expr_stmt|;
name|producer
operator|=
operator|new
name|KafkaProducer
argument_list|<>
argument_list|(
name|properties
argument_list|,
operator|new
name|ByteArraySerializer
argument_list|()
argument_list|,
operator|new
name|ByteArraySerializer
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|callback
operator|=
parameter_list|(
name|metadata
parameter_list|,
name|exception
parameter_list|)
lambda|->
block|{
if|if
condition|(
name|exception
operator|!=
literal|null
condition|)
block|{
name|lostRecords
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
switch|switch
condition|(
name|writeSemantic
condition|)
block|{
case|case
name|BEST_EFFORT
case|:
name|LOG
operator|.
name|warn
argument_list|(
name|ACTION_CARRY_ON
argument_list|,
name|getWriterId
argument_list|()
argument_list|,
name|topic
argument_list|,
name|writeSemantic
argument_list|)
expr_stmt|;
break|break;
case|case
name|AT_LEAST_ONCE
case|:
name|LOG
operator|.
name|error
argument_list|(
name|ACTION_ABORT
argument_list|,
name|getWriterId
argument_list|()
argument_list|,
name|topic
argument_list|,
name|writeSemantic
argument_list|,
name|exception
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|sendExceptionRef
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|exception
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unsupported delivery semantic "
operator|+
name|writeSemantic
argument_list|)
throw|;
block|}
block|}
block|}
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting WriterId [{}], Delivery Semantic [{}], Target Kafka Topic [{}]"
argument_list|,
name|writerId
argument_list|,
name|writeSemantic
argument_list|,
name|topic
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|Writable
name|w
parameter_list|)
throws|throws
name|IOException
block|{
name|checkExceptions
argument_list|()
expr_stmt|;
try|try
block|{
name|sentRecords
operator|++
expr_stmt|;
name|producer
operator|.
name|send
argument_list|(
name|KafkaUtils
operator|.
name|toProducerRecord
argument_list|(
name|topic
argument_list|,
operator|(
name|KafkaWritable
operator|)
name|w
argument_list|)
argument_list|,
name|callback
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KafkaException
name|kafkaException
parameter_list|)
block|{
name|handleKafkaException
argument_list|(
name|kafkaException
argument_list|)
expr_stmt|;
name|checkExceptions
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|handleKafkaException
parameter_list|(
name|KafkaException
name|kafkaException
parameter_list|)
block|{
if|if
condition|(
name|kafkaException
operator|instanceof
name|TimeoutException
condition|)
block|{
comment|//This might happen if the producer cannot send data to the Kafka cluster and thus, its internal buffer fills up.
name|LOG
operator|.
name|error
argument_list|(
name|TIMEOUT_CONFIG_HINT
argument_list|,
name|kafkaException
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|KafkaUtils
operator|.
name|exceptionIsFatal
argument_list|(
name|kafkaException
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|String
operator|.
name|format
argument_list|(
name|ABORT_MSG
argument_list|,
name|writerId
argument_list|,
name|kafkaException
operator|.
name|getMessage
argument_list|()
argument_list|,
name|topic
argument_list|,
operator|-
literal|1L
argument_list|)
argument_list|)
expr_stmt|;
name|sendExceptionRef
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|kafkaException
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|writeSemantic
operator|==
name|KafkaOutputFormat
operator|.
name|WriteSemantic
operator|.
name|AT_LEAST_ONCE
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|ACTION_ABORT
argument_list|,
name|writerId
argument_list|,
name|topic
argument_list|,
name|writeSemantic
argument_list|,
name|kafkaException
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|sendExceptionRef
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|kafkaException
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|ACTION_CARRY_ON
argument_list|,
name|writerId
argument_list|,
name|topic
argument_list|,
name|writeSemantic
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|abort
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Aborting is set to TRUE, Closing writerId [{}] without flush."
argument_list|,
name|writerId
argument_list|)
expr_stmt|;
name|producer
operator|.
name|close
argument_list|(
literal|0
argument_list|,
name|TimeUnit
operator|.
name|MICROSECONDS
argument_list|)
expr_stmt|;
return|return;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Flushing Kafka Producer with writerId [{}]"
argument_list|,
name|writerId
argument_list|)
expr_stmt|;
name|producer
operator|.
name|flush
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing WriterId [{}]"
argument_list|,
name|writerId
argument_list|)
expr_stmt|;
name|producer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed WriterId [{}] Delivery semantic [{}], Topic[{}], Total sent Records [{}], Total Lost Records [{}]"
argument_list|,
name|writerId
argument_list|,
name|writeSemantic
argument_list|,
name|topic
argument_list|,
name|sentRecords
argument_list|,
name|lostRecords
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|checkExceptions
argument_list|()
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
name|String
name|getWriterId
parameter_list|()
block|{
return|return
name|writerId
return|;
block|}
annotation|@
name|VisibleForTesting
name|long
name|getLostRecords
parameter_list|()
block|{
return|return
name|lostRecords
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
name|long
name|getSentRecords
parameter_list|()
block|{
return|return
name|sentRecords
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|BytesWritable
name|bytesWritable
parameter_list|,
name|KafkaWritable
name|kafkaWritable
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|write
argument_list|(
name|kafkaWritable
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|(
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|close
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|checkExceptions
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|sendExceptionRef
operator|.
name|get
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Send Exception Aborting write from writerId [{}]"
argument_list|,
name|writerId
argument_list|)
expr_stmt|;
name|producer
operator|.
name|close
argument_list|(
literal|0
argument_list|,
name|TimeUnit
operator|.
name|MICROSECONDS
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|sendExceptionRef
operator|.
name|get
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

