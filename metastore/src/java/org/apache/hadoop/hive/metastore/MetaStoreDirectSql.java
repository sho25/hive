begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|join
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|repeat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|jdo
operator|.
name|PersistenceManager
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|jdo
operator|.
name|Query
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Order
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SerDeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SkewedInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SkewedValueList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|FilterParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|LeafNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|LogicalOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|Operator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|TreeNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|parser
operator|.
name|ExpressionTree
operator|.
name|TreeVisitor
import|;
end_import

begin_comment
comment|/**  * This class contains the optimizations for MetaStore that rely on direct SQL access to  * the underlying database. It should use ANSI SQL and be compatible with common databases  * such as MySQL (note that MySQL doesn't use full ANSI mode by default), Postgres, etc.  *  * As of now, only the partition retrieval is done this way to improve job startup time;  * JDOQL partition retrieval is still present so as not to limit the ORM solution we have  * to SQL stores only. There's always a way to do without direct SQL.  */
end_comment

begin_class
class|class
name|MetaStoreDirectSql
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|MetaStoreDirectSql
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|PersistenceManager
name|pm
decl_stmt|;
specifier|public
name|MetaStoreDirectSql
parameter_list|(
name|PersistenceManager
name|pm
parameter_list|)
block|{
name|this
operator|.
name|pm
operator|=
name|pm
expr_stmt|;
block|}
comment|/**    * Gets partitions by using direct SQL queries.    * @param dbName Metastore db name.    * @param tblName Metastore table name.    * @param partNames Partition names to get.    * @return List of partitions.    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsViaSqlFilter
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partNames
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|list
init|=
name|repeat
argument_list|(
literal|",?"
argument_list|,
name|partNames
operator|.
name|size
argument_list|()
argument_list|)
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
decl_stmt|;
return|return
name|getPartitionsViaSqlFilterInternal
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
literal|"and PARTITIONS.PART_NAME in ("
operator|+
name|list
operator|+
literal|")"
argument_list|,
name|partNames
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Gets partitions by using direct SQL queries.    * @param dbName Metastore db name.    * @param tblName Metastore table name.    * @param parser The parsed filter from which the SQL filter will be generated.    * @return List of partitions.    */
specifier|public
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsViaSqlFilter
parameter_list|(
name|Table
name|table
parameter_list|,
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|FilterParser
name|parser
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|params
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|,
name|joins
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|sqlFilter
init|=
operator|(
name|parser
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
name|PartitionFilterGenerator
operator|.
name|generateSqlFilter
argument_list|(
name|table
argument_list|,
name|parser
operator|.
name|tree
argument_list|,
name|params
argument_list|,
name|joins
argument_list|)
decl_stmt|;
return|return
name|getPartitionsViaSqlFilterInternal
argument_list|(
name|dbName
argument_list|,
name|tblName
argument_list|,
name|sqlFilter
argument_list|,
name|params
argument_list|,
name|joins
argument_list|)
return|;
block|}
comment|/**    * Get partition objects for the query using direct SQL queries, to avoid bazillion    * queries created by DN retrieving stuff for each object individually.    * @param dbName Metastore db name.    * @param tblName Metastore table name.    * @param sqlFilter SQL filter to use. Better be SQL92-compliant. Can be null.    * @param paramsForFilter params for ?-s in SQL filter text. Params must be in order.    * @param joinsForFilter if the filter needs additional join statement, they must be in    *                       this list. Better be SQL92-compliant.    * @return List of partition objects. FieldSchema is currently not populated.    */
specifier|private
name|List
argument_list|<
name|Partition
argument_list|>
name|getPartitionsViaSqlFilterInternal
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|tblName
parameter_list|,
name|String
name|sqlFilter
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|paramsForFilter
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|joinsForFilter
parameter_list|)
throws|throws
name|MetaException
block|{
name|boolean
name|doTrace
init|=
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
decl_stmt|;
comment|// Get all simple fields for partitions and related objects, which we can map one-on-one.
comment|// We will do this in 2 queries to use different existing indices for each one.
comment|// We do not get table and DB name, assuming they are the same as we are using to filter.
comment|// TODO: We might want to tune the indexes instead. With current ones MySQL performs
comment|// poorly, esp. with 'order by' w/o index on large tables, even if the number of actual
comment|// results is small (query that returns 8 out of 32k partitions can go 4sec. to 0sec. by
comment|// just adding a PART_ID IN (...) filter that doesn't alter the results to it, probably
comment|// causing it to not sort the entire table due to not knowing how selective the filter is.
name|String
name|queryText
init|=
literal|"select PARTITIONS.PART_ID from PARTITIONS"
operator|+
literal|"  inner join TBLS on PARTITIONS.TBL_ID = TBLS.TBL_ID "
operator|+
literal|"  inner join DBS on TBLS.DB_ID = DBS.DB_ID "
operator|+
name|join
argument_list|(
name|joinsForFilter
argument_list|,
literal|' '
argument_list|)
operator|+
literal|" where TBLS.TBL_NAME = ? and DBS.NAME = ?"
operator|+
operator|(
operator|(
name|sqlFilter
operator|==
literal|null
operator|)
condition|?
literal|""
else|:
literal|" "
operator|+
name|sqlFilter
operator|)
decl_stmt|;
name|Object
index|[]
name|params
init|=
operator|new
name|Object
index|[
name|paramsForFilter
operator|.
name|size
argument_list|()
operator|+
literal|2
index|]
decl_stmt|;
name|params
index|[
literal|0
index|]
operator|=
name|tblName
expr_stmt|;
name|params
index|[
literal|1
index|]
operator|=
name|dbName
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|paramsForFilter
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|params
index|[
name|i
operator|+
literal|2
index|]
operator|=
name|paramsForFilter
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
name|long
name|start
init|=
name|doTrace
condition|?
name|System
operator|.
name|nanoTime
argument_list|()
else|:
literal|0
decl_stmt|;
name|Query
name|query
init|=
name|pm
operator|.
name|newQuery
argument_list|(
literal|"javax.jdo.query.SQL"
argument_list|,
name|queryText
argument_list|)
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|List
argument_list|<
name|Object
argument_list|>
name|sqlResult
init|=
operator|(
name|List
argument_list|<
name|Object
argument_list|>
operator|)
name|query
operator|.
name|executeWithArray
argument_list|(
name|params
argument_list|)
decl_stmt|;
if|if
condition|(
name|sqlResult
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|()
return|;
comment|// no partitions, bail early.
block|}
name|long
name|queryTime
init|=
name|doTrace
condition|?
name|System
operator|.
name|nanoTime
argument_list|()
else|:
literal|0
decl_stmt|;
comment|// Prepare StringBuilder for "PART_ID in (...)" to use in future queries.
name|int
name|sbCapacity
init|=
name|sqlResult
operator|.
name|size
argument_list|()
operator|*
literal|7
decl_stmt|;
comment|// if there are 100k things => 6 chars, plus comma
name|StringBuilder
name|partSb
init|=
operator|new
name|StringBuilder
argument_list|(
name|sbCapacity
argument_list|)
decl_stmt|;
comment|// Assume db and table names are the same for all partition, that's what we're selecting for.
for|for
control|(
name|Object
name|partitionId
range|:
name|sqlResult
control|)
block|{
name|partSb
operator|.
name|append
argument_list|(
operator|(
name|Long
operator|)
name|partitionId
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|String
name|partIds
init|=
name|trimCommaList
argument_list|(
name|partSb
argument_list|)
decl_stmt|;
if|if
condition|(
name|doTrace
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Direct SQL query in "
operator|+
operator|(
name|queryTime
operator|-
name|start
operator|)
operator|/
literal|1000000.0
operator|+
literal|"ms + "
operator|+
operator|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|queryTime
operator|)
operator|/
literal|1000000.0
operator|+
literal|"ms, the query is [ "
operator|+
name|queryText
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
comment|// Now get most of the other fields.
name|queryText
operator|=
literal|"select PARTITIONS.PART_ID, SDS.SD_ID, SDS.CD_ID, SERDES.SERDE_ID, "
operator|+
literal|"  PARTITIONS.CREATE_TIME, PARTITIONS.LAST_ACCESS_TIME, SDS.INPUT_FORMAT, "
operator|+
literal|"  SDS.IS_COMPRESSED, SDS.IS_STOREDASSUBDIRECTORIES, SDS.LOCATION,  SDS.NUM_BUCKETS, "
operator|+
literal|"  SDS.OUTPUT_FORMAT, SERDES.NAME, SERDES.SLIB "
operator|+
literal|"from PARTITIONS"
operator|+
literal|"  left outer join SDS on PARTITIONS.SD_ID = SDS.SD_ID "
operator|+
literal|"  left outer join SERDES on SDS.SERDE_ID = SERDES.SERDE_ID "
operator|+
literal|"where PART_ID in ("
operator|+
name|partIds
operator|+
literal|") order by PART_NAME asc"
expr_stmt|;
name|start
operator|=
name|doTrace
condition|?
name|System
operator|.
name|nanoTime
argument_list|()
else|:
literal|0
expr_stmt|;
name|query
operator|=
name|pm
operator|.
name|newQuery
argument_list|(
literal|"javax.jdo.query.SQL"
argument_list|,
name|queryText
argument_list|)
expr_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|List
argument_list|<
name|Object
index|[]
argument_list|>
name|sqlResult2
init|=
operator|(
name|List
argument_list|<
name|Object
index|[]
argument_list|>
operator|)
name|query
operator|.
name|executeWithArray
argument_list|(
name|params
argument_list|)
decl_stmt|;
name|queryTime
operator|=
name|doTrace
condition|?
name|System
operator|.
name|nanoTime
argument_list|()
else|:
literal|0
expr_stmt|;
comment|// Read all the fields and create partitions, SDs and serdes.
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Partition
argument_list|>
name|partitions
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Partition
argument_list|>
argument_list|()
decl_stmt|;
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|StorageDescriptor
argument_list|>
name|sds
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|StorageDescriptor
argument_list|>
argument_list|()
decl_stmt|;
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|SerDeInfo
argument_list|>
name|serdes
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|SerDeInfo
argument_list|>
argument_list|()
decl_stmt|;
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
argument_list|>
name|colss
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
comment|// Keep order by name, consistent with JDO.
name|ArrayList
argument_list|<
name|Partition
argument_list|>
name|orderedResult
init|=
operator|new
name|ArrayList
argument_list|<
name|Partition
argument_list|>
argument_list|(
name|sqlResult
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Prepare StringBuilder-s for "in (...)" lists to use in one-to-many queries.
name|StringBuilder
name|sdSb
init|=
operator|new
name|StringBuilder
argument_list|(
name|sbCapacity
argument_list|)
decl_stmt|,
name|serdeSb
init|=
operator|new
name|StringBuilder
argument_list|(
name|sbCapacity
argument_list|)
decl_stmt|;
name|StringBuilder
name|colsSb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|7
argument_list|)
decl_stmt|;
comment|// We expect that there's only one field schema.
name|tblName
operator|=
name|tblName
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
name|dbName
operator|=
name|dbName
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
for|for
control|(
name|Object
index|[]
name|fields
range|:
name|sqlResult2
control|)
block|{
comment|// Here comes the ugly part...
name|long
name|partitionId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
literal|0
index|]
decl_stmt|;
name|Long
name|sdId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
literal|1
index|]
decl_stmt|;
name|Long
name|colId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
literal|2
index|]
decl_stmt|;
name|Long
name|serdeId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
literal|3
index|]
decl_stmt|;
if|if
condition|(
name|sdId
operator|==
literal|null
operator|||
name|colId
operator|==
literal|null
operator|||
name|serdeId
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Unexpected null for one of the IDs, SD "
operator|+
name|sdId
operator|+
literal|", column "
operator|+
name|colId
operator|+
literal|", serde "
operator|+
name|serdeId
argument_list|)
throw|;
block|}
name|Partition
name|part
init|=
operator|new
name|Partition
argument_list|()
decl_stmt|;
name|orderedResult
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
comment|// Set the collection fields; some code might not check presence before accessing them.
name|part
operator|.
name|setParameters
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|part
operator|.
name|setValues
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|part
operator|.
name|setDbName
argument_list|(
name|dbName
argument_list|)
expr_stmt|;
name|part
operator|.
name|setTableName
argument_list|(
name|tblName
argument_list|)
expr_stmt|;
if|if
condition|(
name|fields
index|[
literal|4
index|]
operator|!=
literal|null
condition|)
name|part
operator|.
name|setCreateTime
argument_list|(
operator|(
name|Integer
operator|)
name|fields
index|[
literal|4
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|fields
index|[
literal|5
index|]
operator|!=
literal|null
condition|)
name|part
operator|.
name|setLastAccessTime
argument_list|(
operator|(
name|Integer
operator|)
name|fields
index|[
literal|5
index|]
argument_list|)
expr_stmt|;
name|partitions
operator|.
name|put
argument_list|(
name|partitionId
argument_list|,
name|part
argument_list|)
expr_stmt|;
comment|// We assume each partition has an unique SD.
name|StorageDescriptor
name|sd
init|=
operator|new
name|StorageDescriptor
argument_list|()
decl_stmt|;
name|StorageDescriptor
name|oldSd
init|=
name|sds
operator|.
name|put
argument_list|(
name|sdId
argument_list|,
name|sd
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldSd
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Partitions reuse SDs; we don't expect that"
argument_list|)
throw|;
block|}
comment|// Set the collection fields; some code might not check presence before accessing them.
name|sd
operator|.
name|setSortCols
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Order
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setBucketCols
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setParameters
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setSkewedInfo
argument_list|(
operator|new
name|SkewedInfo
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|()
argument_list|,
operator|new
name|HashMap
argument_list|<
name|SkewedValueList
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setInputFormat
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|6
index|]
argument_list|)
expr_stmt|;
name|Boolean
name|tmpBoolean
init|=
name|extractSqlBoolean
argument_list|(
name|fields
index|[
literal|7
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmpBoolean
operator|!=
literal|null
condition|)
name|sd
operator|.
name|setCompressed
argument_list|(
name|tmpBoolean
argument_list|)
expr_stmt|;
name|tmpBoolean
operator|=
name|extractSqlBoolean
argument_list|(
name|fields
index|[
literal|8
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|tmpBoolean
operator|!=
literal|null
condition|)
name|sd
operator|.
name|setStoredAsSubDirectories
argument_list|(
name|tmpBoolean
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setLocation
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|9
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|fields
index|[
literal|10
index|]
operator|!=
literal|null
condition|)
name|sd
operator|.
name|setNumBuckets
argument_list|(
operator|(
name|Integer
operator|)
name|fields
index|[
literal|10
index|]
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setOutputFormat
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|11
index|]
argument_list|)
expr_stmt|;
name|sdSb
operator|.
name|append
argument_list|(
name|sdId
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
name|part
operator|.
name|setSd
argument_list|(
name|sd
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
init|=
name|colss
operator|.
name|get
argument_list|(
name|colId
argument_list|)
decl_stmt|;
comment|// We expect that colId will be the same for all (or many) SDs.
if|if
condition|(
name|cols
operator|==
literal|null
condition|)
block|{
name|cols
operator|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
expr_stmt|;
name|colss
operator|.
name|put
argument_list|(
name|colId
argument_list|,
name|cols
argument_list|)
expr_stmt|;
name|colsSb
operator|.
name|append
argument_list|(
name|colId
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sd
operator|.
name|setCols
argument_list|(
name|cols
argument_list|)
expr_stmt|;
comment|// We assume each SD has an unique serde.
name|SerDeInfo
name|serde
init|=
operator|new
name|SerDeInfo
argument_list|()
decl_stmt|;
name|SerDeInfo
name|oldSerde
init|=
name|serdes
operator|.
name|put
argument_list|(
name|serdeId
argument_list|,
name|serde
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldSerde
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"SDs reuse serdes; we don't expect that"
argument_list|)
throw|;
block|}
name|serde
operator|.
name|setParameters
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|serde
operator|.
name|setName
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|12
index|]
argument_list|)
expr_stmt|;
name|serde
operator|.
name|setSerializationLib
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|13
index|]
argument_list|)
expr_stmt|;
name|serdeSb
operator|.
name|append
argument_list|(
name|serdeId
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
name|sd
operator|.
name|setSerdeInfo
argument_list|(
name|serde
argument_list|)
expr_stmt|;
block|}
name|query
operator|.
name|closeAll
argument_list|()
expr_stmt|;
if|if
condition|(
name|doTrace
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Direct SQL query in "
operator|+
operator|(
name|queryTime
operator|-
name|start
operator|)
operator|/
literal|1000000.0
operator|+
literal|"ms + "
operator|+
operator|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|queryTime
operator|)
operator|/
literal|1000000.0
operator|+
literal|"ms, the query is [ "
operator|+
name|queryText
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
comment|// Prepare IN (blah) lists for the following queries. Cut off the final ','s.
name|String
name|sdIds
init|=
name|trimCommaList
argument_list|(
name|sdSb
argument_list|)
decl_stmt|,
name|serdeIds
init|=
name|trimCommaList
argument_list|(
name|serdeSb
argument_list|)
decl_stmt|,
name|colIds
init|=
name|trimCommaList
argument_list|(
name|colsSb
argument_list|)
decl_stmt|;
comment|// Now get all the one-to-many things. Start with partitions.
name|queryText
operator|=
literal|"select PART_ID, PARAM_KEY, PARAM_VALUE from PARTITION_PARAMS where PART_ID in ("
operator|+
name|partIds
operator|+
literal|") and PARAM_KEY is not null order by PART_ID asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|partitions
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|Partition
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|Partition
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
name|t
operator|.
name|putToParameters
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|queryText
operator|=
literal|"select PART_ID, PART_KEY_VAL from PARTITION_KEY_VALS where PART_ID in ("
operator|+
name|partIds
operator|+
literal|") and INTEGER_IDX>= 0 order by PART_ID asc, INTEGER_IDX asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|partitions
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|Partition
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|Partition
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
name|t
operator|.
name|addToValues
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// Get all the stuff for SD. Don't do empty-list check - we expect partitions do have SDs.
name|queryText
operator|=
literal|"select SD_ID, PARAM_KEY, PARAM_VALUE from SD_PARAMS where SD_ID in ("
operator|+
name|sdIds
operator|+
literal|") and PARAM_KEY is not null order by SD_ID asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|sds
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|StorageDescriptor
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|StorageDescriptor
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
name|t
operator|.
name|putToParameters
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// Note that SORT_COLS has "ORDER" column, which is not SQL92-legal. We have two choices
comment|// here - drop SQL92, or get '*' and be broken on certain schema changes. We do the latter.
name|queryText
operator|=
literal|"select SD_ID, COLUMN_NAME, SORT_COLS.* from SORT_COLS where SD_ID in ("
operator|+
name|sdIds
operator|+
literal|") and INTEGER_IDX>= 0 order by SD_ID asc, INTEGER_IDX asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|sds
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|StorageDescriptor
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|StorageDescriptor
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
if|if
condition|(
name|fields
index|[
literal|4
index|]
operator|==
literal|null
condition|)
return|return;
name|t
operator|.
name|addToSortCols
argument_list|(
operator|new
name|Order
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|,
operator|(
name|Integer
operator|)
name|fields
index|[
literal|4
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|queryText
operator|=
literal|"select SD_ID, BUCKET_COL_NAME from BUCKETING_COLS where SD_ID in ("
operator|+
name|sdIds
operator|+
literal|") and INTEGER_IDX>= 0 order by SD_ID asc, INTEGER_IDX asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|sds
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|StorageDescriptor
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|StorageDescriptor
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
name|t
operator|.
name|addToBucketCols
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// Skewed columns stuff.
name|queryText
operator|=
literal|"select SD_ID, SKEWED_COL_NAME from SKEWED_COL_NAMES where SD_ID in ("
operator|+
name|sdIds
operator|+
literal|") and INTEGER_IDX>= 0 order by SD_ID asc, INTEGER_IDX asc"
expr_stmt|;
name|boolean
name|hasSkewedColumns
init|=
name|loopJoinOrderedResult
argument_list|(
name|sds
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|StorageDescriptor
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|StorageDescriptor
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
if|if
condition|(
operator|!
name|t
operator|.
name|isSetSkewedInfo
argument_list|()
condition|)
name|t
operator|.
name|setSkewedInfo
argument_list|(
operator|new
name|SkewedInfo
argument_list|()
argument_list|)
expr_stmt|;
name|t
operator|.
name|getSkewedInfo
argument_list|()
operator|.
name|addToSkewedColNames
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
operator|>
literal|0
decl_stmt|;
comment|// Assume we don't need to fetch the rest of the skewed column data if we have no columns.
if|if
condition|(
name|hasSkewedColumns
condition|)
block|{
comment|// We are skipping the SKEWED_STRING_LIST table here, as it seems to be totally useless.
name|queryText
operator|=
literal|"select SKEWED_VALUES.SD_ID_OID, SKEWED_STRING_LIST_VALUES.STRING_LIST_ID, "
operator|+
literal|"  SKEWED_STRING_LIST_VALUES.STRING_LIST_VALUE "
operator|+
literal|"from SKEWED_VALUES "
operator|+
literal|"  left outer join SKEWED_STRING_LIST_VALUES on "
operator|+
literal|"    SKEWED_VALUES.STRING_LIST_ID_EID = SKEWED_STRING_LIST_VALUES.STRING_LIST_ID "
operator|+
literal|"where SKEWED_VALUES.SD_ID_OID in ("
operator|+
name|sdIds
operator|+
literal|") "
operator|+
literal|"  and SKEWED_VALUES.STRING_LIST_ID_EID is not null "
operator|+
literal|"  and SKEWED_VALUES.INTEGER_IDX>= 0 "
operator|+
literal|"order by SKEWED_VALUES.SD_ID_OID asc, SKEWED_VALUES.INTEGER_IDX asc, "
operator|+
literal|"  SKEWED_STRING_LIST_VALUES.INTEGER_IDX asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|sds
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|StorageDescriptor
argument_list|>
argument_list|()
block|{
specifier|private
name|Long
name|currentListId
decl_stmt|;
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|currentList
decl_stmt|;
specifier|public
name|void
name|apply
parameter_list|(
name|StorageDescriptor
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
if|if
condition|(
operator|!
name|t
operator|.
name|isSetSkewedInfo
argument_list|()
condition|)
name|t
operator|.
name|setSkewedInfo
argument_list|(
operator|new
name|SkewedInfo
argument_list|()
argument_list|)
expr_stmt|;
comment|// Note that this is not a typical list accumulator - there's no call to finalize
comment|// the last list. Instead we add list to SD first, as well as locally to add elements.
if|if
condition|(
name|fields
index|[
literal|1
index|]
operator|==
literal|null
condition|)
block|{
name|currentList
operator|=
literal|null
expr_stmt|;
comment|// left outer join produced a list with no values
name|currentListId
operator|=
literal|null
expr_stmt|;
name|t
operator|.
name|getSkewedInfo
argument_list|()
operator|.
name|addToSkewedColValues
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|long
name|fieldsListId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
literal|1
index|]
decl_stmt|;
if|if
condition|(
name|currentListId
operator|==
literal|null
operator|||
name|fieldsListId
operator|!=
name|currentListId
condition|)
block|{
name|currentList
operator|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|currentListId
operator|=
name|fieldsListId
expr_stmt|;
name|t
operator|.
name|getSkewedInfo
argument_list|()
operator|.
name|addToSkewedColValues
argument_list|(
name|currentList
argument_list|)
expr_stmt|;
block|}
name|currentList
operator|.
name|add
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
comment|// We are skipping the SKEWED_STRING_LIST table here, as it seems to be totally useless.
name|queryText
operator|=
literal|"select SKEWED_COL_VALUE_LOC_MAP.SD_ID, SKEWED_STRING_LIST_VALUES.STRING_LIST_ID,"
operator|+
literal|"  SKEWED_COL_VALUE_LOC_MAP.LOCATION, SKEWED_STRING_LIST_VALUES.STRING_LIST_VALUE "
operator|+
literal|"from SKEWED_COL_VALUE_LOC_MAP"
operator|+
literal|"  left outer join SKEWED_STRING_LIST_VALUES on SKEWED_COL_VALUE_LOC_MAP."
operator|+
literal|"STRING_LIST_ID_KID = SKEWED_STRING_LIST_VALUES.STRING_LIST_ID "
operator|+
literal|"where SKEWED_COL_VALUE_LOC_MAP.SD_ID in ("
operator|+
name|sdIds
operator|+
literal|")"
operator|+
literal|"  and SKEWED_COL_VALUE_LOC_MAP.STRING_LIST_ID_KID is not null "
operator|+
literal|"order by SKEWED_COL_VALUE_LOC_MAP.SD_ID asc,"
operator|+
literal|"  SKEWED_STRING_LIST_VALUES.INTEGER_IDX asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|sds
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|StorageDescriptor
argument_list|>
argument_list|()
block|{
specifier|private
name|Long
name|currentListId
decl_stmt|;
specifier|private
name|SkewedValueList
name|currentList
decl_stmt|;
specifier|public
name|void
name|apply
parameter_list|(
name|StorageDescriptor
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
if|if
condition|(
operator|!
name|t
operator|.
name|isSetSkewedInfo
argument_list|()
condition|)
name|t
operator|.
name|setSkewedInfo
argument_list|(
operator|new
name|SkewedInfo
argument_list|()
argument_list|)
expr_stmt|;
comment|// Note that this is not a typical list accumulator - there's no call to finalize
comment|// the last list. Instead we add list to SD first, as well as locally to add elements.
if|if
condition|(
name|fields
index|[
literal|1
index|]
operator|==
literal|null
condition|)
block|{
name|currentList
operator|=
literal|null
expr_stmt|;
comment|// left outer join produced a list with no values
name|currentListId
operator|=
literal|null
expr_stmt|;
name|t
operator|.
name|getSkewedInfo
argument_list|()
operator|.
name|putToSkewedColValueLocationMaps
argument_list|(
operator|new
name|SkewedValueList
argument_list|()
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|long
name|fieldsListId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
literal|1
index|]
decl_stmt|;
if|if
condition|(
name|currentListId
operator|==
literal|null
operator|||
name|fieldsListId
operator|!=
name|currentListId
condition|)
block|{
name|currentList
operator|=
operator|new
name|SkewedValueList
argument_list|()
expr_stmt|;
name|currentListId
operator|=
name|fieldsListId
expr_stmt|;
name|t
operator|.
name|getSkewedInfo
argument_list|()
operator|.
name|putToSkewedColValueLocationMaps
argument_list|(
name|currentList
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
name|currentList
operator|.
name|addToSkewedValueList
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|3
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
block|}
comment|// if (hasSkewedColumns)
comment|// Get FieldSchema stuff if any.
if|if
condition|(
operator|!
name|colss
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// We are skipping the CDS table here, as it seems to be totally useless.
name|queryText
operator|=
literal|"select CD_ID, COMMENT, COLUMN_NAME, TYPE_NAME from COLUMNS_V2 where CD_ID in ("
operator|+
name|colIds
operator|+
literal|") and INTEGER_IDX>= 0 order by CD_ID asc, INTEGER_IDX asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|colss
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|List
argument_list|<
name|FieldSchema
argument_list|>
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
name|t
operator|.
name|add
argument_list|(
operator|new
name|FieldSchema
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|3
index|]
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
comment|// Finally, get all the stuff for serdes - just the params.
name|queryText
operator|=
literal|"select SERDE_ID, PARAM_KEY, PARAM_VALUE from SERDE_PARAMS where SERDE_ID in ("
operator|+
name|serdeIds
operator|+
literal|") and PARAM_KEY is not null order by SERDE_ID asc"
expr_stmt|;
name|loopJoinOrderedResult
argument_list|(
name|serdes
argument_list|,
name|queryText
argument_list|,
literal|0
argument_list|,
operator|new
name|ApplyFunc
argument_list|<
name|SerDeInfo
argument_list|>
argument_list|()
block|{
specifier|public
name|void
name|apply
parameter_list|(
name|SerDeInfo
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
block|{
name|t
operator|.
name|putToParameters
argument_list|(
operator|(
name|String
operator|)
name|fields
index|[
literal|1
index|]
argument_list|,
operator|(
name|String
operator|)
name|fields
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|orderedResult
return|;
block|}
specifier|private
specifier|static
name|Boolean
name|extractSqlBoolean
parameter_list|(
name|Object
name|value
parameter_list|)
throws|throws
name|MetaException
block|{
comment|// MySQL has booleans, but e.g. Derby uses 'Y'/'N' mapping. People using derby probably
comment|// don't care about performance anyway, but let's cover the common case.
if|if
condition|(
name|value
operator|==
literal|null
condition|)
return|return
literal|null
return|;
if|if
condition|(
name|value
operator|instanceof
name|Boolean
condition|)
return|return
operator|(
name|Boolean
operator|)
name|value
return|;
name|Character
name|c
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|value
operator|instanceof
name|String
operator|&&
operator|(
operator|(
name|String
operator|)
name|value
operator|)
operator|.
name|length
argument_list|()
operator|==
literal|1
condition|)
block|{
name|c
operator|=
operator|(
operator|(
name|String
operator|)
name|value
operator|)
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|c
operator|==
literal|'Y'
condition|)
return|return
literal|true
return|;
if|if
condition|(
name|c
operator|==
literal|'N'
condition|)
return|return
literal|false
return|;
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Cannot extrace boolean from column value "
operator|+
name|value
argument_list|)
throw|;
block|}
specifier|private
specifier|static
name|String
name|trimCommaList
parameter_list|(
name|StringBuilder
name|sb
parameter_list|)
block|{
if|if
condition|(
name|sb
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|setLength
argument_list|(
name|sb
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
specifier|abstract
class|class
name|ApplyFunc
parameter_list|<
name|Target
parameter_list|>
block|{
specifier|public
specifier|abstract
name|void
name|apply
parameter_list|(
name|Target
name|t
parameter_list|,
name|Object
index|[]
name|fields
parameter_list|)
function_decl|;
block|}
comment|/**    * Merges applies the result of a PM SQL query into a tree of object.    * Essentially it's an object join. DN could do this for us, but it issues queries    * separately for every object, which is suboptimal.    * @param tree The object tree, by ID.    * @param queryText The query text.    * @param keyIndex Index of the Long column corresponding to the map ID in query result rows.    * @param func The function that is called on each (object,row) pair with the same id.    * @return the count of results returned from the query.    */
specifier|private
parameter_list|<
name|T
parameter_list|>
name|int
name|loopJoinOrderedResult
parameter_list|(
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|T
argument_list|>
name|tree
parameter_list|,
name|String
name|queryText
parameter_list|,
name|int
name|keyIndex
parameter_list|,
name|ApplyFunc
argument_list|<
name|T
argument_list|>
name|func
parameter_list|)
throws|throws
name|MetaException
block|{
name|boolean
name|doTrace
init|=
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
decl_stmt|;
name|long
name|start
init|=
name|doTrace
condition|?
name|System
operator|.
name|nanoTime
argument_list|()
else|:
literal|0
decl_stmt|;
name|Query
name|query
init|=
name|pm
operator|.
name|newQuery
argument_list|(
literal|"javax.jdo.query.SQL"
argument_list|,
name|queryText
argument_list|)
decl_stmt|;
name|Object
name|result
init|=
name|query
operator|.
name|execute
argument_list|()
decl_stmt|;
name|long
name|queryTime
init|=
name|doTrace
condition|?
name|System
operator|.
name|nanoTime
argument_list|()
else|:
literal|0
decl_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
name|query
operator|.
name|closeAll
argument_list|()
expr_stmt|;
return|return
literal|0
return|;
block|}
if|if
condition|(
operator|!
operator|(
name|result
operator|instanceof
name|List
argument_list|<
name|?
argument_list|>
operator|)
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Wrong result type "
operator|+
name|result
operator|.
name|getClass
argument_list|()
argument_list|)
throw|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|List
argument_list|<
name|Object
index|[]
argument_list|>
name|list
init|=
operator|(
name|List
argument_list|<
name|Object
index|[]
argument_list|>
operator|)
name|result
decl_stmt|;
name|Iterator
argument_list|<
name|Object
index|[]
argument_list|>
name|iter
init|=
name|list
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Object
index|[]
name|fields
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|T
argument_list|>
name|entry
range|:
name|tree
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|fields
operator|==
literal|null
operator|&&
operator|!
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
break|break;
name|long
name|id
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
while|while
condition|(
name|fields
operator|!=
literal|null
operator|||
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
if|if
condition|(
name|fields
operator|==
literal|null
condition|)
block|{
name|fields
operator|=
name|iter
operator|.
name|next
argument_list|()
expr_stmt|;
block|}
name|long
name|nestedId
init|=
operator|(
name|Long
operator|)
name|fields
index|[
name|keyIndex
index|]
decl_stmt|;
if|if
condition|(
name|nestedId
operator|<
name|id
condition|)
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Found entries for unknown ID "
operator|+
name|nestedId
argument_list|)
throw|;
if|if
condition|(
name|nestedId
operator|>
name|id
condition|)
break|break;
comment|// fields belong to one of the next entries
name|func
operator|.
name|apply
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|fields
argument_list|)
expr_stmt|;
name|fields
operator|=
literal|null
expr_stmt|;
block|}
block|}
name|int
name|rv
init|=
name|list
operator|.
name|size
argument_list|()
decl_stmt|;
name|query
operator|.
name|closeAll
argument_list|()
expr_stmt|;
if|if
condition|(
name|doTrace
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Direct SQL query in "
operator|+
operator|(
name|queryTime
operator|-
name|start
operator|)
operator|/
literal|1000000.0
operator|+
literal|"ms + "
operator|+
operator|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|queryTime
operator|)
operator|/
literal|1000000.0
operator|+
literal|"ms, the query is ["
operator|+
name|queryText
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
return|return
name|rv
return|;
block|}
specifier|private
specifier|static
class|class
name|PartitionFilterGenerator
implements|implements
name|TreeVisitor
block|{
specifier|private
specifier|final
name|Table
name|table
decl_stmt|;
specifier|private
specifier|final
name|StringBuilder
name|filterBuffer
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|params
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|joins
decl_stmt|;
specifier|private
name|PartitionFilterGenerator
parameter_list|(
name|Table
name|table
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|params
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|joins
parameter_list|)
block|{
name|this
operator|.
name|table
operator|=
name|table
expr_stmt|;
name|this
operator|.
name|params
operator|=
name|params
expr_stmt|;
name|this
operator|.
name|joins
operator|=
name|joins
expr_stmt|;
name|this
operator|.
name|filterBuffer
operator|=
operator|new
name|StringBuilder
argument_list|()
expr_stmt|;
block|}
comment|/**      * Generate the ANSI SQL92 filter for the given expression tree      * @param table the table being queried      * @param params the ordered parameters for the resulting expression      * @param joins the joins necessary for the resulting expression      * @return the string representation of the expression tree      */
specifier|public
specifier|static
name|String
name|generateSqlFilter
parameter_list|(
name|Table
name|table
parameter_list|,
name|ExpressionTree
name|tree
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|params
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|joins
parameter_list|)
throws|throws
name|MetaException
block|{
assert|assert
name|table
operator|!=
literal|null
assert|;
if|if
condition|(
name|tree
operator|.
name|getRoot
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return
literal|""
return|;
block|}
name|PartitionFilterGenerator
name|visitor
init|=
operator|new
name|PartitionFilterGenerator
argument_list|(
name|table
argument_list|,
name|params
argument_list|,
name|joins
argument_list|)
decl_stmt|;
name|tree
operator|.
name|getRoot
argument_list|()
operator|.
name|accept
argument_list|(
name|visitor
argument_list|)
expr_stmt|;
comment|// Some joins might be null (see processNode for LeafNode), clean them up.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|joins
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|joins
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|!=
literal|null
condition|)
continue|continue;
name|joins
operator|.
name|remove
argument_list|(
name|i
operator|--
argument_list|)
expr_stmt|;
block|}
return|return
literal|"and ("
operator|+
name|visitor
operator|.
name|filterBuffer
operator|.
name|toString
argument_list|()
operator|+
literal|")"
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
name|TreeNode
name|node
parameter_list|)
throws|throws
name|MetaException
block|{
assert|assert
name|node
operator|!=
literal|null
operator|&&
name|node
operator|.
name|getLhs
argument_list|()
operator|!=
literal|null
operator|&&
name|node
operator|.
name|getRhs
argument_list|()
operator|!=
literal|null
assert|;
name|filterBuffer
operator|.
name|append
argument_list|(
literal|" ("
argument_list|)
expr_stmt|;
name|node
operator|.
name|getLhs
argument_list|()
operator|.
name|accept
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|filterBuffer
operator|.
name|append
argument_list|(
operator|(
name|node
operator|.
name|getAndOr
argument_list|()
operator|==
name|LogicalOperator
operator|.
name|AND
operator|)
condition|?
literal|" and "
else|:
literal|" or "
argument_list|)
expr_stmt|;
name|node
operator|.
name|getRhs
argument_list|()
operator|.
name|accept
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|filterBuffer
operator|.
name|append
argument_list|(
literal|") "
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
name|LeafNode
name|node
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|node
operator|.
name|operator
operator|==
name|Operator
operator|.
name|LIKE
condition|)
block|{
comment|// ANSI92 supports || for concatenation (we need to concat '%'-s to the parameter),
comment|// but it doesn't work on all RDBMSes, e.g. on MySQL by default. So don't use it for now.
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"LIKE is not supported for SQL filter pushdown"
argument_list|)
throw|;
block|}
name|int
name|partColCount
init|=
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|partColIndex
init|=
name|node
operator|.
name|getPartColIndexForFilter
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|String
name|valueAsString
init|=
name|node
operator|.
name|getFilterPushdownParam
argument_list|(
name|table
argument_list|,
name|partColIndex
argument_list|)
decl_stmt|;
comment|// Add parameters linearly; we are traversing leaf nodes LTR, so they would match correctly.
name|params
operator|.
name|add
argument_list|(
name|valueAsString
argument_list|)
expr_stmt|;
if|if
condition|(
name|joins
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// There's a fixed number of partition cols that we might have filters on. To avoid
comment|// joining multiple times for one column (if there are several filters on it), we will
comment|// keep numCols elements in the list, one for each column; we will fill it with nulls,
comment|// put each join at a corresponding index when necessary, and remove nulls in the end.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|partColCount
condition|;
operator|++
name|i
control|)
block|{
name|joins
operator|.
name|add
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|joins
operator|.
name|get
argument_list|(
name|partColIndex
argument_list|)
operator|==
literal|null
condition|)
block|{
name|joins
operator|.
name|set
argument_list|(
name|partColIndex
argument_list|,
literal|"inner join PARTITION_KEY_VALS as FILTER"
operator|+
name|partColIndex
operator|+
literal|" on FILTER"
operator|+
name|partColIndex
operator|+
literal|".PART_ID = PARTITIONS.PART_ID and FILTER"
operator|+
name|partColIndex
operator|+
literal|".INTEGER_IDX = "
operator|+
name|partColIndex
argument_list|)
expr_stmt|;
block|}
name|String
name|tableValue
init|=
literal|"FILTER"
operator|+
name|partColIndex
operator|+
literal|".PART_KEY_VAL"
decl_stmt|;
comment|// TODO: need casts here if #doesOperatorSupportIntegral is amended to include lt/gt/etc.
name|filterBuffer
operator|.
name|append
argument_list|(
name|node
operator|.
name|isReverseOrder
condition|?
literal|"(? "
operator|+
name|node
operator|.
name|operator
operator|.
name|getSqlOp
argument_list|()
operator|+
literal|" "
operator|+
name|tableValue
operator|+
literal|")"
else|:
literal|"("
operator|+
name|tableValue
operator|+
literal|" "
operator|+
name|node
operator|.
name|operator
operator|.
name|getSqlOp
argument_list|()
operator|+
literal|" ?)"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

