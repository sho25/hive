begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|hbase
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|CommandLine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|GnuParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|HelpFormatter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|OptionBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|Options
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|ParseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|Deadline
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|ObjectStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|RawStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|NoSuchObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Role
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ArrayBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|BlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_comment
comment|/**  * A tool to take the contents of an RDBMS based Hive metastore and import it into an HBase based  * one.  To use this the config files for Hive configured to work with the RDBMS (that is,  * including the JDBC string, etc.) as well as HBase configuration files must be in the path.  * There should not be a hive-site.xml that specifies HBaseStore in the path.  This tool will then  * handle connecting to the RDBMS via the {@link org.apache.hadoop.hive.metastore.ObjectStore}  * and HBase via {@link org.apache.hadoop.hive.metastore.hbase.HBaseStore} and transferring the  * data.  *  * This tool can import an entire metastore or only selected objects.  When selecting objects it  * is necessary to fully specify the object's name.  For example, if you want to import the table  * T in the default database it needs to be identified as default.T.  The same is true for  * functions.  When an object is specified, everything under that object will be imported (e.g.  * if you select database D, then all tables and functions in that database will be  * imported as well).  *  * At this point only tables and partitions are handled in parallel as it is assumed there are  * relatively few of everything else.  *  * Note that HBaseSchemaTool must have already been used to create the appropriate tables in HBase.  */
end_comment

begin_class
specifier|public
class|class
name|HBaseImport
block|{
specifier|static
specifier|final
specifier|private
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HBaseImport
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|public
specifier|static
name|int
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
block|{
try|try
block|{
name|HBaseImport
name|tool
init|=
operator|new
name|HBaseImport
argument_list|()
decl_stmt|;
name|int
name|rv
init|=
name|tool
operator|.
name|init
argument_list|(
name|args
argument_list|)
decl_stmt|;
if|if
condition|(
name|rv
operator|!=
literal|0
condition|)
return|return
name|rv
return|;
name|tool
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Caught exception "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" with message<"
operator|+
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|">"
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
return|return
literal|0
return|;
block|}
specifier|private
name|ThreadLocal
argument_list|<
name|RawStore
argument_list|>
name|rdbmsStore
init|=
operator|new
name|ThreadLocal
argument_list|<
name|RawStore
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|RawStore
name|initialValue
parameter_list|()
block|{
if|if
condition|(
name|rdbmsConf
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"order violation, need to set rdbms conf first"
argument_list|)
throw|;
block|}
name|RawStore
name|os
init|=
operator|new
name|ObjectStore
argument_list|()
decl_stmt|;
name|os
operator|.
name|setConf
argument_list|(
name|rdbmsConf
argument_list|)
expr_stmt|;
return|return
name|os
return|;
block|}
block|}
decl_stmt|;
specifier|private
name|ThreadLocal
argument_list|<
name|RawStore
argument_list|>
name|hbaseStore
init|=
operator|new
name|ThreadLocal
argument_list|<
name|RawStore
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|RawStore
name|initialValue
parameter_list|()
block|{
if|if
condition|(
name|hbaseConf
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"order violation, need to set hbase conf first"
argument_list|)
throw|;
block|}
name|RawStore
name|hs
init|=
operator|new
name|HBaseStore
argument_list|()
decl_stmt|;
name|hs
operator|.
name|setConf
argument_list|(
name|hbaseConf
argument_list|)
expr_stmt|;
return|return
name|hs
return|;
block|}
block|}
decl_stmt|;
specifier|private
name|Configuration
name|rdbmsConf
decl_stmt|;
specifier|private
name|Configuration
name|hbaseConf
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Database
argument_list|>
name|dbs
decl_stmt|;
specifier|private
name|BlockingQueue
argument_list|<
name|Table
argument_list|>
name|partitionedTables
decl_stmt|;
specifier|private
name|BlockingQueue
argument_list|<
name|String
index|[]
argument_list|>
name|tableNameQueue
decl_stmt|;
specifier|private
name|BlockingQueue
argument_list|<
name|PartQueueEntry
argument_list|>
name|partQueue
decl_stmt|;
specifier|private
name|boolean
name|writingToQueue
decl_stmt|,
name|readersFinished
decl_stmt|;
specifier|private
name|boolean
name|doKerberos
decl_stmt|,
name|doAll
decl_stmt|;
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|rolesToImport
decl_stmt|,
name|dbsToImport
decl_stmt|,
name|tablesToImport
decl_stmt|,
name|functionsToImport
decl_stmt|;
specifier|private
name|int
name|parallel
decl_stmt|;
specifier|private
name|int
name|batchSize
decl_stmt|;
specifier|private
name|HBaseImport
parameter_list|()
block|{}
annotation|@
name|VisibleForTesting
specifier|public
name|HBaseImport
parameter_list|(
name|String
modifier|...
name|args
parameter_list|)
throws|throws
name|ParseException
block|{
name|init
argument_list|(
name|args
argument_list|)
expr_stmt|;
block|}
specifier|private
name|int
name|init
parameter_list|(
name|String
modifier|...
name|args
parameter_list|)
throws|throws
name|ParseException
block|{
name|Options
name|options
init|=
operator|new
name|Options
argument_list|()
decl_stmt|;
name|doAll
operator|=
name|doKerberos
operator|=
literal|false
expr_stmt|;
name|parallel
operator|=
literal|1
expr_stmt|;
name|batchSize
operator|=
literal|1000
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"all"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Import the full metastore"
argument_list|)
operator|.
name|create
argument_list|(
literal|'a'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"batchsize"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Number of partitions to read and write in a batch, defaults to 1000"
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|create
argument_list|(
literal|'b'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"database"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Import a single database"
argument_list|)
operator|.
name|hasArgs
argument_list|()
operator|.
name|create
argument_list|(
literal|'d'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"help"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"You're looking at it"
argument_list|)
operator|.
name|create
argument_list|(
literal|'h'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"function"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Import a single function"
argument_list|)
operator|.
name|hasArgs
argument_list|()
operator|.
name|create
argument_list|(
literal|'f'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"kerberos"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Import all kerberos related objects (master key, tokens)"
argument_list|)
operator|.
name|create
argument_list|(
literal|'k'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"parallel"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Parallel factor for loading (only applied to tables and partitions), "
operator|+
literal|"defaults to 1"
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|create
argument_list|(
literal|'p'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"role"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Import a single role"
argument_list|)
operator|.
name|hasArgs
argument_list|()
operator|.
name|create
argument_list|(
literal|'r'
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withLongOpt
argument_list|(
literal|"tables"
argument_list|)
operator|.
name|withDescription
argument_list|(
literal|"Import a single tables"
argument_list|)
operator|.
name|hasArgs
argument_list|()
operator|.
name|create
argument_list|(
literal|'t'
argument_list|)
argument_list|)
expr_stmt|;
name|CommandLine
name|cli
init|=
operator|new
name|GnuParser
argument_list|()
operator|.
name|parse
argument_list|(
name|options
argument_list|,
name|args
argument_list|)
decl_stmt|;
comment|// Process help, if it was asked for, this must be done first
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'h'
argument_list|)
condition|)
block|{
name|printHelp
argument_list|(
name|options
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
name|boolean
name|hasCmd
init|=
literal|false
decl_stmt|;
comment|// Now process the other command line args
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'a'
argument_list|)
condition|)
block|{
name|hasCmd
operator|=
literal|true
expr_stmt|;
name|doAll
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'b'
argument_list|)
condition|)
block|{
name|batchSize
operator|=
name|Integer
operator|.
name|valueOf
argument_list|(
name|cli
operator|.
name|getOptionValue
argument_list|(
literal|'b'
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'d'
argument_list|)
condition|)
block|{
name|hasCmd
operator|=
literal|true
expr_stmt|;
name|dbsToImport
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|cli
operator|.
name|getOptionValues
argument_list|(
literal|'d'
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'f'
argument_list|)
condition|)
block|{
name|hasCmd
operator|=
literal|true
expr_stmt|;
name|functionsToImport
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|cli
operator|.
name|getOptionValues
argument_list|(
literal|'f'
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'p'
argument_list|)
condition|)
block|{
name|parallel
operator|=
name|Integer
operator|.
name|valueOf
argument_list|(
name|cli
operator|.
name|getOptionValue
argument_list|(
literal|'p'
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'r'
argument_list|)
condition|)
block|{
name|hasCmd
operator|=
literal|true
expr_stmt|;
name|rolesToImport
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|cli
operator|.
name|getOptionValues
argument_list|(
literal|'r'
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'k'
argument_list|)
condition|)
block|{
name|doKerberos
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|cli
operator|.
name|hasOption
argument_list|(
literal|'t'
argument_list|)
condition|)
block|{
name|hasCmd
operator|=
literal|true
expr_stmt|;
name|tablesToImport
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|cli
operator|.
name|getOptionValues
argument_list|(
literal|'t'
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|hasCmd
condition|)
block|{
name|printHelp
argument_list|(
name|options
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
name|dbs
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
comment|// We don't want to bound the size of the table queue because we keep it all in memory
name|partitionedTables
operator|=
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|()
expr_stmt|;
name|tableNameQueue
operator|=
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|()
expr_stmt|;
comment|// Bound the size of this queue so we don't get too much in memory.
name|partQueue
operator|=
operator|new
name|ArrayBlockingQueue
argument_list|<>
argument_list|(
name|parallel
operator|*
literal|2
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
specifier|private
name|void
name|printHelp
parameter_list|(
name|Options
name|options
parameter_list|)
block|{
operator|(
operator|new
name|HelpFormatter
argument_list|()
operator|)
operator|.
name|printHelp
argument_list|(
literal|"hbaseschematool"
argument_list|,
name|options
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
name|void
name|run
parameter_list|()
throws|throws
name|MetaException
throws|,
name|InstantiationException
throws|,
name|IllegalAccessException
throws|,
name|NoSuchObjectException
throws|,
name|InvalidObjectException
throws|,
name|InterruptedException
block|{
comment|// Order here is crucial, as you can't add tables until you've added databases, etc.
name|init
argument_list|()
expr_stmt|;
if|if
condition|(
name|doAll
operator|||
name|rolesToImport
operator|!=
literal|null
condition|)
block|{
name|copyRoles
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|doAll
operator|||
name|dbsToImport
operator|!=
literal|null
condition|)
block|{
name|copyDbs
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|doAll
operator|||
name|dbsToImport
operator|!=
literal|null
operator|||
name|tablesToImport
operator|!=
literal|null
condition|)
block|{
name|copyTables
argument_list|()
expr_stmt|;
name|copyPartitions
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|doAll
operator|||
name|dbsToImport
operator|!=
literal|null
operator|||
name|functionsToImport
operator|!=
literal|null
condition|)
block|{
name|copyFunctions
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|doAll
operator|||
name|doKerberos
condition|)
block|{
name|copyKerberos
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|init
parameter_list|()
throws|throws
name|MetaException
throws|,
name|IllegalAccessException
throws|,
name|InstantiationException
block|{
if|if
condition|(
name|rdbmsConf
operator|!=
literal|null
condition|)
block|{
comment|// We've been configured for testing, so don't do anything here.
return|return;
block|}
comment|// We're depending on having everything properly in the path
name|rdbmsConf
operator|=
operator|new
name|HiveConf
argument_list|()
expr_stmt|;
name|hbaseConf
operator|=
operator|new
name|HiveConf
argument_list|()
expr_stmt|;
comment|//
name|HiveConf
operator|.
name|setVar
argument_list|(
name|hbaseConf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_RAW_STORE_IMPL
argument_list|,
name|HBaseStore
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|HiveConf
operator|.
name|setBoolVar
argument_list|(
name|hbaseConf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_FASTPATH
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// First get a connection to the RDBMS based store
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|setConf
argument_list|(
name|rdbmsConf
argument_list|)
expr_stmt|;
comment|// Get a connection to the HBase based store
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|setConf
argument_list|(
name|hbaseConf
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|copyRoles
parameter_list|()
throws|throws
name|NoSuchObjectException
throws|,
name|InvalidObjectException
throws|,
name|MetaException
block|{
name|screen
argument_list|(
literal|"Copying roles"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|toCopy
init|=
name|doAll
condition|?
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|listRoleNames
argument_list|()
else|:
name|rolesToImport
decl_stmt|;
for|for
control|(
name|String
name|roleName
range|:
name|toCopy
control|)
block|{
name|Role
name|role
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getRole
argument_list|(
name|roleName
argument_list|)
decl_stmt|;
name|screen
argument_list|(
literal|"Copying role "
operator|+
name|roleName
argument_list|)
expr_stmt|;
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|addRole
argument_list|(
name|roleName
argument_list|,
name|role
operator|.
name|getOwnerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|copyDbs
parameter_list|()
throws|throws
name|MetaException
throws|,
name|NoSuchObjectException
throws|,
name|InvalidObjectException
block|{
name|screen
argument_list|(
literal|"Copying databases"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|toCopy
init|=
name|doAll
condition|?
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getAllDatabases
argument_list|()
else|:
name|dbsToImport
decl_stmt|;
for|for
control|(
name|String
name|dbName
range|:
name|toCopy
control|)
block|{
name|Database
name|db
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getDatabase
argument_list|(
name|dbName
argument_list|)
decl_stmt|;
name|dbs
operator|.
name|add
argument_list|(
name|db
argument_list|)
expr_stmt|;
name|screen
argument_list|(
literal|"Copying database "
operator|+
name|dbName
argument_list|)
expr_stmt|;
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|createDatabase
argument_list|(
name|db
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|copyTables
parameter_list|()
throws|throws
name|MetaException
throws|,
name|InvalidObjectException
throws|,
name|InterruptedException
block|{
name|screen
argument_list|(
literal|"Copying tables"
argument_list|)
expr_stmt|;
comment|// Start the parallel threads that will copy the tables
name|Thread
index|[]
name|copiers
init|=
operator|new
name|Thread
index|[
name|parallel
index|]
decl_stmt|;
name|writingToQueue
operator|=
literal|true
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|parallel
condition|;
name|i
operator|++
control|)
block|{
name|copiers
index|[
name|i
index|]
operator|=
operator|new
name|TableCopier
argument_list|()
expr_stmt|;
name|copiers
index|[
name|i
index|]
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|// Put tables from the databases we copied into the queue
for|for
control|(
name|Database
name|db
range|:
name|dbs
control|)
block|{
name|screen
argument_list|(
literal|"Coyping tables in database "
operator|+
name|db
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|tableName
range|:
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getAllTables
argument_list|(
name|db
operator|.
name|getName
argument_list|()
argument_list|)
control|)
block|{
name|tableNameQueue
operator|.
name|put
argument_list|(
operator|new
name|String
index|[]
block|{
name|db
operator|.
name|getName
argument_list|()
block|,
name|tableName
block|}
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Now put any specifically requested tables into the queue
if|if
condition|(
name|tablesToImport
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|compoundTableName
range|:
name|tablesToImport
control|)
block|{
name|String
index|[]
name|tn
init|=
name|compoundTableName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
if|if
condition|(
name|tn
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
name|error
argument_list|(
name|compoundTableName
operator|+
literal|" not in proper form.  Must be in form dbname.tablename.  "
operator|+
literal|"Ignoring this table and continuing."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tableNameQueue
operator|.
name|put
argument_list|(
operator|new
name|String
index|[]
block|{
name|tn
index|[
literal|0
index|]
block|,
name|tn
index|[
literal|1
index|]
block|}
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|writingToQueue
operator|=
literal|false
expr_stmt|;
comment|// Wait until we've finished adding all the tables
for|for
control|(
name|Thread
name|copier
range|:
name|copiers
control|)
name|copier
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
specifier|private
class|class
name|TableCopier
extends|extends
name|Thread
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
name|writingToQueue
operator|||
name|tableNameQueue
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|String
index|[]
name|name
init|=
name|tableNameQueue
operator|.
name|poll
argument_list|(
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
name|name
operator|!=
literal|null
condition|)
block|{
name|Table
name|table
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getTable
argument_list|(
name|name
index|[
literal|0
index|]
argument_list|,
name|name
index|[
literal|1
index|]
argument_list|)
decl_stmt|;
comment|// If this has partitions, put it in the list to fetch partions for
if|if
condition|(
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|!=
literal|null
operator|&&
name|table
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|partitionedTables
operator|.
name|put
argument_list|(
name|table
argument_list|)
expr_stmt|;
block|}
name|screen
argument_list|(
literal|"Copying table "
operator|+
name|name
index|[
literal|0
index|]
operator|+
literal|"."
operator|+
name|name
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|createTable
argument_list|(
name|table
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|MetaException
decl||
name|InvalidObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|/* Partition copying is a little complex.  As we went through and copied the tables we put each    * partitioned table into a queue.  We will now go through that queue and add partitions for the    * tables.  We do the finding of partitions and writing of them separately and in parallel.    * This way if there is one table with>> partitions then all of the others that skew won't    * hurt us.  To avoid pulling all of the partitions for a table into memory, we batch up    * partitions (by default in batches of 1000) and copy them over in batches.    */
specifier|private
name|void
name|copyPartitions
parameter_list|()
throws|throws
name|MetaException
throws|,
name|NoSuchObjectException
throws|,
name|InvalidObjectException
throws|,
name|InterruptedException
block|{
name|screen
argument_list|(
literal|"Copying partitions"
argument_list|)
expr_stmt|;
name|readersFinished
operator|=
literal|false
expr_stmt|;
name|Thread
index|[]
name|readers
init|=
operator|new
name|Thread
index|[
name|parallel
index|]
decl_stmt|;
name|Thread
index|[]
name|writers
init|=
operator|new
name|Thread
index|[
name|parallel
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|parallel
condition|;
name|i
operator|++
control|)
block|{
name|readers
index|[
name|i
index|]
operator|=
operator|new
name|PartitionReader
argument_list|()
expr_stmt|;
name|readers
index|[
name|i
index|]
operator|.
name|start
argument_list|()
expr_stmt|;
name|writers
index|[
name|i
index|]
operator|=
operator|new
name|PartitionWriter
argument_list|()
expr_stmt|;
name|writers
index|[
name|i
index|]
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
for|for
control|(
name|Thread
name|reader
range|:
name|readers
control|)
name|reader
operator|.
name|join
argument_list|()
expr_stmt|;
name|readersFinished
operator|=
literal|true
expr_stmt|;
comment|// Wait until we've finished adding all the partitions
for|for
control|(
name|Thread
name|writer
range|:
name|writers
control|)
name|writer
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
specifier|private
class|class
name|PartitionReader
extends|extends
name|Thread
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
name|partitionedTables
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|Table
name|table
init|=
name|partitionedTables
operator|.
name|poll
argument_list|(
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
name|table
operator|!=
literal|null
condition|)
block|{
name|screen
argument_list|(
literal|"Fetching partitions for table "
operator|+
name|table
operator|.
name|getDbName
argument_list|()
operator|+
literal|"."
operator|+
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|partNames
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|listPartitionNames
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
operator|(
name|short
operator|)
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|partNames
operator|.
name|size
argument_list|()
operator|<=
name|batchSize
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding all partition names to queue for "
operator|+
name|table
operator|.
name|getDbName
argument_list|()
operator|+
literal|"."
operator|+
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|partQueue
operator|.
name|put
argument_list|(
operator|new
name|PartQueueEntry
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|int
name|goUntil
init|=
name|partNames
operator|.
name|size
argument_list|()
operator|%
name|batchSize
operator|==
literal|0
condition|?
name|partNames
operator|.
name|size
argument_list|()
operator|/
name|batchSize
else|:
name|partNames
operator|.
name|size
argument_list|()
operator|/
name|batchSize
operator|+
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|goUntil
condition|;
name|i
operator|++
control|)
block|{
name|int
name|start
init|=
name|i
operator|*
name|batchSize
decl_stmt|;
name|int
name|end
init|=
name|Math
operator|.
name|min
argument_list|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|*
name|batchSize
argument_list|,
name|partNames
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding partitions "
operator|+
name|start
operator|+
literal|" to "
operator|+
name|end
operator|+
literal|" for "
operator|+
name|table
operator|.
name|getDbName
argument_list|()
operator|+
literal|"."
operator|+
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|partQueue
operator|.
name|put
argument_list|(
operator|new
name|PartQueueEntry
argument_list|(
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|partNames
operator|.
name|subList
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|MetaException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
specifier|private
class|class
name|PartitionWriter
extends|extends
name|Thread
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
comment|// This keeps us from throwing exceptions in our raw store calls
name|Deadline
operator|.
name|registerIfNot
argument_list|(
literal|1000000
argument_list|)
expr_stmt|;
while|while
condition|(
operator|!
name|readersFinished
operator|||
name|partQueue
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|PartQueueEntry
name|entry
init|=
name|partQueue
operator|.
name|poll
argument_list|(
literal|1
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
name|entry
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Writing partitions "
operator|+
name|entry
operator|.
name|dbName
operator|+
literal|"."
operator|+
name|entry
operator|.
name|tableName
operator|+
literal|"."
operator|+
name|StringUtils
operator|.
name|join
argument_list|(
name|entry
operator|.
name|partNames
argument_list|,
literal|':'
argument_list|)
argument_list|)
expr_stmt|;
comment|// Fetch these partitions and write them to HBase
name|Deadline
operator|.
name|startTimer
argument_list|(
literal|"hbaseimport"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Partition
argument_list|>
name|parts
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getPartitionsByNames
argument_list|(
name|entry
operator|.
name|dbName
argument_list|,
name|entry
operator|.
name|tableName
argument_list|,
name|entry
operator|.
name|partNames
argument_list|)
decl_stmt|;
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|addPartitions
argument_list|(
name|entry
operator|.
name|dbName
argument_list|,
name|entry
operator|.
name|tableName
argument_list|,
name|parts
argument_list|)
expr_stmt|;
name|Deadline
operator|.
name|stopTimer
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
decl||
name|MetaException
decl||
name|InvalidObjectException
decl||
name|NoSuchObjectException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
specifier|private
name|void
name|copyFunctions
parameter_list|()
throws|throws
name|MetaException
throws|,
name|NoSuchObjectException
throws|,
name|InvalidObjectException
block|{
name|screen
argument_list|(
literal|"Copying functions"
argument_list|)
expr_stmt|;
comment|// Copy any functions from databases we copied.
for|for
control|(
name|Database
name|db
range|:
name|dbs
control|)
block|{
name|screen
argument_list|(
literal|"Copying functions in database "
operator|+
name|db
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|funcName
range|:
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getFunctions
argument_list|(
name|db
operator|.
name|getName
argument_list|()
argument_list|,
literal|"*"
argument_list|)
control|)
block|{
name|copyOneFunction
argument_list|(
name|db
operator|.
name|getName
argument_list|()
argument_list|,
name|funcName
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Now do any specifically requested functions
if|if
condition|(
name|functionsToImport
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|compoundFuncName
range|:
name|functionsToImport
control|)
block|{
name|String
index|[]
name|fn
init|=
name|compoundFuncName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
if|if
condition|(
name|fn
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
name|error
argument_list|(
name|compoundFuncName
operator|+
literal|" not in proper form.  Must be in form dbname.funcname.  "
operator|+
literal|"Ignoring this function and continuing."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|copyOneFunction
argument_list|(
name|fn
index|[
literal|0
index|]
argument_list|,
name|fn
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|void
name|copyOneFunction
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|funcName
parameter_list|)
throws|throws
name|MetaException
throws|,
name|InvalidObjectException
block|{
name|Function
name|func
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getFunction
argument_list|(
name|dbName
argument_list|,
name|funcName
argument_list|)
decl_stmt|;
name|screen
argument_list|(
literal|"Copying function "
operator|+
name|dbName
operator|+
literal|"."
operator|+
name|funcName
argument_list|)
expr_stmt|;
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|createFunction
argument_list|(
name|func
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|copyKerberos
parameter_list|()
throws|throws
name|MetaException
block|{
name|screen
argument_list|(
literal|"Copying kerberos related items"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|tokenId
range|:
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getAllTokenIdentifiers
argument_list|()
control|)
block|{
name|String
name|token
init|=
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getToken
argument_list|(
name|tokenId
argument_list|)
decl_stmt|;
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|addToken
argument_list|(
name|tokenId
argument_list|,
name|token
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|masterKey
range|:
name|rdbmsStore
operator|.
name|get
argument_list|()
operator|.
name|getMasterKeys
argument_list|()
control|)
block|{
name|hbaseStore
operator|.
name|get
argument_list|()
operator|.
name|addMasterKey
argument_list|(
name|masterKey
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|screen
parameter_list|(
name|String
name|msg
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|error
parameter_list|(
name|String
name|msg
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"ERROR:  "
operator|+
name|msg
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
name|void
name|setConnections
parameter_list|(
name|RawStore
name|rdbms
parameter_list|,
name|RawStore
name|hbase
parameter_list|)
block|{
name|rdbmsStore
operator|.
name|set
argument_list|(
name|rdbms
argument_list|)
expr_stmt|;
name|hbaseStore
operator|.
name|set
argument_list|(
name|hbase
argument_list|)
expr_stmt|;
name|rdbmsConf
operator|=
name|rdbms
operator|.
name|getConf
argument_list|()
expr_stmt|;
name|hbaseConf
operator|=
name|hbase
operator|.
name|getConf
argument_list|()
expr_stmt|;
block|}
specifier|private
specifier|static
class|class
name|PartQueueEntry
block|{
specifier|final
name|String
name|dbName
decl_stmt|;
specifier|final
name|String
name|tableName
decl_stmt|;
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|partNames
decl_stmt|;
name|PartQueueEntry
parameter_list|(
name|String
name|d
parameter_list|,
name|String
name|t
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|p
parameter_list|)
block|{
name|dbName
operator|=
name|d
expr_stmt|;
name|tableName
operator|=
name|t
expr_stmt|;
name|partNames
operator|=
name|p
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

