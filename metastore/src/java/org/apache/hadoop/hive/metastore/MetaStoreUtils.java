begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Constructor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|ServerSocket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|JavaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SerDeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ListObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|MapObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
operator|.
name|Category
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructField
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|thrift
operator|.
name|HadoopThriftAuthBridge
import|;
end_import

begin_class
specifier|public
class|class
name|MetaStoreUtils
block|{
specifier|protected
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
literal|"hive.log"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_DATABASE_NAME
init|=
literal|"default"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_DATABASE_COMMENT
init|=
literal|"Default Hive database"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DATABASE_WAREHOUSE_SUFFIX
init|=
literal|".db"
decl_stmt|;
comment|/**    * printStackTrace    *    * Helper function to print an exception stack trace to the log and not stderr    *    * @param e    *          the exception    *    */
specifier|static
specifier|public
name|void
name|printStackTrace
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
for|for
control|(
name|StackTraceElement
name|s
range|:
name|e
operator|.
name|getStackTrace
argument_list|()
control|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
name|Table
name|createColumnsetSchema
parameter_list|(
name|String
name|name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|columns
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"columns not specified for table "
operator|+
name|name
argument_list|)
throw|;
block|}
name|Table
name|tTable
init|=
operator|new
name|Table
argument_list|()
decl_stmt|;
name|tTable
operator|.
name|setTableName
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|tTable
operator|.
name|setSd
argument_list|(
operator|new
name|StorageDescriptor
argument_list|()
argument_list|)
expr_stmt|;
name|StorageDescriptor
name|sd
init|=
name|tTable
operator|.
name|getSd
argument_list|()
decl_stmt|;
name|sd
operator|.
name|setSerdeInfo
argument_list|(
operator|new
name|SerDeInfo
argument_list|()
argument_list|)
expr_stmt|;
name|SerDeInfo
name|serdeInfo
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
decl_stmt|;
name|serdeInfo
operator|.
name|setSerializationLib
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|serdeInfo
operator|.
name|setParameters
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_FORMAT
argument_list|,
literal|"1"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fields
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
name|sd
operator|.
name|setCols
argument_list|(
name|fields
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|col
range|:
name|columns
control|)
block|{
name|FieldSchema
name|field
init|=
operator|new
name|FieldSchema
argument_list|(
name|col
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
argument_list|,
literal|"'default'"
argument_list|)
decl_stmt|;
name|fields
operator|.
name|add
argument_list|(
name|field
argument_list|)
expr_stmt|;
block|}
name|tTable
operator|.
name|setPartitionKeys
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|partCol
range|:
name|partCols
control|)
block|{
name|FieldSchema
name|part
init|=
operator|new
name|FieldSchema
argument_list|()
decl_stmt|;
name|part
operator|.
name|setName
argument_list|(
name|partCol
argument_list|)
expr_stmt|;
name|part
operator|.
name|setType
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
argument_list|)
expr_stmt|;
comment|// default
comment|// partition
comment|// key
name|tTable
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
block|}
name|sd
operator|.
name|setNumBuckets
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
return|return
name|tTable
return|;
block|}
comment|/**    * recursiveDelete    *    * just recursively deletes a dir - you'd think Java would have something to    * do this??    *    * @param f    *          - the file/dir to delete    * @exception IOException    *              propogate f.delete() exceptions    *    */
specifier|static
specifier|public
name|void
name|recursiveDelete
parameter_list|(
name|File
name|f
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|f
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|File
name|fs
index|[]
init|=
name|f
operator|.
name|listFiles
argument_list|()
decl_stmt|;
for|for
control|(
name|File
name|subf
range|:
name|fs
control|)
block|{
name|recursiveDelete
argument_list|(
name|subf
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|f
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"could not delete: "
operator|+
name|f
operator|.
name|getPath
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * getDeserializer    *    * Get the Deserializer for a table given its name and properties.    *    * @param conf    *          hadoop config    * @param schema    *          the properties to use to instantiate the deserializer    * @return    *   Returns instantiated deserializer by looking up class name of deserializer stored in passed    *   in properties. Also, initializes the deserializer with schema stored in passed in properties.    * @exception MetaException    *              if any problems instantiating the Deserializer    *    *              todo - this should move somewhere into serde.jar    *    */
specifier|static
specifier|public
name|Deserializer
name|getDeserializer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Properties
name|schema
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|lib
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_LIB
argument_list|)
decl_stmt|;
try|try
block|{
name|Deserializer
name|deserializer
init|=
name|SerDeUtils
operator|.
name|lookupDeserializer
argument_list|(
name|lib
argument_list|)
decl_stmt|;
operator|(
name|deserializer
operator|)
operator|.
name|initialize
argument_list|(
name|conf
argument_list|,
name|schema
argument_list|)
expr_stmt|;
return|return
name|deserializer
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error in initSerDe: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|MetaStoreUtils
operator|.
name|printStackTrace
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * getDeserializer    *    * Get the Deserializer for a table.    *    * @param conf    *          - hadoop config    * @param table    *          the table    * @return    *   Returns instantiated deserializer by looking up class name of deserializer stored in    *   storage descriptor of passed in table. Also, initializes the deserializer with schema    *   of table.    * @exception MetaException    *              if any problems instantiating the Deserializer    *    *              todo - this should move somewhere into serde.jar    *    */
specifier|static
specifier|public
name|Deserializer
name|getDeserializer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|lib
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
if|if
condition|(
name|lib
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
try|try
block|{
name|Deserializer
name|deserializer
init|=
name|SerDeUtils
operator|.
name|lookupDeserializer
argument_list|(
name|lib
argument_list|)
decl_stmt|;
name|deserializer
operator|.
name|initialize
argument_list|(
name|conf
argument_list|,
name|MetaStoreUtils
operator|.
name|getTableMetadata
argument_list|(
name|table
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|deserializer
return|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error in initSerDe: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|MetaStoreUtils
operator|.
name|printStackTrace
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * getDeserializer    *    * Get the Deserializer for a partition.    *    * @param conf    *          - hadoop config    * @param part    *          the partition    * @param table the table    * @return    *   Returns instantiated deserializer by looking up class name of deserializer stored in    *   storage descriptor of passed in partition. Also, initializes the deserializer with    *   schema of partition.    * @exception MetaException    *              if any problems instantiating the Deserializer    *    */
specifier|static
specifier|public
name|Deserializer
name|getDeserializer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|lib
init|=
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
try|try
block|{
name|Deserializer
name|deserializer
init|=
name|SerDeUtils
operator|.
name|lookupDeserializer
argument_list|(
name|lib
argument_list|)
decl_stmt|;
name|deserializer
operator|.
name|initialize
argument_list|(
name|conf
argument_list|,
name|MetaStoreUtils
operator|.
name|getPartitionMetadata
argument_list|(
name|part
argument_list|,
name|table
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|deserializer
return|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error in initSerDe: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|MetaStoreUtils
operator|.
name|printStackTrace
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|static
specifier|public
name|void
name|deleteWHDirectory
parameter_list|(
name|Path
name|path
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|use_trash
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
if|if
condition|(
operator|!
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|path
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"drop data called on table/partition with no directory: "
operator|+
name|path
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|use_trash
condition|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
name|Path
name|newPath
init|=
operator|new
name|Path
argument_list|(
literal|"/Trash/Current"
operator|+
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|newPath
argument_list|)
operator|==
literal|false
condition|)
block|{
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|mkdirs
argument_list|(
name|newPath
argument_list|)
expr_stmt|;
block|}
do|do
block|{
name|newPath
operator|=
operator|new
name|Path
argument_list|(
literal|"/Trash/Current"
operator|+
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|+
literal|"."
operator|+
name|count
argument_list|)
expr_stmt|;
if|if
condition|(
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|newPath
argument_list|)
condition|)
block|{
name|count
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|rename
argument_list|(
name|path
argument_list|,
name|newPath
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
do|while
condition|(
operator|++
name|count
operator|<
literal|50
condition|)
do|;
if|if
condition|(
name|count
operator|>=
literal|50
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Rename failed due to maxing out retries"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|// directly delete it
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|delete
argument_list|(
name|path
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Got exception trying to delete data dir: "
operator|+
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Got exception trying to delete data dir: "
operator|+
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Given a list of partition columns and a partial mapping from    * some partition columns to values the function returns the values    * for the column.    * @param partCols the list of table partition columns    * @param partSpec the partial mapping from partition column to values    * @return list of values of for given partition columns, any missing    *         values in partSpec is replaced by an empty string    */
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPvals
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|partCols
control|)
block|{
name|String
name|val
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
literal|""
expr_stmt|;
block|}
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
return|return
name|pvals
return|;
block|}
comment|/**    * validateName    *    * Checks the name conforms to our standars which are: "[a-zA-z_0-9]+". checks    * this is just characters and numbers and _    *    * @param name    *          the name to validate    * @return true or false depending on conformance    * @exception MetaException    *              if it doesn't match the pattern.    */
specifier|static
specifier|public
name|boolean
name|validateName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|Pattern
name|tpat
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"[\\w_]+"
argument_list|)
decl_stmt|;
name|Matcher
name|m
init|=
name|tpat
operator|.
name|matcher
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|static
specifier|public
name|String
name|validateTblColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|validateName
argument_list|(
name|fieldSchema
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|"name: "
operator|+
name|fieldSchema
operator|.
name|getName
argument_list|()
return|;
block|}
if|if
condition|(
operator|!
name|validateColumnType
argument_list|(
name|fieldSchema
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|"type: "
operator|+
name|fieldSchema
operator|.
name|getType
argument_list|()
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|static
name|void
name|throwExceptionIfIncompatibleColTypeChange
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
throws|throws
name|InvalidOperationException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|incompatibleCols
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|int
name|maxCols
init|=
name|Math
operator|.
name|min
argument_list|(
name|oldCols
operator|.
name|size
argument_list|()
argument_list|,
name|newCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|maxCols
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|areColTypesCompatible
argument_list|(
name|oldCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|,
name|newCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
name|incompatibleCols
operator|.
name|add
argument_list|(
name|newCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|incompatibleCols
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|InvalidOperationException
argument_list|(
literal|"The following columns have types incompatible with the existing "
operator|+
literal|"columns in their respective positions :\n"
operator|+
name|StringUtils
operator|.
name|join
argument_list|(
name|incompatibleCols
argument_list|,
literal|','
argument_list|)
argument_list|)
throw|;
block|}
block|}
comment|/**    * @return true if oldType and newType are compatible.    * Two types are compatible if we have internal functions to cast one to another.    */
specifier|static
specifier|private
name|boolean
name|areColTypesCompatible
parameter_list|(
name|String
name|oldType
parameter_list|,
name|String
name|newType
parameter_list|)
block|{
if|if
condition|(
name|oldType
operator|.
name|equals
argument_list|(
name|newType
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|/*      * RCFile default serde (ColumnarSerde) serializes the values in such a way that the      * datatypes can be converted from string to any type. The map is also serialized as      * a string, which can be read as a string as well. However, with any binary      * serialization, this is not true.      *      * Primitive types like INT, STRING, BIGINT, etc are compatible with each other and are      * not blocked.      */
if|if
condition|(
name|serdeConstants
operator|.
name|PrimitiveTypes
operator|.
name|contains
argument_list|(
name|oldType
operator|.
name|toLowerCase
argument_list|()
argument_list|)
operator|&&
name|serdeConstants
operator|.
name|PrimitiveTypes
operator|.
name|contains
argument_list|(
name|newType
operator|.
name|toLowerCase
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * validate column type    *    * if it is predefined, yes. otherwise no    * @param name    * @return    */
specifier|static
specifier|public
name|boolean
name|validateColumnType
parameter_list|(
name|String
name|type
parameter_list|)
block|{
name|int
name|last
init|=
literal|0
decl_stmt|;
name|boolean
name|lastAlphaDigit
init|=
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|last
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|type
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|type
operator|.
name|length
argument_list|()
operator|||
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|!=
name|lastAlphaDigit
condition|)
block|{
name|String
name|token
init|=
name|type
operator|.
name|substring
argument_list|(
name|last
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|last
operator|=
name|i
expr_stmt|;
if|if
condition|(
operator|!
name|hiveThriftTypeMap
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
break|break;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNames
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
literal|null
operator|==
name|cols
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|validateName
argument_list|(
name|col
argument_list|)
condition|)
block|{
return|return
name|col
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNamesSubsetCol
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|skewedColNames
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
literal|null
operator|==
name|skewedColNames
condition|)
block|{
return|return
literal|null
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|fieldSchema
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// make a copy
name|List
argument_list|<
name|String
argument_list|>
name|copySkewedColNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|skewedColNames
argument_list|)
decl_stmt|;
comment|// remove valid columns
name|copySkewedColNames
operator|.
name|removeAll
argument_list|(
name|colNames
argument_list|)
expr_stmt|;
if|if
condition|(
name|copySkewedColNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|copySkewedColNames
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|String
name|getListType
parameter_list|(
name|String
name|t
parameter_list|)
block|{
return|return
literal|"array<"
operator|+
name|t
operator|+
literal|">"
return|;
block|}
specifier|public
specifier|static
name|String
name|getMapType
parameter_list|(
name|String
name|k
parameter_list|,
name|String
name|v
parameter_list|)
block|{
return|return
literal|"map<"
operator|+
name|k
operator|+
literal|","
operator|+
name|v
operator|+
literal|">"
return|;
block|}
specifier|public
specifier|static
name|void
name|setSerdeParam
parameter_list|(
name|SerDeInfo
name|sdi
parameter_list|,
name|Properties
name|schema
parameter_list|,
name|String
name|param
parameter_list|)
block|{
name|String
name|val
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|param
argument_list|)
decl_stmt|;
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|val
argument_list|)
condition|)
block|{
name|sdi
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|param
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
specifier|static
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|typeToThriftTypeMap
decl_stmt|;
static|static
block|{
name|typeToThriftTypeMap
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|BOOLEAN_TYPE_NAME
argument_list|,
literal|"bool"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|TINYINT_TYPE_NAME
argument_list|,
literal|"byte"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SMALLINT_TYPE_NAME
argument_list|,
literal|"i16"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|INT_TYPE_NAME
argument_list|,
literal|"i32"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|BIGINT_TYPE_NAME
argument_list|,
literal|"i64"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DOUBLE_TYPE_NAME
argument_list|,
literal|"double"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|FLOAT_TYPE_NAME
argument_list|,
literal|"float"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|LIST_TYPE_NAME
argument_list|,
literal|"list"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|MAP_TYPE_NAME
argument_list|,
literal|"map"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
argument_list|,
literal|"string"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|BINARY_TYPE_NAME
argument_list|,
literal|"binary"
argument_list|)
expr_stmt|;
comment|// These 4 types are not supported yet.
comment|// We should define a complex type date in thrift that contains a single int
comment|// member, and DynamicSerDe
comment|// should convert it to date type at runtime.
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DATE_TYPE_NAME
argument_list|,
literal|"date"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DATETIME_TYPE_NAME
argument_list|,
literal|"datetime"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|TIMESTAMP_TYPE_NAME
argument_list|,
literal|"timestamp"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DECIMAL_TYPE_NAME
argument_list|,
literal|"decimal"
argument_list|)
expr_stmt|;
block|}
specifier|static
name|Set
argument_list|<
name|String
argument_list|>
name|hiveThriftTypeMap
decl_stmt|;
comment|//for validation
static|static
block|{
name|hiveThriftTypeMap
operator|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|addAll
argument_list|(
name|serdeConstants
operator|.
name|PrimitiveTypes
argument_list|)
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|addAll
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|CollectionTypes
argument_list|)
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|add
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|UNION_TYPE_NAME
argument_list|)
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|add
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRUCT_TYPE_NAME
argument_list|)
expr_stmt|;
block|}
comment|/**    * Convert type to ThriftType. We do that by tokenizing the type and convert    * each token.    */
specifier|public
specifier|static
name|String
name|typeToThriftType
parameter_list|(
name|String
name|type
parameter_list|)
block|{
name|StringBuilder
name|thriftType
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|int
name|last
init|=
literal|0
decl_stmt|;
name|boolean
name|lastAlphaDigit
init|=
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|last
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|type
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|type
operator|.
name|length
argument_list|()
operator|||
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|!=
name|lastAlphaDigit
condition|)
block|{
name|String
name|token
init|=
name|type
operator|.
name|substring
argument_list|(
name|last
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|last
operator|=
name|i
expr_stmt|;
name|String
name|thriftToken
init|=
name|typeToThriftTypeMap
operator|.
name|get
argument_list|(
name|token
argument_list|)
decl_stmt|;
name|thriftType
operator|.
name|append
argument_list|(
name|thriftToken
operator|==
literal|null
condition|?
name|token
else|:
name|thriftToken
argument_list|)
expr_stmt|;
name|lastAlphaDigit
operator|=
operator|!
name|lastAlphaDigit
expr_stmt|;
block|}
block|}
return|return
name|thriftType
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to Thrift DDL + column names and column types    *    * @param structName    *          The name of the table    * @param fieldSchemas    *          List of fields along with their schemas    * @return String containing "Thrift    *         DDL#comma-separated-column-names#colon-separated-columntypes    *         Example:    *         "struct result { a string, map<int,string> b}#a,b#string:map<int,string>"    */
specifier|public
specifier|static
name|String
name|getFullDDLFromFieldSchema
parameter_list|(
name|String
name|structName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|ddl
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|getDDLFromFieldSchema
argument_list|(
name|structName
argument_list|,
name|fieldSchemas
argument_list|)
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|'#'
argument_list|)
expr_stmt|;
name|StringBuilder
name|colnames
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|coltypes
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|fieldSchemas
control|)
block|{
if|if
condition|(
name|first
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|colnames
operator|.
name|append
argument_list|(
literal|','
argument_list|)
expr_stmt|;
name|coltypes
operator|.
name|append
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
block|}
name|colnames
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|coltypes
operator|.
name|append
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
name|colnames
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|'#'
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|coltypes
argument_list|)
expr_stmt|;
return|return
name|ddl
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to Thrift DDL.    */
specifier|public
specifier|static
name|String
name|getDDLFromFieldSchema
parameter_list|(
name|String
name|structName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|ddl
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|"struct "
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|structName
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|" { "
argument_list|)
expr_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|fieldSchemas
control|)
block|{
if|if
condition|(
name|first
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|ddl
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
name|typeToThriftType
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|' '
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"DDL: "
operator|+
name|ddl
argument_list|)
expr_stmt|;
return|return
name|ddl
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getTableMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getPartitionMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|partition
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|part
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get partition level schema from table level schema.    * This function will use the same column names, column types and partition keys for    * each partition Properties. Their values are copied from the table Properties. This    * is mainly to save CPU and memory. CPU is saved because the first time the    * StorageDescriptor column names are accessed, JDO needs to execute a SQL query to    * retrieve the data. If we know the data will be the same as the table level schema    * and they are immutable, we should just reuse the table level schema objects.    *    * @param sd The Partition level Storage Descriptor.    * @param tblsd The Table level Storage Descriptor.    * @param parameters partition level parameters    * @param databaseName DB name    * @param tableName table name    * @param partitionKeys partition columns    * @param tblSchema The table level schema from which this partition should be copied.    * @return the properties    */
specifier|public
specifier|static
name|Properties
name|getPartSchemaFromTableSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|,
name|Properties
name|tblSchema
parameter_list|)
block|{
comment|// Inherent most properties from table level schema and overwrite some properties
comment|// in the following code.
comment|// This is mainly for saving CPU and memory to reuse the column names, types and
comment|// partition columns in the table level schema.
name|Properties
name|schema
init|=
operator|(
name|Properties
operator|)
name|tblSchema
operator|.
name|clone
argument_list|()
decl_stmt|;
comment|// InputFormat
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblInput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblInput
operator|==
literal|null
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|inputFormat
operator|=
name|tblInput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
comment|// OutputFormat
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblOutput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblOutput
operator|==
literal|null
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|outputFormat
operator|=
name|tblOutput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
comment|// Location
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Bucket count
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// SerdeInfo
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// We should not update the following 3 values if SerDeInfo contains these.
comment|// This is to keep backward compatible with getSchema(), where these 3 keys
comment|// are updated after SerDeInfo properties got copied.
name|String
name|cols
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
decl_stmt|;
name|String
name|colTypes
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
decl_stmt|;
name|String
name|parts
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|key
init|=
name|param
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|schema
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|!=
literal|null
operator|&&
operator|(
name|key
operator|.
name|equals
argument_list|(
name|cols
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|colTypes
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|parts
argument_list|)
operator|)
condition|)
block|{
continue|continue;
block|}
name|schema
operator|.
name|put
argument_list|(
name|key
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
literal|""
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// skipping columns since partition level field schemas are the same as table level's
comment|// skipping partition keys since it is the same as table level partition keys
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
name|Properties
name|schema
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_NAME
argument_list|,
name|databaseName
operator|+
literal|"."
operator|+
name|tableName
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|put
argument_list|(
name|param
operator|.
name|getKey
argument_list|()
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
literal|""
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|StringBuilder
name|colNameBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colTypeBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|tblsd
operator|.
name|getCols
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|colNameBuf
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
expr_stmt|;
block|}
name|colNameBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
block|}
name|String
name|colNames
init|=
name|colNameBuf
operator|.
name|toString
argument_list|()
decl_stmt|;
name|String
name|colTypes
init|=
name|colTypeBuf
operator|.
name|toString
argument_list|()
decl_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
argument_list|,
name|colNames
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
argument_list|,
name|colTypes
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_DDL
argument_list|,
name|getDDLFromFieldSchema
argument_list|(
name|tableName
argument_list|,
name|sd
operator|.
name|getCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|partString
init|=
literal|""
decl_stmt|;
name|String
name|partStringSep
init|=
literal|""
decl_stmt|;
for|for
control|(
name|FieldSchema
name|partKey
range|:
name|partitionKeys
control|)
block|{
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partStringSep
argument_list|)
expr_stmt|;
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|partStringSep
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|partStringSep
operator|=
literal|"/"
expr_stmt|;
block|}
block|}
if|if
condition|(
name|partString
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|,
name|partString
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// add non-null parameters to the schema
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|schema
return|;
block|}
comment|/**    * Convert FieldSchemas to columnNames.    */
specifier|public
specifier|static
name|String
name|getColumnNamesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to columnTypes.    */
specifier|public
specifier|static
name|String
name|getColumnTypesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|void
name|makeDir
parameter_list|(
name|Path
name|path
parameter_list|,
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|MetaException
block|{
name|FileSystem
name|fs
decl_stmt|;
try|try
block|{
name|fs
operator|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|path
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Unable to : "
operator|+
name|path
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|void
name|startMetaStore
parameter_list|(
specifier|final
name|int
name|port
parameter_list|,
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|)
throws|throws
name|Exception
block|{
name|Thread
name|thread
init|=
operator|new
name|Thread
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|HiveMetaStore
operator|.
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Metastore Thrift Server threw an exception..."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|thread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|thread
operator|.
name|start
argument_list|()
expr_stmt|;
name|loopUntilHMSReady
argument_list|(
name|port
argument_list|)
expr_stmt|;
block|}
comment|/**    * A simple connect test to make sure that the metastore is up    * @throws Exception    */
specifier|private
specifier|static
name|void
name|loopUntilHMSReady
parameter_list|(
name|int
name|port
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|retries
init|=
literal|0
decl_stmt|;
name|Exception
name|exc
init|=
literal|null
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
name|Socket
name|socket
init|=
operator|new
name|Socket
argument_list|()
decl_stmt|;
name|socket
operator|.
name|connect
argument_list|(
operator|new
name|InetSocketAddress
argument_list|(
name|port
argument_list|)
argument_list|,
literal|5000
argument_list|)
expr_stmt|;
name|socket
operator|.
name|close
argument_list|()
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|retries
operator|++
operator|>
literal|6
condition|)
block|{
comment|//give up
name|exc
operator|=
name|e
expr_stmt|;
break|break;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
literal|10000
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|exc
throw|;
block|}
comment|/**    * Finds a free port on the machine.    *    * @return    * @throws IOException    */
specifier|public
specifier|static
name|int
name|findFreePort
parameter_list|()
throws|throws
name|IOException
block|{
name|ServerSocket
name|socket
init|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|int
name|port
init|=
name|socket
operator|.
name|getLocalPort
argument_list|()
decl_stmt|;
name|socket
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|port
return|;
block|}
comment|/**    * Catches exceptions that can't be handled and bundles them to MetaException    *    * @param e    * @throws MetaException    */
specifier|static
name|void
name|logAndThrowMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|exInfo
init|=
literal|"Got exception: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|exInfo
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Converting exception to MetaException"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|exInfo
argument_list|)
throw|;
block|}
comment|/**    * @param tableName    * @param deserializer    * @return the list of fields    * @throws SerDeException    * @throws MetaException    */
specifier|public
specifier|static
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|getFieldsFromDeserializer
parameter_list|(
name|String
name|tableName
parameter_list|,
name|Deserializer
name|deserializer
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|MetaException
block|{
name|ObjectInspector
name|oi
init|=
name|deserializer
operator|.
name|getObjectInspector
argument_list|()
decl_stmt|;
name|String
index|[]
name|names
init|=
name|tableName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
name|String
name|last_name
init|=
name|names
index|[
name|names
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|names
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|oi
operator|instanceof
name|StructObjectInspector
condition|)
block|{
name|StructObjectInspector
name|soi
init|=
operator|(
name|StructObjectInspector
operator|)
name|oi
decl_stmt|;
name|StructField
name|sf
init|=
name|soi
operator|.
name|getStructFieldRef
argument_list|(
name|names
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|sf
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Invalid Field "
operator|+
name|names
index|[
name|i
index|]
argument_list|)
throw|;
block|}
else|else
block|{
name|oi
operator|=
name|sf
operator|.
name|getFieldObjectInspector
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|oi
operator|instanceof
name|ListObjectInspector
operator|&&
name|names
index|[
name|i
index|]
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"$elem$"
argument_list|)
condition|)
block|{
name|ListObjectInspector
name|loi
init|=
operator|(
name|ListObjectInspector
operator|)
name|oi
decl_stmt|;
name|oi
operator|=
name|loi
operator|.
name|getListElementObjectInspector
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oi
operator|instanceof
name|MapObjectInspector
operator|&&
name|names
index|[
name|i
index|]
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"$key$"
argument_list|)
condition|)
block|{
name|MapObjectInspector
name|moi
init|=
operator|(
name|MapObjectInspector
operator|)
name|oi
decl_stmt|;
name|oi
operator|=
name|moi
operator|.
name|getMapKeyObjectInspector
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oi
operator|instanceof
name|MapObjectInspector
operator|&&
name|names
index|[
name|i
index|]
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"$value$"
argument_list|)
condition|)
block|{
name|MapObjectInspector
name|moi
init|=
operator|(
name|MapObjectInspector
operator|)
name|oi
decl_stmt|;
name|oi
operator|=
name|moi
operator|.
name|getMapValueObjectInspector
argument_list|()
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Unknown type for "
operator|+
name|names
index|[
name|i
index|]
argument_list|)
throw|;
block|}
block|}
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
name|str_fields
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
comment|// rules on how to recurse the ObjectInspector based on its type
if|if
condition|(
name|oi
operator|.
name|getCategory
argument_list|()
operator|!=
name|Category
operator|.
name|STRUCT
condition|)
block|{
name|str_fields
operator|.
name|add
argument_list|(
operator|new
name|FieldSchema
argument_list|(
name|last_name
argument_list|,
name|oi
operator|.
name|getTypeName
argument_list|()
argument_list|,
name|FROM_SERIALIZER
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|?
extends|extends
name|StructField
argument_list|>
name|fields
init|=
operator|(
operator|(
name|StructObjectInspector
operator|)
name|oi
operator|)
operator|.
name|getAllStructFieldRefs
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fields
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|StructField
name|structField
init|=
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|String
name|fieldName
init|=
name|structField
operator|.
name|getFieldName
argument_list|()
decl_stmt|;
name|String
name|fieldTypeName
init|=
name|structField
operator|.
name|getFieldObjectInspector
argument_list|()
operator|.
name|getTypeName
argument_list|()
decl_stmt|;
name|String
name|fieldComment
init|=
name|determineFieldComment
argument_list|(
name|structField
operator|.
name|getFieldComment
argument_list|()
argument_list|)
decl_stmt|;
name|str_fields
operator|.
name|add
argument_list|(
operator|new
name|FieldSchema
argument_list|(
name|fieldName
argument_list|,
name|fieldTypeName
argument_list|,
name|fieldComment
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|str_fields
return|;
block|}
specifier|private
specifier|static
specifier|final
name|String
name|FROM_SERIALIZER
init|=
literal|"from deserializer"
decl_stmt|;
specifier|private
specifier|static
name|String
name|determineFieldComment
parameter_list|(
name|String
name|comment
parameter_list|)
block|{
return|return
operator|(
name|comment
operator|==
literal|null
operator|||
name|comment
operator|.
name|isEmpty
argument_list|()
operator|)
condition|?
name|FROM_SERIALIZER
else|:
name|comment
return|;
block|}
comment|/**    * Convert TypeInfo to FieldSchema.    */
specifier|public
specifier|static
name|FieldSchema
name|getFieldSchemaFromTypeInfo
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TypeInfo
name|typeInfo
parameter_list|)
block|{
return|return
operator|new
name|FieldSchema
argument_list|(
name|fieldName
argument_list|,
name|typeInfo
operator|.
name|getTypeName
argument_list|()
argument_list|,
literal|"generated by TypeInfoUtils.getFieldSchemaFromTypeInfo"
argument_list|)
return|;
block|}
comment|/**    * Determines whether a table is an external table.    *    * @param table table of interest    *    * @return true if external    */
specifier|public
specifier|static
name|boolean
name|isExternalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
literal|"EXTERNAL"
argument_list|)
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isArchived
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
specifier|public
specifier|static
name|Path
name|getOriginalLocation
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
assert|assert
operator|(
name|isArchived
argument_list|(
name|part
argument_list|)
operator|)
assert|;
name|String
name|originalLocation
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|originalLocation
operator|!=
literal|null
operator|)
assert|;
return|return
operator|new
name|Path
argument_list|(
name|originalLocation
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isNonNativeTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|(
name|table
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|META_TABLE_STORAGE
argument_list|)
operator|!=
literal|null
operator|)
return|;
block|}
comment|/**    * Returns true if partial has the same values as full for all values that    * aren't empty in partial.    */
specifier|public
specifier|static
name|boolean
name|pvalMatches
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partial
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|full
parameter_list|)
block|{
if|if
condition|(
name|partial
operator|.
name|size
argument_list|()
operator|>
name|full
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Iterator
argument_list|<
name|String
argument_list|>
name|p
init|=
name|partial
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|String
argument_list|>
name|f
init|=
name|full
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|p
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|String
name|pval
init|=
name|p
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|fval
init|=
name|f
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|pval
operator|.
name|length
argument_list|()
operator|!=
literal|0
operator|&&
operator|!
name|pval
operator|.
name|equals
argument_list|(
name|fval
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|String
name|getIndexTableName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|baseTblName
parameter_list|,
name|String
name|indexName
parameter_list|)
block|{
return|return
name|dbName
operator|+
literal|"__"
operator|+
name|baseTblName
operator|+
literal|"_"
operator|+
name|indexName
operator|+
literal|"__"
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isIndexTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|INDEX_TABLE
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Given a map of partition column names to values, this creates a filter    * string that can be used to call the *byFilter methods    * @param m    * @return the filter string    */
specifier|public
specifier|static
name|String
name|makeFilterStringFromMap
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|m
parameter_list|)
block|{
name|StringBuilder
name|filter
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|m
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|col
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|String
name|val
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|filter
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|filter
operator|.
name|append
argument_list|(
name|col
operator|+
literal|"=\""
operator|+
name|val
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|filter
operator|.
name|append
argument_list|(
literal|" and "
operator|+
name|col
operator|+
literal|"=\""
operator|+
name|val
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|filter
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * create listener instances as per the configuration.    *    * @param clazz    * @param conf    * @param listenerImplList    * @return    * @throws MetaException    */
specifier|static
parameter_list|<
name|T
parameter_list|>
name|List
argument_list|<
name|T
argument_list|>
name|getMetaStoreListeners
parameter_list|(
name|Class
argument_list|<
name|T
argument_list|>
name|clazz
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|String
name|listenerImplList
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|T
argument_list|>
name|listeners
init|=
operator|new
name|ArrayList
argument_list|<
name|T
argument_list|>
argument_list|()
decl_stmt|;
name|listenerImplList
operator|=
name|listenerImplList
operator|.
name|trim
argument_list|()
expr_stmt|;
if|if
condition|(
name|listenerImplList
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
return|return
name|listeners
return|;
block|}
name|String
index|[]
name|listenerImpls
init|=
name|listenerImplList
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|listenerImpl
range|:
name|listenerImpls
control|)
block|{
try|try
block|{
name|T
name|listener
init|=
operator|(
name|T
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|listenerImpl
operator|.
name|trim
argument_list|()
argument_list|,
literal|true
argument_list|,
name|JavaUtils
operator|.
name|getClassLoader
argument_list|()
argument_list|)
operator|.
name|getConstructor
argument_list|(
name|Configuration
operator|.
name|class
argument_list|)
operator|.
name|newInstance
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvocationTargetException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|ie
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|listeners
return|;
block|}
specifier|public
specifier|static
name|Class
argument_list|<
name|?
argument_list|>
name|getClass
parameter_list|(
name|String
name|rawStoreClassName
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
return|return
name|Class
operator|.
name|forName
argument_list|(
name|rawStoreClassName
argument_list|,
literal|true
argument_list|,
name|JavaUtils
operator|.
name|getClassLoader
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
name|rawStoreClassName
operator|+
literal|" class not found"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create an object of the given class.    * @param theClass    * @param parameterTypes    *          an array of parameterTypes for the constructor    * @param initargs    *          the list of arguments for the constructor    */
specifier|public
specifier|static
parameter_list|<
name|T
parameter_list|>
name|T
name|newInstance
parameter_list|(
name|Class
argument_list|<
name|T
argument_list|>
name|theClass
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
index|[]
name|parameterTypes
parameter_list|,
name|Object
index|[]
name|initargs
parameter_list|)
block|{
comment|// Perform some sanity checks on the arguments.
if|if
condition|(
name|parameterTypes
operator|.
name|length
operator|!=
name|initargs
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Number of constructor parameter types doesn't match number of arguments"
argument_list|)
throw|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|parameterTypes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
init|=
name|parameterTypes
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|clazz
operator|.
name|isInstance
argument_list|(
name|initargs
index|[
name|i
index|]
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Object : "
operator|+
name|initargs
index|[
name|i
index|]
operator|+
literal|" is not an instance of "
operator|+
name|clazz
argument_list|)
throw|;
block|}
block|}
try|try
block|{
name|Constructor
argument_list|<
name|T
argument_list|>
name|meth
init|=
name|theClass
operator|.
name|getDeclaredConstructor
argument_list|(
name|parameterTypes
argument_list|)
decl_stmt|;
name|meth
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|meth
operator|.
name|newInstance
argument_list|(
name|initargs
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unable to instantiate "
operator|+
name|theClass
operator|.
name|getName
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|void
name|validatePartitionNameCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|invalidPartitionVal
init|=
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
decl_stmt|;
if|if
condition|(
name|invalidPartitionVal
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Partition value '"
operator|+
name|invalidPartitionVal
operator|+
literal|"' contains a character "
operator|+
literal|"not matched by whitelist pattern '"
operator|+
name|partitionValidationPattern
operator|.
name|toString
argument_list|()
operator|+
literal|"'.  "
operator|+
literal|"(configure with "
operator|+
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_PARTITION_NAME_WHITELIST_PATTERN
operator|.
name|varname
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|boolean
name|partitionNameHasValidCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
return|return
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
operator|==
literal|null
return|;
block|}
comment|/**    * @param schema1: The first schema to be compared    * @param schema2: The second schema to be compared    * @return true if the two schemas are the same else false    *         for comparing a field we ignore the comment it has    */
specifier|public
specifier|static
name|boolean
name|compareFieldColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema1
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema2
parameter_list|)
block|{
if|if
condition|(
name|schema1
operator|.
name|size
argument_list|()
operator|!=
name|schema2
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|schema1
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|FieldSchema
name|f1
init|=
name|schema1
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|FieldSchema
name|f2
init|=
name|schema2
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// The default equals provided by thrift compares the comments too for
comment|// equality, thus we need to compare the relevant fields here.
if|if
condition|(
name|f1
operator|.
name|getName
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|f2
operator|.
name|getName
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|f1
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|f2
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|f1
operator|.
name|getType
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|f2
operator|.
name|getType
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|f1
operator|.
name|getType
argument_list|()
operator|.
name|equals
argument_list|(
name|f2
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Read and return the meta store Sasl configuration. Currently it uses the default    * Hadoop SASL configuration and can be configured using "hadoop.rpc.protection"    * @param conf    * @return The SASL configuration    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getMetaStoreSaslProperties
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
comment|// As of now Hive Meta Store uses the same configuration as Hadoop SASL configuration
return|return
name|ShimLoader
operator|.
name|getHadoopThriftAuthBridge
argument_list|()
operator|.
name|getHadoopSaslProperties
argument_list|(
name|conf
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
name|getPartitionValWithInvalidCharacter
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
if|if
condition|(
name|partitionValidationPattern
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|partVal
range|:
name|partVals
control|)
block|{
if|if
condition|(
operator|!
name|partitionValidationPattern
operator|.
name|matcher
argument_list|(
name|partVal
argument_list|)
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
name|partVal
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
end_class

end_unit

