begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Constructor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|ServerSocket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLClassLoader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Predicates
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|JavaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|common
operator|.
name|StatsSetupConst
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|conf
operator|.
name|HiveConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|HiveMetaStore
operator|.
name|HMSHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ColumnStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|ColumnStatisticsObj
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|EnvironmentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|FieldSchema
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidObjectException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|InvalidOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|SerDeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|hbase
operator|.
name|stats
operator|.
name|merge
operator|.
name|ColumnStatsMerger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|hbase
operator|.
name|stats
operator|.
name|merge
operator|.
name|ColumnStatsMergerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|partition
operator|.
name|spec
operator|.
name|PartitionSpecProxy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|Deserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|SerDeUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|lazy
operator|.
name|LazySimpleSerDe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ListObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|MapObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|ObjectInspector
operator|.
name|Category
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructField
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|objectinspector
operator|.
name|StructObjectInspector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde2
operator|.
name|typeinfo
operator|.
name|TypeInfoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|shims
operator|.
name|ShimLoader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|thrift
operator|.
name|HadoopThriftAuthBridge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|HiveStringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hive
operator|.
name|common
operator|.
name|util
operator|.
name|ReflectionUtil
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_class
specifier|public
class|class
name|MetaStoreUtils
block|{
specifier|protected
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"hive.log"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_DATABASE_NAME
init|=
literal|"default"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_DATABASE_COMMENT
init|=
literal|"Default Hive database"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_SERIALIZATION_FORMAT
init|=
literal|"1"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|DATABASE_WAREHOUSE_SUFFIX
init|=
literal|".db"
decl_stmt|;
comment|// Right now we only support one special character '/'.
comment|// More special characters can be added accordingly in the future.
comment|// NOTE:
comment|// If the following array is updated, please also be sure to update the
comment|// configuration parameter documentation
comment|// HIVE_SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES in HiveConf as well.
specifier|public
specifier|static
specifier|final
name|char
index|[]
name|specialCharactersInTableNames
init|=
operator|new
name|char
index|[]
block|{
literal|'/'
block|}
decl_stmt|;
specifier|public
specifier|static
name|Table
name|createColumnsetSchema
parameter_list|(
name|String
name|name
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|partCols
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|columns
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"columns not specified for table "
operator|+
name|name
argument_list|)
throw|;
block|}
name|Table
name|tTable
init|=
operator|new
name|Table
argument_list|()
decl_stmt|;
name|tTable
operator|.
name|setTableName
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|tTable
operator|.
name|setSd
argument_list|(
operator|new
name|StorageDescriptor
argument_list|()
argument_list|)
expr_stmt|;
name|StorageDescriptor
name|sd
init|=
name|tTable
operator|.
name|getSd
argument_list|()
decl_stmt|;
name|sd
operator|.
name|setSerdeInfo
argument_list|(
operator|new
name|SerDeInfo
argument_list|()
argument_list|)
expr_stmt|;
name|SerDeInfo
name|serdeInfo
init|=
name|sd
operator|.
name|getSerdeInfo
argument_list|()
decl_stmt|;
name|serdeInfo
operator|.
name|setSerializationLib
argument_list|(
name|LazySimpleSerDe
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|serdeInfo
operator|.
name|setParameters
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
name|serdeInfo
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_FORMAT
argument_list|,
name|DEFAULT_SERIALIZATION_FORMAT
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fields
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
name|sd
operator|.
name|setCols
argument_list|(
name|fields
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|col
range|:
name|columns
control|)
block|{
name|FieldSchema
name|field
init|=
operator|new
name|FieldSchema
argument_list|(
name|col
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
argument_list|,
literal|"'default'"
argument_list|)
decl_stmt|;
name|fields
operator|.
name|add
argument_list|(
name|field
argument_list|)
expr_stmt|;
block|}
name|tTable
operator|.
name|setPartitionKeys
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|partCol
range|:
name|partCols
control|)
block|{
name|FieldSchema
name|part
init|=
operator|new
name|FieldSchema
argument_list|()
decl_stmt|;
name|part
operator|.
name|setName
argument_list|(
name|partCol
argument_list|)
expr_stmt|;
name|part
operator|.
name|setType
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
argument_list|)
expr_stmt|;
comment|// default
comment|// partition
comment|// key
name|tTable
operator|.
name|getPartitionKeys
argument_list|()
operator|.
name|add
argument_list|(
name|part
argument_list|)
expr_stmt|;
block|}
name|sd
operator|.
name|setNumBuckets
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
return|return
name|tTable
return|;
block|}
comment|/**    * recursiveDelete    *    * just recursively deletes a dir - you'd think Java would have something to    * do this??    *    * @param f    *          - the file/dir to delete    * @exception IOException    *              propogate f.delete() exceptions    *    */
specifier|static
specifier|public
name|void
name|recursiveDelete
parameter_list|(
name|File
name|f
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|f
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|File
name|fs
index|[]
init|=
name|f
operator|.
name|listFiles
argument_list|()
decl_stmt|;
for|for
control|(
name|File
name|subf
range|:
name|fs
control|)
block|{
name|recursiveDelete
argument_list|(
name|subf
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|f
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"could not delete: "
operator|+
name|f
operator|.
name|getPath
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param partParams    * @return True if the passed Parameters Map contains values for all "Fast Stats".    */
specifier|public
specifier|static
name|boolean
name|containsAllFastStats
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partParams
parameter_list|)
block|{
for|for
control|(
name|String
name|stat
range|:
name|StatsSetupConst
operator|.
name|fastStats
control|)
block|{
if|if
condition|(
operator|!
name|partParams
operator|.
name|containsKey
argument_list|(
name|stat
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updateTableStatsFast
parameter_list|(
name|Database
name|db
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updateTableStatsFast
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updateTableStatsFast
parameter_list|(
name|Database
name|db
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
name|tbl
operator|.
name|getPartitionKeysSize
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// Update stats only when unpartitioned
name|FileStatus
index|[]
name|fileStatuses
init|=
name|wh
operator|.
name|getFileStatusesForUnpartitionedTable
argument_list|(
name|db
argument_list|,
name|tbl
argument_list|)
decl_stmt|;
return|return
name|updateTableStatsFast
argument_list|(
name|tbl
argument_list|,
name|fileStatuses
argument_list|,
name|madeDir
argument_list|,
name|forceRecompute
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Table by querying    * the warehouse if the passed Table does not already have values for these parameters.    * @param tbl    * @param fileStatus    * @param newDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Table already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updateTableStatsFast
parameter_list|(
name|Table
name|tbl
parameter_list|,
name|FileStatus
index|[]
name|fileStatus
parameter_list|,
name|boolean
name|newDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|tbl
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|params
operator|!=
literal|null
operator|)
operator|&&
name|params
operator|.
name|containsKey
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
condition|)
block|{
name|boolean
name|doNotUpdateStats
init|=
name|Boolean
operator|.
name|valueOf
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
argument_list|)
decl_stmt|;
name|params
operator|.
name|remove
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
expr_stmt|;
name|tbl
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
comment|// to make sure we remove this marker property
if|if
condition|(
name|doNotUpdateStats
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
name|boolean
name|updated
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|forceRecompute
operator|||
name|params
operator|==
literal|null
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|params
argument_list|)
condition|)
block|{
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
name|params
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|newDir
condition|)
block|{
comment|// The table location already exists and may contain data.
comment|// Let's try to populate those stats that don't require full scan.
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating table stats fast for "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|populateQuickStats
argument_list|(
name|fileStatus
argument_list|,
name|params
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated size of table "
operator|+
name|tbl
operator|.
name|getTableName
argument_list|()
operator|+
literal|" to "
operator|+
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
block|}
name|tbl
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
name|updated
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|updated
return|;
block|}
specifier|public
specifier|static
name|void
name|populateQuickStats
parameter_list|(
name|FileStatus
index|[]
name|fileStatus
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
name|int
name|numFiles
init|=
literal|0
decl_stmt|;
name|long
name|tableSize
init|=
literal|0L
decl_stmt|;
for|for
control|(
name|FileStatus
name|status
range|:
name|fileStatus
control|)
block|{
comment|// don't take directories into account for quick stats
if|if
condition|(
operator|!
name|status
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|tableSize
operator|+=
name|status
operator|.
name|getLen
argument_list|()
expr_stmt|;
name|numFiles
operator|+=
literal|1
expr_stmt|;
block|}
block|}
name|params
operator|.
name|put
argument_list|(
name|StatsSetupConst
operator|.
name|NUM_FILES
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|numFiles
argument_list|)
argument_list|)
expr_stmt|;
name|params
operator|.
name|put
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|tableSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// check if stats need to be (re)calculated
specifier|public
specifier|static
name|boolean
name|requireCalStats
parameter_list|(
name|Configuration
name|hiveConf
parameter_list|,
name|Partition
name|oldPart
parameter_list|,
name|Partition
name|newPart
parameter_list|,
name|Table
name|tbl
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
block|{
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TRUE
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|DO_NOT_UPDATE_STATS
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|MetaStoreUtils
operator|.
name|isView
argument_list|(
name|tbl
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|oldPart
operator|==
literal|null
operator|&&
name|newPart
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// requires to calculate stats if new partition doesn't have it
if|if
condition|(
operator|(
name|newPart
operator|==
literal|null
operator|)
operator|||
operator|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|==
literal|null
operator|)
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|newPart
operator|.
name|getParameters
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// requires to calculate stats if new and old have different fast stats
if|if
condition|(
operator|(
name|oldPart
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|!=
literal|null
operator|)
condition|)
block|{
for|for
control|(
name|String
name|stat
range|:
name|StatsSetupConst
operator|.
name|fastStats
control|)
block|{
if|if
condition|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|.
name|containsKey
argument_list|(
name|stat
argument_list|)
condition|)
block|{
name|Long
name|oldStat
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|oldPart
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|stat
argument_list|)
argument_list|)
decl_stmt|;
name|Long
name|newStat
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|newPart
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|stat
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|oldStat
operator|.
name|equals
argument_list|(
name|newStat
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
name|part
argument_list|,
name|wh
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
name|part
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
literal|false
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Partition by querying    *  the warehouse if the passed Partition does not already have values for these parameters.    * @param part    * @param wh    * @param madeDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Partition already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|Partition
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
return|return
name|updatePartitionStatsFast
argument_list|(
operator|new
name|PartitionSpecProxy
operator|.
name|SimplePartitionWrapperIterator
argument_list|(
name|part
argument_list|)
argument_list|,
name|wh
argument_list|,
name|madeDir
argument_list|,
name|forceRecompute
argument_list|,
name|environmentContext
argument_list|)
return|;
block|}
comment|/**    * Updates the numFiles and totalSize parameters for the passed Partition by querying    *  the warehouse if the passed Partition does not already have values for these parameters.    * @param part    * @param wh    * @param madeDir if true, the directory was just created and can be assumed to be empty    * @param forceRecompute Recompute stats even if the passed Partition already has    * these parameters set    * @return true if the stats were updated, false otherwise    */
specifier|public
specifier|static
name|boolean
name|updatePartitionStatsFast
parameter_list|(
name|PartitionSpecProxy
operator|.
name|PartitionIterator
name|part
parameter_list|,
name|Warehouse
name|wh
parameter_list|,
name|boolean
name|madeDir
parameter_list|,
name|boolean
name|forceRecompute
parameter_list|,
name|EnvironmentContext
name|environmentContext
parameter_list|)
throws|throws
name|MetaException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
name|boolean
name|updated
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|forceRecompute
operator|||
name|params
operator|==
literal|null
operator|||
operator|!
name|containsAllFastStats
argument_list|(
name|params
argument_list|)
condition|)
block|{
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
name|params
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|madeDir
condition|)
block|{
comment|// The partition location already existed and may contain data. Lets try to
comment|// populate those statistics that don't require a full scan of the data.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Updating partition stats fast for: "
operator|+
name|part
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|fileStatus
init|=
name|wh
operator|.
name|getFileStatusesForLocation
argument_list|(
name|part
operator|.
name|getLocation
argument_list|()
argument_list|)
decl_stmt|;
name|populateQuickStats
argument_list|(
name|fileStatus
argument_list|,
name|params
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Updated size to "
operator|+
name|params
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|TOTAL_SIZE
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|environmentContext
operator|!=
literal|null
operator|&&
name|environmentContext
operator|.
name|isSetProperties
argument_list|()
operator|&&
name|StatsSetupConst
operator|.
name|TASK
operator|.
name|equals
argument_list|(
name|environmentContext
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|StatsSetupConst
operator|.
name|STATS_GENERATED
argument_list|)
argument_list|)
condition|)
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|StatsSetupConst
operator|.
name|setBasicStatsState
argument_list|(
name|params
argument_list|,
name|StatsSetupConst
operator|.
name|FALSE
argument_list|)
expr_stmt|;
block|}
block|}
name|part
operator|.
name|setParameters
argument_list|(
name|params
argument_list|)
expr_stmt|;
name|updated
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|updated
return|;
block|}
comment|/**    * getDeserializer    *    * Get the Deserializer for a table.    *    * @param conf    *          - hadoop config    * @param table    *          the table    * @return    *   Returns instantiated deserializer by looking up class name of deserializer stored in    *   storage descriptor of passed in table. Also, initializes the deserializer with schema    *   of table.    * @exception MetaException    *              if any problems instantiating the Deserializer    *    *              todo - this should move somewhere into serde.jar    *    */
specifier|static
specifier|public
name|Deserializer
name|getDeserializer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|,
name|boolean
name|skipConfError
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|lib
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
if|if
condition|(
name|lib
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|getDeserializer
argument_list|(
name|conf
argument_list|,
name|table
argument_list|,
name|skipConfError
argument_list|,
name|lib
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Deserializer
name|getDeserializer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|,
name|boolean
name|skipConfError
parameter_list|,
name|String
name|lib
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
name|Deserializer
name|deserializer
init|=
name|ReflectionUtil
operator|.
name|newInstance
argument_list|(
name|conf
operator|.
name|getClassByName
argument_list|(
name|lib
argument_list|)
operator|.
name|asSubclass
argument_list|(
name|Deserializer
operator|.
name|class
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|skipConfError
condition|)
block|{
name|SerDeUtils
operator|.
name|initializeSerDeWithoutErrorCheck
argument_list|(
name|deserializer
argument_list|,
name|conf
argument_list|,
name|MetaStoreUtils
operator|.
name|getTableMetadata
argument_list|(
name|table
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|SerDeUtils
operator|.
name|initializeSerDe
argument_list|(
name|deserializer
argument_list|,
name|conf
argument_list|,
name|MetaStoreUtils
operator|.
name|getTableMetadata
argument_list|(
name|table
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
return|return
name|deserializer
return|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error in initSerDe: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|Class
argument_list|<
name|?
extends|extends
name|Deserializer
argument_list|>
name|getDeserializerClass
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
throws|throws
name|Exception
block|{
name|String
name|lib
init|=
name|table
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
return|return
name|lib
operator|==
literal|null
condition|?
literal|null
else|:
name|conf
operator|.
name|getClassByName
argument_list|(
name|lib
argument_list|)
operator|.
name|asSubclass
argument_list|(
name|Deserializer
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * getDeserializer    *    * Get the Deserializer for a partition.    *    * @param conf    *          - hadoop config    * @param part    *          the partition    * @param table the table    * @return    *   Returns instantiated deserializer by looking up class name of deserializer stored in    *   storage descriptor of passed in partition. Also, initializes the deserializer with    *   schema of partition.    * @exception MetaException    *              if any problems instantiating the Deserializer    *    */
specifier|static
specifier|public
name|Deserializer
name|getDeserializer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|lib
init|=
name|part
operator|.
name|getSd
argument_list|()
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
decl_stmt|;
try|try
block|{
name|Deserializer
name|deserializer
init|=
name|ReflectionUtil
operator|.
name|newInstance
argument_list|(
name|conf
operator|.
name|getClassByName
argument_list|(
name|lib
argument_list|)
operator|.
name|asSubclass
argument_list|(
name|Deserializer
operator|.
name|class
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|SerDeUtils
operator|.
name|initializeSerDe
argument_list|(
name|deserializer
argument_list|,
name|conf
argument_list|,
name|MetaStoreUtils
operator|.
name|getTableMetadata
argument_list|(
name|table
argument_list|)
argument_list|,
name|MetaStoreUtils
operator|.
name|getPartitionMetadata
argument_list|(
name|part
argument_list|,
name|table
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|deserializer
return|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error in initSerDe: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|static
specifier|public
name|void
name|deleteWHDirectory
parameter_list|(
name|Path
name|path
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|use_trash
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
if|if
condition|(
operator|!
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|path
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"drop data called on table/partition with no directory: "
operator|+
name|path
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|use_trash
condition|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
name|Path
name|newPath
init|=
operator|new
name|Path
argument_list|(
literal|"/Trash/Current"
operator|+
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|newPath
argument_list|)
operator|==
literal|false
condition|)
block|{
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|mkdirs
argument_list|(
name|newPath
argument_list|)
expr_stmt|;
block|}
do|do
block|{
name|newPath
operator|=
operator|new
name|Path
argument_list|(
literal|"/Trash/Current"
operator|+
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|+
literal|"."
operator|+
name|count
argument_list|)
expr_stmt|;
if|if
condition|(
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|newPath
argument_list|)
condition|)
block|{
name|count
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|rename
argument_list|(
name|path
argument_list|,
name|newPath
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
do|while
condition|(
operator|++
name|count
operator|<
literal|50
condition|)
do|;
if|if
condition|(
name|count
operator|>=
literal|50
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Rename failed due to maxing out retries"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|// directly delete it
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|delete
argument_list|(
name|path
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Got exception trying to delete data dir: "
operator|+
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Got exception trying to delete data dir: "
operator|+
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Given a list of partition columns and a partial mapping from    * some partition columns to values the function returns the values    * for the column.    * @param partCols the list of table partition columns    * @param partSpec the partial mapping from partition column to values    * @return list of values of for given partition columns, any missing    *         values in partSpec is replaced by an empty string    */
specifier|public
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|getPvals
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partCols
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|partSpec
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|pvals
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|field
range|:
name|partCols
control|)
block|{
name|String
name|val
init|=
name|partSpec
operator|.
name|get
argument_list|(
name|field
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
literal|""
expr_stmt|;
block|}
name|pvals
operator|.
name|add
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
return|return
name|pvals
return|;
block|}
comment|/**    * validateName    *    * Checks the name conforms to our standars which are: "[a-zA-z_0-9]+". checks    * this is just characters and numbers and _    *    * @param name    *          the name to validate    * @param conf    *          hive configuration    * @return true or false depending on conformance    * @exception MetaException    *              if it doesn't match the pattern.    */
specifier|static
specifier|public
name|boolean
name|validateName
parameter_list|(
name|String
name|name
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|Pattern
name|tpat
init|=
literal|null
decl_stmt|;
name|String
name|allowedCharacters
init|=
literal|"\\w_"
decl_stmt|;
if|if
condition|(
name|conf
operator|!=
literal|null
operator|&&
name|HiveConf
operator|.
name|getBoolVar
argument_list|(
name|conf
argument_list|,
name|HiveConf
operator|.
name|ConfVars
operator|.
name|HIVE_SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES
argument_list|)
condition|)
block|{
for|for
control|(
name|Character
name|c
range|:
name|specialCharactersInTableNames
control|)
block|{
name|allowedCharacters
operator|+=
name|c
expr_stmt|;
block|}
block|}
name|tpat
operator|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"["
operator|+
name|allowedCharacters
operator|+
literal|"]+"
argument_list|)
expr_stmt|;
name|Matcher
name|m
init|=
name|tpat
operator|.
name|matcher
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/*    * At the Metadata level there are no restrictions on Column Names.    */
specifier|public
specifier|static
specifier|final
name|boolean
name|validateColumnName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
specifier|static
specifier|public
name|String
name|validateTblColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|validateColumnName
argument_list|(
name|fieldSchema
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|"name: "
operator|+
name|fieldSchema
operator|.
name|getName
argument_list|()
return|;
block|}
name|String
name|typeError
init|=
name|validateColumnType
argument_list|(
name|fieldSchema
operator|.
name|getType
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|typeError
operator|!=
literal|null
condition|)
block|{
return|return
name|typeError
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|static
name|void
name|throwExceptionIfIncompatibleColTypeChange
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
throws|throws
name|InvalidOperationException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|incompatibleCols
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|int
name|maxCols
init|=
name|Math
operator|.
name|min
argument_list|(
name|oldCols
operator|.
name|size
argument_list|()
argument_list|,
name|newCols
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|maxCols
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|areColTypesCompatible
argument_list|(
name|oldCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|,
name|newCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
name|incompatibleCols
operator|.
name|add
argument_list|(
name|newCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|incompatibleCols
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|InvalidOperationException
argument_list|(
literal|"The following columns have types incompatible with the existing "
operator|+
literal|"columns in their respective positions :\n"
operator|+
name|StringUtils
operator|.
name|join
argument_list|(
name|incompatibleCols
argument_list|,
literal|','
argument_list|)
argument_list|)
throw|;
block|}
block|}
specifier|static
name|boolean
name|isCascadeNeededInAlterTable
parameter_list|(
name|Table
name|oldTable
parameter_list|,
name|Table
name|newTable
parameter_list|)
block|{
comment|//currently cascade only supports add/replace columns and
comment|//changing column type/position/name/comments
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
init|=
name|oldTable
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
init|=
name|newTable
operator|.
name|getSd
argument_list|()
operator|.
name|getCols
argument_list|()
decl_stmt|;
return|return
operator|!
name|areSameColumns
argument_list|(
name|oldCols
argument_list|,
name|newCols
argument_list|)
return|;
block|}
specifier|static
name|boolean
name|areSameColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|oldCols
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|newCols
parameter_list|)
block|{
if|if
condition|(
name|oldCols
operator|.
name|size
argument_list|()
operator|!=
name|newCols
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
else|else
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|oldCols
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|FieldSchema
name|oldCol
init|=
name|oldCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|FieldSchema
name|newCol
init|=
name|newCols
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|oldCol
operator|.
name|equals
argument_list|(
name|newCol
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * @return true if oldType and newType are compatible.    * Two types are compatible if we have internal functions to cast one to another.    */
specifier|static
specifier|private
name|boolean
name|areColTypesCompatible
parameter_list|(
name|String
name|oldType
parameter_list|,
name|String
name|newType
parameter_list|)
block|{
comment|/*      * RCFile default serde (ColumnarSerde) serializes the values in such a way that the      * datatypes can be converted from string to any type. The map is also serialized as      * a string, which can be read as a string as well. However, with any binary      * serialization, this is not true.      *      * Primitive types like INT, STRING, BIGINT, etc are compatible with each other and are      * not blocked.      */
return|return
name|TypeInfoUtils
operator|.
name|implicitConvertible
argument_list|(
name|TypeInfoUtils
operator|.
name|getTypeInfoFromTypeString
argument_list|(
name|oldType
argument_list|)
argument_list|,
name|TypeInfoUtils
operator|.
name|getTypeInfoFromTypeString
argument_list|(
name|newType
argument_list|)
argument_list|)
return|;
block|}
specifier|public
specifier|static
specifier|final
name|int
name|MAX_MS_TYPENAME_LENGTH
init|=
literal|2000
decl_stmt|;
comment|// 4000/2, for an unlikely unicode case
specifier|public
specifier|static
specifier|final
name|String
name|TYPE_FROM_DESERIALIZER
init|=
literal|"<derived from deserializer>"
decl_stmt|;
comment|/**    * validate column type    *    * if it is predefined, yes. otherwise no    * @param name    * @return    */
specifier|static
specifier|public
name|String
name|validateColumnType
parameter_list|(
name|String
name|type
parameter_list|)
block|{
if|if
condition|(
name|type
operator|.
name|equals
argument_list|(
name|TYPE_FROM_DESERIALIZER
argument_list|)
condition|)
return|return
literal|null
return|;
if|if
condition|(
name|type
operator|.
name|length
argument_list|()
operator|>
name|MAX_MS_TYPENAME_LENGTH
condition|)
block|{
return|return
literal|"type name is too long: "
operator|+
name|type
return|;
block|}
name|int
name|last
init|=
literal|0
decl_stmt|;
name|boolean
name|lastAlphaDigit
init|=
name|isValidTypeChar
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|last
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|type
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|type
operator|.
name|length
argument_list|()
operator|||
name|isValidTypeChar
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|!=
name|lastAlphaDigit
condition|)
block|{
name|String
name|token
init|=
name|type
operator|.
name|substring
argument_list|(
name|last
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|last
operator|=
name|i
expr_stmt|;
if|if
condition|(
operator|!
name|hiveThriftTypeMap
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
return|return
literal|"type: "
operator|+
name|type
return|;
block|}
break|break;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isValidTypeChar
parameter_list|(
name|char
name|c
parameter_list|)
block|{
return|return
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|c
argument_list|)
operator|||
name|c
operator|==
literal|'_'
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNames
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
literal|null
operator|==
name|cols
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|validateColumnName
argument_list|(
name|col
argument_list|)
condition|)
block|{
return|return
name|col
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|public
specifier|static
name|String
name|validateSkewedColNamesSubsetCol
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|skewedColNames
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
if|if
condition|(
literal|null
operator|==
name|skewedColNames
condition|)
block|{
return|return
literal|null
return|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|colNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FieldSchema
name|fieldSchema
range|:
name|cols
control|)
block|{
name|colNames
operator|.
name|add
argument_list|(
name|fieldSchema
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// make a copy
name|List
argument_list|<
name|String
argument_list|>
name|copySkewedColNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|skewedColNames
argument_list|)
decl_stmt|;
comment|// remove valid columns
name|copySkewedColNames
operator|.
name|removeAll
argument_list|(
name|colNames
argument_list|)
expr_stmt|;
if|if
condition|(
name|copySkewedColNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|copySkewedColNames
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|String
name|getListType
parameter_list|(
name|String
name|t
parameter_list|)
block|{
return|return
literal|"array<"
operator|+
name|t
operator|+
literal|">"
return|;
block|}
specifier|public
specifier|static
name|String
name|getMapType
parameter_list|(
name|String
name|k
parameter_list|,
name|String
name|v
parameter_list|)
block|{
return|return
literal|"map<"
operator|+
name|k
operator|+
literal|","
operator|+
name|v
operator|+
literal|">"
return|;
block|}
specifier|public
specifier|static
name|void
name|setSerdeParam
parameter_list|(
name|SerDeInfo
name|sdi
parameter_list|,
name|Properties
name|schema
parameter_list|,
name|String
name|param
parameter_list|)
block|{
name|String
name|val
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|param
argument_list|)
decl_stmt|;
if|if
condition|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|val
argument_list|)
condition|)
block|{
name|sdi
operator|.
name|getParameters
argument_list|()
operator|.
name|put
argument_list|(
name|param
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
specifier|static
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|typeToThriftTypeMap
decl_stmt|;
static|static
block|{
name|typeToThriftTypeMap
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|BOOLEAN_TYPE_NAME
argument_list|,
literal|"bool"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|TINYINT_TYPE_NAME
argument_list|,
literal|"byte"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SMALLINT_TYPE_NAME
argument_list|,
literal|"i16"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|INT_TYPE_NAME
argument_list|,
literal|"i32"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|BIGINT_TYPE_NAME
argument_list|,
literal|"i64"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DOUBLE_TYPE_NAME
argument_list|,
literal|"double"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|FLOAT_TYPE_NAME
argument_list|,
literal|"float"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|LIST_TYPE_NAME
argument_list|,
literal|"list"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|MAP_TYPE_NAME
argument_list|,
literal|"map"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRING_TYPE_NAME
argument_list|,
literal|"string"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|BINARY_TYPE_NAME
argument_list|,
literal|"binary"
argument_list|)
expr_stmt|;
comment|// These 4 types are not supported yet.
comment|// We should define a complex type date in thrift that contains a single int
comment|// member, and DynamicSerDe
comment|// should convert it to date type at runtime.
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DATE_TYPE_NAME
argument_list|,
literal|"date"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DATETIME_TYPE_NAME
argument_list|,
literal|"datetime"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|TIMESTAMP_TYPE_NAME
argument_list|,
literal|"timestamp"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|DECIMAL_TYPE_NAME
argument_list|,
literal|"decimal"
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|INTERVAL_YEAR_MONTH_TYPE_NAME
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|INTERVAL_YEAR_MONTH_TYPE_NAME
argument_list|)
expr_stmt|;
name|typeToThriftTypeMap
operator|.
name|put
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|INTERVAL_DAY_TIME_TYPE_NAME
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|INTERVAL_DAY_TIME_TYPE_NAME
argument_list|)
expr_stmt|;
block|}
specifier|static
name|Set
argument_list|<
name|String
argument_list|>
name|hiveThriftTypeMap
decl_stmt|;
comment|//for validation
static|static
block|{
name|hiveThriftTypeMap
operator|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|addAll
argument_list|(
name|serdeConstants
operator|.
name|PrimitiveTypes
argument_list|)
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|addAll
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|CollectionTypes
argument_list|)
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|add
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|UNION_TYPE_NAME
argument_list|)
expr_stmt|;
name|hiveThriftTypeMap
operator|.
name|add
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|STRUCT_TYPE_NAME
argument_list|)
expr_stmt|;
block|}
comment|/**    * Convert type to ThriftType. We do that by tokenizing the type and convert    * each token.    */
specifier|public
specifier|static
name|String
name|typeToThriftType
parameter_list|(
name|String
name|type
parameter_list|)
block|{
name|StringBuilder
name|thriftType
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|int
name|last
init|=
literal|0
decl_stmt|;
name|boolean
name|lastAlphaDigit
init|=
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|last
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|type
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|==
name|type
operator|.
name|length
argument_list|()
operator|||
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|type
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|!=
name|lastAlphaDigit
condition|)
block|{
name|String
name|token
init|=
name|type
operator|.
name|substring
argument_list|(
name|last
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|last
operator|=
name|i
expr_stmt|;
name|String
name|thriftToken
init|=
name|typeToThriftTypeMap
operator|.
name|get
argument_list|(
name|token
argument_list|)
decl_stmt|;
name|thriftType
operator|.
name|append
argument_list|(
name|thriftToken
operator|==
literal|null
condition|?
name|token
else|:
name|thriftToken
argument_list|)
expr_stmt|;
name|lastAlphaDigit
operator|=
operator|!
name|lastAlphaDigit
expr_stmt|;
block|}
block|}
return|return
name|thriftType
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to Thrift DDL + column names and column types    *    * @param structName    *          The name of the table    * @param fieldSchemas    *          List of fields along with their schemas    * @return String containing "Thrift    *         DDL#comma-separated-column-names#colon-separated-columntypes    *         Example:    *         "struct result { a string, map<int,string> b}#a,b#string:map<int,string>"    */
specifier|public
specifier|static
name|String
name|getFullDDLFromFieldSchema
parameter_list|(
name|String
name|structName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|ddl
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|getDDLFromFieldSchema
argument_list|(
name|structName
argument_list|,
name|fieldSchemas
argument_list|)
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|'#'
argument_list|)
expr_stmt|;
name|StringBuilder
name|colnames
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|coltypes
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|fieldSchemas
control|)
block|{
if|if
condition|(
name|first
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|colnames
operator|.
name|append
argument_list|(
literal|','
argument_list|)
expr_stmt|;
name|coltypes
operator|.
name|append
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
block|}
name|colnames
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|coltypes
operator|.
name|append
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
name|colnames
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|'#'
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|coltypes
argument_list|)
expr_stmt|;
return|return
name|ddl
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to Thrift DDL.    */
specifier|public
specifier|static
name|String
name|getDDLFromFieldSchema
parameter_list|(
name|String
name|structName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|ddl
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|"struct "
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|structName
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|" { "
argument_list|)
expr_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|fieldSchemas
control|)
block|{
if|if
condition|(
name|first
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|ddl
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
name|typeToThriftType
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
literal|' '
argument_list|)
expr_stmt|;
name|ddl
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ddl
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"DDL: "
operator|+
name|ddl
argument_list|)
expr_stmt|;
return|return
name|ddl
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getTableMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getPartitionMetadata
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|partition
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getSd
argument_list|()
argument_list|,
name|partition
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Table
name|table
parameter_list|)
block|{
return|return
name|MetaStoreUtils
operator|.
name|getSchema
argument_list|(
name|part
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getSd
argument_list|()
argument_list|,
name|table
operator|.
name|getParameters
argument_list|()
argument_list|,
name|table
operator|.
name|getDbName
argument_list|()
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|table
operator|.
name|getPartitionKeys
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get partition level schema from table level schema.    * This function will use the same column names, column types and partition keys for    * each partition Properties. Their values are copied from the table Properties. This    * is mainly to save CPU and memory. CPU is saved because the first time the    * StorageDescriptor column names are accessed, JDO needs to execute a SQL query to    * retrieve the data. If we know the data will be the same as the table level schema    * and they are immutable, we should just reuse the table level schema objects.    *    * @param sd The Partition level Storage Descriptor.    * @param tblsd The Table level Storage Descriptor.    * @param parameters partition level parameters    * @param databaseName DB name    * @param tableName table name    * @param partitionKeys partition columns    * @param tblSchema The table level schema from which this partition should be copied.    * @return the properties    */
specifier|public
specifier|static
name|Properties
name|getPartSchemaFromTableSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|,
name|Properties
name|tblSchema
parameter_list|)
block|{
comment|// Inherent most properties from table level schema and overwrite some properties
comment|// in the following code.
comment|// This is mainly for saving CPU and memory to reuse the column names, types and
comment|// partition columns in the table level schema.
name|Properties
name|schema
init|=
operator|(
name|Properties
operator|)
name|tblSchema
operator|.
name|clone
argument_list|()
decl_stmt|;
comment|// InputFormat
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblInput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblInput
operator|==
literal|null
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|inputFormat
operator|=
name|tblInput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
comment|// OutputFormat
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|String
name|tblOutput
init|=
name|schema
operator|.
name|getProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|tblOutput
operator|==
literal|null
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|outputFormat
operator|=
name|tblOutput
expr_stmt|;
block|}
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
comment|// Location
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Bucket count
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// SerdeInfo
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// We should not update the following 3 values if SerDeInfo contains these.
comment|// This is to keep backward compatible with getSchema(), where these 3 keys
comment|// are updated after SerDeInfo properties got copied.
name|String
name|cols
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
decl_stmt|;
name|String
name|colTypes
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
decl_stmt|;
name|String
name|parts
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|key
init|=
name|param
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|schema
operator|.
name|get
argument_list|(
name|key
argument_list|)
operator|!=
literal|null
operator|&&
operator|(
name|key
operator|.
name|equals
argument_list|(
name|cols
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|colTypes
argument_list|)
operator|||
name|key
operator|.
name|equals
argument_list|(
name|parts
argument_list|)
operator|)
condition|)
block|{
continue|continue;
block|}
name|schema
operator|.
name|put
argument_list|(
name|key
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
literal|""
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// skipping columns since partition level field schemas are the same as table level's
comment|// skipping partition keys since it is the same as table level partition keys
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|addCols
parameter_list|(
name|Properties
name|schema
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|cols
parameter_list|)
block|{
name|StringBuilder
name|colNameBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colTypeBuf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|StringBuilder
name|colComment
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|FieldSchema
name|col
range|:
name|cols
control|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|colNameBuf
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
literal|":"
argument_list|)
expr_stmt|;
name|colComment
operator|.
name|append
argument_list|(
literal|'\0'
argument_list|)
expr_stmt|;
block|}
name|colNameBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|colTypeBuf
operator|.
name|append
argument_list|(
name|col
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
name|colComment
operator|.
name|append
argument_list|(
operator|(
literal|null
operator|!=
name|col
operator|.
name|getComment
argument_list|()
operator|)
condition|?
name|col
operator|.
name|getComment
argument_list|()
else|:
literal|""
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMNS
argument_list|,
name|colNameBuf
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|colTypes
init|=
name|colTypeBuf
operator|.
name|toString
argument_list|()
decl_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_COLUMN_TYPES
argument_list|,
name|colTypes
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
literal|"columns.comments"
argument_list|,
name|colComment
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchemaWithoutCols
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
name|Properties
name|schema
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|String
name|inputFormat
init|=
name|sd
operator|.
name|getInputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|inputFormat
operator|==
literal|null
operator|||
name|inputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|inputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileInputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_INPUT_FORMAT
argument_list|,
name|inputFormat
argument_list|)
expr_stmt|;
name|String
name|outputFormat
init|=
name|sd
operator|.
name|getOutputFormat
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputFormat
operator|==
literal|null
operator|||
name|outputFormat
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|outputFormat
operator|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SequenceFileOutputFormat
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|FILE_OUTPUT_FORMAT
argument_list|,
name|outputFormat
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_NAME
argument_list|,
name|databaseName
operator|+
literal|"."
operator|+
name|tableName
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_LOCATION
argument_list|,
name|sd
operator|.
name|getLocation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_COUNT
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|sd
operator|.
name|getNumBuckets
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|!=
literal|null
operator|&&
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|BUCKET_FIELD_NAME
argument_list|,
name|sd
operator|.
name|getBucketCols
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|param
range|:
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getParameters
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|schema
operator|.
name|put
argument_list|(
name|param
operator|.
name|getKey
argument_list|()
argument_list|,
operator|(
name|param
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
operator|)
condition|?
name|param
operator|.
name|getValue
argument_list|()
else|:
literal|""
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_LIB
argument_list|,
name|sd
operator|.
name|getSerdeInfo
argument_list|()
operator|.
name|getSerializationLib
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sd
operator|.
name|getCols
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|serde
operator|.
name|serdeConstants
operator|.
name|SERIALIZATION_DDL
argument_list|,
name|getDDLFromFieldSchema
argument_list|(
name|tableName
argument_list|,
name|sd
operator|.
name|getCols
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|partString
init|=
literal|""
decl_stmt|;
name|String
name|partStringSep
init|=
literal|""
decl_stmt|;
name|String
name|partTypesString
init|=
literal|""
decl_stmt|;
name|String
name|partTypesStringSep
init|=
literal|""
decl_stmt|;
for|for
control|(
name|FieldSchema
name|partKey
range|:
name|partitionKeys
control|)
block|{
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partStringSep
argument_list|)
expr_stmt|;
name|partString
operator|=
name|partString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|partTypesString
operator|=
name|partTypesString
operator|.
name|concat
argument_list|(
name|partTypesStringSep
argument_list|)
expr_stmt|;
name|partTypesString
operator|=
name|partTypesString
operator|.
name|concat
argument_list|(
name|partKey
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|partStringSep
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|partStringSep
operator|=
literal|"/"
expr_stmt|;
name|partTypesStringSep
operator|=
literal|":"
expr_stmt|;
block|}
block|}
if|if
condition|(
name|partString
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMNS
argument_list|,
name|partString
argument_list|)
expr_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|hive_metastoreConstants
operator|.
name|META_TABLE_PARTITION_COLUMN_TYPES
argument_list|,
name|partTypesString
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|parameters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|parameters
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// add non-null parameters to the schema
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|schema
operator|.
name|setProperty
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|schema
return|;
block|}
specifier|public
specifier|static
name|Properties
name|getSchema
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|sd
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|StorageDescriptor
name|tblsd
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|databaseName
parameter_list|,
name|String
name|tableName
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|partitionKeys
parameter_list|)
block|{
return|return
name|addCols
argument_list|(
name|getSchemaWithoutCols
argument_list|(
name|sd
argument_list|,
name|tblsd
argument_list|,
name|parameters
argument_list|,
name|databaseName
argument_list|,
name|tableName
argument_list|,
name|partitionKeys
argument_list|)
argument_list|,
name|tblsd
operator|.
name|getCols
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Convert FieldSchemas to columnNames.    */
specifier|public
specifier|static
name|String
name|getColumnNamesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Convert FieldSchemas to columnTypes.    */
specifier|public
specifier|static
name|String
name|getColumnTypesFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|String
name|getColumnCommentsFromFieldSchema
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|fieldSchemas
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldSchemas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|SerDeUtils
operator|.
name|COLUMN_COMMENTS_DELIMITER
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|fieldSchemas
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getComment
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|void
name|makeDir
parameter_list|(
name|Path
name|path
parameter_list|,
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|MetaException
block|{
name|FileSystem
name|fs
decl_stmt|;
try|try
block|{
name|fs
operator|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|hiveConf
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|path
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Unable to : "
operator|+
name|path
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|int
name|startMetaStore
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|startMetaStore
argument_list|(
name|ShimLoader
operator|.
name|getHadoopThriftAuthBridge
argument_list|()
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|int
name|startMetaStore
parameter_list|(
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|,
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|port
init|=
name|findFreePort
argument_list|()
decl_stmt|;
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|,
name|conf
argument_list|)
expr_stmt|;
return|return
name|port
return|;
block|}
specifier|public
specifier|static
name|int
name|startMetaStore
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|startMetaStore
argument_list|(
name|ShimLoader
operator|.
name|getHadoopThriftAuthBridge
argument_list|()
argument_list|,
name|conf
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|startMetaStore
parameter_list|(
specifier|final
name|int
name|port
parameter_list|,
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|)
throws|throws
name|Exception
block|{
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|startMetaStore
parameter_list|(
specifier|final
name|int
name|port
parameter_list|,
specifier|final
name|HadoopThriftAuthBridge
name|bridge
parameter_list|,
name|HiveConf
name|hiveConf
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
name|hiveConf
operator|==
literal|null
condition|)
block|{
name|hiveConf
operator|=
operator|new
name|HiveConf
argument_list|(
name|HMSHandler
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
specifier|final
name|HiveConf
name|finalHiveConf
init|=
name|hiveConf
decl_stmt|;
name|Thread
name|thread
init|=
operator|new
name|Thread
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|HiveMetaStore
operator|.
name|startMetaStore
argument_list|(
name|port
argument_list|,
name|bridge
argument_list|,
name|finalHiveConf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Metastore Thrift Server threw an exception..."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|thread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|thread
operator|.
name|start
argument_list|()
expr_stmt|;
name|loopUntilHMSReady
argument_list|(
name|port
argument_list|)
expr_stmt|;
block|}
comment|/**    * A simple connect test to make sure that the metastore is up    * @throws Exception    */
specifier|private
specifier|static
name|void
name|loopUntilHMSReady
parameter_list|(
name|int
name|port
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|retries
init|=
literal|0
decl_stmt|;
name|Exception
name|exc
init|=
literal|null
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
name|Socket
name|socket
init|=
operator|new
name|Socket
argument_list|()
decl_stmt|;
name|socket
operator|.
name|connect
argument_list|(
operator|new
name|InetSocketAddress
argument_list|(
name|port
argument_list|)
argument_list|,
literal|5000
argument_list|)
expr_stmt|;
name|socket
operator|.
name|close
argument_list|()
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|retries
operator|++
operator|>
literal|60
condition|)
block|{
comment|//give up
name|exc
operator|=
name|e
expr_stmt|;
break|break;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
block|}
comment|// something is preventing metastore from starting
comment|// print the stack from all threads for debugging purposes
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to connect to metastore server: "
operator|+
name|exc
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Printing all thread stack traces for debugging before throwing exception."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|getAllThreadStacksAsString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|exc
throw|;
block|}
specifier|private
specifier|static
name|String
name|getAllThreadStacksAsString
parameter_list|()
block|{
name|Map
argument_list|<
name|Thread
argument_list|,
name|StackTraceElement
index|[]
argument_list|>
name|threadStacks
init|=
name|Thread
operator|.
name|getAllStackTraces
argument_list|()
decl_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Thread
argument_list|,
name|StackTraceElement
index|[]
argument_list|>
name|entry
range|:
name|threadStacks
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Thread
name|t
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|System
operator|.
name|lineSeparator
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"Name: "
argument_list|)
operator|.
name|append
argument_list|(
name|t
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|" State: "
operator|+
name|t
operator|.
name|getState
argument_list|()
argument_list|)
expr_stmt|;
name|addStackString
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|sb
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
specifier|static
name|void
name|addStackString
parameter_list|(
name|StackTraceElement
index|[]
name|stackElems
parameter_list|,
name|StringBuilder
name|sb
parameter_list|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|System
operator|.
name|lineSeparator
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|StackTraceElement
name|stackElem
range|:
name|stackElems
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|stackElem
argument_list|)
operator|.
name|append
argument_list|(
name|System
operator|.
name|lineSeparator
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Finds a free port on the machine.    *    * @return    * @throws IOException    */
specifier|public
specifier|static
name|int
name|findFreePort
parameter_list|()
throws|throws
name|IOException
block|{
name|ServerSocket
name|socket
init|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|int
name|port
init|=
name|socket
operator|.
name|getLocalPort
argument_list|()
decl_stmt|;
name|socket
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|port
return|;
block|}
comment|/**    * Finds a free port on the machine, but allow the    * ability to specify a port number to not use, no matter what.    */
specifier|public
specifier|static
name|int
name|findFreePortExcepting
parameter_list|(
name|int
name|portToExclude
parameter_list|)
throws|throws
name|IOException
block|{
name|ServerSocket
name|socket1
init|=
literal|null
decl_stmt|;
name|ServerSocket
name|socket2
init|=
literal|null
decl_stmt|;
try|try
block|{
name|socket1
operator|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|socket2
operator|=
operator|new
name|ServerSocket
argument_list|(
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|socket1
operator|.
name|getLocalPort
argument_list|()
operator|!=
name|portToExclude
condition|)
block|{
return|return
name|socket1
operator|.
name|getLocalPort
argument_list|()
return|;
block|}
comment|// If we're here, then socket1.getLocalPort was the port to exclude
comment|// Since both sockets were open together at a point in time, we're
comment|// guaranteed that socket2.getLocalPort() is not the same.
return|return
name|socket2
operator|.
name|getLocalPort
argument_list|()
return|;
block|}
finally|finally
block|{
if|if
condition|(
name|socket1
operator|!=
literal|null
condition|)
block|{
name|socket1
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|socket2
operator|!=
literal|null
condition|)
block|{
name|socket2
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Catches exceptions that can't be handled and bundles them to MetaException    *    * @param e    * @throws MetaException    */
specifier|static
name|void
name|logAndThrowMetaException
parameter_list|(
name|Exception
name|e
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|exInfo
init|=
literal|"Got exception: "
operator|+
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|exInfo
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Converting exception to MetaException"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|MetaException
argument_list|(
name|exInfo
argument_list|)
throw|;
block|}
comment|/**    * @param tableName    * @param deserializer    * @return the list of fields    * @throws SerDeException    * @throws MetaException    */
specifier|public
specifier|static
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|getFieldsFromDeserializer
parameter_list|(
name|String
name|tableName
parameter_list|,
name|Deserializer
name|deserializer
parameter_list|)
throws|throws
name|SerDeException
throws|,
name|MetaException
block|{
name|ObjectInspector
name|oi
init|=
name|deserializer
operator|.
name|getObjectInspector
argument_list|()
decl_stmt|;
name|String
index|[]
name|names
init|=
name|tableName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
name|String
name|last_name
init|=
name|names
index|[
name|names
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|names
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|oi
operator|instanceof
name|StructObjectInspector
condition|)
block|{
name|StructObjectInspector
name|soi
init|=
operator|(
name|StructObjectInspector
operator|)
name|oi
decl_stmt|;
name|StructField
name|sf
init|=
name|soi
operator|.
name|getStructFieldRef
argument_list|(
name|names
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|sf
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Invalid Field "
operator|+
name|names
index|[
name|i
index|]
argument_list|)
throw|;
block|}
else|else
block|{
name|oi
operator|=
name|sf
operator|.
name|getFieldObjectInspector
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|oi
operator|instanceof
name|ListObjectInspector
operator|&&
name|names
index|[
name|i
index|]
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"$elem$"
argument_list|)
condition|)
block|{
name|ListObjectInspector
name|loi
init|=
operator|(
name|ListObjectInspector
operator|)
name|oi
decl_stmt|;
name|oi
operator|=
name|loi
operator|.
name|getListElementObjectInspector
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oi
operator|instanceof
name|MapObjectInspector
operator|&&
name|names
index|[
name|i
index|]
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"$key$"
argument_list|)
condition|)
block|{
name|MapObjectInspector
name|moi
init|=
operator|(
name|MapObjectInspector
operator|)
name|oi
decl_stmt|;
name|oi
operator|=
name|moi
operator|.
name|getMapKeyObjectInspector
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oi
operator|instanceof
name|MapObjectInspector
operator|&&
name|names
index|[
name|i
index|]
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"$value$"
argument_list|)
condition|)
block|{
name|MapObjectInspector
name|moi
init|=
operator|(
name|MapObjectInspector
operator|)
name|oi
decl_stmt|;
name|oi
operator|=
name|moi
operator|.
name|getMapValueObjectInspector
argument_list|()
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Unknown type for "
operator|+
name|names
index|[
name|i
index|]
argument_list|)
throw|;
block|}
block|}
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
name|str_fields
init|=
operator|new
name|ArrayList
argument_list|<
name|FieldSchema
argument_list|>
argument_list|()
decl_stmt|;
comment|// rules on how to recurse the ObjectInspector based on its type
if|if
condition|(
name|oi
operator|.
name|getCategory
argument_list|()
operator|!=
name|Category
operator|.
name|STRUCT
condition|)
block|{
name|str_fields
operator|.
name|add
argument_list|(
operator|new
name|FieldSchema
argument_list|(
name|last_name
argument_list|,
name|oi
operator|.
name|getTypeName
argument_list|()
argument_list|,
name|FROM_SERIALIZER
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|?
extends|extends
name|StructField
argument_list|>
name|fields
init|=
operator|(
operator|(
name|StructObjectInspector
operator|)
name|oi
operator|)
operator|.
name|getAllStructFieldRefs
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fields
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|StructField
name|structField
init|=
name|fields
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|String
name|fieldName
init|=
name|structField
operator|.
name|getFieldName
argument_list|()
decl_stmt|;
name|String
name|fieldTypeName
init|=
name|structField
operator|.
name|getFieldObjectInspector
argument_list|()
operator|.
name|getTypeName
argument_list|()
decl_stmt|;
name|String
name|fieldComment
init|=
name|determineFieldComment
argument_list|(
name|structField
operator|.
name|getFieldComment
argument_list|()
argument_list|)
decl_stmt|;
name|str_fields
operator|.
name|add
argument_list|(
operator|new
name|FieldSchema
argument_list|(
name|fieldName
argument_list|,
name|fieldTypeName
argument_list|,
name|fieldComment
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|str_fields
return|;
block|}
specifier|private
specifier|static
specifier|final
name|String
name|FROM_SERIALIZER
init|=
literal|"from deserializer"
decl_stmt|;
specifier|private
specifier|static
name|String
name|determineFieldComment
parameter_list|(
name|String
name|comment
parameter_list|)
block|{
return|return
operator|(
name|comment
operator|==
literal|null
operator|)
condition|?
name|FROM_SERIALIZER
else|:
name|comment
return|;
block|}
comment|/**    * Convert TypeInfo to FieldSchema.    */
specifier|public
specifier|static
name|FieldSchema
name|getFieldSchemaFromTypeInfo
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TypeInfo
name|typeInfo
parameter_list|)
block|{
return|return
operator|new
name|FieldSchema
argument_list|(
name|fieldName
argument_list|,
name|typeInfo
operator|.
name|getTypeName
argument_list|()
argument_list|,
literal|"generated by TypeInfoUtils.getFieldSchemaFromTypeInfo"
argument_list|)
return|;
block|}
comment|/**    * Determines whether a table is an external table.    *    * @param table table of interest    *    * @return true if external    */
specifier|public
specifier|static
name|boolean
name|isExternalTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
literal|"EXTERNAL"
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Determines whether a table is an immutable table.    * Immutable tables are write-once/replace, and do not support append. Partitioned    * immutable tables do support additions by way of creation of new partitions, but    * do not allow the partitions themselves to be appended to. "INSERT INTO" will not    * work for Immutable tables.    *    * @param table table of interest    *    * @return true if immutable    */
specifier|public
specifier|static
name|boolean
name|isImmutableTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|table
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
name|params
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|"TRUE"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|IS_IMMUTABLE
argument_list|)
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isArchived
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
if|if
condition|(
literal|"true"
operator|.
name|equalsIgnoreCase
argument_list|(
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|IS_ARCHIVED
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
specifier|public
specifier|static
name|Path
name|getOriginalLocation
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Partition
name|part
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
init|=
name|part
operator|.
name|getParameters
argument_list|()
decl_stmt|;
assert|assert
operator|(
name|isArchived
argument_list|(
name|part
argument_list|)
operator|)
assert|;
name|String
name|originalLocation
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|ORIGINAL_LOCATION
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|originalLocation
operator|!=
literal|null
operator|)
assert|;
return|return
operator|new
name|Path
argument_list|(
name|originalLocation
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isNonNativeTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|(
name|table
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|META_TABLE_STORAGE
argument_list|)
operator|!=
literal|null
operator|)
return|;
block|}
comment|/**    * Filter that filters out hidden files    */
specifier|private
specifier|static
specifier|final
name|PathFilter
name|hiddenFileFilter
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
name|name
init|=
name|p
operator|.
name|getName
argument_list|()
decl_stmt|;
return|return
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
operator|!
name|name
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Utility method that determines if a specified directory already has    * contents (non-hidden files) or not - useful to determine if an    * immutable table already has contents, for example.    *    * @param path    * @throws IOException    */
specifier|public
specifier|static
name|boolean
name|isDirEmpty
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|path
argument_list|)
condition|)
block|{
name|FileStatus
index|[]
name|status
init|=
name|fs
operator|.
name|globStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|,
literal|"*"
argument_list|)
argument_list|,
name|hiddenFileFilter
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|.
name|length
operator|>
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Returns true if partial has the same values as full for all values that    * aren't empty in partial.    */
specifier|public
specifier|static
name|boolean
name|pvalMatches
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partial
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|full
parameter_list|)
block|{
if|if
condition|(
name|partial
operator|.
name|size
argument_list|()
operator|>
name|full
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|Iterator
argument_list|<
name|String
argument_list|>
name|p
init|=
name|partial
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|String
argument_list|>
name|f
init|=
name|full
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|p
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|String
name|pval
init|=
name|p
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|fval
init|=
name|f
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|pval
operator|.
name|length
argument_list|()
operator|!=
literal|0
operator|&&
operator|!
name|pval
operator|.
name|equals
argument_list|(
name|fval
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|public
specifier|static
name|String
name|getIndexTableName
parameter_list|(
name|String
name|dbName
parameter_list|,
name|String
name|baseTblName
parameter_list|,
name|String
name|indexName
parameter_list|)
block|{
return|return
name|dbName
operator|+
literal|"__"
operator|+
name|baseTblName
operator|+
literal|"_"
operator|+
name|indexName
operator|+
literal|"__"
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isIndexTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|INDEX_TABLE
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isMaterializedViewTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|MATERIALIZED_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Given a map of partition column names to values, this creates a filter    * string that can be used to call the *byFilter methods    * @param m    * @return the filter string    */
specifier|public
specifier|static
name|String
name|makeFilterStringFromMap
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|m
parameter_list|)
block|{
name|StringBuilder
name|filter
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|m
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|col
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|String
name|val
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|filter
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|filter
operator|.
name|append
argument_list|(
name|col
operator|+
literal|"=\""
operator|+
name|val
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|filter
operator|.
name|append
argument_list|(
literal|" and "
operator|+
name|col
operator|+
literal|"=\""
operator|+
name|val
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|filter
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isView
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|TableType
operator|.
name|VIRTUAL_VIEW
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|table
operator|.
name|getTableType
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * create listener instances as per the configuration.    *    * @param clazz    * @param conf    * @param listenerImplList    * @return    * @throws MetaException    */
specifier|static
parameter_list|<
name|T
parameter_list|>
name|List
argument_list|<
name|T
argument_list|>
name|getMetaStoreListeners
parameter_list|(
name|Class
argument_list|<
name|T
argument_list|>
name|clazz
parameter_list|,
name|HiveConf
name|conf
parameter_list|,
name|String
name|listenerImplList
parameter_list|)
throws|throws
name|MetaException
block|{
name|List
argument_list|<
name|T
argument_list|>
name|listeners
init|=
operator|new
name|ArrayList
argument_list|<
name|T
argument_list|>
argument_list|()
decl_stmt|;
name|listenerImplList
operator|=
name|listenerImplList
operator|.
name|trim
argument_list|()
expr_stmt|;
if|if
condition|(
name|listenerImplList
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
return|return
name|listeners
return|;
block|}
name|String
index|[]
name|listenerImpls
init|=
name|listenerImplList
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|listenerImpl
range|:
name|listenerImpls
control|)
block|{
try|try
block|{
name|T
name|listener
init|=
operator|(
name|T
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|listenerImpl
operator|.
name|trim
argument_list|()
argument_list|,
literal|true
argument_list|,
name|JavaUtils
operator|.
name|getClassLoader
argument_list|()
argument_list|)
operator|.
name|getConstructor
argument_list|(
name|Configuration
operator|.
name|class
argument_list|)
operator|.
name|newInstance
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InvocationTargetException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|ie
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Failed to instantiate listener named: "
operator|+
name|listenerImpl
operator|+
literal|", reason: "
operator|+
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|listeners
return|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|public
specifier|static
name|Class
argument_list|<
name|?
extends|extends
name|RawStore
argument_list|>
name|getClass
parameter_list|(
name|String
name|rawStoreClassName
parameter_list|)
throws|throws
name|MetaException
block|{
try|try
block|{
return|return
operator|(
name|Class
argument_list|<
name|?
extends|extends
name|RawStore
argument_list|>
operator|)
name|Class
operator|.
name|forName
argument_list|(
name|rawStoreClassName
argument_list|,
literal|true
argument_list|,
name|JavaUtils
operator|.
name|getClassLoader
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
name|rawStoreClassName
operator|+
literal|" class not found"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create an object of the given class.    * @param theClass    * @param parameterTypes    *          an array of parameterTypes for the constructor    * @param initargs    *          the list of arguments for the constructor    */
specifier|public
specifier|static
parameter_list|<
name|T
parameter_list|>
name|T
name|newInstance
parameter_list|(
name|Class
argument_list|<
name|T
argument_list|>
name|theClass
parameter_list|,
name|Class
argument_list|<
name|?
argument_list|>
index|[]
name|parameterTypes
parameter_list|,
name|Object
index|[]
name|initargs
parameter_list|)
block|{
comment|// Perform some sanity checks on the arguments.
if|if
condition|(
name|parameterTypes
operator|.
name|length
operator|!=
name|initargs
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Number of constructor parameter types doesn't match number of arguments"
argument_list|)
throw|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|parameterTypes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
init|=
name|parameterTypes
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|clazz
operator|.
name|isInstance
argument_list|(
name|initargs
index|[
name|i
index|]
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Object : "
operator|+
name|initargs
index|[
name|i
index|]
operator|+
literal|" is not an instance of "
operator|+
name|clazz
argument_list|)
throw|;
block|}
block|}
try|try
block|{
name|Constructor
argument_list|<
name|T
argument_list|>
name|meth
init|=
name|theClass
operator|.
name|getDeclaredConstructor
argument_list|(
name|parameterTypes
argument_list|)
decl_stmt|;
name|meth
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|meth
operator|.
name|newInstance
argument_list|(
name|initargs
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unable to instantiate "
operator|+
name|theClass
operator|.
name|getName
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|void
name|validatePartitionNameCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
throws|throws
name|MetaException
block|{
name|String
name|invalidPartitionVal
init|=
name|HiveStringUtils
operator|.
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
decl_stmt|;
if|if
condition|(
name|invalidPartitionVal
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Partition value '"
operator|+
name|invalidPartitionVal
operator|+
literal|"' contains a character "
operator|+
literal|"not matched by whitelist pattern '"
operator|+
name|partitionValidationPattern
operator|.
name|toString
argument_list|()
operator|+
literal|"'.  "
operator|+
literal|"(configure with "
operator|+
name|HiveConf
operator|.
name|ConfVars
operator|.
name|METASTORE_PARTITION_NAME_WHITELIST_PATTERN
operator|.
name|varname
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
name|boolean
name|partitionNameHasValidCharacters
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|partVals
parameter_list|,
name|Pattern
name|partitionValidationPattern
parameter_list|)
block|{
return|return
name|HiveStringUtils
operator|.
name|getPartitionValWithInvalidCharacter
argument_list|(
name|partVals
argument_list|,
name|partitionValidationPattern
argument_list|)
operator|==
literal|null
return|;
block|}
comment|/**    * @param schema1: The first schema to be compared    * @param schema2: The second schema to be compared    * @return true if the two schemas are the same else false    *         for comparing a field we ignore the comment it has    */
specifier|public
specifier|static
name|boolean
name|compareFieldColumns
parameter_list|(
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema1
parameter_list|,
name|List
argument_list|<
name|FieldSchema
argument_list|>
name|schema2
parameter_list|)
block|{
if|if
condition|(
name|schema1
operator|.
name|size
argument_list|()
operator|!=
name|schema2
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|schema1
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|FieldSchema
name|f1
init|=
name|schema1
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|FieldSchema
name|f2
init|=
name|schema2
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// The default equals provided by thrift compares the comments too for
comment|// equality, thus we need to compare the relevant fields here.
if|if
condition|(
name|f1
operator|.
name|getName
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|f2
operator|.
name|getName
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|f1
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|f2
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|f1
operator|.
name|getType
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|f2
operator|.
name|getType
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|f1
operator|.
name|getType
argument_list|()
operator|.
name|equals
argument_list|(
name|f2
operator|.
name|getType
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Read and return the meta store Sasl configuration. Currently it uses the default    * Hadoop SASL configuration and can be configured using "hadoop.rpc.protection"    * HADOOP-10211, made a backward incompatible change due to which this call doesn't    * work with Hadoop 2.4.0 and later.    * @param conf    * @return The SASL configuration    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getMetaStoreSaslProperties
parameter_list|(
name|HiveConf
name|conf
parameter_list|)
block|{
comment|// As of now Hive Meta Store uses the same configuration as Hadoop SASL configuration
return|return
name|ShimLoader
operator|.
name|getHadoopThriftAuthBridge
argument_list|()
operator|.
name|getHadoopSaslProperties
argument_list|(
name|conf
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|ARCHIVING_LEVEL
init|=
literal|"archiving_level"
decl_stmt|;
specifier|public
specifier|static
name|int
name|getArchivingLevel
parameter_list|(
name|Partition
name|part
parameter_list|)
throws|throws
name|MetaException
block|{
if|if
condition|(
operator|!
name|isArchived
argument_list|(
name|part
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MetaException
argument_list|(
literal|"Getting level of unarchived partition"
argument_list|)
throw|;
block|}
name|String
name|lv
init|=
name|part
operator|.
name|getParameters
argument_list|()
operator|.
name|get
argument_list|(
name|ARCHIVING_LEVEL
argument_list|)
decl_stmt|;
if|if
condition|(
name|lv
operator|!=
literal|null
condition|)
block|{
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|lv
argument_list|)
return|;
block|}
else|else
block|{
comment|// partitions archived before introducing multiple archiving
return|return
name|part
operator|.
name|getValues
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
block|}
specifier|public
specifier|static
name|String
index|[]
name|getQualifiedName
parameter_list|(
name|String
name|defaultDbName
parameter_list|,
name|String
name|tableName
parameter_list|)
block|{
name|String
index|[]
name|names
init|=
name|tableName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|length
operator|==
literal|1
condition|)
block|{
return|return
operator|new
name|String
index|[]
block|{
name|defaultDbName
block|,
name|tableName
block|}
return|;
block|}
return|return
operator|new
name|String
index|[]
block|{
name|names
index|[
literal|0
index|]
block|,
name|names
index|[
literal|1
index|]
block|}
return|;
block|}
comment|/**    * Helper function to transform Nulls to empty strings.    */
specifier|private
specifier|static
specifier|final
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|transFormNullsToEmptyString
init|=
operator|new
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|java
operator|.
name|lang
operator|.
name|String
name|apply
parameter_list|(
annotation|@
name|Nullable
name|java
operator|.
name|lang
operator|.
name|String
name|string
parameter_list|)
block|{
if|if
condition|(
name|string
operator|==
literal|null
condition|)
block|{
return|return
literal|""
return|;
block|}
else|else
block|{
return|return
name|string
return|;
block|}
block|}
block|}
decl_stmt|;
comment|/**    * We have aneed to sanity-check the map before conversion from persisted objects to    * metadata thrift objects because null values in maps will cause a NPE if we send    * across thrift. Pruning is appropriate for most cases except for databases such as    * Oracle where Empty strings are stored as nulls, in which case we need to handle that.    * See HIVE-8485 for motivations for this.    */
specifier|public
specifier|static
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|trimMapNulls
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|dnMap
parameter_list|,
name|boolean
name|retrieveMapNullsAsEmptyStrings
parameter_list|)
block|{
if|if
condition|(
name|dnMap
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Must be deterministic order map - see HIVE-8707
comment|//   => we use Maps.newLinkedHashMap instead of Maps.newHashMap
if|if
condition|(
name|retrieveMapNullsAsEmptyStrings
condition|)
block|{
comment|// convert any nulls present in map values to empty strings - this is done in the case
comment|// of backing dbs like oracle which persist empty strings as nulls.
return|return
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|Maps
operator|.
name|transformValues
argument_list|(
name|dnMap
argument_list|,
name|transFormNullsToEmptyString
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// prune any nulls present in map values - this is the typical case.
return|return
name|Maps
operator|.
name|newLinkedHashMap
argument_list|(
name|Maps
operator|.
name|filterValues
argument_list|(
name|dnMap
argument_list|,
name|Predicates
operator|.
name|notNull
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**    * Create a URL from a string representing a path to a local file.    * The path string can be just a path, or can start with file:/, file:///    * @param onestr  path string    * @return    */
specifier|private
specifier|static
name|URL
name|urlFromPathString
parameter_list|(
name|String
name|onestr
parameter_list|)
block|{
name|URL
name|oneurl
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|StringUtils
operator|.
name|indexOf
argument_list|(
name|onestr
argument_list|,
literal|"file:/"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|oneurl
operator|=
operator|new
name|URL
argument_list|(
name|onestr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|oneurl
operator|=
operator|new
name|File
argument_list|(
name|onestr
argument_list|)
operator|.
name|toURL
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|err
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad URL "
operator|+
name|onestr
operator|+
literal|", ignoring path"
argument_list|)
expr_stmt|;
block|}
return|return
name|oneurl
return|;
block|}
comment|/**    * Add new elements to the classpath.    *    * @param newPaths    *          Array of classpath elements    */
specifier|public
specifier|static
name|ClassLoader
name|addToClassPath
parameter_list|(
name|ClassLoader
name|cloader
parameter_list|,
name|String
index|[]
name|newPaths
parameter_list|)
throws|throws
name|Exception
block|{
name|URLClassLoader
name|loader
init|=
operator|(
name|URLClassLoader
operator|)
name|cloader
decl_stmt|;
name|List
argument_list|<
name|URL
argument_list|>
name|curPath
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|loader
operator|.
name|getURLs
argument_list|()
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|URL
argument_list|>
name|newPath
init|=
operator|new
name|ArrayList
argument_list|<
name|URL
argument_list|>
argument_list|()
decl_stmt|;
comment|// get a list with the current classpath components
for|for
control|(
name|URL
name|onePath
range|:
name|curPath
control|)
block|{
name|newPath
operator|.
name|add
argument_list|(
name|onePath
argument_list|)
expr_stmt|;
block|}
name|curPath
operator|=
name|newPath
expr_stmt|;
for|for
control|(
name|String
name|onestr
range|:
name|newPaths
control|)
block|{
name|URL
name|oneurl
init|=
name|urlFromPathString
argument_list|(
name|onestr
argument_list|)
decl_stmt|;
if|if
condition|(
name|oneurl
operator|!=
literal|null
operator|&&
operator|!
name|curPath
operator|.
name|contains
argument_list|(
name|oneurl
argument_list|)
condition|)
block|{
name|curPath
operator|.
name|add
argument_list|(
name|oneurl
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|URLClassLoader
argument_list|(
name|curPath
operator|.
name|toArray
argument_list|(
operator|new
name|URL
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|loader
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|String
name|encodeTableName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
comment|// The encoding method is simple, e.g., replace
comment|// all the special characters with the corresponding number in ASCII.
comment|// Note that unicode is not supported in table names. And we have explicit
comment|// checks for it.
name|String
name|ret
init|=
literal|""
decl_stmt|;
for|for
control|(
name|char
name|ch
range|:
name|name
operator|.
name|toCharArray
argument_list|()
control|)
block|{
if|if
condition|(
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|ch
argument_list|)
operator|||
name|ch
operator|==
literal|'_'
condition|)
block|{
name|ret
operator|+=
name|ch
expr_stmt|;
block|}
else|else
block|{
name|ret
operator|+=
literal|"-"
operator|+
operator|(
name|int
operator|)
name|ch
operator|+
literal|"-"
expr_stmt|;
block|}
block|}
return|return
name|ret
return|;
block|}
comment|// this function will merge csOld into csNew.
specifier|public
specifier|static
name|void
name|mergeColStats
parameter_list|(
name|ColumnStatistics
name|csNew
parameter_list|,
name|ColumnStatistics
name|csOld
parameter_list|)
throws|throws
name|InvalidObjectException
block|{
name|List
argument_list|<
name|ColumnStatisticsObj
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|csOld
operator|.
name|getStatsObjSize
argument_list|()
condition|)
block|{
comment|// Some of the columns' stats are missing
comment|// This implies partition schema has changed. We will merge columns
comment|// present in both, overwrite stats for columns absent in metastore and
comment|// leave alone columns stats missing from stats task. This last case may
comment|// leave stats in stale state. This will be addressed later.
name|LOG
operator|.
name|debug
argument_list|(
literal|"New ColumnStats size is "
operator|+
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|". But old ColumnStats size is "
operator|+
name|csOld
operator|.
name|getStatsObjSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// In this case, we have to find out which columns can be merged.
name|Map
argument_list|<
name|String
argument_list|,
name|ColumnStatisticsObj
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|// We build a hash map from colName to object for old ColumnStats.
for|for
control|(
name|ColumnStatisticsObj
name|obj
range|:
name|csOld
operator|.
name|getStatsObj
argument_list|()
control|)
block|{
name|map
operator|.
name|put
argument_list|(
name|obj
operator|.
name|getColName
argument_list|()
argument_list|,
name|obj
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|index
init|=
literal|0
init|;
name|index
operator|<
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|index
operator|++
control|)
block|{
name|ColumnStatisticsObj
name|statsObjNew
init|=
name|csNew
operator|.
name|getStatsObj
argument_list|()
operator|.
name|get
argument_list|(
name|index
argument_list|)
decl_stmt|;
name|ColumnStatisticsObj
name|statsObjOld
init|=
name|map
operator|.
name|get
argument_list|(
name|statsObjNew
operator|.
name|getColName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|statsObjOld
operator|!=
literal|null
condition|)
block|{
comment|// If statsObjOld is found, we can merge.
name|ColumnStatsMerger
name|merger
init|=
name|ColumnStatsMergerFactory
operator|.
name|getColumnStatsMerger
argument_list|(
name|statsObjNew
argument_list|,
name|statsObjOld
argument_list|)
decl_stmt|;
name|merger
operator|.
name|merge
argument_list|(
name|statsObjNew
argument_list|,
name|statsObjOld
argument_list|)
expr_stmt|;
block|}
name|list
operator|.
name|add
argument_list|(
name|statsObjNew
argument_list|)
expr_stmt|;
block|}
name|csNew
operator|.
name|setStatsObj
argument_list|(
name|list
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|boolean
name|isMmTable
parameter_list|(
name|Table
name|table
parameter_list|)
block|{
return|return
name|isMmTable
argument_list|(
name|table
operator|.
name|getParameters
argument_list|()
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|isMmTable
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|params
parameter_list|)
block|{
comment|// TODO: perhaps it should be a 3rd value for 'transactional'?
name|String
name|value
init|=
name|params
operator|.
name|get
argument_list|(
name|hive_metastoreConstants
operator|.
name|TABLE_IS_MM
argument_list|)
decl_stmt|;
return|return
name|value
operator|!=
literal|null
operator|&&
name|value
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"true"
argument_list|)
return|;
block|}
block|}
end_class

end_unit

