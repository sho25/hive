begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
package|;
end_package

begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|MetaException
import|;
end_import

begin_class
specifier|public
class|class
name|TestAlter
extends|extends
name|MetaStoreTestBase
block|{
specifier|public
name|TestAlter
parameter_list|()
throws|throws
name|Exception
block|{   }
specifier|public
name|void
name|testAlter
parameter_list|()
throws|throws
name|Exception
block|{
try|try
block|{
name|DB
name|db
init|=
name|DB
operator|.
name|createDB
argument_list|(
literal|"foo1"
argument_list|,
name|conf_
argument_list|)
decl_stmt|;
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tables
init|=
name|db
operator|.
name|getTables
argument_list|(
literal|".+"
argument_list|)
decl_stmt|;
comment|//        System.err.println("tables=" + tables);
name|assertTrue
argument_list|(
name|tables
operator|.
name|size
argument_list|()
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
name|Table
name|bar1
init|=
name|Table
operator|.
name|create
argument_list|(
name|db
argument_list|,
literal|"bar1"
argument_list|,
name|createSchema
argument_list|(
literal|"foo1"
argument_list|,
literal|"bar1"
argument_list|)
argument_list|,
name|conf_
argument_list|)
decl_stmt|;
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tables
init|=
name|db
operator|.
name|getTables
argument_list|(
literal|".+"
argument_list|)
decl_stmt|;
comment|//        System.err.println("tables=" + tables);
name|assertTrue
argument_list|(
name|tables
operator|.
name|size
argument_list|()
operator|==
literal|1
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|tables
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|equals
argument_list|(
literal|"bar1"
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Properties
name|schema
init|=
name|bar1
operator|.
name|getSchema
argument_list|()
decl_stmt|;
name|schema
operator|.
name|setProperty
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hive
operator|.
name|metastore
operator|.
name|api
operator|.
name|Constants
operator|.
name|META_TABLE_NAME
argument_list|,
literal|"bar2"
argument_list|)
expr_stmt|;
name|bar1
operator|.
name|alter
argument_list|(
name|schema
argument_list|)
expr_stmt|;
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tables
init|=
name|db
operator|.
name|getTables
argument_list|(
literal|".+"
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|tables
operator|.
name|size
argument_list|()
operator|==
literal|1
argument_list|)
expr_stmt|;
comment|//        System.err.println("tables=" + tables);
name|assertTrue
argument_list|(
name|tables
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|equals
argument_list|(
literal|"bar2"
argument_list|)
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|bar1
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|ref
init|=
operator|new
name|Path
argument_list|(
name|db
operator|.
name|getPath
argument_list|()
argument_list|,
literal|"bar2"
argument_list|)
decl_stmt|;
comment|//        System.err.println("path=" + path);
name|assertTrue
argument_list|(
name|path
operator|.
name|equals
argument_list|(
name|ref
argument_list|)
argument_list|)
expr_stmt|;
name|FileStatus
name|files
index|[]
init|=
name|fileSys_
operator|.
name|listStatus
argument_list|(
name|db
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
comment|//        for(FileStatus p: files) {
comment|//          System.err.println("path=" + p.getPath());
comment|//        }
comment|// bugbug not running below now because in file:// hdfs mode, seem to get two copies for each file
comment|// one with just /tmp/.../..  and another with file:/tmp/.../..
comment|//        assertTrue(files.length == 1);
comment|//        assertTrue(files[0].getPath().equals(ref));
block|}
comment|//        cleanup();
block|}
catch|catch
parameter_list|(
name|MetaException
name|e
parameter_list|)
block|{
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
block|}
end_class

end_unit

